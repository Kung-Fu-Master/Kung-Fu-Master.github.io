{"meta":{"version":1,"warehouse":"3.0.2"},"models":{"Asset":[{"_id":"themes/3-hexo/source/css/gitalk.css","path":"css/gitalk.css","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/mobile.styl","path":"css/mobile.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/img/article-list-background.jpeg","path":"img/article-list-background.jpeg","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/img/gov.png","path":"img/gov.png","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/img/brown-papersq.png","path":"img/brown-papersq.png","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/img/school-book.png","path":"img/school-book.png","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/js/iconfont.js","path":"js/iconfont.js","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/js/jquery.pjax.js","path":"js/jquery.pjax.js","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/js/script.js","path":"js/script.js","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/js/search.js","path":"js/search.js","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/img/avatar.jpg","path":"img/avatar.jpg","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/js/titleTip.js","path":"js/titleTip.js","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/img/alipay.jpg","path":"img/alipay.jpg","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/img/weixin.jpg","path":"img/weixin.jpg","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/icomoon.svg","path":"css/fonts/icomoon.svg","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/icomoon.eot","path":"css/fonts/icomoon.eot","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/icomoon.woff","path":"css/fonts/icomoon.woff","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/icomoon.ttf","path":"css/fonts/icomoon.ttf","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/iconfont.svg","path":"css/fonts/iconfont.svg","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/iconfont.eot","path":"css/fonts/iconfont.eot","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/iconfont.woff","path":"css/fonts/iconfont.woff","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/iconfont.ttf","path":"css/fonts/iconfont.ttf","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/selection.json","path":"css/fonts/selection.json","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/atom-dark.styl","path":"css/hl_theme/atom-dark.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/atom-light.styl","path":"css/hl_theme/atom-light.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/brown-paper.styl","path":"css/hl_theme/brown-paper.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/darcula.styl","path":"css/hl_theme/darcula.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/github-gist.styl","path":"css/hl_theme/github-gist.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/github.styl","path":"css/hl_theme/github.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/gruvbox-dark.styl","path":"css/hl_theme/gruvbox-dark.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/gruvbox-light.styl","path":"css/hl_theme/gruvbox-light.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/kimbie-dark.styl","path":"css/hl_theme/kimbie-dark.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/kimbie-light.styl","path":"css/hl_theme/kimbie-light.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/railscasts.styl","path":"css/hl_theme/railscasts.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/rainbow.styl","path":"css/hl_theme/rainbow.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/school-book.styl","path":"css/hl_theme/school-book.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/sublime.styl","path":"css/hl_theme/sublime.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/sunburst.styl","path":"css/hl_theme/sunburst.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/zenbum.styl","path":"css/hl_theme/zenbum.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/iconfont.woff2","path":"css/fonts/iconfont.woff2","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/js/gitment.js","path":"js/gitment.js","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/js/gitalk.js","path":"js/gitalk.js","modified":0,"renderable":1}],"Cache":[{"_id":"themes/3-hexo/.DS_Store","hash":"0770f9d42bfdd8d420de48fed463015e001cf579","modified":1597237660796},{"_id":"themes/3-hexo/.gitignore","hash":"46eca80fe689a00cbe4d015c094702af54119021","modified":1597237527283},{"_id":"themes/3-hexo/LICENSE","hash":"b04140c5f682db2b300428f97bb164fd7f5f18bd","modified":1597237527286},{"_id":"themes/3-hexo/README.md","hash":"8039597b22ca957af75f9167edd9ad640f12b496","modified":1597246688007},{"_id":"themes/3-hexo/_config.yml","hash":"984ad7ed208726b2517bc85cdf95cbd29ae4d6de","modified":1597246066943},{"_id":"source/_posts/hello-world.md","hash":"acad91ace80b80295b11a9b7ad4c29a2dcfdd8fb","modified":1581598064230},{"_id":"themes/3-hexo/git.bak/FETCH_HEAD","hash":"424b774dc37bc0f04562834ebc57413798646265","modified":1597237672397},{"_id":"themes/3-hexo/git.bak/HEAD","hash":"509e0f78e789c5517a73f9884e9c4d0c89abf07b","modified":1581598064674},{"_id":"themes/3-hexo/git.bak/ORIG_HEAD","hash":"dd1e560dba03636d502a133176c3b83d578721b4","modified":1597237672461},{"_id":"themes/3-hexo/git.bak/config","hash":"74be0249edf475f3cf43bc953d62bd9f0ee6d52e","modified":1581598064677},{"_id":"themes/3-hexo/git.bak/description","hash":"88d76a8724b84a5bbcc3bea08650bc679a0b3da6","modified":1581598064681},{"_id":"themes/3-hexo/git.bak/index","hash":"7646c610fbb7ded84ce47f25e643cc5cdbfe3aac","modified":1597237660805},{"_id":"themes/3-hexo/git.bak/packed-refs","hash":"7186860381ac8a4fa8a028dd797e76ccc557ccb8","modified":1581598064798},{"_id":"themes/3-hexo/languages/en.yml","hash":"616e02c035c86033ab4a97c5ae9e0a9e5f0b8ea3","modified":1597237527290},{"_id":"themes/3-hexo/languages/zh-CN.yml","hash":"83633d45420c96dfac41333aeac3f3616dca5286","modified":1597237527291},{"_id":"themes/3-hexo/layout/index.ejs","hash":"1c185288c2925a652d577965626718e12df07f65","modified":1597237527301},{"_id":"themes/3-hexo/layout/indexs.md","hash":"7804d0ea54f6d824cc5784773dc6d85d0f55e711","modified":1597237660800},{"_id":"themes/3-hexo/layout/post.ejs","hash":"a0eaba41e7ec9db5843af482470a45531049b457","modified":1597237527303},{"_id":"themes/3-hexo/source/.DS_Store","hash":"fdcc907c46e093a14b153c5dc8c038461997ed3c","modified":1597237660800},{"_id":"source/_posts/Englist_Learn/Englisth1.md","hash":"487bd620c64b07b02566c5151fbc9c8a0cfa08c8","modified":1586174953377},{"_id":"source/_posts/blogs/HTTP_TCP_Socket.md","hash":"3dd3ebf4ffa88a60d9c7d5d445a8585f823e3248","modified":1593760649032},{"_id":"source/_posts/blogs/Hexo_01_部署github_blog.md","hash":"68299adab289edf6a714ca8e3195b8e752c8b126","modified":1597236124092},{"_id":"source/_posts/blogs/Hexo_02_git_clone_blog后如何运行 - 副本.md","hash":"f97eb8901456e485f360679e5f826e0eb0fdb865","modified":1597234112334},{"_id":"source/_posts/blogs/Hexo_03_写博客语法.md","hash":"8cb36360f54e518f935774301d1f43316bfe12fd","modified":1597248831718},{"_id":"source/_posts/blogs/Restful_API.md","hash":"cff9326039e26752e0045507c27d3361332c1602","modified":1593760658331},{"_id":"source/_posts/deeplearning/deeplearning_01_get_started.md","hash":"f8ed9eff6ed40e825013c4f4703fb486afb4c68c","modified":1597229167889},{"_id":"source/_posts/links/Learning_links.md","hash":"a4f56b9725697f8a14b63dc3516f09633ebca7b9","modified":1587697436506},{"_id":"source/_posts/linux/ACPI是什么&BIOS中ACPI要怎么设置.md","hash":"1fd9bf47bdfaab3448193bf033de193bd318e04c","modified":1581598064235},{"_id":"source/_posts/linux/BIOS.md","hash":"f952060e1a73fb00d7360a416f04d339212087b3","modified":1581598064249},{"_id":"source/_posts/linux/CPU角度理解PCIE.md","hash":"3c79bf34dd5cc96d2c7e01b34bcbb0c9535a5665","modified":1581598064273},{"_id":"source/_posts/linux/Centos更改kernel 默认启动项.md","hash":"5f5022961f44e15cc824be81ba24ec8263c91384","modified":1581598064357},{"_id":"source/_posts/linux/Devtoolset 升级gcc到8.3.1.md","hash":"979bdd03f27aa04b136705428a56ca8ac568ccaa","modified":1581598064361},{"_id":"source/_posts/linux/Intel_pstate&HWP功能enable_disable.md","hash":"f7568eea466d70da89edf9e41ecbfd35e5d03818","modified":1581598064366},{"_id":"source/_posts/linux/EOF.md","hash":"3fa697e0e4f54c85684964a441be26905177b556","modified":1591684336861},{"_id":"source/_posts/linux/Linux 修改root名称.md","hash":"ee719a06bacbabdca5b8612ce64f7591d3b6a6f9","modified":1581598064375},{"_id":"source/_posts/linux/Linux_command_find_grep_sed_awk.md","hash":"e9d5c7f9631a80b5920a8e0caeade851b4795c8f","modified":1581598064379},{"_id":"source/_posts/linux/Intel_pstate-acpi-cpufreq驱动切换.md","hash":"64f7e75e171578cd9b0d5190ec96d00b39a96df4","modified":1581598064371},{"_id":"source/_posts/linux/Linux_kernel_userspace体系结构.md","hash":"86dc5935526c352be6da25f3333a6af855af2588","modified":1581598064384},{"_id":"source/_posts/linux/Linux_kernel_更新.md","hash":"d883edb437efc88f48f361dba490235b68a59e2e","modified":1581598064399},{"_id":"source/_posts/linux/Linux下查看动态库中是否包含某个函数.txt","hash":"a6b6bc8d8c455fb1bbef3e5393f37d39c4ef5d22","modified":1584078276000},{"_id":"source/_posts/linux/Linux永远修改时间.md","hash":"11d01bc3c054b10eb13aec8072ae485726597fe7","modified":1581598064405},{"_id":"source/_posts/linux/Linux能访问外网_外网却访问不了此Linux.md","hash":"d947b7f108903fc7fff68bb191d038902a9ee774","modified":1581598064408},{"_id":"source/_posts/linux/MMIO.md","hash":"75847ec6722fc798d039c49b270d76277e1bc2ff","modified":1581598064411},{"_id":"source/_posts/linux/RHEL8.0开机总是要dhclient手动获取IP.md","hash":"76d9f896d21f15d59fd5eb3e92114575d9573c5f","modified":1581598064419},{"_id":"source/_posts/linux/TSC.md","hash":"147818fe1ce612bd42d699d6413b7d627b7f95b6","modified":1581598064422},{"_id":"source/_posts/linux/PTU(Power Thermal Utility).md","hash":"cbd7d34034fefcadc09c7bf202401f1acbc3e27a","modified":1581598064415},{"_id":"source/_posts/linux/Ubuntu下安装CUDA8.0及nvidia驱动(详细教程).md","hash":"d38f094facd07f5c2b25a3bcc8b098d3da82aa40","modified":1581598064426},{"_id":"source/_posts/linux/U盘RAW类型修复.md","hash":"463e27c9ce8501310c7cbe546542d17ed5803abe","modified":1590928033077},{"_id":"source/_posts/linux/U盘安装OS_Ubuntu_18.04.md","hash":"60b65e0c0e44c184645e26d0e91cd6279fb2cfcb","modified":1587396727328},{"_id":"source/_posts/linux/U盘分区之后如何恢复.md","hash":"3e951a59b44aa17293b19dd3a7232a28d3f9c7cc","modified":1590927521039},{"_id":"source/_posts/linux/Windows10mstsc远程登录Centos7.0.md","hash":"51b53f1016e0fd9d1004c14922428b60cd3fe4fd","modified":1581598064458},{"_id":"source/_posts/linux/cmake.md","hash":"c19f511e7193652473536d3f036409b17766ea00","modified":1584357750487},{"_id":"source/_posts/linux/centos升级gcc到9.1.0.md","hash":"b70503aa50b9b18367bf47f38b80a3f5ccc9f742","modified":1584357763510},{"_id":"source/_posts/linux/cppc动态调频.md","hash":"3a87c0ab33be8c4e83b07801e5552ab8742d8bea","modified":1581598064466},{"_id":"source/_posts/linux/curl_wget.md","hash":"9d14f5c22d834aea9014e75c6364c3c5342d876f","modified":1589206907208},{"_id":"source/_posts/linux/dd_command.md","hash":"16fbc8e62436c21917549cf6afdb6eff9d3a8413","modified":1591685470972},{"_id":"source/_posts/linux/dmidecode.md","hash":"b3cdbd9e8bc48fe4d6ac2cbc3d23940471f9ae06","modified":1581598064470},{"_id":"source/_posts/linux/docker.md","hash":"97ce0a762852f3a03b11e751722c5f13f5daca32","modified":1581598064473},{"_id":"source/_posts/linux/emon.md","hash":"803cb0afa3c5dc99dd8caaeace1daa1ae0f0abe7","modified":1581598064477},{"_id":"source/_posts/linux/etc_profile-etc_bashrc-~.bashrc.md","hash":"2f685d46b2f8a27879f2e3ffa345dcf79ebb0bc7","modified":1581598064480},{"_id":"source/_posts/linux/history.md","hash":"78ce840e859cf35bbcff1f8e9e9582c607c336fc","modified":1597048834014},{"_id":"source/_posts/linux/fdisk磁盘分区.md","hash":"dedd7c4aad6595dda70816def4a28145c4e20962","modified":1596456946989},{"_id":"source/_posts/linux/intel_pstate-acpi-cpufreq驱动研究.md","hash":"6c65fe7a1be1bcacba1c80e943b926d5034dec45","modified":1581598064484},{"_id":"source/_posts/linux/linux制作U盘启动盘.md","hash":"3426e47a36b324f9e5e49012842e331b0dbdfd8c","modified":1581598064488},{"_id":"source/_posts/linux/linux向其它终端发送消息.md","hash":"46df7e0b9638836a56024cebf4b2f5a90d565322","modified":1597049200444},{"_id":"source/_posts/linux/linux日志_服务日志.md","hash":"c7cde893a8e9e5cc67b17deb8aecab8fac011baa","modified":1594024306431},{"_id":"source/_posts/linux/linux查看运行的服务.md","hash":"9e51723e358d426e7ac9ea18ee6cffa8a25b60f2","modified":1597075501357},{"_id":"source/_posts/linux/linux给grub添加内核启动参数.md","hash":"2cc1c3d76f7f983158c2c99fb49fc659543d5b49","modified":1581598064514},{"_id":"source/_posts/linux/ln_-s_-_linux 软连接command.md","hash":"8c527f11270e0195d9a7913a9c86441d07b8d17c","modified":1581598064518},{"_id":"source/_posts/linux/ntpdate_synchronize_os_time.md","hash":"2c89f7e9cbac2d50a42332026c49a7628a64830f","modified":1590928320894},{"_id":"source/_posts/linux/perf.md","hash":"6320f6a70246b111a9daf2b5c6752b51ffcc6a46","modified":1581598064522},{"_id":"source/_posts/linux/rpm_yum.md","hash":"eb05b8243a132382835b7f5593bcf87f6d2dab63","modified":1590546401152},{"_id":"source/_posts/linux/scp机器间复制文件.md","hash":"648b1032a1281842feb5a544092298c0a1440859","modified":1581598064526},{"_id":"source/_posts/linux/screen程序在后台运行.md","hash":"3ab3ff5b7035775788e130982fd7877475ec9631","modified":1581598064530},{"_id":"source/_posts/linux/sda_hda.md","hash":"93f05c34a80c8099e1894accb76e7bfaf674ec88","modified":1581598064543},{"_id":"source/_posts/linux/ssh端口映射.md","hash":"f95df5e78bb3d3384dbb96a1f51c1eab6844426a","modified":1594825714602},{"_id":"source/_posts/linux/vim.md","hash":"5a0443c0a3f31ee978090fabf37bbe2b7fc6cfcc","modified":1591432923336},{"_id":"source/_posts/linux/yum下载遇到XZ_5.1.2alpha问题.md","hash":"ce34041b549679d7b3052fa8ce4c268ae63fa189","modified":1581598064576},{"_id":"source/_posts/linux/wget_www.baidu.com.md","hash":"c1cb4a7601b5fa09472937d4e799838c8e85a119","modified":1581598064573},{"_id":"source/_posts/linux/yum使用和安装cmake-3版本上.md","hash":"5403b8e7055b738b3123277fcb405d117ed39a85","modified":1581598064581},{"_id":"source/_posts/linux/按字节-字寻址_字长_地址总线_数据总线关系.md","hash":"e1118077967725acb030ae19794d3b9145c06688","modified":1581598064584},{"_id":"source/_posts/linux/查看SSD.md","hash":"b0da2b34ffffc25cfd2b993cf3db9d05eb7827e7","modified":1581598064605},{"_id":"source/_posts/linux/用户态和内核共享内存-使用dev_mem&mmap.md","hash":"3da6f2d718708b73d4d2ce58b496cd2371c12d42","modified":1581598064609},{"_id":"source/_posts/linux/硬盘存储空间单位GB.md","hash":"cd0475ee5d07eb3328e4fc7fcd3ead40d5048fd4","modified":1581598064613},{"_id":"source/_posts/linux/脚本执行错误_r_command not found.md","hash":"1f29005fc1e45fe6514423b4b6989775a09b0ae1","modified":1581598064622},{"_id":"source/_posts/linux/解压缩命令合集.md","hash":"54de9f3383a8726310b74c92fb996c6db797d7ad","modified":1581598064625},{"_id":"source/_posts/linux/连接router后机器连不上外网.md","hash":"756bea3bd7be9b1669b26280766e1986f0b64764","modified":1581598064629},{"_id":"source/_posts/micro_service/01_kubernetes_build.md","hash":"425947ef4c57e20b2857355f17ec75e02dc2defe","modified":1597669725105},{"_id":"source/_posts/micro_service/02_kubernetes_roles_introduction.md","hash":"d21d21190b22c146c0aad5f0eecab2e2633e271c","modified":1597077376615},{"_id":"source/_posts/micro_service/03_kubernetes_ns_pod.md","hash":"d3b7310d497f3cda592132ffa66a81c70e5e45d2","modified":1597077381398},{"_id":"source/_posts/micro_service/04_kubernetes_service.md","hash":"3ad214d1bff4ddc4e2a0e3fe1b8f6f9f0ba2e237","modified":1597077385691},{"_id":"source/_posts/micro_service/05_kubernetes_volume.md","hash":"65d8e8e338d1640eb5970b8b3de7d15d343a3007","modified":1597077390335},{"_id":"source/_posts/micro_service/06_kubernetes_deployment.md","hash":"dfe40f87f2b3684bfa839de52a09c4a705bbb10b","modified":1597077394335},{"_id":"source/_posts/micro_service/07_kubernetes_Etcd.md","hash":"d564e59da380c7a7dea417e1b0ff50ec4f2118a1","modified":1597077398266},{"_id":"source/_posts/micro_service/08_kubernetes_samples_problems.md","hash":"c8afbfc25aaf32a2cb56c170908cc8c4f0144103","modified":1597077402349},{"_id":"source/_posts/micro_service/09_kubernetes_certificate.md","hash":"8a8eb24248072533d500ef1b9a7d3aa823ba2dbb","modified":1597077408889},{"_id":"source/_posts/micro_service/Istio_K8s_SpringCloud.md","hash":"61784610fc18064a981708a47ac3518aa3949f5a","modified":1597077470898},{"_id":"source/_posts/micro_service/Resources.md","hash":"1cb6460bd64a6afd7aa70cfd4d0e39b1e62f0655","modified":1597077486957},{"_id":"source/_posts/micro_service/istio_01_conception.md","hash":"1492fbf7e235495693558cd5b7853686ef43176c","modified":1597077436328},{"_id":"source/_posts/micro_service/istio_02_installation.md","hash":"4fd20ba0b32f7675ae6acab14e59ace64009467c","modified":1597669266628},{"_id":"source/_posts/micro_service/istio_03_configuration.md","hash":"42f6ce2487772dfa844506acd8c4438cf50fd429","modified":1597077447051},{"_id":"source/_posts/micro_service/services_analysis.md","hash":"78632fed18b3f173fb07466804984a69563528d1","modified":1597077525924},{"_id":"source/_posts/nodejs/1.webstorm自动提示设置.md","hash":"040dde380c1891d688df80b4862d2c0ec43d73ad","modified":1583386072711},{"_id":"source/_posts/nodejs/2.Linux_Node.js_安装.md","hash":"c4b6c0662b444191249b3baa780c8430b354e807","modified":1586263474099},{"_id":"source/_posts/nodejs/2.Windows10_Node.js_安装.md","hash":"ad389c9d958b21b99ca211b5193127c57d43cea2","modified":1595258513896},{"_id":"source/_posts/nodejs/3.JSP匿名函数,自执行函数.md","hash":"9e413600aac85991a600b7d152e3299208cd159e","modified":1597232034154},{"_id":"source/_posts/nodejs/Express简介.md","hash":"30d1f24d5c8579d2d5e69236d120ce32a22a74ab","modified":1586712243802},{"_id":"source/_posts/nodejs/4.node_modules.md","hash":"24423c5c71226d050a5b222976a904686dfded06","modified":1597232112832},{"_id":"source/_posts/nodejs/NodeJs简介.md","hash":"57ca746ca193cf906386434c72010810474954e6","modified":1586715190629},{"_id":"source/_posts/nodejs/浏览器工作原理.md","hash":"45070a1fd5e5f5d034711c98f1a7076f62820373","modified":1586712500398},{"_id":"source/_posts/storage/ceph_conception_01.md","hash":"d420396282bdaf6e59c273c6ba85045ad5486f58","modified":1596457235856},{"_id":"source/_posts/storage/ceph_deployment_02.md","hash":"146a75a8db95f07436f77063938f0d0554b26963","modified":1597139711446},{"_id":"source/_posts/storage/greenplum.md","hash":"34375a7d1117f97dacb64692c00192312f85370a","modified":1597076992138},{"_id":"source/_posts/storage/minIO_02_deployment_on_kubernetes.md","hash":"118548d738e2ea7a62e83422d06b0ccb2147687e","modified":1597148656375},{"_id":"source/_posts/storage/minIO_01_conception.md","hash":"db792b9014eab2a22d05698b255d8cb970bd04a6","modified":1596697921451},{"_id":"source/_posts/storage/minIO_03_client.md.md","hash":"88ebf55f9fdcd14d756c31dd50ed551683db2bfa","modified":1596700733555},{"_id":"source/_posts/technologies/Intel_tips_at_work.md","hash":"9ac068fbc3477aad2cb56e70ea54dbf13898c1ea","modified":1587131455010},{"_id":"source/_posts/technologies/git_problems_encountered.md","hash":"49132c1e10013c3519bab3433219fd440cd6291b","modified":1596725057796},{"_id":"source/_posts/windows/U盘分区之后如何恢复.md","hash":"b96d35f958be5b54a4e0387bfcc4678b53e875b2","modified":1584357467431},{"_id":"source/_posts/windows/Windows10_VScode远程连接linux编辑调试.md","hash":"0104db0f82c48a3b0ab320971230e8195f5c74b9","modified":1586262694325},{"_id":"themes/3-hexo/git.bak/hooks/applypatch-msg.sample","hash":"61f0ed9af9a16dbba9b834edfb657f07aa10125d","modified":1581598064687},{"_id":"themes/3-hexo/git.bak/hooks/commit-msg.sample","hash":"e44c3d173580f6b4d8ee7f9b963d252af9902703","modified":1581598064690},{"_id":"themes/3-hexo/git.bak/hooks/fsmonitor-watchman.sample","hash":"6f2154c4968380d98c0af71eef8ce335e1b25814","modified":1581598064695},{"_id":"themes/3-hexo/git.bak/hooks/post-update.sample","hash":"6c00d034115de8f56eba4ded1eba7ffc73b332f6","modified":1581598064698},{"_id":"themes/3-hexo/git.bak/hooks/pre-applypatch.sample","hash":"7863e8a9fef55740491ab4429a13081a20a1dad9","modified":1581598064703},{"_id":"themes/3-hexo/git.bak/hooks/pre-commit.sample","hash":"b2004f56774b38f9c2b69920e8776614c123776a","modified":1581598064708},{"_id":"themes/3-hexo/git.bak/hooks/pre-push.sample","hash":"ac10c067e42e887ed93052dbece70922812546f3","modified":1581598064712},{"_id":"themes/3-hexo/git.bak/hooks/pre-rebase.sample","hash":"afa580632af0424e3af1a24e5c1e8ff6b2abb3b7","modified":1581598064716},{"_id":"themes/3-hexo/git.bak/hooks/pre-receive.sample","hash":"bfff8781c853c3d554371cc50e63ec70eb377711","modified":1581598064719},{"_id":"themes/3-hexo/git.bak/hooks/prepare-commit-msg.sample","hash":"255ff34ec71029bb23cf1257514d52eb99c9c8c1","modified":1581598064723},{"_id":"themes/3-hexo/git.bak/hooks/update.sample","hash":"df9f68bdcd0e7c6cee8cdce7b17f8ff7e625847b","modified":1581598064727},{"_id":"themes/3-hexo/git.bak/info/exclude","hash":"0214ce0925395605f10f65300bc1e4871dd9441e","modified":1581598064737},{"_id":"themes/3-hexo/git.bak/logs/HEAD","hash":"24cd14cf77b3b3d84e2ea9d61f13d97650532ca9","modified":1597237660812},{"_id":"themes/3-hexo/git.bak/refs/stash","hash":"ddca99c06a32a3b4ac28e6f09174f10fa8b82df6","modified":1597237504894},{"_id":"themes/3-hexo/layout/_partial/article.ejs","hash":"9e5afcc26f47f93c165072b0a2b5cbf72efb7ef9","modified":1597237527291},{"_id":"themes/3-hexo/layout/_partial/article_copyright.ejs","hash":"9e1cdec49d5b9b44399348d96ecd7331f3ee7d85","modified":1597237527292},{"_id":"themes/3-hexo/layout/_partial/comment.ejs","hash":"d18f94e04ef0cf7abb432a8e707ccb3abc7fe435","modified":1581598064846},{"_id":"themes/3-hexo/layout/_partial/copyright.ejs","hash":"4c09f47e899fe36bfe36d92b12996219c2b5f622","modified":1597237527294},{"_id":"themes/3-hexo/layout/_partial/dashang.ejs","hash":"b2a01cc1f0326965f0a186ce3c9b3c991fd4e2c9","modified":1597237527294},{"_id":"themes/3-hexo/layout/_partial/footer.ejs","hash":"9087af9647a87c3fa9ef87632de5427ba4abe9c4","modified":1597237527295},{"_id":"themes/3-hexo/layout/_partial/friends.ejs","hash":"e6dd90be668195016d6e1c51a6baefb50676e6ab","modified":1597237527296},{"_id":"themes/3-hexo/layout/_partial/header.ejs","hash":"1e04b617fe38acca8b3d3774c5dbfcb74a02db6b","modified":1597237527297},{"_id":"themes/3-hexo/layout/_partial/full-toc.ejs","hash":"60a085fab3165ea1fc6370abac0bd6ab1b2f2510","modified":1597237527297},{"_id":"themes/3-hexo/layout/_partial/mathjax.ejs","hash":"e2be0e37f3d48e63e65a47d819bfb800b9aa3784","modified":1581598064899},{"_id":"themes/3-hexo/layout/_partial/meta.ejs","hash":"ab6329ddd908b0567c18f39ac6a8553c6fec67c5","modified":1597237527298},{"_id":"themes/3-hexo/layout/_partial/nav-right.ejs","hash":"bebb374c8a505bf0e4dcc9dc63b426f96c015358","modified":1597237527300},{"_id":"themes/3-hexo/layout/_partial/nav-left.ejs","hash":"e59000bde9fa1fda8910a5add2d43cf41362cee6","modified":1597237527299},{"_id":"themes/3-hexo/layout/_partial/tag.ejs","hash":"8704e6bd833d270cc6a494d4e7cf1dfeddedba40","modified":1597237527300},{"_id":"themes/3-hexo/layout/_partial/toc-ref.ejs","hash":"33f7a4bfca1bb9835ec8f0d1e73188d1f56cc8b9","modified":1581598064922},{"_id":"themes/3-hexo/source/css/gitalk.css","hash":"3dc58e9a3fd63a3144d5fe850eb55e3dc885c9fb","modified":1581598065041},{"_id":"themes/3-hexo/source/css/mobile.styl","hash":"1c2f8b7d7cf46f219adb3a628bdf380f29ff4a6b","modified":1597237527313},{"_id":"themes/3-hexo/source/css/style.styl","hash":"29fa7f6619519c2dcfec4efac4314c5af659a92a","modified":1597237527314},{"_id":"themes/3-hexo/source/img/article-list-background.jpeg","hash":"4fdf8b3e53dd02d6ee6360aebfadb0cba1fb5633","modified":1581598065154},{"_id":"themes/3-hexo/source/img/gov.png","hash":"f31c9f47faedf7f33b9580d6284ab891fb697560","modified":1597237527315},{"_id":"themes/3-hexo/source/img/brown-papersq.png","hash":"3a1332ede3a75a3d24f60b6ed69035b72da5e182","modified":1581598065161},{"_id":"themes/3-hexo/source/img/school-book.png","hash":"711ec983c874e093bb89eb77afcbdf6741fa61ee","modified":1581598065165},{"_id":"themes/3-hexo/source/js/iconfont.js","hash":"3a0869ca1b09af07d82987e343a3bc4cb9558ecb","modified":1581598065186},{"_id":"themes/3-hexo/source/js/jquery.pjax.js","hash":"8c2a4f10a4da3d9615a3a81542494c6d21479b3d","modified":1581598065197},{"_id":"themes/3-hexo/source/js/script.js","hash":"1f96e0b4f663baf992e4b311acf353e7d2f94d9a","modified":1597237527321},{"_id":"themes/3-hexo/source/js/search.js","hash":"788c610149a5f9361295f9f0207c8523f37ddb8b","modified":1581598065206},{"_id":"themes/3-hexo/source/img/avatar.jpg","hash":"35a3f3736ea47e482e100a220023c6ef193fa93d","modified":1590932037832},{"_id":"themes/3-hexo/source/js/titleTip.js","hash":"7299ac046ddd6e6a4267d435f7b4c8198baaaccc","modified":1597237527322},{"_id":"themes/3-hexo/source/img/alipay.jpg","hash":"92f3232ad812ed9e796ddbbdb057f23edeed28ed","modified":1581598065150},{"_id":"themes/3-hexo/source/img/weixin.jpg","hash":"ac3de5dbab14549cd64d3f43769bef9004291526","modified":1581598065170},{"_id":"source/_posts/blogs/HTTP_TCP_Socket/socket.jpg","hash":"496b1d4cc6e6737b75846ca1751616ee2b943b90","modified":1592808591407},{"_id":"source/_posts/deeplearning/deeplearning_01_get_started/03.PNG","hash":"0448754143c63d10915c775652bbe1eaf0cd3429","modified":1597218297945},{"_id":"source/_posts/blogs/Hexo_01_部署github_blog/deploy.jpg","hash":"7d73e058e926c435a946c3f70a109cc2fe985295","modified":1581598064643},{"_id":"source/_posts/deeplearning/deeplearning_01_get_started/04.PNG","hash":"baffcd5f4cbee7b7e804ce2cd2d194b5d0a4757c","modified":1597218374457},{"_id":"source/_posts/language/c/gdb.md","hash":"69e742d2cb3772e70b0275efad121d652ceb8160","modified":1596459836512},{"_id":"source/_posts/language/go/goLang.md","hash":"8f98c5bf529e1c8ce053dfc72fff27619aea1db1","modified":1588173958131},{"_id":"source/_posts/language/python/linux_install_python_pip_pipenv.md","hash":"49104b3e4ddc6f64c6fc02bdc3ba38f37b8496e8","modified":1588173910249},{"_id":"source/_posts/linux/ACPI是什么&BIOS中ACPI要怎么设置/acpi.jpg","hash":"f231d7fc0990444380889a125ea61b7cb0b6a5f0","modified":1581598064240},{"_id":"source/_posts/linux/ACPI是什么&BIOS中ACPI要怎么设置/acpi_bios.jpg","hash":"26ca938620770ef5735b84525aec2c58cca383c4","modified":1581598064245},{"_id":"source/_posts/linux/BIOS/bios.gif","hash":"3035616439a8d9f6622ffe230f6686b6b0623168","modified":1581598064254},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture1.jpg","hash":"bc5912d9d93c3c14ae45ef3daf3346879dc90ce5","modified":1581598064279},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture11.jpg","hash":"25fa8ef27407f9136031b5eae545786f4a21f7dd","modified":1581598064294},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture2.jpg","hash":"1210c621445bc7383f20ff9724a4a1d1accf2cce","modified":1581598064307},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture4.jpg","hash":"0cb890d5e5f09fd9beab74778dbe28208df9850d","modified":1581598064319},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture6.jpg","hash":"e75662ccb5f7c29ae0d8e24be0d29c565e07b6da","modified":1581598064335},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture9.jpg","hash":"dc915c0441e7433510e1a17773e61569cf4b6dce","modified":1581598064353},{"_id":"source/_posts/linux/Linux_kernel_userspace体系结构/linux_gun.jpg","hash":"8568e074f244e445593f071d25e6895bf2b08036","modified":1581598064389},{"_id":"source/_posts/linux/U盘分区之后如何恢复/clean.png","hash":"58c1c5e23ffe3400293af12eb24c236e4b89a4ee","modified":1581598064435},{"_id":"source/_posts/linux/U盘分区之后如何恢复/diskpart.png","hash":"58c1c5e23ffe3400293af12eb24c236e4b89a4ee","modified":1581598064439},{"_id":"source/_posts/linux/U盘分区之后如何恢复/list_disk.png","hash":"58c1c5e23ffe3400293af12eb24c236e4b89a4ee","modified":1581598064445},{"_id":"source/_posts/linux/U盘分区之后如何恢复/select_disk.png","hash":"58c1c5e23ffe3400293af12eb24c236e4b89a4ee","modified":1581598064449},{"_id":"source/_posts/linux/linux制作U盘启动盘/dd.png","hash":"fc995e69a462206967bdec2f1d190cf8236038d0","modified":1581598064493},{"_id":"source/_posts/linux/linux制作U盘启动盘/mkfs.png","hash":"827bd99efaf9084e405fc44e1b25377b94179331","modified":1581598064504},{"_id":"source/_posts/linux/linux制作U盘启动盘/umount.png","hash":"5767457dc3116f04713c3f244593342cb3dd2df5","modified":1581598064508},{"_id":"source/_posts/linux/screen程序在后台运行/screen_logs.png","hash":"e5af67f000eeae8c0c9e2efe3e0fb7e1190a816d","modified":1581598064535},{"_id":"source/_posts/linux/screen程序在后台运行/screenlog.0.png","hash":"0ade7530720c84a5bf95b754f525b9c02a0dcfe9","modified":1581598064539},{"_id":"source/_posts/linux/ssh端口映射/local_port_transmit.png","hash":"a868beb2a79f154502812dcb1212ede2eefb048d","modified":1594729914170},{"_id":"source/_posts/linux/ssh端口映射/port_transmit_protocol.png","hash":"7d0113ab806f0732b570180de8cdb749c2942e3f","modified":1594730272944},{"_id":"source/_posts/linux/按字节-字寻址_字长_地址总线_数据总线关系/logical_physical.png","hash":"0ddaadc7b01712b3a711bf97030c81f775ab2b93","modified":1581598064595},{"_id":"source/_posts/linux/硬盘存储空间单位GB/unit_GB.gif","hash":"5d827e0d4e31cd3b676af756ff1cdbd3df911424","modified":1581598064618},{"_id":"source/_posts/micro_service/01_kubernetes_build/1.JPG","hash":"566cbdeabe2e3c0ada1714dfd1e879de9a1b8a38","modified":1586917440000},{"_id":"source/_posts/micro_service/01_kubernetes_build/3.JPG","hash":"ebc328818eec28d4ffe327e2a15b97b944c87c9b","modified":1586932848000},{"_id":"source/_posts/micro_service/01_kubernetes_build/6.JPG","hash":"92ba1d5858920fcc8c5a942cbd7b25a94dc8486a","modified":1586935130000},{"_id":"source/_posts/micro_service/01_kubernetes_build/Asymmetric_encryption.JPG","hash":"e688de20ac8f50947366d892165d7c5f40b242eb","modified":1586935046000},{"_id":"source/_posts/micro_service/01_kubernetes_build/K8s_arch1.JPG","hash":"6447d60dd07308f4ff3b358cac2ba5c1e082953f","modified":1587005610000},{"_id":"source/_posts/micro_service/01_kubernetes_build/K8s_arch3.JPG","hash":"ff34f0bdf61b21715edd3541bb89081bb9155da3","modified":1587006974000},{"_id":"source/_posts/micro_service/01_kubernetes_build/K8s_arch2.JPG","hash":"8dcb6bdf5e8494569b611dfd0e4ba4d0c293c7d9","modified":1587006302000},{"_id":"source/_posts/micro_service/01_kubernetes_build/Pod_Scaling.JPG","hash":"d2063a9fc37438d2b13f0c92a61ff2c4a580a95d","modified":1587018460000},{"_id":"source/_posts/micro_service/01_kubernetes_build/Pod_communication2.JPG","hash":"b62699e73410016a17146c2fd721fd108247fb86","modified":1587020360000},{"_id":"source/_posts/micro_service/01_kubernetes_build/Pod_communication1.JPG","hash":"86306c989ea829a4088c2f63a486dcdea28fbc5d","modified":1587020162000},{"_id":"source/_posts/micro_service/01_kubernetes_build/Pod_communication3.JPG","hash":"92e44ea22d8cbfc702fe8a0344c3c3ca748889e3","modified":1587020646000},{"_id":"source/_posts/micro_service/01_kubernetes_build/Rolling_update1.JPG","hash":"4b7425067eb7677985de84798443612c16aedafe","modified":1587018572000},{"_id":"source/_posts/micro_service/01_kubernetes_build/Rolling_update2.JPG","hash":"105bee998aba4ed36bb32927fedc95dd2f6528f9","modified":1587018690000},{"_id":"source/_posts/micro_service/01_kubernetes_build/Symmetric_encryption.JPG","hash":"59e70ebb4fd57b9129c9878c7d12ab18e8bb5557","modified":1586934080000},{"_id":"source/_posts/micro_service/01_kubernetes_build/k8s_architecture1.JPG","hash":"bf2b5b98f6069c7c1e0188c131d08853501141dd","modified":1586933528000},{"_id":"source/_posts/micro_service/istio_03_configuration/istio_arch_19.JPG","hash":"527c4645ed73e59467e42fea4b9b9ed1e308fc9a","modified":1587376000000},{"_id":"source/_posts/micro_service/istio_03_configuration/istio_arch_20.JPG","hash":"30ea66371d496fb3fd64407e001fe52e4713e3f9","modified":1587376056000},{"_id":"source/_posts/micro_service/services_analysis/REST_FUL_API.png","hash":"5917b9cdca3a682895ade2e3f93c94327de11efa","modified":1594731453582},{"_id":"source/_posts/nodejs/1.webstorm自动提示设置/6.png","hash":"c397fb9812ae19395c19e037486a52bb61db86e6","modified":1583385969013},{"_id":"source/_posts/nodejs/1.webstorm自动提示设置/8.png","hash":"53a6e10281cb4659880397d44865a30161056b18","modified":1583386035206},{"_id":"source/_posts/nodejs/2.Windows10_Node.js_安装/NODE_PATH.png","hash":"bfdec96c3e4aacee8b40c0a4943c1eaf7b0a3a3e","modified":1581598064651},{"_id":"source/_posts/nodejs/2.Windows10_Node.js_安装/PATH_nodejs_intall.png","hash":"4d1c9202cc201c1a27cd137f80ea0617e4aaf8be","modified":1581598064655},{"_id":"source/_posts/nodejs/浏览器工作原理/DNS.gif","hash":"462ddef9ffd6aeeb9c0a6f5a8b1343ab8f364dde","modified":1492693000000},{"_id":"source/_posts/nodejs/浏览器工作原理/HTTPMsgStructure2.png","hash":"e82dd65dbc7cb7455d761929a2b737a863ddb85f","modified":1492499796000},{"_id":"source/_posts/nodejs/浏览器工作原理/client-server.png","hash":"1784f380b6168214bf708396901cf696fdf5f539","modified":1492484234000},{"_id":"source/_posts/nodejs/浏览器工作原理/css_parser.png","hash":"b177e2518be5b4a7738da741af735999ccc4a0d3","modified":1491982490000},{"_id":"source/_posts/nodejs/浏览器工作原理/dom.png","hash":"f7c93eea10f05934d7e39813fbf76f9bee19d8f5","modified":1491981286000},{"_id":"source/_posts/nodejs/浏览器工作原理/flow.png","hash":"4165c41f2799daccc0cdbba92f0bbaf78ed4257f","modified":1491965750000},{"_id":"source/_posts/nodejs/浏览器工作原理/gecko.jpg","hash":"0ef7b807fd5d5d40f4d65e94de7ff8a4d9da1a8e","modified":1491969748000},{"_id":"source/_posts/nodejs/浏览器工作原理/handshake.png","hash":"b9adab50b95796ce8791dcb8df3807f83fb2e6e1","modified":1499953481962},{"_id":"source/_posts/nodejs/浏览器工作原理/node-modules.png","hash":"823d3b93cf754199cfdfcda056ec8fa6a7d5167d","modified":1492508820000},{"_id":"source/_posts/nodejs/浏览器工作原理/nodeWeb.png","hash":"a6c15a0cd524b81c823f58ebd30f66adb507b133","modified":1492558792000},{"_id":"source/_posts/nodejs/浏览器工作原理/sublimeconf22.png","hash":"82748e9d8a0ee25f3e50b3db20cc4b6799edefd4","modified":1499843712000},{"_id":"source/_posts/nodejs/浏览器工作原理/taobao_ip.png","hash":"2487d4e2f9d411fd93e4249e15e0758ce39fdccd","modified":1492054676000},{"_id":"source/_posts/nodejs/1.webstorm自动提示设置/7.png","hash":"2d2a2e9b8b03e32f7c6ab82ee5f2027a3a5a9d0e","modified":1583386002267},{"_id":"source/_posts/nodejs/浏览器工作原理/taobao_url.png","hash":"00a5ae643c83abe98397f3993558ec5cc81a237c","modified":1492054492000},{"_id":"source/_posts/nodejs/浏览器工作原理/webkitflow.png","hash":"675c0ef1c3cd0de8e7dced027cd751b5013520dc","modified":1491969720000},{"_id":"source/_posts/technologies/docker/docker_step_02.md","hash":"2d466f66a1e381c65dc6ce8c7648dd0cdd177fb1","modified":1594640985134},{"_id":"source/_posts/technologies/docker/docker_step_01.md","hash":"918601674a00976f7a9a0477557959b55ac3ce0f","modified":1597327143293},{"_id":"source/_posts/technologies/maven/IntelliJ_idea.md","hash":"eaacc81692df7d11a76f6623fa1d104a9c7069ba","modified":1586351480735},{"_id":"source/_posts/technologies/docker/dockerfile.md","hash":"31d153bab96d82a62a91747a5df7a0cc781f8469","modified":1590926661054},{"_id":"source/_posts/technologies/maven/maven_eclipse_tomcat_JDK1.8_configuration.md","hash":"acf7085047a5cc4f7f0264512325c6b7513c34af","modified":1586351320066},{"_id":"source/_posts/technologies/maven/maven_project.md","hash":"02f85d66501ca85eb81f2aef62e12453db906b5d","modified":1586689654734},{"_id":"source/_posts/technologies/maven/navicat_premium.md","hash":"25502d4e67c3ab43ae4c296812acf6e4e7588443","modified":1586443843226},{"_id":"source/_posts/technologies/maven/thrift.md","hash":"012f3064545bc3a1b46c250cd6ff06f6cc0e6d0a","modified":1586351676164},{"_id":"source/_posts/technologies/security/algorithm_security.md","hash":"67a1cfa4f092ebdc7c7b9fb16e55a994fdf6f636","modified":1597077256111},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates.md","hash":"151591d6821536e45f52f51f1142cdc2ab110f63","modified":1597077250871},{"_id":"source/_posts/technologies/maven/ubuntu18.04安装Mysql8.0.md","hash":"6fcf53bd1db8cf4ebfb7b264498b5d0b0e059227","modified":1586445019902},{"_id":"source/_posts/technologies/security/openssl_certificates.md","hash":"2be8f37eb1a3af7eb4404abcd9754e1efe7f3359","modified":1597077624116},{"_id":"source/_posts/technologies/security/pki.md","hash":"9e16eceddf99bfd489460c7a61fd2295fc8a836f","modified":1597077240552},{"_id":"source/_posts/technologies/security/tls_ssl_https_http_protocol.md","hash":"a5f8a58aa80e4ea352360713ade5ad4dbd2943f7","modified":1597077227732},{"_id":"source/_posts/technologies/security/token_jwt.md","hash":"6aa0eeafdeacf1645de5cce60a6ea6b0e7943690","modified":1597077233942},{"_id":"source/_posts/technologies/web/JavaScript.md","hash":"f83903446d3fa7db22fe08136ca3bf9a483ca359","modified":1586948969781},{"_id":"source/_posts/technologies/web/bootstrap.md","hash":"ec0adc6d147c7477efe6404b595959b483c2b6b8","modified":1584357158841},{"_id":"source/_posts/technologies/web/datatables.md","hash":"51fc67f3bed76fd84b13294c8df91e4b95d8149d","modified":1584358222341},{"_id":"source/_posts/windows/U盘分区之后如何恢复/1.png","hash":"58c1c5e23ffe3400293af12eb24c236e4b89a4ee","modified":1584066744000},{"_id":"source/_posts/windows/U盘分区之后如何恢复/2.png","hash":"58c1c5e23ffe3400293af12eb24c236e4b89a4ee","modified":1584066754000},{"_id":"source/_posts/windows/U盘分区之后如何恢复/3.png","hash":"58c1c5e23ffe3400293af12eb24c236e4b89a4ee","modified":1584066760000},{"_id":"source/_posts/windows/U盘分区之后如何恢复/4.png","hash":"58c1c5e23ffe3400293af12eb24c236e4b89a4ee","modified":1584066766000},{"_id":"source/_posts/windows/U盘分区之后如何恢复/5.png","hash":"58c1c5e23ffe3400293af12eb24c236e4b89a4ee","modified":1584066772000},{"_id":"source/_posts/windows/Windows10_VScode远程连接linux编辑调试/1.png","hash":"dd15f2eb99cf23bd7e17f90b249067eb76851c1a","modified":1584066542000},{"_id":"source/_posts/windows/Windows10_VScode远程连接linux编辑调试/2.png","hash":"6d4b284081489534d6e1bae1f25e42777266fa91","modified":1584066554000},{"_id":"source/_posts/windows/Windows10_VScode远程连接linux编辑调试/3.png","hash":"34bbe99b72a3545accdc6fa85b1ef0fa86ad2694","modified":1584066562000},{"_id":"source/_posts/technologies/web/HTML.md","hash":"7da460065c816f7aaf6b58a6be7ef82f78a7a4da","modified":1584357139439},{"_id":"source/_posts/windows/Windows10_VScode远程连接linux编辑调试/5.png","hash":"f7cf4c81c89048f43c69070b2e217577bd04e4fc","modified":1584066576000},{"_id":"source/_posts/windows/Windows10_VScode远程连接linux编辑调试/4.png","hash":"773007d58d12bd3b9702750048b19ae123a9d20a","modified":1584066568000},{"_id":"source/_posts/windows/Windows10_VScode远程连接linux编辑调试/6.png","hash":"685a4a2eeb07f47a8d0a9e7210b4d8b595607116","modified":1584066584000},{"_id":"source/_posts/windows/Windows10_VScode远程连接linux编辑调试/7.png","hash":"d0b2d40e5c4fd717e7f9172b6b49b23a0a7fc3ff","modified":1584066592000},{"_id":"themes/3-hexo/git.bak/logs/refs/stash","hash":"f6bba28a090984abae39b46c463de1e5d97ba10f","modified":1597237504896},{"_id":"themes/3-hexo/git.bak/objects/0b/3dbb318e78ebef47a9241bba2b4e50d92ac109","hash":"6da141105e0788f61a32d36dabd2eaa66bd18921","modified":1597237504583},{"_id":"themes/3-hexo/git.bak/objects/12/f4b97fd6a8db7295220f418b5d2f25689f0784","hash":"b64293ae09d1b7e108112577c535e2c44dbe7953","modified":1597237504593},{"_id":"themes/3-hexo/git.bak/objects/17/b59719741d1127e1eed86394fe1038bb9085fb","hash":"a78822c1c12bf71c7731ca795f23f389fde09a66","modified":1597237504644},{"_id":"themes/3-hexo/git.bak/objects/33/fb84e202db6a2b067a4dddb063736238bfebea","hash":"b0474ecf8a7ab7b69c998641020de4d4fe2b706a","modified":1597237504582},{"_id":"themes/3-hexo/git.bak/objects/6d/0a40c620119760ea0f6f737648a383f753a0e2","hash":"0cc5381e336790fd71cec67a179c22627f410e97","modified":1597237568419},{"_id":"themes/3-hexo/git.bak/objects/71/ef56cbb224948d2852dc353ed919da3edebc5b","hash":"dc9317b6752f6a534da314a33373ce2873807638","modified":1597237568416},{"_id":"themes/3-hexo/git.bak/objects/95/d5f1d7bee9398578c0b413c0ed3d4e54ccd7f9","hash":"61ec42b1b8820a38e1edbad1f374ba6925d4bc6f","modified":1597237504642},{"_id":"themes/3-hexo/git.bak/objects/a2/0b66a56889492033cae013d395c76887e81b06","hash":"3fc0d7c2a0508706abb6d98461042bd2aefe7d79","modified":1597237504374},{"_id":"themes/3-hexo/git.bak/objects/8c/4ee70b2b2d51215a29860fa9c6ff15694e3d22","hash":"a4e3d8aae8102b9f19f77c07c189c65aee322e89","modified":1597237504573},{"_id":"themes/3-hexo/git.bak/objects/c0/5cb8d59cd5dd658af61e0f84beeb5466c7b22e","hash":"ad7ead5cb2d65d570d81d24d0de8cd9166a63129","modified":1597237504826},{"_id":"themes/3-hexo/git.bak/objects/ca/8f1870bd2c016d5d52ce3deca448fa5bf9a69d","hash":"ee514e03a58d3dbb062e88d792c33fcb6c1be25b","modified":1597237504645},{"_id":"themes/3-hexo/git.bak/objects/cc/ac6c98c30d13bf3e54621845bf17ea30e431d0","hash":"c7673b6782da499913d0984dff30d9e4aee63200","modified":1597237568413},{"_id":"themes/3-hexo/git.bak/objects/fc/c0f83464b076cefe24545ceb299a7bc3e82e51","hash":"9f559a0e904afa1456d2b8baf51c8cba35b25598","modified":1597237504646},{"_id":"themes/3-hexo/git.bak/objects/pack/pack-65553499904f765c705aad8cd266f19a07bbaadc.idx","hash":"a9b061e5b68e3978527ae54ef14f3151a5dfa473","modified":1597237358036},{"_id":"themes/3-hexo/git.bak/objects/pack/pack-e58995235e8928786b64c3df82dba98a1aae246c.idx","hash":"ba9dd3ce695eb469fede2023920bdf98bc46d41f","modified":1581598064767},{"_id":"themes/3-hexo/git.bak/refs/heads/master","hash":"dd1e560dba03636d502a133176c3b83d578721b4","modified":1597237527325},{"_id":"themes/3-hexo/layout/_partial/comments/click2show.ejs","hash":"05b09c45b379ffeb4f48c1604044d88829f90799","modified":1581598064851},{"_id":"themes/3-hexo/layout/_partial/comments/disqus.ejs","hash":"32ce7b48d366b9c888ff2ceb911a3cd82f864537","modified":1581598064856},{"_id":"themes/3-hexo/layout/_partial/comments/gitalk.ejs","hash":"01567e010cf4f2dd141fe2019490d3f0d5aa2529","modified":1581598064864},{"_id":"themes/3-hexo/layout/_partial/comments/gitment.ejs","hash":"eaf2b6f297282606b630ad55fb9e38af7e2829dc","modified":1581598064868},{"_id":"themes/3-hexo/layout/_partial/comments/utteranc.ejs","hash":"8f2d4f42fbad351677c82e72420224587a5bd666","modified":1597237527293},{"_id":"themes/3-hexo/layout/_partial/comments/livere.ejs","hash":"2d115e79cadedc2d5d8f4b5618559640d986e01f","modified":1597237527293},{"_id":"themes/3-hexo/source/css/_partial/comment.styl","hash":"d5fa333970a2eac66937d42eeb16fdb362e121ed","modified":1597237527304},{"_id":"themes/3-hexo/source/css/_partial/dashang.styl","hash":"f0eac1dc1f5dbed1769d032bb5fd5f002faaee26","modified":1581598064959},{"_id":"themes/3-hexo/source/css/_partial/fade.styl","hash":"02c7510a26f306e240f23ddbf772a69be2c890dd","modified":1581598064964},{"_id":"themes/3-hexo/source/css/_partial/font.styl","hash":"542c85263a63a832aaac3b021bc661fe6661bcc4","modified":1597237527305},{"_id":"themes/3-hexo/source/css/_partial/nav-left.styl","hash":"16a81f7b6a38d6a423a9c995c95a40d6c16ead55","modified":1597237527306},{"_id":"themes/3-hexo/source/css/_partial/full-toc.styl","hash":"9a732af065d0a80c9e420934be0f3582bf0129dc","modified":1597237527306},{"_id":"themes/3-hexo/source/css/_partial/nav-right.styl","hash":"9e741abd6f71695d360c349e0dffc790f5b1ffc2","modified":1597237527307},{"_id":"themes/3-hexo/source/css/_partial/nprogress.styl","hash":"2620a02169a6aeb75137fd368eac2c36423d8498","modified":1581598064985},{"_id":"themes/3-hexo/source/css/_partial/num-load.styl","hash":"f7ef35459ece22e1da950b86126be1c2bfe97fcf","modified":1581598064990},{"_id":"themes/3-hexo/source/css/_partial/post.styl","hash":"f1251e2a3b5334af3a22b51fc0293c2456568b50","modified":1597237527308},{"_id":"themes/3-hexo/source/css/fonts/icomoon.svg","hash":"b5e7562c8494b0ddb3a70ecc5545ef7340d8e971","modified":1581598065005},{"_id":"themes/3-hexo/source/css/fonts/icomoon.eot","hash":"b6195bedc1cb2f9cfcb26cc27021f2e94be2ab0a","modified":1581598064999},{"_id":"themes/3-hexo/source/css/fonts/icomoon.woff","hash":"3985d29416bb9b19f50a2f20f2bbbce47f10af8d","modified":1581598065013},{"_id":"themes/3-hexo/source/css/fonts/icomoon.ttf","hash":"eb976d8b8559fcddfc2658a03a4350cb566fc06b","modified":1581598065009},{"_id":"themes/3-hexo/source/css/fonts/iconfont.svg","hash":"3630aabf2f9c0417f483ebd03d9e429dbc2594e0","modified":1597237527310},{"_id":"themes/3-hexo/source/css/fonts/iconfont.eot","hash":"b14b8624988ff069aff3145f88c0d7ac49052bd3","modified":1597237527309},{"_id":"themes/3-hexo/source/css/fonts/iconfont.woff","hash":"0d2d4559f1ac4fa801eb8cc099fa5bf9dcf955ef","modified":1597237527311},{"_id":"themes/3-hexo/source/css/fonts/iconfont.ttf","hash":"140829ecf12d30c6e18d8dc6dc0c188a66addd25","modified":1597237527311},{"_id":"themes/3-hexo/source/css/fonts/selection.json","hash":"b6456a4eabcffd95e822d1d7adce96da524d481a","modified":1581598065034},{"_id":"themes/3-hexo/source/css/hl_theme/atom-dark.styl","hash":"f3eb4e5feda9cbd6242ccf44ca064e2979b5d719","modified":1581598065052},{"_id":"themes/3-hexo/source/css/hl_theme/atom-light.styl","hash":"553987211d3323a7dfc0b08786b183a3435978c9","modified":1597237527313},{"_id":"themes/3-hexo/source/css/hl_theme/brown-paper.styl","hash":"03af387edcc1cf8c18d12e9c440fd51b6cf425b6","modified":1581598065063},{"_id":"themes/3-hexo/source/css/hl_theme/darcula.styl","hash":"2bfc14f27ccca108b4b3755782de8366e8bd001e","modified":1581598065078},{"_id":"themes/3-hexo/source/css/hl_theme/github-gist.styl","hash":"5e05b19832c1099bd9d284bc3ed00dc8a3d7ee23","modified":1581598065088},{"_id":"themes/3-hexo/source/css/hl_theme/github.styl","hash":"53276ff1f224f691dfe811e82c0af7f4476abf5d","modified":1581598065092},{"_id":"themes/3-hexo/source/css/hl_theme/gruvbox-dark.styl","hash":"315ad610d303caba9eac80a7d51002193a15478a","modified":1581598065096},{"_id":"themes/3-hexo/source/css/hl_theme/gruvbox-light.styl","hash":"1bece084b1dbbbd4af064f05feffd8c332b96a48","modified":1581598065100},{"_id":"themes/3-hexo/source/css/hl_theme/kimbie-dark.styl","hash":"e9c190f9ffc37a13cac430512e4e0c760205be4a","modified":1581598065104},{"_id":"themes/3-hexo/source/css/hl_theme/kimbie-light.styl","hash":"0c3ccd0d64e7504c7061d246dc32737f502f64e4","modified":1581598065110},{"_id":"themes/3-hexo/source/css/hl_theme/railscasts.styl","hash":"a6e8cfd2202afd7893f5268f3437421e35066e7b","modified":1581598065115},{"_id":"themes/3-hexo/source/css/hl_theme/rainbow.styl","hash":"e5c37646a9d9c1094f9aab7a7c65a4b242e8db00","modified":1581598065119},{"_id":"themes/3-hexo/source/css/hl_theme/school-book.styl","hash":"51659351b391a2be5c68728bb51b7ad467c5e0db","modified":1581598065123},{"_id":"themes/3-hexo/source/css/hl_theme/sublime.styl","hash":"501d75ef0f4385bea24d9b9b4cc434ba68d4be27","modified":1581598065127},{"_id":"themes/3-hexo/source/css/hl_theme/sunburst.styl","hash":"2aa9817e68fb2ed216781ea04b733039ebe18214","modified":1581598065131},{"_id":"themes/3-hexo/source/css/hl_theme/zenbum.styl","hash":"92941a6ae73b74f44ad7c559c5548c44073c644a","modified":1581598065134},{"_id":"themes/3-hexo/source/css/fonts/iconfont.woff2","hash":"b0317a0b2ebb1181a8bf5a97d03556dd54538645","modified":1597237527312},{"_id":"source/_posts/blogs/Restful_API/Restful.png","hash":"fe71f887a0059c0b9b107266bf36bb5a373f4276","modified":1592814544063},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture12.jpg","hash":"bf958f317625fc01799cb7a283ac6adb59956d90","modified":1581598064300},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture3.jpg","hash":"54e86f39193f2b92ce2af2c0f8419436240c7085","modified":1581598064314},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture5.jpg","hash":"b1b103dd758ae4df0cd064659a7d43559e1952e9","modified":1581598064330},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture7.jpg","hash":"322ac2dafaffc8c283d7e9140280f45421efb5ca","modified":1581598064341},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture8.jpg","hash":"aea8e0c4f3e439aa8946512e16f51f065efe464d","modified":1581598064347},{"_id":"source/_posts/linux/Linux_kernel_userspace体系结构/linux_kernel.jpg","hash":"c461a2df4d5520cd63358296620a043a38c50575","modified":1581598064394},{"_id":"source/_posts/linux/linux制作U盘启动盘/fdisk.png","hash":"29e367da801dec3f6975d10c8aae9d7b18e11fc7","modified":1581598064499},{"_id":"source/_posts/linux/ssh端口映射/local_port_transmit1.png","hash":"f39f6ac26a3a3e6fef98c70881c0f621cfad1216","modified":1594730091101},{"_id":"source/_posts/micro_service/01_kubernetes_build/2.JPG","hash":"ca9354ab691edf10832976afb9c3f0a55e56f837","modified":1586917560000},{"_id":"source/_posts/micro_service/01_kubernetes_build/5.JPG","hash":"1e54fc6049a5cccfb0ca3395d8df528836149ccb","modified":1586933036000},{"_id":"source/_posts/micro_service/01_kubernetes_build/4.JPG","hash":"f82a79ce1470ca3575c3beef250d8103a9ed93d5","modified":1586932918000},{"_id":"source/_posts/micro_service/01_kubernetes_build/K8s_arch4.JPG","hash":"0974d9a80991964c3ac4595f269a1e726b627765","modified":1587017506000},{"_id":"source/_posts/micro_service/05_kubernetes_volume/PV_PVC.PNG","hash":"b3d4198aad959dcc32c6de276ba16c10ea5c8078","modified":1590741667317},{"_id":"source/_posts/micro_service/07_kubernetes_Etcd/etcd_3.PNG","hash":"5ec9c0a1524d65f2711511069d8336a5d80792ae","modified":1594014078308},{"_id":"source/_posts/micro_service/istio_01_conception/Pilot_Architecture.png","hash":"e50e0aed665a181d2a0dc3b4350c79e9969b25cc","modified":1587372934000},{"_id":"source/_posts/micro_service/istio_01_conception/istio_arch.jpeg","hash":"6fe64e3ed3e1cf69c3afb2e1f2897684502af734","modified":1587372066000},{"_id":"source/_posts/micro_service/istio_01_conception/envoy_xds.png","hash":"ed49164a15c09d3019d5bd0749fdb8b47fb5bddc","modified":1596549861592},{"_id":"source/_posts/micro_service/01_kubernetes_build/k8s_architecture2.JPG","hash":"f8b04ee63df04a0764756e4ffcca4c034e5120ed","modified":1587019040000},{"_id":"source/_posts/micro_service/istio_03_configuration/security_policy.PNG","hash":"3d3e283582fefd864e0d031822a7fd3f124f1190","modified":1596559683515},{"_id":"source/_posts/micro_service/istio_03_configuration/traffic_control.PNG","hash":"0af77b9d7ed7e5aabecd0150e3ef95754ad91302","modified":1596548357812},{"_id":"source/_posts/nodejs/1.webstorm自动提示设置/1.png","hash":"0848ccafcee74e678276c5fdb1464e0ac3e0e25f","modified":1583385810849},{"_id":"source/_posts/nodejs/1.webstorm自动提示设置/2.png","hash":"a2468e2daf788c55028a05109a12f607af96d039","modified":1583385836874},{"_id":"source/_posts/nodejs/1.webstorm自动提示设置/3.png","hash":"8ee6e75907ac28feea60f0cf42b90fb43a5c0a63","modified":1583385850492},{"_id":"source/_posts/nodejs/1.webstorm自动提示设置/4.png","hash":"e834744d98be4e58dede9ec3aeb6fee8f03cde4f","modified":1583385864328},{"_id":"source/_posts/nodejs/1.webstorm自动提示设置/5.png","hash":"0e562184cd74722a234db4060c0c7ecbf94963ef","modified":1583385888687},{"_id":"source/_posts/nodejs/4.node_modules/taobao_mirror.PNG","hash":"a725107bff1e952029f75ef7fd640873f38fa307","modified":1583460309363},{"_id":"source/_posts/nodejs/浏览器工作原理/Web.png","hash":"0de98a3c9390e882f788c597f297402f3603cca6","modified":1492514804000},{"_id":"source/_posts/nodejs/浏览器工作原理/chrome_rendering1.png","hash":"771fe609cf4384ad2c8cc8dea3f23a34d6af3527","modified":1499828810000},{"_id":"source/_posts/nodejs/浏览器工作原理/chrome_rendering2.png","hash":"3804da167147d183c95833ef39a1584a47d2d508","modified":1499828900000},{"_id":"source/_posts/nodejs/浏览器工作原理/http-header.png","hash":"8d858bcbea613ad69e401d43c3708a38b973a7e1","modified":1492485366000},{"_id":"source/_posts/nodejs/浏览器工作原理/npm1.png","hash":"1b6732f7e40e6a5a9bdfc477e2631ac61f947e1b","modified":1492479194000},{"_id":"source/_posts/nodejs/浏览器工作原理/sublimeconf1.png","hash":"7a0d8d065e530cd1a5f815946473bafd25247e04","modified":1499843524000},{"_id":"themes/3-hexo/git.bak/objects/9f/c8814f959a05438b90b61317ecf4fa1accc084","hash":"0641dc878890723c80fa34f7375c6ca4f53f7805","modified":1597237504590},{"_id":"themes/3-hexo/git.bak/objects/b8/8362d8b1768b1d1ed031a9a0de215a3191a6ec","hash":"f04e0e06e1129a2cc2122cc86cf53db423474ffd","modified":1597237504598},{"_id":"themes/3-hexo/source/js/gitment.js","hash":"67984b83cd46ff4300d4fd959bf6c17dd66b4136","modified":1581598065182},{"_id":"source/_posts/blogs/HTTP_TCP_Socket/ISO-TCP.IP.png","hash":"1511b62201cb7168f073f0ccbe1daf5a71c19138","modified":1592809309748},{"_id":"source/_posts/blogs/Hexo_01_部署github_blog/registry_gitalk.PNG","hash":"856740f2c5d2aaf83cc27aa6979b206cc4cfd1b3","modified":1597233155253},{"_id":"source/_posts/language/python/linux_install_python_pip_pipenv/pipfile.JPG","hash":"6e04b251b84050d62f7ac7081862a6843c6cfcd1","modified":1587826312827},{"_id":"source/_posts/linux/sda_hda/power_data_interface.png","hash":"e2247a7e6780a10f0339ebc235f0866c4dd6d597","modified":1581598064560},{"_id":"source/_posts/linux/按字节-字寻址_字长_地址总线_数据总线关系/address.png","hash":"421b58e086b755f6cd1cdd341c1212b42bd21add","modified":1581598064590},{"_id":"source/_posts/nodejs/浏览器工作原理/env_path.png","hash":"2c1368b17a1447d8fc018a259a2280f63a9e9ba9","modified":1492156164000},{"_id":"source/_posts/nodejs/浏览器工作原理/htmlFormEl.png","hash":"5052dd3771752c0923fef6a80afd809349fab151","modified":1492482952000},{"_id":"source/_posts/technologies/maven/maven_project/compile.JPG","hash":"e05a60e2824ca55d265619da2f58cc15f902784e","modified":1586688702000},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/1.png","hash":"535193d7d60ea1cf5c97ff9fd02d658d28fba8f4","modified":1594788640701},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/10.png","hash":"14fa5983d84240c8ca7790a48d1ff059b4ce8b2d","modified":1594788782950},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/11.png","hash":"9bd4e17909bec0d308231044a9e531c79f6fbfbb","modified":1594788791878},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/12.png","hash":"2de64b342229deea86b03cbd5f24d663ae66edd0","modified":1594788799557},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/13.png","hash":"1677b154e7a8c4cd234238224401c009dd48dc25","modified":1594788807087},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/14.jpg","hash":"4bea863fd41d9153397ac7e50b200fab0404401e","modified":1594788816571},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/15.png","hash":"e3f44cc0d5e0ee4e2bc7990fa0f07ac6f83553ab","modified":1594788836929},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/16.png","hash":"da3b727d63ebaec0f0ed01acc0410cf1be720bf3","modified":1594788850333},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/18.png","hash":"a39cffaa883843a6a6ebf15e89d0df03e5b4e0cc","modified":1594788886929},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/19.jpg","hash":"307a478c4b3474f76661fe8e6f4ad66f9ca9ece4","modified":1594788895092},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/2.png","hash":"cd986c08eace5ab07427ed7f2ea41af42d1b9d97","modified":1594788664017},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/20.png","hash":"f53087c20bb08712d5df19580d050215c27c70b5","modified":1594788904316},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/4.png","hash":"79f02a125a88f2541db37a63a78117bc2cf9ebb9","modified":1594788697912},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/6.png","hash":"afe28458e9c0118cbc6f080781140a9b0ba6030a","modified":1594788748322},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/7.png","hash":"08a716426e70fd0da66b3a6050ba38c5077652af","modified":1594788755367},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/8.png","hash":"1d5b40149630905b3440d23b918f6458fb412cd0","modified":1594788764477},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/9.png","hash":"d303be13e76faf1913b4ba1dab8dd53bcf78dae2","modified":1594788774596},{"_id":"source/_posts/technologies/security/tls_ssl_https_http_protocol/osi.png","hash":"558db12914e093c78dbda439ade2fe44aaf29360","modified":1594878090459},{"_id":"source/_posts/technologies/security/tls_ssl_https_http_protocol/tcp_ip.png","hash":"486f6d7c5b1b5f4db4fb350ff3c8430f0ac65d23","modified":1594878071062},{"_id":"source/_posts/technologies/web/HTML/2.PNG","hash":"723182d00d1760eb8406b595d13eaad1833deab6","modified":1584010609667},{"_id":"source/_posts/technologies/web/HTML/4.PNG","hash":"fc1c5ed205c2abbebb0d04681620ea4e4566b772","modified":1584020324068},{"_id":"source/_posts/technologies/web/HTML/5.PNG","hash":"48c37c2fd3408a21692310f6a9c7aa7982d409fe","modified":1584025389789},{"_id":"source/_posts/technologies/web/HTML/6_1.PNG","hash":"616527c38d95543ca94834fd7f21a3445610db01","modified":1584030387279},{"_id":"source/_posts/technologies/web/HTML/7.PNG","hash":"f1e1929c3c1bb4a07317629cf948172456eefa10","modified":1584027377866},{"_id":"source/_posts/technologies/web/HTML/table_td_empty.gif","hash":"9692bbee25004a322dd84a8e9ea294c9a2cbec14","modified":1584009819149},{"_id":"source/_posts/technologies/web/JavaScript/pic.JPG","hash":"dee2336070aed563aa462e0196cf3a1203e69055","modified":1586931918000},{"_id":"themes/3-hexo/git.bak/logs/refs/heads/master","hash":"9334d9cef79a86d6990db250409f3bcd6a257684","modified":1597237527326},{"_id":"themes/3-hexo/git.bak/refs/remotes/origin/HEAD","hash":"e72f7364331a01c35feea3858c09e16db1631660","modified":1581598064827},{"_id":"themes/3-hexo/git.bak/refs/remotes/origin/changeIcon","hash":"b88d9fc08fe7a3bfb4e10206b801441d3f337b2d","modified":1597237358158},{"_id":"themes/3-hexo/git.bak/refs/remotes/origin/master","hash":"dd1e560dba03636d502a133176c3b83d578721b4","modified":1597237358153},{"_id":"source/_posts/deeplearning/deeplearning_01_get_started/02.PNG","hash":"988c1e6c0c84ca30840cd41dcdd36f5c8796701c","modified":1597217192443},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture10.jpg","hash":"f677a9134b896c147af9e3bfc99f95801a400391","modified":1581598064288},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/0.PNG","hash":"a5b11e40d94e564c74f275e0b2637de6df15040c","modified":1594789472147},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/17.png","hash":"423b4de305b1b0d53ec12fe6f69ef7d816b87133","modified":1594788877146},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/3.png","hash":"d7c9b6b6e8d3dfb5aa65e3d7a9b0cb4e90b9b95c","modified":1594788689728},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/5.png","hash":"090ca17bc561e623cc027980dec6e3cf93e36ed5","modified":1594788721010},{"_id":"source/_posts/technologies/security/tls_ssl_https_http_protocol/https.png","hash":"bbf47e3860a3af9482bef3406215453864acbd2f","modified":1594879696954},{"_id":"source/_posts/technologies/security/token_jwt/token_scene1.png","hash":"a5a2e7824e9a6ef694bf58d3d5e203b47d9c227f","modified":1595230028707},{"_id":"source/_posts/technologies/web/HTML/12.PNG","hash":"9821d9e5a1ef0daea47a26b14da93fc688cd9463","modified":1584207372047},{"_id":"source/_posts/technologies/web/HTML/3.PNG","hash":"f22fb4c2414b13dad95350c4215923116d4281e9","modified":1584012566563},{"_id":"source/_posts/deeplearning/deeplearning_01_get_started/01.PNG","hash":"dae96c50a20774dc9f742afee1e67f623ede106a","modified":1597215634914},{"_id":"source/_posts/deeplearning/deeplearning_01_get_started/07.PNG","hash":"f7193b55d85d1b5208cce3a02f19db7abcc53a16","modified":1597222008813},{"_id":"source/_posts/linux/sda_hda/IDE_power_sata.png","hash":"472701f7095ef418fc1b33480ef33ebf54fb4f79","modified":1581598064556},{"_id":"source/_posts/linux/sda_hda/sda_interface.png","hash":"7bf33b16c821b6a1b6cb073d220f699699fa5e07","modified":1581598064566},{"_id":"source/_posts/micro_service/09_kubernetes_certificate/k8s_certificates.PNG","hash":"521ba7cdd0d4eb3844a5534a5ee11027d494b9e4","modified":1594001912931},{"_id":"source/_posts/micro_service/services_analysis/architecture.png","hash":"83855ba6cf45dcae2d6ee17c8e43ab420e226d25","modified":1594731453658},{"_id":"source/_posts/nodejs/浏览器工作原理/sublimeconf21.png","hash":"4fad8d85d0b884279c1d1475a9ebfa3aaa750dfd","modified":1499843674000},{"_id":"source/_posts/technologies/maven/maven_project/jar.JPG","hash":"cd696f9fce0abcbb596d4c58e78895ac1f06528d","modified":1586688930000},{"_id":"source/_posts/technologies/security/pki/pki_mode.png","hash":"e9071b8c7aafb73fadfe2d646df893fd40ead775","modified":1595231774681},{"_id":"source/_posts/technologies/security/tls_ssl_https_http_protocol/http_tls_ssl.png","hash":"b6fa4f1d8bced00f0b04f18be3cd1f10864d6c0b","modified":1594879594226},{"_id":"source/_posts/technologies/web/HTML/1.PNG","hash":"3ad78055f9bce980f860596414e04ef81ce61580","modified":1584012710072},{"_id":"themes/3-hexo/git.bak/logs/refs/remotes/origin/HEAD","hash":"26007d6bfb189bb238d0ccb5ea14b8615a6880f6","modified":1581598064757},{"_id":"themes/3-hexo/git.bak/logs/refs/remotes/origin/master","hash":"da8f62b52bffa7918bb9c9c8e37af9ecd91b78dd","modified":1597237358155},{"_id":"themes/3-hexo/git.bak/logs/refs/remotes/origin/changeIcon","hash":"63bdf92ec16e04fb7617f1b240486d3d515a65b3","modified":1597237358159},{"_id":"source/_posts/technologies/security/pki/tls_deployment.jpg","hash":"d3183fa5d61915553bd04b1a0feaa59e391397e9","modified":1595232217417},{"_id":"source/_posts/technologies/web/HTML/6.PNG","hash":"062798980be3891b4e05311bbeb86229f97e36c6","modified":1584029963734},{"_id":"source/_posts/blogs/HTTP_TCP_Socket/ISO.png","hash":"bf419d02ba64f2e62255316851593c31464c552c","modified":1592808133084},{"_id":"source/_posts/technologies/docker/dockerfile/01.png","hash":"ace5e9b1f35f4277568176f2c4196c2bb2a74f50","modified":1588674836000},{"_id":"source/_posts/linux/sda_hda/IDE_interface.png","hash":"988dda3cf0240dbacc71736b899e737e093173c5","modified":1581598064550},{"_id":"source/_posts/deeplearning/deeplearning_01_get_started/06.PNG","hash":"cad973215231d6f32e5edb46b054f9cc34c0c444","modified":1597221962969},{"_id":"source/_posts/technologies/security/pki/key_save.png","hash":"28f8947dde55d003a28fff2bc3594ba587d8c2bb","modified":1595231582242},{"_id":"themes/3-hexo/git.bak/objects/pack/pack-65553499904f765c705aad8cd266f19a07bbaadc.pack","hash":"a6bd762fd91632c9e21990e7e4938f230509bd74","modified":1597237357919},{"_id":"themes/3-hexo/source/js/gitalk.js","hash":"a95b598d998c4723f978ed21614127150075bf40","modified":1597237527320},{"_id":"source/_posts/deeplearning/deeplearning_01_get_started/05.PNG","hash":"258f1255e9c0cfabcaa9701dd2ffcab1d0b6253a","modified":1597221068719},{"_id":"source/_posts/micro_service/09_kubernetes_certificate/CA_simulate.PNG","hash":"5a5b353b5cdbaae68b8df1727107638498a05aa3","modified":1594003238273},{"_id":"source/_posts/nodejs/浏览器工作原理/51jobnode.png","hash":"a6bd6a6ac7561349bfbf8f60857f7a228fbc87c9","modified":1499955233210},{"_id":"source/_posts/nodejs/浏览器工作原理/npm.png","hash":"eaaca8f9567e6216557789f286da08b7d20a44a1","modified":1492478264000},{"_id":"source/_posts/deeplearning/deeplearning_01_get_started/08.PNG","hash":"784585bf4cf332e5d10b7c4723de1c00c3739cff","modified":1597222450092},{"_id":"source/_posts/technologies/security/pki/base_encryption.png","hash":"c8c8327bfad3d73cfae7a468d00315466633b1f2","modified":1595231367397},{"_id":"source/_posts/blogs/HTTP_TCP_Socket/tcp-ip-handshark.png","hash":"47db48d5734839580ffd53dc793e89711f4cef17","modified":1592808803754},{"_id":"source/_posts/technologies/docker/dockerfile/02.png","hash":"11b3a665b93035cd672e1075cc2c51dd7653c01e","modified":1588674998000},{"_id":"themes/3-hexo/git.bak/objects/pack/pack-e58995235e8928786b64c3df82dba98a1aae246c.pack","hash":"bb7afb66b960e2f2b517e7a07a068ba651cf846d","modified":1581598064788},{"_id":"source/_posts/nodejs/浏览器工作原理/fiddlersetup.exe","hash":"98454635315e6940da83d39f8590c4ca82009e47","modified":1492055082000},{"_id":"public/2020/08/13/windows/Windows10_VScode远程连接linux编辑调试/index.html","hash":"5f4c5dfea6a3df8106dfc8f5502c4bcd4b4b64d5","modified":1597669794913},{"_id":"public/2020/08/13/windows/U盘分区之后如何恢复/index.html","hash":"8ec4fc1087c72d1deea25d4403d6d9f9eb64938c","modified":1597669794913},{"_id":"public/2020/08/13/technologies/web/JavaScript/index.html","hash":"8e7340af35586925f4a6ed25afaa9317aab35226","modified":1597669794913},{"_id":"public/2020/08/13/technologies/web/HTML/index.html","hash":"437beb35dd72379c0dcbfab333c623042518c2f6","modified":1597669794913},{"_id":"public/2020/08/13/technologies/web/datatables/index.html","hash":"24f9082c37ec70ae10fca0712707b20740c27cd7","modified":1597669794913},{"_id":"public/2020/08/13/technologies/web/bootstrap/index.html","hash":"a790bf7391128200181ce167a65c90dc82993664","modified":1597669794913},{"_id":"public/2020/08/13/technologies/security/token_jwt/index.html","hash":"81865e731eea792d6159616075e465bbe2982933","modified":1597669794913},{"_id":"public/2020/08/13/technologies/security/tls_ssl_https_http_protocol/index.html","hash":"bb37b0afcf06f582d20d83095f64671178e3e31d","modified":1597669794913},{"_id":"public/2020/08/13/technologies/security/pki/index.html","hash":"02ad0104407fd57013eefd097ae300be5eeed6e2","modified":1597669794913},{"_id":"public/2020/08/13/technologies/security/openssl_certificates/index.html","hash":"92f1a180baa2f05c9ad7f12c67a0825369b9cdfb","modified":1597669794913},{"_id":"public/2020/08/13/technologies/security/key_digest_signature_certificates/index.html","hash":"e4edc463c9045d6e063e0130d7fac6ffffa78247","modified":1597669794913},{"_id":"public/2020/08/13/technologies/security/algorithm_security/index.html","hash":"c60ad5e2816ebcd15fd6fa9507f19270f09b986a","modified":1597669794913},{"_id":"public/2020/08/13/technologies/maven/ubuntu18.04安装Mysql8.0/index.html","hash":"b704b59332713501e3bf4d06016d35509a01506e","modified":1597669794913},{"_id":"public/2020/08/13/technologies/maven/thrift/index.html","hash":"72645fa6e31c45e94215e9d29a7fce68d6c85f04","modified":1597669794913},{"_id":"public/2020/08/13/technologies/maven/navicat_premium/index.html","hash":"86ed1d8635adad7d15f15334b2ee8d22b70e4d59","modified":1597669794913},{"_id":"public/2020/08/13/technologies/maven/maven_project/index.html","hash":"6693274a683bf940358f9a0c5ef8a719d0f5e603","modified":1597669794913},{"_id":"public/2020/08/13/technologies/maven/maven_eclipse_tomcat_JDK1.8_configuration/index.html","hash":"f25039d60cc9cac1a9d712d1f147b12b3493feee","modified":1597669794913},{"_id":"public/2020/08/13/technologies/maven/IntelliJ_idea/index.html","hash":"5088f5b295844b0bc1038e9871d6c8f01fa502d9","modified":1597669794913},{"_id":"public/2020/08/13/technologies/docker/docker_step_02/index.html","hash":"99a7dc3e5bbfd535b119080b7e53232d6f04fcde","modified":1597669794913},{"_id":"public/2020/08/13/technologies/docker/docker_step_01/index.html","hash":"efeed5096164b33004271f6b6c7de944f8745360","modified":1597669794913},{"_id":"public/2020/08/13/technologies/docker/dockerfile/index.html","hash":"88e722fc16c3537e1a024c03ac09e2089e4a27b1","modified":1597669794913},{"_id":"public/2020/08/13/technologies/Intel_tips_at_work/index.html","hash":"8268aaf36d16d3b609ebaef859e1c55bc1362c16","modified":1597669794913},{"_id":"public/2020/08/13/technologies/git_problems_encountered/index.html","hash":"142522e759524c1938d7ba3ecbcc5a28d5ffd1a7","modified":1597669794913},{"_id":"public/2020/08/13/storage/minIO_03_client.md/index.html","hash":"8ed2e34b07f3655566d73fd2aec6f1e822e5fef7","modified":1597669794913},{"_id":"public/2020/08/13/storage/minIO_02_deployment_on_kubernetes/index.html","hash":"b5c58af84ab16cd4ca06e0190c4b7bd2a4268461","modified":1597669794913},{"_id":"public/2020/08/13/storage/minIO_01_conception/index.html","hash":"abc2126a2ba520d4511dc42974f86868163314f8","modified":1597669794913},{"_id":"public/2020/08/13/storage/greenplum/index.html","hash":"ed43487e9c8bc8a27b192e9835fb2908c9bf6090","modified":1597669794913},{"_id":"public/2020/08/13/storage/ceph_deployment_02/index.html","hash":"78e04ba5043aeb7aeb1efd14c7888b118217678d","modified":1597669794913},{"_id":"public/2020/08/13/storage/ceph_conception_01/index.html","hash":"d7f12056a27dd25f2f79d7b2529c0736862aac14","modified":1597669794913},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/index.html","hash":"60bb50b626377d68559491bdda125ddcba879da9","modified":1597669794913},{"_id":"public/2020/08/13/nodejs/NodeJs简介/index.html","hash":"b64e96dfd09b7d77e11f874ab8ce4c3ec26e66e2","modified":1597669794913},{"_id":"public/2020/08/13/nodejs/Express简介/index.html","hash":"2c61eddabf0447a203aeaad125631edfc7aecbde","modified":1597669794913},{"_id":"public/2020/08/13/nodejs/4.node_modules/index.html","hash":"50d01ff268d46710a6606b80c1f17519d96f5bd0","modified":1597669794913},{"_id":"public/2020/08/13/nodejs/3.JSP匿名函数,自执行函数/index.html","hash":"107850f9cd0f81cf02d0d2b932639c4ac4218c94","modified":1597669794913},{"_id":"public/2020/08/13/nodejs/2.Windows10_Node.js_安装/index.html","hash":"5e9e43ab1c630ed46c109bf88182c3a34048a0a4","modified":1597669794913},{"_id":"public/2020/08/13/nodejs/2.Linux_Node.js_安装/index.html","hash":"9e27845b05ead508c110f3def64398fa48d1be19","modified":1597669794913},{"_id":"public/2020/08/13/nodejs/1.webstorm自动提示设置/index.html","hash":"166629f6e8d929697e3e8bb9355eb25bab6e7744","modified":1597669794913},{"_id":"public/2020/08/13/micro_service/services_analysis/index.html","hash":"70c839fc502fd8e3327a69a52a234722a199678e","modified":1597669794913},{"_id":"public/2020/08/13/micro_service/Resources/index.html","hash":"757d18b25916dc8fd18577fd7e8cfcb97cfa3928","modified":1597669794913},{"_id":"public/2020/08/13/micro_service/Istio_K8s_SpringCloud/index.html","hash":"793b96f8ca7bb6cb04e21d9e63056947f5f02304","modified":1597669794913},{"_id":"public/2020/08/13/micro_service/istio_03_configuration/index.html","hash":"8269cd4ab3f4aee4e7b7f85a991aeec2e052571a","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/istio_02_installation/index.html","hash":"0229ce5acea9842da7f5fa8a5243257b34c815f4","modified":1597669794913},{"_id":"public/2020/08/13/micro_service/istio_01_conception/index.html","hash":"e6063197e2407088efdd656dd0d4c513bfcc6742","modified":1597669794913},{"_id":"public/2020/08/13/micro_service/09_kubernetes_certificate/index.html","hash":"72b1668bc3bc8082a03da1519bb2497951d122b2","modified":1597669794913},{"_id":"public/2020/08/13/micro_service/08_kubernetes_samples_problems/index.html","hash":"a3084c83611a0792035494d7893da11b3e60869a","modified":1597669794913},{"_id":"public/2020/08/13/micro_service/07_kubernetes_Etcd/index.html","hash":"065e2a95e11805ae40c472061b2122cb8042f280","modified":1597669794913},{"_id":"public/2020/08/13/micro_service/06_kubernetes_deployment/index.html","hash":"a593cb6ca80dac0eb21505c7f0e8f16eec57e209","modified":1597669794913},{"_id":"public/2020/08/13/micro_service/05_kubernetes_volume/index.html","hash":"940bd3122da34f801a1b558f56ef238ac1ceb428","modified":1597669794913},{"_id":"public/2020/08/13/micro_service/04_kubernetes_service/index.html","hash":"728933aa35656a28b4300f8eab3b7511752119f4","modified":1597669794913},{"_id":"public/2020/08/13/micro_service/03_kubernetes_ns_pod/index.html","hash":"58ee9438b936ccd60f8780141ab835f903952cee","modified":1597669794913},{"_id":"public/2020/08/13/micro_service/02_kubernetes_roles_introduction/index.html","hash":"948fe5321fb842654c5d136c71136ab0fd086aec","modified":1597669794913},{"_id":"public/2020/08/13/micro_service/01_kubernetes_build/index.html","hash":"4b007a227d2ba305f1676a678944f8a21b04094f","modified":1597669794913},{"_id":"public/2020/08/13/linux/连接router后机器连不上外网/index.html","hash":"e7fb12259bc4ba421aba556d411f6821ac0f48d9","modified":1597669794913},{"_id":"public/2020/08/13/linux/解压缩命令合集/index.html","hash":"18fdee843596fe8d8575f2169f606b97177f689d","modified":1597669794913},{"_id":"public/2020/08/13/linux/脚本执行错误_r_command not found/index.html","hash":"a9ae5e4595dc2797fa0b1c59f7f163b886ae1ea2","modified":1597669794913},{"_id":"public/2020/08/13/linux/硬盘存储空间单位GB/index.html","hash":"1dc20e5a491d980e58cc28df3b0bdcdca8f9203a","modified":1597669794913},{"_id":"public/2020/08/13/linux/用户态和内核共享内存-使用dev_mem&mmap/index.html","hash":"c44cd54806e88aa4fe5dbe89334c4cc400dc72d8","modified":1597669794913},{"_id":"public/2020/08/13/linux/查看SSD/index.html","hash":"d97e620566b2b88ffb6e90311783bad347c2b58e","modified":1597669794913},{"_id":"public/2020/08/13/linux/按字节-字寻址_字长_地址总线_数据总线关系/index.html","hash":"dae1e6a18c2168dde6b8dfa85ca272740cb14cca","modified":1597669794913},{"_id":"public/2020/08/13/linux/yum使用和安装cmake-3版本上/index.html","hash":"7a074aea9b4057b82b69610183a1027b25530dc1","modified":1597669794913},{"_id":"public/2020/08/13/linux/yum下载遇到XZ_5.1.2alpha问题/index.html","hash":"d14369fb236ff4f4cc4800dc85cd0a1abad3f799","modified":1597669794913},{"_id":"public/2020/08/13/linux/Windows10mstsc远程登录Centos7.0/index.html","hash":"e5f9e1a4ed838f251fe1361fcb5f5c6fd3f42557","modified":1597669794913},{"_id":"public/2020/08/13/linux/wget_www.baidu.com/index.html","hash":"333830a21672318b78ca18498ff7e8ec19c5ba3e","modified":1597669794913},{"_id":"public/2020/08/13/linux/vim/index.html","hash":"624f5b6f0443374d26df0b709cb6767f2ca91080","modified":1597669794913},{"_id":"public/2020/08/13/linux/U盘安装OS_Ubuntu_18.04/index.html","hash":"e998a8032c653add9d9e5c0fcd4231865d907b0a","modified":1597669794913},{"_id":"public/2020/08/13/linux/U盘分区之后如何恢复/index.html","hash":"ddaad41ad774693119e63c9124d86437b1d4ef95","modified":1597669794913},{"_id":"public/2020/08/13/linux/U盘RAW类型修复/index.html","hash":"40c294be83456c7a230be2e1a5f9eb8bfc715ec5","modified":1597669794913},{"_id":"public/2020/08/13/linux/Ubuntu下安装CUDA8.0及nvidia驱动(详细教程)/index.html","hash":"8f2cca359dd6668b94efee16d2f7ccc67c3e0411","modified":1597669794913},{"_id":"public/2020/08/13/linux/TSC/index.html","hash":"3e086ba1255120cf46bde241d887d044e79a31ea","modified":1597669794913},{"_id":"public/2020/08/13/linux/ssh端口映射/index.html","hash":"dba8bfe9feb505d1fc748b817970992723f4d1b6","modified":1597669794913},{"_id":"public/2020/08/13/linux/sda_hda/index.html","hash":"e0e6575f5d336a68c59c9783050e1a0eaa1b4ab8","modified":1597669794913},{"_id":"public/2020/08/13/linux/screen程序在后台运行/index.html","hash":"21ae88cd18e4d73693cad0b59247e23b8a3e71ef","modified":1597669794913},{"_id":"public/2020/08/13/linux/scp机器间复制文件/index.html","hash":"b0cda1a73adfa3b7fb3080f05788dd348bf43eed","modified":1597669794913},{"_id":"public/2020/08/13/linux/rpm_yum/index.html","hash":"40fb361cf413a90a7c7e942effbc210c62fb3e93","modified":1597669794913},{"_id":"public/2020/08/13/linux/RHEL8.0开机总是要dhclient手动获取IP/index.html","hash":"d25a427eb608860e755e54652f6913e52f8e041e","modified":1597669794913},{"_id":"public/2020/08/13/linux/PTU(Power Thermal Utility)/index.html","hash":"0698fdd70babe9c60169914f79bd2dd588e55b17","modified":1597669794913},{"_id":"public/2020/08/13/linux/perf/index.html","hash":"dbd07759e539c70cefd977cc35cd0506be69fc69","modified":1597669794913},{"_id":"public/2020/08/13/linux/ntpdate_synchronize_os_time/index.html","hash":"9782f45cdf4cc765defa96a135f3b8b769bc906c","modified":1597669794913},{"_id":"public/2020/08/13/linux/MMIO/index.html","hash":"854a5e5392732ed05c9299b1e978e9c28af40ea1","modified":1597669794913},{"_id":"public/2020/08/13/linux/ln_-s_-_linux 软连接command/index.html","hash":"8d4a7543dca22979fb0fd49bc6b0dd9270bd7635","modified":1597669794913},{"_id":"public/2020/08/13/linux/Linux能访问外网_外网却访问不了此Linux/index.html","hash":"e02e80e7e3c340f0c8370b8e52b8f619b345eef0","modified":1597669794913},{"_id":"public/2020/08/13/linux/linux给grub添加内核启动参数/index.html","hash":"9e5d685ce15afcd2a0128db0c5de2b8053c5e81c","modified":1597669794913},{"_id":"public/2020/08/13/linux/Linux永远修改时间/index.html","hash":"961a18790947756e0cf2913caa4e2dbef94c9c4b","modified":1597669794913},{"_id":"public/2020/08/13/linux/linux查看运行的服务/index.html","hash":"b4dd0513fbf1874db81dfb41acb46240494cfe69","modified":1597669794913},{"_id":"public/2020/08/13/linux/linux日志_服务日志/index.html","hash":"ecc0b35fdbc134ea999baa2491506c9db16cfdd3","modified":1597669794913},{"_id":"public/2020/08/13/linux/linux向其它终端发送消息/index.html","hash":"ff6f277da4029cf70b2588e27eaaa64580a68840","modified":1597669794913},{"_id":"public/2020/08/13/linux/linux制作U盘启动盘/index.html","hash":"df94b0af541353ed5ded608540525ae04b21306d","modified":1597669794913},{"_id":"public/2020/08/13/linux/Linux_kernel_更新/index.html","hash":"0046529944a5492333c6e00daf01c229ee7bafcf","modified":1597669794913},{"_id":"public/2020/08/13/linux/Linux_kernel_userspace体系结构/index.html","hash":"a5f5c414510de75da5c7ff23d2fff06ab7e427be","modified":1597669794913},{"_id":"public/2020/08/13/linux/Linux_command_find_grep_sed_awk/index.html","hash":"525b1e5e34ed7e67866348b87b3503337896a2e1","modified":1597669794913},{"_id":"public/2020/08/13/linux/Linux 修改root名称/index.html","hash":"6608483f6e9ace275c42126e8bfa41d6c5ca0fc0","modified":1597669794913},{"_id":"public/2020/08/13/linux/intel_pstate-acpi-cpufreq驱动研究/index.html","hash":"034278245b892e232b0b3ae6e73fbebb520b32c6","modified":1597669794913},{"_id":"public/2020/08/13/linux/Intel_pstate-acpi-cpufreq驱动切换/index.html","hash":"7ccea73f03ecc29fd6ddad4fa62900d3a8d3a7bd","modified":1597669794913},{"_id":"public/2020/08/13/linux/Intel_pstate&HWP功能enable_disable/index.html","hash":"a2fa3435b1e1fc1202cc8c61fec8c9ca0aebef3d","modified":1597669794913},{"_id":"public/2020/08/13/linux/history/index.html","hash":"a0916837814bd8e3bab9ddb4334275cc24e79879","modified":1597669794913},{"_id":"public/2020/08/13/linux/fdisk磁盘分区/index.html","hash":"5b172f99083932f081278f3a36677583aa06743c","modified":1597669794913},{"_id":"public/2020/08/13/linux/etc_profile-etc_bashrc-~.bashrc/index.html","hash":"f31ecbc23aa146218809a2a62701f5fa01e396a2","modified":1597669794913},{"_id":"public/2020/08/13/linux/EOF/index.html","hash":"5293f876fbcac9d6780696d0058af8040dec6dcc","modified":1597669794913},{"_id":"public/2020/08/13/linux/emon/index.html","hash":"f4bb09fcdb61380aca74ec5aeedee64313417910","modified":1597669794913},{"_id":"public/2020/08/13/linux/docker/index.html","hash":"6b138e78ab90cd04ec9e406c3b300d87f2182fee","modified":1597669794913},{"_id":"public/2020/08/13/linux/dmidecode/index.html","hash":"ae820b10351a17aec17c077efec03e78bc8bd3dc","modified":1597669794913},{"_id":"public/2020/08/13/linux/Devtoolset 升级gcc到8.3.1/index.html","hash":"6c3ca4045a977eb55bc96b4343040e785fe02104","modified":1597669794913},{"_id":"public/2020/08/13/linux/dd_command/index.html","hash":"f90b087de419d16b13c762ceefd00b23b8030346","modified":1597669794913},{"_id":"public/2020/08/13/linux/curl_wget/index.html","hash":"8c928f05ba61a02c23315dbb0a16f4cbd8c798fa","modified":1597669794913},{"_id":"public/2020/08/13/linux/CPU角度理解PCIE/index.html","hash":"06a0feb37f255d4de64e4b245f409b4f4b253743","modified":1597669794913},{"_id":"public/2020/08/13/linux/cppc动态调频/index.html","hash":"1a2e07aa51706ae691dc6f536a8de8e8b93bb5d1","modified":1597669794913},{"_id":"public/2020/08/13/linux/cmake/index.html","hash":"0c45527b4f3c3e725d10dcfe8a81626600b2f1db","modified":1597669794913},{"_id":"public/2020/08/13/linux/Centos更改kernel 默认启动项/index.html","hash":"88262c1d13939fec8b06d4b7f26aa2749bfad914","modified":1597669794913},{"_id":"public/2020/08/13/linux/centos升级gcc到9.1.0/index.html","hash":"8caf1f5098361b8f88cdc03badc3b89c26b01d0f","modified":1597669794913},{"_id":"public/2020/08/13/linux/BIOS/index.html","hash":"80739315f4d9dc5a32cd2d31aa5ba13e8ccd7108","modified":1597669794913},{"_id":"public/2020/08/13/linux/ACPI是什么&BIOS中ACPI要怎么设置/index.html","hash":"7b08d01e58b5558d26126fde47af0e95fc56d5f2","modified":1597669794913},{"_id":"public/2020/08/13/links/Learning_links/index.html","hash":"a356f851c1403b2c9840ef6c421bb44ddc4712c4","modified":1597669794913},{"_id":"public/2020/08/13/language/python/linux_install_python_pip_pipenv/index.html","hash":"9524a74dd2bf723720a385f92b41cce184f70951","modified":1597669794913},{"_id":"public/2020/08/13/language/go/goLang/index.html","hash":"42ae78f8dc68ee6bdd8169be6f3497bfaa80029f","modified":1597669794913},{"_id":"public/2020/08/13/language/c/gdb/index.html","hash":"c7f954f14d8eafd176edd731c8f1c16e563d43d9","modified":1597669794913},{"_id":"public/2020/08/13/Englist_Learn/Englisth1/index.html","hash":"3c0593c3aa0b1633c6ce0e42618dae1e09d6fca3","modified":1597669794913},{"_id":"public/2020/08/13/deeplearning/deeplearning_01_get_started/index.html","hash":"495a50f7a09fa04fe45a6395e0bfd3093d83bfb2","modified":1597669794913},{"_id":"public/2020/08/13/blogs/Restful_API/index.html","hash":"908236b7da5a4e5f0fe85d2af5ed947ec4e5c6e2","modified":1597669794913},{"_id":"public/2020/08/13/blogs/HTTP_TCP_Socket/index.html","hash":"c7ec3bef1da70bbd498f582c7f41ae46ddb8c023","modified":1597669794913},{"_id":"public/2020/08/13/blogs/Hexo_03_写博客语法/index.html","hash":"b4f1589ad3eee5c2f511c31e84d3d2eb4df824b8","modified":1597669794913},{"_id":"public/2020/08/13/blogs/Hexo_02_git_clone_blog后如何运行 - 副本/index.html","hash":"5705c5c138f9c73ee5b802462f4288fededa27c0","modified":1597669794913},{"_id":"public/2020/08/13/blogs/Hexo_01_部署github_blog/index.html","hash":"6287a00f639b7b5144ae95599ae0e11d657507fd","modified":1597669794913},{"_id":"public/2020/08/13/hello-world/index.html","hash":"9602ec7fddec9a133fbb721598dd31bed9bbdb2a","modified":1597669794913},{"_id":"public/archives/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/page/2/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/page/3/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/page/4/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/page/5/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/page/6/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/page/7/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/page/8/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/page/9/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/page/10/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/page/11/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/page/12/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/page/13/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/page/2/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/page/3/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/page/4/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/page/5/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/page/6/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/page/7/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/page/8/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/page/9/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/page/10/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/page/11/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/page/12/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/page/13/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/08/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/08/page/2/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/08/page/3/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/08/page/4/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/08/page/5/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/08/page/6/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/08/page/7/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/08/page/8/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/08/page/9/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/08/page/10/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/08/page/11/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/08/page/12/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/archives/2020/08/page/13/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/Englisth/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/blogs/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/Englisth/5500/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/LearnLinks/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/deeplearning/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/linux/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/linux/page/2/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/linux/page/3/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/linux/page/4/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/linux/page/5/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/linux/page/6/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/microService/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/microService/page/2/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/microService/kubernetes/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/microService/istio/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/microService/REST-API/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/nodejs/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/storage/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/technologies/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/technologies/page/2/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/technologies/page/3/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/windows/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/language/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/technologies/docker/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/language/python/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/language/go/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/technologies/maven/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/language/c/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/technologies/security/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/categories/technologies/web前端/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/page/2/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/page/3/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/page/4/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/page/5/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/page/6/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/page/7/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/page/8/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/page/9/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/page/10/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/page/11/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/page/12/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/page/13/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/tags/deeplearning/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/tags/SSH-port/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/tags/kubernetes/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/tags/kubernetes/page/2/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/tags/istio/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/tags/storage/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/tags/git/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/tags/security/index.html","hash":"ec1866153f3a6a48fca583d2da887d8a83d4fb2e","modified":1597669794913},{"_id":"public/img/gov.png","hash":"f31c9f47faedf7f33b9580d6284ab891fb697560","modified":1597340831186},{"_id":"public/img/brown-papersq.png","hash":"3a1332ede3a75a3d24f60b6ed69035b72da5e182","modified":1597340831186},{"_id":"public/img/article-list-background.jpeg","hash":"4fdf8b3e53dd02d6ee6360aebfadb0cba1fb5633","modified":1597340831186},{"_id":"public/img/school-book.png","hash":"711ec983c874e093bb89eb77afcbdf6741fa61ee","modified":1597340831186},{"_id":"public/img/avatar.jpg","hash":"35a3f3736ea47e482e100a220023c6ef193fa93d","modified":1597340831186},{"_id":"public/css/fonts/icomoon.svg","hash":"b5e7562c8494b0ddb3a70ecc5545ef7340d8e971","modified":1597340831186},{"_id":"public/css/fonts/icomoon.eot","hash":"b6195bedc1cb2f9cfcb26cc27021f2e94be2ab0a","modified":1597340831186},{"_id":"public/css/fonts/icomoon.woff","hash":"3985d29416bb9b19f50a2f20f2bbbce47f10af8d","modified":1597340831186},{"_id":"public/css/fonts/icomoon.ttf","hash":"eb976d8b8559fcddfc2658a03a4350cb566fc06b","modified":1597340831186},{"_id":"public/css/fonts/iconfont.svg","hash":"3630aabf2f9c0417f483ebd03d9e429dbc2594e0","modified":1597340831186},{"_id":"public/css/fonts/iconfont.eot","hash":"b14b8624988ff069aff3145f88c0d7ac49052bd3","modified":1597340831186},{"_id":"public/css/fonts/iconfont.woff","hash":"0d2d4559f1ac4fa801eb8cc099fa5bf9dcf955ef","modified":1597340831186},{"_id":"public/css/fonts/iconfont.ttf","hash":"140829ecf12d30c6e18d8dc6dc0c188a66addd25","modified":1597340831186},{"_id":"public/css/fonts/iconfont.woff2","hash":"b0317a0b2ebb1181a8bf5a97d03556dd54538645","modified":1597340831186},{"_id":"public/2020/08/13/linux/BIOS/bios.gif","hash":"3035616439a8d9f6622ffe230f6686b6b0623168","modified":1597340831186},{"_id":"public/2020/08/13/linux/硬盘存储空间单位GB/unit_GB.gif","hash":"5d827e0d4e31cd3b676af756ff1cdbd3df911424","modified":1597340831186},{"_id":"public/2020/08/13/blogs/Hexo_01_部署github_blog/deploy.jpg","hash":"7d73e058e926c435a946c3f70a109cc2fe985295","modified":1597340831186},{"_id":"public/2020/08/13/linux/ACPI是什么&BIOS中ACPI要怎么设置/acpi.jpg","hash":"f231d7fc0990444380889a125ea61b7cb0b6a5f0","modified":1597340831186},{"_id":"public/2020/08/13/linux/ACPI是什么&BIOS中ACPI要怎么设置/acpi_bios.jpg","hash":"26ca938620770ef5735b84525aec2c58cca383c4","modified":1597340831186},{"_id":"public/2020/08/13/linux/Linux_kernel_userspace体系结构/linux_gun.jpg","hash":"8568e074f244e445593f071d25e6895bf2b08036","modified":1597340831186},{"_id":"public/2020/08/13/linux/screen程序在后台运行/screen_logs.png","hash":"e5af67f000eeae8c0c9e2efe3e0fb7e1190a816d","modified":1597340831186},{"_id":"public/2020/08/13/linux/screen程序在后台运行/screenlog.0.png","hash":"0ade7530720c84a5bf95b754f525b9c02a0dcfe9","modified":1597340831186},{"_id":"public/2020/08/13/linux/按字节-字寻址_字长_地址总线_数据总线关系/logical_physical.png","hash":"0ddaadc7b01712b3a711bf97030c81f775ab2b93","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/services_analysis/REST_FUL_API.png","hash":"5917b9cdca3a682895ade2e3f93c94327de11efa","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/2.Windows10_Node.js_安装/NODE_PATH.png","hash":"bfdec96c3e4aacee8b40c0a4943c1eaf7b0a3a3e","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/2.Windows10_Node.js_安装/PATH_nodejs_intall.png","hash":"4d1c9202cc201c1a27cd137f80ea0617e4aaf8be","modified":1597340831186},{"_id":"public/2020/08/13/linux/ssh端口映射/local_port_transmit.png","hash":"a868beb2a79f154502812dcb1212ede2eefb048d","modified":1597340831186},{"_id":"public/2020/08/13/linux/ssh端口映射/port_transmit_protocol.png","hash":"7d0113ab806f0732b570180de8cdb749c2942e3f","modified":1597340831186},{"_id":"public/2020/08/13/blogs/HTTP_TCP_Socket/socket.jpg","hash":"496b1d4cc6e6737b75846ca1751616ee2b943b90","modified":1597340831186},{"_id":"public/2020/08/13/linux/U盘分区之后如何恢复/diskpart.png","hash":"58c1c5e23ffe3400293af12eb24c236e4b89a4ee","modified":1597340831186},{"_id":"public/2020/08/13/linux/U盘分区之后如何恢复/clean.png","hash":"58c1c5e23ffe3400293af12eb24c236e4b89a4ee","modified":1597340831186},{"_id":"public/2020/08/13/linux/U盘分区之后如何恢复/list_disk.png","hash":"58c1c5e23ffe3400293af12eb24c236e4b89a4ee","modified":1597340831186},{"_id":"public/2020/08/13/linux/U盘分区之后如何恢复/select_disk.png","hash":"58c1c5e23ffe3400293af12eb24c236e4b89a4ee","modified":1597340831186},{"_id":"public/2020/08/13/linux/linux制作U盘启动盘/dd.png","hash":"fc995e69a462206967bdec2f1d190cf8236038d0","modified":1597340831186},{"_id":"public/2020/08/13/linux/linux制作U盘启动盘/mkfs.png","hash":"827bd99efaf9084e405fc44e1b25377b94179331","modified":1597340831186},{"_id":"public/2020/08/13/linux/linux制作U盘启动盘/umount.png","hash":"5767457dc3116f04713c3f244593342cb3dd2df5","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/istio_03_configuration/istio_arch_19.JPG","hash":"527c4645ed73e59467e42fea4b9b9ed1e308fc9a","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/istio_03_configuration/istio_arch_20.JPG","hash":"30ea66371d496fb3fd64407e001fe52e4713e3f9","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/istio_03_configuration/traffic_control.PNG","hash":"0af77b9d7ed7e5aabecd0150e3ef95754ad91302","modified":1597340831186},{"_id":"public/2020/08/13/windows/U盘分区之后如何恢复/1.png","hash":"58c1c5e23ffe3400293af12eb24c236e4b89a4ee","modified":1597340831186},{"_id":"public/2020/08/13/windows/U盘分区之后如何恢复/2.png","hash":"58c1c5e23ffe3400293af12eb24c236e4b89a4ee","modified":1597340831186},{"_id":"public/2020/08/13/windows/U盘分区之后如何恢复/3.png","hash":"58c1c5e23ffe3400293af12eb24c236e4b89a4ee","modified":1597340831186},{"_id":"public/2020/08/13/windows/U盘分区之后如何恢复/4.png","hash":"58c1c5e23ffe3400293af12eb24c236e4b89a4ee","modified":1597340831186},{"_id":"public/2020/08/13/windows/U盘分区之后如何恢复/5.png","hash":"58c1c5e23ffe3400293af12eb24c236e4b89a4ee","modified":1597340831186},{"_id":"public/2020/08/13/deeplearning/deeplearning_01_get_started/03.PNG","hash":"0448754143c63d10915c775652bbe1eaf0cd3429","modified":1597340831186},{"_id":"public/2020/08/13/deeplearning/deeplearning_01_get_started/04.PNG","hash":"baffcd5f4cbee7b7e804ce2cd2d194b5d0a4757c","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/1.webstorm自动提示设置/2.png","hash":"a2468e2daf788c55028a05109a12f607af96d039","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/1.webstorm自动提示设置/7.png","hash":"2d2a2e9b8b03e32f7c6ab82ee5f2027a3a5a9d0e","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/1.webstorm自动提示设置/6.png","hash":"c397fb9812ae19395c19e037486a52bb61db86e6","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/1.webstorm自动提示设置/8.png","hash":"53a6e10281cb4659880397d44865a30161056b18","modified":1597340831186},{"_id":"public/2020/08/13/linux/CPU角度理解PCIE/picture1.jpg","hash":"bc5912d9d93c3c14ae45ef3daf3346879dc90ce5","modified":1597340831186},{"_id":"public/2020/08/13/linux/CPU角度理解PCIE/picture11.jpg","hash":"25fa8ef27407f9136031b5eae545786f4a21f7dd","modified":1597340831186},{"_id":"public/2020/08/13/linux/CPU角度理解PCIE/picture2.jpg","hash":"1210c621445bc7383f20ff9724a4a1d1accf2cce","modified":1597340831186},{"_id":"public/2020/08/13/linux/CPU角度理解PCIE/picture4.jpg","hash":"0cb890d5e5f09fd9beab74778dbe28208df9850d","modified":1597340831186},{"_id":"public/2020/08/13/linux/CPU角度理解PCIE/picture6.jpg","hash":"e75662ccb5f7c29ae0d8e24be0d29c565e07b6da","modified":1597340831186},{"_id":"public/2020/08/13/linux/CPU角度理解PCIE/picture9.jpg","hash":"dc915c0441e7433510e1a17773e61569cf4b6dce","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/01_kubernetes_build/1.JPG","hash":"566cbdeabe2e3c0ada1714dfd1e879de9a1b8a38","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/01_kubernetes_build/3.JPG","hash":"ebc328818eec28d4ffe327e2a15b97b944c87c9b","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/01_kubernetes_build/Asymmetric_encryption.JPG","hash":"e688de20ac8f50947366d892165d7c5f40b242eb","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/01_kubernetes_build/6.JPG","hash":"92ba1d5858920fcc8c5a942cbd7b25a94dc8486a","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/01_kubernetes_build/K8s_arch1.JPG","hash":"6447d60dd07308f4ff3b358cac2ba5c1e082953f","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/01_kubernetes_build/K8s_arch2.JPG","hash":"8dcb6bdf5e8494569b611dfd0e4ba4d0c293c7d9","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/01_kubernetes_build/K8s_arch3.JPG","hash":"ff34f0bdf61b21715edd3541bb89081bb9155da3","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/01_kubernetes_build/Pod_Scaling.JPG","hash":"d2063a9fc37438d2b13f0c92a61ff2c4a580a95d","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/01_kubernetes_build/Pod_communication1.JPG","hash":"86306c989ea829a4088c2f63a486dcdea28fbc5d","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/01_kubernetes_build/Pod_communication2.JPG","hash":"b62699e73410016a17146c2fd721fd108247fb86","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/01_kubernetes_build/Pod_communication3.JPG","hash":"92e44ea22d8cbfc702fe8a0344c3c3ca748889e3","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/01_kubernetes_build/Rolling_update1.JPG","hash":"4b7425067eb7677985de84798443612c16aedafe","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/01_kubernetes_build/Symmetric_encryption.JPG","hash":"59e70ebb4fd57b9129c9878c7d12ab18e8bb5557","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/01_kubernetes_build/Rolling_update2.JPG","hash":"105bee998aba4ed36bb32927fedc95dd2f6528f9","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/01_kubernetes_build/k8s_architecture1.JPG","hash":"bf2b5b98f6069c7c1e0188c131d08853501141dd","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/DNS.gif","hash":"462ddef9ffd6aeeb9c0a6f5a8b1343ab8f364dde","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/HTTPMsgStructure2.png","hash":"e82dd65dbc7cb7455d761929a2b737a863ddb85f","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/client-server.png","hash":"1784f380b6168214bf708396901cf696fdf5f539","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/css_parser.png","hash":"b177e2518be5b4a7738da741af735999ccc4a0d3","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/dom.png","hash":"f7c93eea10f05934d7e39813fbf76f9bee19d8f5","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/flow.png","hash":"4165c41f2799daccc0cdbba92f0bbaf78ed4257f","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/gecko.jpg","hash":"0ef7b807fd5d5d40f4d65e94de7ff8a4d9da1a8e","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/handshake.png","hash":"b9adab50b95796ce8791dcb8df3807f83fb2e6e1","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/node-modules.png","hash":"823d3b93cf754199cfdfcda056ec8fa6a7d5167d","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/nodeWeb.png","hash":"a6c15a0cd524b81c823f58ebd30f66adb507b133","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/sublimeconf22.png","hash":"82748e9d8a0ee25f3e50b3db20cc4b6799edefd4","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/taobao_ip.png","hash":"2487d4e2f9d411fd93e4249e15e0758ce39fdccd","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/taobao_url.png","hash":"00a5ae643c83abe98397f3993558ec5cc81a237c","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/webkitflow.png","hash":"675c0ef1c3cd0de8e7dced027cd751b5013520dc","modified":1597340831186},{"_id":"public/2020/08/13/technologies/web/HTML/6.PNG","hash":"062798980be3891b4e05311bbeb86229f97e36c6","modified":1597340831186},{"_id":"public/2020/08/13/windows/Windows10_VScode远程连接linux编辑调试/1.png","hash":"dd15f2eb99cf23bd7e17f90b249067eb76851c1a","modified":1597340831186},{"_id":"public/2020/08/13/windows/Windows10_VScode远程连接linux编辑调试/2.png","hash":"6d4b284081489534d6e1bae1f25e42777266fa91","modified":1597340831186},{"_id":"public/2020/08/13/windows/Windows10_VScode远程连接linux编辑调试/3.png","hash":"34bbe99b72a3545accdc6fa85b1ef0fa86ad2694","modified":1597340831186},{"_id":"public/2020/08/13/windows/Windows10_VScode远程连接linux编辑调试/4.png","hash":"773007d58d12bd3b9702750048b19ae123a9d20a","modified":1597340831186},{"_id":"public/2020/08/13/windows/Windows10_VScode远程连接linux编辑调试/5.png","hash":"f7cf4c81c89048f43c69070b2e217577bd04e4fc","modified":1597340831186},{"_id":"public/2020/08/13/windows/Windows10_VScode远程连接linux编辑调试/6.png","hash":"685a4a2eeb07f47a8d0a9e7210b4d8b595607116","modified":1597340831186},{"_id":"public/2020/08/13/windows/Windows10_VScode远程连接linux编辑调试/7.png","hash":"d0b2d40e5c4fd717e7f9172b6b49b23a0a7fc3ff","modified":1597340831186},{"_id":"public/2020/08/13/language/python/linux_install_python_pip_pipenv/pipfile.JPG","hash":"6e04b251b84050d62f7ac7081862a6843c6cfcd1","modified":1597340831186},{"_id":"public/2020/08/13/technologies/web/JavaScript/pic.JPG","hash":"dee2336070aed563aa462e0196cf3a1203e69055","modified":1597340831186},{"_id":"public/2020/08/13/technologies/maven/maven_project/compile.JPG","hash":"e05a60e2824ca55d265619da2f58cc15f902784e","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/pki/pki_mode.png","hash":"e9071b8c7aafb73fadfe2d646df893fd40ead775","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/tls_ssl_https_http_protocol/osi.png","hash":"558db12914e093c78dbda439ade2fe44aaf29360","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/tls_ssl_https_http_protocol/https.png","hash":"bbf47e3860a3af9482bef3406215453864acbd2f","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/tls_ssl_https_http_protocol/tcp_ip.png","hash":"486f6d7c5b1b5f4db4fb350ff3c8430f0ac65d23","modified":1597340831186},{"_id":"public/2020/08/13/technologies/web/HTML/1.PNG","hash":"3ad78055f9bce980f860596414e04ef81ce61580","modified":1597340831186},{"_id":"public/2020/08/13/technologies/web/HTML/12.PNG","hash":"9821d9e5a1ef0daea47a26b14da93fc688cd9463","modified":1597340831186},{"_id":"public/2020/08/13/technologies/web/HTML/2.PNG","hash":"723182d00d1760eb8406b595d13eaad1833deab6","modified":1597340831186},{"_id":"public/2020/08/13/technologies/web/HTML/3.PNG","hash":"f22fb4c2414b13dad95350c4215923116d4281e9","modified":1597340831186},{"_id":"public/2020/08/13/technologies/web/HTML/4.PNG","hash":"fc1c5ed205c2abbebb0d04681620ea4e4566b772","modified":1597340831186},{"_id":"public/2020/08/13/technologies/web/HTML/5.PNG","hash":"48c37c2fd3408a21692310f6a9c7aa7982d409fe","modified":1597340831186},{"_id":"public/2020/08/13/technologies/web/HTML/6_1.PNG","hash":"616527c38d95543ca94834fd7f21a3445610db01","modified":1597340831186},{"_id":"public/2020/08/13/technologies/web/HTML/7.PNG","hash":"f1e1929c3c1bb4a07317629cf948172456eefa10","modified":1597340831186},{"_id":"public/2020/08/13/technologies/web/HTML/table_td_empty.gif","hash":"9692bbee25004a322dd84a8e9ea294c9a2cbec14","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/key_digest_signature_certificates/1.png","hash":"535193d7d60ea1cf5c97ff9fd02d658d28fba8f4","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/key_digest_signature_certificates/10.png","hash":"14fa5983d84240c8ca7790a48d1ff059b4ce8b2d","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/key_digest_signature_certificates/11.png","hash":"9bd4e17909bec0d308231044a9e531c79f6fbfbb","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/key_digest_signature_certificates/12.png","hash":"2de64b342229deea86b03cbd5f24d663ae66edd0","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/key_digest_signature_certificates/13.png","hash":"1677b154e7a8c4cd234238224401c009dd48dc25","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/key_digest_signature_certificates/14.jpg","hash":"4bea863fd41d9153397ac7e50b200fab0404401e","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/key_digest_signature_certificates/15.png","hash":"e3f44cc0d5e0ee4e2bc7990fa0f07ac6f83553ab","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/key_digest_signature_certificates/16.png","hash":"da3b727d63ebaec0f0ed01acc0410cf1be720bf3","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/key_digest_signature_certificates/17.png","hash":"423b4de305b1b0d53ec12fe6f69ef7d816b87133","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/key_digest_signature_certificates/2.png","hash":"cd986c08eace5ab07427ed7f2ea41af42d1b9d97","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/key_digest_signature_certificates/19.jpg","hash":"307a478c4b3474f76661fe8e6f4ad66f9ca9ece4","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/key_digest_signature_certificates/18.png","hash":"a39cffaa883843a6a6ebf15e89d0df03e5b4e0cc","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/key_digest_signature_certificates/20.png","hash":"f53087c20bb08712d5df19580d050215c27c70b5","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/key_digest_signature_certificates/3.png","hash":"d7c9b6b6e8d3dfb5aa65e3d7a9b0cb4e90b9b95c","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/key_digest_signature_certificates/4.png","hash":"79f02a125a88f2541db37a63a78117bc2cf9ebb9","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/key_digest_signature_certificates/5.png","hash":"090ca17bc561e623cc027980dec6e3cf93e36ed5","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/key_digest_signature_certificates/6.png","hash":"afe28458e9c0118cbc6f080781140a9b0ba6030a","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/key_digest_signature_certificates/7.png","hash":"08a716426e70fd0da66b3a6050ba38c5077652af","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/key_digest_signature_certificates/8.png","hash":"1d5b40149630905b3440d23b918f6458fb412cd0","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/key_digest_signature_certificates/9.png","hash":"d303be13e76faf1913b4ba1dab8dd53bcf78dae2","modified":1597340831186},{"_id":"public/img/alipay.jpg","hash":"92f3232ad812ed9e796ddbbdb057f23edeed28ed","modified":1597340831186},{"_id":"public/img/weixin.jpg","hash":"ac3de5dbab14549cd64d3f43769bef9004291526","modified":1597340831186},{"_id":"public/2020/08/13/blogs/HTTP_TCP_Socket/ISO-TCP.IP.png","hash":"1511b62201cb7168f073f0ccbe1daf5a71c19138","modified":1597340831186},{"_id":"public/2020/08/13/blogs/Hexo_01_部署github_blog/registry_gitalk.PNG","hash":"856740f2c5d2aaf83cc27aa6979b206cc4cfd1b3","modified":1597340831186},{"_id":"public/2020/08/13/technologies/maven/maven_project/jar.JPG","hash":"cd696f9fce0abcbb596d4c58e78895ac1f06528d","modified":1597340831186},{"_id":"public/2020/08/13/blogs/Restful_API/Restful.png","hash":"fe71f887a0059c0b9b107266bf36bb5a373f4276","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/05_kubernetes_volume/PV_PVC.PNG","hash":"b3d4198aad959dcc32c6de276ba16c10ea5c8078","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/07_kubernetes_Etcd/etcd_3.PNG","hash":"5ec9c0a1524d65f2711511069d8336a5d80792ae","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/4.node_modules/taobao_mirror.PNG","hash":"a725107bff1e952029f75ef7fd640873f38fa307","modified":1597340831186},{"_id":"public/2020/08/13/linux/Linux_kernel_userspace体系结构/linux_kernel.jpg","hash":"c461a2df4d5520cd63358296620a043a38c50575","modified":1597340831186},{"_id":"public/2020/08/13/linux/ssh端口映射/local_port_transmit1.png","hash":"f39f6ac26a3a3e6fef98c70881c0f621cfad1216","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/istio_01_conception/Pilot_Architecture.png","hash":"e50e0aed665a181d2a0dc3b4350c79e9969b25cc","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/istio_01_conception/envoy_xds.png","hash":"ed49164a15c09d3019d5bd0749fdb8b47fb5bddc","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/istio_01_conception/istio_arch.jpeg","hash":"6fe64e3ed3e1cf69c3afb2e1f2897684502af734","modified":1597340831186},{"_id":"public/2020/08/13/linux/linux制作U盘启动盘/fdisk.png","hash":"29e367da801dec3f6975d10c8aae9d7b18e11fc7","modified":1597340831186},{"_id":"public/2020/08/13/linux/sda_hda/power_data_interface.png","hash":"e2247a7e6780a10f0339ebc235f0866c4dd6d597","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/istio_03_configuration/security_policy.PNG","hash":"3d3e283582fefd864e0d031822a7fd3f124f1190","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/1.webstorm自动提示设置/1.png","hash":"0848ccafcee74e678276c5fdb1464e0ac3e0e25f","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/1.webstorm自动提示设置/3.png","hash":"8ee6e75907ac28feea60f0cf42b90fb43a5c0a63","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/1.webstorm自动提示设置/4.png","hash":"e834744d98be4e58dede9ec3aeb6fee8f03cde4f","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/1.webstorm自动提示设置/5.png","hash":"0e562184cd74722a234db4060c0c7ecbf94963ef","modified":1597340831186},{"_id":"public/2020/08/13/linux/CPU角度理解PCIE/picture12.jpg","hash":"bf958f317625fc01799cb7a283ac6adb59956d90","modified":1597340831186},{"_id":"public/2020/08/13/linux/CPU角度理解PCIE/picture3.jpg","hash":"54e86f39193f2b92ce2af2c0f8419436240c7085","modified":1597340831186},{"_id":"public/2020/08/13/linux/CPU角度理解PCIE/picture5.jpg","hash":"b1b103dd758ae4df0cd064659a7d43559e1952e9","modified":1597340831186},{"_id":"public/2020/08/13/linux/CPU角度理解PCIE/picture7.jpg","hash":"322ac2dafaffc8c283d7e9140280f45421efb5ca","modified":1597340831186},{"_id":"public/2020/08/13/linux/CPU角度理解PCIE/picture8.jpg","hash":"aea8e0c4f3e439aa8946512e16f51f065efe464d","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/01_kubernetes_build/2.JPG","hash":"ca9354ab691edf10832976afb9c3f0a55e56f837","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/01_kubernetes_build/4.JPG","hash":"f82a79ce1470ca3575c3beef250d8103a9ed93d5","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/01_kubernetes_build/5.JPG","hash":"1e54fc6049a5cccfb0ca3395d8df528836149ccb","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/01_kubernetes_build/K8s_arch4.JPG","hash":"0974d9a80991964c3ac4595f269a1e726b627765","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/01_kubernetes_build/k8s_architecture2.JPG","hash":"f8b04ee63df04a0764756e4ffcca4c034e5120ed","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/pki/tls_deployment.jpg","hash":"d3183fa5d61915553bd04b1a0feaa59e391397e9","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/Web.png","hash":"0de98a3c9390e882f788c597f297402f3603cca6","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/chrome_rendering1.png","hash":"771fe609cf4384ad2c8cc8dea3f23a34d6af3527","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/chrome_rendering2.png","hash":"3804da167147d183c95833ef39a1584a47d2d508","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/http-header.png","hash":"8d858bcbea613ad69e401d43c3708a38b973a7e1","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/npm1.png","hash":"1b6732f7e40e6a5a9bdfc477e2631ac61f947e1b","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/sublimeconf1.png","hash":"7a0d8d065e530cd1a5f815946473bafd25247e04","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/token_jwt/token_scene1.png","hash":"a5a2e7824e9a6ef694bf58d3d5e203b47d9c227f","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/key_digest_signature_certificates/0.PNG","hash":"a5b11e40d94e564c74f275e0b2637de6df15040c","modified":1597340831186},{"_id":"public/css/mobile.css","hash":"5998f6fc27998596beb1e40e4bc3c43be2ed764c","modified":1597340831186},{"_id":"public/js/titleTip.js","hash":"81dca549063e29ba3a4a278f0f4388eba8a2167b","modified":1597340831186},{"_id":"public/js/search.js","hash":"c80c9a231ee040c7adc07a477793873fb85ce8bc","modified":1597340831186},{"_id":"public/css/hl_theme/atom-dark.css","hash":"88d11052a24e8100af6248eb4dbe1ce7b0e96408","modified":1597340831186},{"_id":"public/css/hl_theme/atom-light.css","hash":"d31edb9816dae6b01410028bceb91757a962f780","modified":1597340831186},{"_id":"public/css/hl_theme/brown-paper.css","hash":"500c8e750373f6656ff49a7857c871ceedcf8777","modified":1597340831186},{"_id":"public/css/hl_theme/darcula.css","hash":"4341074bae4bc9f0b86e32b623e27babc0159b6e","modified":1597340831186},{"_id":"public/css/hl_theme/github-gist.css","hash":"7a41c1c479d09df875f99f1f6d94aac42e9e2ad0","modified":1597340831186},{"_id":"public/css/hl_theme/github.css","hash":"e05a0806a508a26b9f3f3794b6b588ec6504ad3f","modified":1597340831186},{"_id":"public/css/hl_theme/gruvbox-dark.css","hash":"8c440d9b4ee19ac03eaee3c6af78ba52e5ba5535","modified":1597340831186},{"_id":"public/css/hl_theme/kimbie-dark.css","hash":"728527fcc308da454722c119b89e6da3025bd1e3","modified":1597340831186},{"_id":"public/css/hl_theme/gruvbox-light.css","hash":"30514aaa242a34647aa666cfca4fc74c595ea8f2","modified":1597340831186},{"_id":"public/css/hl_theme/kimbie-light.css","hash":"0c61926c989163faefb031d27bce3e287d6e10f2","modified":1597340831186},{"_id":"public/css/hl_theme/rainbow.css","hash":"7ff4251938076ddb7e4e49413db82653e5b61321","modified":1597340831186},{"_id":"public/css/hl_theme/railscasts.css","hash":"511f2fd2a84d426e5da5cb17880cc08f73beb002","modified":1597340831186},{"_id":"public/css/hl_theme/sublime.css","hash":"f65c5b116d9213afb9c324384a2f3bc86cb71121","modified":1597340831186},{"_id":"public/css/hl_theme/school-book.css","hash":"ffbbcd13a74ac2404262c50b7a43053dfd0096ff","modified":1597340831186},{"_id":"public/css/hl_theme/sunburst.css","hash":"8a135abac1512cf430d1d1ad2304b79afa1a4d6e","modified":1597340831186},{"_id":"public/css/hl_theme/zenbum.css","hash":"0a78f74a93568e20b32ca7427c719e9bae9a0b55","modified":1597340831186},{"_id":"public/css/style.css","hash":"2dc2f3d794d4102d3ce4c807d41903277e4585e7","modified":1597340831186},{"_id":"public/css/gitalk.css","hash":"58177ce227c50ee359fbf99a4fdd26058887afc5","modified":1597340831186},{"_id":"public/js/iconfont.js","hash":"3a0869ca1b09af07d82987e343a3bc4cb9558ecb","modified":1597340831186},{"_id":"public/js/jquery.pjax.js","hash":"191c49fdb40dff115a49cfd2b30dffb888d86550","modified":1597340831186},{"_id":"public/js/script.js","hash":"03fc06177b47fd6bac7ae393f9712c726272467b","modified":1597340831186},{"_id":"public/css/fonts/selection.json","hash":"047b615ea32dc48dae5b964061427d41feaaafdf","modified":1597340831186},{"_id":"public/js/gitment.js","hash":"59a1e03f2b0ce61dd9bd405d3c52d3e07cc10dec","modified":1597340831186},{"_id":"public/2020/08/13/deeplearning/deeplearning_01_get_started/01.PNG","hash":"dae96c50a20774dc9f742afee1e67f623ede106a","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/services_analysis/architecture.png","hash":"83855ba6cf45dcae2d6ee17c8e43ab420e226d25","modified":1597340831186},{"_id":"public/2020/08/13/linux/按字节-字寻址_字长_地址总线_数据总线关系/address.png","hash":"421b58e086b755f6cd1cdd341c1212b42bd21add","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/env_path.png","hash":"2c1368b17a1447d8fc018a259a2280f63a9e9ba9","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/htmlFormEl.png","hash":"5052dd3771752c0923fef6a80afd809349fab151","modified":1597340831186},{"_id":"public/2020/08/13/technologies/docker/dockerfile/01.png","hash":"ace5e9b1f35f4277568176f2c4196c2bb2a74f50","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/tls_ssl_https_http_protocol/http_tls_ssl.png","hash":"b6fa4f1d8bced00f0b04f18be3cd1f10864d6c0b","modified":1597340831186},{"_id":"public/js/gitalk.js","hash":"a75ead28e6a1fab2a006cc7332ca2d2e868ce8e1","modified":1597340831186},{"_id":"public/2020/08/13/linux/CPU角度理解PCIE/picture10.jpg","hash":"f677a9134b896c147af9e3bfc99f95801a400391","modified":1597340831186},{"_id":"public/2020/08/13/deeplearning/deeplearning_01_get_started/02.PNG","hash":"988c1e6c0c84ca30840cd41dcdd36f5c8796701c","modified":1597340831186},{"_id":"public/2020/08/13/linux/sda_hda/IDE_power_sata.png","hash":"472701f7095ef418fc1b33480ef33ebf54fb4f79","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/09_kubernetes_certificate/k8s_certificates.PNG","hash":"521ba7cdd0d4eb3844a5534a5ee11027d494b9e4","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/sublimeconf21.png","hash":"4fad8d85d0b884279c1d1475a9ebfa3aaa750dfd","modified":1597340831186},{"_id":"public/2020/08/13/linux/sda_hda/IDE_interface.png","hash":"988dda3cf0240dbacc71736b899e737e093173c5","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/pki/key_save.png","hash":"28f8947dde55d003a28fff2bc3594ba587d8c2bb","modified":1597340831186},{"_id":"public/2020/08/13/deeplearning/deeplearning_01_get_started/07.PNG","hash":"f7193b55d85d1b5208cce3a02f19db7abcc53a16","modified":1597340831186},{"_id":"public/2020/08/13/linux/sda_hda/sda_interface.png","hash":"7bf33b16c821b6a1b6cb073d220f699699fa5e07","modified":1597340831186},{"_id":"public/2020/08/13/blogs/HTTP_TCP_Socket/ISO.png","hash":"bf419d02ba64f2e62255316851593c31464c552c","modified":1597340831186},{"_id":"public/2020/08/13/micro_service/09_kubernetes_certificate/CA_simulate.PNG","hash":"5a5b353b5cdbaae68b8df1727107638498a05aa3","modified":1597340831186},{"_id":"public/2020/08/13/deeplearning/deeplearning_01_get_started/06.PNG","hash":"cad973215231d6f32e5edb46b054f9cc34c0c444","modified":1597340831186},{"_id":"public/2020/08/13/technologies/security/pki/base_encryption.png","hash":"c8c8327bfad3d73cfae7a468d00315466633b1f2","modified":1597340831186},{"_id":"public/2020/08/13/deeplearning/deeplearning_01_get_started/08.PNG","hash":"784585bf4cf332e5d10b7c4723de1c00c3739cff","modified":1597340831186},{"_id":"public/2020/08/13/deeplearning/deeplearning_01_get_started/05.PNG","hash":"258f1255e9c0cfabcaa9701dd2ffcab1d0b6253a","modified":1597340831186},{"_id":"public/2020/08/13/blogs/HTTP_TCP_Socket/tcp-ip-handshark.png","hash":"47db48d5734839580ffd53dc793e89711f4cef17","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/npm.png","hash":"eaaca8f9567e6216557789f286da08b7d20a44a1","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/51jobnode.png","hash":"a6bd6a6ac7561349bfbf8f60857f7a228fbc87c9","modified":1597340831186},{"_id":"public/2020/08/13/technologies/docker/dockerfile/02.png","hash":"11b3a665b93035cd672e1075cc2c51dd7653c01e","modified":1597340831186},{"_id":"public/2020/08/13/nodejs/浏览器工作原理/fiddlersetup.exe","hash":"98454635315e6940da83d39f8590c4ca82009e47","modified":1597340831186},{"_id":"source/_posts/micro_service/istio_03_configuration_dashboard.md","hash":"018bd6af6b351135a125041cd62a58d68dc3fd79","modified":1597669944558},{"_id":"source/_posts/micro_service/istio_03_configuration_dashboard/istio_arch_20.JPG","hash":"30ea66371d496fb3fd64407e001fe52e4713e3f9","modified":1587376056000},{"_id":"source/_posts/micro_service/istio_03_configuration_dashboard/istio_arch_19.JPG","hash":"527c4645ed73e59467e42fea4b9b9ed1e308fc9a","modified":1587376000000},{"_id":"source/_posts/micro_service/istio_03_configuration_dashboard/traffic_control.PNG","hash":"0af77b9d7ed7e5aabecd0150e3ef95754ad91302","modified":1596548357812},{"_id":"source/_posts/micro_service/istio_03_configuration_dashboard/security_policy.PNG","hash":"3d3e283582fefd864e0d031822a7fd3f124f1190","modified":1596559683515},{"_id":"public/2020/08/13/micro_service/istio_03_configuration_dashboard/index.html","hash":"21ad0a1b30f23d8b5a23476a921eb76b5eb9db6d","modified":1597670500920},{"_id":"public/2020/08/13/micro_service/istio_03_configuration_dashboard/istio_arch_20.JPG","hash":"30ea66371d496fb3fd64407e001fe52e4713e3f9","modified":1597559713838},{"_id":"public/2020/08/13/micro_service/istio_03_configuration_dashboard/istio_arch_19.JPG","hash":"527c4645ed73e59467e42fea4b9b9ed1e308fc9a","modified":1597559713838},{"_id":"public/2020/08/13/micro_service/istio_03_configuration_dashboard/traffic_control.PNG","hash":"0af77b9d7ed7e5aabecd0150e3ef95754ad91302","modified":1597559713838},{"_id":"public/2020/08/13/micro_service/istio_03_configuration_dashboard/security_policy.PNG","hash":"3d3e283582fefd864e0d031822a7fd3f124f1190","modified":1597559713838},{"_id":"source/_posts/micro_service/istio_03_configuration_dashboard/kiali_1.PNG","hash":"6aed2815225397b1b7e18cf757ec6a0725b3276e","modified":1597668766830},{"_id":"public/2020/08/13/micro_service/istio_03_configuration_dashboard/kiali_1.PNG","hash":"6aed2815225397b1b7e18cf757ec6a0725b3276e","modified":1597669794913}],"Category":[{"name":"Englisth","_id":"ckdt3hmbl0003hohx2hea8acf"},{"name":"blogs","_id":"ckdt3hmbp0007hohx0y5g3nd5"},{"name":"5500","parent":"ckdt3hmbl0003hohx2hea8acf","_id":"ckdt3hmc8000jhohxfcilaxte"},{"name":"LearnLinks","_id":"ckdt3hmcj000shohx45ow3c3i"},{"name":"deeplearning","_id":"ckdt3hmcp000yhohx1gvk1di0"},{"name":"linux","_id":"ckdt3hmcy0013hohx7rbo61gb"},{"name":"microService","_id":"ckdt3hmg40045hohxek716bww"},{"name":"kubernetes","parent":"ckdt3hmg40045hohxek716bww","_id":"ckdt3hmgc004shohx1k011z08"},{"name":"istio","parent":"ckdt3hmg40045hohxek716bww","_id":"ckdt3hmgz006hhohx9awndt37"},{"name":"REST-API","parent":"ckdt3hmg40045hohxek716bww","_id":"ckdt3hmh60077hohx056b3qn9"},{"name":"nodejs","_id":"ckdt3hmh6007bhohxb1iy7qre"},{"name":"storage","_id":"ckdt3hmha007whohx5u5z4fh4"},{"name":"technologies","_id":"ckdt3hmhe0088hohxf9ld66ze"},{"name":"windows","_id":"ckdt3hmhf008chohxf4nj8et7"},{"name":"language","_id":"ckdt3hml3008khohx7oejc87p"},{"name":"docker","parent":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmm8008rhohxhz764dlo"},{"name":"python","parent":"ckdt3hml3008khohx7oejc87p","_id":"ckdt3hmmw008uhohx8ipi1kxi"},{"name":"go","parent":"ckdt3hml3008khohx7oejc87p","_id":"ckdt3hmnr008yhohx3n388q20"},{"name":"maven","parent":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmoh0098hohx4t1ag7o3"},{"name":"c","parent":"ckdt3hml3008khohx7oejc87p","_id":"ckdt3hmoj009ihohx8e0k07dv"},{"name":"security","parent":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmop00a7hohxgc2bd91j"},{"name":"web前端","parent":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmot00ashohxbg9y9x86"}],"Data":[],"Page":[],"Post":[{"title":"Hello World","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","slug":"hello-world","published":1,"date":"2020-08-12T16:05:44.355Z","updated":"2020-02-13T12:47:44.230Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hm9w0000hohxhykg921v","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n"},{"title":"Unit 1","_content":"\n### abandon ~ abolish  \n\n2. abandon 放弃  \na = at; bandon = ban 禁令。 处于禁令之中->放弃自身权利 \n392. ban 取缔， 查禁    \n394. band 捆绑，乐队(乐队队员都绑着同样的袋子) n.波段，一群，疑惑，v.束缚，绑扎  \n489. bind 捆， 绑， 包括， 束缚  过去分词->bound  与下面词是异源同形词  \n555. bound adj.被束缚的, 一定的 n. 界限 v.&跳(跃)  \n554. bounce n.&vi. 弹起, 弹回，跳起； n. 弹力  \n556. boundary n.分界线, 边界  ary -> 形容词or名词后缀  \n395. bandage n.绷带 v. 用绷带扎缚  \n2396. husband n.丈夫  （hus==house：与房子绑定的人 ==hut） \n464. bend v.弯曲; 屈从，屈服；n. 弯曲(处)  \n536. bond n.结合，粘结； 公债，债券； 契约  \n\n","source":"_posts/Englist_Learn/Englisth1.md","raw":"---\ntitle: Unit 1\ntags: \ncategories:\n- Englisth\n- 5500\n---\n\n### abandon ~ abolish  \n\n2. abandon 放弃  \na = at; bandon = ban 禁令。 处于禁令之中->放弃自身权利 \n392. ban 取缔， 查禁    \n394. band 捆绑，乐队(乐队队员都绑着同样的袋子) n.波段，一群，疑惑，v.束缚，绑扎  \n489. bind 捆， 绑， 包括， 束缚  过去分词->bound  与下面词是异源同形词  \n555. bound adj.被束缚的, 一定的 n. 界限 v.&跳(跃)  \n554. bounce n.&vi. 弹起, 弹回，跳起； n. 弹力  \n556. boundary n.分界线, 边界  ary -> 形容词or名词后缀  \n395. bandage n.绷带 v. 用绷带扎缚  \n2396. husband n.丈夫  （hus==house：与房子绑定的人 ==hut） \n464. bend v.弯曲; 屈从，屈服；n. 弯曲(处)  \n536. bond n.结合，粘结； 公债，债券； 契约  \n\n","slug":"Englist_Learn/Englisth1","published":1,"date":"2020-08-12T16:05:45.308Z","updated":"2020-04-06T12:09:13.377Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmbi0001hohx5pfl1irl","content":"<h3 id=\"abandon-abolish\"><a href=\"#abandon-abolish\" class=\"headerlink\" title=\"abandon ~ abolish\"></a>abandon ~ abolish</h3><ol start=\"2\">\n<li>abandon 放弃<br>a = at; bandon = ban 禁令。 处于禁令之中-&gt;放弃自身权利 </li>\n<li>ban 取缔， 查禁    </li>\n<li>band 捆绑，乐队(乐队队员都绑着同样的袋子) n.波段，一群，疑惑，v.束缚，绑扎  </li>\n<li>bind 捆， 绑， 包括， 束缚  过去分词-&gt;bound  与下面词是异源同形词  </li>\n<li>bound adj.被束缚的, 一定的 n. 界限 v.&amp;跳(跃)  </li>\n<li>bounce n.&amp;vi. 弹起, 弹回，跳起； n. 弹力  </li>\n<li>boundary n.分界线, 边界  ary -&gt; 形容词or名词后缀  </li>\n<li>bandage n.绷带 v. 用绷带扎缚  </li>\n<li>husband n.丈夫  （hus==house：与房子绑定的人 ==hut） </li>\n<li>bend v.弯曲; 屈从，屈服；n. 弯曲(处)  </li>\n<li>bond n.结合，粘结； 公债，债券； 契约  </li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"abandon-abolish\"><a href=\"#abandon-abolish\" class=\"headerlink\" title=\"abandon ~ abolish\"></a>abandon ~ abolish</h3><ol start=\"2\">\n<li>abandon 放弃<br>a = at; bandon = ban 禁令。 处于禁令之中-&gt;放弃自身权利 </li>\n<li>ban 取缔， 查禁    </li>\n<li>band 捆绑，乐队(乐队队员都绑着同样的袋子) n.波段，一群，疑惑，v.束缚，绑扎  </li>\n<li>bind 捆， 绑， 包括， 束缚  过去分词-&gt;bound  与下面词是异源同形词  </li>\n<li>bound adj.被束缚的, 一定的 n. 界限 v.&amp;跳(跃)  </li>\n<li>bounce n.&amp;vi. 弹起, 弹回，跳起； n. 弹力  </li>\n<li>boundary n.分界线, 边界  ary -&gt; 形容词or名词后缀  </li>\n<li>bandage n.绷带 v. 用绷带扎缚  </li>\n<li>husband n.丈夫  （hus==house：与房子绑定的人 ==hut） </li>\n<li>bend v.弯曲; 屈从，屈服；n. 弯曲(处)  </li>\n<li>bond n.结合，粘结； 公债，债券； 契约  </li>\n</ol>\n"},{"title":"HTTP, TCP, Socket","_content":"\n## iso七层模型\n有应用层 表示层 会话层 传输层 网络层 数据链路层 物理层,其中http就属于应用层,tcp与udp是属于传输层\n![](ISO.png)\n![](ISO-TCP.IP.png)\n> 实体层：连接网络的硬件设备，就是将电脑连接起来的物理手段. 如光缆/电缆/无线电波\n> 数据链路层 (Link)：建立逻辑连接、进行硬件地址寻址、差错校验等功能，如32位和64位计算机，他们的解码方式是不一样的，数据链路层就规定个二进制数据的解读方式。\n> 网络层 (Network)：进行逻辑地址寻址，实现不同网络之间的路径选择。网络层建立了主机之间的通信，它在网络层引入了一套地址机制:网络地址.简称网址（Ip地址），我们可以通过Ip地址,可以找到唯一的一台计算机，通过主机MAC地址来接收和发送信息.\n> 传输层 (Transport)：定义传输数据的协议端口号，以及流控和差错效验，定义了端口和端口之间的通信，帮助我们使不同的应用程序能够接收到自己所需要的的数据。\n> 会话层 (Session Layer)：包括建立、管理、终止会话，用来建立和管理应用程序之间的通信，实现自动寻址，自动收发数据。\n> 表示层 (Presentation Layer)：数据的表示、安全、压缩。比如我们要用基于Unix系统的mac电脑给pc机发送数据，表示层为我们解决了通信间语法的问题。\n> 应用层 (Application)：网络服务与最终用户的一个接口。比如不同的文件类型要用不同的应用程序打开，应用层中就规定了不同应用程序的数据格式.\n\n### http和tcp的联系\n> * http是基于tcp，就相当于生活中的吃饭时候你都会用到碗，这个碗就是tcp，吃饭这件事情就相当于http，因为我们http发送数据之前，会先进行tcp三次握手，记住这时候只是发送一些状态码的确认等，并没有对http的数据进行发送。\n\n> * http长连接和短连接，其实就是tcp长连接与短连接，在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，请求结束就中断连接，HTTP1.1就使用长连接，\n用长连接的HTTP协议，会在响应头加入这行代码：\n\n\n\t Connection:keep-alive\n使用长连接每次打开一个网页除了第一次需要三次握手连接，接下来请求服务器就不用再握手了，就一直使用这个连接，这个keep-alive不会永久保持，这个可以在服务器端设置\n\n> * 长连接和短连接简短概括\n短连接就相当于每次一碗饭就去换一个碗，长连接就是每次吃饭都使用这个碗\n\n### tcp和udp的区别\n> tcp是面向连接的，udp不是面向连接的，怎么说呢？就相当于我们生活中打电话或者微信聊天，要先嘟嘟嘟连接，之后才可以打电话聊天，这个就是面向连接的，也是比较可靠的，udp是不用先去做连接的，所以叫做面向非连接，类似生活中发短信，直接发送过去\n\n有人会问了，为什么http是基于tcp而不是udp呢？\n这个tcp协议比较可靠，不过，目前，有人正在研究基于TCP+UDP混合的HTTP协议。\n\n![](socket.jpg)\n\n### IP：\n网络层协议；（高速公路）\n为计算机网络相互连接进行通信而设计的协议。\n> IP协议对应于网络层，TCP协议对应于传输层，而HTTP协议对应于应用层。注意TPC/IP位于传输层，它主要用来解决数据如何在网络中传输，与IP协议要区分开\n\n### TCP和UDP：\n传输层协议；（卡车）\n> TCP和UDP使用IP协议从一个网络传送数据包到另一个网络。把IP想像成一种高速公路，它允许其它协议在上面行驶并找到到其它电脑的出口。TCP和UDP是高速公路上的“卡车”，它们携带的货物就是像HTTP，文件传输协议FTP这样的协议等。\n\n### HTTP：\n> 应用层协议；（货物）。HTTP(超文本传输协议)是利用TCP在两台电脑(通常是Web服务器和客户端)之间传输信息的协议。客户端使用Web浏览器发起HTTP请求给Web服务器，Web服务器发送被请求的信息给客户端。\nHTTP是应用层协议，主要用于包装数据\n\n### SOCKET：\n> 套接字，TCP/IP网络的API。(港口码头/车站)Socket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。socket是在应用层和传输层之间的一个抽象层，它把TCP/IP层复杂的操作抽象为几个简单的接口供应用层调用已实现进程在网络中通信。\nSocket相当于调用接口(API)，用来调取TCP/IP协议, Socket接口定义了许多函数或例程，用以开发TCP/IP网络上的应用程序。\n\n### TCP/IP：\n> 代表传输控制协议/网际协议，指的是一系列协议，TCP/IP 模型在 OSI 模型的基础上进行了简化，变成了四层，从下到上分别为：网络接口层、网络层、传输层、应用层。\n\n###TCP/UDP区别\n> TCP: （传输控制协议，Transmission Control Protocol）：(类似打电话) 面向连接、传输可靠（保证数据正确性）、有序（保证数据顺序）、传输大量数据（流模式）、速度慢、对系统资源的要求多，程序结构较复杂，每一条TCP连接只能是点到点的，TCP首部开销20字节。\n\n> UDP: (用户数据报协议，User Data Protocol)：（类似发短信） 面向非连接 、传输不可靠（可能丢包）、无序、传输少量数据（数据报模式）、速度快，对系统资源的要求少，程序结构较简单 ，UDP支持一对一，一对多，多对一和多对多的交互通信，UDP的首部开销小，只有8个字节。\n\n### tcp三次握手建立连接\n![](tcp-ip-handshark.png)\n> 第一次握手：客户端发送syn包(seq=x)到服务器，并进入SYN_SEND状态，等待服务器确认；\n> 第二次握手：服务器收到syn包，必须确认客户的SYN（ack=x+1），同时自己也发送一个SYN包（seq=y），即SYN+ACK包，此时服务器进入SYN_RECV状态；\n> 第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=y+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。\n握手过程中传送的包里不包含数据，三次握手完毕后，客户端与服务器才正式开始传送数据。理想状态下，TCP连接一旦建立，在通信双方中的任何一方主动关闭连接之前，TCP 连接都将被一直保持下去。\n主机A向主机B发出连接请求数据包：“我想给你发数据，可以吗？”，这是第一次对话；\n主机B向主机A发送同意连接和要求同步（同步就是两台主机一个在发送，一个在接收，协调工作）的数据包：“可以，你什么时候发？”，这是第二次对话；\n主机A再发出一个数据包确认主机B的要求同步：“我现在就发，你接着吧！”，这是第三次对话。\n三次“对话”的目的是使数据包的发送和接收同步，经过三次“对话”之后，主机A才向主机B正式发送数据。\n\n### Websocket\nWebsocket协议解决了服务器与客户端全双工通信的问题。\n\n注:什么是单工、半双工、全工通信？\n信息只能单向传送为单工；\n信息能双向传送但不能同时双向传送称为半双工；\n信息能够同时双向传送则称为全双工。\n\n### WebSocket和Socket区别\n可以把WebSocket想象成HTTP(应用层)，HTTP和Socket什么关系，WebSocket和Socket就是什么关系。\nHTTP 协议有一个缺陷：通信只能由客户端发起，做不到服务器主动向客户端推送信息。\nWebSocket 协议在2008年诞生，2011年成为国际标准。所有浏览器都已经支持了。\n它的最大特点就是，服务器可以主动向客户端推送信息，客户端也可以主动向服务器发送信息，是真正的双向平等对话，属于服务器推送技术的一种。\n\n\n### 使用Socket建立网络\n> 网络上两个程序通过双向通信实现数据交换，socket又叫套接字，每个应用程序开启后，都会在传输层端口上绑定一个socket，不同应用程序之间通过寻找端口找到socket实现数据通信。\nSocket连接过程分为三个步骤：服务器监听，客户端请求，连接确认。\n\n> 1、服务器监听：服务器端套接字并不定位具体的客户端套接字，而是处于等待连接的状态，实时监控网络状态，等待客户端的连接请求。\n\n> 2、客户端请求：指客户端的套接字提出连接请求，要连接的目标是服务器端的套接字。为此，客户端的套接字必须首先描述它要连接的服务器的套接字，指出服务器端套接字的地址和端口号，然后就向服务器端套接字提出连接请求。\n\n> 3、连接确认：当服务器端套接字监听到或者说接收到客户端套接字的连接请求时，就响应客户端套接字的请求，建立一个新的线程，把服务器端套接字的描述发给客户端，一旦客户端确认了此描述，双方就正式建立连接。\n\n","source":"_posts/blogs/HTTP_TCP_Socket.md","raw":"---\ntitle: HTTP, TCP, Socket\ntags:\ncategories:\n- blogs\n---\n\n## iso七层模型\n有应用层 表示层 会话层 传输层 网络层 数据链路层 物理层,其中http就属于应用层,tcp与udp是属于传输层\n![](ISO.png)\n![](ISO-TCP.IP.png)\n> 实体层：连接网络的硬件设备，就是将电脑连接起来的物理手段. 如光缆/电缆/无线电波\n> 数据链路层 (Link)：建立逻辑连接、进行硬件地址寻址、差错校验等功能，如32位和64位计算机，他们的解码方式是不一样的，数据链路层就规定个二进制数据的解读方式。\n> 网络层 (Network)：进行逻辑地址寻址，实现不同网络之间的路径选择。网络层建立了主机之间的通信，它在网络层引入了一套地址机制:网络地址.简称网址（Ip地址），我们可以通过Ip地址,可以找到唯一的一台计算机，通过主机MAC地址来接收和发送信息.\n> 传输层 (Transport)：定义传输数据的协议端口号，以及流控和差错效验，定义了端口和端口之间的通信，帮助我们使不同的应用程序能够接收到自己所需要的的数据。\n> 会话层 (Session Layer)：包括建立、管理、终止会话，用来建立和管理应用程序之间的通信，实现自动寻址，自动收发数据。\n> 表示层 (Presentation Layer)：数据的表示、安全、压缩。比如我们要用基于Unix系统的mac电脑给pc机发送数据，表示层为我们解决了通信间语法的问题。\n> 应用层 (Application)：网络服务与最终用户的一个接口。比如不同的文件类型要用不同的应用程序打开，应用层中就规定了不同应用程序的数据格式.\n\n### http和tcp的联系\n> * http是基于tcp，就相当于生活中的吃饭时候你都会用到碗，这个碗就是tcp，吃饭这件事情就相当于http，因为我们http发送数据之前，会先进行tcp三次握手，记住这时候只是发送一些状态码的确认等，并没有对http的数据进行发送。\n\n> * http长连接和短连接，其实就是tcp长连接与短连接，在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，请求结束就中断连接，HTTP1.1就使用长连接，\n用长连接的HTTP协议，会在响应头加入这行代码：\n\n\n\t Connection:keep-alive\n使用长连接每次打开一个网页除了第一次需要三次握手连接，接下来请求服务器就不用再握手了，就一直使用这个连接，这个keep-alive不会永久保持，这个可以在服务器端设置\n\n> * 长连接和短连接简短概括\n短连接就相当于每次一碗饭就去换一个碗，长连接就是每次吃饭都使用这个碗\n\n### tcp和udp的区别\n> tcp是面向连接的，udp不是面向连接的，怎么说呢？就相当于我们生活中打电话或者微信聊天，要先嘟嘟嘟连接，之后才可以打电话聊天，这个就是面向连接的，也是比较可靠的，udp是不用先去做连接的，所以叫做面向非连接，类似生活中发短信，直接发送过去\n\n有人会问了，为什么http是基于tcp而不是udp呢？\n这个tcp协议比较可靠，不过，目前，有人正在研究基于TCP+UDP混合的HTTP协议。\n\n![](socket.jpg)\n\n### IP：\n网络层协议；（高速公路）\n为计算机网络相互连接进行通信而设计的协议。\n> IP协议对应于网络层，TCP协议对应于传输层，而HTTP协议对应于应用层。注意TPC/IP位于传输层，它主要用来解决数据如何在网络中传输，与IP协议要区分开\n\n### TCP和UDP：\n传输层协议；（卡车）\n> TCP和UDP使用IP协议从一个网络传送数据包到另一个网络。把IP想像成一种高速公路，它允许其它协议在上面行驶并找到到其它电脑的出口。TCP和UDP是高速公路上的“卡车”，它们携带的货物就是像HTTP，文件传输协议FTP这样的协议等。\n\n### HTTP：\n> 应用层协议；（货物）。HTTP(超文本传输协议)是利用TCP在两台电脑(通常是Web服务器和客户端)之间传输信息的协议。客户端使用Web浏览器发起HTTP请求给Web服务器，Web服务器发送被请求的信息给客户端。\nHTTP是应用层协议，主要用于包装数据\n\n### SOCKET：\n> 套接字，TCP/IP网络的API。(港口码头/车站)Socket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。socket是在应用层和传输层之间的一个抽象层，它把TCP/IP层复杂的操作抽象为几个简单的接口供应用层调用已实现进程在网络中通信。\nSocket相当于调用接口(API)，用来调取TCP/IP协议, Socket接口定义了许多函数或例程，用以开发TCP/IP网络上的应用程序。\n\n### TCP/IP：\n> 代表传输控制协议/网际协议，指的是一系列协议，TCP/IP 模型在 OSI 模型的基础上进行了简化，变成了四层，从下到上分别为：网络接口层、网络层、传输层、应用层。\n\n###TCP/UDP区别\n> TCP: （传输控制协议，Transmission Control Protocol）：(类似打电话) 面向连接、传输可靠（保证数据正确性）、有序（保证数据顺序）、传输大量数据（流模式）、速度慢、对系统资源的要求多，程序结构较复杂，每一条TCP连接只能是点到点的，TCP首部开销20字节。\n\n> UDP: (用户数据报协议，User Data Protocol)：（类似发短信） 面向非连接 、传输不可靠（可能丢包）、无序、传输少量数据（数据报模式）、速度快，对系统资源的要求少，程序结构较简单 ，UDP支持一对一，一对多，多对一和多对多的交互通信，UDP的首部开销小，只有8个字节。\n\n### tcp三次握手建立连接\n![](tcp-ip-handshark.png)\n> 第一次握手：客户端发送syn包(seq=x)到服务器，并进入SYN_SEND状态，等待服务器确认；\n> 第二次握手：服务器收到syn包，必须确认客户的SYN（ack=x+1），同时自己也发送一个SYN包（seq=y），即SYN+ACK包，此时服务器进入SYN_RECV状态；\n> 第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=y+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。\n握手过程中传送的包里不包含数据，三次握手完毕后，客户端与服务器才正式开始传送数据。理想状态下，TCP连接一旦建立，在通信双方中的任何一方主动关闭连接之前，TCP 连接都将被一直保持下去。\n主机A向主机B发出连接请求数据包：“我想给你发数据，可以吗？”，这是第一次对话；\n主机B向主机A发送同意连接和要求同步（同步就是两台主机一个在发送，一个在接收，协调工作）的数据包：“可以，你什么时候发？”，这是第二次对话；\n主机A再发出一个数据包确认主机B的要求同步：“我现在就发，你接着吧！”，这是第三次对话。\n三次“对话”的目的是使数据包的发送和接收同步，经过三次“对话”之后，主机A才向主机B正式发送数据。\n\n### Websocket\nWebsocket协议解决了服务器与客户端全双工通信的问题。\n\n注:什么是单工、半双工、全工通信？\n信息只能单向传送为单工；\n信息能双向传送但不能同时双向传送称为半双工；\n信息能够同时双向传送则称为全双工。\n\n### WebSocket和Socket区别\n可以把WebSocket想象成HTTP(应用层)，HTTP和Socket什么关系，WebSocket和Socket就是什么关系。\nHTTP 协议有一个缺陷：通信只能由客户端发起，做不到服务器主动向客户端推送信息。\nWebSocket 协议在2008年诞生，2011年成为国际标准。所有浏览器都已经支持了。\n它的最大特点就是，服务器可以主动向客户端推送信息，客户端也可以主动向服务器发送信息，是真正的双向平等对话，属于服务器推送技术的一种。\n\n\n### 使用Socket建立网络\n> 网络上两个程序通过双向通信实现数据交换，socket又叫套接字，每个应用程序开启后，都会在传输层端口上绑定一个socket，不同应用程序之间通过寻找端口找到socket实现数据通信。\nSocket连接过程分为三个步骤：服务器监听，客户端请求，连接确认。\n\n> 1、服务器监听：服务器端套接字并不定位具体的客户端套接字，而是处于等待连接的状态，实时监控网络状态，等待客户端的连接请求。\n\n> 2、客户端请求：指客户端的套接字提出连接请求，要连接的目标是服务器端的套接字。为此，客户端的套接字必须首先描述它要连接的服务器的套接字，指出服务器端套接字的地址和端口号，然后就向服务器端套接字提出连接请求。\n\n> 3、连接确认：当服务器端套接字监听到或者说接收到客户端套接字的连接请求时，就响应客户端套接字的请求，建立一个新的线程，把服务器端套接字的描述发给客户端，一旦客户端确认了此描述，双方就正式建立连接。\n\n","slug":"blogs/HTTP_TCP_Socket","published":1,"date":"2020-08-12T16:05:44.379Z","updated":"2020-07-03T07:17:29.032Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmbk0002hohxeg92g1pc","content":"<h2 id=\"iso七层模型\"><a href=\"#iso七层模型\" class=\"headerlink\" title=\"iso七层模型\"></a>iso七层模型</h2><p>有应用层 表示层 会话层 传输层 网络层 数据链路层 物理层,其中http就属于应用层,tcp与udp是属于传输层<br><img src=\"ISO.png\" alt=\"\"><br><img src=\"ISO-TCP.IP.png\" alt=\"\"></p>\n<blockquote>\n<p>实体层：连接网络的硬件设备，就是将电脑连接起来的物理手段. 如光缆/电缆/无线电波<br>数据链路层 (Link)：建立逻辑连接、进行硬件地址寻址、差错校验等功能，如32位和64位计算机，他们的解码方式是不一样的，数据链路层就规定个二进制数据的解读方式。<br>网络层 (Network)：进行逻辑地址寻址，实现不同网络之间的路径选择。网络层建立了主机之间的通信，它在网络层引入了一套地址机制:网络地址.简称网址（Ip地址），我们可以通过Ip地址,可以找到唯一的一台计算机，通过主机MAC地址来接收和发送信息.<br>传输层 (Transport)：定义传输数据的协议端口号，以及流控和差错效验，定义了端口和端口之间的通信，帮助我们使不同的应用程序能够接收到自己所需要的的数据。<br>会话层 (Session Layer)：包括建立、管理、终止会话，用来建立和管理应用程序之间的通信，实现自动寻址，自动收发数据。<br>表示层 (Presentation Layer)：数据的表示、安全、压缩。比如我们要用基于Unix系统的mac电脑给pc机发送数据，表示层为我们解决了通信间语法的问题。<br>应用层 (Application)：网络服务与最终用户的一个接口。比如不同的文件类型要用不同的应用程序打开，应用层中就规定了不同应用程序的数据格式.</p>\n</blockquote>\n<h3 id=\"http和tcp的联系\"><a href=\"#http和tcp的联系\" class=\"headerlink\" title=\"http和tcp的联系\"></a>http和tcp的联系</h3><blockquote>\n<ul>\n<li>http是基于tcp，就相当于生活中的吃饭时候你都会用到碗，这个碗就是tcp，吃饭这件事情就相当于http，因为我们http发送数据之前，会先进行tcp三次握手，记住这时候只是发送一些状态码的确认等，并没有对http的数据进行发送。</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>http长连接和短连接，其实就是tcp长连接与短连接，在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，请求结束就中断连接，HTTP1.1就使用长连接，<br>用长连接的HTTP协议，会在响应头加入这行代码：</li>\n</ul>\n</blockquote>\n<pre><code>Connection:keep-alive</code></pre><p>使用长连接每次打开一个网页除了第一次需要三次握手连接，接下来请求服务器就不用再握手了，就一直使用这个连接，这个keep-alive不会永久保持，这个可以在服务器端设置</p>\n<blockquote>\n<ul>\n<li>长连接和短连接简短概括<br>短连接就相当于每次一碗饭就去换一个碗，长连接就是每次吃饭都使用这个碗</li>\n</ul>\n</blockquote>\n<h3 id=\"tcp和udp的区别\"><a href=\"#tcp和udp的区别\" class=\"headerlink\" title=\"tcp和udp的区别\"></a>tcp和udp的区别</h3><blockquote>\n<p>tcp是面向连接的，udp不是面向连接的，怎么说呢？就相当于我们生活中打电话或者微信聊天，要先嘟嘟嘟连接，之后才可以打电话聊天，这个就是面向连接的，也是比较可靠的，udp是不用先去做连接的，所以叫做面向非连接，类似生活中发短信，直接发送过去</p>\n</blockquote>\n<p>有人会问了，为什么http是基于tcp而不是udp呢？<br>这个tcp协议比较可靠，不过，目前，有人正在研究基于TCP+UDP混合的HTTP协议。</p>\n<p><img src=\"socket.jpg\" alt=\"\"></p>\n<h3 id=\"IP：\"><a href=\"#IP：\" class=\"headerlink\" title=\"IP：\"></a>IP：</h3><p>网络层协议；（高速公路）<br>为计算机网络相互连接进行通信而设计的协议。</p>\n<blockquote>\n<p>IP协议对应于网络层，TCP协议对应于传输层，而HTTP协议对应于应用层。注意TPC/IP位于传输层，它主要用来解决数据如何在网络中传输，与IP协议要区分开</p>\n</blockquote>\n<h3 id=\"TCP和UDP：\"><a href=\"#TCP和UDP：\" class=\"headerlink\" title=\"TCP和UDP：\"></a>TCP和UDP：</h3><p>传输层协议；（卡车）</p>\n<blockquote>\n<p>TCP和UDP使用IP协议从一个网络传送数据包到另一个网络。把IP想像成一种高速公路，它允许其它协议在上面行驶并找到到其它电脑的出口。TCP和UDP是高速公路上的“卡车”，它们携带的货物就是像HTTP，文件传输协议FTP这样的协议等。</p>\n</blockquote>\n<h3 id=\"HTTP：\"><a href=\"#HTTP：\" class=\"headerlink\" title=\"HTTP：\"></a>HTTP：</h3><blockquote>\n<p>应用层协议；（货物）。HTTP(超文本传输协议)是利用TCP在两台电脑(通常是Web服务器和客户端)之间传输信息的协议。客户端使用Web浏览器发起HTTP请求给Web服务器，Web服务器发送被请求的信息给客户端。<br>HTTP是应用层协议，主要用于包装数据</p>\n</blockquote>\n<h3 id=\"SOCKET：\"><a href=\"#SOCKET：\" class=\"headerlink\" title=\"SOCKET：\"></a>SOCKET：</h3><blockquote>\n<p>套接字，TCP/IP网络的API。(港口码头/车站)Socket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。socket是在应用层和传输层之间的一个抽象层，它把TCP/IP层复杂的操作抽象为几个简单的接口供应用层调用已实现进程在网络中通信。<br>Socket相当于调用接口(API)，用来调取TCP/IP协议, Socket接口定义了许多函数或例程，用以开发TCP/IP网络上的应用程序。</p>\n</blockquote>\n<h3 id=\"TCP-IP：\"><a href=\"#TCP-IP：\" class=\"headerlink\" title=\"TCP/IP：\"></a>TCP/IP：</h3><blockquote>\n<p>代表传输控制协议/网际协议，指的是一系列协议，TCP/IP 模型在 OSI 模型的基础上进行了简化，变成了四层，从下到上分别为：网络接口层、网络层、传输层、应用层。</p>\n</blockquote>\n<p>###TCP/UDP区别</p>\n<blockquote>\n<p>TCP: （传输控制协议，Transmission Control Protocol）：(类似打电话) 面向连接、传输可靠（保证数据正确性）、有序（保证数据顺序）、传输大量数据（流模式）、速度慢、对系统资源的要求多，程序结构较复杂，每一条TCP连接只能是点到点的，TCP首部开销20字节。</p>\n</blockquote>\n<blockquote>\n<p>UDP: (用户数据报协议，User Data Protocol)：（类似发短信） 面向非连接 、传输不可靠（可能丢包）、无序、传输少量数据（数据报模式）、速度快，对系统资源的要求少，程序结构较简单 ，UDP支持一对一，一对多，多对一和多对多的交互通信，UDP的首部开销小，只有8个字节。</p>\n</blockquote>\n<h3 id=\"tcp三次握手建立连接\"><a href=\"#tcp三次握手建立连接\" class=\"headerlink\" title=\"tcp三次握手建立连接\"></a>tcp三次握手建立连接</h3><p><img src=\"tcp-ip-handshark.png\" alt=\"\"></p>\n<blockquote>\n<p>第一次握手：客户端发送syn包(seq=x)到服务器，并进入SYN_SEND状态，等待服务器确认；<br>第二次握手：服务器收到syn包，必须确认客户的SYN（ack=x+1），同时自己也发送一个SYN包（seq=y），即SYN+ACK包，此时服务器进入SYN_RECV状态；<br>第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=y+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。<br>握手过程中传送的包里不包含数据，三次握手完毕后，客户端与服务器才正式开始传送数据。理想状态下，TCP连接一旦建立，在通信双方中的任何一方主动关闭连接之前，TCP 连接都将被一直保持下去。<br>主机A向主机B发出连接请求数据包：“我想给你发数据，可以吗？”，这是第一次对话；<br>主机B向主机A发送同意连接和要求同步（同步就是两台主机一个在发送，一个在接收，协调工作）的数据包：“可以，你什么时候发？”，这是第二次对话；<br>主机A再发出一个数据包确认主机B的要求同步：“我现在就发，你接着吧！”，这是第三次对话。<br>三次“对话”的目的是使数据包的发送和接收同步，经过三次“对话”之后，主机A才向主机B正式发送数据。</p>\n</blockquote>\n<h3 id=\"Websocket\"><a href=\"#Websocket\" class=\"headerlink\" title=\"Websocket\"></a>Websocket</h3><p>Websocket协议解决了服务器与客户端全双工通信的问题。</p>\n<p>注:什么是单工、半双工、全工通信？<br>信息只能单向传送为单工；<br>信息能双向传送但不能同时双向传送称为半双工；<br>信息能够同时双向传送则称为全双工。</p>\n<h3 id=\"WebSocket和Socket区别\"><a href=\"#WebSocket和Socket区别\" class=\"headerlink\" title=\"WebSocket和Socket区别\"></a>WebSocket和Socket区别</h3><p>可以把WebSocket想象成HTTP(应用层)，HTTP和Socket什么关系，WebSocket和Socket就是什么关系。<br>HTTP 协议有一个缺陷：通信只能由客户端发起，做不到服务器主动向客户端推送信息。<br>WebSocket 协议在2008年诞生，2011年成为国际标准。所有浏览器都已经支持了。<br>它的最大特点就是，服务器可以主动向客户端推送信息，客户端也可以主动向服务器发送信息，是真正的双向平等对话，属于服务器推送技术的一种。</p>\n<h3 id=\"使用Socket建立网络\"><a href=\"#使用Socket建立网络\" class=\"headerlink\" title=\"使用Socket建立网络\"></a>使用Socket建立网络</h3><blockquote>\n<p>网络上两个程序通过双向通信实现数据交换，socket又叫套接字，每个应用程序开启后，都会在传输层端口上绑定一个socket，不同应用程序之间通过寻找端口找到socket实现数据通信。<br>Socket连接过程分为三个步骤：服务器监听，客户端请求，连接确认。</p>\n</blockquote>\n<blockquote>\n<p>1、服务器监听：服务器端套接字并不定位具体的客户端套接字，而是处于等待连接的状态，实时监控网络状态，等待客户端的连接请求。</p>\n</blockquote>\n<blockquote>\n<p>2、客户端请求：指客户端的套接字提出连接请求，要连接的目标是服务器端的套接字。为此，客户端的套接字必须首先描述它要连接的服务器的套接字，指出服务器端套接字的地址和端口号，然后就向服务器端套接字提出连接请求。</p>\n</blockquote>\n<blockquote>\n<p>3、连接确认：当服务器端套接字监听到或者说接收到客户端套接字的连接请求时，就响应客户端套接字的请求，建立一个新的线程，把服务器端套接字的描述发给客户端，一旦客户端确认了此描述，双方就正式建立连接。</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"iso七层模型\"><a href=\"#iso七层模型\" class=\"headerlink\" title=\"iso七层模型\"></a>iso七层模型</h2><p>有应用层 表示层 会话层 传输层 网络层 数据链路层 物理层,其中http就属于应用层,tcp与udp是属于传输层<br><img src=\"ISO.png\" alt=\"\"><br><img src=\"ISO-TCP.IP.png\" alt=\"\"></p>\n<blockquote>\n<p>实体层：连接网络的硬件设备，就是将电脑连接起来的物理手段. 如光缆/电缆/无线电波<br>数据链路层 (Link)：建立逻辑连接、进行硬件地址寻址、差错校验等功能，如32位和64位计算机，他们的解码方式是不一样的，数据链路层就规定个二进制数据的解读方式。<br>网络层 (Network)：进行逻辑地址寻址，实现不同网络之间的路径选择。网络层建立了主机之间的通信，它在网络层引入了一套地址机制:网络地址.简称网址（Ip地址），我们可以通过Ip地址,可以找到唯一的一台计算机，通过主机MAC地址来接收和发送信息.<br>传输层 (Transport)：定义传输数据的协议端口号，以及流控和差错效验，定义了端口和端口之间的通信，帮助我们使不同的应用程序能够接收到自己所需要的的数据。<br>会话层 (Session Layer)：包括建立、管理、终止会话，用来建立和管理应用程序之间的通信，实现自动寻址，自动收发数据。<br>表示层 (Presentation Layer)：数据的表示、安全、压缩。比如我们要用基于Unix系统的mac电脑给pc机发送数据，表示层为我们解决了通信间语法的问题。<br>应用层 (Application)：网络服务与最终用户的一个接口。比如不同的文件类型要用不同的应用程序打开，应用层中就规定了不同应用程序的数据格式.</p>\n</blockquote>\n<h3 id=\"http和tcp的联系\"><a href=\"#http和tcp的联系\" class=\"headerlink\" title=\"http和tcp的联系\"></a>http和tcp的联系</h3><blockquote>\n<ul>\n<li>http是基于tcp，就相当于生活中的吃饭时候你都会用到碗，这个碗就是tcp，吃饭这件事情就相当于http，因为我们http发送数据之前，会先进行tcp三次握手，记住这时候只是发送一些状态码的确认等，并没有对http的数据进行发送。</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>http长连接和短连接，其实就是tcp长连接与短连接，在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，请求结束就中断连接，HTTP1.1就使用长连接，<br>用长连接的HTTP协议，会在响应头加入这行代码：</li>\n</ul>\n</blockquote>\n<pre><code>Connection:keep-alive</code></pre><p>使用长连接每次打开一个网页除了第一次需要三次握手连接，接下来请求服务器就不用再握手了，就一直使用这个连接，这个keep-alive不会永久保持，这个可以在服务器端设置</p>\n<blockquote>\n<ul>\n<li>长连接和短连接简短概括<br>短连接就相当于每次一碗饭就去换一个碗，长连接就是每次吃饭都使用这个碗</li>\n</ul>\n</blockquote>\n<h3 id=\"tcp和udp的区别\"><a href=\"#tcp和udp的区别\" class=\"headerlink\" title=\"tcp和udp的区别\"></a>tcp和udp的区别</h3><blockquote>\n<p>tcp是面向连接的，udp不是面向连接的，怎么说呢？就相当于我们生活中打电话或者微信聊天，要先嘟嘟嘟连接，之后才可以打电话聊天，这个就是面向连接的，也是比较可靠的，udp是不用先去做连接的，所以叫做面向非连接，类似生活中发短信，直接发送过去</p>\n</blockquote>\n<p>有人会问了，为什么http是基于tcp而不是udp呢？<br>这个tcp协议比较可靠，不过，目前，有人正在研究基于TCP+UDP混合的HTTP协议。</p>\n<p><img src=\"socket.jpg\" alt=\"\"></p>\n<h3 id=\"IP：\"><a href=\"#IP：\" class=\"headerlink\" title=\"IP：\"></a>IP：</h3><p>网络层协议；（高速公路）<br>为计算机网络相互连接进行通信而设计的协议。</p>\n<blockquote>\n<p>IP协议对应于网络层，TCP协议对应于传输层，而HTTP协议对应于应用层。注意TPC/IP位于传输层，它主要用来解决数据如何在网络中传输，与IP协议要区分开</p>\n</blockquote>\n<h3 id=\"TCP和UDP：\"><a href=\"#TCP和UDP：\" class=\"headerlink\" title=\"TCP和UDP：\"></a>TCP和UDP：</h3><p>传输层协议；（卡车）</p>\n<blockquote>\n<p>TCP和UDP使用IP协议从一个网络传送数据包到另一个网络。把IP想像成一种高速公路，它允许其它协议在上面行驶并找到到其它电脑的出口。TCP和UDP是高速公路上的“卡车”，它们携带的货物就是像HTTP，文件传输协议FTP这样的协议等。</p>\n</blockquote>\n<h3 id=\"HTTP：\"><a href=\"#HTTP：\" class=\"headerlink\" title=\"HTTP：\"></a>HTTP：</h3><blockquote>\n<p>应用层协议；（货物）。HTTP(超文本传输协议)是利用TCP在两台电脑(通常是Web服务器和客户端)之间传输信息的协议。客户端使用Web浏览器发起HTTP请求给Web服务器，Web服务器发送被请求的信息给客户端。<br>HTTP是应用层协议，主要用于包装数据</p>\n</blockquote>\n<h3 id=\"SOCKET：\"><a href=\"#SOCKET：\" class=\"headerlink\" title=\"SOCKET：\"></a>SOCKET：</h3><blockquote>\n<p>套接字，TCP/IP网络的API。(港口码头/车站)Socket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。socket是在应用层和传输层之间的一个抽象层，它把TCP/IP层复杂的操作抽象为几个简单的接口供应用层调用已实现进程在网络中通信。<br>Socket相当于调用接口(API)，用来调取TCP/IP协议, Socket接口定义了许多函数或例程，用以开发TCP/IP网络上的应用程序。</p>\n</blockquote>\n<h3 id=\"TCP-IP：\"><a href=\"#TCP-IP：\" class=\"headerlink\" title=\"TCP/IP：\"></a>TCP/IP：</h3><blockquote>\n<p>代表传输控制协议/网际协议，指的是一系列协议，TCP/IP 模型在 OSI 模型的基础上进行了简化，变成了四层，从下到上分别为：网络接口层、网络层、传输层、应用层。</p>\n</blockquote>\n<p>###TCP/UDP区别</p>\n<blockquote>\n<p>TCP: （传输控制协议，Transmission Control Protocol）：(类似打电话) 面向连接、传输可靠（保证数据正确性）、有序（保证数据顺序）、传输大量数据（流模式）、速度慢、对系统资源的要求多，程序结构较复杂，每一条TCP连接只能是点到点的，TCP首部开销20字节。</p>\n</blockquote>\n<blockquote>\n<p>UDP: (用户数据报协议，User Data Protocol)：（类似发短信） 面向非连接 、传输不可靠（可能丢包）、无序、传输少量数据（数据报模式）、速度快，对系统资源的要求少，程序结构较简单 ，UDP支持一对一，一对多，多对一和多对多的交互通信，UDP的首部开销小，只有8个字节。</p>\n</blockquote>\n<h3 id=\"tcp三次握手建立连接\"><a href=\"#tcp三次握手建立连接\" class=\"headerlink\" title=\"tcp三次握手建立连接\"></a>tcp三次握手建立连接</h3><p><img src=\"tcp-ip-handshark.png\" alt=\"\"></p>\n<blockquote>\n<p>第一次握手：客户端发送syn包(seq=x)到服务器，并进入SYN_SEND状态，等待服务器确认；<br>第二次握手：服务器收到syn包，必须确认客户的SYN（ack=x+1），同时自己也发送一个SYN包（seq=y），即SYN+ACK包，此时服务器进入SYN_RECV状态；<br>第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=y+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。<br>握手过程中传送的包里不包含数据，三次握手完毕后，客户端与服务器才正式开始传送数据。理想状态下，TCP连接一旦建立，在通信双方中的任何一方主动关闭连接之前，TCP 连接都将被一直保持下去。<br>主机A向主机B发出连接请求数据包：“我想给你发数据，可以吗？”，这是第一次对话；<br>主机B向主机A发送同意连接和要求同步（同步就是两台主机一个在发送，一个在接收，协调工作）的数据包：“可以，你什么时候发？”，这是第二次对话；<br>主机A再发出一个数据包确认主机B的要求同步：“我现在就发，你接着吧！”，这是第三次对话。<br>三次“对话”的目的是使数据包的发送和接收同步，经过三次“对话”之后，主机A才向主机B正式发送数据。</p>\n</blockquote>\n<h3 id=\"Websocket\"><a href=\"#Websocket\" class=\"headerlink\" title=\"Websocket\"></a>Websocket</h3><p>Websocket协议解决了服务器与客户端全双工通信的问题。</p>\n<p>注:什么是单工、半双工、全工通信？<br>信息只能单向传送为单工；<br>信息能双向传送但不能同时双向传送称为半双工；<br>信息能够同时双向传送则称为全双工。</p>\n<h3 id=\"WebSocket和Socket区别\"><a href=\"#WebSocket和Socket区别\" class=\"headerlink\" title=\"WebSocket和Socket区别\"></a>WebSocket和Socket区别</h3><p>可以把WebSocket想象成HTTP(应用层)，HTTP和Socket什么关系，WebSocket和Socket就是什么关系。<br>HTTP 协议有一个缺陷：通信只能由客户端发起，做不到服务器主动向客户端推送信息。<br>WebSocket 协议在2008年诞生，2011年成为国际标准。所有浏览器都已经支持了。<br>它的最大特点就是，服务器可以主动向客户端推送信息，客户端也可以主动向服务器发送信息，是真正的双向平等对话，属于服务器推送技术的一种。</p>\n<h3 id=\"使用Socket建立网络\"><a href=\"#使用Socket建立网络\" class=\"headerlink\" title=\"使用Socket建立网络\"></a>使用Socket建立网络</h3><blockquote>\n<p>网络上两个程序通过双向通信实现数据交换，socket又叫套接字，每个应用程序开启后，都会在传输层端口上绑定一个socket，不同应用程序之间通过寻找端口找到socket实现数据通信。<br>Socket连接过程分为三个步骤：服务器监听，客户端请求，连接确认。</p>\n</blockquote>\n<blockquote>\n<p>1、服务器监听：服务器端套接字并不定位具体的客户端套接字，而是处于等待连接的状态，实时监控网络状态，等待客户端的连接请求。</p>\n</blockquote>\n<blockquote>\n<p>2、客户端请求：指客户端的套接字提出连接请求，要连接的目标是服务器端的套接字。为此，客户端的套接字必须首先描述它要连接的服务器的套接字，指出服务器端套接字的地址和端口号，然后就向服务器端套接字提出连接请求。</p>\n</blockquote>\n<blockquote>\n<p>3、连接确认：当服务器端套接字监听到或者说接收到客户端套接字的连接请求时，就响应客户端套接字的请求，建立一个新的线程，把服务器端套接字的描述发给客户端，一旦客户端确认了此描述，双方就正式建立连接。</p>\n</blockquote>\n"},{"title":"Hexo 01 部署github blog","_content":"\n## **1. 确认电脑安装过git**\n\n\t鼠标右击有git gui和git bash选项，随便新建一个文件夹，进入。\n## **2. 以管理员身份打开cmd， cd到当前目录**\n\n\t1. #npm install -g hexo-cli\n\t2. #npm install hexo-deployer-git --save\n\t3. #hexo init\n\t在public目录下可看到我们自己书写的博客文档（.md文件）\n## **3. 生成网页浏览**\n\n\t$ hexo g\n\t默认地址是 localhost:4000, 浏览器输入此链接即可看到默认样式\n## **4. 选择主题，Hexo可随时使用、更换博客主题**\nHexo官方主题网页  \n其中一个主题  \n\n\t$ git clone https://github.com/yelog/hexo-theme-3-hexo.git themes/3-hexo\n下载项目至博客项目下的themes目录中，文件夹命名为3-hexo，并在博客配置文件_config.yml中指定使用该主题：  \n修改hexo根目录的_config.yml文件，如下  \n\n\ttheme: 3-hexo\n更新:\n\n\t$ cd themes/3-hexo\n\t$ git pull\n## **5. 配置SSH密钥**\n\n\t$ ssh-keygen -t rsa -C \"1041618918@qq.com\"\n\t$ cat ~/.ssh/id_rsa.pub                    //C:\\Users\\yazhanma\\.ssh\\id_rsa.pub\n复制内容添加到github ->settings->SSH and GPG keys-> add SSH key, 名字随便取.  \n此时安装网上说的测试命令#ssh -T git@github.com是否能连接上，自己试了试不行仍然time out，但是不影响估计是得等一段时间才行，仍然继续下面步骤部署成功.  \n修改博客配置文件_config.yml  \n\n\tdeploy:\n\t  type: git\n\t  repo: https://github.com/Kung-Fu-Master/Kung-Fu-Master.github.io\n\t  // 如果执行$hexo d后出现一个错误但还是部署成功, 可以将路径改成以下ssh格式就不会执行$hexo d命令后出错, 但是部署速度超级慢\n\t  // repo: git@github.com:Kung-Fu-Master/Kung-Fu-Master.github.io.git\n\t  branch: master\n\n## **6. 发布到GitHub**\n\n\t$ hexo g\n\t$ hexo d\n完成后，就有属于自己的博客了，在github的setting中 可以看到自己的博客地址。\n\n\thttps://kung-fu-master.github.io\n如果文章没更新, 对于chrome浏览器  \n第一种方法: 可以选择等待一会时间再查看  \n第二种方法: 点击地址栏右侧的菜单按钮->更多工具->清除浏览数据->清除数据 再刷新就可看到文章已更新  \n\n## **7. 配置评论系统**\n目前 3-hexo 已经集成了评论系统有 gitalk 、gitment、 disqus 、来必力、utteranc  \n\n7.1 登录 github ，注册应用\n[点击进行注册](https://github.com/settings/applications/new)\n![](registry_gitalk.PNG)\n注册完后，可得到 `Client ID` 和 `Client Secret`.  \n\n7.2 因为 gitalk 是基于 Github 的 Issue 的，所以需要指定一个仓库，用来承接 gitalk 的评论，我们一般使用 Github Page 来做我们博客的评论，所以，新建仓库名为 xxx.github.io，其中 xxx 为你的 Github 用户名  \ngitalk官网: [https://gitalk.github.io/](https://gitalk.github.io/)\n\n7.3 配置主题\n在主题下 _config.yml 中找到如下配置，启用评论，并使用 gitalk.  \n\n\t########## 评论设置 #############\n\tcomment:\n\t  on: true\n\t  type: gitalk\n在主题下 _config.yml 中找到 gitalk 配置，将 第 1 步 得到的 Client ID 和 Client Secret 复制到如下位置\n\n\tgitalk:\n\t  githubID:    # 填你的 github 用户名\n\t  repo:  xxx.github.io     # 承载评论的仓库，一般使用 Github Page 仓库\n\t  ClientID:   # 第 7.1 步获得 Client ID\n\t  ClientSecret:  # 第 7.1 步获得 Client Secret\n\t  adminUser:     # Github 用户名\n\t  distractionFreeMode: true\n\t  language: zh-CN\n\t  perPage: 10\n\n## **8. 开启字数统计**\n开启此功能需先安装插件，在 hexo 根目录(博客的目录,没有package.json文件的话会自动生成), 执行 `$ npm i hexo-wordcount --save`\n修改 _config.yml\n\n\tword_count: true\n\n## **写博客、发布文章**\n新建一篇博客，执行下面的命令, 或者自己手动创建*.md文件, 后缀名一定要是\".md\".\n\n\t$ hexo new post \"article title\"\n![](deploy.jpg)\n\\source\\ _posts 将会看到 article title.md 文件\n\n用MarDown编辑器打开就可以编辑文章了。文章编辑好之后，运行生成、部署命令:  \n\n\t$ hexo g   // 生成\n\t$ hexo d   // 部署\n当然你也可以执行下面的命令，相当于上面两条命令的效果\n\n\t$ hexo d -g #在部署前先生成\n部署成功后访问 你的地址，https://yourName.github.io (这里输入我的地址:https://Kung-Fu-Master.github.io), 将可以看到生成的文章。\n\n## **踩坑提醒**\n1. 注意需要提前安装一个扩展：\n\n\n\t$ npm install hexo-deployer-git --save\n如果没有执行者行命令，将会提醒\n\n\n\t$ deloyer not found:git\n2. 如果出现下面这样的错误\n\n\nPermission denied (publickey).\nfatal: Could not read from remote repository.\nPlease make sure you have the correct access rights\nand the repository exists.\n\n则是因为没有设置好public key所致。  \n在本机生成public key,不懂的可以参考我的这一篇博客Git ssh 配置及使用  \n\n","source":"_posts/blogs/Hexo_01_部署github_blog.md","raw":"---\ntitle: Hexo 01 部署github blog\ntags:\ncategories:\n- blogs\n---\n\n## **1. 确认电脑安装过git**\n\n\t鼠标右击有git gui和git bash选项，随便新建一个文件夹，进入。\n## **2. 以管理员身份打开cmd， cd到当前目录**\n\n\t1. #npm install -g hexo-cli\n\t2. #npm install hexo-deployer-git --save\n\t3. #hexo init\n\t在public目录下可看到我们自己书写的博客文档（.md文件）\n## **3. 生成网页浏览**\n\n\t$ hexo g\n\t默认地址是 localhost:4000, 浏览器输入此链接即可看到默认样式\n## **4. 选择主题，Hexo可随时使用、更换博客主题**\nHexo官方主题网页  \n其中一个主题  \n\n\t$ git clone https://github.com/yelog/hexo-theme-3-hexo.git themes/3-hexo\n下载项目至博客项目下的themes目录中，文件夹命名为3-hexo，并在博客配置文件_config.yml中指定使用该主题：  \n修改hexo根目录的_config.yml文件，如下  \n\n\ttheme: 3-hexo\n更新:\n\n\t$ cd themes/3-hexo\n\t$ git pull\n## **5. 配置SSH密钥**\n\n\t$ ssh-keygen -t rsa -C \"1041618918@qq.com\"\n\t$ cat ~/.ssh/id_rsa.pub                    //C:\\Users\\yazhanma\\.ssh\\id_rsa.pub\n复制内容添加到github ->settings->SSH and GPG keys-> add SSH key, 名字随便取.  \n此时安装网上说的测试命令#ssh -T git@github.com是否能连接上，自己试了试不行仍然time out，但是不影响估计是得等一段时间才行，仍然继续下面步骤部署成功.  \n修改博客配置文件_config.yml  \n\n\tdeploy:\n\t  type: git\n\t  repo: https://github.com/Kung-Fu-Master/Kung-Fu-Master.github.io\n\t  // 如果执行$hexo d后出现一个错误但还是部署成功, 可以将路径改成以下ssh格式就不会执行$hexo d命令后出错, 但是部署速度超级慢\n\t  // repo: git@github.com:Kung-Fu-Master/Kung-Fu-Master.github.io.git\n\t  branch: master\n\n## **6. 发布到GitHub**\n\n\t$ hexo g\n\t$ hexo d\n完成后，就有属于自己的博客了，在github的setting中 可以看到自己的博客地址。\n\n\thttps://kung-fu-master.github.io\n如果文章没更新, 对于chrome浏览器  \n第一种方法: 可以选择等待一会时间再查看  \n第二种方法: 点击地址栏右侧的菜单按钮->更多工具->清除浏览数据->清除数据 再刷新就可看到文章已更新  \n\n## **7. 配置评论系统**\n目前 3-hexo 已经集成了评论系统有 gitalk 、gitment、 disqus 、来必力、utteranc  \n\n7.1 登录 github ，注册应用\n[点击进行注册](https://github.com/settings/applications/new)\n![](registry_gitalk.PNG)\n注册完后，可得到 `Client ID` 和 `Client Secret`.  \n\n7.2 因为 gitalk 是基于 Github 的 Issue 的，所以需要指定一个仓库，用来承接 gitalk 的评论，我们一般使用 Github Page 来做我们博客的评论，所以，新建仓库名为 xxx.github.io，其中 xxx 为你的 Github 用户名  \ngitalk官网: [https://gitalk.github.io/](https://gitalk.github.io/)\n\n7.3 配置主题\n在主题下 _config.yml 中找到如下配置，启用评论，并使用 gitalk.  \n\n\t########## 评论设置 #############\n\tcomment:\n\t  on: true\n\t  type: gitalk\n在主题下 _config.yml 中找到 gitalk 配置，将 第 1 步 得到的 Client ID 和 Client Secret 复制到如下位置\n\n\tgitalk:\n\t  githubID:    # 填你的 github 用户名\n\t  repo:  xxx.github.io     # 承载评论的仓库，一般使用 Github Page 仓库\n\t  ClientID:   # 第 7.1 步获得 Client ID\n\t  ClientSecret:  # 第 7.1 步获得 Client Secret\n\t  adminUser:     # Github 用户名\n\t  distractionFreeMode: true\n\t  language: zh-CN\n\t  perPage: 10\n\n## **8. 开启字数统计**\n开启此功能需先安装插件，在 hexo 根目录(博客的目录,没有package.json文件的话会自动生成), 执行 `$ npm i hexo-wordcount --save`\n修改 _config.yml\n\n\tword_count: true\n\n## **写博客、发布文章**\n新建一篇博客，执行下面的命令, 或者自己手动创建*.md文件, 后缀名一定要是\".md\".\n\n\t$ hexo new post \"article title\"\n![](deploy.jpg)\n\\source\\ _posts 将会看到 article title.md 文件\n\n用MarDown编辑器打开就可以编辑文章了。文章编辑好之后，运行生成、部署命令:  \n\n\t$ hexo g   // 生成\n\t$ hexo d   // 部署\n当然你也可以执行下面的命令，相当于上面两条命令的效果\n\n\t$ hexo d -g #在部署前先生成\n部署成功后访问 你的地址，https://yourName.github.io (这里输入我的地址:https://Kung-Fu-Master.github.io), 将可以看到生成的文章。\n\n## **踩坑提醒**\n1. 注意需要提前安装一个扩展：\n\n\n\t$ npm install hexo-deployer-git --save\n如果没有执行者行命令，将会提醒\n\n\n\t$ deloyer not found:git\n2. 如果出现下面这样的错误\n\n\nPermission denied (publickey).\nfatal: Could not read from remote repository.\nPlease make sure you have the correct access rights\nand the repository exists.\n\n则是因为没有设置好public key所致。  \n在本机生成public key,不懂的可以参考我的这一篇博客Git ssh 配置及使用  \n\n","slug":"blogs/Hexo_01_部署github_blog","published":1,"date":"2020-08-12T16:05:44.375Z","updated":"2020-08-12T12:42:04.092Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmbm0004hohx3ryi04nw","content":"<h2 id=\"1-确认电脑安装过git\"><a href=\"#1-确认电脑安装过git\" class=\"headerlink\" title=\"1. 确认电脑安装过git\"></a><strong>1. 确认电脑安装过git</strong></h2><pre><code>鼠标右击有git gui和git bash选项，随便新建一个文件夹，进入。</code></pre><h2 id=\"2-以管理员身份打开cmd，-cd到当前目录\"><a href=\"#2-以管理员身份打开cmd，-cd到当前目录\" class=\"headerlink\" title=\"2. 以管理员身份打开cmd， cd到当前目录\"></a><strong>2. 以管理员身份打开cmd， cd到当前目录</strong></h2><pre><code>1. #npm install -g hexo-cli\n2. #npm install hexo-deployer-git --save\n3. #hexo init\n在public目录下可看到我们自己书写的博客文档（.md文件）</code></pre><h2 id=\"3-生成网页浏览\"><a href=\"#3-生成网页浏览\" class=\"headerlink\" title=\"3. 生成网页浏览\"></a><strong>3. 生成网页浏览</strong></h2><pre><code>$ hexo g\n默认地址是 localhost:4000, 浏览器输入此链接即可看到默认样式</code></pre><h2 id=\"4-选择主题，Hexo可随时使用、更换博客主题\"><a href=\"#4-选择主题，Hexo可随时使用、更换博客主题\" class=\"headerlink\" title=\"4. 选择主题，Hexo可随时使用、更换博客主题\"></a><strong>4. 选择主题，Hexo可随时使用、更换博客主题</strong></h2><p>Hexo官方主题网页<br>其中一个主题  </p>\n<pre><code>$ git clone https://github.com/yelog/hexo-theme-3-hexo.git themes/3-hexo</code></pre><p>下载项目至博客项目下的themes目录中，文件夹命名为3-hexo，并在博客配置文件_config.yml中指定使用该主题：<br>修改hexo根目录的_config.yml文件，如下  </p>\n<pre><code>theme: 3-hexo</code></pre><p>更新:</p>\n<pre><code>$ cd themes/3-hexo\n$ git pull</code></pre><h2 id=\"5-配置SSH密钥\"><a href=\"#5-配置SSH密钥\" class=\"headerlink\" title=\"5. 配置SSH密钥\"></a><strong>5. 配置SSH密钥</strong></h2><pre><code>$ ssh-keygen -t rsa -C &quot;1041618918@qq.com&quot;\n$ cat ~/.ssh/id_rsa.pub                    //C:\\Users\\yazhanma\\.ssh\\id_rsa.pub</code></pre><p>复制内容添加到github -&gt;settings-&gt;SSH and GPG keys-&gt; add SSH key, 名字随便取.<br>此时安装网上说的测试命令#ssh -T <a href=\"mailto:git@github.com\">git@github.com</a>是否能连接上，自己试了试不行仍然time out，但是不影响估计是得等一段时间才行，仍然继续下面步骤部署成功.<br>修改博客配置文件_config.yml  </p>\n<pre><code>deploy:\n  type: git\n  repo: https://github.com/Kung-Fu-Master/Kung-Fu-Master.github.io\n  // 如果执行$hexo d后出现一个错误但还是部署成功, 可以将路径改成以下ssh格式就不会执行$hexo d命令后出错, 但是部署速度超级慢\n  // repo: git@github.com:Kung-Fu-Master/Kung-Fu-Master.github.io.git\n  branch: master</code></pre><h2 id=\"6-发布到GitHub\"><a href=\"#6-发布到GitHub\" class=\"headerlink\" title=\"6. 发布到GitHub\"></a><strong>6. 发布到GitHub</strong></h2><pre><code>$ hexo g\n$ hexo d</code></pre><p>完成后，就有属于自己的博客了，在github的setting中 可以看到自己的博客地址。</p>\n<pre><code>https://kung-fu-master.github.io</code></pre><p>如果文章没更新, 对于chrome浏览器<br>第一种方法: 可以选择等待一会时间再查看<br>第二种方法: 点击地址栏右侧的菜单按钮-&gt;更多工具-&gt;清除浏览数据-&gt;清除数据 再刷新就可看到文章已更新  </p>\n<h2 id=\"7-配置评论系统\"><a href=\"#7-配置评论系统\" class=\"headerlink\" title=\"7. 配置评论系统\"></a><strong>7. 配置评论系统</strong></h2><p>目前 3-hexo 已经集成了评论系统有 gitalk 、gitment、 disqus 、来必力、utteranc  </p>\n<p>7.1 登录 github ，注册应用<br><a href=\"https://github.com/settings/applications/new\" target=\"_blank\" rel=\"noopener\">点击进行注册</a><br><img src=\"registry_gitalk.PNG\" alt=\"\"><br>注册完后，可得到 <code>Client ID</code> 和 <code>Client Secret</code>.  </p>\n<p>7.2 因为 gitalk 是基于 Github 的 Issue 的，所以需要指定一个仓库，用来承接 gitalk 的评论，我们一般使用 Github Page 来做我们博客的评论，所以，新建仓库名为 xxx.github.io，其中 xxx 为你的 Github 用户名<br>gitalk官网: <a href=\"https://gitalk.github.io/\" target=\"_blank\" rel=\"noopener\">https://gitalk.github.io/</a></p>\n<p>7.3 配置主题<br>在主题下 _config.yml 中找到如下配置，启用评论，并使用 gitalk.  </p>\n<pre><code>########## 评论设置 #############\ncomment:\n  on: true\n  type: gitalk</code></pre><p>在主题下 _config.yml 中找到 gitalk 配置，将 第 1 步 得到的 Client ID 和 Client Secret 复制到如下位置</p>\n<pre><code>gitalk:\n  githubID:    # 填你的 github 用户名\n  repo:  xxx.github.io     # 承载评论的仓库，一般使用 Github Page 仓库\n  ClientID:   # 第 7.1 步获得 Client ID\n  ClientSecret:  # 第 7.1 步获得 Client Secret\n  adminUser:     # Github 用户名\n  distractionFreeMode: true\n  language: zh-CN\n  perPage: 10</code></pre><h2 id=\"8-开启字数统计\"><a href=\"#8-开启字数统计\" class=\"headerlink\" title=\"8. 开启字数统计\"></a><strong>8. 开启字数统计</strong></h2><p>开启此功能需先安装插件，在 hexo 根目录(博客的目录,没有package.json文件的话会自动生成), 执行 <code>$ npm i hexo-wordcount --save</code><br>修改 _config.yml</p>\n<pre><code>word_count: true</code></pre><h2 id=\"写博客、发布文章\"><a href=\"#写博客、发布文章\" class=\"headerlink\" title=\"写博客、发布文章\"></a><strong>写博客、发布文章</strong></h2><p>新建一篇博客，执行下面的命令, 或者自己手动创建*.md文件, 后缀名一定要是”.md”.</p>\n<pre><code>$ hexo new post &quot;article title&quot;</code></pre><p><img src=\"deploy.jpg\" alt=\"\"><br>\\source\\ _posts 将会看到 article title.md 文件</p>\n<p>用MarDown编辑器打开就可以编辑文章了。文章编辑好之后，运行生成、部署命令:  </p>\n<pre><code>$ hexo g   // 生成\n$ hexo d   // 部署</code></pre><p>当然你也可以执行下面的命令，相当于上面两条命令的效果</p>\n<pre><code>$ hexo d -g #在部署前先生成</code></pre><p>部署成功后访问 你的地址，<a href=\"https://yourName.github.io\" target=\"_blank\" rel=\"noopener\">https://yourName.github.io</a> (这里输入我的地址:<a href=\"https://Kung-Fu-Master.github.io\">https://Kung-Fu-Master.github.io</a>), 将可以看到生成的文章。</p>\n<h2 id=\"踩坑提醒\"><a href=\"#踩坑提醒\" class=\"headerlink\" title=\"踩坑提醒\"></a><strong>踩坑提醒</strong></h2><ol>\n<li>注意需要提前安装一个扩展：</li>\n</ol>\n<pre><code>$ npm install hexo-deployer-git --save</code></pre><p>如果没有执行者行命令，将会提醒</p>\n<pre><code>$ deloyer not found:git</code></pre><ol start=\"2\">\n<li>如果出现下面这样的错误</li>\n</ol>\n<p>Permission denied (publickey).<br>fatal: Could not read from remote repository.<br>Please make sure you have the correct access rights<br>and the repository exists.</p>\n<p>则是因为没有设置好public key所致。<br>在本机生成public key,不懂的可以参考我的这一篇博客Git ssh 配置及使用  </p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"1-确认电脑安装过git\"><a href=\"#1-确认电脑安装过git\" class=\"headerlink\" title=\"1. 确认电脑安装过git\"></a><strong>1. 确认电脑安装过git</strong></h2><pre><code>鼠标右击有git gui和git bash选项，随便新建一个文件夹，进入。</code></pre><h2 id=\"2-以管理员身份打开cmd，-cd到当前目录\"><a href=\"#2-以管理员身份打开cmd，-cd到当前目录\" class=\"headerlink\" title=\"2. 以管理员身份打开cmd， cd到当前目录\"></a><strong>2. 以管理员身份打开cmd， cd到当前目录</strong></h2><pre><code>1. #npm install -g hexo-cli\n2. #npm install hexo-deployer-git --save\n3. #hexo init\n在public目录下可看到我们自己书写的博客文档（.md文件）</code></pre><h2 id=\"3-生成网页浏览\"><a href=\"#3-生成网页浏览\" class=\"headerlink\" title=\"3. 生成网页浏览\"></a><strong>3. 生成网页浏览</strong></h2><pre><code>$ hexo g\n默认地址是 localhost:4000, 浏览器输入此链接即可看到默认样式</code></pre><h2 id=\"4-选择主题，Hexo可随时使用、更换博客主题\"><a href=\"#4-选择主题，Hexo可随时使用、更换博客主题\" class=\"headerlink\" title=\"4. 选择主题，Hexo可随时使用、更换博客主题\"></a><strong>4. 选择主题，Hexo可随时使用、更换博客主题</strong></h2><p>Hexo官方主题网页<br>其中一个主题  </p>\n<pre><code>$ git clone https://github.com/yelog/hexo-theme-3-hexo.git themes/3-hexo</code></pre><p>下载项目至博客项目下的themes目录中，文件夹命名为3-hexo，并在博客配置文件_config.yml中指定使用该主题：<br>修改hexo根目录的_config.yml文件，如下  </p>\n<pre><code>theme: 3-hexo</code></pre><p>更新:</p>\n<pre><code>$ cd themes/3-hexo\n$ git pull</code></pre><h2 id=\"5-配置SSH密钥\"><a href=\"#5-配置SSH密钥\" class=\"headerlink\" title=\"5. 配置SSH密钥\"></a><strong>5. 配置SSH密钥</strong></h2><pre><code>$ ssh-keygen -t rsa -C &quot;1041618918@qq.com&quot;\n$ cat ~/.ssh/id_rsa.pub                    //C:\\Users\\yazhanma\\.ssh\\id_rsa.pub</code></pre><p>复制内容添加到github -&gt;settings-&gt;SSH and GPG keys-&gt; add SSH key, 名字随便取.<br>此时安装网上说的测试命令#ssh -T <a href=\"mailto:git@github.com\">git@github.com</a>是否能连接上，自己试了试不行仍然time out，但是不影响估计是得等一段时间才行，仍然继续下面步骤部署成功.<br>修改博客配置文件_config.yml  </p>\n<pre><code>deploy:\n  type: git\n  repo: https://github.com/Kung-Fu-Master/Kung-Fu-Master.github.io\n  // 如果执行$hexo d后出现一个错误但还是部署成功, 可以将路径改成以下ssh格式就不会执行$hexo d命令后出错, 但是部署速度超级慢\n  // repo: git@github.com:Kung-Fu-Master/Kung-Fu-Master.github.io.git\n  branch: master</code></pre><h2 id=\"6-发布到GitHub\"><a href=\"#6-发布到GitHub\" class=\"headerlink\" title=\"6. 发布到GitHub\"></a><strong>6. 发布到GitHub</strong></h2><pre><code>$ hexo g\n$ hexo d</code></pre><p>完成后，就有属于自己的博客了，在github的setting中 可以看到自己的博客地址。</p>\n<pre><code>https://kung-fu-master.github.io</code></pre><p>如果文章没更新, 对于chrome浏览器<br>第一种方法: 可以选择等待一会时间再查看<br>第二种方法: 点击地址栏右侧的菜单按钮-&gt;更多工具-&gt;清除浏览数据-&gt;清除数据 再刷新就可看到文章已更新  </p>\n<h2 id=\"7-配置评论系统\"><a href=\"#7-配置评论系统\" class=\"headerlink\" title=\"7. 配置评论系统\"></a><strong>7. 配置评论系统</strong></h2><p>目前 3-hexo 已经集成了评论系统有 gitalk 、gitment、 disqus 、来必力、utteranc  </p>\n<p>7.1 登录 github ，注册应用<br><a href=\"https://github.com/settings/applications/new\" target=\"_blank\" rel=\"noopener\">点击进行注册</a><br><img src=\"registry_gitalk.PNG\" alt=\"\"><br>注册完后，可得到 <code>Client ID</code> 和 <code>Client Secret</code>.  </p>\n<p>7.2 因为 gitalk 是基于 Github 的 Issue 的，所以需要指定一个仓库，用来承接 gitalk 的评论，我们一般使用 Github Page 来做我们博客的评论，所以，新建仓库名为 xxx.github.io，其中 xxx 为你的 Github 用户名<br>gitalk官网: <a href=\"https://gitalk.github.io/\" target=\"_blank\" rel=\"noopener\">https://gitalk.github.io/</a></p>\n<p>7.3 配置主题<br>在主题下 _config.yml 中找到如下配置，启用评论，并使用 gitalk.  </p>\n<pre><code>########## 评论设置 #############\ncomment:\n  on: true\n  type: gitalk</code></pre><p>在主题下 _config.yml 中找到 gitalk 配置，将 第 1 步 得到的 Client ID 和 Client Secret 复制到如下位置</p>\n<pre><code>gitalk:\n  githubID:    # 填你的 github 用户名\n  repo:  xxx.github.io     # 承载评论的仓库，一般使用 Github Page 仓库\n  ClientID:   # 第 7.1 步获得 Client ID\n  ClientSecret:  # 第 7.1 步获得 Client Secret\n  adminUser:     # Github 用户名\n  distractionFreeMode: true\n  language: zh-CN\n  perPage: 10</code></pre><h2 id=\"8-开启字数统计\"><a href=\"#8-开启字数统计\" class=\"headerlink\" title=\"8. 开启字数统计\"></a><strong>8. 开启字数统计</strong></h2><p>开启此功能需先安装插件，在 hexo 根目录(博客的目录,没有package.json文件的话会自动生成), 执行 <code>$ npm i hexo-wordcount --save</code><br>修改 _config.yml</p>\n<pre><code>word_count: true</code></pre><h2 id=\"写博客、发布文章\"><a href=\"#写博客、发布文章\" class=\"headerlink\" title=\"写博客、发布文章\"></a><strong>写博客、发布文章</strong></h2><p>新建一篇博客，执行下面的命令, 或者自己手动创建*.md文件, 后缀名一定要是”.md”.</p>\n<pre><code>$ hexo new post &quot;article title&quot;</code></pre><p><img src=\"deploy.jpg\" alt=\"\"><br>\\source\\ _posts 将会看到 article title.md 文件</p>\n<p>用MarDown编辑器打开就可以编辑文章了。文章编辑好之后，运行生成、部署命令:  </p>\n<pre><code>$ hexo g   // 生成\n$ hexo d   // 部署</code></pre><p>当然你也可以执行下面的命令，相当于上面两条命令的效果</p>\n<pre><code>$ hexo d -g #在部署前先生成</code></pre><p>部署成功后访问 你的地址，<a href=\"https://yourName.github.io\" target=\"_blank\" rel=\"noopener\">https://yourName.github.io</a> (这里输入我的地址:<a href=\"https://Kung-Fu-Master.github.io\">https://Kung-Fu-Master.github.io</a>), 将可以看到生成的文章。</p>\n<h2 id=\"踩坑提醒\"><a href=\"#踩坑提醒\" class=\"headerlink\" title=\"踩坑提醒\"></a><strong>踩坑提醒</strong></h2><ol>\n<li>注意需要提前安装一个扩展：</li>\n</ol>\n<pre><code>$ npm install hexo-deployer-git --save</code></pre><p>如果没有执行者行命令，将会提醒</p>\n<pre><code>$ deloyer not found:git</code></pre><ol start=\"2\">\n<li>如果出现下面这样的错误</li>\n</ol>\n<p>Permission denied (publickey).<br>fatal: Could not read from remote repository.<br>Please make sure you have the correct access rights<br>and the repository exists.</p>\n<p>则是因为没有设置好public key所致。<br>在本机生成public key,不懂的可以参考我的这一篇博客Git ssh 配置及使用  </p>\n"},{"title":"Hexo 02 git clone blog后如何运行","_content":"\n## **1. 确保系统已安装node.js, git工具**\n\n## **2. cmd管理员身份进入git clone下来的文件夹**\n\n\t$ cd ...\\blogs_backup\\blogs\n\t$ npm install hexo-deployer-git --save\n## **3. 生成部署博客**\n\n\t$ hexo g    //generate，md生成html\n\t$ hexo s    //start，开启服务, 网页上输入http://localhost:4000 即可查看\n添加***.md文件后\n\n\t#hexo d        //deploy部署，中途需要输入账号密码, 稍等一会即可chrome网页上输入https://Kung-Fu-Master.github.io 查看\n但是此时新添加的.md文件没有上传到blogs_backup git仓库中，需要打开git bash, git add这个.md文件再git commit -m \"add new .md\", git push, 完成blogs_backup仓库的更新.\n\n## **免密 $hexo d 方法**\n### **第一种, 亲测**\ngit bash终端 cd 到博客副本文件夹, 输入: $git config --global credential.helper store  \n接下来 $git push 需要输入密码，以后 $git push 就不用了, 然后 $hexo d 也就不需要了  \n\n原因是执行 $git config --global credential.helper store 后会创建文件 C:\\Users\\hp\\.git-credentials(Windows系统下)  \n里面内容: https://git账户名:登陆git密码@github.com  \n### **第二种, 网上**\n创建文件 C:\\Users\\hp\\.git-credentials 并添加内容 https://{username}:{password}@github.com\n添加git config内容\n\n\t$git config --global credential.helper store\n执行此命令后，用户主目录下(C:\\Users\\hp\\)的.gitconfig文件会多了一项：[credential]\n\n\thelper = store\n重新git push就不需要用户名密码了\n\n","source":"_posts/blogs/Hexo_02_git_clone_blog后如何运行 - 副本.md","raw":"---\ntitle: Hexo 02 git clone blog后如何运行\ntags:\ncategories:\n- blogs\n---\n\n## **1. 确保系统已安装node.js, git工具**\n\n## **2. cmd管理员身份进入git clone下来的文件夹**\n\n\t$ cd ...\\blogs_backup\\blogs\n\t$ npm install hexo-deployer-git --save\n## **3. 生成部署博客**\n\n\t$ hexo g    //generate，md生成html\n\t$ hexo s    //start，开启服务, 网页上输入http://localhost:4000 即可查看\n添加***.md文件后\n\n\t#hexo d        //deploy部署，中途需要输入账号密码, 稍等一会即可chrome网页上输入https://Kung-Fu-Master.github.io 查看\n但是此时新添加的.md文件没有上传到blogs_backup git仓库中，需要打开git bash, git add这个.md文件再git commit -m \"add new .md\", git push, 完成blogs_backup仓库的更新.\n\n## **免密 $hexo d 方法**\n### **第一种, 亲测**\ngit bash终端 cd 到博客副本文件夹, 输入: $git config --global credential.helper store  \n接下来 $git push 需要输入密码，以后 $git push 就不用了, 然后 $hexo d 也就不需要了  \n\n原因是执行 $git config --global credential.helper store 后会创建文件 C:\\Users\\hp\\.git-credentials(Windows系统下)  \n里面内容: https://git账户名:登陆git密码@github.com  \n### **第二种, 网上**\n创建文件 C:\\Users\\hp\\.git-credentials 并添加内容 https://{username}:{password}@github.com\n添加git config内容\n\n\t$git config --global credential.helper store\n执行此命令后，用户主目录下(C:\\Users\\hp\\)的.gitconfig文件会多了一项：[credential]\n\n\thelper = store\n重新git push就不需要用户名密码了\n\n","slug":"blogs/Hexo_02_git_clone_blog后如何运行 - 副本","published":1,"date":"2020-08-12T16:05:44.376Z","updated":"2020-08-12T12:08:32.334Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmbn0005hohx7y423oqe","content":"<h2 id=\"1-确保系统已安装node-js-git工具\"><a href=\"#1-确保系统已安装node-js-git工具\" class=\"headerlink\" title=\"1. 确保系统已安装node.js, git工具\"></a><strong>1. 确保系统已安装node.js, git工具</strong></h2><h2 id=\"2-cmd管理员身份进入git-clone下来的文件夹\"><a href=\"#2-cmd管理员身份进入git-clone下来的文件夹\" class=\"headerlink\" title=\"2. cmd管理员身份进入git clone下来的文件夹\"></a><strong>2. cmd管理员身份进入git clone下来的文件夹</strong></h2><pre><code>$ cd ...\\blogs_backup\\blogs\n$ npm install hexo-deployer-git --save</code></pre><h2 id=\"3-生成部署博客\"><a href=\"#3-生成部署博客\" class=\"headerlink\" title=\"3. 生成部署博客\"></a><strong>3. 生成部署博客</strong></h2><pre><code>$ hexo g    //generate，md生成html\n$ hexo s    //start，开启服务, 网页上输入http://localhost:4000 即可查看</code></pre><p>添加***.md文件后</p>\n<pre><code>#hexo d        //deploy部署，中途需要输入账号密码, 稍等一会即可chrome网页上输入https://Kung-Fu-Master.github.io 查看</code></pre><p>但是此时新添加的.md文件没有上传到blogs_backup git仓库中，需要打开git bash, git add这个.md文件再git commit -m “add new .md”, git push, 完成blogs_backup仓库的更新.</p>\n<h2 id=\"免密-hexo-d-方法\"><a href=\"#免密-hexo-d-方法\" class=\"headerlink\" title=\"免密 $hexo d 方法\"></a><strong>免密 $hexo d 方法</strong></h2><h3 id=\"第一种-亲测\"><a href=\"#第一种-亲测\" class=\"headerlink\" title=\"第一种, 亲测\"></a><strong>第一种, 亲测</strong></h3><p>git bash终端 cd 到博客副本文件夹, 输入: $git config –global credential.helper store<br>接下来 $git push 需要输入密码，以后 $git push 就不用了, 然后 $hexo d 也就不需要了  </p>\n<p>原因是执行 $git config –global credential.helper store 后会创建文件 C:\\Users\\hp.git-credentials(Windows系统下)<br>里面内容: <a href=\"https://git账户名:登陆git密码@github.com\" target=\"_blank\" rel=\"noopener\">https://git账户名:登陆git密码@github.com</a>  </p>\n<h3 id=\"第二种-网上\"><a href=\"#第二种-网上\" class=\"headerlink\" title=\"第二种, 网上\"></a><strong>第二种, 网上</strong></h3><p>创建文件 C:\\Users\\hp.git-credentials 并添加内容 https://{username}:{password}@github.com<br>添加git config内容</p>\n<pre><code>$git config --global credential.helper store</code></pre><p>执行此命令后，用户主目录下(C:\\Users\\hp)的.gitconfig文件会多了一项：[credential]</p>\n<pre><code>helper = store</code></pre><p>重新git push就不需要用户名密码了</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"1-确保系统已安装node-js-git工具\"><a href=\"#1-确保系统已安装node-js-git工具\" class=\"headerlink\" title=\"1. 确保系统已安装node.js, git工具\"></a><strong>1. 确保系统已安装node.js, git工具</strong></h2><h2 id=\"2-cmd管理员身份进入git-clone下来的文件夹\"><a href=\"#2-cmd管理员身份进入git-clone下来的文件夹\" class=\"headerlink\" title=\"2. cmd管理员身份进入git clone下来的文件夹\"></a><strong>2. cmd管理员身份进入git clone下来的文件夹</strong></h2><pre><code>$ cd ...\\blogs_backup\\blogs\n$ npm install hexo-deployer-git --save</code></pre><h2 id=\"3-生成部署博客\"><a href=\"#3-生成部署博客\" class=\"headerlink\" title=\"3. 生成部署博客\"></a><strong>3. 生成部署博客</strong></h2><pre><code>$ hexo g    //generate，md生成html\n$ hexo s    //start，开启服务, 网页上输入http://localhost:4000 即可查看</code></pre><p>添加***.md文件后</p>\n<pre><code>#hexo d        //deploy部署，中途需要输入账号密码, 稍等一会即可chrome网页上输入https://Kung-Fu-Master.github.io 查看</code></pre><p>但是此时新添加的.md文件没有上传到blogs_backup git仓库中，需要打开git bash, git add这个.md文件再git commit -m “add new .md”, git push, 完成blogs_backup仓库的更新.</p>\n<h2 id=\"免密-hexo-d-方法\"><a href=\"#免密-hexo-d-方法\" class=\"headerlink\" title=\"免密 $hexo d 方法\"></a><strong>免密 $hexo d 方法</strong></h2><h3 id=\"第一种-亲测\"><a href=\"#第一种-亲测\" class=\"headerlink\" title=\"第一种, 亲测\"></a><strong>第一种, 亲测</strong></h3><p>git bash终端 cd 到博客副本文件夹, 输入: $git config –global credential.helper store<br>接下来 $git push 需要输入密码，以后 $git push 就不用了, 然后 $hexo d 也就不需要了  </p>\n<p>原因是执行 $git config –global credential.helper store 后会创建文件 C:\\Users\\hp.git-credentials(Windows系统下)<br>里面内容: <a href=\"https://git账户名:登陆git密码@github.com\" target=\"_blank\" rel=\"noopener\">https://git账户名:登陆git密码@github.com</a>  </p>\n<h3 id=\"第二种-网上\"><a href=\"#第二种-网上\" class=\"headerlink\" title=\"第二种, 网上\"></a><strong>第二种, 网上</strong></h3><p>创建文件 C:\\Users\\hp.git-credentials 并添加内容 https://{username}:{password}@github.com<br>添加git config内容</p>\n<pre><code>$git config --global credential.helper store</code></pre><p>执行此命令后，用户主目录下(C:\\Users\\hp)的.gitconfig文件会多了一项：[credential]</p>\n<pre><code>helper = store</code></pre><p>重新git push就不需要用户名密码了</p>\n"},{"title":"Hexo 03 写博客语法","_content":"\n## **表格**\n\n| 左对齐 | 右对齐 | 居中对齐 |\n| :------| -----: | :------: |\n| 单元格 | 单元格 | 单元格 |\n| 单元格 | 单元格 | 单元格 |\n\n## 内容\n\n\t添加内容\n1","source":"_posts/blogs/Hexo_03_写博客语法.md","raw":"---\ntitle: Hexo 03 写博客语法\ntags:\ncategories:\n- blogs\n---\n\n## **表格**\n\n| 左对齐 | 右对齐 | 居中对齐 |\n| :------| -----: | :------: |\n| 单元格 | 单元格 | 单元格 |\n| 单元格 | 单元格 | 单元格 |\n\n## 内容\n\n\t添加内容\n1","slug":"blogs/Hexo_03_写博客语法","published":1,"date":"2020-08-12T16:05:44.378Z","updated":"2020-08-12T16:13:51.718Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmbo0006hohx0f6n1cql","content":"<h2 id=\"表格\"><a href=\"#表格\" class=\"headerlink\" title=\"表格\"></a><strong>表格</strong></h2><table>\n<thead>\n<tr>\n<th align=\"left\">左对齐</th>\n<th align=\"right\">右对齐</th>\n<th align=\"center\">居中对齐</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">单元格</td>\n<td align=\"right\">单元格</td>\n<td align=\"center\">单元格</td>\n</tr>\n<tr>\n<td align=\"left\">单元格</td>\n<td align=\"right\">单元格</td>\n<td align=\"center\">单元格</td>\n</tr>\n</tbody></table>\n<h2 id=\"内容\"><a href=\"#内容\" class=\"headerlink\" title=\"内容\"></a>内容</h2><pre><code>添加内容</code></pre><p>1</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"表格\"><a href=\"#表格\" class=\"headerlink\" title=\"表格\"></a><strong>表格</strong></h2><table>\n<thead>\n<tr>\n<th align=\"left\">左对齐</th>\n<th align=\"right\">右对齐</th>\n<th align=\"center\">居中对齐</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">单元格</td>\n<td align=\"right\">单元格</td>\n<td align=\"center\">单元格</td>\n</tr>\n<tr>\n<td align=\"left\">单元格</td>\n<td align=\"right\">单元格</td>\n<td align=\"center\">单元格</td>\n</tr>\n</tbody></table>\n<h2 id=\"内容\"><a href=\"#内容\" class=\"headerlink\" title=\"内容\"></a>内容</h2><pre><code>添加内容</code></pre><p>1</p>\n"},{"title":"Learning Links","_content":"\n## 目前接触到的各种Learn视频网站  \n\tCSDN学院: https://edu.csdn.net/  \n\t黑马程序员: http://www.itheima.com/ or http://yun.itheima.com/?pc&hm  //提供很多免费课程  \n\t传智播客: http://www.itcast.cn/  \n\tphp中文网: https://www.php.cn/  提供很多免费课程\n\t慕课网: https://www.imooc.com/  \n\n## 博客or文档Learn\n\tw3school在线教程: https://www.w3school.com.cn/\n\t\t在线编写测试HTML代码: https://www.w3school.com.cn/tiy/t.asp?f=html_div_test\n\t\t\n\tC语言中文网: http://c.biancheng.net/\n\t\n\t菜鸟教程: https://www.runoob.com/  \n\n## MDN\n\thttps://developer.mozilla.org/zh-CN/  \n\n## Web前端  \n### NodeJS\n\t网址: https://nodejs.org\n\t中文网址:http://nodejs.cn/  \n\t\n\tnpm说明文档网址(查各种node_modules源码和使用说明): https://www.npmjs.com/  \n\t\n\t模拟 NodeJS 单线程但又是异步执行情况的网址: http://latentflip.com/loupe/  \n\t\n### AngularJS\n\tchrome 浏览器打开: https://angularjs.org/ 网站下载免解压或压缩版  \n\tGihub: https://github.com/angular/angular.js/releases  \n\n## 需要加别人QQ获取资源\n\thttp://www.itjcw123.cn/  \n\thttp://19r9qt.coding-pages.com/categories/  \n\n\n## 免费在线作图, 实时协作\nXmind官网地址： https://www.xmind.cn\nProcessOn在线作图地址：https://www.processon.com\n\n","source":"_posts/links/Learning_links.md","raw":"---\ntitle: Learning Links\ntags:\ncategories:\n- LearnLinks\n---\n\n## 目前接触到的各种Learn视频网站  \n\tCSDN学院: https://edu.csdn.net/  \n\t黑马程序员: http://www.itheima.com/ or http://yun.itheima.com/?pc&hm  //提供很多免费课程  \n\t传智播客: http://www.itcast.cn/  \n\tphp中文网: https://www.php.cn/  提供很多免费课程\n\t慕课网: https://www.imooc.com/  \n\n## 博客or文档Learn\n\tw3school在线教程: https://www.w3school.com.cn/\n\t\t在线编写测试HTML代码: https://www.w3school.com.cn/tiy/t.asp?f=html_div_test\n\t\t\n\tC语言中文网: http://c.biancheng.net/\n\t\n\t菜鸟教程: https://www.runoob.com/  \n\n## MDN\n\thttps://developer.mozilla.org/zh-CN/  \n\n## Web前端  \n### NodeJS\n\t网址: https://nodejs.org\n\t中文网址:http://nodejs.cn/  \n\t\n\tnpm说明文档网址(查各种node_modules源码和使用说明): https://www.npmjs.com/  \n\t\n\t模拟 NodeJS 单线程但又是异步执行情况的网址: http://latentflip.com/loupe/  \n\t\n### AngularJS\n\tchrome 浏览器打开: https://angularjs.org/ 网站下载免解压或压缩版  \n\tGihub: https://github.com/angular/angular.js/releases  \n\n## 需要加别人QQ获取资源\n\thttp://www.itjcw123.cn/  \n\thttp://19r9qt.coding-pages.com/categories/  \n\n\n## 免费在线作图, 实时协作\nXmind官网地址： https://www.xmind.cn\nProcessOn在线作图地址：https://www.processon.com\n\n","slug":"links/Learning_links","published":1,"date":"2020-08-12T16:05:45.939Z","updated":"2020-04-24T03:03:56.506Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmbp0008hohx6jwl8zjf","content":"<h2 id=\"目前接触到的各种Learn视频网站\"><a href=\"#目前接触到的各种Learn视频网站\" class=\"headerlink\" title=\"目前接触到的各种Learn视频网站\"></a>目前接触到的各种Learn视频网站</h2><pre><code>CSDN学院: https://edu.csdn.net/  \n黑马程序员: http://www.itheima.com/ or http://yun.itheima.com/?pc&amp;hm  //提供很多免费课程  \n传智播客: http://www.itcast.cn/  \nphp中文网: https://www.php.cn/  提供很多免费课程\n慕课网: https://www.imooc.com/  </code></pre><h2 id=\"博客or文档Learn\"><a href=\"#博客or文档Learn\" class=\"headerlink\" title=\"博客or文档Learn\"></a>博客or文档Learn</h2><pre><code>w3school在线教程: https://www.w3school.com.cn/\n    在线编写测试HTML代码: https://www.w3school.com.cn/tiy/t.asp?f=html_div_test\n\nC语言中文网: http://c.biancheng.net/\n\n菜鸟教程: https://www.runoob.com/  </code></pre><h2 id=\"MDN\"><a href=\"#MDN\" class=\"headerlink\" title=\"MDN\"></a>MDN</h2><pre><code>https://developer.mozilla.org/zh-CN/  </code></pre><h2 id=\"Web前端\"><a href=\"#Web前端\" class=\"headerlink\" title=\"Web前端\"></a>Web前端</h2><h3 id=\"NodeJS\"><a href=\"#NodeJS\" class=\"headerlink\" title=\"NodeJS\"></a>NodeJS</h3><pre><code>网址: https://nodejs.org\n中文网址:http://nodejs.cn/  \n\nnpm说明文档网址(查各种node_modules源码和使用说明): https://www.npmjs.com/  \n\n模拟 NodeJS 单线程但又是异步执行情况的网址: http://latentflip.com/loupe/  </code></pre><h3 id=\"AngularJS\"><a href=\"#AngularJS\" class=\"headerlink\" title=\"AngularJS\"></a>AngularJS</h3><pre><code>chrome 浏览器打开: https://angularjs.org/ 网站下载免解压或压缩版  \nGihub: https://github.com/angular/angular.js/releases  </code></pre><h2 id=\"需要加别人QQ获取资源\"><a href=\"#需要加别人QQ获取资源\" class=\"headerlink\" title=\"需要加别人QQ获取资源\"></a>需要加别人QQ获取资源</h2><pre><code>http://www.itjcw123.cn/  \nhttp://19r9qt.coding-pages.com/categories/  </code></pre><h2 id=\"免费在线作图-实时协作\"><a href=\"#免费在线作图-实时协作\" class=\"headerlink\" title=\"免费在线作图, 实时协作\"></a>免费在线作图, 实时协作</h2><p>Xmind官网地址： <a href=\"https://www.xmind.cn\" target=\"_blank\" rel=\"noopener\">https://www.xmind.cn</a><br>ProcessOn在线作图地址：<a href=\"https://www.processon.com\" target=\"_blank\" rel=\"noopener\">https://www.processon.com</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"目前接触到的各种Learn视频网站\"><a href=\"#目前接触到的各种Learn视频网站\" class=\"headerlink\" title=\"目前接触到的各种Learn视频网站\"></a>目前接触到的各种Learn视频网站</h2><pre><code>CSDN学院: https://edu.csdn.net/  \n黑马程序员: http://www.itheima.com/ or http://yun.itheima.com/?pc&amp;hm  //提供很多免费课程  \n传智播客: http://www.itcast.cn/  \nphp中文网: https://www.php.cn/  提供很多免费课程\n慕课网: https://www.imooc.com/  </code></pre><h2 id=\"博客or文档Learn\"><a href=\"#博客or文档Learn\" class=\"headerlink\" title=\"博客or文档Learn\"></a>博客or文档Learn</h2><pre><code>w3school在线教程: https://www.w3school.com.cn/\n    在线编写测试HTML代码: https://www.w3school.com.cn/tiy/t.asp?f=html_div_test\n\nC语言中文网: http://c.biancheng.net/\n\n菜鸟教程: https://www.runoob.com/  </code></pre><h2 id=\"MDN\"><a href=\"#MDN\" class=\"headerlink\" title=\"MDN\"></a>MDN</h2><pre><code>https://developer.mozilla.org/zh-CN/  </code></pre><h2 id=\"Web前端\"><a href=\"#Web前端\" class=\"headerlink\" title=\"Web前端\"></a>Web前端</h2><h3 id=\"NodeJS\"><a href=\"#NodeJS\" class=\"headerlink\" title=\"NodeJS\"></a>NodeJS</h3><pre><code>网址: https://nodejs.org\n中文网址:http://nodejs.cn/  \n\nnpm说明文档网址(查各种node_modules源码和使用说明): https://www.npmjs.com/  \n\n模拟 NodeJS 单线程但又是异步执行情况的网址: http://latentflip.com/loupe/  </code></pre><h3 id=\"AngularJS\"><a href=\"#AngularJS\" class=\"headerlink\" title=\"AngularJS\"></a>AngularJS</h3><pre><code>chrome 浏览器打开: https://angularjs.org/ 网站下载免解压或压缩版  \nGihub: https://github.com/angular/angular.js/releases  </code></pre><h2 id=\"需要加别人QQ获取资源\"><a href=\"#需要加别人QQ获取资源\" class=\"headerlink\" title=\"需要加别人QQ获取资源\"></a>需要加别人QQ获取资源</h2><pre><code>http://www.itjcw123.cn/  \nhttp://19r9qt.coding-pages.com/categories/  </code></pre><h2 id=\"免费在线作图-实时协作\"><a href=\"#免费在线作图-实时协作\" class=\"headerlink\" title=\"免费在线作图, 实时协作\"></a>免费在线作图, 实时协作</h2><p>Xmind官网地址： <a href=\"https://www.xmind.cn\" target=\"_blank\" rel=\"noopener\">https://www.xmind.cn</a><br>ProcessOn在线作图地址：<a href=\"https://www.processon.com\" target=\"_blank\" rel=\"noopener\">https://www.processon.com</a></p>\n"},{"title":"Restful API","_content":"\n## Rest\n> REST，即Representational State Transfer的缩写。直接翻译的意思是\"表现层状态转化\"。\n它是一种互联网应用程序的API设计理念：URL定位资源，用HTTP动词（GET,POST,DELETE,DETC）描述操作。\n> REST描述了一个架构样式的网络系统，比如 web 应用程序。它首次出现在 2000 年 Roy Fielding 的博士论文中，Roy Fielding是 HTTP 规范的主要编写者之一。在目前主流的三种Web服务交互方案中，REST相比于SOAP（Simple Object Access protocol，简单对象访问协议）以及XML-RPC更加简单明了，无论是对URL的处理还是对Payload的编码，REST都倾向于用更加简单轻量的方法设计和实现。值得注意的是REST并没有一个明确的标准，而更像是一种设计的风格。\n\n### 产生背景\n> 近年来移动互联网的发展，前端设备层出不穷（手机、平板、桌面电脑、其他专用设备......），因此，必须有一种统一的机制，方便不同的前端设备与后端进行通信,于是RESTful诞生了，它可以通过一套统一的接口为 Web，iOS和Android提供服务。\n![](Restful.png)\n\n### URI\n> 即统一资源标识符，服务器上每一种资源，比如文档、图像、视频片段、程序 都由一个通用资源标识符（Uniform Resource Identifier, 简称\"URI\"）进行定位。\n\n### HTTP动词\n常用的HTTP动词有下面五个\n * GET（SELECT）：从服务器取出资源（一项或多项）。\n * POST（CREATE）：在服务器新建一个资源。\n * PUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源）。\n * PATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性）。\n * DELETE（DELETE）：从服务器删除资源。\n\n### RESTful架构\n> RESTful架构是对MVC架构改进后所形成的一种架构，通过使用事先定义好的接口与不同的服务联系起来。在RESTful架构中，浏览器使用POST，DELETE，PUT和GET四种请求方式分别对指定的URL资源进行增删改查操作。因此，RESTful是通过URI实现对资源的管理及访问，具有扩展性强、结构清晰的特点。\n\n> 服务器上每一种资源，比如一个文件，一张图片，一部电影，都有对应的url地址，如果我们的客户端需要对服务器上的这个资源进行操作，就需要通过http协议执行相应的动作来操作它，比如进行获取，更新，删除。\n简单来说就是url地址中只包含名词表示资源，使用http动词表示动作进行操作资源\n举个例子：左边是错误的设计，而右边是正确的\n\n\t GET /blog/getArticles --> GET /blog/Articles  获取所有文章\n\t GET /blog/addArticles --> POST /blog/Articles  添加一篇文章\n\t GET /blog/editArticles --> PUT /blog/Articles  修改一篇文章 \n\t GET /rest/api/deleteArticles?id=1 --> DELETE /blog/Articles/1  删除一篇文章\n\n### 各大平台API为什么不使用restful的风格\n> 这就好象是中文已经用了上千年，突然有几位教授大谈“回字的14种写法”，这只能算是新瓶装旧酒、学究式的文章。一旦媒体不忽悠了，也就过气了。而媒体关注了几个月之后，关注点已经放到云、大数据等等明显是更长久、更工程化的概念上了，懒得对小伎俩去宣传了。\n> 那个东西除了平白无故地额外多出来规定，没有什么发明技术含量的东西（不能被大企业用来衍生出自己的专利技术），因此不可能成为工业标准，充其量是叫兽用用。\n> 其实所谓的 restful 更适合那些总想着沽名钓誉的硕士研究生们去堆砌辞藻，用来体现出自己比其他众多工程技术人员“高人一等”，以避免其它具有更丰富的工程技术的开发人员瞧不起这些人。除此以外，它没有什么实际的技术含量，（正如所看到的）所有实际大项目的工程技术人员都在使用轻量级的web服务方式（从10几年前的电信级的、基于http的远程传输应用就是，人家根本不用webservice）。基本上都是初学者或者大学老师在纠结于繁琐的web服务里边“如何规范名词儿”的问题。\n\n> 核心问题在于RESTful API设计，容易思考，但是不适合实际使用。\n> 这个，就和设计网络协议一样，七层网络模型，理解很给力，实际还是采用四层网络模型一样。\n> 基于RESTful API理解很好理解，但是会严重增加不必要的网络传输消耗。实际使用，基于较少网络消耗较少数据连接的考虑，会更加贴近实际业务场景的API设计，至于DELETE，PUT之类的，不是不愿意使用，是需要对现有业务进行大量不必要的改造，而这种改造，完成是没有必要的。\n\n### 原则\n> REST 指的是一组架构约束条件和原则。满足这些约束条件和原则的应用程序或设计就是 RESTful。\n\n> Web 应用程序最重要的 REST 原则是，客户端和服务器之间的交互在请求之间是无状态的。从客户端到服务器的每个请求都必须包含理解请求所必需的信息。如果服务器在请求之间的任何时间点重启，客户端不会得到通知。此外，无状态请求可以由任何可用服务器回答，这十分适合云计算之类的环境。客户端可以缓存数据以改进性能。\n\n> 在服务器端，应用程序状态和功能可以分为各种资源。资源是一个有趣的概念实体，它向客户端公开。资源的例子有：应用程序对象、数据库记录、算法等等。每个资源都使用 URI (Universal Resource Identifier) 得到一个唯一的地址。所有资源都共享统一的接口，以便在客户端和服务器之间传输状态。使用的是标准的 HTTP 方法，比如 GET、PUT、POST 和 DELETE。Hypermedia 是应用程序状态的引擎，资源表示通过超链接互联。\n\n### 特点\n1、每一个URI代表1种资源；\n2、客户端使用GET、POST、PUT、DELETE4个表示操作方式的动词对服务端资源进行操作：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源；\n3、通过操作资源的表现形式来操作资源；\n4、资源的表现形式是XML或者HTML；\n5、客户端与服务端之间的交互在请求之间是无状态的，从客户端到服务端的每个请求都必须包含理解请求所必需的信息。\n\n\n","source":"_posts/blogs/Restful_API.md","raw":"---\ntitle: Restful API\ntags:\ncategories:\n- blogs\n---\n\n## Rest\n> REST，即Representational State Transfer的缩写。直接翻译的意思是\"表现层状态转化\"。\n它是一种互联网应用程序的API设计理念：URL定位资源，用HTTP动词（GET,POST,DELETE,DETC）描述操作。\n> REST描述了一个架构样式的网络系统，比如 web 应用程序。它首次出现在 2000 年 Roy Fielding 的博士论文中，Roy Fielding是 HTTP 规范的主要编写者之一。在目前主流的三种Web服务交互方案中，REST相比于SOAP（Simple Object Access protocol，简单对象访问协议）以及XML-RPC更加简单明了，无论是对URL的处理还是对Payload的编码，REST都倾向于用更加简单轻量的方法设计和实现。值得注意的是REST并没有一个明确的标准，而更像是一种设计的风格。\n\n### 产生背景\n> 近年来移动互联网的发展，前端设备层出不穷（手机、平板、桌面电脑、其他专用设备......），因此，必须有一种统一的机制，方便不同的前端设备与后端进行通信,于是RESTful诞生了，它可以通过一套统一的接口为 Web，iOS和Android提供服务。\n![](Restful.png)\n\n### URI\n> 即统一资源标识符，服务器上每一种资源，比如文档、图像、视频片段、程序 都由一个通用资源标识符（Uniform Resource Identifier, 简称\"URI\"）进行定位。\n\n### HTTP动词\n常用的HTTP动词有下面五个\n * GET（SELECT）：从服务器取出资源（一项或多项）。\n * POST（CREATE）：在服务器新建一个资源。\n * PUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源）。\n * PATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性）。\n * DELETE（DELETE）：从服务器删除资源。\n\n### RESTful架构\n> RESTful架构是对MVC架构改进后所形成的一种架构，通过使用事先定义好的接口与不同的服务联系起来。在RESTful架构中，浏览器使用POST，DELETE，PUT和GET四种请求方式分别对指定的URL资源进行增删改查操作。因此，RESTful是通过URI实现对资源的管理及访问，具有扩展性强、结构清晰的特点。\n\n> 服务器上每一种资源，比如一个文件，一张图片，一部电影，都有对应的url地址，如果我们的客户端需要对服务器上的这个资源进行操作，就需要通过http协议执行相应的动作来操作它，比如进行获取，更新，删除。\n简单来说就是url地址中只包含名词表示资源，使用http动词表示动作进行操作资源\n举个例子：左边是错误的设计，而右边是正确的\n\n\t GET /blog/getArticles --> GET /blog/Articles  获取所有文章\n\t GET /blog/addArticles --> POST /blog/Articles  添加一篇文章\n\t GET /blog/editArticles --> PUT /blog/Articles  修改一篇文章 \n\t GET /rest/api/deleteArticles?id=1 --> DELETE /blog/Articles/1  删除一篇文章\n\n### 各大平台API为什么不使用restful的风格\n> 这就好象是中文已经用了上千年，突然有几位教授大谈“回字的14种写法”，这只能算是新瓶装旧酒、学究式的文章。一旦媒体不忽悠了，也就过气了。而媒体关注了几个月之后，关注点已经放到云、大数据等等明显是更长久、更工程化的概念上了，懒得对小伎俩去宣传了。\n> 那个东西除了平白无故地额外多出来规定，没有什么发明技术含量的东西（不能被大企业用来衍生出自己的专利技术），因此不可能成为工业标准，充其量是叫兽用用。\n> 其实所谓的 restful 更适合那些总想着沽名钓誉的硕士研究生们去堆砌辞藻，用来体现出自己比其他众多工程技术人员“高人一等”，以避免其它具有更丰富的工程技术的开发人员瞧不起这些人。除此以外，它没有什么实际的技术含量，（正如所看到的）所有实际大项目的工程技术人员都在使用轻量级的web服务方式（从10几年前的电信级的、基于http的远程传输应用就是，人家根本不用webservice）。基本上都是初学者或者大学老师在纠结于繁琐的web服务里边“如何规范名词儿”的问题。\n\n> 核心问题在于RESTful API设计，容易思考，但是不适合实际使用。\n> 这个，就和设计网络协议一样，七层网络模型，理解很给力，实际还是采用四层网络模型一样。\n> 基于RESTful API理解很好理解，但是会严重增加不必要的网络传输消耗。实际使用，基于较少网络消耗较少数据连接的考虑，会更加贴近实际业务场景的API设计，至于DELETE，PUT之类的，不是不愿意使用，是需要对现有业务进行大量不必要的改造，而这种改造，完成是没有必要的。\n\n### 原则\n> REST 指的是一组架构约束条件和原则。满足这些约束条件和原则的应用程序或设计就是 RESTful。\n\n> Web 应用程序最重要的 REST 原则是，客户端和服务器之间的交互在请求之间是无状态的。从客户端到服务器的每个请求都必须包含理解请求所必需的信息。如果服务器在请求之间的任何时间点重启，客户端不会得到通知。此外，无状态请求可以由任何可用服务器回答，这十分适合云计算之类的环境。客户端可以缓存数据以改进性能。\n\n> 在服务器端，应用程序状态和功能可以分为各种资源。资源是一个有趣的概念实体，它向客户端公开。资源的例子有：应用程序对象、数据库记录、算法等等。每个资源都使用 URI (Universal Resource Identifier) 得到一个唯一的地址。所有资源都共享统一的接口，以便在客户端和服务器之间传输状态。使用的是标准的 HTTP 方法，比如 GET、PUT、POST 和 DELETE。Hypermedia 是应用程序状态的引擎，资源表示通过超链接互联。\n\n### 特点\n1、每一个URI代表1种资源；\n2、客户端使用GET、POST、PUT、DELETE4个表示操作方式的动词对服务端资源进行操作：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源；\n3、通过操作资源的表现形式来操作资源；\n4、资源的表现形式是XML或者HTML；\n5、客户端与服务端之间的交互在请求之间是无状态的，从客户端到服务端的每个请求都必须包含理解请求所必需的信息。\n\n\n","slug":"blogs/Restful_API","published":1,"date":"2020-08-12T16:05:44.388Z","updated":"2020-07-03T07:17:38.331Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmbt0009hohx6njy27x3","content":"<h2 id=\"Rest\"><a href=\"#Rest\" class=\"headerlink\" title=\"Rest\"></a>Rest</h2><blockquote>\n<p>REST，即Representational State Transfer的缩写。直接翻译的意思是”表现层状态转化”。<br>它是一种互联网应用程序的API设计理念：URL定位资源，用HTTP动词（GET,POST,DELETE,DETC）描述操作。<br>REST描述了一个架构样式的网络系统，比如 web 应用程序。它首次出现在 2000 年 Roy Fielding 的博士论文中，Roy Fielding是 HTTP 规范的主要编写者之一。在目前主流的三种Web服务交互方案中，REST相比于SOAP（Simple Object Access protocol，简单对象访问协议）以及XML-RPC更加简单明了，无论是对URL的处理还是对Payload的编码，REST都倾向于用更加简单轻量的方法设计和实现。值得注意的是REST并没有一个明确的标准，而更像是一种设计的风格。</p>\n</blockquote>\n<h3 id=\"产生背景\"><a href=\"#产生背景\" class=\"headerlink\" title=\"产生背景\"></a>产生背景</h3><blockquote>\n<p>近年来移动互联网的发展，前端设备层出不穷（手机、平板、桌面电脑、其他专用设备……），因此，必须有一种统一的机制，方便不同的前端设备与后端进行通信,于是RESTful诞生了，它可以通过一套统一的接口为 Web，iOS和Android提供服务。<br><img src=\"Restful.png\" alt=\"\"></p>\n</blockquote>\n<h3 id=\"URI\"><a href=\"#URI\" class=\"headerlink\" title=\"URI\"></a>URI</h3><blockquote>\n<p>即统一资源标识符，服务器上每一种资源，比如文档、图像、视频片段、程序 都由一个通用资源标识符（Uniform Resource Identifier, 简称”URI”）进行定位。</p>\n</blockquote>\n<h3 id=\"HTTP动词\"><a href=\"#HTTP动词\" class=\"headerlink\" title=\"HTTP动词\"></a>HTTP动词</h3><p>常用的HTTP动词有下面五个</p>\n<ul>\n<li>GET（SELECT）：从服务器取出资源（一项或多项）。</li>\n<li>POST（CREATE）：在服务器新建一个资源。</li>\n<li>PUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源）。</li>\n<li>PATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性）。</li>\n<li>DELETE（DELETE）：从服务器删除资源。</li>\n</ul>\n<h3 id=\"RESTful架构\"><a href=\"#RESTful架构\" class=\"headerlink\" title=\"RESTful架构\"></a>RESTful架构</h3><blockquote>\n<p>RESTful架构是对MVC架构改进后所形成的一种架构，通过使用事先定义好的接口与不同的服务联系起来。在RESTful架构中，浏览器使用POST，DELETE，PUT和GET四种请求方式分别对指定的URL资源进行增删改查操作。因此，RESTful是通过URI实现对资源的管理及访问，具有扩展性强、结构清晰的特点。</p>\n</blockquote>\n<blockquote>\n<p>服务器上每一种资源，比如一个文件，一张图片，一部电影，都有对应的url地址，如果我们的客户端需要对服务器上的这个资源进行操作，就需要通过http协议执行相应的动作来操作它，比如进行获取，更新，删除。<br>简单来说就是url地址中只包含名词表示资源，使用http动词表示动作进行操作资源<br>举个例子：左边是错误的设计，而右边是正确的</p>\n</blockquote>\n<pre><code>GET /blog/getArticles --&gt; GET /blog/Articles  获取所有文章\nGET /blog/addArticles --&gt; POST /blog/Articles  添加一篇文章\nGET /blog/editArticles --&gt; PUT /blog/Articles  修改一篇文章 \nGET /rest/api/deleteArticles?id=1 --&gt; DELETE /blog/Articles/1  删除一篇文章</code></pre><h3 id=\"各大平台API为什么不使用restful的风格\"><a href=\"#各大平台API为什么不使用restful的风格\" class=\"headerlink\" title=\"各大平台API为什么不使用restful的风格\"></a>各大平台API为什么不使用restful的风格</h3><blockquote>\n<p>这就好象是中文已经用了上千年，突然有几位教授大谈“回字的14种写法”，这只能算是新瓶装旧酒、学究式的文章。一旦媒体不忽悠了，也就过气了。而媒体关注了几个月之后，关注点已经放到云、大数据等等明显是更长久、更工程化的概念上了，懒得对小伎俩去宣传了。<br>那个东西除了平白无故地额外多出来规定，没有什么发明技术含量的东西（不能被大企业用来衍生出自己的专利技术），因此不可能成为工业标准，充其量是叫兽用用。<br>其实所谓的 restful 更适合那些总想着沽名钓誉的硕士研究生们去堆砌辞藻，用来体现出自己比其他众多工程技术人员“高人一等”，以避免其它具有更丰富的工程技术的开发人员瞧不起这些人。除此以外，它没有什么实际的技术含量，（正如所看到的）所有实际大项目的工程技术人员都在使用轻量级的web服务方式（从10几年前的电信级的、基于http的远程传输应用就是，人家根本不用webservice）。基本上都是初学者或者大学老师在纠结于繁琐的web服务里边“如何规范名词儿”的问题。</p>\n</blockquote>\n<blockquote>\n<p>核心问题在于RESTful API设计，容易思考，但是不适合实际使用。<br>这个，就和设计网络协议一样，七层网络模型，理解很给力，实际还是采用四层网络模型一样。<br>基于RESTful API理解很好理解，但是会严重增加不必要的网络传输消耗。实际使用，基于较少网络消耗较少数据连接的考虑，会更加贴近实际业务场景的API设计，至于DELETE，PUT之类的，不是不愿意使用，是需要对现有业务进行大量不必要的改造，而这种改造，完成是没有必要的。</p>\n</blockquote>\n<h3 id=\"原则\"><a href=\"#原则\" class=\"headerlink\" title=\"原则\"></a>原则</h3><blockquote>\n<p>REST 指的是一组架构约束条件和原则。满足这些约束条件和原则的应用程序或设计就是 RESTful。</p>\n</blockquote>\n<blockquote>\n<p>Web 应用程序最重要的 REST 原则是，客户端和服务器之间的交互在请求之间是无状态的。从客户端到服务器的每个请求都必须包含理解请求所必需的信息。如果服务器在请求之间的任何时间点重启，客户端不会得到通知。此外，无状态请求可以由任何可用服务器回答，这十分适合云计算之类的环境。客户端可以缓存数据以改进性能。</p>\n</blockquote>\n<blockquote>\n<p>在服务器端，应用程序状态和功能可以分为各种资源。资源是一个有趣的概念实体，它向客户端公开。资源的例子有：应用程序对象、数据库记录、算法等等。每个资源都使用 URI (Universal Resource Identifier) 得到一个唯一的地址。所有资源都共享统一的接口，以便在客户端和服务器之间传输状态。使用的是标准的 HTTP 方法，比如 GET、PUT、POST 和 DELETE。Hypermedia 是应用程序状态的引擎，资源表示通过超链接互联。</p>\n</blockquote>\n<h3 id=\"特点\"><a href=\"#特点\" class=\"headerlink\" title=\"特点\"></a>特点</h3><p>1、每一个URI代表1种资源；<br>2、客户端使用GET、POST、PUT、DELETE4个表示操作方式的动词对服务端资源进行操作：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源；<br>3、通过操作资源的表现形式来操作资源；<br>4、资源的表现形式是XML或者HTML；<br>5、客户端与服务端之间的交互在请求之间是无状态的，从客户端到服务端的每个请求都必须包含理解请求所必需的信息。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Rest\"><a href=\"#Rest\" class=\"headerlink\" title=\"Rest\"></a>Rest</h2><blockquote>\n<p>REST，即Representational State Transfer的缩写。直接翻译的意思是”表现层状态转化”。<br>它是一种互联网应用程序的API设计理念：URL定位资源，用HTTP动词（GET,POST,DELETE,DETC）描述操作。<br>REST描述了一个架构样式的网络系统，比如 web 应用程序。它首次出现在 2000 年 Roy Fielding 的博士论文中，Roy Fielding是 HTTP 规范的主要编写者之一。在目前主流的三种Web服务交互方案中，REST相比于SOAP（Simple Object Access protocol，简单对象访问协议）以及XML-RPC更加简单明了，无论是对URL的处理还是对Payload的编码，REST都倾向于用更加简单轻量的方法设计和实现。值得注意的是REST并没有一个明确的标准，而更像是一种设计的风格。</p>\n</blockquote>\n<h3 id=\"产生背景\"><a href=\"#产生背景\" class=\"headerlink\" title=\"产生背景\"></a>产生背景</h3><blockquote>\n<p>近年来移动互联网的发展，前端设备层出不穷（手机、平板、桌面电脑、其他专用设备……），因此，必须有一种统一的机制，方便不同的前端设备与后端进行通信,于是RESTful诞生了，它可以通过一套统一的接口为 Web，iOS和Android提供服务。<br><img src=\"Restful.png\" alt=\"\"></p>\n</blockquote>\n<h3 id=\"URI\"><a href=\"#URI\" class=\"headerlink\" title=\"URI\"></a>URI</h3><blockquote>\n<p>即统一资源标识符，服务器上每一种资源，比如文档、图像、视频片段、程序 都由一个通用资源标识符（Uniform Resource Identifier, 简称”URI”）进行定位。</p>\n</blockquote>\n<h3 id=\"HTTP动词\"><a href=\"#HTTP动词\" class=\"headerlink\" title=\"HTTP动词\"></a>HTTP动词</h3><p>常用的HTTP动词有下面五个</p>\n<ul>\n<li>GET（SELECT）：从服务器取出资源（一项或多项）。</li>\n<li>POST（CREATE）：在服务器新建一个资源。</li>\n<li>PUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源）。</li>\n<li>PATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性）。</li>\n<li>DELETE（DELETE）：从服务器删除资源。</li>\n</ul>\n<h3 id=\"RESTful架构\"><a href=\"#RESTful架构\" class=\"headerlink\" title=\"RESTful架构\"></a>RESTful架构</h3><blockquote>\n<p>RESTful架构是对MVC架构改进后所形成的一种架构，通过使用事先定义好的接口与不同的服务联系起来。在RESTful架构中，浏览器使用POST，DELETE，PUT和GET四种请求方式分别对指定的URL资源进行增删改查操作。因此，RESTful是通过URI实现对资源的管理及访问，具有扩展性强、结构清晰的特点。</p>\n</blockquote>\n<blockquote>\n<p>服务器上每一种资源，比如一个文件，一张图片，一部电影，都有对应的url地址，如果我们的客户端需要对服务器上的这个资源进行操作，就需要通过http协议执行相应的动作来操作它，比如进行获取，更新，删除。<br>简单来说就是url地址中只包含名词表示资源，使用http动词表示动作进行操作资源<br>举个例子：左边是错误的设计，而右边是正确的</p>\n</blockquote>\n<pre><code>GET /blog/getArticles --&gt; GET /blog/Articles  获取所有文章\nGET /blog/addArticles --&gt; POST /blog/Articles  添加一篇文章\nGET /blog/editArticles --&gt; PUT /blog/Articles  修改一篇文章 \nGET /rest/api/deleteArticles?id=1 --&gt; DELETE /blog/Articles/1  删除一篇文章</code></pre><h3 id=\"各大平台API为什么不使用restful的风格\"><a href=\"#各大平台API为什么不使用restful的风格\" class=\"headerlink\" title=\"各大平台API为什么不使用restful的风格\"></a>各大平台API为什么不使用restful的风格</h3><blockquote>\n<p>这就好象是中文已经用了上千年，突然有几位教授大谈“回字的14种写法”，这只能算是新瓶装旧酒、学究式的文章。一旦媒体不忽悠了，也就过气了。而媒体关注了几个月之后，关注点已经放到云、大数据等等明显是更长久、更工程化的概念上了，懒得对小伎俩去宣传了。<br>那个东西除了平白无故地额外多出来规定，没有什么发明技术含量的东西（不能被大企业用来衍生出自己的专利技术），因此不可能成为工业标准，充其量是叫兽用用。<br>其实所谓的 restful 更适合那些总想着沽名钓誉的硕士研究生们去堆砌辞藻，用来体现出自己比其他众多工程技术人员“高人一等”，以避免其它具有更丰富的工程技术的开发人员瞧不起这些人。除此以外，它没有什么实际的技术含量，（正如所看到的）所有实际大项目的工程技术人员都在使用轻量级的web服务方式（从10几年前的电信级的、基于http的远程传输应用就是，人家根本不用webservice）。基本上都是初学者或者大学老师在纠结于繁琐的web服务里边“如何规范名词儿”的问题。</p>\n</blockquote>\n<blockquote>\n<p>核心问题在于RESTful API设计，容易思考，但是不适合实际使用。<br>这个，就和设计网络协议一样，七层网络模型，理解很给力，实际还是采用四层网络模型一样。<br>基于RESTful API理解很好理解，但是会严重增加不必要的网络传输消耗。实际使用，基于较少网络消耗较少数据连接的考虑，会更加贴近实际业务场景的API设计，至于DELETE，PUT之类的，不是不愿意使用，是需要对现有业务进行大量不必要的改造，而这种改造，完成是没有必要的。</p>\n</blockquote>\n<h3 id=\"原则\"><a href=\"#原则\" class=\"headerlink\" title=\"原则\"></a>原则</h3><blockquote>\n<p>REST 指的是一组架构约束条件和原则。满足这些约束条件和原则的应用程序或设计就是 RESTful。</p>\n</blockquote>\n<blockquote>\n<p>Web 应用程序最重要的 REST 原则是，客户端和服务器之间的交互在请求之间是无状态的。从客户端到服务器的每个请求都必须包含理解请求所必需的信息。如果服务器在请求之间的任何时间点重启，客户端不会得到通知。此外，无状态请求可以由任何可用服务器回答，这十分适合云计算之类的环境。客户端可以缓存数据以改进性能。</p>\n</blockquote>\n<blockquote>\n<p>在服务器端，应用程序状态和功能可以分为各种资源。资源是一个有趣的概念实体，它向客户端公开。资源的例子有：应用程序对象、数据库记录、算法等等。每个资源都使用 URI (Universal Resource Identifier) 得到一个唯一的地址。所有资源都共享统一的接口，以便在客户端和服务器之间传输状态。使用的是标准的 HTTP 方法，比如 GET、PUT、POST 和 DELETE。Hypermedia 是应用程序状态的引擎，资源表示通过超链接互联。</p>\n</blockquote>\n<h3 id=\"特点\"><a href=\"#特点\" class=\"headerlink\" title=\"特点\"></a>特点</h3><p>1、每一个URI代表1种资源；<br>2、客户端使用GET、POST、PUT、DELETE4个表示操作方式的动词对服务端资源进行操作：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源；<br>3、通过操作资源的表现形式来操作资源；<br>4、资源的表现形式是XML或者HTML；<br>5、客户端与服务端之间的交互在请求之间是无状态的，从客户端到服务端的每个请求都必须包含理解请求所必需的信息。</p>\n"},{"title":"deeplearning 01 getting started","_content":"\nReferenece: [csdn 深度学习入门视频课程](https://edu.csdn.net/course/detail/3921)\n\n## **机器学习流程**\n![](01.PNG)\n数据获取，特征工程，建立模型，评估与应用  \n深度学习是一个黑盒子但是也要了解里面细节.  \n\n## **数据集**\n**01. 大数据集**\n2009年之前机器学习耗费资源多, 速度慢, 交流关注的少.  \n2009年 李飞飞号召全美多所高校标注图片中物体特征位置, 组成一个含有22K个种类和14M张图片的库.  \nhttp://www.image-net.org/  \n图片库非常大, 做大型科研等可以参考.  \n\n2012年Alex在图像分类比赛中使用深度学习算法获得冠军，精度比第二名用传统人工智能得到的精度高出十几个百分点, 由此让人们意识到深度学习在计算机视觉方面的重要作用.\n\n2017年李飞飞宣布图像分类比赛结束, 因为机器识别效果远超人类, 比赛再做下去没有多大意义.\n\n![](02.PNG)\n在数据规模比较小是可以不用深度学习.  \n当数据规模达到上万或几十万量时候深度学习效果比传统人工智能好.  \n\n**02 小数据集**\n`CIFAR-10` 百度,google等搜索下载\n\n## **K近邻算法**\n![](03.PNG)\n![](04.PNG)\nK近邻算法对测试的用的image A和图片集中的images B,c,d..., 像素点的值对应位相减, 再求和得到两张图片总像素点的差值和.  \n再取图片集前10个差值小的图片, 会发现跟测试用的image A内容可能相差很大，只是背景或前景色相类似.  \n因此K近邻算法不能用来图像分类, 需要再画出图片中感兴趣的区域再识别.  \n\n\n## **线性函数**\n![](05.PNG)\n![](06.PNG)\n![](07.PNG)\n\n## **损失函数**\n![](08.PNG)\n错误得分 - 正确得分, 再 +1或者+10(表示正确得分要比错误得分高1或者10才算没有损失), 再跟0比大小取大值, 小于等于0表示没有损失.  \n\n\n\n\n\n","source":"_posts/deeplearning/deeplearning_01_get_started.md","raw":"---\ntitle: deeplearning 01 getting started\ntags: deeplearning\ncategories:\n- deeplearning\n---\n\nReferenece: [csdn 深度学习入门视频课程](https://edu.csdn.net/course/detail/3921)\n\n## **机器学习流程**\n![](01.PNG)\n数据获取，特征工程，建立模型，评估与应用  \n深度学习是一个黑盒子但是也要了解里面细节.  \n\n## **数据集**\n**01. 大数据集**\n2009年之前机器学习耗费资源多, 速度慢, 交流关注的少.  \n2009年 李飞飞号召全美多所高校标注图片中物体特征位置, 组成一个含有22K个种类和14M张图片的库.  \nhttp://www.image-net.org/  \n图片库非常大, 做大型科研等可以参考.  \n\n2012年Alex在图像分类比赛中使用深度学习算法获得冠军，精度比第二名用传统人工智能得到的精度高出十几个百分点, 由此让人们意识到深度学习在计算机视觉方面的重要作用.\n\n2017年李飞飞宣布图像分类比赛结束, 因为机器识别效果远超人类, 比赛再做下去没有多大意义.\n\n![](02.PNG)\n在数据规模比较小是可以不用深度学习.  \n当数据规模达到上万或几十万量时候深度学习效果比传统人工智能好.  \n\n**02 小数据集**\n`CIFAR-10` 百度,google等搜索下载\n\n## **K近邻算法**\n![](03.PNG)\n![](04.PNG)\nK近邻算法对测试的用的image A和图片集中的images B,c,d..., 像素点的值对应位相减, 再求和得到两张图片总像素点的差值和.  \n再取图片集前10个差值小的图片, 会发现跟测试用的image A内容可能相差很大，只是背景或前景色相类似.  \n因此K近邻算法不能用来图像分类, 需要再画出图片中感兴趣的区域再识别.  \n\n\n## **线性函数**\n![](05.PNG)\n![](06.PNG)\n![](07.PNG)\n\n## **损失函数**\n![](08.PNG)\n错误得分 - 正确得分, 再 +1或者+10(表示正确得分要比错误得分高1或者10才算没有损失), 再跟0比大小取大值, 小于等于0表示没有损失.  \n\n\n\n\n\n","slug":"deeplearning/deeplearning_01_get_started","published":1,"date":"2020-08-12T16:05:44.551Z","updated":"2020-08-12T10:46:07.889Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmbw000bhohx6xmx31zh","content":"<p>Referenece: <a href=\"https://edu.csdn.net/course/detail/3921\" target=\"_blank\" rel=\"noopener\">csdn 深度学习入门视频课程</a></p>\n<h2 id=\"机器学习流程\"><a href=\"#机器学习流程\" class=\"headerlink\" title=\"机器学习流程\"></a><strong>机器学习流程</strong></h2><p><img src=\"01.PNG\" alt=\"\"><br>数据获取，特征工程，建立模型，评估与应用<br>深度学习是一个黑盒子但是也要了解里面细节.  </p>\n<h2 id=\"数据集\"><a href=\"#数据集\" class=\"headerlink\" title=\"数据集\"></a><strong>数据集</strong></h2><p><strong>01. 大数据集</strong><br>2009年之前机器学习耗费资源多, 速度慢, 交流关注的少.<br>2009年 李飞飞号召全美多所高校标注图片中物体特征位置, 组成一个含有22K个种类和14M张图片的库.<br><a href=\"http://www.image-net.org/\" target=\"_blank\" rel=\"noopener\">http://www.image-net.org/</a><br>图片库非常大, 做大型科研等可以参考.  </p>\n<p>2012年Alex在图像分类比赛中使用深度学习算法获得冠军，精度比第二名用传统人工智能得到的精度高出十几个百分点, 由此让人们意识到深度学习在计算机视觉方面的重要作用.</p>\n<p>2017年李飞飞宣布图像分类比赛结束, 因为机器识别效果远超人类, 比赛再做下去没有多大意义.</p>\n<p><img src=\"02.PNG\" alt=\"\"><br>在数据规模比较小是可以不用深度学习.<br>当数据规模达到上万或几十万量时候深度学习效果比传统人工智能好.  </p>\n<p><strong>02 小数据集</strong><br><code>CIFAR-10</code> 百度,google等搜索下载</p>\n<h2 id=\"K近邻算法\"><a href=\"#K近邻算法\" class=\"headerlink\" title=\"K近邻算法\"></a><strong>K近邻算法</strong></h2><p><img src=\"03.PNG\" alt=\"\"><br><img src=\"04.PNG\" alt=\"\"><br>K近邻算法对测试的用的image A和图片集中的images B,c,d…, 像素点的值对应位相减, 再求和得到两张图片总像素点的差值和.<br>再取图片集前10个差值小的图片, 会发现跟测试用的image A内容可能相差很大，只是背景或前景色相类似.<br>因此K近邻算法不能用来图像分类, 需要再画出图片中感兴趣的区域再识别.  </p>\n<h2 id=\"线性函数\"><a href=\"#线性函数\" class=\"headerlink\" title=\"线性函数\"></a><strong>线性函数</strong></h2><p><img src=\"05.PNG\" alt=\"\"><br><img src=\"06.PNG\" alt=\"\"><br><img src=\"07.PNG\" alt=\"\"></p>\n<h2 id=\"损失函数\"><a href=\"#损失函数\" class=\"headerlink\" title=\"损失函数\"></a><strong>损失函数</strong></h2><p><img src=\"08.PNG\" alt=\"\"><br>错误得分 - 正确得分, 再 +1或者+10(表示正确得分要比错误得分高1或者10才算没有损失), 再跟0比大小取大值, 小于等于0表示没有损失.  </p>\n","site":{"data":{}},"excerpt":"","more":"<p>Referenece: <a href=\"https://edu.csdn.net/course/detail/3921\" target=\"_blank\" rel=\"noopener\">csdn 深度学习入门视频课程</a></p>\n<h2 id=\"机器学习流程\"><a href=\"#机器学习流程\" class=\"headerlink\" title=\"机器学习流程\"></a><strong>机器学习流程</strong></h2><p><img src=\"01.PNG\" alt=\"\"><br>数据获取，特征工程，建立模型，评估与应用<br>深度学习是一个黑盒子但是也要了解里面细节.  </p>\n<h2 id=\"数据集\"><a href=\"#数据集\" class=\"headerlink\" title=\"数据集\"></a><strong>数据集</strong></h2><p><strong>01. 大数据集</strong><br>2009年之前机器学习耗费资源多, 速度慢, 交流关注的少.<br>2009年 李飞飞号召全美多所高校标注图片中物体特征位置, 组成一个含有22K个种类和14M张图片的库.<br><a href=\"http://www.image-net.org/\" target=\"_blank\" rel=\"noopener\">http://www.image-net.org/</a><br>图片库非常大, 做大型科研等可以参考.  </p>\n<p>2012年Alex在图像分类比赛中使用深度学习算法获得冠军，精度比第二名用传统人工智能得到的精度高出十几个百分点, 由此让人们意识到深度学习在计算机视觉方面的重要作用.</p>\n<p>2017年李飞飞宣布图像分类比赛结束, 因为机器识别效果远超人类, 比赛再做下去没有多大意义.</p>\n<p><img src=\"02.PNG\" alt=\"\"><br>在数据规模比较小是可以不用深度学习.<br>当数据规模达到上万或几十万量时候深度学习效果比传统人工智能好.  </p>\n<p><strong>02 小数据集</strong><br><code>CIFAR-10</code> 百度,google等搜索下载</p>\n<h2 id=\"K近邻算法\"><a href=\"#K近邻算法\" class=\"headerlink\" title=\"K近邻算法\"></a><strong>K近邻算法</strong></h2><p><img src=\"03.PNG\" alt=\"\"><br><img src=\"04.PNG\" alt=\"\"><br>K近邻算法对测试的用的image A和图片集中的images B,c,d…, 像素点的值对应位相减, 再求和得到两张图片总像素点的差值和.<br>再取图片集前10个差值小的图片, 会发现跟测试用的image A内容可能相差很大，只是背景或前景色相类似.<br>因此K近邻算法不能用来图像分类, 需要再画出图片中感兴趣的区域再识别.  </p>\n<h2 id=\"线性函数\"><a href=\"#线性函数\" class=\"headerlink\" title=\"线性函数\"></a><strong>线性函数</strong></h2><p><img src=\"05.PNG\" alt=\"\"><br><img src=\"06.PNG\" alt=\"\"><br><img src=\"07.PNG\" alt=\"\"></p>\n<h2 id=\"损失函数\"><a href=\"#损失函数\" class=\"headerlink\" title=\"损失函数\"></a><strong>损失函数</strong></h2><p><img src=\"08.PNG\" alt=\"\"><br>错误得分 - 正确得分, 再 +1或者+10(表示正确得分要比错误得分高1或者10才算没有损失), 再跟0比大小取大值, 小于等于0表示没有损失.  </p>\n"},{"title":"ACPI是什么,BIOS中ACPI要怎么设置","_content":"有很多朋友都不知道ACPI是什么，在设备管理器或是BIOS里我们可以看到ACPI选项，比较常见的就是我们查看设备管理器中的计算机，有ACPI X64-based PC的标识。那么ACPI是什么？BIOS中开启ACPI又有什么作用呢？下面一起来学习下相关知识。 \n![](acpi.jpg)\n\n一、ACPI是什么？\n\nACPI其实是一种电源管理标准，ACPI是Advanced Configuration and Power Interface的首字母缩写，一般翻译成高级电源管理，是Intel、Microsoft和东芝共同开发的一种电源管理标准。\n二、ACPI有什么用？\n  ACPI是Windows的一部分(Win98开始)，它帮助操作系统合理控制和分配计算机硬件设备的电量，有了ACPI，操作系统可以根据设备实际情况，根据需要把不同的硬件设备关闭。如Win7或者Win8系统，系统睡眠时，系统把当前信息储存在内存中，只保留内存等几个关键部件硬件的通电，使计算机处在高度节电状态。\n  ACPI功能强大，它还能够实现设备和处理器性能管理、配置/即插即用设备管理、系统事件、温度管理、嵌入式控制器以及SMBus控制器等。\n![](acpi_bios.jpg)\n\n开启acpi有什么好处\n\nACPI表示高级配置和电源管理接口ACPI可实现以下功能:\n\n1、用户可以使外设在指定时间开关；\n2、使用笔记本电脑的用户可以指定计算机在低电压的情况下进入低功耗状态，以保证重要的应用程序运行；\n3、操作系统可以在应用程序对时间要求不高的情况下降低时钟频率；\n4、操作系统可以根据外设和主板的具体需求为它分配能源；\n5、在无人使用计算机时可以使计算机进入休眠状态，但保证一些通信设备打开；\n6、即插即用设备在插入时能够由ACPI来控制。\n\n目前的主流电脑都是支持ACPI电源标准的。\n","source":"_posts/linux/ACPI是什么&BIOS中ACPI要怎么设置.md","raw":"---\ntitle: ACPI是什么,BIOS中ACPI要怎么设置\ntags: \ncategories:\n- linux\n---\n有很多朋友都不知道ACPI是什么，在设备管理器或是BIOS里我们可以看到ACPI选项，比较常见的就是我们查看设备管理器中的计算机，有ACPI X64-based PC的标识。那么ACPI是什么？BIOS中开启ACPI又有什么作用呢？下面一起来学习下相关知识。 \n![](acpi.jpg)\n\n一、ACPI是什么？\n\nACPI其实是一种电源管理标准，ACPI是Advanced Configuration and Power Interface的首字母缩写，一般翻译成高级电源管理，是Intel、Microsoft和东芝共同开发的一种电源管理标准。\n二、ACPI有什么用？\n  ACPI是Windows的一部分(Win98开始)，它帮助操作系统合理控制和分配计算机硬件设备的电量，有了ACPI，操作系统可以根据设备实际情况，根据需要把不同的硬件设备关闭。如Win7或者Win8系统，系统睡眠时，系统把当前信息储存在内存中，只保留内存等几个关键部件硬件的通电，使计算机处在高度节电状态。\n  ACPI功能强大，它还能够实现设备和处理器性能管理、配置/即插即用设备管理、系统事件、温度管理、嵌入式控制器以及SMBus控制器等。\n![](acpi_bios.jpg)\n\n开启acpi有什么好处\n\nACPI表示高级配置和电源管理接口ACPI可实现以下功能:\n\n1、用户可以使外设在指定时间开关；\n2、使用笔记本电脑的用户可以指定计算机在低电压的情况下进入低功耗状态，以保证重要的应用程序运行；\n3、操作系统可以在应用程序对时间要求不高的情况下降低时钟频率；\n4、操作系统可以根据外设和主板的具体需求为它分配能源；\n5、在无人使用计算机时可以使计算机进入休眠状态，但保证一些通信设备打开；\n6、即插即用设备在插入时能够由ACPI来控制。\n\n目前的主流电脑都是支持ACPI电源标准的。\n","slug":"linux/ACPI是什么&BIOS中ACPI要怎么设置","published":1,"date":"2020-08-12T16:05:46.072Z","updated":"2020-02-13T12:47:44.235Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmby000chohx7kiu6ptb","content":"<p>有很多朋友都不知道ACPI是什么，在设备管理器或是BIOS里我们可以看到ACPI选项，比较常见的就是我们查看设备管理器中的计算机，有ACPI X64-based PC的标识。那么ACPI是什么？BIOS中开启ACPI又有什么作用呢？下面一起来学习下相关知识。<br><img src=\"acpi.jpg\" alt=\"\"></p>\n<p>一、ACPI是什么？</p>\n<p>ACPI其实是一种电源管理标准，ACPI是Advanced Configuration and Power Interface的首字母缩写，一般翻译成高级电源管理，是Intel、Microsoft和东芝共同开发的一种电源管理标准。<br>二、ACPI有什么用？<br>  ACPI是Windows的一部分(Win98开始)，它帮助操作系统合理控制和分配计算机硬件设备的电量，有了ACPI，操作系统可以根据设备实际情况，根据需要把不同的硬件设备关闭。如Win7或者Win8系统，系统睡眠时，系统把当前信息储存在内存中，只保留内存等几个关键部件硬件的通电，使计算机处在高度节电状态。<br>  ACPI功能强大，它还能够实现设备和处理器性能管理、配置/即插即用设备管理、系统事件、温度管理、嵌入式控制器以及SMBus控制器等。<br><img src=\"acpi_bios.jpg\" alt=\"\"></p>\n<p>开启acpi有什么好处</p>\n<p>ACPI表示高级配置和电源管理接口ACPI可实现以下功能:</p>\n<p>1、用户可以使外设在指定时间开关；<br>2、使用笔记本电脑的用户可以指定计算机在低电压的情况下进入低功耗状态，以保证重要的应用程序运行；<br>3、操作系统可以在应用程序对时间要求不高的情况下降低时钟频率；<br>4、操作系统可以根据外设和主板的具体需求为它分配能源；<br>5、在无人使用计算机时可以使计算机进入休眠状态，但保证一些通信设备打开；<br>6、即插即用设备在插入时能够由ACPI来控制。</p>\n<p>目前的主流电脑都是支持ACPI电源标准的。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>有很多朋友都不知道ACPI是什么，在设备管理器或是BIOS里我们可以看到ACPI选项，比较常见的就是我们查看设备管理器中的计算机，有ACPI X64-based PC的标识。那么ACPI是什么？BIOS中开启ACPI又有什么作用呢？下面一起来学习下相关知识。<br><img src=\"acpi.jpg\" alt=\"\"></p>\n<p>一、ACPI是什么？</p>\n<p>ACPI其实是一种电源管理标准，ACPI是Advanced Configuration and Power Interface的首字母缩写，一般翻译成高级电源管理，是Intel、Microsoft和东芝共同开发的一种电源管理标准。<br>二、ACPI有什么用？<br>  ACPI是Windows的一部分(Win98开始)，它帮助操作系统合理控制和分配计算机硬件设备的电量，有了ACPI，操作系统可以根据设备实际情况，根据需要把不同的硬件设备关闭。如Win7或者Win8系统，系统睡眠时，系统把当前信息储存在内存中，只保留内存等几个关键部件硬件的通电，使计算机处在高度节电状态。<br>  ACPI功能强大，它还能够实现设备和处理器性能管理、配置/即插即用设备管理、系统事件、温度管理、嵌入式控制器以及SMBus控制器等。<br><img src=\"acpi_bios.jpg\" alt=\"\"></p>\n<p>开启acpi有什么好处</p>\n<p>ACPI表示高级配置和电源管理接口ACPI可实现以下功能:</p>\n<p>1、用户可以使外设在指定时间开关；<br>2、使用笔记本电脑的用户可以指定计算机在低电压的情况下进入低功耗状态，以保证重要的应用程序运行；<br>3、操作系统可以在应用程序对时间要求不高的情况下降低时钟频率；<br>4、操作系统可以根据外设和主板的具体需求为它分配能源；<br>5、在无人使用计算机时可以使计算机进入休眠状态，但保证一些通信设备打开；<br>6、即插即用设备在插入时能够由ACPI来控制。</p>\n<p>目前的主流电脑都是支持ACPI电源标准的。</p>\n"},{"title":"BIOS","_content":"\n英特尔公司从2000年开始，发明了可扩展固件接口（Extensible Firmware Interface），用以规范BIOS的开发。而支持EFI规范的BIOS也被称为EFI BIOS。之后为了推广EFI，业界多家著名公司共同成立了统一可扩展固件接口论坛（UEFI Forum），英特尔公司将EFI 1.1规范贡献给业界，用以制订新的国际标准UEFI规范。目前UEFI规范的最新版本是2.3.1，英特尔公司曾经预测，2010年，全世界或有有60%以上的个人电脑使用支持UEFI规范的BIOS产品。\n![](bios.gif)\n抠出纽扣电池可使BIOS恢复到出厂默认值\n\nBIOS设置程序是储存在BIOS芯片中的，BIOS芯片是主板上一块长方形或正方形芯片，只有在开机时才可以进行设置。（一般在计算机启动时按F2或者Delete进入BIOS进行设置，一些特殊机型按F1、Esc、F12等进行设置）。BIOS设置程序主要对计算机的基本输入输出系统进行管理和设置，使系统运行在最好状态下，使用BIOS设置程序还可以排除系统故障或者诊断系统问题。有人认为既然BIOS是\"程序\"，那它就应该是属于软件，感觉就像自己常用的Word或Excel。但也有很多人不这么认为，因为它与一般的软件还是有一些区别，而且它与硬件的联系也是相当地紧密。形象地说，BIOS应该是连接软件程序与硬件设备的一座\"桥梁\"，负责解决硬件的即时要求。主板上的BIOS芯片或许是主板上唯一贴有标签的芯片，一般它是一块32针的双列直插式的集成电路，上面印有\"BIOS\"字样。\nROM\n在微机（微型计算机Microcomputer System）的发展初期，BIOS都存放在ROM（Read Only Memory，只读存储器）中。ROM内部的资料是在ROM的制造工序中，在工厂里用特殊的方法被烧录进去的，其中的内容只能读不能改，一旦烧录进去，用户只能验证写入的资料是否正确，不能再作任何修改。如果发现资料有任何错误，则只有舍弃不用。\nEPROM\nEPROM（Erasable Programmable ROM，可擦除可编程ROM）芯片可重复擦除和写入，解决了ROM芯片只能写入一次的弊端。EPROM芯片有一个很明显的特征，在其正面的陶瓷封装上，开有一个玻璃窗口，透过该窗口，可以看到其内部的集成电路，紫外线透过该孔照射内部芯片就可以擦除其内的数据，完成芯片擦除的操作要用到EPROM擦除器。EPROM内资料的写入要用专用的编程器，并且往芯片中写内容时必须要加一定的编程电压（VPP=12—24V，随不同的芯片型号而定）。EPROM的型号是以27开头的，如27C020(8*256K）是一片2M Bits容量的EPROM芯片。EPROM芯片在写入资料后，还要以不透光的贴纸或胶布把窗口封住，以免受到周围的紫外线照射而使资料受损。\nEEPROM\n由于EPROM操作的不便，586以后的主板上BIOS ROM芯片大部分都采用EEPROM（Electrically Erasable Programmable ROM，电可擦除可编程ROM）。 [7]  通过跳线开关和系统配带的驱动程序盘，可以对EEPROM进行重写，方便地实现BIOS升级。\nBIOS芯片中主要存放：\n●自诊断程序：通过读取CMOSRAM中的内容识别硬件配置，并对其进行自检和初始化；\n● CMOS设置程序：引导过程中，用特殊热键启动，进行设置后，存入CMOS RAM中；\n● 系统自举装载程序：在自检成功后将磁盘相对0道0扇区上的引导程序装入内存，让其运行以装入DOS系统；\n● 主要I/O设备的驱动程序和中断服务：由于BIOS直接和系统硬件资源打交道，因此总是针对某一类型的硬件系统，而各种硬件系统又各有不同，所以存在各种不同种类的BIOS，随着硬件技术的发展，同一种BIOS也先后出现了不同的版本，新版本的BIOS比起老版本来说，功能更强。\nNORFlash\n从奔腾时代开始，现代的电脑主板都使用NORFlash来作为BIOS的存储芯片。除了容量比EEPROM更大外，主要是NORFlash具有写入功能 [1]  ，运行电脑通过软件的方式进行BIOS的更新，而无需额外的硬件支持（通常EEPROM的擦写需要不同的电压和条件），且写入速度快。\n\n\n\n\n","source":"_posts/linux/BIOS.md","raw":"---\ntitle: BIOS\ntags: \ncategories: \n- linux\n---\n\n英特尔公司从2000年开始，发明了可扩展固件接口（Extensible Firmware Interface），用以规范BIOS的开发。而支持EFI规范的BIOS也被称为EFI BIOS。之后为了推广EFI，业界多家著名公司共同成立了统一可扩展固件接口论坛（UEFI Forum），英特尔公司将EFI 1.1规范贡献给业界，用以制订新的国际标准UEFI规范。目前UEFI规范的最新版本是2.3.1，英特尔公司曾经预测，2010年，全世界或有有60%以上的个人电脑使用支持UEFI规范的BIOS产品。\n![](bios.gif)\n抠出纽扣电池可使BIOS恢复到出厂默认值\n\nBIOS设置程序是储存在BIOS芯片中的，BIOS芯片是主板上一块长方形或正方形芯片，只有在开机时才可以进行设置。（一般在计算机启动时按F2或者Delete进入BIOS进行设置，一些特殊机型按F1、Esc、F12等进行设置）。BIOS设置程序主要对计算机的基本输入输出系统进行管理和设置，使系统运行在最好状态下，使用BIOS设置程序还可以排除系统故障或者诊断系统问题。有人认为既然BIOS是\"程序\"，那它就应该是属于软件，感觉就像自己常用的Word或Excel。但也有很多人不这么认为，因为它与一般的软件还是有一些区别，而且它与硬件的联系也是相当地紧密。形象地说，BIOS应该是连接软件程序与硬件设备的一座\"桥梁\"，负责解决硬件的即时要求。主板上的BIOS芯片或许是主板上唯一贴有标签的芯片，一般它是一块32针的双列直插式的集成电路，上面印有\"BIOS\"字样。\nROM\n在微机（微型计算机Microcomputer System）的发展初期，BIOS都存放在ROM（Read Only Memory，只读存储器）中。ROM内部的资料是在ROM的制造工序中，在工厂里用特殊的方法被烧录进去的，其中的内容只能读不能改，一旦烧录进去，用户只能验证写入的资料是否正确，不能再作任何修改。如果发现资料有任何错误，则只有舍弃不用。\nEPROM\nEPROM（Erasable Programmable ROM，可擦除可编程ROM）芯片可重复擦除和写入，解决了ROM芯片只能写入一次的弊端。EPROM芯片有一个很明显的特征，在其正面的陶瓷封装上，开有一个玻璃窗口，透过该窗口，可以看到其内部的集成电路，紫外线透过该孔照射内部芯片就可以擦除其内的数据，完成芯片擦除的操作要用到EPROM擦除器。EPROM内资料的写入要用专用的编程器，并且往芯片中写内容时必须要加一定的编程电压（VPP=12—24V，随不同的芯片型号而定）。EPROM的型号是以27开头的，如27C020(8*256K）是一片2M Bits容量的EPROM芯片。EPROM芯片在写入资料后，还要以不透光的贴纸或胶布把窗口封住，以免受到周围的紫外线照射而使资料受损。\nEEPROM\n由于EPROM操作的不便，586以后的主板上BIOS ROM芯片大部分都采用EEPROM（Electrically Erasable Programmable ROM，电可擦除可编程ROM）。 [7]  通过跳线开关和系统配带的驱动程序盘，可以对EEPROM进行重写，方便地实现BIOS升级。\nBIOS芯片中主要存放：\n●自诊断程序：通过读取CMOSRAM中的内容识别硬件配置，并对其进行自检和初始化；\n● CMOS设置程序：引导过程中，用特殊热键启动，进行设置后，存入CMOS RAM中；\n● 系统自举装载程序：在自检成功后将磁盘相对0道0扇区上的引导程序装入内存，让其运行以装入DOS系统；\n● 主要I/O设备的驱动程序和中断服务：由于BIOS直接和系统硬件资源打交道，因此总是针对某一类型的硬件系统，而各种硬件系统又各有不同，所以存在各种不同种类的BIOS，随着硬件技术的发展，同一种BIOS也先后出现了不同的版本，新版本的BIOS比起老版本来说，功能更强。\nNORFlash\n从奔腾时代开始，现代的电脑主板都使用NORFlash来作为BIOS的存储芯片。除了容量比EEPROM更大外，主要是NORFlash具有写入功能 [1]  ，运行电脑通过软件的方式进行BIOS的更新，而无需额外的硬件支持（通常EEPROM的擦写需要不同的电压和条件），且写入速度快。\n\n\n\n\n","slug":"linux/BIOS","published":1,"date":"2020-08-12T16:05:46.080Z","updated":"2020-02-13T12:47:44.249Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmc2000ghohxdcvfg16y","content":"<p>英特尔公司从2000年开始，发明了可扩展固件接口（Extensible Firmware Interface），用以规范BIOS的开发。而支持EFI规范的BIOS也被称为EFI BIOS。之后为了推广EFI，业界多家著名公司共同成立了统一可扩展固件接口论坛（UEFI Forum），英特尔公司将EFI 1.1规范贡献给业界，用以制订新的国际标准UEFI规范。目前UEFI规范的最新版本是2.3.1，英特尔公司曾经预测，2010年，全世界或有有60%以上的个人电脑使用支持UEFI规范的BIOS产品。<br><img src=\"bios.gif\" alt=\"\"><br>抠出纽扣电池可使BIOS恢复到出厂默认值</p>\n<p>BIOS设置程序是储存在BIOS芯片中的，BIOS芯片是主板上一块长方形或正方形芯片，只有在开机时才可以进行设置。（一般在计算机启动时按F2或者Delete进入BIOS进行设置，一些特殊机型按F1、Esc、F12等进行设置）。BIOS设置程序主要对计算机的基本输入输出系统进行管理和设置，使系统运行在最好状态下，使用BIOS设置程序还可以排除系统故障或者诊断系统问题。有人认为既然BIOS是”程序”，那它就应该是属于软件，感觉就像自己常用的Word或Excel。但也有很多人不这么认为，因为它与一般的软件还是有一些区别，而且它与硬件的联系也是相当地紧密。形象地说，BIOS应该是连接软件程序与硬件设备的一座”桥梁”，负责解决硬件的即时要求。主板上的BIOS芯片或许是主板上唯一贴有标签的芯片，一般它是一块32针的双列直插式的集成电路，上面印有”BIOS”字样。<br>ROM<br>在微机（微型计算机Microcomputer System）的发展初期，BIOS都存放在ROM（Read Only Memory，只读存储器）中。ROM内部的资料是在ROM的制造工序中，在工厂里用特殊的方法被烧录进去的，其中的内容只能读不能改，一旦烧录进去，用户只能验证写入的资料是否正确，不能再作任何修改。如果发现资料有任何错误，则只有舍弃不用。<br>EPROM<br>EPROM（Erasable Programmable ROM，可擦除可编程ROM）芯片可重复擦除和写入，解决了ROM芯片只能写入一次的弊端。EPROM芯片有一个很明显的特征，在其正面的陶瓷封装上，开有一个玻璃窗口，透过该窗口，可以看到其内部的集成电路，紫外线透过该孔照射内部芯片就可以擦除其内的数据，完成芯片擦除的操作要用到EPROM擦除器。EPROM内资料的写入要用专用的编程器，并且往芯片中写内容时必须要加一定的编程电压（VPP=12—24V，随不同的芯片型号而定）。EPROM的型号是以27开头的，如27C020(8*256K）是一片2M Bits容量的EPROM芯片。EPROM芯片在写入资料后，还要以不透光的贴纸或胶布把窗口封住，以免受到周围的紫外线照射而使资料受损。<br>EEPROM<br>由于EPROM操作的不便，586以后的主板上BIOS ROM芯片大部分都采用EEPROM（Electrically Erasable Programmable ROM，电可擦除可编程ROM）。 [7]  通过跳线开关和系统配带的驱动程序盘，可以对EEPROM进行重写，方便地实现BIOS升级。<br>BIOS芯片中主要存放：<br>●自诊断程序：通过读取CMOSRAM中的内容识别硬件配置，并对其进行自检和初始化；<br>● CMOS设置程序：引导过程中，用特殊热键启动，进行设置后，存入CMOS RAM中；<br>● 系统自举装载程序：在自检成功后将磁盘相对0道0扇区上的引导程序装入内存，让其运行以装入DOS系统；<br>● 主要I/O设备的驱动程序和中断服务：由于BIOS直接和系统硬件资源打交道，因此总是针对某一类型的硬件系统，而各种硬件系统又各有不同，所以存在各种不同种类的BIOS，随着硬件技术的发展，同一种BIOS也先后出现了不同的版本，新版本的BIOS比起老版本来说，功能更强。<br>NORFlash<br>从奔腾时代开始，现代的电脑主板都使用NORFlash来作为BIOS的存储芯片。除了容量比EEPROM更大外，主要是NORFlash具有写入功能 [1]  ，运行电脑通过软件的方式进行BIOS的更新，而无需额外的硬件支持（通常EEPROM的擦写需要不同的电压和条件），且写入速度快。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>英特尔公司从2000年开始，发明了可扩展固件接口（Extensible Firmware Interface），用以规范BIOS的开发。而支持EFI规范的BIOS也被称为EFI BIOS。之后为了推广EFI，业界多家著名公司共同成立了统一可扩展固件接口论坛（UEFI Forum），英特尔公司将EFI 1.1规范贡献给业界，用以制订新的国际标准UEFI规范。目前UEFI规范的最新版本是2.3.1，英特尔公司曾经预测，2010年，全世界或有有60%以上的个人电脑使用支持UEFI规范的BIOS产品。<br><img src=\"bios.gif\" alt=\"\"><br>抠出纽扣电池可使BIOS恢复到出厂默认值</p>\n<p>BIOS设置程序是储存在BIOS芯片中的，BIOS芯片是主板上一块长方形或正方形芯片，只有在开机时才可以进行设置。（一般在计算机启动时按F2或者Delete进入BIOS进行设置，一些特殊机型按F1、Esc、F12等进行设置）。BIOS设置程序主要对计算机的基本输入输出系统进行管理和设置，使系统运行在最好状态下，使用BIOS设置程序还可以排除系统故障或者诊断系统问题。有人认为既然BIOS是”程序”，那它就应该是属于软件，感觉就像自己常用的Word或Excel。但也有很多人不这么认为，因为它与一般的软件还是有一些区别，而且它与硬件的联系也是相当地紧密。形象地说，BIOS应该是连接软件程序与硬件设备的一座”桥梁”，负责解决硬件的即时要求。主板上的BIOS芯片或许是主板上唯一贴有标签的芯片，一般它是一块32针的双列直插式的集成电路，上面印有”BIOS”字样。<br>ROM<br>在微机（微型计算机Microcomputer System）的发展初期，BIOS都存放在ROM（Read Only Memory，只读存储器）中。ROM内部的资料是在ROM的制造工序中，在工厂里用特殊的方法被烧录进去的，其中的内容只能读不能改，一旦烧录进去，用户只能验证写入的资料是否正确，不能再作任何修改。如果发现资料有任何错误，则只有舍弃不用。<br>EPROM<br>EPROM（Erasable Programmable ROM，可擦除可编程ROM）芯片可重复擦除和写入，解决了ROM芯片只能写入一次的弊端。EPROM芯片有一个很明显的特征，在其正面的陶瓷封装上，开有一个玻璃窗口，透过该窗口，可以看到其内部的集成电路，紫外线透过该孔照射内部芯片就可以擦除其内的数据，完成芯片擦除的操作要用到EPROM擦除器。EPROM内资料的写入要用专用的编程器，并且往芯片中写内容时必须要加一定的编程电压（VPP=12—24V，随不同的芯片型号而定）。EPROM的型号是以27开头的，如27C020(8*256K）是一片2M Bits容量的EPROM芯片。EPROM芯片在写入资料后，还要以不透光的贴纸或胶布把窗口封住，以免受到周围的紫外线照射而使资料受损。<br>EEPROM<br>由于EPROM操作的不便，586以后的主板上BIOS ROM芯片大部分都采用EEPROM（Electrically Erasable Programmable ROM，电可擦除可编程ROM）。 [7]  通过跳线开关和系统配带的驱动程序盘，可以对EEPROM进行重写，方便地实现BIOS升级。<br>BIOS芯片中主要存放：<br>●自诊断程序：通过读取CMOSRAM中的内容识别硬件配置，并对其进行自检和初始化；<br>● CMOS设置程序：引导过程中，用特殊热键启动，进行设置后，存入CMOS RAM中；<br>● 系统自举装载程序：在自检成功后将磁盘相对0道0扇区上的引导程序装入内存，让其运行以装入DOS系统；<br>● 主要I/O设备的驱动程序和中断服务：由于BIOS直接和系统硬件资源打交道，因此总是针对某一类型的硬件系统，而各种硬件系统又各有不同，所以存在各种不同种类的BIOS，随着硬件技术的发展，同一种BIOS也先后出现了不同的版本，新版本的BIOS比起老版本来说，功能更强。<br>NORFlash<br>从奔腾时代开始，现代的电脑主板都使用NORFlash来作为BIOS的存储芯片。除了容量比EEPROM更大外，主要是NORFlash具有写入功能 [1]  ，运行电脑通过软件的方式进行BIOS的更新，而无需额外的硬件支持（通常EEPROM的擦写需要不同的电压和条件），且写入速度快。</p>\n"},{"title":"CPU角度理解PCIE","_content":"概述\n为什么需要写这篇文章，当我阅读《深入浅出SSD》这篇书籍中PCIe章节时发现，本书籍的侧重点是放在PCIe控制器和PCIe协议上，从CPU角度理解PCIe知识偏少，本文对下面几个知识点做出一些补充。\n\nCPU访问外设寄存器与内存编址方式；\nCPU如何访问PCIe配置空间；\nCPU能够通过寄存器访问配置空间，为什么还需要映射PCIe配置空间；\n如何扫描PCIe树并且为PCIe分配ID；\n如何将pcie域地址映射到存储器域地址空间。\n通过本篇文章将对问题1、2、3做出解答。\n\n统一编址于独立编址\nCPU编址是程序指令与物理地址线建立链接的方式，在CPU内部有专门的地址集合，编址过程是由CPU体系架构所决定的，参考示意图如图 1所示（仅仅代表示意图，讲解一种逻辑结构，不代表实际电路）。CPU编址时就已经指定了0x8000_0000~0xFFFF_FFFF这个地址空间为连接到图中内存的地址线，内存如何连接到CPU需要当参考CPU的datasheet，当CPU程序指令对0x8000_0000这个物理地址地址发起访问时，等价于是在访问图中2G内存的首地址。\n![](picture1.jpg)\n    图 1\n\n内存通过CPU地址总线来寻址定位，然后通过CPU数据总线读写数据。CPU的地址总线位数是CPU设计时确定，因此一款CPU所能寻址的地址范围是一定的，而内存是需要占用CPU的寻址空间的，内存与CPU采用总线直接连接。\n\nIO指的是与CPU连接的各种外设，CPU访问各种外设有两种方式：一种是类似于访问内存的方式，即把外设的寄存器当成内存地址读写，从文可以以访问内存方式操作外设寄存器。这时，IO与内存统一编址，IO地址与内存地址在同一个地址空间下，这种编址方式叫做IO与内存统一编址。另外一种编址方式是IO地址与内存地址分开独立编址，这种编址方式叫做独立编址，此时，CPU访问外设寄存器需要通过CPU特定的指令去访问外设寄存器，而不能通过地址直接访问外设寄存器。常见的ARM、PowerPc、MIPS架构都是采用统一编址，X86架构采用独立编址。\n\n访问PCIe配置空间256bytes\nPCI总线规定访问配置空间总线事务，使用ID号进行寻址。PCI设备ID号由总线号（Bus Number）、设备号（Device Number）和功能号（Function Number）。其中总线号在HOST主桥遍历PCI总线树时确定，在一颗PCI总线树上，总线号由系统软件决定，通常与HOST主桥直接相连接的PCI总线编号为0，系统软件使用DFS（Depth-First Search）算法扫描PCI总线树上的所有PCI总线，并依次编号。一条PCI总线的设备号由PCI设备的IDSEL信号与PCI总线地址线的连接关系确定，功能号与PCI设备的具体设计有关。一个PCIe系统最多有256条Bus，每条Bus上最多可以挂在32个设备，每个PCIe设备最多有8个功能设备。\n\n在XX处理器中的HOST主桥中，与PCIE设备配置相关的寄存器由CFG_ADDR、CFG_DATA等组成。系统软件使用CFG_ADDR（CFG_ADDR寄存器结构如图 2所示）和CFG_DATA寄存器访问PCIe设备的配置空间，这些寄存器都是采取同一编址（所有内存寄存器都使用存储器映射方式进行寻址）。当处理器访问PCIe配置空间时，首先需要在CFG_ADD寄存器中设置这个PCIe设备对应的总线号、设备号、功能号和寄存器偏移，然后使能Enable位，之后当处理器对CFG_DATA读写访问时，HOST主桥将这个存储器读写访问转换成PCIe配置读写请求，并且发送到PCIe总线上。如果Enable位没有使能，那么CPU对寄存器的访问也就是一个普通IO的访问，而不能让HOST转换成总线请求访问，访问PCIe配置空间时按照PCIe总线标准配置TLP请求，CFG_DATA是读取的数据或者待写入的数据。\n![](picture2.jpg)\n图 2\n\n31位：Enable位，为1时，对CFG_DATA读写才能转换成PCIe总线配置请求。\n30~24位：保留。\n23~16位：总线号，最多=256个。\n15~11位：设备号，最多=32个。\n10~8位：功能号，最多=8个。\n7~2位：寄存器偏移，最多访问寄存器=64个地址，这里一个地址是DW，那么能干访问的PCIe配置空间大小为64*4=256Byte，所以访问PCIe配置空间都是以4字节对齐访问的。\n走到这里很多读者可能就会有这样的疑问，既然CPU能够直接通过寄存器访问配置空间，为啥还会出现配置空间在存储域地址的映射这一说法呢？下面给出详细解答。\n\n访问PCIe配置空间寄存器的方法需要追溯到原始的PCI规范。为了发起PCI总线配置周期，Intel（Intel是PCIe龙头老大，最新的PCIe的规范总是它最先尝试的）实现的PCI规范使用IO空间的CF8h和CFCh来分别作为索引和数据寄存器，这种方法可以访问所有PCI设备的255 bytes配置寄存器。Intel Chipsets目前仍然支持这种访PCI配置空间的方法。PCIe规范在PCI规范的基础上，将配置空间扩展到4K bytes，至于为什么扩展到4K，具体可以参考PCIe规范，这些配置CFG_ADDR和CFG_DATA寄存器方法仍然可以访问所有PCIe设备配置空间的头255 bytes，但是该方法访问不了剩下的（255B~4K）配置空间。怎么办呢？Intel外一种PCIe配置空间访问方法。Intel Chipset通过将配置空间映射到内存地址空间，PCIe配置空间可以像对映射范围内的内存进行read/write来访问了。这种映射是由北桥芯片来完成的，但是不同芯片的映射方式也是不同的。目前我查看了ARM芯片的datasheet，确实是这样的方式。\n\nPCIe规范为每个PCIe设备添加了更多的配置寄存器，空间为4K，尽管CFG_ADDR和CFG_DATA寄存器方法仍然能够访问lower 255 bytes，但是必须提供另外一种方法来访问剩下的（255B~4K）range寄存器。Intel的解决方案是使用了预留256MB内存地址空间，对这段内存的任何访问都会发起PCIe 配置cycle。由于4K的配置空间是directly mapped to memory的，那么PCIe规范必须保证所有的PCIe设备的配置空间占用不同的内存地址，按照PCIe规范，支持最多256个bus，每个Bus支持最多32个PCIe devices，每个device支持最多8个function,也就是说：占用内存的最大值为：256 * 32 * 8 * 4K = 256MB。图 3是ARM Cortex-A9 datasheet内存地址分配局部图。被PCIe配置空间占用的256M内存空间会屏蔽掉DRAM使用该段内存区，这些地址都由CPU出厂时已经固化好了。\n![](picture3.jpg)\n图 3\n\nPCIe配置空间的内存映射对32bit系统的影响\n由于PCIe配置空间占用了256M内存空间，而且该被占用空间对DRAM来说是不可用的，这意味着256M空间消失于系统内存，这在32bit系统中更为明显。比如，在32 bit winxp中（作者目前电脑还是用的XP系统，电脑用了七八年了），理论上可以访问到的内存是4G，如果4G空间都被DRAM给占用，由于PCIe的存在，被PCIe占用的那部分内存空间对OS来说是不可用的，莫名的消失了最多256M内存，其实还有其他外设寄存器需要映射到内存，如果是独立编址就不存在寄存器占用内存。所以在XP系统中实际能够访问DRAM空间最大值为3.2G。64位CPU寻址不存在这个情况，个地址目前来说应该用不完，这里读者需要注意的是CPU有32和64位寻址方式，同样操作系统也有32和64位之分，在Linux系统中主要体现在库文件上。\n\n有些CPU没有直接指定PCIe配置空间的地址范围，需要读取某个寄存器的值BaseAddr，这个值就说PCIe配置寄存器在内存区域映射的基地址。访问PCIe设备配置空间时候需要手动计算访问PCIe配置空间的地址。计算发放如下:\n\nSIZE_PER_FUNC = 4K = 1000h\n\nSIZE_PER_DEVICE = 4K * 8 = 8000h\n\nSIZE_PER_BUS = 4K *8* 32 = 100000h\n\n访问总线号为busNo，设备号为DevNo，功能号为funcNo的offset寄存器的计算公式是：\n\nMemory Address = BaseAddr+ busNo * SIZE_PER_BUS+ devNo * SIZE_PER_DEVICE+ funcNo * SIZE_PER_FUNC+ offset\n\n访问PCIe配置空间就需要通过总线号、设备号、功能号、寄存器偏移进行转换成内存地址。转换函数如图 2所示。\n![](picture4.jpg)\n图 4\n\n问题4和5在下面文章中讲解，介于作者实力有限。如有错误，望读者给出宝贵的意见。\n\n剩下两个问题，上电扫描PCIe树和存储地址到PCIe地址的映射，本篇文章将对这两个问题做出解答。本文可能会针对某一款芯片做出详细流程解答，读者可以只关注整个流程，具体映射机制和寄存器参考芯片datasheet。上篇文章已经了解到如何访问配置空间，前256Bytes可以通过寄存器方式访问，后面的256B~4k必须通过映射才能访问，映射无非就是把配置空间映射到存储地址空间，或者把PCIe设备空间映射到存储地址空间。下面开始讨论映射关系。\n\n地址映射关系\nPCIe在存储域地址空间分为三部分，PCIe控制器本身的寄存器、PCIe设备的配置空间、PCIe设备空间。寄存器和配置空间由处理器本身决定存储地址范围，本款处理器地址范围如图 1所示，配置空间地址、寄存器地址、内存地址都已经确定。PCIe设备空间需要编程人员去配置Outbound和Inbound寄存器组，确定映射关系\n![](picture5.jpg)\n图 5\n\nOutbound在PCIe控制器中扮演的角色是将存储地址翻译到PCIe域的PCIe地址，Inbound是将PCIe地址翻译成存储地址，图 2是一个完整的RC和EP模型地址翻译模型，图中的地址数字仅仅代表一种形态，具体地址应该是什么在后文中讲解。当cpu需要访问EP的内存空间时，首先应该将存储地址转换成PCIe地址，在根据TLP到达指定的EP，进而将PCIe地址转换成EP端的存储地址。\n![](picture6.jpg)\n图 6\n\nPCIe地址到存储地址之间的映射关系由三个寄存器决定（有两个寄存器组应该是32个寄存器）OB_SIZE、OB_OFFSET_INDEXn、OB_OFFSETn_HI，n的范围是0~31。在PCIe控制器中是把PCIe地址等分成32块regions (Regions 0 to 31)，每个regions的大小是可以通过编程设置OB_SIZE寄存器确定大小，大小有1, 2, 4, or 8 MB，那么通过Outbound能够翻译的地址最大为8M*32=256M。存储域地址中有5位作为识别32个regions的index，OB_SIZE的大小决定这5位在32位地址上的位置。当OB_SIZE等于0，1，2，3时，index在存储地址中对应的位置是Bits[24:20], bits[25:21], bits[26:22], and bits[27:23]，每个regions翻倍，是不是对应的地址应该按翻倍对齐呢，翻倍就是左移一位数据。OB_SIZE寄存器如图 3所示。\n![](picture7.jpg)                                                                                      图 7\n\nOB_OFFSET_INDEXn寄存器结构如图 4所示，n是上一段落提到的index的值。该寄存器第0位是地址翻译使能位，第31~20位是第n个regions的基地址的31~20位，这里的取值取决regions的大小，当OB_SIZE 等于0，1，2，3时，bits[31:20], bits[31:21], bits[31:22], and bits[31:23]位相应被使用。OB_OFFSETn_HI寄存器的值是64位PCIe地址中第n个regions的基地址的63~32位，在32位PCIe地址中，该寄存器的值等于0。\n![](picture8.jpg)\n图 8\n\n配置OutBound翻译的几个寄存器也做了详解，下面根据举例说明。图 5中配置空间存储地址由CPU本身架构所决定，这部分的地址映射才芯片内部完成，不需要由编程人员配置。PCIe设备空间被分成了32等分。假设region大小是2M，PCIe地址是64位，程序中需要对0x9D3A_1234存储地址做映射， 64位PCIe地址被使用在region 9上，初始化OBOFFSET9_HI值为0x3344 5566, OB_OFFSET9值56Ex xxxx（x的值这里不关心，看该寄存器结构就很清楚，第0位在地址翻译时候应该使能位1，这里仅仅用来讲解怎么做映射，不需要关心后面的Bits） ，下面分析怎么翻译到PCIe地址：\n\n由于是regions大小2M，那么index应该取地址的bits [25:21]，提取0x9D3A_1234存储地址的bits [25:21得到01001b，该值等于9，那么该地址应该启用regions 9 翻译。存储地址的bits[20:00]是用做翻译到PCIe地址的bits[20:00]位，该值也可以理解成reginos 9内的偏移值，值是0x001A 1234。\n生成regions 块PCIe的基地址，该地址应pcie_base=OBOFFSET9_HI <<32 + OB_OFFSET9的bits[31:21] = 0x 3344 5566 56E0 0000。\n计算PCIe地址，pcie_addr = pcie_base + 存储地址bits[20:0] =0x3344 5566 56FA 1234。\n![](picture9.jpg)\n图 9\n\n从上面存储地址到PCIe地址映射可以看到，通过cpu寻址可以直接访问到PCIe设备空间，最多可以访问PCIe设备空间大小为256M，具体Outbound能够访问的大小根据芯片而定，当CPU与FPGA之间有大量数据交互时候也可以采用Inbound方式（Inbound地址翻译流程如图 6所示，这里就不在翻译），将CPU的内存映射到FPGA的寻址空间（这里是站在CPU角度看的，从图2可以理解具体映射大小还由EP决定），FPGA可以采用DMA方式访问cpu的内存，并且速度很快。有些芯片厂商干脆采用同核异构方式将CPU于FPGA集成在一起（有的将cpu与dsp集成在一起），两者之间采用AXI高速总线通讯。\n![](picture10.jpg)                                                                                    \\图 10\n\n扫描PCIe树\n扫描树的流程如下：\n\n建立存储地址到PCIe地址映射 （映射方式上面段落已经讲解了，固定的PCIe配置空间映射）\n分配PCIe总线号\n分配设备号\n访问配置空间 （这里有一个原则读者需要注意，对PCIe设备配置空间访问时，一定要确定总线号、设备号、功能号、寄存器，不然无法找到设备）\n读写BAR0确定PCIe设备1空间大小\n分配PCIe地址\n分配总线号\n扫描PCIe总线树时，需要对这些PCIe总线进行编号，即初始化PCIe桥（在本文一律指透明桥）的Primary、Secondary和Subordinate Bus寄存器。在Linux内核中采用DFS算法对PCIe总线树进行遍历，DFS算法是按照深度优先的原则遍历PCIe树，局部代码如图 7所示，这里可以跟踪pci_scan_bridge函数，函数采用DFS算法对总线进行编号（后期会讲解搜索树，比较常见hash表、红黑树）。\n![](picture11.jpg)\n图 11\n\n分配设备号\nPCIe设备的IDSEL信号与PCIe总线的AD[31:0]信号的连接关系决定了该设备在这条总线上的设备号。在配置读写总线事务的地址周期中，AD[10:0]已经被信号已经被功能号和寄存器号使用，因此PCIe设备的IDSEL只能与AD[31:11]信号连接。上一篇文章中谈到CONFIG_ADDR寄存器中的Device Number字段一共有5位，最大能够表示32个设备，这里只有21位，显然在两者之间不能建立一一映射关系。一个PCIe总线号下最多可以挂在21个PCIe设备，那么多个PCIe总线不就可以挂载32个设备了么。\n\n访问配置空间\n在32位PCIe地址空间中，PCIe设备通常将PCIe配置存放在E2PROM中，PCIe设备进行上电初始化时，将E2PROM中的信息读到PCIe设备的配置空间作为初始值，由硬件自动完成。BAR0空间存储了PCIe设备空间的大小，某些位被设置成不可预读，当BAR0全部写入1时，然后在读取BAR0值，从数据低位看有多少连续位没有改变。没有改变的数据位数记录的该PCIe设备空间的大小，假如有n位没有改变，那么设备空间大小应该是2的n次方。第0位代表IO/Memory、第2，3位代表32/64位地址、第4位代表是否可预取，具体位定义格式可以直接参考内核PCIe总线代码，解析BAR函数如图 8所示。\n![](picture12.jpg)\n图 12\n\n分配PCIe地址\n系统软件根据根据设备空间大小建立存储地址PCIe设备地址空间的映射，给PCIe设备分配的PCIe基地址写入到BAR0，如果是64位PCIe地址，那么BAR1是高32位地址。\n\n结语\n 写《从cpu角度理解PCIe》文章我参考了部分芯片的datasheet，并结合linux代码分析，本文仅仅起到分析流程的作用，具体映射机制和寄存器芯片参考相应芯片datasheet。如有错误，还望指正。\n","source":"_posts/linux/CPU角度理解PCIE.md","raw":"---\ntitle: CPU角度理解PCIE\ntags: \ncategories:\n- linux\n---\n概述\n为什么需要写这篇文章，当我阅读《深入浅出SSD》这篇书籍中PCIe章节时发现，本书籍的侧重点是放在PCIe控制器和PCIe协议上，从CPU角度理解PCIe知识偏少，本文对下面几个知识点做出一些补充。\n\nCPU访问外设寄存器与内存编址方式；\nCPU如何访问PCIe配置空间；\nCPU能够通过寄存器访问配置空间，为什么还需要映射PCIe配置空间；\n如何扫描PCIe树并且为PCIe分配ID；\n如何将pcie域地址映射到存储器域地址空间。\n通过本篇文章将对问题1、2、3做出解答。\n\n统一编址于独立编址\nCPU编址是程序指令与物理地址线建立链接的方式，在CPU内部有专门的地址集合，编址过程是由CPU体系架构所决定的，参考示意图如图 1所示（仅仅代表示意图，讲解一种逻辑结构，不代表实际电路）。CPU编址时就已经指定了0x8000_0000~0xFFFF_FFFF这个地址空间为连接到图中内存的地址线，内存如何连接到CPU需要当参考CPU的datasheet，当CPU程序指令对0x8000_0000这个物理地址地址发起访问时，等价于是在访问图中2G内存的首地址。\n![](picture1.jpg)\n    图 1\n\n内存通过CPU地址总线来寻址定位，然后通过CPU数据总线读写数据。CPU的地址总线位数是CPU设计时确定，因此一款CPU所能寻址的地址范围是一定的，而内存是需要占用CPU的寻址空间的，内存与CPU采用总线直接连接。\n\nIO指的是与CPU连接的各种外设，CPU访问各种外设有两种方式：一种是类似于访问内存的方式，即把外设的寄存器当成内存地址读写，从文可以以访问内存方式操作外设寄存器。这时，IO与内存统一编址，IO地址与内存地址在同一个地址空间下，这种编址方式叫做IO与内存统一编址。另外一种编址方式是IO地址与内存地址分开独立编址，这种编址方式叫做独立编址，此时，CPU访问外设寄存器需要通过CPU特定的指令去访问外设寄存器，而不能通过地址直接访问外设寄存器。常见的ARM、PowerPc、MIPS架构都是采用统一编址，X86架构采用独立编址。\n\n访问PCIe配置空间256bytes\nPCI总线规定访问配置空间总线事务，使用ID号进行寻址。PCI设备ID号由总线号（Bus Number）、设备号（Device Number）和功能号（Function Number）。其中总线号在HOST主桥遍历PCI总线树时确定，在一颗PCI总线树上，总线号由系统软件决定，通常与HOST主桥直接相连接的PCI总线编号为0，系统软件使用DFS（Depth-First Search）算法扫描PCI总线树上的所有PCI总线，并依次编号。一条PCI总线的设备号由PCI设备的IDSEL信号与PCI总线地址线的连接关系确定，功能号与PCI设备的具体设计有关。一个PCIe系统最多有256条Bus，每条Bus上最多可以挂在32个设备，每个PCIe设备最多有8个功能设备。\n\n在XX处理器中的HOST主桥中，与PCIE设备配置相关的寄存器由CFG_ADDR、CFG_DATA等组成。系统软件使用CFG_ADDR（CFG_ADDR寄存器结构如图 2所示）和CFG_DATA寄存器访问PCIe设备的配置空间，这些寄存器都是采取同一编址（所有内存寄存器都使用存储器映射方式进行寻址）。当处理器访问PCIe配置空间时，首先需要在CFG_ADD寄存器中设置这个PCIe设备对应的总线号、设备号、功能号和寄存器偏移，然后使能Enable位，之后当处理器对CFG_DATA读写访问时，HOST主桥将这个存储器读写访问转换成PCIe配置读写请求，并且发送到PCIe总线上。如果Enable位没有使能，那么CPU对寄存器的访问也就是一个普通IO的访问，而不能让HOST转换成总线请求访问，访问PCIe配置空间时按照PCIe总线标准配置TLP请求，CFG_DATA是读取的数据或者待写入的数据。\n![](picture2.jpg)\n图 2\n\n31位：Enable位，为1时，对CFG_DATA读写才能转换成PCIe总线配置请求。\n30~24位：保留。\n23~16位：总线号，最多=256个。\n15~11位：设备号，最多=32个。\n10~8位：功能号，最多=8个。\n7~2位：寄存器偏移，最多访问寄存器=64个地址，这里一个地址是DW，那么能干访问的PCIe配置空间大小为64*4=256Byte，所以访问PCIe配置空间都是以4字节对齐访问的。\n走到这里很多读者可能就会有这样的疑问，既然CPU能够直接通过寄存器访问配置空间，为啥还会出现配置空间在存储域地址的映射这一说法呢？下面给出详细解答。\n\n访问PCIe配置空间寄存器的方法需要追溯到原始的PCI规范。为了发起PCI总线配置周期，Intel（Intel是PCIe龙头老大，最新的PCIe的规范总是它最先尝试的）实现的PCI规范使用IO空间的CF8h和CFCh来分别作为索引和数据寄存器，这种方法可以访问所有PCI设备的255 bytes配置寄存器。Intel Chipsets目前仍然支持这种访PCI配置空间的方法。PCIe规范在PCI规范的基础上，将配置空间扩展到4K bytes，至于为什么扩展到4K，具体可以参考PCIe规范，这些配置CFG_ADDR和CFG_DATA寄存器方法仍然可以访问所有PCIe设备配置空间的头255 bytes，但是该方法访问不了剩下的（255B~4K）配置空间。怎么办呢？Intel外一种PCIe配置空间访问方法。Intel Chipset通过将配置空间映射到内存地址空间，PCIe配置空间可以像对映射范围内的内存进行read/write来访问了。这种映射是由北桥芯片来完成的，但是不同芯片的映射方式也是不同的。目前我查看了ARM芯片的datasheet，确实是这样的方式。\n\nPCIe规范为每个PCIe设备添加了更多的配置寄存器，空间为4K，尽管CFG_ADDR和CFG_DATA寄存器方法仍然能够访问lower 255 bytes，但是必须提供另外一种方法来访问剩下的（255B~4K）range寄存器。Intel的解决方案是使用了预留256MB内存地址空间，对这段内存的任何访问都会发起PCIe 配置cycle。由于4K的配置空间是directly mapped to memory的，那么PCIe规范必须保证所有的PCIe设备的配置空间占用不同的内存地址，按照PCIe规范，支持最多256个bus，每个Bus支持最多32个PCIe devices，每个device支持最多8个function,也就是说：占用内存的最大值为：256 * 32 * 8 * 4K = 256MB。图 3是ARM Cortex-A9 datasheet内存地址分配局部图。被PCIe配置空间占用的256M内存空间会屏蔽掉DRAM使用该段内存区，这些地址都由CPU出厂时已经固化好了。\n![](picture3.jpg)\n图 3\n\nPCIe配置空间的内存映射对32bit系统的影响\n由于PCIe配置空间占用了256M内存空间，而且该被占用空间对DRAM来说是不可用的，这意味着256M空间消失于系统内存，这在32bit系统中更为明显。比如，在32 bit winxp中（作者目前电脑还是用的XP系统，电脑用了七八年了），理论上可以访问到的内存是4G，如果4G空间都被DRAM给占用，由于PCIe的存在，被PCIe占用的那部分内存空间对OS来说是不可用的，莫名的消失了最多256M内存，其实还有其他外设寄存器需要映射到内存，如果是独立编址就不存在寄存器占用内存。所以在XP系统中实际能够访问DRAM空间最大值为3.2G。64位CPU寻址不存在这个情况，个地址目前来说应该用不完，这里读者需要注意的是CPU有32和64位寻址方式，同样操作系统也有32和64位之分，在Linux系统中主要体现在库文件上。\n\n有些CPU没有直接指定PCIe配置空间的地址范围，需要读取某个寄存器的值BaseAddr，这个值就说PCIe配置寄存器在内存区域映射的基地址。访问PCIe设备配置空间时候需要手动计算访问PCIe配置空间的地址。计算发放如下:\n\nSIZE_PER_FUNC = 4K = 1000h\n\nSIZE_PER_DEVICE = 4K * 8 = 8000h\n\nSIZE_PER_BUS = 4K *8* 32 = 100000h\n\n访问总线号为busNo，设备号为DevNo，功能号为funcNo的offset寄存器的计算公式是：\n\nMemory Address = BaseAddr+ busNo * SIZE_PER_BUS+ devNo * SIZE_PER_DEVICE+ funcNo * SIZE_PER_FUNC+ offset\n\n访问PCIe配置空间就需要通过总线号、设备号、功能号、寄存器偏移进行转换成内存地址。转换函数如图 2所示。\n![](picture4.jpg)\n图 4\n\n问题4和5在下面文章中讲解，介于作者实力有限。如有错误，望读者给出宝贵的意见。\n\n剩下两个问题，上电扫描PCIe树和存储地址到PCIe地址的映射，本篇文章将对这两个问题做出解答。本文可能会针对某一款芯片做出详细流程解答，读者可以只关注整个流程，具体映射机制和寄存器参考芯片datasheet。上篇文章已经了解到如何访问配置空间，前256Bytes可以通过寄存器方式访问，后面的256B~4k必须通过映射才能访问，映射无非就是把配置空间映射到存储地址空间，或者把PCIe设备空间映射到存储地址空间。下面开始讨论映射关系。\n\n地址映射关系\nPCIe在存储域地址空间分为三部分，PCIe控制器本身的寄存器、PCIe设备的配置空间、PCIe设备空间。寄存器和配置空间由处理器本身决定存储地址范围，本款处理器地址范围如图 1所示，配置空间地址、寄存器地址、内存地址都已经确定。PCIe设备空间需要编程人员去配置Outbound和Inbound寄存器组，确定映射关系\n![](picture5.jpg)\n图 5\n\nOutbound在PCIe控制器中扮演的角色是将存储地址翻译到PCIe域的PCIe地址，Inbound是将PCIe地址翻译成存储地址，图 2是一个完整的RC和EP模型地址翻译模型，图中的地址数字仅仅代表一种形态，具体地址应该是什么在后文中讲解。当cpu需要访问EP的内存空间时，首先应该将存储地址转换成PCIe地址，在根据TLP到达指定的EP，进而将PCIe地址转换成EP端的存储地址。\n![](picture6.jpg)\n图 6\n\nPCIe地址到存储地址之间的映射关系由三个寄存器决定（有两个寄存器组应该是32个寄存器）OB_SIZE、OB_OFFSET_INDEXn、OB_OFFSETn_HI，n的范围是0~31。在PCIe控制器中是把PCIe地址等分成32块regions (Regions 0 to 31)，每个regions的大小是可以通过编程设置OB_SIZE寄存器确定大小，大小有1, 2, 4, or 8 MB，那么通过Outbound能够翻译的地址最大为8M*32=256M。存储域地址中有5位作为识别32个regions的index，OB_SIZE的大小决定这5位在32位地址上的位置。当OB_SIZE等于0，1，2，3时，index在存储地址中对应的位置是Bits[24:20], bits[25:21], bits[26:22], and bits[27:23]，每个regions翻倍，是不是对应的地址应该按翻倍对齐呢，翻倍就是左移一位数据。OB_SIZE寄存器如图 3所示。\n![](picture7.jpg)                                                                                      图 7\n\nOB_OFFSET_INDEXn寄存器结构如图 4所示，n是上一段落提到的index的值。该寄存器第0位是地址翻译使能位，第31~20位是第n个regions的基地址的31~20位，这里的取值取决regions的大小，当OB_SIZE 等于0，1，2，3时，bits[31:20], bits[31:21], bits[31:22], and bits[31:23]位相应被使用。OB_OFFSETn_HI寄存器的值是64位PCIe地址中第n个regions的基地址的63~32位，在32位PCIe地址中，该寄存器的值等于0。\n![](picture8.jpg)\n图 8\n\n配置OutBound翻译的几个寄存器也做了详解，下面根据举例说明。图 5中配置空间存储地址由CPU本身架构所决定，这部分的地址映射才芯片内部完成，不需要由编程人员配置。PCIe设备空间被分成了32等分。假设region大小是2M，PCIe地址是64位，程序中需要对0x9D3A_1234存储地址做映射， 64位PCIe地址被使用在region 9上，初始化OBOFFSET9_HI值为0x3344 5566, OB_OFFSET9值56Ex xxxx（x的值这里不关心，看该寄存器结构就很清楚，第0位在地址翻译时候应该使能位1，这里仅仅用来讲解怎么做映射，不需要关心后面的Bits） ，下面分析怎么翻译到PCIe地址：\n\n由于是regions大小2M，那么index应该取地址的bits [25:21]，提取0x9D3A_1234存储地址的bits [25:21得到01001b，该值等于9，那么该地址应该启用regions 9 翻译。存储地址的bits[20:00]是用做翻译到PCIe地址的bits[20:00]位，该值也可以理解成reginos 9内的偏移值，值是0x001A 1234。\n生成regions 块PCIe的基地址，该地址应pcie_base=OBOFFSET9_HI <<32 + OB_OFFSET9的bits[31:21] = 0x 3344 5566 56E0 0000。\n计算PCIe地址，pcie_addr = pcie_base + 存储地址bits[20:0] =0x3344 5566 56FA 1234。\n![](picture9.jpg)\n图 9\n\n从上面存储地址到PCIe地址映射可以看到，通过cpu寻址可以直接访问到PCIe设备空间，最多可以访问PCIe设备空间大小为256M，具体Outbound能够访问的大小根据芯片而定，当CPU与FPGA之间有大量数据交互时候也可以采用Inbound方式（Inbound地址翻译流程如图 6所示，这里就不在翻译），将CPU的内存映射到FPGA的寻址空间（这里是站在CPU角度看的，从图2可以理解具体映射大小还由EP决定），FPGA可以采用DMA方式访问cpu的内存，并且速度很快。有些芯片厂商干脆采用同核异构方式将CPU于FPGA集成在一起（有的将cpu与dsp集成在一起），两者之间采用AXI高速总线通讯。\n![](picture10.jpg)                                                                                    \\图 10\n\n扫描PCIe树\n扫描树的流程如下：\n\n建立存储地址到PCIe地址映射 （映射方式上面段落已经讲解了，固定的PCIe配置空间映射）\n分配PCIe总线号\n分配设备号\n访问配置空间 （这里有一个原则读者需要注意，对PCIe设备配置空间访问时，一定要确定总线号、设备号、功能号、寄存器，不然无法找到设备）\n读写BAR0确定PCIe设备1空间大小\n分配PCIe地址\n分配总线号\n扫描PCIe总线树时，需要对这些PCIe总线进行编号，即初始化PCIe桥（在本文一律指透明桥）的Primary、Secondary和Subordinate Bus寄存器。在Linux内核中采用DFS算法对PCIe总线树进行遍历，DFS算法是按照深度优先的原则遍历PCIe树，局部代码如图 7所示，这里可以跟踪pci_scan_bridge函数，函数采用DFS算法对总线进行编号（后期会讲解搜索树，比较常见hash表、红黑树）。\n![](picture11.jpg)\n图 11\n\n分配设备号\nPCIe设备的IDSEL信号与PCIe总线的AD[31:0]信号的连接关系决定了该设备在这条总线上的设备号。在配置读写总线事务的地址周期中，AD[10:0]已经被信号已经被功能号和寄存器号使用，因此PCIe设备的IDSEL只能与AD[31:11]信号连接。上一篇文章中谈到CONFIG_ADDR寄存器中的Device Number字段一共有5位，最大能够表示32个设备，这里只有21位，显然在两者之间不能建立一一映射关系。一个PCIe总线号下最多可以挂在21个PCIe设备，那么多个PCIe总线不就可以挂载32个设备了么。\n\n访问配置空间\n在32位PCIe地址空间中，PCIe设备通常将PCIe配置存放在E2PROM中，PCIe设备进行上电初始化时，将E2PROM中的信息读到PCIe设备的配置空间作为初始值，由硬件自动完成。BAR0空间存储了PCIe设备空间的大小，某些位被设置成不可预读，当BAR0全部写入1时，然后在读取BAR0值，从数据低位看有多少连续位没有改变。没有改变的数据位数记录的该PCIe设备空间的大小，假如有n位没有改变，那么设备空间大小应该是2的n次方。第0位代表IO/Memory、第2，3位代表32/64位地址、第4位代表是否可预取，具体位定义格式可以直接参考内核PCIe总线代码，解析BAR函数如图 8所示。\n![](picture12.jpg)\n图 12\n\n分配PCIe地址\n系统软件根据根据设备空间大小建立存储地址PCIe设备地址空间的映射，给PCIe设备分配的PCIe基地址写入到BAR0，如果是64位PCIe地址，那么BAR1是高32位地址。\n\n结语\n 写《从cpu角度理解PCIe》文章我参考了部分芯片的datasheet，并结合linux代码分析，本文仅仅起到分析流程的作用，具体映射机制和寄存器芯片参考相应芯片datasheet。如有错误，还望指正。\n","slug":"linux/CPU角度理解PCIE","published":1,"date":"2020-08-12T16:05:46.120Z","updated":"2020-02-13T12:47:44.273Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmc7000ihohx5ctccebh","content":"<p>概述<br>为什么需要写这篇文章，当我阅读《深入浅出SSD》这篇书籍中PCIe章节时发现，本书籍的侧重点是放在PCIe控制器和PCIe协议上，从CPU角度理解PCIe知识偏少，本文对下面几个知识点做出一些补充。</p>\n<p>CPU访问外设寄存器与内存编址方式；<br>CPU如何访问PCIe配置空间；<br>CPU能够通过寄存器访问配置空间，为什么还需要映射PCIe配置空间；<br>如何扫描PCIe树并且为PCIe分配ID；<br>如何将pcie域地址映射到存储器域地址空间。<br>通过本篇文章将对问题1、2、3做出解答。</p>\n<p>统一编址于独立编址<br>CPU编址是程序指令与物理地址线建立链接的方式，在CPU内部有专门的地址集合，编址过程是由CPU体系架构所决定的，参考示意图如图 1所示（仅仅代表示意图，讲解一种逻辑结构，不代表实际电路）。CPU编址时就已经指定了0x8000_0000~0xFFFF_FFFF这个地址空间为连接到图中内存的地址线，内存如何连接到CPU需要当参考CPU的datasheet，当CPU程序指令对0x8000_0000这个物理地址地址发起访问时，等价于是在访问图中2G内存的首地址。<br><img src=\"picture1.jpg\" alt=\"\"><br>    图 1</p>\n<p>内存通过CPU地址总线来寻址定位，然后通过CPU数据总线读写数据。CPU的地址总线位数是CPU设计时确定，因此一款CPU所能寻址的地址范围是一定的，而内存是需要占用CPU的寻址空间的，内存与CPU采用总线直接连接。</p>\n<p>IO指的是与CPU连接的各种外设，CPU访问各种外设有两种方式：一种是类似于访问内存的方式，即把外设的寄存器当成内存地址读写，从文可以以访问内存方式操作外设寄存器。这时，IO与内存统一编址，IO地址与内存地址在同一个地址空间下，这种编址方式叫做IO与内存统一编址。另外一种编址方式是IO地址与内存地址分开独立编址，这种编址方式叫做独立编址，此时，CPU访问外设寄存器需要通过CPU特定的指令去访问外设寄存器，而不能通过地址直接访问外设寄存器。常见的ARM、PowerPc、MIPS架构都是采用统一编址，X86架构采用独立编址。</p>\n<p>访问PCIe配置空间256bytes<br>PCI总线规定访问配置空间总线事务，使用ID号进行寻址。PCI设备ID号由总线号（Bus Number）、设备号（Device Number）和功能号（Function Number）。其中总线号在HOST主桥遍历PCI总线树时确定，在一颗PCI总线树上，总线号由系统软件决定，通常与HOST主桥直接相连接的PCI总线编号为0，系统软件使用DFS（Depth-First Search）算法扫描PCI总线树上的所有PCI总线，并依次编号。一条PCI总线的设备号由PCI设备的IDSEL信号与PCI总线地址线的连接关系确定，功能号与PCI设备的具体设计有关。一个PCIe系统最多有256条Bus，每条Bus上最多可以挂在32个设备，每个PCIe设备最多有8个功能设备。</p>\n<p>在XX处理器中的HOST主桥中，与PCIE设备配置相关的寄存器由CFG_ADDR、CFG_DATA等组成。系统软件使用CFG_ADDR（CFG_ADDR寄存器结构如图 2所示）和CFG_DATA寄存器访问PCIe设备的配置空间，这些寄存器都是采取同一编址（所有内存寄存器都使用存储器映射方式进行寻址）。当处理器访问PCIe配置空间时，首先需要在CFG_ADD寄存器中设置这个PCIe设备对应的总线号、设备号、功能号和寄存器偏移，然后使能Enable位，之后当处理器对CFG_DATA读写访问时，HOST主桥将这个存储器读写访问转换成PCIe配置读写请求，并且发送到PCIe总线上。如果Enable位没有使能，那么CPU对寄存器的访问也就是一个普通IO的访问，而不能让HOST转换成总线请求访问，访问PCIe配置空间时按照PCIe总线标准配置TLP请求，CFG_DATA是读取的数据或者待写入的数据。<br><img src=\"picture2.jpg\" alt=\"\"><br>图 2</p>\n<p>31位：Enable位，为1时，对CFG_DATA读写才能转换成PCIe总线配置请求。<br>30<del>24位：保留。<br>23</del>16位：总线号，最多=256个。<br>15<del>11位：设备号，最多=32个。<br>10</del>8位：功能号，最多=8个。<br>7~2位：寄存器偏移，最多访问寄存器=64个地址，这里一个地址是DW，那么能干访问的PCIe配置空间大小为64*4=256Byte，所以访问PCIe配置空间都是以4字节对齐访问的。<br>走到这里很多读者可能就会有这样的疑问，既然CPU能够直接通过寄存器访问配置空间，为啥还会出现配置空间在存储域地址的映射这一说法呢？下面给出详细解答。</p>\n<p>访问PCIe配置空间寄存器的方法需要追溯到原始的PCI规范。为了发起PCI总线配置周期，Intel（Intel是PCIe龙头老大，最新的PCIe的规范总是它最先尝试的）实现的PCI规范使用IO空间的CF8h和CFCh来分别作为索引和数据寄存器，这种方法可以访问所有PCI设备的255 bytes配置寄存器。Intel Chipsets目前仍然支持这种访PCI配置空间的方法。PCIe规范在PCI规范的基础上，将配置空间扩展到4K bytes，至于为什么扩展到4K，具体可以参考PCIe规范，这些配置CFG_ADDR和CFG_DATA寄存器方法仍然可以访问所有PCIe设备配置空间的头255 bytes，但是该方法访问不了剩下的（255B~4K）配置空间。怎么办呢？Intel外一种PCIe配置空间访问方法。Intel Chipset通过将配置空间映射到内存地址空间，PCIe配置空间可以像对映射范围内的内存进行read/write来访问了。这种映射是由北桥芯片来完成的，但是不同芯片的映射方式也是不同的。目前我查看了ARM芯片的datasheet，确实是这样的方式。</p>\n<p>PCIe规范为每个PCIe设备添加了更多的配置寄存器，空间为4K，尽管CFG_ADDR和CFG_DATA寄存器方法仍然能够访问lower 255 bytes，但是必须提供另外一种方法来访问剩下的（255B~4K）range寄存器。Intel的解决方案是使用了预留256MB内存地址空间，对这段内存的任何访问都会发起PCIe 配置cycle。由于4K的配置空间是directly mapped to memory的，那么PCIe规范必须保证所有的PCIe设备的配置空间占用不同的内存地址，按照PCIe规范，支持最多256个bus，每个Bus支持最多32个PCIe devices，每个device支持最多8个function,也就是说：占用内存的最大值为：256 * 32 * 8 * 4K = 256MB。图 3是ARM Cortex-A9 datasheet内存地址分配局部图。被PCIe配置空间占用的256M内存空间会屏蔽掉DRAM使用该段内存区，这些地址都由CPU出厂时已经固化好了。<br><img src=\"picture3.jpg\" alt=\"\"><br>图 3</p>\n<p>PCIe配置空间的内存映射对32bit系统的影响<br>由于PCIe配置空间占用了256M内存空间，而且该被占用空间对DRAM来说是不可用的，这意味着256M空间消失于系统内存，这在32bit系统中更为明显。比如，在32 bit winxp中（作者目前电脑还是用的XP系统，电脑用了七八年了），理论上可以访问到的内存是4G，如果4G空间都被DRAM给占用，由于PCIe的存在，被PCIe占用的那部分内存空间对OS来说是不可用的，莫名的消失了最多256M内存，其实还有其他外设寄存器需要映射到内存，如果是独立编址就不存在寄存器占用内存。所以在XP系统中实际能够访问DRAM空间最大值为3.2G。64位CPU寻址不存在这个情况，个地址目前来说应该用不完，这里读者需要注意的是CPU有32和64位寻址方式，同样操作系统也有32和64位之分，在Linux系统中主要体现在库文件上。</p>\n<p>有些CPU没有直接指定PCIe配置空间的地址范围，需要读取某个寄存器的值BaseAddr，这个值就说PCIe配置寄存器在内存区域映射的基地址。访问PCIe设备配置空间时候需要手动计算访问PCIe配置空间的地址。计算发放如下:</p>\n<p>SIZE_PER_FUNC = 4K = 1000h</p>\n<p>SIZE_PER_DEVICE = 4K * 8 = 8000h</p>\n<p>SIZE_PER_BUS = 4K <em>8</em> 32 = 100000h</p>\n<p>访问总线号为busNo，设备号为DevNo，功能号为funcNo的offset寄存器的计算公式是：</p>\n<p>Memory Address = BaseAddr+ busNo * SIZE_PER_BUS+ devNo * SIZE_PER_DEVICE+ funcNo * SIZE_PER_FUNC+ offset</p>\n<p>访问PCIe配置空间就需要通过总线号、设备号、功能号、寄存器偏移进行转换成内存地址。转换函数如图 2所示。<br><img src=\"picture4.jpg\" alt=\"\"><br>图 4</p>\n<p>问题4和5在下面文章中讲解，介于作者实力有限。如有错误，望读者给出宝贵的意见。</p>\n<p>剩下两个问题，上电扫描PCIe树和存储地址到PCIe地址的映射，本篇文章将对这两个问题做出解答。本文可能会针对某一款芯片做出详细流程解答，读者可以只关注整个流程，具体映射机制和寄存器参考芯片datasheet。上篇文章已经了解到如何访问配置空间，前256Bytes可以通过寄存器方式访问，后面的256B~4k必须通过映射才能访问，映射无非就是把配置空间映射到存储地址空间，或者把PCIe设备空间映射到存储地址空间。下面开始讨论映射关系。</p>\n<p>地址映射关系<br>PCIe在存储域地址空间分为三部分，PCIe控制器本身的寄存器、PCIe设备的配置空间、PCIe设备空间。寄存器和配置空间由处理器本身决定存储地址范围，本款处理器地址范围如图 1所示，配置空间地址、寄存器地址、内存地址都已经确定。PCIe设备空间需要编程人员去配置Outbound和Inbound寄存器组，确定映射关系<br><img src=\"picture5.jpg\" alt=\"\"><br>图 5</p>\n<p>Outbound在PCIe控制器中扮演的角色是将存储地址翻译到PCIe域的PCIe地址，Inbound是将PCIe地址翻译成存储地址，图 2是一个完整的RC和EP模型地址翻译模型，图中的地址数字仅仅代表一种形态，具体地址应该是什么在后文中讲解。当cpu需要访问EP的内存空间时，首先应该将存储地址转换成PCIe地址，在根据TLP到达指定的EP，进而将PCIe地址转换成EP端的存储地址。<br><img src=\"picture6.jpg\" alt=\"\"><br>图 6</p>\n<p>PCIe地址到存储地址之间的映射关系由三个寄存器决定（有两个寄存器组应该是32个寄存器）OB_SIZE、OB_OFFSET_INDEXn、OB_OFFSETn_HI，n的范围是0~31。在PCIe控制器中是把PCIe地址等分成32块regions (Regions 0 to 31)，每个regions的大小是可以通过编程设置OB_SIZE寄存器确定大小，大小有1, 2, 4, or 8 MB，那么通过Outbound能够翻译的地址最大为8M*32=256M。存储域地址中有5位作为识别32个regions的index，OB_SIZE的大小决定这5位在32位地址上的位置。当OB_SIZE等于0，1，2，3时，index在存储地址中对应的位置是Bits[24:20], bits[25:21], bits[26:22], and bits[27:23]，每个regions翻倍，是不是对应的地址应该按翻倍对齐呢，翻倍就是左移一位数据。OB_SIZE寄存器如图 3所示。<br><img src=\"picture7.jpg\" alt=\"\">                                                                                      图 7</p>\n<p>OB_OFFSET_INDEXn寄存器结构如图 4所示，n是上一段落提到的index的值。该寄存器第0位是地址翻译使能位，第31<del>20位是第n个regions的基地址的31</del>20位，这里的取值取决regions的大小，当OB_SIZE 等于0，1，2，3时，bits[31:20], bits[31:21], bits[31:22], and bits[31:23]位相应被使用。OB_OFFSETn_HI寄存器的值是64位PCIe地址中第n个regions的基地址的63~32位，在32位PCIe地址中，该寄存器的值等于0。<br><img src=\"picture8.jpg\" alt=\"\"><br>图 8</p>\n<p>配置OutBound翻译的几个寄存器也做了详解，下面根据举例说明。图 5中配置空间存储地址由CPU本身架构所决定，这部分的地址映射才芯片内部完成，不需要由编程人员配置。PCIe设备空间被分成了32等分。假设region大小是2M，PCIe地址是64位，程序中需要对0x9D3A_1234存储地址做映射， 64位PCIe地址被使用在region 9上，初始化OBOFFSET9_HI值为0x3344 5566, OB_OFFSET9值56Ex xxxx（x的值这里不关心，看该寄存器结构就很清楚，第0位在地址翻译时候应该使能位1，这里仅仅用来讲解怎么做映射，不需要关心后面的Bits） ，下面分析怎么翻译到PCIe地址：</p>\n<p>由于是regions大小2M，那么index应该取地址的bits [25:21]，提取0x9D3A_1234存储地址的bits [25:21得到01001b，该值等于9，那么该地址应该启用regions 9 翻译。存储地址的bits[20:00]是用做翻译到PCIe地址的bits[20:00]位，该值也可以理解成reginos 9内的偏移值，值是0x001A 1234。<br>生成regions 块PCIe的基地址，该地址应pcie_base=OBOFFSET9_HI &lt;&lt;32 + OB_OFFSET9的bits[31:21] = 0x 3344 5566 56E0 0000。<br>计算PCIe地址，pcie_addr = pcie_base + 存储地址bits[20:0] =0x3344 5566 56FA 1234。<br><img src=\"picture9.jpg\" alt=\"\"><br>图 9</p>\n<p>从上面存储地址到PCIe地址映射可以看到，通过cpu寻址可以直接访问到PCIe设备空间，最多可以访问PCIe设备空间大小为256M，具体Outbound能够访问的大小根据芯片而定，当CPU与FPGA之间有大量数据交互时候也可以采用Inbound方式（Inbound地址翻译流程如图 6所示，这里就不在翻译），将CPU的内存映射到FPGA的寻址空间（这里是站在CPU角度看的，从图2可以理解具体映射大小还由EP决定），FPGA可以采用DMA方式访问cpu的内存，并且速度很快。有些芯片厂商干脆采用同核异构方式将CPU于FPGA集成在一起（有的将cpu与dsp集成在一起），两者之间采用AXI高速总线通讯。<br><img src=\"picture10.jpg\" alt=\"\">                                                                                    \\图 10</p>\n<p>扫描PCIe树<br>扫描树的流程如下：</p>\n<p>建立存储地址到PCIe地址映射 （映射方式上面段落已经讲解了，固定的PCIe配置空间映射）<br>分配PCIe总线号<br>分配设备号<br>访问配置空间 （这里有一个原则读者需要注意，对PCIe设备配置空间访问时，一定要确定总线号、设备号、功能号、寄存器，不然无法找到设备）<br>读写BAR0确定PCIe设备1空间大小<br>分配PCIe地址<br>分配总线号<br>扫描PCIe总线树时，需要对这些PCIe总线进行编号，即初始化PCIe桥（在本文一律指透明桥）的Primary、Secondary和Subordinate Bus寄存器。在Linux内核中采用DFS算法对PCIe总线树进行遍历，DFS算法是按照深度优先的原则遍历PCIe树，局部代码如图 7所示，这里可以跟踪pci_scan_bridge函数，函数采用DFS算法对总线进行编号（后期会讲解搜索树，比较常见hash表、红黑树）。<br><img src=\"picture11.jpg\" alt=\"\"><br>图 11</p>\n<p>分配设备号<br>PCIe设备的IDSEL信号与PCIe总线的AD[31:0]信号的连接关系决定了该设备在这条总线上的设备号。在配置读写总线事务的地址周期中，AD[10:0]已经被信号已经被功能号和寄存器号使用，因此PCIe设备的IDSEL只能与AD[31:11]信号连接。上一篇文章中谈到CONFIG_ADDR寄存器中的Device Number字段一共有5位，最大能够表示32个设备，这里只有21位，显然在两者之间不能建立一一映射关系。一个PCIe总线号下最多可以挂在21个PCIe设备，那么多个PCIe总线不就可以挂载32个设备了么。</p>\n<p>访问配置空间<br>在32位PCIe地址空间中，PCIe设备通常将PCIe配置存放在E2PROM中，PCIe设备进行上电初始化时，将E2PROM中的信息读到PCIe设备的配置空间作为初始值，由硬件自动完成。BAR0空间存储了PCIe设备空间的大小，某些位被设置成不可预读，当BAR0全部写入1时，然后在读取BAR0值，从数据低位看有多少连续位没有改变。没有改变的数据位数记录的该PCIe设备空间的大小，假如有n位没有改变，那么设备空间大小应该是2的n次方。第0位代表IO/Memory、第2，3位代表32/64位地址、第4位代表是否可预取，具体位定义格式可以直接参考内核PCIe总线代码，解析BAR函数如图 8所示。<br><img src=\"picture12.jpg\" alt=\"\"><br>图 12</p>\n<p>分配PCIe地址<br>系统软件根据根据设备空间大小建立存储地址PCIe设备地址空间的映射，给PCIe设备分配的PCIe基地址写入到BAR0，如果是64位PCIe地址，那么BAR1是高32位地址。</p>\n<p>结语<br> 写《从cpu角度理解PCIe》文章我参考了部分芯片的datasheet，并结合linux代码分析，本文仅仅起到分析流程的作用，具体映射机制和寄存器芯片参考相应芯片datasheet。如有错误，还望指正。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>概述<br>为什么需要写这篇文章，当我阅读《深入浅出SSD》这篇书籍中PCIe章节时发现，本书籍的侧重点是放在PCIe控制器和PCIe协议上，从CPU角度理解PCIe知识偏少，本文对下面几个知识点做出一些补充。</p>\n<p>CPU访问外设寄存器与内存编址方式；<br>CPU如何访问PCIe配置空间；<br>CPU能够通过寄存器访问配置空间，为什么还需要映射PCIe配置空间；<br>如何扫描PCIe树并且为PCIe分配ID；<br>如何将pcie域地址映射到存储器域地址空间。<br>通过本篇文章将对问题1、2、3做出解答。</p>\n<p>统一编址于独立编址<br>CPU编址是程序指令与物理地址线建立链接的方式，在CPU内部有专门的地址集合，编址过程是由CPU体系架构所决定的，参考示意图如图 1所示（仅仅代表示意图，讲解一种逻辑结构，不代表实际电路）。CPU编址时就已经指定了0x8000_0000~0xFFFF_FFFF这个地址空间为连接到图中内存的地址线，内存如何连接到CPU需要当参考CPU的datasheet，当CPU程序指令对0x8000_0000这个物理地址地址发起访问时，等价于是在访问图中2G内存的首地址。<br><img src=\"picture1.jpg\" alt=\"\"><br>    图 1</p>\n<p>内存通过CPU地址总线来寻址定位，然后通过CPU数据总线读写数据。CPU的地址总线位数是CPU设计时确定，因此一款CPU所能寻址的地址范围是一定的，而内存是需要占用CPU的寻址空间的，内存与CPU采用总线直接连接。</p>\n<p>IO指的是与CPU连接的各种外设，CPU访问各种外设有两种方式：一种是类似于访问内存的方式，即把外设的寄存器当成内存地址读写，从文可以以访问内存方式操作外设寄存器。这时，IO与内存统一编址，IO地址与内存地址在同一个地址空间下，这种编址方式叫做IO与内存统一编址。另外一种编址方式是IO地址与内存地址分开独立编址，这种编址方式叫做独立编址，此时，CPU访问外设寄存器需要通过CPU特定的指令去访问外设寄存器，而不能通过地址直接访问外设寄存器。常见的ARM、PowerPc、MIPS架构都是采用统一编址，X86架构采用独立编址。</p>\n<p>访问PCIe配置空间256bytes<br>PCI总线规定访问配置空间总线事务，使用ID号进行寻址。PCI设备ID号由总线号（Bus Number）、设备号（Device Number）和功能号（Function Number）。其中总线号在HOST主桥遍历PCI总线树时确定，在一颗PCI总线树上，总线号由系统软件决定，通常与HOST主桥直接相连接的PCI总线编号为0，系统软件使用DFS（Depth-First Search）算法扫描PCI总线树上的所有PCI总线，并依次编号。一条PCI总线的设备号由PCI设备的IDSEL信号与PCI总线地址线的连接关系确定，功能号与PCI设备的具体设计有关。一个PCIe系统最多有256条Bus，每条Bus上最多可以挂在32个设备，每个PCIe设备最多有8个功能设备。</p>\n<p>在XX处理器中的HOST主桥中，与PCIE设备配置相关的寄存器由CFG_ADDR、CFG_DATA等组成。系统软件使用CFG_ADDR（CFG_ADDR寄存器结构如图 2所示）和CFG_DATA寄存器访问PCIe设备的配置空间，这些寄存器都是采取同一编址（所有内存寄存器都使用存储器映射方式进行寻址）。当处理器访问PCIe配置空间时，首先需要在CFG_ADD寄存器中设置这个PCIe设备对应的总线号、设备号、功能号和寄存器偏移，然后使能Enable位，之后当处理器对CFG_DATA读写访问时，HOST主桥将这个存储器读写访问转换成PCIe配置读写请求，并且发送到PCIe总线上。如果Enable位没有使能，那么CPU对寄存器的访问也就是一个普通IO的访问，而不能让HOST转换成总线请求访问，访问PCIe配置空间时按照PCIe总线标准配置TLP请求，CFG_DATA是读取的数据或者待写入的数据。<br><img src=\"picture2.jpg\" alt=\"\"><br>图 2</p>\n<p>31位：Enable位，为1时，对CFG_DATA读写才能转换成PCIe总线配置请求。<br>30<del>24位：保留。<br>23</del>16位：总线号，最多=256个。<br>15<del>11位：设备号，最多=32个。<br>10</del>8位：功能号，最多=8个。<br>7~2位：寄存器偏移，最多访问寄存器=64个地址，这里一个地址是DW，那么能干访问的PCIe配置空间大小为64*4=256Byte，所以访问PCIe配置空间都是以4字节对齐访问的。<br>走到这里很多读者可能就会有这样的疑问，既然CPU能够直接通过寄存器访问配置空间，为啥还会出现配置空间在存储域地址的映射这一说法呢？下面给出详细解答。</p>\n<p>访问PCIe配置空间寄存器的方法需要追溯到原始的PCI规范。为了发起PCI总线配置周期，Intel（Intel是PCIe龙头老大，最新的PCIe的规范总是它最先尝试的）实现的PCI规范使用IO空间的CF8h和CFCh来分别作为索引和数据寄存器，这种方法可以访问所有PCI设备的255 bytes配置寄存器。Intel Chipsets目前仍然支持这种访PCI配置空间的方法。PCIe规范在PCI规范的基础上，将配置空间扩展到4K bytes，至于为什么扩展到4K，具体可以参考PCIe规范，这些配置CFG_ADDR和CFG_DATA寄存器方法仍然可以访问所有PCIe设备配置空间的头255 bytes，但是该方法访问不了剩下的（255B~4K）配置空间。怎么办呢？Intel外一种PCIe配置空间访问方法。Intel Chipset通过将配置空间映射到内存地址空间，PCIe配置空间可以像对映射范围内的内存进行read/write来访问了。这种映射是由北桥芯片来完成的，但是不同芯片的映射方式也是不同的。目前我查看了ARM芯片的datasheet，确实是这样的方式。</p>\n<p>PCIe规范为每个PCIe设备添加了更多的配置寄存器，空间为4K，尽管CFG_ADDR和CFG_DATA寄存器方法仍然能够访问lower 255 bytes，但是必须提供另外一种方法来访问剩下的（255B~4K）range寄存器。Intel的解决方案是使用了预留256MB内存地址空间，对这段内存的任何访问都会发起PCIe 配置cycle。由于4K的配置空间是directly mapped to memory的，那么PCIe规范必须保证所有的PCIe设备的配置空间占用不同的内存地址，按照PCIe规范，支持最多256个bus，每个Bus支持最多32个PCIe devices，每个device支持最多8个function,也就是说：占用内存的最大值为：256 * 32 * 8 * 4K = 256MB。图 3是ARM Cortex-A9 datasheet内存地址分配局部图。被PCIe配置空间占用的256M内存空间会屏蔽掉DRAM使用该段内存区，这些地址都由CPU出厂时已经固化好了。<br><img src=\"picture3.jpg\" alt=\"\"><br>图 3</p>\n<p>PCIe配置空间的内存映射对32bit系统的影响<br>由于PCIe配置空间占用了256M内存空间，而且该被占用空间对DRAM来说是不可用的，这意味着256M空间消失于系统内存，这在32bit系统中更为明显。比如，在32 bit winxp中（作者目前电脑还是用的XP系统，电脑用了七八年了），理论上可以访问到的内存是4G，如果4G空间都被DRAM给占用，由于PCIe的存在，被PCIe占用的那部分内存空间对OS来说是不可用的，莫名的消失了最多256M内存，其实还有其他外设寄存器需要映射到内存，如果是独立编址就不存在寄存器占用内存。所以在XP系统中实际能够访问DRAM空间最大值为3.2G。64位CPU寻址不存在这个情况，个地址目前来说应该用不完，这里读者需要注意的是CPU有32和64位寻址方式，同样操作系统也有32和64位之分，在Linux系统中主要体现在库文件上。</p>\n<p>有些CPU没有直接指定PCIe配置空间的地址范围，需要读取某个寄存器的值BaseAddr，这个值就说PCIe配置寄存器在内存区域映射的基地址。访问PCIe设备配置空间时候需要手动计算访问PCIe配置空间的地址。计算发放如下:</p>\n<p>SIZE_PER_FUNC = 4K = 1000h</p>\n<p>SIZE_PER_DEVICE = 4K * 8 = 8000h</p>\n<p>SIZE_PER_BUS = 4K <em>8</em> 32 = 100000h</p>\n<p>访问总线号为busNo，设备号为DevNo，功能号为funcNo的offset寄存器的计算公式是：</p>\n<p>Memory Address = BaseAddr+ busNo * SIZE_PER_BUS+ devNo * SIZE_PER_DEVICE+ funcNo * SIZE_PER_FUNC+ offset</p>\n<p>访问PCIe配置空间就需要通过总线号、设备号、功能号、寄存器偏移进行转换成内存地址。转换函数如图 2所示。<br><img src=\"picture4.jpg\" alt=\"\"><br>图 4</p>\n<p>问题4和5在下面文章中讲解，介于作者实力有限。如有错误，望读者给出宝贵的意见。</p>\n<p>剩下两个问题，上电扫描PCIe树和存储地址到PCIe地址的映射，本篇文章将对这两个问题做出解答。本文可能会针对某一款芯片做出详细流程解答，读者可以只关注整个流程，具体映射机制和寄存器参考芯片datasheet。上篇文章已经了解到如何访问配置空间，前256Bytes可以通过寄存器方式访问，后面的256B~4k必须通过映射才能访问，映射无非就是把配置空间映射到存储地址空间，或者把PCIe设备空间映射到存储地址空间。下面开始讨论映射关系。</p>\n<p>地址映射关系<br>PCIe在存储域地址空间分为三部分，PCIe控制器本身的寄存器、PCIe设备的配置空间、PCIe设备空间。寄存器和配置空间由处理器本身决定存储地址范围，本款处理器地址范围如图 1所示，配置空间地址、寄存器地址、内存地址都已经确定。PCIe设备空间需要编程人员去配置Outbound和Inbound寄存器组，确定映射关系<br><img src=\"picture5.jpg\" alt=\"\"><br>图 5</p>\n<p>Outbound在PCIe控制器中扮演的角色是将存储地址翻译到PCIe域的PCIe地址，Inbound是将PCIe地址翻译成存储地址，图 2是一个完整的RC和EP模型地址翻译模型，图中的地址数字仅仅代表一种形态，具体地址应该是什么在后文中讲解。当cpu需要访问EP的内存空间时，首先应该将存储地址转换成PCIe地址，在根据TLP到达指定的EP，进而将PCIe地址转换成EP端的存储地址。<br><img src=\"picture6.jpg\" alt=\"\"><br>图 6</p>\n<p>PCIe地址到存储地址之间的映射关系由三个寄存器决定（有两个寄存器组应该是32个寄存器）OB_SIZE、OB_OFFSET_INDEXn、OB_OFFSETn_HI，n的范围是0~31。在PCIe控制器中是把PCIe地址等分成32块regions (Regions 0 to 31)，每个regions的大小是可以通过编程设置OB_SIZE寄存器确定大小，大小有1, 2, 4, or 8 MB，那么通过Outbound能够翻译的地址最大为8M*32=256M。存储域地址中有5位作为识别32个regions的index，OB_SIZE的大小决定这5位在32位地址上的位置。当OB_SIZE等于0，1，2，3时，index在存储地址中对应的位置是Bits[24:20], bits[25:21], bits[26:22], and bits[27:23]，每个regions翻倍，是不是对应的地址应该按翻倍对齐呢，翻倍就是左移一位数据。OB_SIZE寄存器如图 3所示。<br><img src=\"picture7.jpg\" alt=\"\">                                                                                      图 7</p>\n<p>OB_OFFSET_INDEXn寄存器结构如图 4所示，n是上一段落提到的index的值。该寄存器第0位是地址翻译使能位，第31<del>20位是第n个regions的基地址的31</del>20位，这里的取值取决regions的大小，当OB_SIZE 等于0，1，2，3时，bits[31:20], bits[31:21], bits[31:22], and bits[31:23]位相应被使用。OB_OFFSETn_HI寄存器的值是64位PCIe地址中第n个regions的基地址的63~32位，在32位PCIe地址中，该寄存器的值等于0。<br><img src=\"picture8.jpg\" alt=\"\"><br>图 8</p>\n<p>配置OutBound翻译的几个寄存器也做了详解，下面根据举例说明。图 5中配置空间存储地址由CPU本身架构所决定，这部分的地址映射才芯片内部完成，不需要由编程人员配置。PCIe设备空间被分成了32等分。假设region大小是2M，PCIe地址是64位，程序中需要对0x9D3A_1234存储地址做映射， 64位PCIe地址被使用在region 9上，初始化OBOFFSET9_HI值为0x3344 5566, OB_OFFSET9值56Ex xxxx（x的值这里不关心，看该寄存器结构就很清楚，第0位在地址翻译时候应该使能位1，这里仅仅用来讲解怎么做映射，不需要关心后面的Bits） ，下面分析怎么翻译到PCIe地址：</p>\n<p>由于是regions大小2M，那么index应该取地址的bits [25:21]，提取0x9D3A_1234存储地址的bits [25:21得到01001b，该值等于9，那么该地址应该启用regions 9 翻译。存储地址的bits[20:00]是用做翻译到PCIe地址的bits[20:00]位，该值也可以理解成reginos 9内的偏移值，值是0x001A 1234。<br>生成regions 块PCIe的基地址，该地址应pcie_base=OBOFFSET9_HI &lt;&lt;32 + OB_OFFSET9的bits[31:21] = 0x 3344 5566 56E0 0000。<br>计算PCIe地址，pcie_addr = pcie_base + 存储地址bits[20:0] =0x3344 5566 56FA 1234。<br><img src=\"picture9.jpg\" alt=\"\"><br>图 9</p>\n<p>从上面存储地址到PCIe地址映射可以看到，通过cpu寻址可以直接访问到PCIe设备空间，最多可以访问PCIe设备空间大小为256M，具体Outbound能够访问的大小根据芯片而定，当CPU与FPGA之间有大量数据交互时候也可以采用Inbound方式（Inbound地址翻译流程如图 6所示，这里就不在翻译），将CPU的内存映射到FPGA的寻址空间（这里是站在CPU角度看的，从图2可以理解具体映射大小还由EP决定），FPGA可以采用DMA方式访问cpu的内存，并且速度很快。有些芯片厂商干脆采用同核异构方式将CPU于FPGA集成在一起（有的将cpu与dsp集成在一起），两者之间采用AXI高速总线通讯。<br><img src=\"picture10.jpg\" alt=\"\">                                                                                    \\图 10</p>\n<p>扫描PCIe树<br>扫描树的流程如下：</p>\n<p>建立存储地址到PCIe地址映射 （映射方式上面段落已经讲解了，固定的PCIe配置空间映射）<br>分配PCIe总线号<br>分配设备号<br>访问配置空间 （这里有一个原则读者需要注意，对PCIe设备配置空间访问时，一定要确定总线号、设备号、功能号、寄存器，不然无法找到设备）<br>读写BAR0确定PCIe设备1空间大小<br>分配PCIe地址<br>分配总线号<br>扫描PCIe总线树时，需要对这些PCIe总线进行编号，即初始化PCIe桥（在本文一律指透明桥）的Primary、Secondary和Subordinate Bus寄存器。在Linux内核中采用DFS算法对PCIe总线树进行遍历，DFS算法是按照深度优先的原则遍历PCIe树，局部代码如图 7所示，这里可以跟踪pci_scan_bridge函数，函数采用DFS算法对总线进行编号（后期会讲解搜索树，比较常见hash表、红黑树）。<br><img src=\"picture11.jpg\" alt=\"\"><br>图 11</p>\n<p>分配设备号<br>PCIe设备的IDSEL信号与PCIe总线的AD[31:0]信号的连接关系决定了该设备在这条总线上的设备号。在配置读写总线事务的地址周期中，AD[10:0]已经被信号已经被功能号和寄存器号使用，因此PCIe设备的IDSEL只能与AD[31:11]信号连接。上一篇文章中谈到CONFIG_ADDR寄存器中的Device Number字段一共有5位，最大能够表示32个设备，这里只有21位，显然在两者之间不能建立一一映射关系。一个PCIe总线号下最多可以挂在21个PCIe设备，那么多个PCIe总线不就可以挂载32个设备了么。</p>\n<p>访问配置空间<br>在32位PCIe地址空间中，PCIe设备通常将PCIe配置存放在E2PROM中，PCIe设备进行上电初始化时，将E2PROM中的信息读到PCIe设备的配置空间作为初始值，由硬件自动完成。BAR0空间存储了PCIe设备空间的大小，某些位被设置成不可预读，当BAR0全部写入1时，然后在读取BAR0值，从数据低位看有多少连续位没有改变。没有改变的数据位数记录的该PCIe设备空间的大小，假如有n位没有改变，那么设备空间大小应该是2的n次方。第0位代表IO/Memory、第2，3位代表32/64位地址、第4位代表是否可预取，具体位定义格式可以直接参考内核PCIe总线代码，解析BAR函数如图 8所示。<br><img src=\"picture12.jpg\" alt=\"\"><br>图 12</p>\n<p>分配PCIe地址<br>系统软件根据根据设备空间大小建立存储地址PCIe设备地址空间的映射，给PCIe设备分配的PCIe基地址写入到BAR0，如果是64位PCIe地址，那么BAR1是高32位地址。</p>\n<p>结语<br> 写《从cpu角度理解PCIe》文章我参考了部分芯片的datasheet，并结合linux代码分析，本文仅仅起到分析流程的作用，具体映射机制和寄存器芯片参考相应芯片datasheet。如有错误，还望指正。</p>\n"},{"title":"Centos 更改kernel 默认启动项","_content":"\n在生成grub.cfg之前，最好先备份原始的grub.cfg文件\n\nuname -r   #查看当前内核\nrpm -qa | grep kernel   #显示已经安装的内核 \ncat /boot/grub2/grub.cfg | menuentry   #查看启动项 \n\ngrub2-set-default \"CentOS Linux (3.10.0-693.el7.x86_64) 7 (Core)\" #配置默认内核\ngrub2-editenv list #查看默认启动项\n\ngrub2-mkconfig -o /boot/grub2/grub.cfg   #生成配置 \n\nFrom <https://blog.csdn.net/c935612575/article/details/81558352?utm_source=blogxgwz4> \n","source":"_posts/linux/Centos更改kernel 默认启动项.md","raw":"---\ntitle: Centos 更改kernel 默认启动项\ntags: \ncategories:\n- linux\n---\n\n在生成grub.cfg之前，最好先备份原始的grub.cfg文件\n\nuname -r   #查看当前内核\nrpm -qa | grep kernel   #显示已经安装的内核 \ncat /boot/grub2/grub.cfg | menuentry   #查看启动项 \n\ngrub2-set-default \"CentOS Linux (3.10.0-693.el7.x86_64) 7 (Core)\" #配置默认内核\ngrub2-editenv list #查看默认启动项\n\ngrub2-mkconfig -o /boot/grub2/grub.cfg   #生成配置 \n\nFrom <https://blog.csdn.net/c935612575/article/details/81558352?utm_source=blogxgwz4> \n","slug":"linux/Centos更改kernel 默认启动项","published":1,"date":"2020-08-12T16:05:46.098Z","updated":"2020-02-13T12:47:44.357Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmca000lhohx1how6kzw","content":"<p>在生成grub.cfg之前，最好先备份原始的grub.cfg文件</p>\n<p>uname -r   #查看当前内核<br>rpm -qa | grep kernel   #显示已经安装的内核<br>cat /boot/grub2/grub.cfg | menuentry   #查看启动项 </p>\n<p>grub2-set-default “CentOS Linux (3.10.0-693.el7.x86_64) 7 (Core)” #配置默认内核<br>grub2-editenv list #查看默认启动项</p>\n<p>grub2-mkconfig -o /boot/grub2/grub.cfg   #生成配置 </p>\n<p>From <a href=\"https://blog.csdn.net/c935612575/article/details/81558352?utm_source=blogxgwz4\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/c935612575/article/details/81558352?utm_source=blogxgwz4</a> </p>\n","site":{"data":{}},"excerpt":"","more":"<p>在生成grub.cfg之前，最好先备份原始的grub.cfg文件</p>\n<p>uname -r   #查看当前内核<br>rpm -qa | grep kernel   #显示已经安装的内核<br>cat /boot/grub2/grub.cfg | menuentry   #查看启动项 </p>\n<p>grub2-set-default “CentOS Linux (3.10.0-693.el7.x86_64) 7 (Core)” #配置默认内核<br>grub2-editenv list #查看默认启动项</p>\n<p>grub2-mkconfig -o /boot/grub2/grub.cfg   #生成配置 </p>\n<p>From <a href=\"https://blog.csdn.net/c935612575/article/details/81558352?utm_source=blogxgwz4\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/c935612575/article/details/81558352?utm_source=blogxgwz4</a> </p>\n"},{"title":"Intel_pstate & HWP功能enable/disable","_content":"\nlinux/drivers/cpufreq/intel_pstate.c\n\nFrom <https://github.com/torvalds/linux/blob/v5.0/drivers/cpufreq/intel_pstate.c> \n\n\nIntel_pstate & acpi-cpufreq 驱动切换\nBy default it is intel_pstate driver\n               Change intel_pstate driver to acpi-cpufreq as follow:\n\n    /etc/default/grub, \nchange\nGRUB_CMDLINE_LINUX=\"***quiet\"\nto\nGRUB_CMDLINE_LINUX=\"***quiet intel_pstate=disable\"\nthen\nUEFI 系统上的指令是 grub2-mkconfig -o /boot/efi/EFI/centos/grub.cfg\nafter reboot, then acpi-cpufreq driver willbe used.\n\n\n查看HWP功能是否开启：\n#rdmsr 0x770, 读取1则enable， 读取0则disable\n关闭HWP功能：\nVim /etc/default/grub\nGRUB_CMDLINE_LINUX = \"*** intel_pstate=no_hwp\"\n\nintel_pstate=disable\tdisable intel_pstate 驱动\nintel_pstate=passive\tPassive mode enabled, default_driver = &intel_cpufreq\n\t机器重启后cpupower frequency-info查看驱动确实是intel_cpufreq \n\t  current CPU frequency: Unable to call hardware\n\t  current CPU frequency: 1000 MHz (asserted by call to kernel)\nintel_pstate=no_hwp\tHWP disabled, 重启后执行cpupower frequency-info命令查看\n\t  current CPU frequency: Unable to call hardware\n\t  current CPU frequency: 1000 MHz (asserted by call to kernel)\nintel_pstate=force\t\nintel_pstate=hwp_only\t\nintel_pstate=per_cpu_perf_limits\t\nintel_pstate=support_acpi_ppc\tacpi_ppc = true\n","source":"_posts/linux/Intel_pstate&HWP功能enable_disable.md","raw":"---\ntitle: Intel_pstate & HWP功能enable/disable\ntags: \ncategories:\n- linux\n---\n\nlinux/drivers/cpufreq/intel_pstate.c\n\nFrom <https://github.com/torvalds/linux/blob/v5.0/drivers/cpufreq/intel_pstate.c> \n\n\nIntel_pstate & acpi-cpufreq 驱动切换\nBy default it is intel_pstate driver\n               Change intel_pstate driver to acpi-cpufreq as follow:\n\n    /etc/default/grub, \nchange\nGRUB_CMDLINE_LINUX=\"***quiet\"\nto\nGRUB_CMDLINE_LINUX=\"***quiet intel_pstate=disable\"\nthen\nUEFI 系统上的指令是 grub2-mkconfig -o /boot/efi/EFI/centos/grub.cfg\nafter reboot, then acpi-cpufreq driver willbe used.\n\n\n查看HWP功能是否开启：\n#rdmsr 0x770, 读取1则enable， 读取0则disable\n关闭HWP功能：\nVim /etc/default/grub\nGRUB_CMDLINE_LINUX = \"*** intel_pstate=no_hwp\"\n\nintel_pstate=disable\tdisable intel_pstate 驱动\nintel_pstate=passive\tPassive mode enabled, default_driver = &intel_cpufreq\n\t机器重启后cpupower frequency-info查看驱动确实是intel_cpufreq \n\t  current CPU frequency: Unable to call hardware\n\t  current CPU frequency: 1000 MHz (asserted by call to kernel)\nintel_pstate=no_hwp\tHWP disabled, 重启后执行cpupower frequency-info命令查看\n\t  current CPU frequency: Unable to call hardware\n\t  current CPU frequency: 1000 MHz (asserted by call to kernel)\nintel_pstate=force\t\nintel_pstate=hwp_only\t\nintel_pstate=per_cpu_perf_limits\t\nintel_pstate=support_acpi_ppc\tacpi_ppc = true\n","slug":"linux/Intel_pstate&HWP功能enable_disable","published":1,"date":"2020-08-12T16:05:46.242Z","updated":"2020-02-13T12:47:44.366Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmcc000nhohx2xyf96ek","content":"<p>linux/drivers/cpufreq/intel_pstate.c</p>\n<p>From <a href=\"https://github.com/torvalds/linux/blob/v5.0/drivers/cpufreq/intel_pstate.c\" target=\"_blank\" rel=\"noopener\">https://github.com/torvalds/linux/blob/v5.0/drivers/cpufreq/intel_pstate.c</a> </p>\n<p>Intel_pstate &amp; acpi-cpufreq 驱动切换<br>By default it is intel_pstate driver<br>               Change intel_pstate driver to acpi-cpufreq as follow:</p>\n<pre><code>/etc/default/grub, </code></pre><p>change<br>GRUB_CMDLINE_LINUX=”<strong><em>quiet”<br>to<br>GRUB_CMDLINE_LINUX=”</em></strong>quiet intel_pstate=disable”<br>then<br>UEFI 系统上的指令是 grub2-mkconfig -o /boot/efi/EFI/centos/grub.cfg<br>after reboot, then acpi-cpufreq driver willbe used.</p>\n<p>查看HWP功能是否开启：<br>#rdmsr 0x770, 读取1则enable， 读取0则disable<br>关闭HWP功能：<br>Vim /etc/default/grub<br>GRUB_CMDLINE_LINUX = “*** intel_pstate=no_hwp”</p>\n<p>intel_pstate=disable    disable intel_pstate 驱动<br>intel_pstate=passive    Passive mode enabled, default_driver = &amp;intel_cpufreq<br>    机器重启后cpupower frequency-info查看驱动确实是intel_cpufreq<br>      current CPU frequency: Unable to call hardware<br>      current CPU frequency: 1000 MHz (asserted by call to kernel)<br>intel_pstate=no_hwp    HWP disabled, 重启后执行cpupower frequency-info命令查看<br>      current CPU frequency: Unable to call hardware<br>      current CPU frequency: 1000 MHz (asserted by call to kernel)<br>intel_pstate=force<br>intel_pstate=hwp_only<br>intel_pstate=per_cpu_perf_limits<br>intel_pstate=support_acpi_ppc    acpi_ppc = true</p>\n","site":{"data":{}},"excerpt":"","more":"<p>linux/drivers/cpufreq/intel_pstate.c</p>\n<p>From <a href=\"https://github.com/torvalds/linux/blob/v5.0/drivers/cpufreq/intel_pstate.c\" target=\"_blank\" rel=\"noopener\">https://github.com/torvalds/linux/blob/v5.0/drivers/cpufreq/intel_pstate.c</a> </p>\n<p>Intel_pstate &amp; acpi-cpufreq 驱动切换<br>By default it is intel_pstate driver<br>               Change intel_pstate driver to acpi-cpufreq as follow:</p>\n<pre><code>/etc/default/grub, </code></pre><p>change<br>GRUB_CMDLINE_LINUX=”<strong><em>quiet”<br>to<br>GRUB_CMDLINE_LINUX=”</em></strong>quiet intel_pstate=disable”<br>then<br>UEFI 系统上的指令是 grub2-mkconfig -o /boot/efi/EFI/centos/grub.cfg<br>after reboot, then acpi-cpufreq driver willbe used.</p>\n<p>查看HWP功能是否开启：<br>#rdmsr 0x770, 读取1则enable， 读取0则disable<br>关闭HWP功能：<br>Vim /etc/default/grub<br>GRUB_CMDLINE_LINUX = “*** intel_pstate=no_hwp”</p>\n<p>intel_pstate=disable    disable intel_pstate 驱动<br>intel_pstate=passive    Passive mode enabled, default_driver = &amp;intel_cpufreq<br>    机器重启后cpupower frequency-info查看驱动确实是intel_cpufreq<br>      current CPU frequency: Unable to call hardware<br>      current CPU frequency: 1000 MHz (asserted by call to kernel)<br>intel_pstate=no_hwp    HWP disabled, 重启后执行cpupower frequency-info命令查看<br>      current CPU frequency: Unable to call hardware<br>      current CPU frequency: 1000 MHz (asserted by call to kernel)<br>intel_pstate=force<br>intel_pstate=hwp_only<br>intel_pstate=per_cpu_perf_limits<br>intel_pstate=support_acpi_ppc    acpi_ppc = true</p>\n"},{"title":"Devtoolset 升级gcc到8.3.1","_content":"设置gcc到8.0再用 -mavx512f 参数\nTo install the full tools-set including gfortran on centos 7:\n\n $ yum install centos-release-scl\n $ yum install devtoolset-8                       //yum install devtoolset-7, 升级到gcc 7.3\n $ scl enable devtoolset-8 -- bash           //scl enable devtoolset-7 -- bash, 只在当前终端生效\nenable the tools:\n\n $ source /opt/rh/devtoolset-8/enable \nyou may wish to put the command above in .bash_profile\n\nref: https://unix.stackexchange.com/questions/477360/centos-7-gcc-8-installation\n","source":"_posts/linux/Devtoolset 升级gcc到8.3.1.md","raw":"---\ntitle: Devtoolset 升级gcc到8.3.1\ntags: \ncategories:\n- linux\n---\n设置gcc到8.0再用 -mavx512f 参数\nTo install the full tools-set including gfortran on centos 7:\n\n $ yum install centos-release-scl\n $ yum install devtoolset-8                       //yum install devtoolset-7, 升级到gcc 7.3\n $ scl enable devtoolset-8 -- bash           //scl enable devtoolset-7 -- bash, 只在当前终端生效\nenable the tools:\n\n $ source /opt/rh/devtoolset-8/enable \nyou may wish to put the command above in .bash_profile\n\nref: https://unix.stackexchange.com/questions/477360/centos-7-gcc-8-installation\n","slug":"linux/Devtoolset 升级gcc到8.3.1","published":1,"date":"2020-08-12T16:05:46.148Z","updated":"2020-02-13T12:47:44.361Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmcf000qhohxdmf84rvr","content":"<p>设置gcc到8.0再用 -mavx512f 参数<br>To install the full tools-set including gfortran on centos 7:</p>\n<p> $ yum install centos-release-scl<br> $ yum install devtoolset-8                       //yum install devtoolset-7, 升级到gcc 7.3<br> $ scl enable devtoolset-8 – bash           //scl enable devtoolset-7 – bash, 只在当前终端生效<br>enable the tools:</p>\n<p> $ source /opt/rh/devtoolset-8/enable<br>you may wish to put the command above in .bash_profile</p>\n<p>ref: <a href=\"https://unix.stackexchange.com/questions/477360/centos-7-gcc-8-installation\" target=\"_blank\" rel=\"noopener\">https://unix.stackexchange.com/questions/477360/centos-7-gcc-8-installation</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>设置gcc到8.0再用 -mavx512f 参数<br>To install the full tools-set including gfortran on centos 7:</p>\n<p> $ yum install centos-release-scl<br> $ yum install devtoolset-8                       //yum install devtoolset-7, 升级到gcc 7.3<br> $ scl enable devtoolset-8 – bash           //scl enable devtoolset-7 – bash, 只在当前终端生效<br>enable the tools:</p>\n<p> $ source /opt/rh/devtoolset-8/enable<br>you may wish to put the command above in .bash_profile</p>\n<p>ref: <a href=\"https://unix.stackexchange.com/questions/477360/centos-7-gcc-8-installation\" target=\"_blank\" rel=\"noopener\">https://unix.stackexchange.com/questions/477360/centos-7-gcc-8-installation</a></p>\n"},{"title":"EOF","_content":"\n## EOF\n通过cat配合重定向能够生成文件并追加操作,在它之前先熟悉几个特殊符号:\n\n\t< :输入重定向\n\t> :输出重定向\n\t>> :输出重定向,进行追加,不会覆盖之前内容\n\t<< :标准输入来自命令行的一对分隔号的中间内容.\n\n\"<< EOF EOF\" 的作用是在命令执行过程中用户自定义输入，它类似于起到一个临时文件的作用，只是比使用文件更方便灵活\n\nEOF是END Of File的缩写,表示自定义终止符.既然自定义,那么EOF就不是固定的,可以随意设置别名,在linux按ctrl-d就代表EOF.\nEOF一般会配合cat能够多行文本输出.\n其用法如下:\n\n\t<<EOF        //开始\n\t....\n\tEOF            //结束\n\n还可以自定义，比如自定义：\n\n\t<<BBB        //开始\n\t....\n\tBBB              //结束\n 1. 向文件test.sh里输入内容。 \n\n\t$ cat << EOF > test.sh 或者 $ cat > test.sh << EOF\n\t> 123123123\n\t> 3452354345\n\t> asdfasdfs\n\t> EOF\n追加内容\n\n\t$ cat << EOF >>test.sh 或者 $ cat >> test.sh << EOF\n\t> 7777\n\t> 8888\n\t> EOF\n覆盖\n\n\t$ cat << EOF >test.sh 或者 $ cat > test.sh << EOF\n\t> 55555\n\t> EOF\n 2. 自定义EOF，比如自定义为wang\n\n\t$ cat << wang > haha.txt 或者 $ cat > test.sh << wang\n\t> ggggggg\n\t> 6666666\n\t> wang\n\n\n\n\n\n","source":"_posts/linux/EOF.md","raw":"---\ntitle: EOF\ntags: \ncategories:\n- linux\n---\n\n## EOF\n通过cat配合重定向能够生成文件并追加操作,在它之前先熟悉几个特殊符号:\n\n\t< :输入重定向\n\t> :输出重定向\n\t>> :输出重定向,进行追加,不会覆盖之前内容\n\t<< :标准输入来自命令行的一对分隔号的中间内容.\n\n\"<< EOF EOF\" 的作用是在命令执行过程中用户自定义输入，它类似于起到一个临时文件的作用，只是比使用文件更方便灵活\n\nEOF是END Of File的缩写,表示自定义终止符.既然自定义,那么EOF就不是固定的,可以随意设置别名,在linux按ctrl-d就代表EOF.\nEOF一般会配合cat能够多行文本输出.\n其用法如下:\n\n\t<<EOF        //开始\n\t....\n\tEOF            //结束\n\n还可以自定义，比如自定义：\n\n\t<<BBB        //开始\n\t....\n\tBBB              //结束\n 1. 向文件test.sh里输入内容。 \n\n\t$ cat << EOF > test.sh 或者 $ cat > test.sh << EOF\n\t> 123123123\n\t> 3452354345\n\t> asdfasdfs\n\t> EOF\n追加内容\n\n\t$ cat << EOF >>test.sh 或者 $ cat >> test.sh << EOF\n\t> 7777\n\t> 8888\n\t> EOF\n覆盖\n\n\t$ cat << EOF >test.sh 或者 $ cat > test.sh << EOF\n\t> 55555\n\t> EOF\n 2. 自定义EOF，比如自定义为wang\n\n\t$ cat << wang > haha.txt 或者 $ cat > test.sh << wang\n\t> ggggggg\n\t> 6666666\n\t> wang\n\n\n\n\n\n","slug":"linux/EOF","published":1,"date":"2020-08-12T16:05:46.198Z","updated":"2020-06-09T06:32:16.861Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmch000rhohxdb4ncwky","content":"<h2 id=\"EOF\"><a href=\"#EOF\" class=\"headerlink\" title=\"EOF\"></a>EOF</h2><p>通过cat配合重定向能够生成文件并追加操作,在它之前先熟悉几个特殊符号:</p>\n<pre><code>&lt; :输入重定向\n&gt; :输出重定向\n&gt;&gt; :输出重定向,进行追加,不会覆盖之前内容\n&lt;&lt; :标准输入来自命令行的一对分隔号的中间内容.</code></pre><p>“&lt;&lt; EOF EOF” 的作用是在命令执行过程中用户自定义输入，它类似于起到一个临时文件的作用，只是比使用文件更方便灵活</p>\n<p>EOF是END Of File的缩写,表示自定义终止符.既然自定义,那么EOF就不是固定的,可以随意设置别名,在linux按ctrl-d就代表EOF.<br>EOF一般会配合cat能够多行文本输出.<br>其用法如下:</p>\n<pre><code>&lt;&lt;EOF        //开始\n....\nEOF            //结束</code></pre><p>还可以自定义，比如自定义：</p>\n<pre><code>&lt;&lt;BBB        //开始\n....\nBBB              //结束</code></pre><ol>\n<li><p>向文件test.sh里输入内容。 </p>\n<p>$ cat &lt;&lt; EOF &gt; test.sh 或者 $ cat &gt; test.sh &lt;&lt; EOF</p>\n<blockquote>\n<p>123123123<br>3452354345<br>asdfasdfs<br>EOF<br>追加内容</p>\n</blockquote>\n<p>$ cat &lt;&lt; EOF &gt;&gt;test.sh 或者 $ cat &gt;&gt; test.sh &lt;&lt; EOF</p>\n<blockquote>\n<p>7777<br>8888<br>EOF<br>覆盖</p>\n</blockquote>\n<p>$ cat &lt;&lt; EOF &gt;test.sh 或者 $ cat &gt; test.sh &lt;&lt; EOF</p>\n<blockquote>\n<p>55555<br>EOF</p>\n</blockquote>\n</li>\n<li><p>自定义EOF，比如自定义为wang</p>\n<p>$ cat &lt;&lt; wang &gt; haha.txt 或者 $ cat &gt; test.sh &lt;&lt; wang</p>\n<blockquote>\n<p>ggggggg<br>6666666<br>wang</p>\n</blockquote>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"EOF\"><a href=\"#EOF\" class=\"headerlink\" title=\"EOF\"></a>EOF</h2><p>通过cat配合重定向能够生成文件并追加操作,在它之前先熟悉几个特殊符号:</p>\n<pre><code>&lt; :输入重定向\n&gt; :输出重定向\n&gt;&gt; :输出重定向,进行追加,不会覆盖之前内容\n&lt;&lt; :标准输入来自命令行的一对分隔号的中间内容.</code></pre><p>“&lt;&lt; EOF EOF” 的作用是在命令执行过程中用户自定义输入，它类似于起到一个临时文件的作用，只是比使用文件更方便灵活</p>\n<p>EOF是END Of File的缩写,表示自定义终止符.既然自定义,那么EOF就不是固定的,可以随意设置别名,在linux按ctrl-d就代表EOF.<br>EOF一般会配合cat能够多行文本输出.<br>其用法如下:</p>\n<pre><code>&lt;&lt;EOF        //开始\n....\nEOF            //结束</code></pre><p>还可以自定义，比如自定义：</p>\n<pre><code>&lt;&lt;BBB        //开始\n....\nBBB              //结束</code></pre><ol>\n<li><p>向文件test.sh里输入内容。 </p>\n<p>$ cat &lt;&lt; EOF &gt; test.sh 或者 $ cat &gt; test.sh &lt;&lt; EOF</p>\n<blockquote>\n<p>123123123<br>3452354345<br>asdfasdfs<br>EOF<br>追加内容</p>\n</blockquote>\n<p>$ cat &lt;&lt; EOF &gt;&gt;test.sh 或者 $ cat &gt;&gt; test.sh &lt;&lt; EOF</p>\n<blockquote>\n<p>7777<br>8888<br>EOF<br>覆盖</p>\n</blockquote>\n<p>$ cat &lt;&lt; EOF &gt;test.sh 或者 $ cat &gt; test.sh &lt;&lt; EOF</p>\n<blockquote>\n<p>55555<br>EOF</p>\n</blockquote>\n</li>\n<li><p>自定义EOF，比如自定义为wang</p>\n<p>$ cat &lt;&lt; wang &gt; haha.txt 或者 $ cat &gt; test.sh &lt;&lt; wang</p>\n<blockquote>\n<p>ggggggg<br>6666666<br>wang</p>\n</blockquote>\n</li>\n</ol>\n"},{"title":"Linux 修改root名称","_content":"vi /etc/passwd\n按i键进入编辑状态\n修改第1行第1个root为新的用户名\n按esc键退出编辑状态，并输入:x保存并退出\nvi /etc/shadow                                                 //root用户对应的密码文件\n按i键进入编辑状态\n修改第1行第1个root为新的用户名\n按esc键退出编辑状态，并输入:x!强制保存并退出\n为了正常使用sudo，需要修改/etc/sudoers的设置，修改方法如下（来自How to add users to /etc/sudoers）：\n\t运行vi sudo\n\t找到root    ALL=(ALL)       ALL\n\t在下面添加一行：新用户名    ALL=(ALL)       ALL\n\t:x保存退出\n","source":"_posts/linux/Linux 修改root名称.md","raw":"---\ntitle: Linux 修改root名称\ntags:\ncategories:\n- linux\n---\nvi /etc/passwd\n按i键进入编辑状态\n修改第1行第1个root为新的用户名\n按esc键退出编辑状态，并输入:x保存并退出\nvi /etc/shadow                                                 //root用户对应的密码文件\n按i键进入编辑状态\n修改第1行第1个root为新的用户名\n按esc键退出编辑状态，并输入:x!强制保存并退出\n为了正常使用sudo，需要修改/etc/sudoers的设置，修改方法如下（来自How to add users to /etc/sudoers）：\n\t运行vi sudo\n\t找到root    ALL=(ALL)       ALL\n\t在下面添加一行：新用户名    ALL=(ALL)       ALL\n\t:x保存退出\n","slug":"linux/Linux 修改root名称","published":1,"date":"2020-08-12T16:05:46.263Z","updated":"2020-02-13T12:47:44.375Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmck000uhohxdp278o2h","content":"<p>vi /etc/passwd<br>按i键进入编辑状态<br>修改第1行第1个root为新的用户名<br>按esc键退出编辑状态，并输入:x保存并退出<br>vi /etc/shadow                                                 //root用户对应的密码文件<br>按i键进入编辑状态<br>修改第1行第1个root为新的用户名<br>按esc键退出编辑状态，并输入:x!强制保存并退出<br>为了正常使用sudo，需要修改/etc/sudoers的设置，修改方法如下（来自How to add users to /etc/sudoers）：<br>    运行vi sudo<br>    找到root    ALL=(ALL)       ALL<br>    在下面添加一行：新用户名    ALL=(ALL)       ALL<br>    :x保存退出</p>\n","site":{"data":{}},"excerpt":"","more":"<p>vi /etc/passwd<br>按i键进入编辑状态<br>修改第1行第1个root为新的用户名<br>按esc键退出编辑状态，并输入:x保存并退出<br>vi /etc/shadow                                                 //root用户对应的密码文件<br>按i键进入编辑状态<br>修改第1行第1个root为新的用户名<br>按esc键退出编辑状态，并输入:x!强制保存并退出<br>为了正常使用sudo，需要修改/etc/sudoers的设置，修改方法如下（来自How to add users to /etc/sudoers）：<br>    运行vi sudo<br>    找到root    ALL=(ALL)       ALL<br>    在下面添加一行：新用户名    ALL=(ALL)       ALL<br>    :x保存退出</p>\n"},{"title":"Intel_pstate/acpi-cpufreq驱动切换","type":null,"_content":"\nBy default it is intel_pstate driver\n               Change intel_pstate driver to acpi-cpufreq as follow:\n\n    /etc/default/grub, \nchange\nGRUB_CMDLINE_LINUX=\"***quiet\"\nto\nGRUB_CMDLINE_LINUX=\"***quiet intel_pstate=disable\"\nthen\nUEFI 系统上的指令是 grub2-mkconfig -o /boot/efi/EFI/centos/grub.cfg\nafter reboot, then acpi-cpufreq driver willbe used.\n","source":"_posts/linux/Intel_pstate-acpi-cpufreq驱动切换.md","raw":"---\ntitle: Intel_pstate/acpi-cpufreq驱动切换 \ntype: \ncategories:\n- linux\n---\n\nBy default it is intel_pstate driver\n               Change intel_pstate driver to acpi-cpufreq as follow:\n\n    /etc/default/grub, \nchange\nGRUB_CMDLINE_LINUX=\"***quiet\"\nto\nGRUB_CMDLINE_LINUX=\"***quiet intel_pstate=disable\"\nthen\nUEFI 系统上的指令是 grub2-mkconfig -o /boot/efi/EFI/centos/grub.cfg\nafter reboot, then acpi-cpufreq driver willbe used.\n","slug":"linux/Intel_pstate-acpi-cpufreq驱动切换","published":1,"date":"2020-08-12T16:05:46.259Z","updated":"2020-02-13T12:47:44.371Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmcm000whohx2i3aaqpo","content":"<p>By default it is intel_pstate driver<br>               Change intel_pstate driver to acpi-cpufreq as follow:</p>\n<pre><code>/etc/default/grub, </code></pre><p>change<br>GRUB_CMDLINE_LINUX=”<strong><em>quiet”<br>to<br>GRUB_CMDLINE_LINUX=”</em></strong>quiet intel_pstate=disable”<br>then<br>UEFI 系统上的指令是 grub2-mkconfig -o /boot/efi/EFI/centos/grub.cfg<br>after reboot, then acpi-cpufreq driver willbe used.</p>\n","site":{"data":{}},"excerpt":"","more":"<p>By default it is intel_pstate driver<br>               Change intel_pstate driver to acpi-cpufreq as follow:</p>\n<pre><code>/etc/default/grub, </code></pre><p>change<br>GRUB_CMDLINE_LINUX=”<strong><em>quiet”<br>to<br>GRUB_CMDLINE_LINUX=”</em></strong>quiet intel_pstate=disable”<br>then<br>UEFI 系统上的指令是 grub2-mkconfig -o /boot/efi/EFI/centos/grub.cfg<br>after reboot, then acpi-cpufreq driver willbe used.</p>\n"},{"title":"Linux command, find, grep,sed, awk","_content":"\n*************************************************************************************************************\nuname - a\n\t查看内核版本\nroot@Alpha:# uname -a\nLinux Alpha 4.13.0-36-generic #40~16.04.1-Ubuntu SMP Fri Feb 16 23:25:58 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\n\n*************************************************************************************************************\ngrep      grep --help\n\t-c\n\t-i    不区分大小写\n\t-h\n\t-l\n\t-n\n\t-s\n\t-v\n```\ngrep -n \"IndexIVFFlat*\" *.py  //查找本目录所有后缀为.py的文件是否包含IndexIVFFlat*内容\ngrep 'test' aa bb cc\ngrep -r \"exit\" ./ --color=auto\ngrep -r \"exit\" ./ -h\ngrep -r \"exit\" ./ -n    --显示搜索内容在文件中的行号\nroot@Alpha:~/zhan/system/day4# grep  -r  \"exit\"  process_work.c   -n\n29:             exit(1);\nroot@Alpha:~/zhan/system/day4#\n```\n*************************************************************************************************************\n\nfind     find --help\nfind ./ -name \"exit\"\n```\nroot@Alpha:~/zhan/system/day4# find ./ -size +2k    --搜索大于2k文件的当前目录文件\n./\n./pthread_attr.o\n./pthread_cancel.o\n./condition.o\n./process_work.o\n./rwlock.o\n./mutex.o\n./pthread_create.o\nroot@Alpha:~/zhan/system/day4#\n\nroot@Alpha:~/zhan/system/day4# find ./ -size +2k -size 9k    --搜索大于2k小于9k的当前目录文件\n./pthread_attr.o\n./pthread_cancel.o\n./pthread_create.o\nroot@Alpha:~/zhan/system/day4#\n\nfind ./ -size +200 -size -500   -->不加-size参数时候默认单位: 512B(扇区大小0.5K)，不指定单位默认按照扇区大小\n磁盘最小扇区512B(512字节)\n内存最小块4K(4096字节)\n内存分配1000B和4096B空间对计算机来讲没什么区别都是以4096大小来做映射\n\nfind  ./ -type f  --默认递归搜索所有第一级到第n级目录中的文件，而不包含目录\nfind ./ -maxdepth 1 -type f   --只找当前目录文件，不找子级目录文件\nfind ./ -maxdepth 1 -type f -size +2k\nfind ./ -maxdepth 1 -type f -size +2k | ls -l  不生效，find不能跟管道\"|\"一起使用, 如下使用\nfind ./ -maxdepth 1 -type f -size +2k -exec ls -l {} \\;\n\t-exec指明要执行\"{}\"里面的内容，\"{}\"的内容由ls -l 传参, 执行完要有结束标志分号\";\"， \"\\\"符号转义字符将分号\";\"转义\n```\n\n*************************************************************************************************************\nsed  --Stream Editor(流编辑器)\n早起Unix系统 -- ed 编辑器 , 很多sed命令和vi的末行命令是相同的\n\t\t\t    |       | \n\t                  vi      sed\n\n:/\t查找\n:%/the/this/g\t替换文件中的所有the为this\n\nsed option 'script' file1 file2 ……                sed 参数  's/the/this/', 待处理文件     ---the 替换为 this\n\tsed 's/char/int/' test.c -i                test.c文件中的char改为int                           \n\tsed 's/char/int/' test.c | tee tt.c         test.c文件中的char改为int并另存为tt.c文件\nsed option -f scriptfile file1 file2 ……         sed 参数  -f '脚本文件里写正则等'  待处理文件\n\n选项含义：\n--version\n--help\n-n, --quiet, --silent                静默输出\n-i, --in-place                           直接修改源文件\n-e script                        允许多个脚本指令被执行\n-f  script-file            \n--file=script-file             从文件中读取脚本指令，对编写自动脚本程序来说很棒\n-l   N, --line-length=N   该选项指定l指令可以输出的行长度\n--posix                            禁用GNU sed扩展功能\n-r，--regexp-extended   在脚本指令中使用扩展正则表达式\n-s，--separate                 默认情况下，sed将把命令行指定的多个文件名作为一个长的连续的输入流，\n                                        而GNU sed则允许把他们当做单独的文件，这样如正则表达式则不进行跨文件匹配.\n-u， --unbuffered           最低限度的缓存输入与输出\n\na，    append              追加\ni，     insert                   插入\nd，    delete                 删除\ns，     substitution        替换\n如：$ sed -i \"2a itcast\" ./testfile    在testfile文件中第2行后添加\"itcast\"\n       $ sed -i \"3d\" testfile          删除testfile文件中的第三行\n\nsed程序一行一行读出待处理文件，如果某一行与pattern匹配，则执行相应的action，如果一条命令没有patter而只有action，这个action将作用于待处理文件的每一行， 如\"s/the/this/\"  \"the\"就是pattern\n```\n$ sed 's/bc/-&-/' testfile\n123\na-bc-\n456\npattern2 中的&表示源文件当前行中与pattern1相匹配的字符串\n\n$ sed 's/\\([0-9]\\)\\([0-9]\\)/-\\1-~\\2~/' testfile\n-1-~2~3\nAbc\n-4-~5~6\npattern2中的\\1表示与pattern1的第一个()括号相匹配的内容，\\2表示与pattern1的第二个()括号相匹配的内容弄。\nsed默认使用Basic正则表达式规范，如果制定了-r选项则使用Extended规范，那么()括号就不必转移了，\n如：sed -r 's/([0-9])([0-9])/-\\1-~\\2~/' testfile\n\n# sed '/def/p' out    --- \"p\"表示打印输出包含echo内容的行\n\troot@Alpha:~/zhan/test# sed '/def/p' abc.c\n\tabc\n\tdef\n\tdef      --由参数p打印输出的\n\troot@Alpha:~/zhan/test#\n\troot@Alpha:~/zhan/test# sed -n '/def/p' abc.c   -n 表示静默输出，只输出改变的内容\n\tdef\n\troot@Alpha:~/zhan/test#\n\troot@Alpha:~/zhan/test# sed '/def/d' abc.c\n\tabc\n\tghi\n\troot@Alpha:~/zhan/test#\n\troot@Alpha:~/zhan/test# sed  -i 's/def/ddd/' abc.c == sed  -i  '/def/s/def/ddd/' abc.c\n\tabc                                                                                             sed  参数 pattern/action(动作)   目标文件\n\tddd                                                                                                                         pattern大多数情况可以省略如替换\n\tghi\n\troot@Alpha:~/zhan/test#\n\troot@Alpha:~/zhan/test# sed '1,1s/def/ddd/' abc.c\n\tabc\n\tdef\n\tghi\n\tjkl\n\troot@Alpha:~/zhan/test# sed '1,2s/def/ddd/' abc.c   表示1到2行的所有 \"def\" 替换为 \"ddd\"\n\tabc\n\tddd\n\tghi\n\tjkl\n\troot@Alpha:~/zhan/test#\n\troot@Alpha:~/zhan/test# sed '1,2s/def/-&-/' abc.c\n\tabc\n\t-def-\n\tghi\n\troot@Alpha:~/zhan/test#\n\troot@Alpha:~/zhan/test# sed -r 's/([a-z])([a-z])/-\\1-~\\2~/' abc.c == sed -E 's/([a-z])([a-z])/-\\1-~\\2~/' abc.c\n\t-a-~b~c\n\t-d-~e~f\n\t-g-~h~i\n\troot@Alpha:~/zhan/test#\n```\n\n\t\n\n*************************************************************************************************************\nawk 是开发awk命令的三个人名字的首字母，不是单词缩写，不能读'a wa k'\nsed是以行为单位处理文件，awk比sed强，不仅以行为单位，还能以列为单位处理文件，awk缺省的行分隔符是换行，缺省的列分隔符是连续的空格和Tab，但是行分隔符和列分隔符都可以自定义\nps aux | awk '{print $0}'    取全部，相当于ps aux\nps aux | awk '{print $2}'    按列拆分\n\nAwk option 'script' file1 file2 ……\nAwk option -f scriptfile file1 file2 ……\n和sed一样，awk处理的文件既可以由标准输入重定向得到，也可以当命令行参数传入，编辑命令可以直接当命令行参数传入，也可以用-f参数指定一个脚本文件，如果一条awk命令只有actions部分，则actions作用于待处理文件的每一行，编辑命令格式为:\n/pattern/{actions}        ps aux | awk 'print $0'  其中awk 'print $0'即为actions\ncondition{actions}\n\n如果某种产品的库存量低于75则在行末标注需要订货：\n$ awk '$2 < 75  {printf  \"%s\\t%s\\n\",  $0,  \"REORDER\"} $2 >= 75  {print $0;}'  testfile\n                  |                                |                                                 |                  |\n             pattern                    action                                       pattern        action\nproductA   30   REORDER\nproductB   76\nproductC   55   REORDER\n\n# awk '$2 < 75 {printf \"%s %s\\n\", $0, \"reorder\";} $2 >= 75 {printf \"%s\\n\", $0;}' testfile\nProductA 70 reorder\nProductB 35 reorder\nProductC 75\n\n# ps aux | awk '$2>32000 && $2<50000 {print $2 \" recorder\";}'\n\troot@Alpha:~/zhan/test# ps aux | awk '$2>32000 && $2<50000 {print $2 \" recorder\"}'\n\t32106 recorder\n\t32146 recorder\n\t……\n\troot@Alpha:~/zhan/test#\n# ps aux | awk '$2>32000 && $2<50000 {print $2}'                           与下面命令等价\n# ps aux | awk '$2>32000 && $2<50000 {printf(\"%s\\n\", $2);}'        花括号前的\";\"分号去掉也可以\n$ root@Alpha:~/zhan/test# ps aux|awk ' $2 > 30000 && $2 < 40000 {var = var + 1} END {print var}'\n\troot@Alpha:~/zhan/test# ps aux|awk ' $2 > 30000 && $2 < 40000 {var = var + 1} END {print var}'\n\t18\n\troot@Alpha:~/zhan/test#\n\n统计文件中的空行\n```\n$ awk '/^ *$/ {x=x+1;} END {print x;}' testfile\n         以空格开始，到结束都是空格, END代表一直读到文件尾\n\troot@Alpha:~/zhan/test#  awk '/^ *$/ {x=x+1;} END {print x;}' testfile\n\t10\n\troot@Alpha:~/zhan/test#\n\n打印系统中用户账号列表\n$ awk 'BEGIN {FS=\":\"} {print $1;}' /etc/passwd   \n\tawk默认空格为列分隔符，BEGIN表示在匹配之前以\":\"冒号分隔符分割列\n$ awk -F:  '{print $1}' /etc/passwd   与上面等价\n\t-F:  设置\":\"冒号为列分隔符， -F相当于awk的option可选参数\n\t/etc/passwd 文件中把第一列用户名a对应的第二列如\"x\"删掉，则注销机器用户a下次登录则不需要再输入密码，但是sudo 等仍然需要指定密码，只是图形界面省略了登录输密码步骤\n```\n\t\n\t\n*************************************************************************************************************\n","source":"_posts/linux/Linux_command_find_grep_sed_awk.md","raw":"---\ntitle: Linux command, find, grep,sed, awk\ntags:\ncategories:\n- linux\n---\n\n*************************************************************************************************************\nuname - a\n\t查看内核版本\nroot@Alpha:# uname -a\nLinux Alpha 4.13.0-36-generic #40~16.04.1-Ubuntu SMP Fri Feb 16 23:25:58 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\n\n*************************************************************************************************************\ngrep      grep --help\n\t-c\n\t-i    不区分大小写\n\t-h\n\t-l\n\t-n\n\t-s\n\t-v\n```\ngrep -n \"IndexIVFFlat*\" *.py  //查找本目录所有后缀为.py的文件是否包含IndexIVFFlat*内容\ngrep 'test' aa bb cc\ngrep -r \"exit\" ./ --color=auto\ngrep -r \"exit\" ./ -h\ngrep -r \"exit\" ./ -n    --显示搜索内容在文件中的行号\nroot@Alpha:~/zhan/system/day4# grep  -r  \"exit\"  process_work.c   -n\n29:             exit(1);\nroot@Alpha:~/zhan/system/day4#\n```\n*************************************************************************************************************\n\nfind     find --help\nfind ./ -name \"exit\"\n```\nroot@Alpha:~/zhan/system/day4# find ./ -size +2k    --搜索大于2k文件的当前目录文件\n./\n./pthread_attr.o\n./pthread_cancel.o\n./condition.o\n./process_work.o\n./rwlock.o\n./mutex.o\n./pthread_create.o\nroot@Alpha:~/zhan/system/day4#\n\nroot@Alpha:~/zhan/system/day4# find ./ -size +2k -size 9k    --搜索大于2k小于9k的当前目录文件\n./pthread_attr.o\n./pthread_cancel.o\n./pthread_create.o\nroot@Alpha:~/zhan/system/day4#\n\nfind ./ -size +200 -size -500   -->不加-size参数时候默认单位: 512B(扇区大小0.5K)，不指定单位默认按照扇区大小\n磁盘最小扇区512B(512字节)\n内存最小块4K(4096字节)\n内存分配1000B和4096B空间对计算机来讲没什么区别都是以4096大小来做映射\n\nfind  ./ -type f  --默认递归搜索所有第一级到第n级目录中的文件，而不包含目录\nfind ./ -maxdepth 1 -type f   --只找当前目录文件，不找子级目录文件\nfind ./ -maxdepth 1 -type f -size +2k\nfind ./ -maxdepth 1 -type f -size +2k | ls -l  不生效，find不能跟管道\"|\"一起使用, 如下使用\nfind ./ -maxdepth 1 -type f -size +2k -exec ls -l {} \\;\n\t-exec指明要执行\"{}\"里面的内容，\"{}\"的内容由ls -l 传参, 执行完要有结束标志分号\";\"， \"\\\"符号转义字符将分号\";\"转义\n```\n\n*************************************************************************************************************\nsed  --Stream Editor(流编辑器)\n早起Unix系统 -- ed 编辑器 , 很多sed命令和vi的末行命令是相同的\n\t\t\t    |       | \n\t                  vi      sed\n\n:/\t查找\n:%/the/this/g\t替换文件中的所有the为this\n\nsed option 'script' file1 file2 ……                sed 参数  's/the/this/', 待处理文件     ---the 替换为 this\n\tsed 's/char/int/' test.c -i                test.c文件中的char改为int                           \n\tsed 's/char/int/' test.c | tee tt.c         test.c文件中的char改为int并另存为tt.c文件\nsed option -f scriptfile file1 file2 ……         sed 参数  -f '脚本文件里写正则等'  待处理文件\n\n选项含义：\n--version\n--help\n-n, --quiet, --silent                静默输出\n-i, --in-place                           直接修改源文件\n-e script                        允许多个脚本指令被执行\n-f  script-file            \n--file=script-file             从文件中读取脚本指令，对编写自动脚本程序来说很棒\n-l   N, --line-length=N   该选项指定l指令可以输出的行长度\n--posix                            禁用GNU sed扩展功能\n-r，--regexp-extended   在脚本指令中使用扩展正则表达式\n-s，--separate                 默认情况下，sed将把命令行指定的多个文件名作为一个长的连续的输入流，\n                                        而GNU sed则允许把他们当做单独的文件，这样如正则表达式则不进行跨文件匹配.\n-u， --unbuffered           最低限度的缓存输入与输出\n\na，    append              追加\ni，     insert                   插入\nd，    delete                 删除\ns，     substitution        替换\n如：$ sed -i \"2a itcast\" ./testfile    在testfile文件中第2行后添加\"itcast\"\n       $ sed -i \"3d\" testfile          删除testfile文件中的第三行\n\nsed程序一行一行读出待处理文件，如果某一行与pattern匹配，则执行相应的action，如果一条命令没有patter而只有action，这个action将作用于待处理文件的每一行， 如\"s/the/this/\"  \"the\"就是pattern\n```\n$ sed 's/bc/-&-/' testfile\n123\na-bc-\n456\npattern2 中的&表示源文件当前行中与pattern1相匹配的字符串\n\n$ sed 's/\\([0-9]\\)\\([0-9]\\)/-\\1-~\\2~/' testfile\n-1-~2~3\nAbc\n-4-~5~6\npattern2中的\\1表示与pattern1的第一个()括号相匹配的内容，\\2表示与pattern1的第二个()括号相匹配的内容弄。\nsed默认使用Basic正则表达式规范，如果制定了-r选项则使用Extended规范，那么()括号就不必转移了，\n如：sed -r 's/([0-9])([0-9])/-\\1-~\\2~/' testfile\n\n# sed '/def/p' out    --- \"p\"表示打印输出包含echo内容的行\n\troot@Alpha:~/zhan/test# sed '/def/p' abc.c\n\tabc\n\tdef\n\tdef      --由参数p打印输出的\n\troot@Alpha:~/zhan/test#\n\troot@Alpha:~/zhan/test# sed -n '/def/p' abc.c   -n 表示静默输出，只输出改变的内容\n\tdef\n\troot@Alpha:~/zhan/test#\n\troot@Alpha:~/zhan/test# sed '/def/d' abc.c\n\tabc\n\tghi\n\troot@Alpha:~/zhan/test#\n\troot@Alpha:~/zhan/test# sed  -i 's/def/ddd/' abc.c == sed  -i  '/def/s/def/ddd/' abc.c\n\tabc                                                                                             sed  参数 pattern/action(动作)   目标文件\n\tddd                                                                                                                         pattern大多数情况可以省略如替换\n\tghi\n\troot@Alpha:~/zhan/test#\n\troot@Alpha:~/zhan/test# sed '1,1s/def/ddd/' abc.c\n\tabc\n\tdef\n\tghi\n\tjkl\n\troot@Alpha:~/zhan/test# sed '1,2s/def/ddd/' abc.c   表示1到2行的所有 \"def\" 替换为 \"ddd\"\n\tabc\n\tddd\n\tghi\n\tjkl\n\troot@Alpha:~/zhan/test#\n\troot@Alpha:~/zhan/test# sed '1,2s/def/-&-/' abc.c\n\tabc\n\t-def-\n\tghi\n\troot@Alpha:~/zhan/test#\n\troot@Alpha:~/zhan/test# sed -r 's/([a-z])([a-z])/-\\1-~\\2~/' abc.c == sed -E 's/([a-z])([a-z])/-\\1-~\\2~/' abc.c\n\t-a-~b~c\n\t-d-~e~f\n\t-g-~h~i\n\troot@Alpha:~/zhan/test#\n```\n\n\t\n\n*************************************************************************************************************\nawk 是开发awk命令的三个人名字的首字母，不是单词缩写，不能读'a wa k'\nsed是以行为单位处理文件，awk比sed强，不仅以行为单位，还能以列为单位处理文件，awk缺省的行分隔符是换行，缺省的列分隔符是连续的空格和Tab，但是行分隔符和列分隔符都可以自定义\nps aux | awk '{print $0}'    取全部，相当于ps aux\nps aux | awk '{print $2}'    按列拆分\n\nAwk option 'script' file1 file2 ……\nAwk option -f scriptfile file1 file2 ……\n和sed一样，awk处理的文件既可以由标准输入重定向得到，也可以当命令行参数传入，编辑命令可以直接当命令行参数传入，也可以用-f参数指定一个脚本文件，如果一条awk命令只有actions部分，则actions作用于待处理文件的每一行，编辑命令格式为:\n/pattern/{actions}        ps aux | awk 'print $0'  其中awk 'print $0'即为actions\ncondition{actions}\n\n如果某种产品的库存量低于75则在行末标注需要订货：\n$ awk '$2 < 75  {printf  \"%s\\t%s\\n\",  $0,  \"REORDER\"} $2 >= 75  {print $0;}'  testfile\n                  |                                |                                                 |                  |\n             pattern                    action                                       pattern        action\nproductA   30   REORDER\nproductB   76\nproductC   55   REORDER\n\n# awk '$2 < 75 {printf \"%s %s\\n\", $0, \"reorder\";} $2 >= 75 {printf \"%s\\n\", $0;}' testfile\nProductA 70 reorder\nProductB 35 reorder\nProductC 75\n\n# ps aux | awk '$2>32000 && $2<50000 {print $2 \" recorder\";}'\n\troot@Alpha:~/zhan/test# ps aux | awk '$2>32000 && $2<50000 {print $2 \" recorder\"}'\n\t32106 recorder\n\t32146 recorder\n\t……\n\troot@Alpha:~/zhan/test#\n# ps aux | awk '$2>32000 && $2<50000 {print $2}'                           与下面命令等价\n# ps aux | awk '$2>32000 && $2<50000 {printf(\"%s\\n\", $2);}'        花括号前的\";\"分号去掉也可以\n$ root@Alpha:~/zhan/test# ps aux|awk ' $2 > 30000 && $2 < 40000 {var = var + 1} END {print var}'\n\troot@Alpha:~/zhan/test# ps aux|awk ' $2 > 30000 && $2 < 40000 {var = var + 1} END {print var}'\n\t18\n\troot@Alpha:~/zhan/test#\n\n统计文件中的空行\n```\n$ awk '/^ *$/ {x=x+1;} END {print x;}' testfile\n         以空格开始，到结束都是空格, END代表一直读到文件尾\n\troot@Alpha:~/zhan/test#  awk '/^ *$/ {x=x+1;} END {print x;}' testfile\n\t10\n\troot@Alpha:~/zhan/test#\n\n打印系统中用户账号列表\n$ awk 'BEGIN {FS=\":\"} {print $1;}' /etc/passwd   \n\tawk默认空格为列分隔符，BEGIN表示在匹配之前以\":\"冒号分隔符分割列\n$ awk -F:  '{print $1}' /etc/passwd   与上面等价\n\t-F:  设置\":\"冒号为列分隔符， -F相当于awk的option可选参数\n\t/etc/passwd 文件中把第一列用户名a对应的第二列如\"x\"删掉，则注销机器用户a下次登录则不需要再输入密码，但是sudo 等仍然需要指定密码，只是图形界面省略了登录输密码步骤\n```\n\t\n\t\n*************************************************************************************************************\n","slug":"linux/Linux_command_find_grep_sed_awk","published":1,"date":"2020-08-12T16:05:46.271Z","updated":"2020-02-13T12:47:44.379Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmcp000zhohxh61l6g1p","content":"<hr>\n<p>uname - a<br>    查看内核版本<br>root@Alpha:# uname -a<br>Linux Alpha 4.13.0-36-generic #40~16.04.1-Ubuntu SMP Fri Feb 16 23:25:58 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux</p>\n<hr>\n<p>grep      grep –help<br>    -c<br>    -i    不区分大小写<br>    -h<br>    -l<br>    -n<br>    -s<br>    -v</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">grep -n &quot;IndexIVFFlat*&quot; *.py  &#x2F;&#x2F;查找本目录所有后缀为.py的文件是否包含IndexIVFFlat*内容</span><br><span class=\"line\">grep &#39;test&#39; aa bb cc</span><br><span class=\"line\">grep -r &quot;exit&quot; .&#x2F; --color&#x3D;auto</span><br><span class=\"line\">grep -r &quot;exit&quot; .&#x2F; -h</span><br><span class=\"line\">grep -r &quot;exit&quot; .&#x2F; -n    --显示搜索内容在文件中的行号</span><br><span class=\"line\">root@Alpha:~&#x2F;zhan&#x2F;system&#x2F;day4# grep  -r  &quot;exit&quot;  process_work.c   -n</span><br><span class=\"line\">29:             exit(1);</span><br><span class=\"line\">root@Alpha:~&#x2F;zhan&#x2F;system&#x2F;day4#</span><br></pre></td></tr></table></figure>\n<hr>\n<p>find     find –help<br>find ./ -name “exit”</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@Alpha:~&#x2F;zhan&#x2F;system&#x2F;day4# find .&#x2F; -size +2k    --搜索大于2k文件的当前目录文件</span><br><span class=\"line\">.&#x2F;</span><br><span class=\"line\">.&#x2F;pthread_attr.o</span><br><span class=\"line\">.&#x2F;pthread_cancel.o</span><br><span class=\"line\">.&#x2F;condition.o</span><br><span class=\"line\">.&#x2F;process_work.o</span><br><span class=\"line\">.&#x2F;rwlock.o</span><br><span class=\"line\">.&#x2F;mutex.o</span><br><span class=\"line\">.&#x2F;pthread_create.o</span><br><span class=\"line\">root@Alpha:~&#x2F;zhan&#x2F;system&#x2F;day4#</span><br><span class=\"line\"></span><br><span class=\"line\">root@Alpha:~&#x2F;zhan&#x2F;system&#x2F;day4# find .&#x2F; -size +2k -size 9k    --搜索大于2k小于9k的当前目录文件</span><br><span class=\"line\">.&#x2F;pthread_attr.o</span><br><span class=\"line\">.&#x2F;pthread_cancel.o</span><br><span class=\"line\">.&#x2F;pthread_create.o</span><br><span class=\"line\">root@Alpha:~&#x2F;zhan&#x2F;system&#x2F;day4#</span><br><span class=\"line\"></span><br><span class=\"line\">find .&#x2F; -size +200 -size -500   --&gt;不加-size参数时候默认单位: 512B(扇区大小0.5K)，不指定单位默认按照扇区大小</span><br><span class=\"line\">磁盘最小扇区512B(512字节)</span><br><span class=\"line\">内存最小块4K(4096字节)</span><br><span class=\"line\">内存分配1000B和4096B空间对计算机来讲没什么区别都是以4096大小来做映射</span><br><span class=\"line\"></span><br><span class=\"line\">find  .&#x2F; -type f  --默认递归搜索所有第一级到第n级目录中的文件，而不包含目录</span><br><span class=\"line\">find .&#x2F; -maxdepth 1 -type f   --只找当前目录文件，不找子级目录文件</span><br><span class=\"line\">find .&#x2F; -maxdepth 1 -type f -size +2k</span><br><span class=\"line\">find .&#x2F; -maxdepth 1 -type f -size +2k | ls -l  不生效，find不能跟管道&quot;|&quot;一起使用, 如下使用</span><br><span class=\"line\">find .&#x2F; -maxdepth 1 -type f -size +2k -exec ls -l &#123;&#125; \\;</span><br><span class=\"line\">\t-exec指明要执行&quot;&#123;&#125;&quot;里面的内容，&quot;&#123;&#125;&quot;的内容由ls -l 传参, 执行完要有结束标志分号&quot;;&quot;， &quot;\\&quot;符号转义字符将分号&quot;;&quot;转义</span><br></pre></td></tr></table></figure>\n\n<hr>\n<p>sed  –Stream Editor(流编辑器)<br>早起Unix系统 – ed 编辑器 , 很多sed命令和vi的末行命令是相同的<br>                |       |<br>                      vi      sed</p>\n<p>:/    查找<br>:%/the/this/g    替换文件中的所有the为this</p>\n<p>sed option ‘script’ file1 file2 ……                sed 参数  ‘s/the/this/‘, 待处理文件     —the 替换为 this<br>    sed ‘s/char/int/‘ test.c -i                test.c文件中的char改为int<br>    sed ‘s/char/int/‘ test.c | tee tt.c         test.c文件中的char改为int并另存为tt.c文件<br>sed option -f scriptfile file1 file2 ……         sed 参数  -f ‘脚本文件里写正则等’  待处理文件</p>\n<p>选项含义：<br>–version<br>–help<br>-n, –quiet, –silent                静默输出<br>-i, –in-place                           直接修改源文件<br>-e script                        允许多个脚本指令被执行<br>-f  script-file<br>–file=script-file             从文件中读取脚本指令，对编写自动脚本程序来说很棒<br>-l   N, –line-length=N   该选项指定l指令可以输出的行长度<br>–posix                            禁用GNU sed扩展功能<br>-r，–regexp-extended   在脚本指令中使用扩展正则表达式<br>-s，–separate                 默认情况下，sed将把命令行指定的多个文件名作为一个长的连续的输入流，<br>                                        而GNU sed则允许把他们当做单独的文件，这样如正则表达式则不进行跨文件匹配.<br>-u， –unbuffered           最低限度的缓存输入与输出</p>\n<p>a，    append              追加<br>i，     insert                   插入<br>d，    delete                 删除<br>s，     substitution        替换<br>如：$ sed -i “2a itcast” ./testfile    在testfile文件中第2行后添加”itcast”<br>       $ sed -i “3d” testfile          删除testfile文件中的第三行</p>\n<p>sed程序一行一行读出待处理文件，如果某一行与pattern匹配，则执行相应的action，如果一条命令没有patter而只有action，这个action将作用于待处理文件的每一行， 如”s/the/this/“  “the”就是pattern</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sed &#39;s&#x2F;bc&#x2F;-&amp;-&#x2F;&#39; testfile</span><br><span class=\"line\">123</span><br><span class=\"line\">a-bc-</span><br><span class=\"line\">456</span><br><span class=\"line\">pattern2 中的&amp;表示源文件当前行中与pattern1相匹配的字符串</span><br><span class=\"line\"></span><br><span class=\"line\">$ sed &#39;s&#x2F;\\([0-9]\\)\\([0-9]\\)&#x2F;-\\1-~\\2~&#x2F;&#39; testfile</span><br><span class=\"line\">-1-~2~3</span><br><span class=\"line\">Abc</span><br><span class=\"line\">-4-~5~6</span><br><span class=\"line\">pattern2中的\\1表示与pattern1的第一个()括号相匹配的内容，\\2表示与pattern1的第二个()括号相匹配的内容弄。</span><br><span class=\"line\">sed默认使用Basic正则表达式规范，如果制定了-r选项则使用Extended规范，那么()括号就不必转移了，</span><br><span class=\"line\">如：sed -r &#39;s&#x2F;([0-9])([0-9])&#x2F;-\\1-~\\2~&#x2F;&#39; testfile</span><br><span class=\"line\"></span><br><span class=\"line\"># sed &#39;&#x2F;def&#x2F;p&#39; out    --- &quot;p&quot;表示打印输出包含echo内容的行</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test# sed &#39;&#x2F;def&#x2F;p&#39; abc.c</span><br><span class=\"line\">\tabc</span><br><span class=\"line\">\tdef</span><br><span class=\"line\">\tdef      --由参数p打印输出的</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test#</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test# sed -n &#39;&#x2F;def&#x2F;p&#39; abc.c   -n 表示静默输出，只输出改变的内容</span><br><span class=\"line\">\tdef</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test#</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test# sed &#39;&#x2F;def&#x2F;d&#39; abc.c</span><br><span class=\"line\">\tabc</span><br><span class=\"line\">\tghi</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test#</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test# sed  -i &#39;s&#x2F;def&#x2F;ddd&#x2F;&#39; abc.c &#x3D;&#x3D; sed  -i  &#39;&#x2F;def&#x2F;s&#x2F;def&#x2F;ddd&#x2F;&#39; abc.c</span><br><span class=\"line\">\tabc                                                                                             sed  参数 pattern&#x2F;action(动作)   目标文件</span><br><span class=\"line\">\tddd                                                                                                                         pattern大多数情况可以省略如替换</span><br><span class=\"line\">\tghi</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test#</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test# sed &#39;1,1s&#x2F;def&#x2F;ddd&#x2F;&#39; abc.c</span><br><span class=\"line\">\tabc</span><br><span class=\"line\">\tdef</span><br><span class=\"line\">\tghi</span><br><span class=\"line\">\tjkl</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test# sed &#39;1,2s&#x2F;def&#x2F;ddd&#x2F;&#39; abc.c   表示1到2行的所有 &quot;def&quot; 替换为 &quot;ddd&quot;</span><br><span class=\"line\">\tabc</span><br><span class=\"line\">\tddd</span><br><span class=\"line\">\tghi</span><br><span class=\"line\">\tjkl</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test#</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test# sed &#39;1,2s&#x2F;def&#x2F;-&amp;-&#x2F;&#39; abc.c</span><br><span class=\"line\">\tabc</span><br><span class=\"line\">\t-def-</span><br><span class=\"line\">\tghi</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test#</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test# sed -r &#39;s&#x2F;([a-z])([a-z])&#x2F;-\\1-~\\2~&#x2F;&#39; abc.c &#x3D;&#x3D; sed -E &#39;s&#x2F;([a-z])([a-z])&#x2F;-\\1-~\\2~&#x2F;&#39; abc.c</span><br><span class=\"line\">\t-a-~b~c</span><br><span class=\"line\">\t-d-~e~f</span><br><span class=\"line\">\t-g-~h~i</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test#</span><br></pre></td></tr></table></figure>\n\n\n\n<hr>\n<p>awk 是开发awk命令的三个人名字的首字母，不是单词缩写，不能读’a wa k’<br>sed是以行为单位处理文件，awk比sed强，不仅以行为单位，还能以列为单位处理文件，awk缺省的行分隔符是换行，缺省的列分隔符是连续的空格和Tab，但是行分隔符和列分隔符都可以自定义<br>ps aux | awk ‘{print $0}’    取全部，相当于ps aux<br>ps aux | awk ‘{print $2}’    按列拆分</p>\n<p>Awk option ‘script’ file1 file2 ……<br>Awk option -f scriptfile file1 file2 ……<br>和sed一样，awk处理的文件既可以由标准输入重定向得到，也可以当命令行参数传入，编辑命令可以直接当命令行参数传入，也可以用-f参数指定一个脚本文件，如果一条awk命令只有actions部分，则actions作用于待处理文件的每一行，编辑命令格式为:<br>/pattern/{actions}        ps aux | awk ‘print $0’  其中awk ‘print $0’即为actions<br>condition{actions}</p>\n<p>如果某种产品的库存量低于75则在行末标注需要订货：<br>$ awk ‘$2 &lt; 75  {printf  “%s\\t%s\\n”,  $0,  “REORDER”} $2 &gt;= 75  {print $0;}’  testfile<br>                  |                                |                                                 |                  |<br>             pattern                    action                                       pattern        action<br>productA   30   REORDER<br>productB   76<br>productC   55   REORDER</p>\n<h1 id=\"awk-‘-2-lt-75-printf-“-s-s-n”-0-“reorder”-2-gt-75-printf-“-s-n”-0-’-testfile\"><a href=\"#awk-‘-2-lt-75-printf-“-s-s-n”-0-“reorder”-2-gt-75-printf-“-s-n”-0-’-testfile\" class=\"headerlink\" title=\"awk ‘$2 &lt; 75 {printf “%s %s\\n”, $0, “reorder”;} $2 &gt;= 75 {printf “%s\\n”, $0;}’ testfile\"></a>awk ‘$2 &lt; 75 {printf “%s %s\\n”, $0, “reorder”;} $2 &gt;= 75 {printf “%s\\n”, $0;}’ testfile</h1><p>ProductA 70 reorder<br>ProductB 35 reorder<br>ProductC 75</p>\n<h1 id=\"ps-aux-awk-‘-2-gt-32000-amp-amp-2-lt-50000-print-2-“-recorder”-’\"><a href=\"#ps-aux-awk-‘-2-gt-32000-amp-amp-2-lt-50000-print-2-“-recorder”-’\" class=\"headerlink\" title=\"ps aux | awk ‘$2&gt;32000 &amp;&amp; $2&lt;50000 {print $2 “ recorder”;}’\"></a>ps aux | awk ‘$2&gt;32000 &amp;&amp; $2&lt;50000 {print $2 “ recorder”;}’</h1><pre><code>root@Alpha:~/zhan/test# ps aux | awk &apos;$2&gt;32000 &amp;&amp; $2&lt;50000 {print $2 &quot; recorder&quot;}&apos;\n32106 recorder\n32146 recorder\n……\nroot@Alpha:~/zhan/test#</code></pre><h1 id=\"ps-aux-awk-‘-2-gt-32000-amp-amp-2-lt-50000-print-2-’-与下面命令等价\"><a href=\"#ps-aux-awk-‘-2-gt-32000-amp-amp-2-lt-50000-print-2-’-与下面命令等价\" class=\"headerlink\" title=\"ps aux | awk ‘$2&gt;32000 &amp;&amp; $2&lt;50000 {print $2}’                           与下面命令等价\"></a>ps aux | awk ‘$2&gt;32000 &amp;&amp; $2&lt;50000 {print $2}’                           与下面命令等价</h1><h1 id=\"ps-aux-awk-‘-2-gt-32000-amp-amp-2-lt-50000-printf-“-s-n”-2-’-花括号前的”-”分号去掉也可以\"><a href=\"#ps-aux-awk-‘-2-gt-32000-amp-amp-2-lt-50000-printf-“-s-n”-2-’-花括号前的”-”分号去掉也可以\" class=\"headerlink\" title=\"ps aux | awk ‘$2&gt;32000 &amp;&amp; $2&lt;50000 {printf(“%s\\n”, $2);}’        花括号前的”;”分号去掉也可以\"></a>ps aux | awk ‘$2&gt;32000 &amp;&amp; $2&lt;50000 {printf(“%s\\n”, $2);}’        花括号前的”;”分号去掉也可以</h1><p>$ root@Alpha:<del>/zhan/test# ps aux|awk ‘ $2 &gt; 30000 &amp;&amp; $2 &lt; 40000 {var = var + 1} END {print var}’<br>    root@Alpha:</del>/zhan/test# ps aux|awk ‘ $2 &gt; 30000 &amp;&amp; $2 &lt; 40000 {var = var + 1} END {print var}’<br>    18<br>    root@Alpha:~/zhan/test#</p>\n<p>统计文件中的空行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ awk &#39;&#x2F;^ *$&#x2F; &#123;x&#x3D;x+1;&#125; END &#123;print x;&#125;&#39; testfile</span><br><span class=\"line\">         以空格开始，到结束都是空格, END代表一直读到文件尾</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test#  awk &#39;&#x2F;^ *$&#x2F; &#123;x&#x3D;x+1;&#125; END &#123;print x;&#125;&#39; testfile</span><br><span class=\"line\">\t10</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test#</span><br><span class=\"line\"></span><br><span class=\"line\">打印系统中用户账号列表</span><br><span class=\"line\">$ awk &#39;BEGIN &#123;FS&#x3D;&quot;:&quot;&#125; &#123;print $1;&#125;&#39; &#x2F;etc&#x2F;passwd   </span><br><span class=\"line\">\tawk默认空格为列分隔符，BEGIN表示在匹配之前以&quot;:&quot;冒号分隔符分割列</span><br><span class=\"line\">$ awk -F:  &#39;&#123;print $1&#125;&#39; &#x2F;etc&#x2F;passwd   与上面等价</span><br><span class=\"line\">\t-F:  设置&quot;:&quot;冒号为列分隔符， -F相当于awk的option可选参数</span><br><span class=\"line\">\t&#x2F;etc&#x2F;passwd 文件中把第一列用户名a对应的第二列如&quot;x&quot;删掉，则注销机器用户a下次登录则不需要再输入密码，但是sudo 等仍然需要指定密码，只是图形界面省略了登录输密码步骤</span><br></pre></td></tr></table></figure>\n\n\n<hr>\n","site":{"data":{}},"excerpt":"","more":"<hr>\n<p>uname - a<br>    查看内核版本<br>root@Alpha:# uname -a<br>Linux Alpha 4.13.0-36-generic #40~16.04.1-Ubuntu SMP Fri Feb 16 23:25:58 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux</p>\n<hr>\n<p>grep      grep –help<br>    -c<br>    -i    不区分大小写<br>    -h<br>    -l<br>    -n<br>    -s<br>    -v</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">grep -n &quot;IndexIVFFlat*&quot; *.py  &#x2F;&#x2F;查找本目录所有后缀为.py的文件是否包含IndexIVFFlat*内容</span><br><span class=\"line\">grep &#39;test&#39; aa bb cc</span><br><span class=\"line\">grep -r &quot;exit&quot; .&#x2F; --color&#x3D;auto</span><br><span class=\"line\">grep -r &quot;exit&quot; .&#x2F; -h</span><br><span class=\"line\">grep -r &quot;exit&quot; .&#x2F; -n    --显示搜索内容在文件中的行号</span><br><span class=\"line\">root@Alpha:~&#x2F;zhan&#x2F;system&#x2F;day4# grep  -r  &quot;exit&quot;  process_work.c   -n</span><br><span class=\"line\">29:             exit(1);</span><br><span class=\"line\">root@Alpha:~&#x2F;zhan&#x2F;system&#x2F;day4#</span><br></pre></td></tr></table></figure>\n<hr>\n<p>find     find –help<br>find ./ -name “exit”</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@Alpha:~&#x2F;zhan&#x2F;system&#x2F;day4# find .&#x2F; -size +2k    --搜索大于2k文件的当前目录文件</span><br><span class=\"line\">.&#x2F;</span><br><span class=\"line\">.&#x2F;pthread_attr.o</span><br><span class=\"line\">.&#x2F;pthread_cancel.o</span><br><span class=\"line\">.&#x2F;condition.o</span><br><span class=\"line\">.&#x2F;process_work.o</span><br><span class=\"line\">.&#x2F;rwlock.o</span><br><span class=\"line\">.&#x2F;mutex.o</span><br><span class=\"line\">.&#x2F;pthread_create.o</span><br><span class=\"line\">root@Alpha:~&#x2F;zhan&#x2F;system&#x2F;day4#</span><br><span class=\"line\"></span><br><span class=\"line\">root@Alpha:~&#x2F;zhan&#x2F;system&#x2F;day4# find .&#x2F; -size +2k -size 9k    --搜索大于2k小于9k的当前目录文件</span><br><span class=\"line\">.&#x2F;pthread_attr.o</span><br><span class=\"line\">.&#x2F;pthread_cancel.o</span><br><span class=\"line\">.&#x2F;pthread_create.o</span><br><span class=\"line\">root@Alpha:~&#x2F;zhan&#x2F;system&#x2F;day4#</span><br><span class=\"line\"></span><br><span class=\"line\">find .&#x2F; -size +200 -size -500   --&gt;不加-size参数时候默认单位: 512B(扇区大小0.5K)，不指定单位默认按照扇区大小</span><br><span class=\"line\">磁盘最小扇区512B(512字节)</span><br><span class=\"line\">内存最小块4K(4096字节)</span><br><span class=\"line\">内存分配1000B和4096B空间对计算机来讲没什么区别都是以4096大小来做映射</span><br><span class=\"line\"></span><br><span class=\"line\">find  .&#x2F; -type f  --默认递归搜索所有第一级到第n级目录中的文件，而不包含目录</span><br><span class=\"line\">find .&#x2F; -maxdepth 1 -type f   --只找当前目录文件，不找子级目录文件</span><br><span class=\"line\">find .&#x2F; -maxdepth 1 -type f -size +2k</span><br><span class=\"line\">find .&#x2F; -maxdepth 1 -type f -size +2k | ls -l  不生效，find不能跟管道&quot;|&quot;一起使用, 如下使用</span><br><span class=\"line\">find .&#x2F; -maxdepth 1 -type f -size +2k -exec ls -l &#123;&#125; \\;</span><br><span class=\"line\">\t-exec指明要执行&quot;&#123;&#125;&quot;里面的内容，&quot;&#123;&#125;&quot;的内容由ls -l 传参, 执行完要有结束标志分号&quot;;&quot;， &quot;\\&quot;符号转义字符将分号&quot;;&quot;转义</span><br></pre></td></tr></table></figure>\n\n<hr>\n<p>sed  –Stream Editor(流编辑器)<br>早起Unix系统 – ed 编辑器 , 很多sed命令和vi的末行命令是相同的<br>                |       |<br>                      vi      sed</p>\n<p>:/    查找<br>:%/the/this/g    替换文件中的所有the为this</p>\n<p>sed option ‘script’ file1 file2 ……                sed 参数  ‘s/the/this/‘, 待处理文件     —the 替换为 this<br>    sed ‘s/char/int/‘ test.c -i                test.c文件中的char改为int<br>    sed ‘s/char/int/‘ test.c | tee tt.c         test.c文件中的char改为int并另存为tt.c文件<br>sed option -f scriptfile file1 file2 ……         sed 参数  -f ‘脚本文件里写正则等’  待处理文件</p>\n<p>选项含义：<br>–version<br>–help<br>-n, –quiet, –silent                静默输出<br>-i, –in-place                           直接修改源文件<br>-e script                        允许多个脚本指令被执行<br>-f  script-file<br>–file=script-file             从文件中读取脚本指令，对编写自动脚本程序来说很棒<br>-l   N, –line-length=N   该选项指定l指令可以输出的行长度<br>–posix                            禁用GNU sed扩展功能<br>-r，–regexp-extended   在脚本指令中使用扩展正则表达式<br>-s，–separate                 默认情况下，sed将把命令行指定的多个文件名作为一个长的连续的输入流，<br>                                        而GNU sed则允许把他们当做单独的文件，这样如正则表达式则不进行跨文件匹配.<br>-u， –unbuffered           最低限度的缓存输入与输出</p>\n<p>a，    append              追加<br>i，     insert                   插入<br>d，    delete                 删除<br>s，     substitution        替换<br>如：$ sed -i “2a itcast” ./testfile    在testfile文件中第2行后添加”itcast”<br>       $ sed -i “3d” testfile          删除testfile文件中的第三行</p>\n<p>sed程序一行一行读出待处理文件，如果某一行与pattern匹配，则执行相应的action，如果一条命令没有patter而只有action，这个action将作用于待处理文件的每一行， 如”s/the/this/“  “the”就是pattern</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sed &#39;s&#x2F;bc&#x2F;-&amp;-&#x2F;&#39; testfile</span><br><span class=\"line\">123</span><br><span class=\"line\">a-bc-</span><br><span class=\"line\">456</span><br><span class=\"line\">pattern2 中的&amp;表示源文件当前行中与pattern1相匹配的字符串</span><br><span class=\"line\"></span><br><span class=\"line\">$ sed &#39;s&#x2F;\\([0-9]\\)\\([0-9]\\)&#x2F;-\\1-~\\2~&#x2F;&#39; testfile</span><br><span class=\"line\">-1-~2~3</span><br><span class=\"line\">Abc</span><br><span class=\"line\">-4-~5~6</span><br><span class=\"line\">pattern2中的\\1表示与pattern1的第一个()括号相匹配的内容，\\2表示与pattern1的第二个()括号相匹配的内容弄。</span><br><span class=\"line\">sed默认使用Basic正则表达式规范，如果制定了-r选项则使用Extended规范，那么()括号就不必转移了，</span><br><span class=\"line\">如：sed -r &#39;s&#x2F;([0-9])([0-9])&#x2F;-\\1-~\\2~&#x2F;&#39; testfile</span><br><span class=\"line\"></span><br><span class=\"line\"># sed &#39;&#x2F;def&#x2F;p&#39; out    --- &quot;p&quot;表示打印输出包含echo内容的行</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test# sed &#39;&#x2F;def&#x2F;p&#39; abc.c</span><br><span class=\"line\">\tabc</span><br><span class=\"line\">\tdef</span><br><span class=\"line\">\tdef      --由参数p打印输出的</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test#</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test# sed -n &#39;&#x2F;def&#x2F;p&#39; abc.c   -n 表示静默输出，只输出改变的内容</span><br><span class=\"line\">\tdef</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test#</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test# sed &#39;&#x2F;def&#x2F;d&#39; abc.c</span><br><span class=\"line\">\tabc</span><br><span class=\"line\">\tghi</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test#</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test# sed  -i &#39;s&#x2F;def&#x2F;ddd&#x2F;&#39; abc.c &#x3D;&#x3D; sed  -i  &#39;&#x2F;def&#x2F;s&#x2F;def&#x2F;ddd&#x2F;&#39; abc.c</span><br><span class=\"line\">\tabc                                                                                             sed  参数 pattern&#x2F;action(动作)   目标文件</span><br><span class=\"line\">\tddd                                                                                                                         pattern大多数情况可以省略如替换</span><br><span class=\"line\">\tghi</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test#</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test# sed &#39;1,1s&#x2F;def&#x2F;ddd&#x2F;&#39; abc.c</span><br><span class=\"line\">\tabc</span><br><span class=\"line\">\tdef</span><br><span class=\"line\">\tghi</span><br><span class=\"line\">\tjkl</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test# sed &#39;1,2s&#x2F;def&#x2F;ddd&#x2F;&#39; abc.c   表示1到2行的所有 &quot;def&quot; 替换为 &quot;ddd&quot;</span><br><span class=\"line\">\tabc</span><br><span class=\"line\">\tddd</span><br><span class=\"line\">\tghi</span><br><span class=\"line\">\tjkl</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test#</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test# sed &#39;1,2s&#x2F;def&#x2F;-&amp;-&#x2F;&#39; abc.c</span><br><span class=\"line\">\tabc</span><br><span class=\"line\">\t-def-</span><br><span class=\"line\">\tghi</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test#</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test# sed -r &#39;s&#x2F;([a-z])([a-z])&#x2F;-\\1-~\\2~&#x2F;&#39; abc.c &#x3D;&#x3D; sed -E &#39;s&#x2F;([a-z])([a-z])&#x2F;-\\1-~\\2~&#x2F;&#39; abc.c</span><br><span class=\"line\">\t-a-~b~c</span><br><span class=\"line\">\t-d-~e~f</span><br><span class=\"line\">\t-g-~h~i</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test#</span><br></pre></td></tr></table></figure>\n\n\n\n<hr>\n<p>awk 是开发awk命令的三个人名字的首字母，不是单词缩写，不能读’a wa k’<br>sed是以行为单位处理文件，awk比sed强，不仅以行为单位，还能以列为单位处理文件，awk缺省的行分隔符是换行，缺省的列分隔符是连续的空格和Tab，但是行分隔符和列分隔符都可以自定义<br>ps aux | awk ‘{print $0}’    取全部，相当于ps aux<br>ps aux | awk ‘{print $2}’    按列拆分</p>\n<p>Awk option ‘script’ file1 file2 ……<br>Awk option -f scriptfile file1 file2 ……<br>和sed一样，awk处理的文件既可以由标准输入重定向得到，也可以当命令行参数传入，编辑命令可以直接当命令行参数传入，也可以用-f参数指定一个脚本文件，如果一条awk命令只有actions部分，则actions作用于待处理文件的每一行，编辑命令格式为:<br>/pattern/{actions}        ps aux | awk ‘print $0’  其中awk ‘print $0’即为actions<br>condition{actions}</p>\n<p>如果某种产品的库存量低于75则在行末标注需要订货：<br>$ awk ‘$2 &lt; 75  {printf  “%s\\t%s\\n”,  $0,  “REORDER”} $2 &gt;= 75  {print $0;}’  testfile<br>                  |                                |                                                 |                  |<br>             pattern                    action                                       pattern        action<br>productA   30   REORDER<br>productB   76<br>productC   55   REORDER</p>\n<h1 id=\"awk-‘-2-lt-75-printf-“-s-s-n”-0-“reorder”-2-gt-75-printf-“-s-n”-0-’-testfile\"><a href=\"#awk-‘-2-lt-75-printf-“-s-s-n”-0-“reorder”-2-gt-75-printf-“-s-n”-0-’-testfile\" class=\"headerlink\" title=\"awk ‘$2 &lt; 75 {printf “%s %s\\n”, $0, “reorder”;} $2 &gt;= 75 {printf “%s\\n”, $0;}’ testfile\"></a>awk ‘$2 &lt; 75 {printf “%s %s\\n”, $0, “reorder”;} $2 &gt;= 75 {printf “%s\\n”, $0;}’ testfile</h1><p>ProductA 70 reorder<br>ProductB 35 reorder<br>ProductC 75</p>\n<h1 id=\"ps-aux-awk-‘-2-gt-32000-amp-amp-2-lt-50000-print-2-“-recorder”-’\"><a href=\"#ps-aux-awk-‘-2-gt-32000-amp-amp-2-lt-50000-print-2-“-recorder”-’\" class=\"headerlink\" title=\"ps aux | awk ‘$2&gt;32000 &amp;&amp; $2&lt;50000 {print $2 “ recorder”;}’\"></a>ps aux | awk ‘$2&gt;32000 &amp;&amp; $2&lt;50000 {print $2 “ recorder”;}’</h1><pre><code>root@Alpha:~/zhan/test# ps aux | awk &apos;$2&gt;32000 &amp;&amp; $2&lt;50000 {print $2 &quot; recorder&quot;}&apos;\n32106 recorder\n32146 recorder\n……\nroot@Alpha:~/zhan/test#</code></pre><h1 id=\"ps-aux-awk-‘-2-gt-32000-amp-amp-2-lt-50000-print-2-’-与下面命令等价\"><a href=\"#ps-aux-awk-‘-2-gt-32000-amp-amp-2-lt-50000-print-2-’-与下面命令等价\" class=\"headerlink\" title=\"ps aux | awk ‘$2&gt;32000 &amp;&amp; $2&lt;50000 {print $2}’                           与下面命令等价\"></a>ps aux | awk ‘$2&gt;32000 &amp;&amp; $2&lt;50000 {print $2}’                           与下面命令等价</h1><h1 id=\"ps-aux-awk-‘-2-gt-32000-amp-amp-2-lt-50000-printf-“-s-n”-2-’-花括号前的”-”分号去掉也可以\"><a href=\"#ps-aux-awk-‘-2-gt-32000-amp-amp-2-lt-50000-printf-“-s-n”-2-’-花括号前的”-”分号去掉也可以\" class=\"headerlink\" title=\"ps aux | awk ‘$2&gt;32000 &amp;&amp; $2&lt;50000 {printf(“%s\\n”, $2);}’        花括号前的”;”分号去掉也可以\"></a>ps aux | awk ‘$2&gt;32000 &amp;&amp; $2&lt;50000 {printf(“%s\\n”, $2);}’        花括号前的”;”分号去掉也可以</h1><p>$ root@Alpha:<del>/zhan/test# ps aux|awk ‘ $2 &gt; 30000 &amp;&amp; $2 &lt; 40000 {var = var + 1} END {print var}’<br>    root@Alpha:</del>/zhan/test# ps aux|awk ‘ $2 &gt; 30000 &amp;&amp; $2 &lt; 40000 {var = var + 1} END {print var}’<br>    18<br>    root@Alpha:~/zhan/test#</p>\n<p>统计文件中的空行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ awk &#39;&#x2F;^ *$&#x2F; &#123;x&#x3D;x+1;&#125; END &#123;print x;&#125;&#39; testfile</span><br><span class=\"line\">         以空格开始，到结束都是空格, END代表一直读到文件尾</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test#  awk &#39;&#x2F;^ *$&#x2F; &#123;x&#x3D;x+1;&#125; END &#123;print x;&#125;&#39; testfile</span><br><span class=\"line\">\t10</span><br><span class=\"line\">\troot@Alpha:~&#x2F;zhan&#x2F;test#</span><br><span class=\"line\"></span><br><span class=\"line\">打印系统中用户账号列表</span><br><span class=\"line\">$ awk &#39;BEGIN &#123;FS&#x3D;&quot;:&quot;&#125; &#123;print $1;&#125;&#39; &#x2F;etc&#x2F;passwd   </span><br><span class=\"line\">\tawk默认空格为列分隔符，BEGIN表示在匹配之前以&quot;:&quot;冒号分隔符分割列</span><br><span class=\"line\">$ awk -F:  &#39;&#123;print $1&#125;&#39; &#x2F;etc&#x2F;passwd   与上面等价</span><br><span class=\"line\">\t-F:  设置&quot;:&quot;冒号为列分隔符， -F相当于awk的option可选参数</span><br><span class=\"line\">\t&#x2F;etc&#x2F;passwd 文件中把第一列用户名a对应的第二列如&quot;x&quot;删掉，则注销机器用户a下次登录则不需要再输入密码，但是sudo 等仍然需要指定密码，只是图形界面省略了登录输密码步骤</span><br></pre></td></tr></table></figure>\n\n\n<hr>\n"},{"title":"Linux kernel userspace体系结构","_content":"linux 系统体系结构：\n![](linux_gun.jpg)\n\nlinux kernel体系结构：\narm有7种工作模式，x86也实现了4个不同级别RING0-RING3,RING0级别最高，\n这样linux用户代码运行在RING3下，内核运行在RING0,这样系统本身就得到了\n充分的保护\n用户空间(用户模式)转到内核空间(系统模式)方法：\n·系统调用\n·硬件中断\nlinux kernel 体系结构：\n![](linux_kernel.jpg)\n\n虚拟文件系统VFS:\nVFS(虚拟文件系统)隐藏各种文件系统的具体细节，为文件操作提供统一的接口\n\n二.Linux内核源代码\nlinux内核下载www.kernel.org\n目录结构:\n解压linux kernel tar后目录\n·arch:根据cpu体系结构不同而分的代码\n·block:部分块设备驱动程序\n·crypto:加密，压缩，CRC校验算法\n·documentation:内核文档\n·drivers:设备驱动程序\n·fs(虚拟文件系统vfs):文件系统\n·include:内核所需的头文件，(与平台无关的头文件在include/linux中)\n·lib:库文件代码(与平台相关的)\n·mm:实现内存管理，与硬件体系结构无关的(与硬件体系结构相关的在arch中)\n·net:网络协议的代码\n·samples:一些内核编程的范例\n·scripts:配置内核的脚本\n·security:SElinux的模块\n·sound:音频设备的驱动程序\n·usr:cpio命令实现，用于制作根文件系统的命令(文件系统与内核放到一块的命令)\n·virt:内核虚拟机\nlinux DOC 编译生成:\nlinux源根目录/Documentation/00-INDEX:目录索引\nlinux源根目录/Documentation/HOWTO:指南\n·生成linux内核帮助文档:在linux源根目录(Documentation) 执行make htmldocs\nubuntu16下需要执行sudo apt-get install xmlto安装插件才可生成doc文档\n\n三.Linux内核配置与编译\n清理文件(在linux源码根目录):\n·make clean:只清理所有产生的文件\n·make mrproper:清理所有产生的文件与config配置文件\n·make distclean:清理所有产生的文件与config配置文件，并且编辑过的与补丁文件\n↓\n配置(收集硬件信息如cpu型号，网卡等...):\n·make config:基于文本模式的交互配置\n·make menuconfig:基于文本模式的菜单模式(推荐使用)\n·make oldconfig:使用已有的.config,但会询问新增的配置项\n·make xconfig:图形化的配置(需要安装图形化系统)\n配置方法：\n1)使用make menuconfig操作方法：\n1>按y:编译>连接>镜像文件\n2>按m:编译\n3>按n:什么都不做\n4>按\"空格键\":y,n轮换\n配置完并保存后会在linux源码根目录下生成一个.config文件\n注意：在ubuntu11上要执行apt-get install libncurses5-dev来安装支持包\n\n四.linux内核模块开发\n描述：\nlinux内核组件非常庞大，内核ximage并不包含某组件，而是在该组件需要被使用的时候，动态的添加到正在运行的内核中(也可以卸载)，这种机制叫做“内核模块”的机制。内核模块通常通过使用makefile文件对模块进行编译\n模块安装与卸载:\n1)加载：insmod hello.ko\n2)卸载：rmmod hello\n3)查看：lsmod\n4)加载(自动寻找模块依赖)：modprobe hello\nmodprobe会根据文件/lib/modules/version/modules.dep来查看要加载的模块，看它是否还依赖于其他模块，如果是,会先找到这些模块，把它们先加载到内核\n","source":"_posts/linux/Linux_kernel_userspace体系结构.md","raw":"---\ntitle: Linux kernel userspace体系结构\ntags:\ncategories:\n- linux\n---\nlinux 系统体系结构：\n![](linux_gun.jpg)\n\nlinux kernel体系结构：\narm有7种工作模式，x86也实现了4个不同级别RING0-RING3,RING0级别最高，\n这样linux用户代码运行在RING3下，内核运行在RING0,这样系统本身就得到了\n充分的保护\n用户空间(用户模式)转到内核空间(系统模式)方法：\n·系统调用\n·硬件中断\nlinux kernel 体系结构：\n![](linux_kernel.jpg)\n\n虚拟文件系统VFS:\nVFS(虚拟文件系统)隐藏各种文件系统的具体细节，为文件操作提供统一的接口\n\n二.Linux内核源代码\nlinux内核下载www.kernel.org\n目录结构:\n解压linux kernel tar后目录\n·arch:根据cpu体系结构不同而分的代码\n·block:部分块设备驱动程序\n·crypto:加密，压缩，CRC校验算法\n·documentation:内核文档\n·drivers:设备驱动程序\n·fs(虚拟文件系统vfs):文件系统\n·include:内核所需的头文件，(与平台无关的头文件在include/linux中)\n·lib:库文件代码(与平台相关的)\n·mm:实现内存管理，与硬件体系结构无关的(与硬件体系结构相关的在arch中)\n·net:网络协议的代码\n·samples:一些内核编程的范例\n·scripts:配置内核的脚本\n·security:SElinux的模块\n·sound:音频设备的驱动程序\n·usr:cpio命令实现，用于制作根文件系统的命令(文件系统与内核放到一块的命令)\n·virt:内核虚拟机\nlinux DOC 编译生成:\nlinux源根目录/Documentation/00-INDEX:目录索引\nlinux源根目录/Documentation/HOWTO:指南\n·生成linux内核帮助文档:在linux源根目录(Documentation) 执行make htmldocs\nubuntu16下需要执行sudo apt-get install xmlto安装插件才可生成doc文档\n\n三.Linux内核配置与编译\n清理文件(在linux源码根目录):\n·make clean:只清理所有产生的文件\n·make mrproper:清理所有产生的文件与config配置文件\n·make distclean:清理所有产生的文件与config配置文件，并且编辑过的与补丁文件\n↓\n配置(收集硬件信息如cpu型号，网卡等...):\n·make config:基于文本模式的交互配置\n·make menuconfig:基于文本模式的菜单模式(推荐使用)\n·make oldconfig:使用已有的.config,但会询问新增的配置项\n·make xconfig:图形化的配置(需要安装图形化系统)\n配置方法：\n1)使用make menuconfig操作方法：\n1>按y:编译>连接>镜像文件\n2>按m:编译\n3>按n:什么都不做\n4>按\"空格键\":y,n轮换\n配置完并保存后会在linux源码根目录下生成一个.config文件\n注意：在ubuntu11上要执行apt-get install libncurses5-dev来安装支持包\n\n四.linux内核模块开发\n描述：\nlinux内核组件非常庞大，内核ximage并不包含某组件，而是在该组件需要被使用的时候，动态的添加到正在运行的内核中(也可以卸载)，这种机制叫做“内核模块”的机制。内核模块通常通过使用makefile文件对模块进行编译\n模块安装与卸载:\n1)加载：insmod hello.ko\n2)卸载：rmmod hello\n3)查看：lsmod\n4)加载(自动寻找模块依赖)：modprobe hello\nmodprobe会根据文件/lib/modules/version/modules.dep来查看要加载的模块，看它是否还依赖于其他模块，如果是,会先找到这些模块，把它们先加载到内核\n","slug":"linux/Linux_kernel_userspace体系结构","published":1,"date":"2020-08-12T16:05:46.274Z","updated":"2020-02-13T12:47:44.384Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmcs0010hohxhzn63ph4","content":"<p>linux 系统体系结构：<br><img src=\"linux_gun.jpg\" alt=\"\"></p>\n<p>linux kernel体系结构：<br>arm有7种工作模式，x86也实现了4个不同级别RING0-RING3,RING0级别最高，<br>这样linux用户代码运行在RING3下，内核运行在RING0,这样系统本身就得到了<br>充分的保护<br>用户空间(用户模式)转到内核空间(系统模式)方法：<br>·系统调用<br>·硬件中断<br>linux kernel 体系结构：<br><img src=\"linux_kernel.jpg\" alt=\"\"></p>\n<p>虚拟文件系统VFS:<br>VFS(虚拟文件系统)隐藏各种文件系统的具体细节，为文件操作提供统一的接口</p>\n<p>二.Linux内核源代码<br>linux内核下载<a href=\"http://www.kernel.org\" target=\"_blank\" rel=\"noopener\">www.kernel.org</a><br>目录结构:<br>解压linux kernel tar后目录<br>·arch:根据cpu体系结构不同而分的代码<br>·block:部分块设备驱动程序<br>·crypto:加密，压缩，CRC校验算法<br>·documentation:内核文档<br>·drivers:设备驱动程序<br>·fs(虚拟文件系统vfs):文件系统<br>·include:内核所需的头文件，(与平台无关的头文件在include/linux中)<br>·lib:库文件代码(与平台相关的)<br>·mm:实现内存管理，与硬件体系结构无关的(与硬件体系结构相关的在arch中)<br>·net:网络协议的代码<br>·samples:一些内核编程的范例<br>·scripts:配置内核的脚本<br>·security:SElinux的模块<br>·sound:音频设备的驱动程序<br>·usr:cpio命令实现，用于制作根文件系统的命令(文件系统与内核放到一块的命令)<br>·virt:内核虚拟机<br>linux DOC 编译生成:<br>linux源根目录/Documentation/00-INDEX:目录索引<br>linux源根目录/Documentation/HOWTO:指南<br>·生成linux内核帮助文档:在linux源根目录(Documentation) 执行make htmldocs<br>ubuntu16下需要执行sudo apt-get install xmlto安装插件才可生成doc文档</p>\n<p>三.Linux内核配置与编译<br>清理文件(在linux源码根目录):<br>·make clean:只清理所有产生的文件<br>·make mrproper:清理所有产生的文件与config配置文件<br>·make distclean:清理所有产生的文件与config配置文件，并且编辑过的与补丁文件<br>↓<br>配置(收集硬件信息如cpu型号，网卡等…):<br>·make config:基于文本模式的交互配置<br>·make menuconfig:基于文本模式的菜单模式(推荐使用)<br>·make oldconfig:使用已有的.config,但会询问新增的配置项<br>·make xconfig:图形化的配置(需要安装图形化系统)<br>配置方法：<br>1)使用make menuconfig操作方法：<br>1&gt;按y:编译&gt;连接&gt;镜像文件<br>2&gt;按m:编译<br>3&gt;按n:什么都不做<br>4&gt;按”空格键”:y,n轮换<br>配置完并保存后会在linux源码根目录下生成一个.config文件<br>注意：在ubuntu11上要执行apt-get install libncurses5-dev来安装支持包</p>\n<p>四.linux内核模块开发<br>描述：<br>linux内核组件非常庞大，内核ximage并不包含某组件，而是在该组件需要被使用的时候，动态的添加到正在运行的内核中(也可以卸载)，这种机制叫做“内核模块”的机制。内核模块通常通过使用makefile文件对模块进行编译<br>模块安装与卸载:<br>1)加载：insmod hello.ko<br>2)卸载：rmmod hello<br>3)查看：lsmod<br>4)加载(自动寻找模块依赖)：modprobe hello<br>modprobe会根据文件/lib/modules/version/modules.dep来查看要加载的模块，看它是否还依赖于其他模块，如果是,会先找到这些模块，把它们先加载到内核</p>\n","site":{"data":{}},"excerpt":"","more":"<p>linux 系统体系结构：<br><img src=\"linux_gun.jpg\" alt=\"\"></p>\n<p>linux kernel体系结构：<br>arm有7种工作模式，x86也实现了4个不同级别RING0-RING3,RING0级别最高，<br>这样linux用户代码运行在RING3下，内核运行在RING0,这样系统本身就得到了<br>充分的保护<br>用户空间(用户模式)转到内核空间(系统模式)方法：<br>·系统调用<br>·硬件中断<br>linux kernel 体系结构：<br><img src=\"linux_kernel.jpg\" alt=\"\"></p>\n<p>虚拟文件系统VFS:<br>VFS(虚拟文件系统)隐藏各种文件系统的具体细节，为文件操作提供统一的接口</p>\n<p>二.Linux内核源代码<br>linux内核下载<a href=\"http://www.kernel.org\" target=\"_blank\" rel=\"noopener\">www.kernel.org</a><br>目录结构:<br>解压linux kernel tar后目录<br>·arch:根据cpu体系结构不同而分的代码<br>·block:部分块设备驱动程序<br>·crypto:加密，压缩，CRC校验算法<br>·documentation:内核文档<br>·drivers:设备驱动程序<br>·fs(虚拟文件系统vfs):文件系统<br>·include:内核所需的头文件，(与平台无关的头文件在include/linux中)<br>·lib:库文件代码(与平台相关的)<br>·mm:实现内存管理，与硬件体系结构无关的(与硬件体系结构相关的在arch中)<br>·net:网络协议的代码<br>·samples:一些内核编程的范例<br>·scripts:配置内核的脚本<br>·security:SElinux的模块<br>·sound:音频设备的驱动程序<br>·usr:cpio命令实现，用于制作根文件系统的命令(文件系统与内核放到一块的命令)<br>·virt:内核虚拟机<br>linux DOC 编译生成:<br>linux源根目录/Documentation/00-INDEX:目录索引<br>linux源根目录/Documentation/HOWTO:指南<br>·生成linux内核帮助文档:在linux源根目录(Documentation) 执行make htmldocs<br>ubuntu16下需要执行sudo apt-get install xmlto安装插件才可生成doc文档</p>\n<p>三.Linux内核配置与编译<br>清理文件(在linux源码根目录):<br>·make clean:只清理所有产生的文件<br>·make mrproper:清理所有产生的文件与config配置文件<br>·make distclean:清理所有产生的文件与config配置文件，并且编辑过的与补丁文件<br>↓<br>配置(收集硬件信息如cpu型号，网卡等…):<br>·make config:基于文本模式的交互配置<br>·make menuconfig:基于文本模式的菜单模式(推荐使用)<br>·make oldconfig:使用已有的.config,但会询问新增的配置项<br>·make xconfig:图形化的配置(需要安装图形化系统)<br>配置方法：<br>1)使用make menuconfig操作方法：<br>1&gt;按y:编译&gt;连接&gt;镜像文件<br>2&gt;按m:编译<br>3&gt;按n:什么都不做<br>4&gt;按”空格键”:y,n轮换<br>配置完并保存后会在linux源码根目录下生成一个.config文件<br>注意：在ubuntu11上要执行apt-get install libncurses5-dev来安装支持包</p>\n<p>四.linux内核模块开发<br>描述：<br>linux内核组件非常庞大，内核ximage并不包含某组件，而是在该组件需要被使用的时候，动态的添加到正在运行的内核中(也可以卸载)，这种机制叫做“内核模块”的机制。内核模块通常通过使用makefile文件对模块进行编译<br>模块安装与卸载:<br>1)加载：insmod hello.ko<br>2)卸载：rmmod hello<br>3)查看：lsmod<br>4)加载(自动寻找模块依赖)：modprobe hello<br>modprobe会根据文件/lib/modules/version/modules.dep来查看要加载的模块，看它是否还依赖于其他模块，如果是,会先找到这些模块，把它们先加载到内核</p>\n"},{"title":"Linux kernel 更新","_content":"第一种: 源码更新：\n目前系统内核目录\n/usr/src/kernels/3.10.0-693.el7.x86_64/.config\n/usr/src/kernels/3.10.0-957.21.3.el7.x86_64/.config\n上面文件夹内基本都只有头文件，缺少kernel的源码文件\nmake -j12\n先make modules_install\n然后make install\n就可以重启了\n这种kernel源码一般只有头文件的。。。我没用过yum安装的kernel，都是自己去kernel.org上下载源码自己编译的\n就算下载的kernel比目前版本新也可以，只需要make oldconfig\n就会把老的config都应用到新的内核里\n\n\n1.下载内核\nhttp://www.kernel.org下载内核代码\n# 下载\nsudo wget https://cdn.kernel.org/pub/linux/kernel/v4.x/linux-4.17.3.tar.xz\n# 解压 下载的文件格式是.tar.xz，需要先解压\nsudo xz -d linux-4.17.3.tar.xz\n# 这样只解压了一层，发现解压后是tar格式，需要用tar命令再解压\nsudo tar -xf linux-4.17.3.tar\n# 这样便可以进入到目录linux-4.17.3了\n2.部署内核源码\n# 把内核解压到/usr/src目录下 cd /usr/src tar -xvf ~/Downloads/linux-4.14.1.tar.xz #解压源码\n\n3.在内核代码目录下创建.config\n\ncd linux-4.14.1 \ncp /boot/config-`uname -r` .config #这里`uname -r`可以求出当前的内核版本 sudo make oldconfig\n\n4. 编译内核\nsudo make\nsudo make modules_install\nsudo make install\n\n编译时可能出现缺少openssl，apt install即可，make的时间比较长，中途如果出错再次编译前最好先sudo make clean\n5. 测试\nsudo reboot #重启\nuname -r # 查看内核版本\n\n第一次重启可能比较慢，耐心等待即可。\n\n第二种: rpm包更新:\nCentOS7 更新最新内核\n内核下载地址：https://elrepo.org/linux/kernel/el7/x86_64/RPMS/\n内核选择\nkernel-lt（lt=long-term）长期有效\nkernel-ml（ml=mainline）主流版本\n升级kernel\n安装过程\n1.下载内核\nwget https://elrepo.org/linux/kernel/el7/x86_64/RPMS/kernel-ml-5.4.3-1.el7.elrepo.x86_64.rpm\n如果网站不需要证件，或文件过大需后台下载(-b)命令如下:\nwget -c -b https://elrepo.org/linux/kernel/el7/x86_64/RPMS/kernel-ml-5.4.3-1.el7.elrepo.x86_64.rpm --no-check-certificate\n\n2.安装内核\nrpm -ivh kernel-ml-5.4.3-1.el7.elrepo.x86_64.rpm\n\n3.查看当前默认内核\n# grub2-editenv list\nsaved_entry=CentOS Linux (3.10.0-327.28.3.el7.x86_64) 7 (Core)\n\n4.查看所有内核启动 grub2\n# awk -F \\' '$1==\"menuentry \" {print i++ \" : \" $2}' /etc/grub2.cfg \n0 : CentOS Linux (5.4.3-1.el7.elrepo.x86_64) 7 (Core)\n1 : CentOS Linux (3.10.0-327.28.3.el7.x86_64) 7 (Core)\n2 : CentOS Linux (3.10.0-327.22.2.el7.x86_64) 7 (Core)\n3 : CentOS Linux (3.10.0-327.13.1.el7.x86_64) 7 (Core)\n4 : CentOS Linux, with Linux 0-rescue-cd8c4444947b4b0b818457f51ded6591\n\n5.修改为最新的内核启动\ngrub2-set-default 'CentOS Linux (5.4.3-1.el7.elrepo.x86_64) 7 (Core)'\n\n6.再次查看内核\n# grub2-editenv list\nsaved_entry=CentOS Linux (5.4.3-1.el7.elrepo.x86_64) 7 (Core)\n\n7.重新启动\nreboot\n\n8.更新kernel-ml-headers\nwget http://ftp.osuosl.org/pub/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-headers-5.4.3-1.el7.elrepo.x86_64.rpm\n如果遇到headers版本冲突如下\n先卸载当前的kernel-headers, 会卸载一些依赖如gcc g++等，可以在卸载后安装新版kernel-headers后再安装回来\nyum remove kernel-headers\n再安装此此5.4 kernel-headers\nrpm -ivh kernel-ml-headers-5.4.3-1.el7.elrepo.x86_64.rpm\n\n9.更新kernel-ml-devel\nhttp://ftp.osuosl.org/pub/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-devel-5.4.3-1.el7.elrepo.x86_64.rpm\nrpm -ivh kernel-ml-devel-5.4.3-1.el7.elrepo.x86_64.rpm\n\n\t10. # yum install gcc\n","source":"_posts/linux/Linux_kernel_更新.md","raw":"---\ntitle: Linux kernel 更新\ntags: \ncategories:\n- linux\n---\n第一种: 源码更新：\n目前系统内核目录\n/usr/src/kernels/3.10.0-693.el7.x86_64/.config\n/usr/src/kernels/3.10.0-957.21.3.el7.x86_64/.config\n上面文件夹内基本都只有头文件，缺少kernel的源码文件\nmake -j12\n先make modules_install\n然后make install\n就可以重启了\n这种kernel源码一般只有头文件的。。。我没用过yum安装的kernel，都是自己去kernel.org上下载源码自己编译的\n就算下载的kernel比目前版本新也可以，只需要make oldconfig\n就会把老的config都应用到新的内核里\n\n\n1.下载内核\nhttp://www.kernel.org下载内核代码\n# 下载\nsudo wget https://cdn.kernel.org/pub/linux/kernel/v4.x/linux-4.17.3.tar.xz\n# 解压 下载的文件格式是.tar.xz，需要先解压\nsudo xz -d linux-4.17.3.tar.xz\n# 这样只解压了一层，发现解压后是tar格式，需要用tar命令再解压\nsudo tar -xf linux-4.17.3.tar\n# 这样便可以进入到目录linux-4.17.3了\n2.部署内核源码\n# 把内核解压到/usr/src目录下 cd /usr/src tar -xvf ~/Downloads/linux-4.14.1.tar.xz #解压源码\n\n3.在内核代码目录下创建.config\n\ncd linux-4.14.1 \ncp /boot/config-`uname -r` .config #这里`uname -r`可以求出当前的内核版本 sudo make oldconfig\n\n4. 编译内核\nsudo make\nsudo make modules_install\nsudo make install\n\n编译时可能出现缺少openssl，apt install即可，make的时间比较长，中途如果出错再次编译前最好先sudo make clean\n5. 测试\nsudo reboot #重启\nuname -r # 查看内核版本\n\n第一次重启可能比较慢，耐心等待即可。\n\n第二种: rpm包更新:\nCentOS7 更新最新内核\n内核下载地址：https://elrepo.org/linux/kernel/el7/x86_64/RPMS/\n内核选择\nkernel-lt（lt=long-term）长期有效\nkernel-ml（ml=mainline）主流版本\n升级kernel\n安装过程\n1.下载内核\nwget https://elrepo.org/linux/kernel/el7/x86_64/RPMS/kernel-ml-5.4.3-1.el7.elrepo.x86_64.rpm\n如果网站不需要证件，或文件过大需后台下载(-b)命令如下:\nwget -c -b https://elrepo.org/linux/kernel/el7/x86_64/RPMS/kernel-ml-5.4.3-1.el7.elrepo.x86_64.rpm --no-check-certificate\n\n2.安装内核\nrpm -ivh kernel-ml-5.4.3-1.el7.elrepo.x86_64.rpm\n\n3.查看当前默认内核\n# grub2-editenv list\nsaved_entry=CentOS Linux (3.10.0-327.28.3.el7.x86_64) 7 (Core)\n\n4.查看所有内核启动 grub2\n# awk -F \\' '$1==\"menuentry \" {print i++ \" : \" $2}' /etc/grub2.cfg \n0 : CentOS Linux (5.4.3-1.el7.elrepo.x86_64) 7 (Core)\n1 : CentOS Linux (3.10.0-327.28.3.el7.x86_64) 7 (Core)\n2 : CentOS Linux (3.10.0-327.22.2.el7.x86_64) 7 (Core)\n3 : CentOS Linux (3.10.0-327.13.1.el7.x86_64) 7 (Core)\n4 : CentOS Linux, with Linux 0-rescue-cd8c4444947b4b0b818457f51ded6591\n\n5.修改为最新的内核启动\ngrub2-set-default 'CentOS Linux (5.4.3-1.el7.elrepo.x86_64) 7 (Core)'\n\n6.再次查看内核\n# grub2-editenv list\nsaved_entry=CentOS Linux (5.4.3-1.el7.elrepo.x86_64) 7 (Core)\n\n7.重新启动\nreboot\n\n8.更新kernel-ml-headers\nwget http://ftp.osuosl.org/pub/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-headers-5.4.3-1.el7.elrepo.x86_64.rpm\n如果遇到headers版本冲突如下\n先卸载当前的kernel-headers, 会卸载一些依赖如gcc g++等，可以在卸载后安装新版kernel-headers后再安装回来\nyum remove kernel-headers\n再安装此此5.4 kernel-headers\nrpm -ivh kernel-ml-headers-5.4.3-1.el7.elrepo.x86_64.rpm\n\n9.更新kernel-ml-devel\nhttp://ftp.osuosl.org/pub/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-devel-5.4.3-1.el7.elrepo.x86_64.rpm\nrpm -ivh kernel-ml-devel-5.4.3-1.el7.elrepo.x86_64.rpm\n\n\t10. # yum install gcc\n","slug":"linux/Linux_kernel_更新","published":1,"date":"2020-08-12T16:05:46.280Z","updated":"2020-02-13T12:47:44.399Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmcv0012hohxcsuldp2n","content":"<p>第一种: 源码更新：<br>目前系统内核目录<br>/usr/src/kernels/3.10.0-693.el7.x86_64/.config<br>/usr/src/kernels/3.10.0-957.21.3.el7.x86_64/.config<br>上面文件夹内基本都只有头文件，缺少kernel的源码文件<br>make -j12<br>先make modules_install<br>然后make install<br>就可以重启了<br>这种kernel源码一般只有头文件的。。。我没用过yum安装的kernel，都是自己去kernel.org上下载源码自己编译的<br>就算下载的kernel比目前版本新也可以，只需要make oldconfig<br>就会把老的config都应用到新的内核里</p>\n<p>1.下载内核<br><a href=\"http://www.kernel.org下载内核代码\" target=\"_blank\" rel=\"noopener\">http://www.kernel.org下载内核代码</a></p>\n<h1 id=\"下载\"><a href=\"#下载\" class=\"headerlink\" title=\"下载\"></a>下载</h1><p>sudo wget <a href=\"https://cdn.kernel.org/pub/linux/kernel/v4.x/linux-4.17.3.tar.xz\" target=\"_blank\" rel=\"noopener\">https://cdn.kernel.org/pub/linux/kernel/v4.x/linux-4.17.3.tar.xz</a></p>\n<h1 id=\"解压-下载的文件格式是-tar-xz，需要先解压\"><a href=\"#解压-下载的文件格式是-tar-xz，需要先解压\" class=\"headerlink\" title=\"解压 下载的文件格式是.tar.xz，需要先解压\"></a>解压 下载的文件格式是.tar.xz，需要先解压</h1><p>sudo xz -d linux-4.17.3.tar.xz</p>\n<h1 id=\"这样只解压了一层，发现解压后是tar格式，需要用tar命令再解压\"><a href=\"#这样只解压了一层，发现解压后是tar格式，需要用tar命令再解压\" class=\"headerlink\" title=\"这样只解压了一层，发现解压后是tar格式，需要用tar命令再解压\"></a>这样只解压了一层，发现解压后是tar格式，需要用tar命令再解压</h1><p>sudo tar -xf linux-4.17.3.tar</p>\n<h1 id=\"这样便可以进入到目录linux-4-17-3了\"><a href=\"#这样便可以进入到目录linux-4-17-3了\" class=\"headerlink\" title=\"这样便可以进入到目录linux-4.17.3了\"></a>这样便可以进入到目录linux-4.17.3了</h1><p>2.部署内核源码</p>\n<h1 id=\"把内核解压到-usr-src目录下-cd-usr-src-tar-xvf-Downloads-linux-4-14-1-tar-xz-解压源码\"><a href=\"#把内核解压到-usr-src目录下-cd-usr-src-tar-xvf-Downloads-linux-4-14-1-tar-xz-解压源码\" class=\"headerlink\" title=\"把内核解压到/usr/src目录下 cd /usr/src tar -xvf ~/Downloads/linux-4.14.1.tar.xz #解压源码\"></a>把内核解压到/usr/src目录下 cd /usr/src tar -xvf ~/Downloads/linux-4.14.1.tar.xz #解压源码</h1><p>3.在内核代码目录下创建.config</p>\n<p>cd linux-4.14.1<br>cp /boot/config-<code>uname -r</code> .config #这里<code>uname -r</code>可以求出当前的内核版本 sudo make oldconfig</p>\n<ol start=\"4\">\n<li>编译内核<br>sudo make<br>sudo make modules_install<br>sudo make install</li>\n</ol>\n<p>编译时可能出现缺少openssl，apt install即可，make的时间比较长，中途如果出错再次编译前最好先sudo make clean<br>5. 测试<br>sudo reboot #重启<br>uname -r # 查看内核版本</p>\n<p>第一次重启可能比较慢，耐心等待即可。</p>\n<p>第二种: rpm包更新:<br>CentOS7 更新最新内核<br>内核下载地址：<a href=\"https://elrepo.org/linux/kernel/el7/x86_64/RPMS/\" target=\"_blank\" rel=\"noopener\">https://elrepo.org/linux/kernel/el7/x86_64/RPMS/</a><br>内核选择<br>kernel-lt（lt=long-term）长期有效<br>kernel-ml（ml=mainline）主流版本<br>升级kernel<br>安装过程<br>1.下载内核<br>wget <a href=\"https://elrepo.org/linux/kernel/el7/x86_64/RPMS/kernel-ml-5.4.3-1.el7.elrepo.x86_64.rpm\" target=\"_blank\" rel=\"noopener\">https://elrepo.org/linux/kernel/el7/x86_64/RPMS/kernel-ml-5.4.3-1.el7.elrepo.x86_64.rpm</a><br>如果网站不需要证件，或文件过大需后台下载(-b)命令如下:<br>wget -c -b <a href=\"https://elrepo.org/linux/kernel/el7/x86_64/RPMS/kernel-ml-5.4.3-1.el7.elrepo.x86_64.rpm\" target=\"_blank\" rel=\"noopener\">https://elrepo.org/linux/kernel/el7/x86_64/RPMS/kernel-ml-5.4.3-1.el7.elrepo.x86_64.rpm</a> –no-check-certificate</p>\n<p>2.安装内核<br>rpm -ivh kernel-ml-5.4.3-1.el7.elrepo.x86_64.rpm</p>\n<p>3.查看当前默认内核</p>\n<h1 id=\"grub2-editenv-list\"><a href=\"#grub2-editenv-list\" class=\"headerlink\" title=\"grub2-editenv list\"></a>grub2-editenv list</h1><p>saved_entry=CentOS Linux (3.10.0-327.28.3.el7.x86_64) 7 (Core)</p>\n<p>4.查看所有内核启动 grub2</p>\n<h1 id=\"awk-F-39-‘-1-”menuentry-“-print-i-“-“-2-’-etc-grub2-cfg\"><a href=\"#awk-F-39-‘-1-”menuentry-“-print-i-“-“-2-’-etc-grub2-cfg\" class=\"headerlink\" title=\"awk -F &#39; ‘$1==”menuentry “ {print i++ “ : “ $2}’ /etc/grub2.cfg\"></a>awk -F &#39; ‘$1==”menuentry “ {print i++ “ : “ $2}’ /etc/grub2.cfg</h1><p>0 : CentOS Linux (5.4.3-1.el7.elrepo.x86_64) 7 (Core)<br>1 : CentOS Linux (3.10.0-327.28.3.el7.x86_64) 7 (Core)<br>2 : CentOS Linux (3.10.0-327.22.2.el7.x86_64) 7 (Core)<br>3 : CentOS Linux (3.10.0-327.13.1.el7.x86_64) 7 (Core)<br>4 : CentOS Linux, with Linux 0-rescue-cd8c4444947b4b0b818457f51ded6591</p>\n<p>5.修改为最新的内核启动<br>grub2-set-default ‘CentOS Linux (5.4.3-1.el7.elrepo.x86_64) 7 (Core)’</p>\n<p>6.再次查看内核</p>\n<h1 id=\"grub2-editenv-list-1\"><a href=\"#grub2-editenv-list-1\" class=\"headerlink\" title=\"grub2-editenv list\"></a>grub2-editenv list</h1><p>saved_entry=CentOS Linux (5.4.3-1.el7.elrepo.x86_64) 7 (Core)</p>\n<p>7.重新启动<br>reboot</p>\n<p>8.更新kernel-ml-headers<br>wget <a href=\"http://ftp.osuosl.org/pub/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-headers-5.4.3-1.el7.elrepo.x86_64.rpm\" target=\"_blank\" rel=\"noopener\">http://ftp.osuosl.org/pub/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-headers-5.4.3-1.el7.elrepo.x86_64.rpm</a><br>如果遇到headers版本冲突如下<br>先卸载当前的kernel-headers, 会卸载一些依赖如gcc g++等，可以在卸载后安装新版kernel-headers后再安装回来<br>yum remove kernel-headers<br>再安装此此5.4 kernel-headers<br>rpm -ivh kernel-ml-headers-5.4.3-1.el7.elrepo.x86_64.rpm</p>\n<p>9.更新kernel-ml-devel<br><a href=\"http://ftp.osuosl.org/pub/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-devel-5.4.3-1.el7.elrepo.x86_64.rpm\" target=\"_blank\" rel=\"noopener\">http://ftp.osuosl.org/pub/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-devel-5.4.3-1.el7.elrepo.x86_64.rpm</a><br>rpm -ivh kernel-ml-devel-5.4.3-1.el7.elrepo.x86_64.rpm</p>\n<pre><code>10. # yum install gcc</code></pre>","site":{"data":{}},"excerpt":"","more":"<p>第一种: 源码更新：<br>目前系统内核目录<br>/usr/src/kernels/3.10.0-693.el7.x86_64/.config<br>/usr/src/kernels/3.10.0-957.21.3.el7.x86_64/.config<br>上面文件夹内基本都只有头文件，缺少kernel的源码文件<br>make -j12<br>先make modules_install<br>然后make install<br>就可以重启了<br>这种kernel源码一般只有头文件的。。。我没用过yum安装的kernel，都是自己去kernel.org上下载源码自己编译的<br>就算下载的kernel比目前版本新也可以，只需要make oldconfig<br>就会把老的config都应用到新的内核里</p>\n<p>1.下载内核<br><a href=\"http://www.kernel.org下载内核代码\" target=\"_blank\" rel=\"noopener\">http://www.kernel.org下载内核代码</a></p>\n<h1 id=\"下载\"><a href=\"#下载\" class=\"headerlink\" title=\"下载\"></a>下载</h1><p>sudo wget <a href=\"https://cdn.kernel.org/pub/linux/kernel/v4.x/linux-4.17.3.tar.xz\" target=\"_blank\" rel=\"noopener\">https://cdn.kernel.org/pub/linux/kernel/v4.x/linux-4.17.3.tar.xz</a></p>\n<h1 id=\"解压-下载的文件格式是-tar-xz，需要先解压\"><a href=\"#解压-下载的文件格式是-tar-xz，需要先解压\" class=\"headerlink\" title=\"解压 下载的文件格式是.tar.xz，需要先解压\"></a>解压 下载的文件格式是.tar.xz，需要先解压</h1><p>sudo xz -d linux-4.17.3.tar.xz</p>\n<h1 id=\"这样只解压了一层，发现解压后是tar格式，需要用tar命令再解压\"><a href=\"#这样只解压了一层，发现解压后是tar格式，需要用tar命令再解压\" class=\"headerlink\" title=\"这样只解压了一层，发现解压后是tar格式，需要用tar命令再解压\"></a>这样只解压了一层，发现解压后是tar格式，需要用tar命令再解压</h1><p>sudo tar -xf linux-4.17.3.tar</p>\n<h1 id=\"这样便可以进入到目录linux-4-17-3了\"><a href=\"#这样便可以进入到目录linux-4-17-3了\" class=\"headerlink\" title=\"这样便可以进入到目录linux-4.17.3了\"></a>这样便可以进入到目录linux-4.17.3了</h1><p>2.部署内核源码</p>\n<h1 id=\"把内核解压到-usr-src目录下-cd-usr-src-tar-xvf-Downloads-linux-4-14-1-tar-xz-解压源码\"><a href=\"#把内核解压到-usr-src目录下-cd-usr-src-tar-xvf-Downloads-linux-4-14-1-tar-xz-解压源码\" class=\"headerlink\" title=\"把内核解压到/usr/src目录下 cd /usr/src tar -xvf ~/Downloads/linux-4.14.1.tar.xz #解压源码\"></a>把内核解压到/usr/src目录下 cd /usr/src tar -xvf ~/Downloads/linux-4.14.1.tar.xz #解压源码</h1><p>3.在内核代码目录下创建.config</p>\n<p>cd linux-4.14.1<br>cp /boot/config-<code>uname -r</code> .config #这里<code>uname -r</code>可以求出当前的内核版本 sudo make oldconfig</p>\n<ol start=\"4\">\n<li>编译内核<br>sudo make<br>sudo make modules_install<br>sudo make install</li>\n</ol>\n<p>编译时可能出现缺少openssl，apt install即可，make的时间比较长，中途如果出错再次编译前最好先sudo make clean<br>5. 测试<br>sudo reboot #重启<br>uname -r # 查看内核版本</p>\n<p>第一次重启可能比较慢，耐心等待即可。</p>\n<p>第二种: rpm包更新:<br>CentOS7 更新最新内核<br>内核下载地址：<a href=\"https://elrepo.org/linux/kernel/el7/x86_64/RPMS/\" target=\"_blank\" rel=\"noopener\">https://elrepo.org/linux/kernel/el7/x86_64/RPMS/</a><br>内核选择<br>kernel-lt（lt=long-term）长期有效<br>kernel-ml（ml=mainline）主流版本<br>升级kernel<br>安装过程<br>1.下载内核<br>wget <a href=\"https://elrepo.org/linux/kernel/el7/x86_64/RPMS/kernel-ml-5.4.3-1.el7.elrepo.x86_64.rpm\" target=\"_blank\" rel=\"noopener\">https://elrepo.org/linux/kernel/el7/x86_64/RPMS/kernel-ml-5.4.3-1.el7.elrepo.x86_64.rpm</a><br>如果网站不需要证件，或文件过大需后台下载(-b)命令如下:<br>wget -c -b <a href=\"https://elrepo.org/linux/kernel/el7/x86_64/RPMS/kernel-ml-5.4.3-1.el7.elrepo.x86_64.rpm\" target=\"_blank\" rel=\"noopener\">https://elrepo.org/linux/kernel/el7/x86_64/RPMS/kernel-ml-5.4.3-1.el7.elrepo.x86_64.rpm</a> –no-check-certificate</p>\n<p>2.安装内核<br>rpm -ivh kernel-ml-5.4.3-1.el7.elrepo.x86_64.rpm</p>\n<p>3.查看当前默认内核</p>\n<h1 id=\"grub2-editenv-list\"><a href=\"#grub2-editenv-list\" class=\"headerlink\" title=\"grub2-editenv list\"></a>grub2-editenv list</h1><p>saved_entry=CentOS Linux (3.10.0-327.28.3.el7.x86_64) 7 (Core)</p>\n<p>4.查看所有内核启动 grub2</p>\n<h1 id=\"awk-F-39-‘-1-”menuentry-“-print-i-“-“-2-’-etc-grub2-cfg\"><a href=\"#awk-F-39-‘-1-”menuentry-“-print-i-“-“-2-’-etc-grub2-cfg\" class=\"headerlink\" title=\"awk -F &#39; ‘$1==”menuentry “ {print i++ “ : “ $2}’ /etc/grub2.cfg\"></a>awk -F &#39; ‘$1==”menuentry “ {print i++ “ : “ $2}’ /etc/grub2.cfg</h1><p>0 : CentOS Linux (5.4.3-1.el7.elrepo.x86_64) 7 (Core)<br>1 : CentOS Linux (3.10.0-327.28.3.el7.x86_64) 7 (Core)<br>2 : CentOS Linux (3.10.0-327.22.2.el7.x86_64) 7 (Core)<br>3 : CentOS Linux (3.10.0-327.13.1.el7.x86_64) 7 (Core)<br>4 : CentOS Linux, with Linux 0-rescue-cd8c4444947b4b0b818457f51ded6591</p>\n<p>5.修改为最新的内核启动<br>grub2-set-default ‘CentOS Linux (5.4.3-1.el7.elrepo.x86_64) 7 (Core)’</p>\n<p>6.再次查看内核</p>\n<h1 id=\"grub2-editenv-list-1\"><a href=\"#grub2-editenv-list-1\" class=\"headerlink\" title=\"grub2-editenv list\"></a>grub2-editenv list</h1><p>saved_entry=CentOS Linux (5.4.3-1.el7.elrepo.x86_64) 7 (Core)</p>\n<p>7.重新启动<br>reboot</p>\n<p>8.更新kernel-ml-headers<br>wget <a href=\"http://ftp.osuosl.org/pub/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-headers-5.4.3-1.el7.elrepo.x86_64.rpm\" target=\"_blank\" rel=\"noopener\">http://ftp.osuosl.org/pub/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-headers-5.4.3-1.el7.elrepo.x86_64.rpm</a><br>如果遇到headers版本冲突如下<br>先卸载当前的kernel-headers, 会卸载一些依赖如gcc g++等，可以在卸载后安装新版kernel-headers后再安装回来<br>yum remove kernel-headers<br>再安装此此5.4 kernel-headers<br>rpm -ivh kernel-ml-headers-5.4.3-1.el7.elrepo.x86_64.rpm</p>\n<p>9.更新kernel-ml-devel<br><a href=\"http://ftp.osuosl.org/pub/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-devel-5.4.3-1.el7.elrepo.x86_64.rpm\" target=\"_blank\" rel=\"noopener\">http://ftp.osuosl.org/pub/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-devel-5.4.3-1.el7.elrepo.x86_64.rpm</a><br>rpm -ivh kernel-ml-devel-5.4.3-1.el7.elrepo.x86_64.rpm</p>\n<pre><code>10. # yum install gcc</code></pre>"},{"title":"Linux 永远修改时间","_content":"安装在虚拟机上的CentOS7的时间分为系统时间和硬件时间。二者都修改，重启系统（init 6 )才会永久生效。\n\n修改步骤如下\n查看当前系统时间 date\n修改当前系统时间 date -s \"2018-2-22 19:10:30\"\n查看硬件时间 hwclock --show\n修改硬件时间 hwclock --set --date \"2018-2-22 19:10:30\"\n同步系统时间和硬件时间 hwclock --hctosys\n保存时钟 clock -w\n重启系统（init 6）后便发现系统时间被修改了\n\ninit0:关机\ninit1：单用户形式，只root进行维护\ninit2：多用户，不能使用net file system\ninit3：完全多用户\ninit5：图形化\ninit6：重启\ninit是Linux系统操作中不可缺少的程序之一。所谓的init进程，它是一个由内核启动的用户级进程。 \n内核自行启动（已经被载入内存，开始运行，并已初始化所有的设备驱动程序和数据结\n构等。之后，就通过启动一个用户级程序init的方式，完成引导进程。所以,init始终是第一个进程（其进程编号始终为1）。 \n内核会在过去曾使用过init的几个地方查找它，它的正确位置（对Linux系统来是/sbin/init）。如果内核找不到init，它就会试着运行/bin/sh，如果运行失败，系统的启动会失败。\n","source":"_posts/linux/Linux永远修改时间.md","raw":"---\ntitle: Linux 永远修改时间\ntags: \ncategories:\n- linux\n---\n安装在虚拟机上的CentOS7的时间分为系统时间和硬件时间。二者都修改，重启系统（init 6 )才会永久生效。\n\n修改步骤如下\n查看当前系统时间 date\n修改当前系统时间 date -s \"2018-2-22 19:10:30\"\n查看硬件时间 hwclock --show\n修改硬件时间 hwclock --set --date \"2018-2-22 19:10:30\"\n同步系统时间和硬件时间 hwclock --hctosys\n保存时钟 clock -w\n重启系统（init 6）后便发现系统时间被修改了\n\ninit0:关机\ninit1：单用户形式，只root进行维护\ninit2：多用户，不能使用net file system\ninit3：完全多用户\ninit5：图形化\ninit6：重启\ninit是Linux系统操作中不可缺少的程序之一。所谓的init进程，它是一个由内核启动的用户级进程。 \n内核自行启动（已经被载入内存，开始运行，并已初始化所有的设备驱动程序和数据结\n构等。之后，就通过启动一个用户级程序init的方式，完成引导进程。所以,init始终是第一个进程（其进程编号始终为1）。 \n内核会在过去曾使用过init的几个地方查找它，它的正确位置（对Linux系统来是/sbin/init）。如果内核找不到init，它就会试着运行/bin/sh，如果运行失败，系统的启动会失败。\n","slug":"linux/Linux永远修改时间","published":1,"date":"2020-08-12T16:05:46.320Z","updated":"2020-02-13T12:47:44.405Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmd10014hohxd0ncaaeg","content":"<p>安装在虚拟机上的CentOS7的时间分为系统时间和硬件时间。二者都修改，重启系统（init 6 )才会永久生效。</p>\n<p>修改步骤如下<br>查看当前系统时间 date<br>修改当前系统时间 date -s “2018-2-22 19:10:30”<br>查看硬件时间 hwclock –show<br>修改硬件时间 hwclock –set –date “2018-2-22 19:10:30”<br>同步系统时间和硬件时间 hwclock –hctosys<br>保存时钟 clock -w<br>重启系统（init 6）后便发现系统时间被修改了</p>\n<p>init0:关机<br>init1：单用户形式，只root进行维护<br>init2：多用户，不能使用net file system<br>init3：完全多用户<br>init5：图形化<br>init6：重启<br>init是Linux系统操作中不可缺少的程序之一。所谓的init进程，它是一个由内核启动的用户级进程。<br>内核自行启动（已经被载入内存，开始运行，并已初始化所有的设备驱动程序和数据结<br>构等。之后，就通过启动一个用户级程序init的方式，完成引导进程。所以,init始终是第一个进程（其进程编号始终为1）。<br>内核会在过去曾使用过init的几个地方查找它，它的正确位置（对Linux系统来是/sbin/init）。如果内核找不到init，它就会试着运行/bin/sh，如果运行失败，系统的启动会失败。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>安装在虚拟机上的CentOS7的时间分为系统时间和硬件时间。二者都修改，重启系统（init 6 )才会永久生效。</p>\n<p>修改步骤如下<br>查看当前系统时间 date<br>修改当前系统时间 date -s “2018-2-22 19:10:30”<br>查看硬件时间 hwclock –show<br>修改硬件时间 hwclock –set –date “2018-2-22 19:10:30”<br>同步系统时间和硬件时间 hwclock –hctosys<br>保存时钟 clock -w<br>重启系统（init 6）后便发现系统时间被修改了</p>\n<p>init0:关机<br>init1：单用户形式，只root进行维护<br>init2：多用户，不能使用net file system<br>init3：完全多用户<br>init5：图形化<br>init6：重启<br>init是Linux系统操作中不可缺少的程序之一。所谓的init进程，它是一个由内核启动的用户级进程。<br>内核自行启动（已经被载入内存，开始运行，并已初始化所有的设备驱动程序和数据结<br>构等。之后，就通过启动一个用户级程序init的方式，完成引导进程。所以,init始终是第一个进程（其进程编号始终为1）。<br>内核会在过去曾使用过init的几个地方查找它，它的正确位置（对Linux系统来是/sbin/init）。如果内核找不到init，它就会试着运行/bin/sh，如果运行失败，系统的启动会失败。</p>\n"},{"_content":"查看是否开启了ssh服务是否安装,使用命令：\nsudo ps -e |grep ssh\n\n安装openssh-server，使用命令：\nsudo apt-get install openssh-server\n\n查看主机的IP地址，使用命令：\nifconfig\n\n• 启动ssh命令：service sshd start\n• 停止ssh命令：service sshd stop\n","source":"_posts/linux/Linux能访问外网_外网却访问不了此Linux.md","raw":"查看是否开启了ssh服务是否安装,使用命令：\nsudo ps -e |grep ssh\n\n安装openssh-server，使用命令：\nsudo apt-get install openssh-server\n\n查看主机的IP地址，使用命令：\nifconfig\n\n• 启动ssh命令：service sshd start\n• 停止ssh命令：service sshd stop\n","slug":"linux/Linux能访问外网_外网却访问不了此Linux","published":1,"date":"2020-08-12T16:05:46.347Z","updated":"2020-02-13T12:47:44.408Z","title":"linux/Linux能访问外网_外网却访问不了此Linux","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmd50015hohx0ud45i77","content":"<p>查看是否开启了ssh服务是否安装,使用命令：<br>sudo ps -e |grep ssh</p>\n<p>安装openssh-server，使用命令：<br>sudo apt-get install openssh-server</p>\n<p>查看主机的IP地址，使用命令：<br>ifconfig</p>\n<p>• 启动ssh命令：service sshd start<br>• 停止ssh命令：service sshd stop</p>\n","site":{"data":{}},"excerpt":"","more":"<p>查看是否开启了ssh服务是否安装,使用命令：<br>sudo ps -e |grep ssh</p>\n<p>安装openssh-server，使用命令：<br>sudo apt-get install openssh-server</p>\n<p>查看主机的IP地址，使用命令：<br>ifconfig</p>\n<p>• 启动ssh命令：service sshd start<br>• 停止ssh命令：service sshd stop</p>\n"},{"title":"MMIO","_content":"Linux kernel目录\n/usr/src/kernels/3.10.0-693.el7.x86_64/.config\n/usr/src/kernels/3.10.0-957.21.3.el7.x86_64/.config\n上面文件夹内基本都只有头文件，缺少kernel的源码文件\nyumdownloader --source kernel  安装新的kernel源码\n\n/dev/mem是linux下的一个字符设备, 源文件是kernel/drivers/char/mem.c, 这个设备文件是专门用来读写物理地址用的。里面的内容是所有物理内存的地址以及内容信息。通常只有root用户对其有读写权限。\n#include<sys/mman.h>\nvoid *mmap(void *start, size_t length, int prot, int flags,\n           int fd, off_t offset);\nint munmap(void *start, size_t length);\nmmap详细用法不在此展开, 特别注意参数start(一般赋值为NULL)和offset是页(page, 一般默认大小为4096bytes)对齐的，而且一定要判断mmap函数的返回值。\n\n#define MAP_SIZE 4096UL\n#define MAP_MASK (MAP_SIZE - 1)\n\nif((fd = open(\"/dev/mem\", O_RDWR | O_SYNC)) == -1)\n{\n\tFATAL;\n}\nprintf(\"/dev/mem opened.\\n\"); \nfflush(stdout);\ntarget = strtoul(argv[1], 0, 0);\nmap_base = mmap(0, MAP_SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, fd, target & ~MAP_MASK);\n    if(map_base == (void *) -1)\n\t{\n\t\tFATAL;\n\t}\n    printf(\"Memory mapped at address %p.\\n\", map_base); \n    fflush(stdout);\n\n\n#######################################################################################\n\n在driver中通过alloc_pages申请得到的page，将page的物理地址export到user space，但是user space拿到这个物理地址后并不能mmap成功。通过perror(“mmap”)，发现总是返回错误\"Operation not permitted!\"，后来发现是由于kernel对user space访问/dev/mem是有限制的，通过编译选项：CONFIG_STRICT_DEVMEM来限制user space 对物理内存的访问，这个选项的说明在arch/x86/Kconfig.debug中有说明：\nconfig STRICT_DEVMEM\n    bool \"Filter access to /dev/mem\"\n    ---help---\n      If this option is disabled, you allow userspace (root) access to all\n      of memory, including kernel and userspace memory. Accidental\n      access to this is obviously disastrous, but specific access can\n      be used by people debugging the kernel. Note that with PAT support\n      enabled, even in this case there are restrictions on /dev/mem\n      use due to the cache aliasing requirements.\n      If this option is switched on, the /dev/mem file only allows\n      userspace access to PCI space and the BIOS code and data regions.\n      This is sufficient for dosemu and X and all common users of\n      /dev/mem.\n      If in doubt, say Y.\n只有在.config文件中设置CONFIG_STRICT_DEVMEM=n才能获得对整个memory的访问权限，在默认情况下，\nCONFIG_STRICT_DEVMEM=y，这也就是之前mmap总是报错：“Operation not permitted”的原因。\n设置这个选项后，编译kernel，然后运行tool，mmap还是返回错误：“Invalid argument”。后来查到还需要设置\n编译选项CONFIG_X86_PAT=n，这个选项也是默认开启的，但是要关闭这个选项还需要开启CONFIG_EXPERT，\n否则CONFIG_X86_PAT总是关不掉。\n \n设置好这三个编译选项后，重新编译kernel，然后运行tool，发现kernel已经解除了对mmap的访问限制，可以\n正确读取对应物理地址的内容了。\n最后还可以通过修改内核源代码来实现，具体的源文件时在/drivers/char/目录下的mem.c文件\nstatic inline int  range_is_allowed(unsigned long pfn, unsigned long size);\n\n\n#######################################################################################\n\nAttachment of Ref 3\n\nI think I've found the issue -- it's to do with /dev/mem memory mapping protection on the x86.\n\nPl refer to this LWN article:\"x86: introduce /dev/mem restrictions with a config option\"http://lwn.net/Articles/267427/\n\nCONFIG_NONPROMISC_DEVMEM\n\nNow (i tested this on a recent 3.2.21 kernel), the config option seems to be called CONFIG_STRICT_DEVMEM.\n\nI changed my kernel config:\n\n$ grep DEVMEM .config\n# CONFIG_STRICT_DEVMEM is not set\n$ \nWhen the above prg was run with the previous kernel, with CONFIG_STRICT_DEVMEM SET:dmesg shows:\n\n[29537.565599] Program a.out tried to access /dev/mem between 1000000->1001000.\n[29537.565663] a.out[13575]: segfault at ffffffff ip 080485bd sp bfb8d640 error 4 in a.out[8048000+1000]\nThis is because of the kernel protection..\n\nWhen the kernel was rebuilt (with the CONFIG_STRICT_DEVMEM UNSET) and the above prg was run :\n\n# ./a.out \nmmap failed: Invalid argument\n# \nThis is because the 'offset' parameter is > 1 MB (invalid on x86) (it was 16MB).\n\nAfter making the mmap offset to be within 1 MB:\n\n# ./a.out \naddr: 0xb7758000\n*addr: 138293760 \n# \nIt works!See the above LWN article for details.\n\nOn x86 architectures with PAT support (Page Attribute Table), the kernel still prevents the mapping of DRAM regions. The reason for this as mentioned in the kernel source is:\n\nThis check is nedded to avoid cache aliasing when PAT is enabled\nThis check will cause a similar error to the one mentioned above. For example:\n\nProgram a.out tried to access /dev/mem between [mem 68200000-68201000].\nThis restriction can be removed by disabling PAT. PAT can be disabled by adding the \"nopat\" argument to the kernel command line at boot time.\n","source":"_posts/linux/MMIO.md","raw":"---\ntitle: MMIO\ntags: \ncategories:\n- linux\n---\nLinux kernel目录\n/usr/src/kernels/3.10.0-693.el7.x86_64/.config\n/usr/src/kernels/3.10.0-957.21.3.el7.x86_64/.config\n上面文件夹内基本都只有头文件，缺少kernel的源码文件\nyumdownloader --source kernel  安装新的kernel源码\n\n/dev/mem是linux下的一个字符设备, 源文件是kernel/drivers/char/mem.c, 这个设备文件是专门用来读写物理地址用的。里面的内容是所有物理内存的地址以及内容信息。通常只有root用户对其有读写权限。\n#include<sys/mman.h>\nvoid *mmap(void *start, size_t length, int prot, int flags,\n           int fd, off_t offset);\nint munmap(void *start, size_t length);\nmmap详细用法不在此展开, 特别注意参数start(一般赋值为NULL)和offset是页(page, 一般默认大小为4096bytes)对齐的，而且一定要判断mmap函数的返回值。\n\n#define MAP_SIZE 4096UL\n#define MAP_MASK (MAP_SIZE - 1)\n\nif((fd = open(\"/dev/mem\", O_RDWR | O_SYNC)) == -1)\n{\n\tFATAL;\n}\nprintf(\"/dev/mem opened.\\n\"); \nfflush(stdout);\ntarget = strtoul(argv[1], 0, 0);\nmap_base = mmap(0, MAP_SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, fd, target & ~MAP_MASK);\n    if(map_base == (void *) -1)\n\t{\n\t\tFATAL;\n\t}\n    printf(\"Memory mapped at address %p.\\n\", map_base); \n    fflush(stdout);\n\n\n#######################################################################################\n\n在driver中通过alloc_pages申请得到的page，将page的物理地址export到user space，但是user space拿到这个物理地址后并不能mmap成功。通过perror(“mmap”)，发现总是返回错误\"Operation not permitted!\"，后来发现是由于kernel对user space访问/dev/mem是有限制的，通过编译选项：CONFIG_STRICT_DEVMEM来限制user space 对物理内存的访问，这个选项的说明在arch/x86/Kconfig.debug中有说明：\nconfig STRICT_DEVMEM\n    bool \"Filter access to /dev/mem\"\n    ---help---\n      If this option is disabled, you allow userspace (root) access to all\n      of memory, including kernel and userspace memory. Accidental\n      access to this is obviously disastrous, but specific access can\n      be used by people debugging the kernel. Note that with PAT support\n      enabled, even in this case there are restrictions on /dev/mem\n      use due to the cache aliasing requirements.\n      If this option is switched on, the /dev/mem file only allows\n      userspace access to PCI space and the BIOS code and data regions.\n      This is sufficient for dosemu and X and all common users of\n      /dev/mem.\n      If in doubt, say Y.\n只有在.config文件中设置CONFIG_STRICT_DEVMEM=n才能获得对整个memory的访问权限，在默认情况下，\nCONFIG_STRICT_DEVMEM=y，这也就是之前mmap总是报错：“Operation not permitted”的原因。\n设置这个选项后，编译kernel，然后运行tool，mmap还是返回错误：“Invalid argument”。后来查到还需要设置\n编译选项CONFIG_X86_PAT=n，这个选项也是默认开启的，但是要关闭这个选项还需要开启CONFIG_EXPERT，\n否则CONFIG_X86_PAT总是关不掉。\n \n设置好这三个编译选项后，重新编译kernel，然后运行tool，发现kernel已经解除了对mmap的访问限制，可以\n正确读取对应物理地址的内容了。\n最后还可以通过修改内核源代码来实现，具体的源文件时在/drivers/char/目录下的mem.c文件\nstatic inline int  range_is_allowed(unsigned long pfn, unsigned long size);\n\n\n#######################################################################################\n\nAttachment of Ref 3\n\nI think I've found the issue -- it's to do with /dev/mem memory mapping protection on the x86.\n\nPl refer to this LWN article:\"x86: introduce /dev/mem restrictions with a config option\"http://lwn.net/Articles/267427/\n\nCONFIG_NONPROMISC_DEVMEM\n\nNow (i tested this on a recent 3.2.21 kernel), the config option seems to be called CONFIG_STRICT_DEVMEM.\n\nI changed my kernel config:\n\n$ grep DEVMEM .config\n# CONFIG_STRICT_DEVMEM is not set\n$ \nWhen the above prg was run with the previous kernel, with CONFIG_STRICT_DEVMEM SET:dmesg shows:\n\n[29537.565599] Program a.out tried to access /dev/mem between 1000000->1001000.\n[29537.565663] a.out[13575]: segfault at ffffffff ip 080485bd sp bfb8d640 error 4 in a.out[8048000+1000]\nThis is because of the kernel protection..\n\nWhen the kernel was rebuilt (with the CONFIG_STRICT_DEVMEM UNSET) and the above prg was run :\n\n# ./a.out \nmmap failed: Invalid argument\n# \nThis is because the 'offset' parameter is > 1 MB (invalid on x86) (it was 16MB).\n\nAfter making the mmap offset to be within 1 MB:\n\n# ./a.out \naddr: 0xb7758000\n*addr: 138293760 \n# \nIt works!See the above LWN article for details.\n\nOn x86 architectures with PAT support (Page Attribute Table), the kernel still prevents the mapping of DRAM regions. The reason for this as mentioned in the kernel source is:\n\nThis check is nedded to avoid cache aliasing when PAT is enabled\nThis check will cause a similar error to the one mentioned above. For example:\n\nProgram a.out tried to access /dev/mem between [mem 68200000-68201000].\nThis restriction can be removed by disabling PAT. PAT can be disabled by adding the \"nopat\" argument to the kernel command line at boot time.\n","slug":"linux/MMIO","published":1,"date":"2020-08-12T16:05:46.350Z","updated":"2020-02-13T12:47:44.411Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmd90018hohxa5b65gq5","content":"<p>Linux kernel目录<br>/usr/src/kernels/3.10.0-693.el7.x86_64/.config<br>/usr/src/kernels/3.10.0-957.21.3.el7.x86_64/.config<br>上面文件夹内基本都只有头文件，缺少kernel的源码文件<br>yumdownloader –source kernel  安装新的kernel源码</p>\n<p>/dev/mem是linux下的一个字符设备, 源文件是kernel/drivers/char/mem.c, 这个设备文件是专门用来读写物理地址用的。里面的内容是所有物理内存的地址以及内容信息。通常只有root用户对其有读写权限。<br>#include&lt;sys/mman.h&gt;<br>void *mmap(void *start, size_t length, int prot, int flags,<br>           int fd, off_t offset);<br>int munmap(void *start, size_t length);<br>mmap详细用法不在此展开, 特别注意参数start(一般赋值为NULL)和offset是页(page, 一般默认大小为4096bytes)对齐的，而且一定要判断mmap函数的返回值。</p>\n<p>#define MAP_SIZE 4096UL<br>#define MAP_MASK (MAP_SIZE - 1)</p>\n<p>if((fd = open(“/dev/mem”, O_RDWR | O_SYNC)) == -1)<br>{<br>    FATAL;<br>}<br>printf(“/dev/mem opened.\\n”);<br>fflush(stdout);<br>target = strtoul(argv[1], 0, 0);<br>map_base = mmap(0, MAP_SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, fd, target &amp; ~MAP_MASK);<br>    if(map_base == (void *) -1)<br>    {<br>        FATAL;<br>    }<br>    printf(“Memory mapped at address %p.\\n”, map_base);<br>    fflush(stdout);</p>\n<p>#######################################################################################</p>\n<p>在driver中通过alloc_pages申请得到的page，将page的物理地址export到user space，但是user space拿到这个物理地址后并不能mmap成功。通过perror(“mmap”)，发现总是返回错误”Operation not permitted!”，后来发现是由于kernel对user space访问/dev/mem是有限制的，通过编译选项：CONFIG_STRICT_DEVMEM来限制user space 对物理内存的访问，这个选项的说明在arch/x86/Kconfig.debug中有说明：<br>config STRICT_DEVMEM<br>    bool “Filter access to /dev/mem”<br>    —help—<br>      If this option is disabled, you allow userspace (root) access to all<br>      of memory, including kernel and userspace memory. Accidental<br>      access to this is obviously disastrous, but specific access can<br>      be used by people debugging the kernel. Note that with PAT support<br>      enabled, even in this case there are restrictions on /dev/mem<br>      use due to the cache aliasing requirements.<br>      If this option is switched on, the /dev/mem file only allows<br>      userspace access to PCI space and the BIOS code and data regions.<br>      This is sufficient for dosemu and X and all common users of<br>      /dev/mem.<br>      If in doubt, say Y.<br>只有在.config文件中设置CONFIG_STRICT_DEVMEM=n才能获得对整个memory的访问权限，在默认情况下，<br>CONFIG_STRICT_DEVMEM=y，这也就是之前mmap总是报错：“Operation not permitted”的原因。<br>设置这个选项后，编译kernel，然后运行tool，mmap还是返回错误：“Invalid argument”。后来查到还需要设置<br>编译选项CONFIG_X86_PAT=n，这个选项也是默认开启的，但是要关闭这个选项还需要开启CONFIG_EXPERT，<br>否则CONFIG_X86_PAT总是关不掉。</p>\n<p>设置好这三个编译选项后，重新编译kernel，然后运行tool，发现kernel已经解除了对mmap的访问限制，可以<br>正确读取对应物理地址的内容了。<br>最后还可以通过修改内核源代码来实现，具体的源文件时在/drivers/char/目录下的mem.c文件<br>static inline int  range_is_allowed(unsigned long pfn, unsigned long size);</p>\n<p>#######################################################################################</p>\n<p>Attachment of Ref 3</p>\n<p>I think I’ve found the issue – it’s to do with /dev/mem memory mapping protection on the x86.</p>\n<p>Pl refer to this LWN article:”x86: introduce /dev/mem restrictions with a config option”<a href=\"http://lwn.net/Articles/267427/\" target=\"_blank\" rel=\"noopener\">http://lwn.net/Articles/267427/</a></p>\n<p>CONFIG_NONPROMISC_DEVMEM</p>\n<p>Now (i tested this on a recent 3.2.21 kernel), the config option seems to be called CONFIG_STRICT_DEVMEM.</p>\n<p>I changed my kernel config:</p>\n<p>$ grep DEVMEM .config</p>\n<h1 id=\"CONFIG-STRICT-DEVMEM-is-not-set\"><a href=\"#CONFIG-STRICT-DEVMEM-is-not-set\" class=\"headerlink\" title=\"CONFIG_STRICT_DEVMEM is not set\"></a>CONFIG_STRICT_DEVMEM is not set</h1><p>$<br>When the above prg was run with the previous kernel, with CONFIG_STRICT_DEVMEM SET:dmesg shows:</p>\n<p>[29537.565599] Program a.out tried to access /dev/mem between 1000000-&gt;1001000.<br>[29537.565663] a.out[13575]: segfault at ffffffff ip 080485bd sp bfb8d640 error 4 in a.out[8048000+1000]<br>This is because of the kernel protection..</p>\n<p>When the kernel was rebuilt (with the CONFIG_STRICT_DEVMEM UNSET) and the above prg was run :</p>\n<h1 id=\"a-out\"><a href=\"#a-out\" class=\"headerlink\" title=\"./a.out\"></a>./a.out</h1><p>mmap failed: Invalid argument</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>This is because the ‘offset’ parameter is &gt; 1 MB (invalid on x86) (it was 16MB).</p>\n<p>After making the mmap offset to be within 1 MB:</p>\n<h1 id=\"a-out-1\"><a href=\"#a-out-1\" class=\"headerlink\" title=\"./a.out\"></a>./a.out</h1><p>addr: 0xb7758000<br>*addr: 138293760 </p>\n<h1 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h1><p>It works!See the above LWN article for details.</p>\n<p>On x86 architectures with PAT support (Page Attribute Table), the kernel still prevents the mapping of DRAM regions. The reason for this as mentioned in the kernel source is:</p>\n<p>This check is nedded to avoid cache aliasing when PAT is enabled<br>This check will cause a similar error to the one mentioned above. For example:</p>\n<p>Program a.out tried to access /dev/mem between [mem 68200000-68201000].<br>This restriction can be removed by disabling PAT. PAT can be disabled by adding the “nopat” argument to the kernel command line at boot time.</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Linux kernel目录<br>/usr/src/kernels/3.10.0-693.el7.x86_64/.config<br>/usr/src/kernels/3.10.0-957.21.3.el7.x86_64/.config<br>上面文件夹内基本都只有头文件，缺少kernel的源码文件<br>yumdownloader –source kernel  安装新的kernel源码</p>\n<p>/dev/mem是linux下的一个字符设备, 源文件是kernel/drivers/char/mem.c, 这个设备文件是专门用来读写物理地址用的。里面的内容是所有物理内存的地址以及内容信息。通常只有root用户对其有读写权限。<br>#include&lt;sys/mman.h&gt;<br>void *mmap(void *start, size_t length, int prot, int flags,<br>           int fd, off_t offset);<br>int munmap(void *start, size_t length);<br>mmap详细用法不在此展开, 特别注意参数start(一般赋值为NULL)和offset是页(page, 一般默认大小为4096bytes)对齐的，而且一定要判断mmap函数的返回值。</p>\n<p>#define MAP_SIZE 4096UL<br>#define MAP_MASK (MAP_SIZE - 1)</p>\n<p>if((fd = open(“/dev/mem”, O_RDWR | O_SYNC)) == -1)<br>{<br>    FATAL;<br>}<br>printf(“/dev/mem opened.\\n”);<br>fflush(stdout);<br>target = strtoul(argv[1], 0, 0);<br>map_base = mmap(0, MAP_SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, fd, target &amp; ~MAP_MASK);<br>    if(map_base == (void *) -1)<br>    {<br>        FATAL;<br>    }<br>    printf(“Memory mapped at address %p.\\n”, map_base);<br>    fflush(stdout);</p>\n<p>#######################################################################################</p>\n<p>在driver中通过alloc_pages申请得到的page，将page的物理地址export到user space，但是user space拿到这个物理地址后并不能mmap成功。通过perror(“mmap”)，发现总是返回错误”Operation not permitted!”，后来发现是由于kernel对user space访问/dev/mem是有限制的，通过编译选项：CONFIG_STRICT_DEVMEM来限制user space 对物理内存的访问，这个选项的说明在arch/x86/Kconfig.debug中有说明：<br>config STRICT_DEVMEM<br>    bool “Filter access to /dev/mem”<br>    —help—<br>      If this option is disabled, you allow userspace (root) access to all<br>      of memory, including kernel and userspace memory. Accidental<br>      access to this is obviously disastrous, but specific access can<br>      be used by people debugging the kernel. Note that with PAT support<br>      enabled, even in this case there are restrictions on /dev/mem<br>      use due to the cache aliasing requirements.<br>      If this option is switched on, the /dev/mem file only allows<br>      userspace access to PCI space and the BIOS code and data regions.<br>      This is sufficient for dosemu and X and all common users of<br>      /dev/mem.<br>      If in doubt, say Y.<br>只有在.config文件中设置CONFIG_STRICT_DEVMEM=n才能获得对整个memory的访问权限，在默认情况下，<br>CONFIG_STRICT_DEVMEM=y，这也就是之前mmap总是报错：“Operation not permitted”的原因。<br>设置这个选项后，编译kernel，然后运行tool，mmap还是返回错误：“Invalid argument”。后来查到还需要设置<br>编译选项CONFIG_X86_PAT=n，这个选项也是默认开启的，但是要关闭这个选项还需要开启CONFIG_EXPERT，<br>否则CONFIG_X86_PAT总是关不掉。</p>\n<p>设置好这三个编译选项后，重新编译kernel，然后运行tool，发现kernel已经解除了对mmap的访问限制，可以<br>正确读取对应物理地址的内容了。<br>最后还可以通过修改内核源代码来实现，具体的源文件时在/drivers/char/目录下的mem.c文件<br>static inline int  range_is_allowed(unsigned long pfn, unsigned long size);</p>\n<p>#######################################################################################</p>\n<p>Attachment of Ref 3</p>\n<p>I think I’ve found the issue – it’s to do with /dev/mem memory mapping protection on the x86.</p>\n<p>Pl refer to this LWN article:”x86: introduce /dev/mem restrictions with a config option”<a href=\"http://lwn.net/Articles/267427/\" target=\"_blank\" rel=\"noopener\">http://lwn.net/Articles/267427/</a></p>\n<p>CONFIG_NONPROMISC_DEVMEM</p>\n<p>Now (i tested this on a recent 3.2.21 kernel), the config option seems to be called CONFIG_STRICT_DEVMEM.</p>\n<p>I changed my kernel config:</p>\n<p>$ grep DEVMEM .config</p>\n<h1 id=\"CONFIG-STRICT-DEVMEM-is-not-set\"><a href=\"#CONFIG-STRICT-DEVMEM-is-not-set\" class=\"headerlink\" title=\"CONFIG_STRICT_DEVMEM is not set\"></a>CONFIG_STRICT_DEVMEM is not set</h1><p>$<br>When the above prg was run with the previous kernel, with CONFIG_STRICT_DEVMEM SET:dmesg shows:</p>\n<p>[29537.565599] Program a.out tried to access /dev/mem between 1000000-&gt;1001000.<br>[29537.565663] a.out[13575]: segfault at ffffffff ip 080485bd sp bfb8d640 error 4 in a.out[8048000+1000]<br>This is because of the kernel protection..</p>\n<p>When the kernel was rebuilt (with the CONFIG_STRICT_DEVMEM UNSET) and the above prg was run :</p>\n<h1 id=\"a-out\"><a href=\"#a-out\" class=\"headerlink\" title=\"./a.out\"></a>./a.out</h1><p>mmap failed: Invalid argument</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>This is because the ‘offset’ parameter is &gt; 1 MB (invalid on x86) (it was 16MB).</p>\n<p>After making the mmap offset to be within 1 MB:</p>\n<h1 id=\"a-out-1\"><a href=\"#a-out-1\" class=\"headerlink\" title=\"./a.out\"></a>./a.out</h1><p>addr: 0xb7758000<br>*addr: 138293760 </p>\n<h1 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h1><p>It works!See the above LWN article for details.</p>\n<p>On x86 architectures with PAT support (Page Attribute Table), the kernel still prevents the mapping of DRAM regions. The reason for this as mentioned in the kernel source is:</p>\n<p>This check is nedded to avoid cache aliasing when PAT is enabled<br>This check will cause a similar error to the one mentioned above. For example:</p>\n<p>Program a.out tried to access /dev/mem between [mem 68200000-68201000].<br>This restriction can be removed by disabling PAT. PAT can be disabled by adding the “nopat” argument to the kernel command line at boot time.</p>\n"},{"title":"RHEL8.0开机总是要dhclient手动获取IP","tages":null,"_content":"使用#dhclient前提是网线得确保连上且没问题\n#kill -9 dhclient_thread_ID\n解决RHEL8.0开机自动获取IP方法如下:\n\t1. #ifconfig                                                     //查看第一个网卡名称ifcfg-enp0s20f0u4u1\n\t2. #cd /etc/sysconfig/network-scripts/\n\t3. #ls\n\tifcfg-enp1s0                                                //发现只有一个网卡配置文件，与#ifconfig查看到得网卡名字都不一致\n\t4. #cp ifcfg-enp1s0 ifcfg-enp0s20f0u4u1    //手动copy一个与存在得网卡名相同得网卡配置文件\n\t5. #vim  ifcfg-enp0s20f0u4u1\n\t\t○ 删除UUID那一行\n\t\t○ 修改NAME=ifcfg-enp0s20f0u4u1\n\t\t○ 修改DEVICE=ifcfg-enp0s20f0u4u1\n\t\t○ 修改ONBOOT=yes                              //开机即启动网络连接\n","source":"_posts/linux/RHEL8.0开机总是要dhclient手动获取IP.md","raw":"---\ntitle: RHEL8.0开机总是要dhclient手动获取IP\ntages: \ncategories:\n- linux\n---\n使用#dhclient前提是网线得确保连上且没问题\n#kill -9 dhclient_thread_ID\n解决RHEL8.0开机自动获取IP方法如下:\n\t1. #ifconfig                                                     //查看第一个网卡名称ifcfg-enp0s20f0u4u1\n\t2. #cd /etc/sysconfig/network-scripts/\n\t3. #ls\n\tifcfg-enp1s0                                                //发现只有一个网卡配置文件，与#ifconfig查看到得网卡名字都不一致\n\t4. #cp ifcfg-enp1s0 ifcfg-enp0s20f0u4u1    //手动copy一个与存在得网卡名相同得网卡配置文件\n\t5. #vim  ifcfg-enp0s20f0u4u1\n\t\t○ 删除UUID那一行\n\t\t○ 修改NAME=ifcfg-enp0s20f0u4u1\n\t\t○ 修改DEVICE=ifcfg-enp0s20f0u4u1\n\t\t○ 修改ONBOOT=yes                              //开机即启动网络连接\n","slug":"linux/RHEL8.0开机总是要dhclient手动获取IP","published":1,"date":"2020-08-12T16:05:46.390Z","updated":"2020-02-13T12:47:44.419Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmdc0019hohxbnos6g82","content":"<p>使用#dhclient前提是网线得确保连上且没问题<br>#kill -9 dhclient_thread_ID<br>解决RHEL8.0开机自动获取IP方法如下:<br>    1. #ifconfig                                                     //查看第一个网卡名称ifcfg-enp0s20f0u4u1<br>    2. #cd /etc/sysconfig/network-scripts/<br>    3. #ls<br>    ifcfg-enp1s0                                                //发现只有一个网卡配置文件，与#ifconfig查看到得网卡名字都不一致<br>    4. #cp ifcfg-enp1s0 ifcfg-enp0s20f0u4u1    //手动copy一个与存在得网卡名相同得网卡配置文件<br>    5. #vim  ifcfg-enp0s20f0u4u1<br>        ○ 删除UUID那一行<br>        ○ 修改NAME=ifcfg-enp0s20f0u4u1<br>        ○ 修改DEVICE=ifcfg-enp0s20f0u4u1<br>        ○ 修改ONBOOT=yes                              //开机即启动网络连接</p>\n","site":{"data":{}},"excerpt":"","more":"<p>使用#dhclient前提是网线得确保连上且没问题<br>#kill -9 dhclient_thread_ID<br>解决RHEL8.0开机自动获取IP方法如下:<br>    1. #ifconfig                                                     //查看第一个网卡名称ifcfg-enp0s20f0u4u1<br>    2. #cd /etc/sysconfig/network-scripts/<br>    3. #ls<br>    ifcfg-enp1s0                                                //发现只有一个网卡配置文件，与#ifconfig查看到得网卡名字都不一致<br>    4. #cp ifcfg-enp1s0 ifcfg-enp0s20f0u4u1    //手动copy一个与存在得网卡名相同得网卡配置文件<br>    5. #vim  ifcfg-enp0s20f0u4u1<br>        ○ 删除UUID那一行<br>        ○ 修改NAME=ifcfg-enp0s20f0u4u1<br>        ○ 修改DEVICE=ifcfg-enp0s20f0u4u1<br>        ○ 修改ONBOOT=yes                              //开机即启动网络连接</p>\n"},{"title":"TSC","_content":"linux/Documentation/virtual/kvm/timekeeping.txt\n\nFrom <https://github.com/torvalds/linux/blob/6f0d349d922ba44e4348a17a78ea51b7135965b1/Documentation/virtual/kvm/timekeeping.txt> \n\n1) Overview\n2) Timing Devices\n3) TSC Hardware\n4) Virtualization Problems\n","source":"_posts/linux/TSC.md","raw":"---\ntitle: TSC\ntags: \ncategories:\n- linux\n---\nlinux/Documentation/virtual/kvm/timekeeping.txt\n\nFrom <https://github.com/torvalds/linux/blob/6f0d349d922ba44e4348a17a78ea51b7135965b1/Documentation/virtual/kvm/timekeeping.txt> \n\n1) Overview\n2) Timing Devices\n3) TSC Hardware\n4) Virtualization Problems\n","slug":"linux/TSC","published":1,"date":"2020-08-12T16:05:46.470Z","updated":"2020-02-13T12:47:44.422Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmdg001chohx7gxzco5x","content":"<p>linux/Documentation/virtual/kvm/timekeeping.txt</p>\n<p>From <a href=\"https://github.com/torvalds/linux/blob/6f0d349d922ba44e4348a17a78ea51b7135965b1/Documentation/virtual/kvm/timekeeping.txt\" target=\"_blank\" rel=\"noopener\">https://github.com/torvalds/linux/blob/6f0d349d922ba44e4348a17a78ea51b7135965b1/Documentation/virtual/kvm/timekeeping.txt</a> </p>\n<p>1) Overview<br>2) Timing Devices<br>3) TSC Hardware<br>4) Virtualization Problems</p>\n","site":{"data":{}},"excerpt":"","more":"<p>linux/Documentation/virtual/kvm/timekeeping.txt</p>\n<p>From <a href=\"https://github.com/torvalds/linux/blob/6f0d349d922ba44e4348a17a78ea51b7135965b1/Documentation/virtual/kvm/timekeeping.txt\" target=\"_blank\" rel=\"noopener\">https://github.com/torvalds/linux/blob/6f0d349d922ba44e4348a17a78ea51b7135965b1/Documentation/virtual/kvm/timekeeping.txt</a> </p>\n<p>1) Overview<br>2) Timing Devices<br>3) TSC Hardware<br>4) Virtualization Problems</p>\n"},{"title":"PTU(Power Thermal Utility)","_content":"PTU (Power Thermal Utility)\nIntel PTU (Power Thermal Utility) 可以用來測試 CPU 與 Memory 但是這工具需要有 Intel 帳號.\n\nFrom <https://blog.csdn.net/guyan1101/article/details/80591831> \n\n","source":"_posts/linux/PTU(Power Thermal Utility).md","raw":"---\ntitle: PTU(Power Thermal Utility)\ntags: \ncategories:\n- linux\n---\nPTU (Power Thermal Utility)\nIntel PTU (Power Thermal Utility) 可以用來測試 CPU 與 Memory 但是這工具需要有 Intel 帳號.\n\nFrom <https://blog.csdn.net/guyan1101/article/details/80591831> \n\n","slug":"linux/PTU(Power Thermal Utility)","published":1,"date":"2020-08-12T16:05:46.387Z","updated":"2020-02-13T12:47:44.415Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmdk001ehohx6dym6wlh","content":"<p>PTU (Power Thermal Utility)<br>Intel PTU (Power Thermal Utility) 可以用來測試 CPU 與 Memory 但是這工具需要有 Intel 帳號.</p>\n<p>From <a href=\"https://blog.csdn.net/guyan1101/article/details/80591831\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/guyan1101/article/details/80591831</a> </p>\n","site":{"data":{}},"excerpt":"","more":"<p>PTU (Power Thermal Utility)<br>Intel PTU (Power Thermal Utility) 可以用來測試 CPU 與 Memory 但是這工具需要有 Intel 帳號.</p>\n<p>From <a href=\"https://blog.csdn.net/guyan1101/article/details/80591831\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/guyan1101/article/details/80591831</a> </p>\n"},{"title":"Ubuntu下安装CUDA8.0及nvidia驱动(详细教程）","_content":"为什么说对的系统呢，这是因为在多次尝试后发现，如果使用ubuntu14安装显卡驱动会出现无法进入系统，一直在循环在登录界面，而ubuntu16则不会出现这个问题，所以说最好升级一下吧，毕竟14有点太老了。\n\n重要的一点是不要在安装或安装后升级内核，否则cuda无法识别内核而导致安装失败！（如果已经升级并且cuda报错，那么百度或谷歌一下如何降内核吧）\n\n先安装一些依赖吧，接下来可能用的到\n\n \n\nsudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler\nsudo apt-get install --no-install-recommends libboost-all-dev\nsudo apt-get install libopenblas-dev liblapack-dev libatlas-base-dev\nsudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev\nsudo apt-get install git cmake build-essential\n \n\n使用如下指令安装你的nvidia驱动（ubntun14会无法进入系统）\n\n \n\nsudo apt-get update\nsudo apt-get install nvidia-367\n安装好后重启，按super（windows）键，在你的程序中搜索nvidia就可以看到\n\n\n\n表示你已经成功安装显卡驱动\n\n \n\n2. 下载cuda8.0 （这里一定要是cuda8，后面的版本不适应与上诉的NVIDIA驱动）\n\n从这里下载 https://developer.nvidia.com/cuda-downloads\n\n\n\n下载出来的1G多的那个就好，下载好后将文件剪切到你的home下，右击文件，点击属性，打开后如图，选择权限，勾选执行\n\n\n\n3. 安装CUDA8.0\n\n配置一下环境变量\n\n \n\nsudo gedit ~/.bashrc\n加入这两行：\n\nexport LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH\n\nexport LD_LIBRARY_PATH=/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH\n\n然后，就可以开始安装了\n\ncd ~\nsudo sh cuda_8.0.61_375.26_linux.run\n然后会看到(按照我下面的输入即可）\n\nDo you accept the previously read EULA?\n\naccept/decline/quit: accept\n\nInstall NVIDIA Accelerated Graphics Driver for Linux-x86_64 361.62?\n\n(y)es/(n)o/(q)uit: n\n\nInstall the CUDA 8.0 Toolkit?\n\n(y)es/(n)o/(q)uit: y\n\nEnter Toolkit Location\n[ default is /usr/local/cuda-8.0 ]: 回车\n\nDo you want to install a symbolic link at /usr/local/cuda?\n(y)es/(n)o/(q)uit: y\n\nInstall the CUDA 8.0 Samples?\n\n(y)es/(n)o/(q)uit: y\n\nEnter CUDA Samples Location\n[ default is /root ]:回车\n\n接下来会出现\n\nInstalling the CUDA Toolkit in /usr/local/cuda-8.0 …\nInstalling the CUDA Samples in /root …\nCopying samples to /home/derek/NVIDIA_CUDA-8.0_Samples now…\nFinished copying samples.\n\n= Summary =\n\nDriver: Installed\nToolkit: Installed in /usr/local/cuda-8.0\nSamples: Installed in /home/derek\n\nPlease make sure that\n– PATH includes /usr/local/cuda-8.0/bin\n– LD_LIBRARY_PATH includes /usr/local/cuda-8.0/lib64, or, add /usr/local/cuda-8.0/lib64 to /etc/ld.so.conf and run ldconfig as root\n\nTo uninstall the CUDA Toolkit, run the uninstall script in /usr/local/cuda-8.0/bin\n\nPlease see CUDA_Installation_Guide_Linux.pdf in /usr/local/cuda-8.0/doc/pdf for detailed information on setting up CUDA.\n\nWARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 361.00 is required for CUDA 8.0 functionality to work.\n\nTo install the driver using this installer, run the following command, replacing with the name of this run filesudo.run -silent -driver\n\n这样就已经安装好了，就是这么简单不要怀疑，只要不出error就可以，如果出现kernel相关错误，那一般是由于内核太高了，cuda不能识别，包括cuda9等等后来的也不能，所以还是想办法降一下内核吧\n\n4. 编辑配置文件\n\nsudo gedit ~/.bash_profile\n打开配置文件，加入以下几行\n\nexport LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64\"\nexport CUDA_HOME=/usr/local/cuda-8.0\n也可以在.bashrc中配置\n\n \n\nsudo gedit ~/.bashrc\n加入这两行\n\nexport PATH=/usr/local/cuda-8.0/bin:$PATH\n\nexport LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH\n\n \n\nsource ~/.bashrc\n \n\n现在就可以验证一下cuda是否安装成功咯\n\n \n\ncd /usr/local/cuda-8.0/samples/1_Utilities/deviceQuery\nsudo make\n./deviceQuery\n--------------------- \n作者：qq_35379989 \n来源：CSDN \n原文：https://blog.csdn.net/qq_35379989/article/details/80147630 \n版权声明：本文为博主原创文章，转载请附上博文链接！\n","source":"_posts/linux/Ubuntu下安装CUDA8.0及nvidia驱动(详细教程).md","raw":"---\ntitle: Ubuntu下安装CUDA8.0及nvidia驱动(详细教程）\ntags: \ncategories:\n- linux\n---\n为什么说对的系统呢，这是因为在多次尝试后发现，如果使用ubuntu14安装显卡驱动会出现无法进入系统，一直在循环在登录界面，而ubuntu16则不会出现这个问题，所以说最好升级一下吧，毕竟14有点太老了。\n\n重要的一点是不要在安装或安装后升级内核，否则cuda无法识别内核而导致安装失败！（如果已经升级并且cuda报错，那么百度或谷歌一下如何降内核吧）\n\n先安装一些依赖吧，接下来可能用的到\n\n \n\nsudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler\nsudo apt-get install --no-install-recommends libboost-all-dev\nsudo apt-get install libopenblas-dev liblapack-dev libatlas-base-dev\nsudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev\nsudo apt-get install git cmake build-essential\n \n\n使用如下指令安装你的nvidia驱动（ubntun14会无法进入系统）\n\n \n\nsudo apt-get update\nsudo apt-get install nvidia-367\n安装好后重启，按super（windows）键，在你的程序中搜索nvidia就可以看到\n\n\n\n表示你已经成功安装显卡驱动\n\n \n\n2. 下载cuda8.0 （这里一定要是cuda8，后面的版本不适应与上诉的NVIDIA驱动）\n\n从这里下载 https://developer.nvidia.com/cuda-downloads\n\n\n\n下载出来的1G多的那个就好，下载好后将文件剪切到你的home下，右击文件，点击属性，打开后如图，选择权限，勾选执行\n\n\n\n3. 安装CUDA8.0\n\n配置一下环境变量\n\n \n\nsudo gedit ~/.bashrc\n加入这两行：\n\nexport LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH\n\nexport LD_LIBRARY_PATH=/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH\n\n然后，就可以开始安装了\n\ncd ~\nsudo sh cuda_8.0.61_375.26_linux.run\n然后会看到(按照我下面的输入即可）\n\nDo you accept the previously read EULA?\n\naccept/decline/quit: accept\n\nInstall NVIDIA Accelerated Graphics Driver for Linux-x86_64 361.62?\n\n(y)es/(n)o/(q)uit: n\n\nInstall the CUDA 8.0 Toolkit?\n\n(y)es/(n)o/(q)uit: y\n\nEnter Toolkit Location\n[ default is /usr/local/cuda-8.0 ]: 回车\n\nDo you want to install a symbolic link at /usr/local/cuda?\n(y)es/(n)o/(q)uit: y\n\nInstall the CUDA 8.0 Samples?\n\n(y)es/(n)o/(q)uit: y\n\nEnter CUDA Samples Location\n[ default is /root ]:回车\n\n接下来会出现\n\nInstalling the CUDA Toolkit in /usr/local/cuda-8.0 …\nInstalling the CUDA Samples in /root …\nCopying samples to /home/derek/NVIDIA_CUDA-8.0_Samples now…\nFinished copying samples.\n\n= Summary =\n\nDriver: Installed\nToolkit: Installed in /usr/local/cuda-8.0\nSamples: Installed in /home/derek\n\nPlease make sure that\n– PATH includes /usr/local/cuda-8.0/bin\n– LD_LIBRARY_PATH includes /usr/local/cuda-8.0/lib64, or, add /usr/local/cuda-8.0/lib64 to /etc/ld.so.conf and run ldconfig as root\n\nTo uninstall the CUDA Toolkit, run the uninstall script in /usr/local/cuda-8.0/bin\n\nPlease see CUDA_Installation_Guide_Linux.pdf in /usr/local/cuda-8.0/doc/pdf for detailed information on setting up CUDA.\n\nWARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 361.00 is required for CUDA 8.0 functionality to work.\n\nTo install the driver using this installer, run the following command, replacing with the name of this run filesudo.run -silent -driver\n\n这样就已经安装好了，就是这么简单不要怀疑，只要不出error就可以，如果出现kernel相关错误，那一般是由于内核太高了，cuda不能识别，包括cuda9等等后来的也不能，所以还是想办法降一下内核吧\n\n4. 编辑配置文件\n\nsudo gedit ~/.bash_profile\n打开配置文件，加入以下几行\n\nexport LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64\"\nexport CUDA_HOME=/usr/local/cuda-8.0\n也可以在.bashrc中配置\n\n \n\nsudo gedit ~/.bashrc\n加入这两行\n\nexport PATH=/usr/local/cuda-8.0/bin:$PATH\n\nexport LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH\n\n \n\nsource ~/.bashrc\n \n\n现在就可以验证一下cuda是否安装成功咯\n\n \n\ncd /usr/local/cuda-8.0/samples/1_Utilities/deviceQuery\nsudo make\n./deviceQuery\n--------------------- \n作者：qq_35379989 \n来源：CSDN \n原文：https://blog.csdn.net/qq_35379989/article/details/80147630 \n版权声明：本文为博主原创文章，转载请附上博文链接！\n","slug":"linux/Ubuntu下安装CUDA8.0及nvidia驱动(详细教程)","published":1,"date":"2020-08-12T16:05:46.472Z","updated":"2020-02-13T12:47:44.426Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmdo001hhohx2rgpd386","content":"<p>为什么说对的系统呢，这是因为在多次尝试后发现，如果使用ubuntu14安装显卡驱动会出现无法进入系统，一直在循环在登录界面，而ubuntu16则不会出现这个问题，所以说最好升级一下吧，毕竟14有点太老了。</p>\n<p>重要的一点是不要在安装或安装后升级内核，否则cuda无法识别内核而导致安装失败！（如果已经升级并且cuda报错，那么百度或谷歌一下如何降内核吧）</p>\n<p>先安装一些依赖吧，接下来可能用的到</p>\n<p>sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler<br>sudo apt-get install –no-install-recommends libboost-all-dev<br>sudo apt-get install libopenblas-dev liblapack-dev libatlas-base-dev<br>sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev<br>sudo apt-get install git cmake build-essential</p>\n<p>使用如下指令安装你的nvidia驱动（ubntun14会无法进入系统）</p>\n<p>sudo apt-get update<br>sudo apt-get install nvidia-367<br>安装好后重启，按super（windows）键，在你的程序中搜索nvidia就可以看到</p>\n<p>表示你已经成功安装显卡驱动</p>\n<ol start=\"2\">\n<li>下载cuda8.0 （这里一定要是cuda8，后面的版本不适应与上诉的NVIDIA驱动）</li>\n</ol>\n<p>从这里下载 <a href=\"https://developer.nvidia.com/cuda-downloads\" target=\"_blank\" rel=\"noopener\">https://developer.nvidia.com/cuda-downloads</a></p>\n<p>下载出来的1G多的那个就好，下载好后将文件剪切到你的home下，右击文件，点击属性，打开后如图，选择权限，勾选执行</p>\n<ol start=\"3\">\n<li>安装CUDA8.0</li>\n</ol>\n<p>配置一下环境变量</p>\n<p>sudo gedit ~/.bashrc<br>加入这两行：</p>\n<p>export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH</p>\n<p>export LD_LIBRARY_PATH=/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH</p>\n<p>然后，就可以开始安装了</p>\n<p>cd ~<br>sudo sh cuda_8.0.61_375.26_linux.run<br>然后会看到(按照我下面的输入即可）</p>\n<p>Do you accept the previously read EULA?</p>\n<p>accept/decline/quit: accept</p>\n<p>Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 361.62?</p>\n<p>(y)es/(n)o/(q)uit: n</p>\n<p>Install the CUDA 8.0 Toolkit?</p>\n<p>(y)es/(n)o/(q)uit: y</p>\n<p>Enter Toolkit Location<br>[ default is /usr/local/cuda-8.0 ]: 回车</p>\n<p>Do you want to install a symbolic link at /usr/local/cuda?<br>(y)es/(n)o/(q)uit: y</p>\n<p>Install the CUDA 8.0 Samples?</p>\n<p>(y)es/(n)o/(q)uit: y</p>\n<p>Enter CUDA Samples Location<br>[ default is /root ]:回车</p>\n<p>接下来会出现</p>\n<p>Installing the CUDA Toolkit in /usr/local/cuda-8.0 …<br>Installing the CUDA Samples in /root …<br>Copying samples to /home/derek/NVIDIA_CUDA-8.0_Samples now…<br>Finished copying samples.</p>\n<p>= Summary =</p>\n<p>Driver: Installed<br>Toolkit: Installed in /usr/local/cuda-8.0<br>Samples: Installed in /home/derek</p>\n<p>Please make sure that<br>– PATH includes /usr/local/cuda-8.0/bin<br>– LD_LIBRARY_PATH includes /usr/local/cuda-8.0/lib64, or, add /usr/local/cuda-8.0/lib64 to /etc/ld.so.conf and run ldconfig as root</p>\n<p>To uninstall the CUDA Toolkit, run the uninstall script in /usr/local/cuda-8.0/bin</p>\n<p>Please see CUDA_Installation_Guide_Linux.pdf in /usr/local/cuda-8.0/doc/pdf for detailed information on setting up CUDA.</p>\n<p>WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 361.00 is required for CUDA 8.0 functionality to work.</p>\n<p>To install the driver using this installer, run the following command, replacing with the name of this run filesudo.run -silent -driver</p>\n<p>这样就已经安装好了，就是这么简单不要怀疑，只要不出error就可以，如果出现kernel相关错误，那一般是由于内核太高了，cuda不能识别，包括cuda9等等后来的也不能，所以还是想办法降一下内核吧</p>\n<ol start=\"4\">\n<li>编辑配置文件</li>\n</ol>\n<p>sudo gedit ~/.bash_profile<br>打开配置文件，加入以下几行</p>\n<p>export LD_LIBRARY_PATH=”$LD_LIBRARY_PATH:/usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64”<br>export CUDA_HOME=/usr/local/cuda-8.0<br>也可以在.bashrc中配置</p>\n<p>sudo gedit ~/.bashrc<br>加入这两行</p>\n<p>export PATH=/usr/local/cuda-8.0/bin:$PATH</p>\n<p>export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH</p>\n<p>source ~/.bashrc</p>\n<p>现在就可以验证一下cuda是否安装成功咯</p>\n<p>cd /usr/local/cuda-8.0/samples/1_Utilities/deviceQuery<br>sudo make<br>./deviceQuery</p>\n<hr>\n<p>作者：qq_35379989<br>来源：CSDN<br>原文：<a href=\"https://blog.csdn.net/qq_35379989/article/details/80147630\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_35379989/article/details/80147630</a><br>版权声明：本文为博主原创文章，转载请附上博文链接！</p>\n","site":{"data":{}},"excerpt":"","more":"<p>为什么说对的系统呢，这是因为在多次尝试后发现，如果使用ubuntu14安装显卡驱动会出现无法进入系统，一直在循环在登录界面，而ubuntu16则不会出现这个问题，所以说最好升级一下吧，毕竟14有点太老了。</p>\n<p>重要的一点是不要在安装或安装后升级内核，否则cuda无法识别内核而导致安装失败！（如果已经升级并且cuda报错，那么百度或谷歌一下如何降内核吧）</p>\n<p>先安装一些依赖吧，接下来可能用的到</p>\n<p>sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler<br>sudo apt-get install –no-install-recommends libboost-all-dev<br>sudo apt-get install libopenblas-dev liblapack-dev libatlas-base-dev<br>sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev<br>sudo apt-get install git cmake build-essential</p>\n<p>使用如下指令安装你的nvidia驱动（ubntun14会无法进入系统）</p>\n<p>sudo apt-get update<br>sudo apt-get install nvidia-367<br>安装好后重启，按super（windows）键，在你的程序中搜索nvidia就可以看到</p>\n<p>表示你已经成功安装显卡驱动</p>\n<ol start=\"2\">\n<li>下载cuda8.0 （这里一定要是cuda8，后面的版本不适应与上诉的NVIDIA驱动）</li>\n</ol>\n<p>从这里下载 <a href=\"https://developer.nvidia.com/cuda-downloads\" target=\"_blank\" rel=\"noopener\">https://developer.nvidia.com/cuda-downloads</a></p>\n<p>下载出来的1G多的那个就好，下载好后将文件剪切到你的home下，右击文件，点击属性，打开后如图，选择权限，勾选执行</p>\n<ol start=\"3\">\n<li>安装CUDA8.0</li>\n</ol>\n<p>配置一下环境变量</p>\n<p>sudo gedit ~/.bashrc<br>加入这两行：</p>\n<p>export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH</p>\n<p>export LD_LIBRARY_PATH=/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH</p>\n<p>然后，就可以开始安装了</p>\n<p>cd ~<br>sudo sh cuda_8.0.61_375.26_linux.run<br>然后会看到(按照我下面的输入即可）</p>\n<p>Do you accept the previously read EULA?</p>\n<p>accept/decline/quit: accept</p>\n<p>Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 361.62?</p>\n<p>(y)es/(n)o/(q)uit: n</p>\n<p>Install the CUDA 8.0 Toolkit?</p>\n<p>(y)es/(n)o/(q)uit: y</p>\n<p>Enter Toolkit Location<br>[ default is /usr/local/cuda-8.0 ]: 回车</p>\n<p>Do you want to install a symbolic link at /usr/local/cuda?<br>(y)es/(n)o/(q)uit: y</p>\n<p>Install the CUDA 8.0 Samples?</p>\n<p>(y)es/(n)o/(q)uit: y</p>\n<p>Enter CUDA Samples Location<br>[ default is /root ]:回车</p>\n<p>接下来会出现</p>\n<p>Installing the CUDA Toolkit in /usr/local/cuda-8.0 …<br>Installing the CUDA Samples in /root …<br>Copying samples to /home/derek/NVIDIA_CUDA-8.0_Samples now…<br>Finished copying samples.</p>\n<p>= Summary =</p>\n<p>Driver: Installed<br>Toolkit: Installed in /usr/local/cuda-8.0<br>Samples: Installed in /home/derek</p>\n<p>Please make sure that<br>– PATH includes /usr/local/cuda-8.0/bin<br>– LD_LIBRARY_PATH includes /usr/local/cuda-8.0/lib64, or, add /usr/local/cuda-8.0/lib64 to /etc/ld.so.conf and run ldconfig as root</p>\n<p>To uninstall the CUDA Toolkit, run the uninstall script in /usr/local/cuda-8.0/bin</p>\n<p>Please see CUDA_Installation_Guide_Linux.pdf in /usr/local/cuda-8.0/doc/pdf for detailed information on setting up CUDA.</p>\n<p>WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 361.00 is required for CUDA 8.0 functionality to work.</p>\n<p>To install the driver using this installer, run the following command, replacing with the name of this run filesudo.run -silent -driver</p>\n<p>这样就已经安装好了，就是这么简单不要怀疑，只要不出error就可以，如果出现kernel相关错误，那一般是由于内核太高了，cuda不能识别，包括cuda9等等后来的也不能，所以还是想办法降一下内核吧</p>\n<ol start=\"4\">\n<li>编辑配置文件</li>\n</ol>\n<p>sudo gedit ~/.bash_profile<br>打开配置文件，加入以下几行</p>\n<p>export LD_LIBRARY_PATH=”$LD_LIBRARY_PATH:/usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64”<br>export CUDA_HOME=/usr/local/cuda-8.0<br>也可以在.bashrc中配置</p>\n<p>sudo gedit ~/.bashrc<br>加入这两行</p>\n<p>export PATH=/usr/local/cuda-8.0/bin:$PATH</p>\n<p>export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH</p>\n<p>source ~/.bashrc</p>\n<p>现在就可以验证一下cuda是否安装成功咯</p>\n<p>cd /usr/local/cuda-8.0/samples/1_Utilities/deviceQuery<br>sudo make<br>./deviceQuery</p>\n<hr>\n<p>作者：qq_35379989<br>来源：CSDN<br>原文：<a href=\"https://blog.csdn.net/qq_35379989/article/details/80147630\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_35379989/article/details/80147630</a><br>版权声明：本文为博主原创文章，转载请附上博文链接！</p>\n"},{"title":"U盘RAW类型修复","_content":"\n## U盘RAW类型修复\n由于不正常断电等因素，U盘插在windows上后OS读取不到，打开磁盘管理器查看发现U盘TYPE为RAW.\n解决办法: \n\n1. 打开系统磁盘管理器，鼠标右击U盘所在的卷，选择删除卷\n\n2. 下载DiskGenius压缩包，免安装，双击\"DiskGenius.exe\"打开\nhttps://dl.pconline.com.cn/download/356592-1.html\n\n3. 查看左边一列，右击U盘所在的选项，选择\"清除扇区数据\"，然后格式化，选择卷标等，之后就可以了.\n\n","source":"_posts/linux/U盘RAW类型修复.md","raw":"---\ntitle: U盘RAW类型修复\ntags: \ncategories:\n- linux\n---\n\n## U盘RAW类型修复\n由于不正常断电等因素，U盘插在windows上后OS读取不到，打开磁盘管理器查看发现U盘TYPE为RAW.\n解决办法: \n\n1. 打开系统磁盘管理器，鼠标右击U盘所在的卷，选择删除卷\n\n2. 下载DiskGenius压缩包，免安装，双击\"DiskGenius.exe\"打开\nhttps://dl.pconline.com.cn/download/356592-1.html\n\n3. 查看左边一列，右击U盘所在的选项，选择\"清除扇区数据\"，然后格式化，选择卷标等，之后就可以了.\n\n","slug":"linux/U盘RAW类型修复","published":1,"date":"2020-08-12T16:05:46.474Z","updated":"2020-05-31T12:27:13.077Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmdr001jhohx7moa5t0w","content":"<h2 id=\"U盘RAW类型修复\"><a href=\"#U盘RAW类型修复\" class=\"headerlink\" title=\"U盘RAW类型修复\"></a>U盘RAW类型修复</h2><p>由于不正常断电等因素，U盘插在windows上后OS读取不到，打开磁盘管理器查看发现U盘TYPE为RAW.<br>解决办法: </p>\n<ol>\n<li><p>打开系统磁盘管理器，鼠标右击U盘所在的卷，选择删除卷</p>\n</li>\n<li><p>下载DiskGenius压缩包，免安装，双击”DiskGenius.exe”打开<br><a href=\"https://dl.pconline.com.cn/download/356592-1.html\" target=\"_blank\" rel=\"noopener\">https://dl.pconline.com.cn/download/356592-1.html</a></p>\n</li>\n<li><p>查看左边一列，右击U盘所在的选项，选择”清除扇区数据”，然后格式化，选择卷标等，之后就可以了.</p>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"U盘RAW类型修复\"><a href=\"#U盘RAW类型修复\" class=\"headerlink\" title=\"U盘RAW类型修复\"></a>U盘RAW类型修复</h2><p>由于不正常断电等因素，U盘插在windows上后OS读取不到，打开磁盘管理器查看发现U盘TYPE为RAW.<br>解决办法: </p>\n<ol>\n<li><p>打开系统磁盘管理器，鼠标右击U盘所在的卷，选择删除卷</p>\n</li>\n<li><p>下载DiskGenius压缩包，免安装，双击”DiskGenius.exe”打开<br><a href=\"https://dl.pconline.com.cn/download/356592-1.html\" target=\"_blank\" rel=\"noopener\">https://dl.pconline.com.cn/download/356592-1.html</a></p>\n</li>\n<li><p>查看左边一列，右击U盘所在的选项，选择”清除扇区数据”，然后格式化，选择卷标等，之后就可以了.</p>\n</li>\n</ol>\n"},{"title":"U盘制作启动盘分区后恢复","_content":"\n## 操作步骤\n1. 插入U盘。\n2. 按windows键，右键点击运行，再左键点击以管理员身份运行。\n3. 输入diskpart,按enter。\n![](diskpart.png)\n4. 输入list disk,按enter。\n![](list_disk.png)\n5. 之后会看到\ndisk 0\ndisk 1\n如果你给你电脑磁盘分过区的话可能还有disk 2  、  disk 3等\n![](list_disk.png)\n6. 输入select disk X(X代表磁盘后面的数字0、1，可磁盘的大小来判断数字是多少，一般是1),按enter\n![](select_disk.png)\n7. 输入clean，按enter\n![](clean.png)\n8. \n以上完成之后，到“磁盘管理”选择U盘，新建简单卷，并重命名你的U盘\n\n打开“磁盘管理”方法:\n任务栏\"Search\"输入\"disk management\", 选择运行\"Create and format hard disk partitions\"\n\"新建简单卷\"方法:\n打开磁盘管理后，选中U盘所在Disk 如Disk1， 右击鼠标，选中第一个新建卷，默认下一步，期间\"Volume lable\"输入盘volume名字就可以了.\n\n\n","source":"_posts/linux/U盘分区之后如何恢复.md","raw":"---\ntitle: U盘制作启动盘分区后恢复\ntags: \ncategories:\n- linux\n---\n\n## 操作步骤\n1. 插入U盘。\n2. 按windows键，右键点击运行，再左键点击以管理员身份运行。\n3. 输入diskpart,按enter。\n![](diskpart.png)\n4. 输入list disk,按enter。\n![](list_disk.png)\n5. 之后会看到\ndisk 0\ndisk 1\n如果你给你电脑磁盘分过区的话可能还有disk 2  、  disk 3等\n![](list_disk.png)\n6. 输入select disk X(X代表磁盘后面的数字0、1，可磁盘的大小来判断数字是多少，一般是1),按enter\n![](select_disk.png)\n7. 输入clean，按enter\n![](clean.png)\n8. \n以上完成之后，到“磁盘管理”选择U盘，新建简单卷，并重命名你的U盘\n\n打开“磁盘管理”方法:\n任务栏\"Search\"输入\"disk management\", 选择运行\"Create and format hard disk partitions\"\n\"新建简单卷\"方法:\n打开磁盘管理后，选中U盘所在Disk 如Disk1， 右击鼠标，选中第一个新建卷，默认下一步，期间\"Volume lable\"输入盘volume名字就可以了.\n\n\n","slug":"linux/U盘分区之后如何恢复","published":1,"date":"2020-08-12T16:05:46.487Z","updated":"2020-05-31T12:18:41.039Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hme0001mhohx8clj8xxk","content":"<h2 id=\"操作步骤\"><a href=\"#操作步骤\" class=\"headerlink\" title=\"操作步骤\"></a>操作步骤</h2><ol>\n<li>插入U盘。</li>\n<li>按windows键，右键点击运行，再左键点击以管理员身份运行。</li>\n<li>输入diskpart,按enter。<br><img src=\"diskpart.png\" alt=\"\"></li>\n<li>输入list disk,按enter。<br><img src=\"list_disk.png\" alt=\"\"></li>\n<li>之后会看到<br>disk 0<br>disk 1<br>如果你给你电脑磁盘分过区的话可能还有disk 2  、  disk 3等<br><img src=\"list_disk.png\" alt=\"\"></li>\n<li>输入select disk X(X代表磁盘后面的数字0、1，可磁盘的大小来判断数字是多少，一般是1),按enter<br><img src=\"select_disk.png\" alt=\"\"></li>\n<li>输入clean，按enter<br><img src=\"clean.png\" alt=\"\"></li>\n<li>以上完成之后，到“磁盘管理”选择U盘，新建简单卷，并重命名你的U盘</li>\n</ol>\n<p>打开“磁盘管理”方法:<br>任务栏”Search”输入”disk management”, 选择运行”Create and format hard disk partitions”<br>“新建简单卷”方法:<br>打开磁盘管理后，选中U盘所在Disk 如Disk1， 右击鼠标，选中第一个新建卷，默认下一步，期间”Volume lable”输入盘volume名字就可以了.</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"操作步骤\"><a href=\"#操作步骤\" class=\"headerlink\" title=\"操作步骤\"></a>操作步骤</h2><ol>\n<li>插入U盘。</li>\n<li>按windows键，右键点击运行，再左键点击以管理员身份运行。</li>\n<li>输入diskpart,按enter。<br><img src=\"diskpart.png\" alt=\"\"></li>\n<li>输入list disk,按enter。<br><img src=\"list_disk.png\" alt=\"\"></li>\n<li>之后会看到<br>disk 0<br>disk 1<br>如果你给你电脑磁盘分过区的话可能还有disk 2  、  disk 3等<br><img src=\"list_disk.png\" alt=\"\"></li>\n<li>输入select disk X(X代表磁盘后面的数字0、1，可磁盘的大小来判断数字是多少，一般是1),按enter<br><img src=\"select_disk.png\" alt=\"\"></li>\n<li>输入clean，按enter<br><img src=\"clean.png\" alt=\"\"></li>\n<li>以上完成之后，到“磁盘管理”选择U盘，新建简单卷，并重命名你的U盘</li>\n</ol>\n<p>打开“磁盘管理”方法:<br>任务栏”Search”输入”disk management”, 选择运行”Create and format hard disk partitions”<br>“新建简单卷”方法:<br>打开磁盘管理后，选中U盘所在Disk 如Disk1， 右击鼠标，选中第一个新建卷，默认下一步，期间”Volume lable”输入盘volume名字就可以了.</p>\n"},{"title":"U盘安装OS_Ubuntu_18.04","_content":"\n### 1. 安装启动盘(U 盘)\n> $ fdisk -l\n> $ umount /dev/sdb1\n> $ mkfs.vfat /dev/sdb -I\n> $ sudo dd if=~/Downloads/ubuntu-16.04-desktop-amd64.iso of=/dev/sdb status=progress\n\n### 2. 开启root访问权限\n> $ sudo passwd root\n> 输入user用户密码，再设置root密码，下次就可以$ su root 获取root权限了\n\n### Add new user\n> $ adduser $USERNAME\n> $ passwd $PASSWD\n\n### 3. 设置网络\n> * 点击屏幕右上角向下三角\n>  + Wired Connected -> Wired Settings -> Network Proxy -> Manual -> HTTP Proxy等输入child-prc.intel.com, port输入913\n>  + 到此可以试着打开浏览器看能不能上网\n> * vi ~/.bashrc 添加如下内容\n\n\texport http_proxy=http://child-prc.intel.com:913\n\texport https_proxy=$http_proxy\n\texport HTTP_PROXY=$http_proxy\n\texport HTTPS_PROXY=$http_proxy\n\n> $ source ~/.bashrc 使得上面添加的内容生效\n> $ apt-get update\n> $ apt-get upgrade\n> $ apt install net-tools\t\t// 到此可以用ifconfig查看ip\n> $ apt-get install vim\t\t// 可以用vim命令了\n> $ vim ~/.vimrc\t// 如果没有则新建.vimrc文件, 添加如下内容\n```\nset nu\nset tabstop=4\n```\n\n### 4. 安装ssh并开启root远程登录\n> $ apt-get install openssh-server\n> $ vim /etc/ssh/sshd_config\n\n\tPermitRootLogin yes\t\t// 去掉PermitRootLogin前面的\"#\"注释，后面值改为yes, 如果不设置则远程只能登录user用户如ai而不能直接登录root\n\n> $ /etc/init.d/ssh start\t\t// 启动SSH服务\n> $ ps -e | grep sshd\t\t\t// 查看SSH是否启动成功\n> $ /etc/init.d/ssh stop\t\t// 关闭SSH服务, 如果先开启服务再设置PermitRootLogin为yes则需要关掉ssh服务再启动ssh服务使其修改生效\n\n### 5. 安装build-essential等必要的编译配置运行程序工具如gcc等\n> $ apt install build-essential\t// 该命令将安装一堆新包，包括gcc，g ++和make。\n> $ gcc --version\t\t// gcc -v\n\n### 安装curl，会安装后运行可能出现的问题\n> * 安装:\n>    $ apt-get update\n>    $ apt-get upgrade\n>    $ apt-get install curl\n>    $ curl --version\n> * 提前设置好系统的proxy如:\n>    export http_proxy=child-prc.intel.com:913\n>    export https_proxy=child-prc.intel.com:913 // https的proxy与上面的http的要一样\n\n> * 运行curl可能出现的问题:\n>\tcurl: error while loading shared libraries: libcurl.so.4: cannot open shared object file: No such file or directo\n>   $ find -name \"libcurl.so.4\" /\n>   查看得到库文件在/usr/local/lib/libcurl.so.4\n>   解决方法一: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib\t//当前终端生效\n>   解决方法二: 把export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib添加到 ~/.bashrc, 然后运行source ~/.bashrc使其永久生效\n\n### Ubuntu18.04 apt-get卸载软件步骤\n> $ whereis curl\n>   curl: /usr/bin/curl /usr/local/curl\n> $ apt-get remove ***\n> $ apt-get autoremove\n> $ apt-get autoclean(或者clean)\n\n### Ubuntu18.04 添加镜像源\n> $ vim /etc/apt/sources.list.d/kubernetes.list\n>   deb https://apt.kubernetes.io/ kubernetes-xenial main\n\n### Modify hostname\n> $ hostnamectl set-hostname $HOSTNAME\n> $ reboot\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n一: 查询安装路径\n1. dpkg -L 软件名\n例如：dpkg -L gedit  \n或者\n2. whereis 软件名\n例如：whereis gedit\n\n二: 查询版本\n1. aptitude show 软件名\n2. dpkg -l 软件名\n例如：dpkg -l gedit \n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n# cpupower\n> $ apt install linux-tools-common\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n> $ yum install epel-release\n> $ yum install cmake\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/linux/U盘安装OS_Ubuntu_18.04.md","raw":"---\ntitle: U盘安装OS_Ubuntu_18.04\ntags: \ncategories:\n- linux\n---\n\n### 1. 安装启动盘(U 盘)\n> $ fdisk -l\n> $ umount /dev/sdb1\n> $ mkfs.vfat /dev/sdb -I\n> $ sudo dd if=~/Downloads/ubuntu-16.04-desktop-amd64.iso of=/dev/sdb status=progress\n\n### 2. 开启root访问权限\n> $ sudo passwd root\n> 输入user用户密码，再设置root密码，下次就可以$ su root 获取root权限了\n\n### Add new user\n> $ adduser $USERNAME\n> $ passwd $PASSWD\n\n### 3. 设置网络\n> * 点击屏幕右上角向下三角\n>  + Wired Connected -> Wired Settings -> Network Proxy -> Manual -> HTTP Proxy等输入child-prc.intel.com, port输入913\n>  + 到此可以试着打开浏览器看能不能上网\n> * vi ~/.bashrc 添加如下内容\n\n\texport http_proxy=http://child-prc.intel.com:913\n\texport https_proxy=$http_proxy\n\texport HTTP_PROXY=$http_proxy\n\texport HTTPS_PROXY=$http_proxy\n\n> $ source ~/.bashrc 使得上面添加的内容生效\n> $ apt-get update\n> $ apt-get upgrade\n> $ apt install net-tools\t\t// 到此可以用ifconfig查看ip\n> $ apt-get install vim\t\t// 可以用vim命令了\n> $ vim ~/.vimrc\t// 如果没有则新建.vimrc文件, 添加如下内容\n```\nset nu\nset tabstop=4\n```\n\n### 4. 安装ssh并开启root远程登录\n> $ apt-get install openssh-server\n> $ vim /etc/ssh/sshd_config\n\n\tPermitRootLogin yes\t\t// 去掉PermitRootLogin前面的\"#\"注释，后面值改为yes, 如果不设置则远程只能登录user用户如ai而不能直接登录root\n\n> $ /etc/init.d/ssh start\t\t// 启动SSH服务\n> $ ps -e | grep sshd\t\t\t// 查看SSH是否启动成功\n> $ /etc/init.d/ssh stop\t\t// 关闭SSH服务, 如果先开启服务再设置PermitRootLogin为yes则需要关掉ssh服务再启动ssh服务使其修改生效\n\n### 5. 安装build-essential等必要的编译配置运行程序工具如gcc等\n> $ apt install build-essential\t// 该命令将安装一堆新包，包括gcc，g ++和make。\n> $ gcc --version\t\t// gcc -v\n\n### 安装curl，会安装后运行可能出现的问题\n> * 安装:\n>    $ apt-get update\n>    $ apt-get upgrade\n>    $ apt-get install curl\n>    $ curl --version\n> * 提前设置好系统的proxy如:\n>    export http_proxy=child-prc.intel.com:913\n>    export https_proxy=child-prc.intel.com:913 // https的proxy与上面的http的要一样\n\n> * 运行curl可能出现的问题:\n>\tcurl: error while loading shared libraries: libcurl.so.4: cannot open shared object file: No such file or directo\n>   $ find -name \"libcurl.so.4\" /\n>   查看得到库文件在/usr/local/lib/libcurl.so.4\n>   解决方法一: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib\t//当前终端生效\n>   解决方法二: 把export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib添加到 ~/.bashrc, 然后运行source ~/.bashrc使其永久生效\n\n### Ubuntu18.04 apt-get卸载软件步骤\n> $ whereis curl\n>   curl: /usr/bin/curl /usr/local/curl\n> $ apt-get remove ***\n> $ apt-get autoremove\n> $ apt-get autoclean(或者clean)\n\n### Ubuntu18.04 添加镜像源\n> $ vim /etc/apt/sources.list.d/kubernetes.list\n>   deb https://apt.kubernetes.io/ kubernetes-xenial main\n\n### Modify hostname\n> $ hostnamectl set-hostname $HOSTNAME\n> $ reboot\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n一: 查询安装路径\n1. dpkg -L 软件名\n例如：dpkg -L gedit  \n或者\n2. whereis 软件名\n例如：whereis gedit\n\n二: 查询版本\n1. aptitude show 软件名\n2. dpkg -l 软件名\n例如：dpkg -l gedit \n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n# cpupower\n> $ apt install linux-tools-common\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n> $ yum install epel-release\n> $ yum install cmake\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n\n\n\n\n\n\n\n","slug":"linux/U盘安装OS_Ubuntu_18.04","published":1,"date":"2020-08-12T16:05:46.500Z","updated":"2020-04-20T15:32:07.328Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hme4001ohohxgk8b1c9r","content":"<h3 id=\"1-安装启动盘-U-盘\"><a href=\"#1-安装启动盘-U-盘\" class=\"headerlink\" title=\"1. 安装启动盘(U 盘)\"></a>1. 安装启动盘(U 盘)</h3><blockquote>\n<p>$ fdisk -l<br>$ umount /dev/sdb1<br>$ mkfs.vfat /dev/sdb -I<br>$ sudo dd if=~/Downloads/ubuntu-16.04-desktop-amd64.iso of=/dev/sdb status=progress</p>\n</blockquote>\n<h3 id=\"2-开启root访问权限\"><a href=\"#2-开启root访问权限\" class=\"headerlink\" title=\"2. 开启root访问权限\"></a>2. 开启root访问权限</h3><blockquote>\n<p>$ sudo passwd root<br>输入user用户密码，再设置root密码，下次就可以$ su root 获取root权限了</p>\n</blockquote>\n<h3 id=\"Add-new-user\"><a href=\"#Add-new-user\" class=\"headerlink\" title=\"Add new user\"></a>Add new user</h3><blockquote>\n<p>$ adduser $USERNAME<br>$ passwd $PASSWD</p>\n</blockquote>\n<h3 id=\"3-设置网络\"><a href=\"#3-设置网络\" class=\"headerlink\" title=\"3. 设置网络\"></a>3. 设置网络</h3><blockquote>\n<ul>\n<li>点击屏幕右上角向下三角<ul>\n<li>Wired Connected -&gt; Wired Settings -&gt; Network Proxy -&gt; Manual -&gt; HTTP Proxy等输入child-prc.intel.com, port输入913</li>\n<li>到此可以试着打开浏览器看能不能上网</li>\n</ul>\n</li>\n<li>vi ~/.bashrc 添加如下内容</li>\n</ul>\n</blockquote>\n<pre><code>export http_proxy=http://child-prc.intel.com:913\nexport https_proxy=$http_proxy\nexport HTTP_PROXY=$http_proxy\nexport HTTPS_PROXY=$http_proxy</code></pre><blockquote>\n<p>$ source ~/.bashrc 使得上面添加的内容生效<br>$ apt-get update<br>$ apt-get upgrade<br>$ apt install net-tools        // 到此可以用ifconfig查看ip<br>$ apt-get install vim        // 可以用vim命令了<br>$ vim ~/.vimrc    // 如果没有则新建.vimrc文件, 添加如下内容</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set nu</span><br><span class=\"line\">set tabstop&#x3D;4</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"4-安装ssh并开启root远程登录\"><a href=\"#4-安装ssh并开启root远程登录\" class=\"headerlink\" title=\"4. 安装ssh并开启root远程登录\"></a>4. 安装ssh并开启root远程登录</h3><blockquote>\n<p>$ apt-get install openssh-server<br>$ vim /etc/ssh/sshd_config</p>\n</blockquote>\n<pre><code>PermitRootLogin yes        // 去掉PermitRootLogin前面的&quot;#&quot;注释，后面值改为yes, 如果不设置则远程只能登录user用户如ai而不能直接登录root</code></pre><blockquote>\n<p>$ /etc/init.d/ssh start        // 启动SSH服务<br>$ ps -e | grep sshd            // 查看SSH是否启动成功<br>$ /etc/init.d/ssh stop        // 关闭SSH服务, 如果先开启服务再设置PermitRootLogin为yes则需要关掉ssh服务再启动ssh服务使其修改生效</p>\n</blockquote>\n<h3 id=\"5-安装build-essential等必要的编译配置运行程序工具如gcc等\"><a href=\"#5-安装build-essential等必要的编译配置运行程序工具如gcc等\" class=\"headerlink\" title=\"5. 安装build-essential等必要的编译配置运行程序工具如gcc等\"></a>5. 安装build-essential等必要的编译配置运行程序工具如gcc等</h3><blockquote>\n<p>$ apt install build-essential    // 该命令将安装一堆新包，包括gcc，g ++和make。<br>$ gcc –version        // gcc -v</p>\n</blockquote>\n<h3 id=\"安装curl，会安装后运行可能出现的问题\"><a href=\"#安装curl，会安装后运行可能出现的问题\" class=\"headerlink\" title=\"安装curl，会安装后运行可能出现的问题\"></a>安装curl，会安装后运行可能出现的问题</h3><blockquote>\n<ul>\n<li>安装:<br> $ apt-get update<br> $ apt-get upgrade<br> $ apt-get install curl<br> $ curl –version</li>\n<li>提前设置好系统的proxy如:<br> export http_proxy=child-prc.intel.com:913<br> export https_proxy=child-prc.intel.com:913 // https的proxy与上面的http的要一样</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>运行curl可能出现的问题:<br> curl: error while loading shared libraries: libcurl.so.4: cannot open shared object file: No such file or directo<br>$ find -name “libcurl.so.4” /<br>查看得到库文件在/usr/local/lib/libcurl.so.4<br>解决方法一: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib    //当前终端生效<br>解决方法二: 把export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib添加到 ~/.bashrc, 然后运行source ~/.bashrc使其永久生效</li>\n</ul>\n</blockquote>\n<h3 id=\"Ubuntu18-04-apt-get卸载软件步骤\"><a href=\"#Ubuntu18-04-apt-get卸载软件步骤\" class=\"headerlink\" title=\"Ubuntu18.04 apt-get卸载软件步骤\"></a>Ubuntu18.04 apt-get卸载软件步骤</h3><blockquote>\n<p>$ whereis curl<br>  curl: /usr/bin/curl /usr/local/curl<br>$ apt-get remove ***<br>$ apt-get autoremove<br>$ apt-get autoclean(或者clean)</p>\n</blockquote>\n<h3 id=\"Ubuntu18-04-添加镜像源\"><a href=\"#Ubuntu18-04-添加镜像源\" class=\"headerlink\" title=\"Ubuntu18.04 添加镜像源\"></a>Ubuntu18.04 添加镜像源</h3><blockquote>\n<p>$ vim /etc/apt/sources.list.d/kubernetes.list<br>  deb <a href=\"https://apt.kubernetes.io/\" target=\"_blank\" rel=\"noopener\">https://apt.kubernetes.io/</a> kubernetes-xenial main</p>\n</blockquote>\n<h3 id=\"Modify-hostname\"><a href=\"#Modify-hostname\" class=\"headerlink\" title=\"Modify hostname\"></a>Modify hostname</h3><blockquote>\n<p>$ hostnamectl set-hostname $HOSTNAME<br>$ reboot</p>\n</blockquote>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※<br>一: 查询安装路径</p>\n<ol>\n<li>dpkg -L 软件名<br>例如：dpkg -L gedit<br>或者</li>\n<li>whereis 软件名<br>例如：whereis gedit</li>\n</ol>\n<p>二: 查询版本</p>\n<ol>\n<li>aptitude show 软件名</li>\n<li>dpkg -l 软件名<br>例如：dpkg -l gedit </li>\n</ol>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<h1 id=\"cpupower\"><a href=\"#cpupower\" class=\"headerlink\" title=\"cpupower\"></a>cpupower</h1><blockquote>\n<p>$ apt install linux-tools-common</p>\n</blockquote>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<blockquote>\n<p>$ yum install epel-release<br>$ yum install cmake</p>\n</blockquote>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"1-安装启动盘-U-盘\"><a href=\"#1-安装启动盘-U-盘\" class=\"headerlink\" title=\"1. 安装启动盘(U 盘)\"></a>1. 安装启动盘(U 盘)</h3><blockquote>\n<p>$ fdisk -l<br>$ umount /dev/sdb1<br>$ mkfs.vfat /dev/sdb -I<br>$ sudo dd if=~/Downloads/ubuntu-16.04-desktop-amd64.iso of=/dev/sdb status=progress</p>\n</blockquote>\n<h3 id=\"2-开启root访问权限\"><a href=\"#2-开启root访问权限\" class=\"headerlink\" title=\"2. 开启root访问权限\"></a>2. 开启root访问权限</h3><blockquote>\n<p>$ sudo passwd root<br>输入user用户密码，再设置root密码，下次就可以$ su root 获取root权限了</p>\n</blockquote>\n<h3 id=\"Add-new-user\"><a href=\"#Add-new-user\" class=\"headerlink\" title=\"Add new user\"></a>Add new user</h3><blockquote>\n<p>$ adduser $USERNAME<br>$ passwd $PASSWD</p>\n</blockquote>\n<h3 id=\"3-设置网络\"><a href=\"#3-设置网络\" class=\"headerlink\" title=\"3. 设置网络\"></a>3. 设置网络</h3><blockquote>\n<ul>\n<li>点击屏幕右上角向下三角<ul>\n<li>Wired Connected -&gt; Wired Settings -&gt; Network Proxy -&gt; Manual -&gt; HTTP Proxy等输入child-prc.intel.com, port输入913</li>\n<li>到此可以试着打开浏览器看能不能上网</li>\n</ul>\n</li>\n<li>vi ~/.bashrc 添加如下内容</li>\n</ul>\n</blockquote>\n<pre><code>export http_proxy=http://child-prc.intel.com:913\nexport https_proxy=$http_proxy\nexport HTTP_PROXY=$http_proxy\nexport HTTPS_PROXY=$http_proxy</code></pre><blockquote>\n<p>$ source ~/.bashrc 使得上面添加的内容生效<br>$ apt-get update<br>$ apt-get upgrade<br>$ apt install net-tools        // 到此可以用ifconfig查看ip<br>$ apt-get install vim        // 可以用vim命令了<br>$ vim ~/.vimrc    // 如果没有则新建.vimrc文件, 添加如下内容</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set nu</span><br><span class=\"line\">set tabstop&#x3D;4</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"4-安装ssh并开启root远程登录\"><a href=\"#4-安装ssh并开启root远程登录\" class=\"headerlink\" title=\"4. 安装ssh并开启root远程登录\"></a>4. 安装ssh并开启root远程登录</h3><blockquote>\n<p>$ apt-get install openssh-server<br>$ vim /etc/ssh/sshd_config</p>\n</blockquote>\n<pre><code>PermitRootLogin yes        // 去掉PermitRootLogin前面的&quot;#&quot;注释，后面值改为yes, 如果不设置则远程只能登录user用户如ai而不能直接登录root</code></pre><blockquote>\n<p>$ /etc/init.d/ssh start        // 启动SSH服务<br>$ ps -e | grep sshd            // 查看SSH是否启动成功<br>$ /etc/init.d/ssh stop        // 关闭SSH服务, 如果先开启服务再设置PermitRootLogin为yes则需要关掉ssh服务再启动ssh服务使其修改生效</p>\n</blockquote>\n<h3 id=\"5-安装build-essential等必要的编译配置运行程序工具如gcc等\"><a href=\"#5-安装build-essential等必要的编译配置运行程序工具如gcc等\" class=\"headerlink\" title=\"5. 安装build-essential等必要的编译配置运行程序工具如gcc等\"></a>5. 安装build-essential等必要的编译配置运行程序工具如gcc等</h3><blockquote>\n<p>$ apt install build-essential    // 该命令将安装一堆新包，包括gcc，g ++和make。<br>$ gcc –version        // gcc -v</p>\n</blockquote>\n<h3 id=\"安装curl，会安装后运行可能出现的问题\"><a href=\"#安装curl，会安装后运行可能出现的问题\" class=\"headerlink\" title=\"安装curl，会安装后运行可能出现的问题\"></a>安装curl，会安装后运行可能出现的问题</h3><blockquote>\n<ul>\n<li>安装:<br> $ apt-get update<br> $ apt-get upgrade<br> $ apt-get install curl<br> $ curl –version</li>\n<li>提前设置好系统的proxy如:<br> export http_proxy=child-prc.intel.com:913<br> export https_proxy=child-prc.intel.com:913 // https的proxy与上面的http的要一样</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>运行curl可能出现的问题:<br> curl: error while loading shared libraries: libcurl.so.4: cannot open shared object file: No such file or directo<br>$ find -name “libcurl.so.4” /<br>查看得到库文件在/usr/local/lib/libcurl.so.4<br>解决方法一: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib    //当前终端生效<br>解决方法二: 把export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib添加到 ~/.bashrc, 然后运行source ~/.bashrc使其永久生效</li>\n</ul>\n</blockquote>\n<h3 id=\"Ubuntu18-04-apt-get卸载软件步骤\"><a href=\"#Ubuntu18-04-apt-get卸载软件步骤\" class=\"headerlink\" title=\"Ubuntu18.04 apt-get卸载软件步骤\"></a>Ubuntu18.04 apt-get卸载软件步骤</h3><blockquote>\n<p>$ whereis curl<br>  curl: /usr/bin/curl /usr/local/curl<br>$ apt-get remove ***<br>$ apt-get autoremove<br>$ apt-get autoclean(或者clean)</p>\n</blockquote>\n<h3 id=\"Ubuntu18-04-添加镜像源\"><a href=\"#Ubuntu18-04-添加镜像源\" class=\"headerlink\" title=\"Ubuntu18.04 添加镜像源\"></a>Ubuntu18.04 添加镜像源</h3><blockquote>\n<p>$ vim /etc/apt/sources.list.d/kubernetes.list<br>  deb <a href=\"https://apt.kubernetes.io/\" target=\"_blank\" rel=\"noopener\">https://apt.kubernetes.io/</a> kubernetes-xenial main</p>\n</blockquote>\n<h3 id=\"Modify-hostname\"><a href=\"#Modify-hostname\" class=\"headerlink\" title=\"Modify hostname\"></a>Modify hostname</h3><blockquote>\n<p>$ hostnamectl set-hostname $HOSTNAME<br>$ reboot</p>\n</blockquote>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※<br>一: 查询安装路径</p>\n<ol>\n<li>dpkg -L 软件名<br>例如：dpkg -L gedit<br>或者</li>\n<li>whereis 软件名<br>例如：whereis gedit</li>\n</ol>\n<p>二: 查询版本</p>\n<ol>\n<li>aptitude show 软件名</li>\n<li>dpkg -l 软件名<br>例如：dpkg -l gedit </li>\n</ol>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<h1 id=\"cpupower\"><a href=\"#cpupower\" class=\"headerlink\" title=\"cpupower\"></a>cpupower</h1><blockquote>\n<p>$ apt install linux-tools-common</p>\n</blockquote>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<blockquote>\n<p>$ yum install epel-release<br>$ yum install cmake</p>\n</blockquote>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n"},{"title":"cmake","_content":"\n参考链接:https://www.jianshu.com/p/aaa19816f7ad\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n1. add_library\n该指令的主要作用就是将指定的源文件生成链接文件，然后添加到工程中去。该指令常用的语法如下：\n```\nadd_library(<name> [STATIC | SHARED | MODULE]\n            [EXCLUDE_FROM_ALL]\n            [source1] [source2] [...])\n```\n<name>表示库文件的名字，该库文件会根据命令里列出的源文件来创建。\nSTATIC、SHARED和MODULE的作用是指定生成的库文件的类型。\nSTATIC库是目标文件的归档文件，在链接其它目标的时候使用。\nSHARED库会被动态链接（动态链接库），在运行时会被加载。\nMODULE库是一种不会被链接到其它目标中的插件，但是可能会在运行时使用dlopen-系列的函数。\n默认状态下，库文件将会在于源文件目录树的构建目录树的位置被创建，该命令也会在这里被调用。\n而语法中的source1 source2分别表示各个源文件。\n使用案例\n```\nadd_subdirectory(sub_dir)\nfile(GLOB HDRS \"*.h\")\nfile(GLOB SRCS \"*.c\")\nset(TARGET_NAME pnp_module)\nadd_library(${TARGET_NAME} SHARED ${HDRS} ${SRCS})\ntarget_link_libraries(${TARGET_NAME} PRIVATE\n        ${CMAKE_THREAD_LIBS_INIT}\t\t\t\t// 库引用了需要使用-lpthread的.c源码文件，需要加上这句\n        pnp_utils_static\n        m)\n\n// CMAKE_CURRENT_SOURCE_DIR：这是当前处理的CMakeLists.txt所在的目录。当前正在处理的源目录的路径。这是当前正由cmake处理的源目录的完整路径。\n// CMAKE_CURRENT_LIST_DIR：这是当前正在处理的listfile的目录。当前正在处理的列表文件的完整目录。\n// 在处理sub_dir/CMakeLists.txt时，CMAKE_CURRENT_LIST_DIR将引用项目/ src，而CMAKE_CURRENT_SOURCE_DIR仍指向外部目录项目。\ntarget_include_directories(${TARGET_NAME} PUBLIC ${CMAKE_CURRENT_LIST_DIR})\n```\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n2. target_link_libraries\n该指令的作用为将目标文件与库文件进行链接。该指令的语法如下：\n```\ntarget_link_libraries(<target> [item1] [item2] [...]\n                      [[debug|optimized|general] <item>] ...)\n```\n<target>是指通过add_executable()和add_library()指令生成已经创建的目标文件。\n[item]表示库文件没有后缀的名字。\n默认情况下，库依赖项是传递的。当这个目标链接到另一个目标时，链接到这个目标的库也会出现在另一个目标的连接线上。\n这个传递的接口存储在interface_link_libraries的目标属性中，可以通过设置该属性直接重写传递接口。\n\n<dl>\n<dt>cmake target_link_libraries() 中<PUBLIC|PRIVATE|INTERFACE> 的区别<dt>\n\t<dd>如果目标的头文件中包含了依赖的头文件(源文件间接包含)，那么这里就是PUBLIC</dd>\n\t<dd>如果目标仅源文件中包含了依赖的头文件，那么这里就是PRIVATE</dd>\n\t<dd>如果目标的头文件包含依赖，但源文件未包含，那么这里就是INTERFACE</dd>\n</dl>\n\n使用案例：\n```\n案例1：\nTARGET_LINK_LIBRARIES(myProject hello)\t\t\t// 连接libhello.so库\nTARGET_LINK_LIBRARIES(myProject libhello.a)\nTARGET_LINK_LIBRARIES(myProject libhello.so)\n// 库引用了需要使用-lpthread的.c源码文件，需要加上${CMAKE_THREAD_LIBS_INIT}\ntarget_link_libraries (${PROJECT_NAME} ${CMAKE_THREAD_LIBS_INIT})\n\n案例2：\nadd_executable(myProject main.cpp)\ntarget_link_libraries(myProject eng mx)     \n#equals to below \ntarget_link_libraries(myProject -leng -lmx) `\ntarget_link_libraries(myProject libeng.so libmx.so)`\n```\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n3. target_include_directories\n为add_executable() 或者add_library() 中定义的输出目标指定编译选项\nInclude的头文件的查找目录，也就是Gcc的[-Idir...]选项\n```\ntarget_include_directories(<target> [SYSTEM] [BEFORE]\n\t\t\t\t\t\t\t<INTERFACE|PUBLIC|PRIVATE> [items1...]\n\t\t\t\t\t\t\t[<INTERFACE|PUBLIC|PRIVATE> [items2...]\n\t\t\t\t\t\t\t...])\n```\n使用案例:\n```\n# gcc头文件查找目录，相当于-I选项，e.g -I/foo/bar\n#CMAKE_SOURCE_DIR是cmake内置变量表示当前项目根目录\ntarget_include_directories(test_elf\n    PRIVATE\n    ${CMAKE_SOURCE_DIR}\n    ${CMAKE_SOURCE_DIR}/common\n    ${CMAKE_SOURCE_DIR}/syscalls\n)\n# 其他编译选项定义，e.g -fPIC\ntarget_compile_options(test_elf\n    PRIVATE\n    -std=c99 \n    -Wall \n    -Wextra \n    -Werror\n)\n```\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※","source":"_posts/linux/cmake.md","raw":"---\ntitle: cmake\ncategories:\n- linux\n---\n\n参考链接:https://www.jianshu.com/p/aaa19816f7ad\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n1. add_library\n该指令的主要作用就是将指定的源文件生成链接文件，然后添加到工程中去。该指令常用的语法如下：\n```\nadd_library(<name> [STATIC | SHARED | MODULE]\n            [EXCLUDE_FROM_ALL]\n            [source1] [source2] [...])\n```\n<name>表示库文件的名字，该库文件会根据命令里列出的源文件来创建。\nSTATIC、SHARED和MODULE的作用是指定生成的库文件的类型。\nSTATIC库是目标文件的归档文件，在链接其它目标的时候使用。\nSHARED库会被动态链接（动态链接库），在运行时会被加载。\nMODULE库是一种不会被链接到其它目标中的插件，但是可能会在运行时使用dlopen-系列的函数。\n默认状态下，库文件将会在于源文件目录树的构建目录树的位置被创建，该命令也会在这里被调用。\n而语法中的source1 source2分别表示各个源文件。\n使用案例\n```\nadd_subdirectory(sub_dir)\nfile(GLOB HDRS \"*.h\")\nfile(GLOB SRCS \"*.c\")\nset(TARGET_NAME pnp_module)\nadd_library(${TARGET_NAME} SHARED ${HDRS} ${SRCS})\ntarget_link_libraries(${TARGET_NAME} PRIVATE\n        ${CMAKE_THREAD_LIBS_INIT}\t\t\t\t// 库引用了需要使用-lpthread的.c源码文件，需要加上这句\n        pnp_utils_static\n        m)\n\n// CMAKE_CURRENT_SOURCE_DIR：这是当前处理的CMakeLists.txt所在的目录。当前正在处理的源目录的路径。这是当前正由cmake处理的源目录的完整路径。\n// CMAKE_CURRENT_LIST_DIR：这是当前正在处理的listfile的目录。当前正在处理的列表文件的完整目录。\n// 在处理sub_dir/CMakeLists.txt时，CMAKE_CURRENT_LIST_DIR将引用项目/ src，而CMAKE_CURRENT_SOURCE_DIR仍指向外部目录项目。\ntarget_include_directories(${TARGET_NAME} PUBLIC ${CMAKE_CURRENT_LIST_DIR})\n```\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n2. target_link_libraries\n该指令的作用为将目标文件与库文件进行链接。该指令的语法如下：\n```\ntarget_link_libraries(<target> [item1] [item2] [...]\n                      [[debug|optimized|general] <item>] ...)\n```\n<target>是指通过add_executable()和add_library()指令生成已经创建的目标文件。\n[item]表示库文件没有后缀的名字。\n默认情况下，库依赖项是传递的。当这个目标链接到另一个目标时，链接到这个目标的库也会出现在另一个目标的连接线上。\n这个传递的接口存储在interface_link_libraries的目标属性中，可以通过设置该属性直接重写传递接口。\n\n<dl>\n<dt>cmake target_link_libraries() 中<PUBLIC|PRIVATE|INTERFACE> 的区别<dt>\n\t<dd>如果目标的头文件中包含了依赖的头文件(源文件间接包含)，那么这里就是PUBLIC</dd>\n\t<dd>如果目标仅源文件中包含了依赖的头文件，那么这里就是PRIVATE</dd>\n\t<dd>如果目标的头文件包含依赖，但源文件未包含，那么这里就是INTERFACE</dd>\n</dl>\n\n使用案例：\n```\n案例1：\nTARGET_LINK_LIBRARIES(myProject hello)\t\t\t// 连接libhello.so库\nTARGET_LINK_LIBRARIES(myProject libhello.a)\nTARGET_LINK_LIBRARIES(myProject libhello.so)\n// 库引用了需要使用-lpthread的.c源码文件，需要加上${CMAKE_THREAD_LIBS_INIT}\ntarget_link_libraries (${PROJECT_NAME} ${CMAKE_THREAD_LIBS_INIT})\n\n案例2：\nadd_executable(myProject main.cpp)\ntarget_link_libraries(myProject eng mx)     \n#equals to below \ntarget_link_libraries(myProject -leng -lmx) `\ntarget_link_libraries(myProject libeng.so libmx.so)`\n```\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n3. target_include_directories\n为add_executable() 或者add_library() 中定义的输出目标指定编译选项\nInclude的头文件的查找目录，也就是Gcc的[-Idir...]选项\n```\ntarget_include_directories(<target> [SYSTEM] [BEFORE]\n\t\t\t\t\t\t\t<INTERFACE|PUBLIC|PRIVATE> [items1...]\n\t\t\t\t\t\t\t[<INTERFACE|PUBLIC|PRIVATE> [items2...]\n\t\t\t\t\t\t\t...])\n```\n使用案例:\n```\n# gcc头文件查找目录，相当于-I选项，e.g -I/foo/bar\n#CMAKE_SOURCE_DIR是cmake内置变量表示当前项目根目录\ntarget_include_directories(test_elf\n    PRIVATE\n    ${CMAKE_SOURCE_DIR}\n    ${CMAKE_SOURCE_DIR}/common\n    ${CMAKE_SOURCE_DIR}/syscalls\n)\n# 其他编译选项定义，e.g -fPIC\ntarget_compile_options(test_elf\n    PRIVATE\n    -std=c99 \n    -Wall \n    -Wextra \n    -Werror\n)\n```\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※","slug":"linux/cmake","published":1,"date":"2020-08-12T16:05:46.100Z","updated":"2020-03-16T11:22:30.487Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hme9001rhohx8hkzahs1","content":"<p>参考链接:<a href=\"https://www.jianshu.com/p/aaa19816f7ad\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/aaa19816f7ad</a><br>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<ol>\n<li>add_library<br>该指令的主要作用就是将指定的源文件生成链接文件，然后添加到工程中去。该指令常用的语法如下：<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_library(&lt;name&gt; [STATIC | SHARED | MODULE]</span><br><span class=\"line\">            [EXCLUDE_FROM_ALL]</span><br><span class=\"line\">            [source1] [source2] [...])</span><br></pre></td></tr></table></figure>\n<name>表示库文件的名字，该库文件会根据命令里列出的源文件来创建。<br>STATIC、SHARED和MODULE的作用是指定生成的库文件的类型。<br>STATIC库是目标文件的归档文件，在链接其它目标的时候使用。<br>SHARED库会被动态链接（动态链接库），在运行时会被加载。<br>MODULE库是一种不会被链接到其它目标中的插件，但是可能会在运行时使用dlopen-系列的函数。<br>默认状态下，库文件将会在于源文件目录树的构建目录树的位置被创建，该命令也会在这里被调用。<br>而语法中的source1 source2分别表示各个源文件。<br>使用案例<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_subdirectory(sub_dir)</span><br><span class=\"line\">file(GLOB HDRS &quot;*.h&quot;)</span><br><span class=\"line\">file(GLOB SRCS &quot;*.c&quot;)</span><br><span class=\"line\">set(TARGET_NAME pnp_module)</span><br><span class=\"line\">add_library($&#123;TARGET_NAME&#125; SHARED $&#123;HDRS&#125; $&#123;SRCS&#125;)</span><br><span class=\"line\">target_link_libraries($&#123;TARGET_NAME&#125; PRIVATE</span><br><span class=\"line\">        $&#123;CMAKE_THREAD_LIBS_INIT&#125;\t\t\t\t&#x2F;&#x2F; 库引用了需要使用-lpthread的.c源码文件，需要加上这句</span><br><span class=\"line\">        pnp_utils_static</span><br><span class=\"line\">        m)</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;&#x2F; CMAKE_CURRENT_SOURCE_DIR：这是当前处理的CMakeLists.txt所在的目录。当前正在处理的源目录的路径。这是当前正由cmake处理的源目录的完整路径。</span><br><span class=\"line\">&#x2F;&#x2F; CMAKE_CURRENT_LIST_DIR：这是当前正在处理的listfile的目录。当前正在处理的列表文件的完整目录。</span><br><span class=\"line\">&#x2F;&#x2F; 在处理sub_dir&#x2F;CMakeLists.txt时，CMAKE_CURRENT_LIST_DIR将引用项目&#x2F; src，而CMAKE_CURRENT_SOURCE_DIR仍指向外部目录项目。</span><br><span class=\"line\">target_include_directories($&#123;TARGET_NAME&#125; PUBLIC $&#123;CMAKE_CURRENT_LIST_DIR&#125;)</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※<br>2. target_link_libraries<br>该指令的作用为将目标文件与库文件进行链接。该指令的语法如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_link_libraries(&lt;target&gt; [item1] [item2] [...]</span><br><span class=\"line\">                      [[debug|optimized|general] &lt;item&gt;] ...)</span><br></pre></td></tr></table></figure>\n<p><target>是指通过add_executable()和add_library()指令生成已经创建的目标文件。<br>[item]表示库文件没有后缀的名字。<br>默认情况下，库依赖项是传递的。当这个目标链接到另一个目标时，链接到这个目标的库也会出现在另一个目标的连接线上。<br>这个传递的接口存储在interface_link_libraries的目标属性中，可以通过设置该属性直接重写传递接口。</p>\n<dl>\n<dt>cmake target_link_libraries() 中<PUBLIC|PRIVATE|INTERFACE> 的区别<dt>\n    <dd>如果目标的头文件中包含了依赖的头文件(源文件间接包含)，那么这里就是PUBLIC</dd>\n    <dd>如果目标仅源文件中包含了依赖的头文件，那么这里就是PRIVATE</dd>\n    <dd>如果目标的头文件包含依赖，但源文件未包含，那么这里就是INTERFACE</dd>\n</dl>\n\n<p>使用案例：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">案例1：</span><br><span class=\"line\">TARGET_LINK_LIBRARIES(myProject hello)\t\t\t&#x2F;&#x2F; 连接libhello.so库</span><br><span class=\"line\">TARGET_LINK_LIBRARIES(myProject libhello.a)</span><br><span class=\"line\">TARGET_LINK_LIBRARIES(myProject libhello.so)</span><br><span class=\"line\">&#x2F;&#x2F; 库引用了需要使用-lpthread的.c源码文件，需要加上$&#123;CMAKE_THREAD_LIBS_INIT&#125;</span><br><span class=\"line\">target_link_libraries ($&#123;PROJECT_NAME&#125; $&#123;CMAKE_THREAD_LIBS_INIT&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">案例2：</span><br><span class=\"line\">add_executable(myProject main.cpp)</span><br><span class=\"line\">target_link_libraries(myProject eng mx)     </span><br><span class=\"line\">#equals to below </span><br><span class=\"line\">target_link_libraries(myProject -leng -lmx) &#96;</span><br><span class=\"line\">target_link_libraries(myProject libeng.so libmx.so)&#96;</span><br></pre></td></tr></table></figure>\n\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※<br>3. target_include_directories<br>为add_executable() 或者add_library() 中定义的输出目标指定编译选项<br>Include的头文件的查找目录，也就是Gcc的[-Idir…]选项</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_include_directories(&lt;target&gt; [SYSTEM] [BEFORE]</span><br><span class=\"line\">\t\t\t\t\t\t\t&lt;INTERFACE|PUBLIC|PRIVATE&gt; [items1...]</span><br><span class=\"line\">\t\t\t\t\t\t\t[&lt;INTERFACE|PUBLIC|PRIVATE&gt; [items2...]</span><br><span class=\"line\">\t\t\t\t\t\t\t...])</span><br></pre></td></tr></table></figure>\n<p>使用案例:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># gcc头文件查找目录，相当于-I选项，e.g -I&#x2F;foo&#x2F;bar</span><br><span class=\"line\">#CMAKE_SOURCE_DIR是cmake内置变量表示当前项目根目录</span><br><span class=\"line\">target_include_directories(test_elf</span><br><span class=\"line\">    PRIVATE</span><br><span class=\"line\">    $&#123;CMAKE_SOURCE_DIR&#125;</span><br><span class=\"line\">    $&#123;CMAKE_SOURCE_DIR&#125;&#x2F;common</span><br><span class=\"line\">    $&#123;CMAKE_SOURCE_DIR&#125;&#x2F;syscalls</span><br><span class=\"line\">)</span><br><span class=\"line\"># 其他编译选项定义，e.g -fPIC</span><br><span class=\"line\">target_compile_options(test_elf</span><br><span class=\"line\">    PRIVATE</span><br><span class=\"line\">    -std&#x3D;c99 </span><br><span class=\"line\">    -Wall </span><br><span class=\"line\">    -Wextra </span><br><span class=\"line\">    -Werror</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n","site":{"data":{}},"excerpt":"","more":"<p>参考链接:<a href=\"https://www.jianshu.com/p/aaa19816f7ad\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/aaa19816f7ad</a><br>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<ol>\n<li>add_library<br>该指令的主要作用就是将指定的源文件生成链接文件，然后添加到工程中去。该指令常用的语法如下：<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_library(&lt;name&gt; [STATIC | SHARED | MODULE]</span><br><span class=\"line\">            [EXCLUDE_FROM_ALL]</span><br><span class=\"line\">            [source1] [source2] [...])</span><br></pre></td></tr></table></figure>\n<name>表示库文件的名字，该库文件会根据命令里列出的源文件来创建。<br>STATIC、SHARED和MODULE的作用是指定生成的库文件的类型。<br>STATIC库是目标文件的归档文件，在链接其它目标的时候使用。<br>SHARED库会被动态链接（动态链接库），在运行时会被加载。<br>MODULE库是一种不会被链接到其它目标中的插件，但是可能会在运行时使用dlopen-系列的函数。<br>默认状态下，库文件将会在于源文件目录树的构建目录树的位置被创建，该命令也会在这里被调用。<br>而语法中的source1 source2分别表示各个源文件。<br>使用案例<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_subdirectory(sub_dir)</span><br><span class=\"line\">file(GLOB HDRS &quot;*.h&quot;)</span><br><span class=\"line\">file(GLOB SRCS &quot;*.c&quot;)</span><br><span class=\"line\">set(TARGET_NAME pnp_module)</span><br><span class=\"line\">add_library($&#123;TARGET_NAME&#125; SHARED $&#123;HDRS&#125; $&#123;SRCS&#125;)</span><br><span class=\"line\">target_link_libraries($&#123;TARGET_NAME&#125; PRIVATE</span><br><span class=\"line\">        $&#123;CMAKE_THREAD_LIBS_INIT&#125;\t\t\t\t&#x2F;&#x2F; 库引用了需要使用-lpthread的.c源码文件，需要加上这句</span><br><span class=\"line\">        pnp_utils_static</span><br><span class=\"line\">        m)</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;&#x2F; CMAKE_CURRENT_SOURCE_DIR：这是当前处理的CMakeLists.txt所在的目录。当前正在处理的源目录的路径。这是当前正由cmake处理的源目录的完整路径。</span><br><span class=\"line\">&#x2F;&#x2F; CMAKE_CURRENT_LIST_DIR：这是当前正在处理的listfile的目录。当前正在处理的列表文件的完整目录。</span><br><span class=\"line\">&#x2F;&#x2F; 在处理sub_dir&#x2F;CMakeLists.txt时，CMAKE_CURRENT_LIST_DIR将引用项目&#x2F; src，而CMAKE_CURRENT_SOURCE_DIR仍指向外部目录项目。</span><br><span class=\"line\">target_include_directories($&#123;TARGET_NAME&#125; PUBLIC $&#123;CMAKE_CURRENT_LIST_DIR&#125;)</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※<br>2. target_link_libraries<br>该指令的作用为将目标文件与库文件进行链接。该指令的语法如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_link_libraries(&lt;target&gt; [item1] [item2] [...]</span><br><span class=\"line\">                      [[debug|optimized|general] &lt;item&gt;] ...)</span><br></pre></td></tr></table></figure>\n<p><target>是指通过add_executable()和add_library()指令生成已经创建的目标文件。<br>[item]表示库文件没有后缀的名字。<br>默认情况下，库依赖项是传递的。当这个目标链接到另一个目标时，链接到这个目标的库也会出现在另一个目标的连接线上。<br>这个传递的接口存储在interface_link_libraries的目标属性中，可以通过设置该属性直接重写传递接口。</p>\n<dl>\n<dt>cmake target_link_libraries() 中<PUBLIC|PRIVATE|INTERFACE> 的区别<dt>\n    <dd>如果目标的头文件中包含了依赖的头文件(源文件间接包含)，那么这里就是PUBLIC</dd>\n    <dd>如果目标仅源文件中包含了依赖的头文件，那么这里就是PRIVATE</dd>\n    <dd>如果目标的头文件包含依赖，但源文件未包含，那么这里就是INTERFACE</dd>\n</dl>\n\n<p>使用案例：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">案例1：</span><br><span class=\"line\">TARGET_LINK_LIBRARIES(myProject hello)\t\t\t&#x2F;&#x2F; 连接libhello.so库</span><br><span class=\"line\">TARGET_LINK_LIBRARIES(myProject libhello.a)</span><br><span class=\"line\">TARGET_LINK_LIBRARIES(myProject libhello.so)</span><br><span class=\"line\">&#x2F;&#x2F; 库引用了需要使用-lpthread的.c源码文件，需要加上$&#123;CMAKE_THREAD_LIBS_INIT&#125;</span><br><span class=\"line\">target_link_libraries ($&#123;PROJECT_NAME&#125; $&#123;CMAKE_THREAD_LIBS_INIT&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">案例2：</span><br><span class=\"line\">add_executable(myProject main.cpp)</span><br><span class=\"line\">target_link_libraries(myProject eng mx)     </span><br><span class=\"line\">#equals to below </span><br><span class=\"line\">target_link_libraries(myProject -leng -lmx) &#96;</span><br><span class=\"line\">target_link_libraries(myProject libeng.so libmx.so)&#96;</span><br></pre></td></tr></table></figure>\n\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※<br>3. target_include_directories<br>为add_executable() 或者add_library() 中定义的输出目标指定编译选项<br>Include的头文件的查找目录，也就是Gcc的[-Idir…]选项</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_include_directories(&lt;target&gt; [SYSTEM] [BEFORE]</span><br><span class=\"line\">\t\t\t\t\t\t\t&lt;INTERFACE|PUBLIC|PRIVATE&gt; [items1...]</span><br><span class=\"line\">\t\t\t\t\t\t\t[&lt;INTERFACE|PUBLIC|PRIVATE&gt; [items2...]</span><br><span class=\"line\">\t\t\t\t\t\t\t...])</span><br></pre></td></tr></table></figure>\n<p>使用案例:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># gcc头文件查找目录，相当于-I选项，e.g -I&#x2F;foo&#x2F;bar</span><br><span class=\"line\">#CMAKE_SOURCE_DIR是cmake内置变量表示当前项目根目录</span><br><span class=\"line\">target_include_directories(test_elf</span><br><span class=\"line\">    PRIVATE</span><br><span class=\"line\">    $&#123;CMAKE_SOURCE_DIR&#125;</span><br><span class=\"line\">    $&#123;CMAKE_SOURCE_DIR&#125;&#x2F;common</span><br><span class=\"line\">    $&#123;CMAKE_SOURCE_DIR&#125;&#x2F;syscalls</span><br><span class=\"line\">)</span><br><span class=\"line\"># 其他编译选项定义，e.g -fPIC</span><br><span class=\"line\">target_compile_options(test_elf</span><br><span class=\"line\">    PRIVATE</span><br><span class=\"line\">    -std&#x3D;c99 </span><br><span class=\"line\">    -Wall </span><br><span class=\"line\">    -Wextra </span><br><span class=\"line\">    -Werror</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n"},{"title":"Windows10 mstsc远程登录Centos7.0","_content":"配置iptables防火墙\n    在xrdp使用是3389端口，所以在iptables中也要开放相应的端口，否则无法访问\n 　　iptables -A INPUT -p tcp --dport 3389 -j ACCEPT\n    　　service iptables save\nFrom <https://www.cnblogs.com/Skyar/p/5260368.html> \n\ncentos 安装xrdp远程连接桌面\n1. 安装epel库，否则无法安装xrdp\n    \nyum install epel-release\n2.安装 xrdp\nyum install xrdp\n3. 安装tigervnc-server\nyum install tigervnc-server\n4. 配置xrdp.ini文件\nvim /etc/xrdp/xrdp.ini\n把max_bpp=32 改成24\n5.配置selinux\nchcon -t bin_t /usr/sbin/xrdp\nchcon -t bin_t /usr/sbin/xrdp-sesman\n6.设置xrdp服务，开机自动启动\nsystemctl start xrdp\nsystemctl enable xrdp\n7.打开防火墙\nfirewall-cmd  --permanent --zone=public --add-port=3389/tcp\nfirewall-cmd --reload\n8.查看xrdp是否启动\nsystemctl status xrdp.service\nss -antup|grep xrdp\n9.启动window rdp连接\nFrom <https://www.cnblogs.com/Jesse-Li/p/10284221.html> \n\n\n2 关闭防火墙\nsystemctl stop firewalld.service\n• 1\n设置开机不启动防火墙\nsystemctl disable firewalld.servie\n\n3、关闭SElinux\n1）查看selinux状态\nsestatus \n• 1\n2）临时关闭selinux\nsetenforce 0\n• 1\n永久关闭selinux\nvim /etc/selinux/config\nSELINUX=disabled\n\n查看服务列表状态:\n 1. systemctl list-units --type=service \n 2. systemctl   list-unit-files       列出所有已经安装的  服务  及  状态      （可为人所读,  内容简略、清晰）：\n\n 3. systemctl 可以列出正在运行的服务状态\n\n启动一个服务：\nsystemctl start postfix.service\n\n关闭一个服务：\nsystemctl stop postfix.service\n\n重启一个服务：\nsystemctl restart postfix.service\n\n显示一个服务的状态：\nsystemctl status postfix.service\n\n在开机时启用一个服务：systemctl enable postfix.service\n在开机时禁用一个服务：systemctl disable postfix.service\n\n查看服务是否开机启动：   systemctl is-enabled postfix.service\n\n查看已启动的服务列表：   systemctl list-unit-files | grep enabled\n\n查看启动失败的服务列表：   systemctl --failed\n\nPS：使用命令 systemctl is-enabled postfix.service 得到的值可以是enable、disable或static，这里的 static 它是指对应的 Unit 文件中没有定义[Install]区域，因此无法配置为开机启动服务。\n\n 说明：启用服务就是在当前“runlevel”的配置文件目录   /etc/systemd/system/multi-user.target.wants  里，建立  /usr/lib/systemd/system   里面对应服务配置文件的软链接；\n禁用服务就是删除此软链接，添加服务就是添加软连接。\n\nFrom <https://www.cnblogs.com/devilmaycry812839668/p/8481760.html> \n","source":"_posts/linux/Windows10mstsc远程登录Centos7.0.md","raw":"---\ntitle: Windows10 mstsc远程登录Centos7.0\ntags: \ncategories: \n- linux\n---\n配置iptables防火墙\n    在xrdp使用是3389端口，所以在iptables中也要开放相应的端口，否则无法访问\n 　　iptables -A INPUT -p tcp --dport 3389 -j ACCEPT\n    　　service iptables save\nFrom <https://www.cnblogs.com/Skyar/p/5260368.html> \n\ncentos 安装xrdp远程连接桌面\n1. 安装epel库，否则无法安装xrdp\n    \nyum install epel-release\n2.安装 xrdp\nyum install xrdp\n3. 安装tigervnc-server\nyum install tigervnc-server\n4. 配置xrdp.ini文件\nvim /etc/xrdp/xrdp.ini\n把max_bpp=32 改成24\n5.配置selinux\nchcon -t bin_t /usr/sbin/xrdp\nchcon -t bin_t /usr/sbin/xrdp-sesman\n6.设置xrdp服务，开机自动启动\nsystemctl start xrdp\nsystemctl enable xrdp\n7.打开防火墙\nfirewall-cmd  --permanent --zone=public --add-port=3389/tcp\nfirewall-cmd --reload\n8.查看xrdp是否启动\nsystemctl status xrdp.service\nss -antup|grep xrdp\n9.启动window rdp连接\nFrom <https://www.cnblogs.com/Jesse-Li/p/10284221.html> \n\n\n2 关闭防火墙\nsystemctl stop firewalld.service\n• 1\n设置开机不启动防火墙\nsystemctl disable firewalld.servie\n\n3、关闭SElinux\n1）查看selinux状态\nsestatus \n• 1\n2）临时关闭selinux\nsetenforce 0\n• 1\n永久关闭selinux\nvim /etc/selinux/config\nSELINUX=disabled\n\n查看服务列表状态:\n 1. systemctl list-units --type=service \n 2. systemctl   list-unit-files       列出所有已经安装的  服务  及  状态      （可为人所读,  内容简略、清晰）：\n\n 3. systemctl 可以列出正在运行的服务状态\n\n启动一个服务：\nsystemctl start postfix.service\n\n关闭一个服务：\nsystemctl stop postfix.service\n\n重启一个服务：\nsystemctl restart postfix.service\n\n显示一个服务的状态：\nsystemctl status postfix.service\n\n在开机时启用一个服务：systemctl enable postfix.service\n在开机时禁用一个服务：systemctl disable postfix.service\n\n查看服务是否开机启动：   systemctl is-enabled postfix.service\n\n查看已启动的服务列表：   systemctl list-unit-files | grep enabled\n\n查看启动失败的服务列表：   systemctl --failed\n\nPS：使用命令 systemctl is-enabled postfix.service 得到的值可以是enable、disable或static，这里的 static 它是指对应的 Unit 文件中没有定义[Install]区域，因此无法配置为开机启动服务。\n\n 说明：启用服务就是在当前“runlevel”的配置文件目录   /etc/systemd/system/multi-user.target.wants  里，建立  /usr/lib/systemd/system   里面对应服务配置文件的软链接；\n禁用服务就是删除此软链接，添加服务就是添加软连接。\n\nFrom <https://www.cnblogs.com/devilmaycry812839668/p/8481760.html> \n","slug":"linux/Windows10mstsc远程登录Centos7.0","published":1,"date":"2020-08-12T16:05:46.523Z","updated":"2020-02-13T12:47:44.458Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmef001thohx9ki9dkbp","content":"<p>配置iptables防火墙<br>    在xrdp使用是3389端口，所以在iptables中也要开放相应的端口，否则无法访问<br> 　　iptables -A INPUT -p tcp –dport 3389 -j ACCEPT<br>    　　service iptables save<br>From <a href=\"https://www.cnblogs.com/Skyar/p/5260368.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/Skyar/p/5260368.html</a> </p>\n<p>centos 安装xrdp远程连接桌面</p>\n<ol>\n<li>安装epel库，否则无法安装xrdp</li>\n</ol>\n<p>yum install epel-release<br>2.安装 xrdp<br>yum install xrdp<br>3. 安装tigervnc-server<br>yum install tigervnc-server<br>4. 配置xrdp.ini文件<br>vim /etc/xrdp/xrdp.ini<br>把max_bpp=32 改成24<br>5.配置selinux<br>chcon -t bin_t /usr/sbin/xrdp<br>chcon -t bin_t /usr/sbin/xrdp-sesman<br>6.设置xrdp服务，开机自动启动<br>systemctl start xrdp<br>systemctl enable xrdp<br>7.打开防火墙<br>firewall-cmd  –permanent –zone=public –add-port=3389/tcp<br>firewall-cmd –reload<br>8.查看xrdp是否启动<br>systemctl status xrdp.service<br>ss -antup|grep xrdp<br>9.启动window rdp连接<br>From <a href=\"https://www.cnblogs.com/Jesse-Li/p/10284221.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/Jesse-Li/p/10284221.html</a> </p>\n<p>2 关闭防火墙<br>systemctl stop firewalld.service<br>• 1<br>设置开机不启动防火墙<br>systemctl disable firewalld.servie</p>\n<p>3、关闭SElinux<br>1）查看selinux状态<br>sestatus<br>• 1<br>2）临时关闭selinux<br>setenforce 0<br>• 1<br>永久关闭selinux<br>vim /etc/selinux/config<br>SELINUX=disabled</p>\n<p>查看服务列表状态:</p>\n<ol>\n<li><p>systemctl list-units –type=service </p>\n</li>\n<li><p>systemctl   list-unit-files       列出所有已经安装的  服务  及  状态      （可为人所读,  内容简略、清晰）：</p>\n</li>\n<li><p>systemctl 可以列出正在运行的服务状态</p>\n</li>\n</ol>\n<p>启动一个服务：<br>systemctl start postfix.service</p>\n<p>关闭一个服务：<br>systemctl stop postfix.service</p>\n<p>重启一个服务：<br>systemctl restart postfix.service</p>\n<p>显示一个服务的状态：<br>systemctl status postfix.service</p>\n<p>在开机时启用一个服务：systemctl enable postfix.service<br>在开机时禁用一个服务：systemctl disable postfix.service</p>\n<p>查看服务是否开机启动：   systemctl is-enabled postfix.service</p>\n<p>查看已启动的服务列表：   systemctl list-unit-files | grep enabled</p>\n<p>查看启动失败的服务列表：   systemctl –failed</p>\n<p>PS：使用命令 systemctl is-enabled postfix.service 得到的值可以是enable、disable或static，这里的 static 它是指对应的 Unit 文件中没有定义[Install]区域，因此无法配置为开机启动服务。</p>\n<p> 说明：启用服务就是在当前“runlevel”的配置文件目录   /etc/systemd/system/multi-user.target.wants  里，建立  /usr/lib/systemd/system   里面对应服务配置文件的软链接；<br>禁用服务就是删除此软链接，添加服务就是添加软连接。</p>\n<p>From <a href=\"https://www.cnblogs.com/devilmaycry812839668/p/8481760.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/devilmaycry812839668/p/8481760.html</a> </p>\n","site":{"data":{}},"excerpt":"","more":"<p>配置iptables防火墙<br>    在xrdp使用是3389端口，所以在iptables中也要开放相应的端口，否则无法访问<br> 　　iptables -A INPUT -p tcp –dport 3389 -j ACCEPT<br>    　　service iptables save<br>From <a href=\"https://www.cnblogs.com/Skyar/p/5260368.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/Skyar/p/5260368.html</a> </p>\n<p>centos 安装xrdp远程连接桌面</p>\n<ol>\n<li>安装epel库，否则无法安装xrdp</li>\n</ol>\n<p>yum install epel-release<br>2.安装 xrdp<br>yum install xrdp<br>3. 安装tigervnc-server<br>yum install tigervnc-server<br>4. 配置xrdp.ini文件<br>vim /etc/xrdp/xrdp.ini<br>把max_bpp=32 改成24<br>5.配置selinux<br>chcon -t bin_t /usr/sbin/xrdp<br>chcon -t bin_t /usr/sbin/xrdp-sesman<br>6.设置xrdp服务，开机自动启动<br>systemctl start xrdp<br>systemctl enable xrdp<br>7.打开防火墙<br>firewall-cmd  –permanent –zone=public –add-port=3389/tcp<br>firewall-cmd –reload<br>8.查看xrdp是否启动<br>systemctl status xrdp.service<br>ss -antup|grep xrdp<br>9.启动window rdp连接<br>From <a href=\"https://www.cnblogs.com/Jesse-Li/p/10284221.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/Jesse-Li/p/10284221.html</a> </p>\n<p>2 关闭防火墙<br>systemctl stop firewalld.service<br>• 1<br>设置开机不启动防火墙<br>systemctl disable firewalld.servie</p>\n<p>3、关闭SElinux<br>1）查看selinux状态<br>sestatus<br>• 1<br>2）临时关闭selinux<br>setenforce 0<br>• 1<br>永久关闭selinux<br>vim /etc/selinux/config<br>SELINUX=disabled</p>\n<p>查看服务列表状态:</p>\n<ol>\n<li><p>systemctl list-units –type=service </p>\n</li>\n<li><p>systemctl   list-unit-files       列出所有已经安装的  服务  及  状态      （可为人所读,  内容简略、清晰）：</p>\n</li>\n<li><p>systemctl 可以列出正在运行的服务状态</p>\n</li>\n</ol>\n<p>启动一个服务：<br>systemctl start postfix.service</p>\n<p>关闭一个服务：<br>systemctl stop postfix.service</p>\n<p>重启一个服务：<br>systemctl restart postfix.service</p>\n<p>显示一个服务的状态：<br>systemctl status postfix.service</p>\n<p>在开机时启用一个服务：systemctl enable postfix.service<br>在开机时禁用一个服务：systemctl disable postfix.service</p>\n<p>查看服务是否开机启动：   systemctl is-enabled postfix.service</p>\n<p>查看已启动的服务列表：   systemctl list-unit-files | grep enabled</p>\n<p>查看启动失败的服务列表：   systemctl –failed</p>\n<p>PS：使用命令 systemctl is-enabled postfix.service 得到的值可以是enable、disable或static，这里的 static 它是指对应的 Unit 文件中没有定义[Install]区域，因此无法配置为开机启动服务。</p>\n<p> 说明：启用服务就是在当前“runlevel”的配置文件目录   /etc/systemd/system/multi-user.target.wants  里，建立  /usr/lib/systemd/system   里面对应服务配置文件的软链接；<br>禁用服务就是删除此软链接，添加服务就是添加软连接。</p>\n<p>From <a href=\"https://www.cnblogs.com/devilmaycry812839668/p/8481760.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/devilmaycry812839668/p/8481760.html</a> </p>\n"},{"title":"centos升级gcc到9.1.0","_content":"centos 升级GCC到9.1.0\n下载gcc-9.1.0源代码\ncd gcc-9.1.0\nvim contrib/download_prerequisites   #查看需要安装的依赖库\n 30 gmp='gmp-6.1.0.tar.bz2'\n 31 mpfr='mpfr-3.1.4.tar.bz2'\n 32 mpc='mpc-1.0.3.tar.gz'\n 33 isl='isl-0.18.tar.bz2'\n直接搜索相应库下载对应版本或下面链接\n1.gmp http://ftp.gnu.org/gnu/gmp/\n2.mpfr http://ftp.gnu.org/gnu/mpfr/\n3.mpc http://ftp.gnu.org/gnu/mpc/\n4.isl http://isl.gforge.inria.fr/\n\ncd gmp-6.1.0\n./configure --prefix=/usr/local/gmp-6.1.0 && make\nmake install\n\ncd mpfr-3.1.4\n./configure --prefix=/usr/local/mpfr-3.1.4 --with-gmp=/usr/local/gmp-6.1.0 && make\nmake install\n\ncd mpc-1.0.3\n./configure --prefix=/usr/local/mpc-1.0.3 --with-gmp=/usr/local/gmp-6.1.0 --with-mpfr=/usr/local/mpfr-3.1.4 && make\nmake install\n\ncd isl-0.18\n$./configure --prefix=/usr/local/isl-0.18 --with-gmp-prefix=/usr/local/gmp-6.1.0\n$make\n$make check\n$make install\n\n$export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/isl-0.18/lib\n或设置到所有tty\n#vi ~/.bashrc\n添加export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/isl-0.18/lib\n再source bashrc\n\n如果报检测不到gmp,mpfr,mpc相关文件，则把下面对应的也加入进来\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/mpc-1.0.3/lib:/usr/local/gmp-6.1.0/lib:/usr/local/mpfr-3.1.4/lib:/usr/local/isl-0.18/lib\n\ncd gcc-9.1.0\n$./configure --prefix=/usr/local/gcc-9.1.0 --enable-threads=posix --disable-checking --disable-multilib --enable-languages=c,c++ --with-gmp=/usr/local/gmp-6.1.0 --with-mpfr=/usr/local/mpfr-3.1.4 --with-mpc=/usr/local/mpc-1.0.3 --with-isl=/usr/local/isl-0.18\n$make -j4 #启用4个job，需要大约25分钟时间\n$make install\n查看安装路径：\n$whereis gcc\n如果有旧的Gcc,替换版本：\n$cd /usr/bin\n$mv gcc gcc.bak\n$mv g++ g++.bak\n$ln -s /usr/local/gcc-9.1.0/bin/gcc /usr/bin/gcc\n$ln -s /usr/local/gcc-9.1.0/bin/g++ /usr/bin/g++\n查看版本：\n$gcc -v\n$g++ -v\n\n运行以下命令检查动态库：\nstrings /usr/lib64/libstdc++.so.6 | grep GLIBC\n\ncp /usr/local/gcc-9.1.0/lib64/libstdc++.so.6.0.26 /usr/lib64/\nmv libstdc++.so.6 libstdc++.so.6.bak\nln libstdc++.so.6.0.26 libstdc++.so.6\n","source":"_posts/linux/centos升级gcc到9.1.0.md","raw":"---\ntitle: centos升级gcc到9.1.0\ntags: \ncategories:\n- linux\n---\ncentos 升级GCC到9.1.0\n下载gcc-9.1.0源代码\ncd gcc-9.1.0\nvim contrib/download_prerequisites   #查看需要安装的依赖库\n 30 gmp='gmp-6.1.0.tar.bz2'\n 31 mpfr='mpfr-3.1.4.tar.bz2'\n 32 mpc='mpc-1.0.3.tar.gz'\n 33 isl='isl-0.18.tar.bz2'\n直接搜索相应库下载对应版本或下面链接\n1.gmp http://ftp.gnu.org/gnu/gmp/\n2.mpfr http://ftp.gnu.org/gnu/mpfr/\n3.mpc http://ftp.gnu.org/gnu/mpc/\n4.isl http://isl.gforge.inria.fr/\n\ncd gmp-6.1.0\n./configure --prefix=/usr/local/gmp-6.1.0 && make\nmake install\n\ncd mpfr-3.1.4\n./configure --prefix=/usr/local/mpfr-3.1.4 --with-gmp=/usr/local/gmp-6.1.0 && make\nmake install\n\ncd mpc-1.0.3\n./configure --prefix=/usr/local/mpc-1.0.3 --with-gmp=/usr/local/gmp-6.1.0 --with-mpfr=/usr/local/mpfr-3.1.4 && make\nmake install\n\ncd isl-0.18\n$./configure --prefix=/usr/local/isl-0.18 --with-gmp-prefix=/usr/local/gmp-6.1.0\n$make\n$make check\n$make install\n\n$export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/isl-0.18/lib\n或设置到所有tty\n#vi ~/.bashrc\n添加export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/isl-0.18/lib\n再source bashrc\n\n如果报检测不到gmp,mpfr,mpc相关文件，则把下面对应的也加入进来\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/mpc-1.0.3/lib:/usr/local/gmp-6.1.0/lib:/usr/local/mpfr-3.1.4/lib:/usr/local/isl-0.18/lib\n\ncd gcc-9.1.0\n$./configure --prefix=/usr/local/gcc-9.1.0 --enable-threads=posix --disable-checking --disable-multilib --enable-languages=c,c++ --with-gmp=/usr/local/gmp-6.1.0 --with-mpfr=/usr/local/mpfr-3.1.4 --with-mpc=/usr/local/mpc-1.0.3 --with-isl=/usr/local/isl-0.18\n$make -j4 #启用4个job，需要大约25分钟时间\n$make install\n查看安装路径：\n$whereis gcc\n如果有旧的Gcc,替换版本：\n$cd /usr/bin\n$mv gcc gcc.bak\n$mv g++ g++.bak\n$ln -s /usr/local/gcc-9.1.0/bin/gcc /usr/bin/gcc\n$ln -s /usr/local/gcc-9.1.0/bin/g++ /usr/bin/g++\n查看版本：\n$gcc -v\n$g++ -v\n\n运行以下命令检查动态库：\nstrings /usr/lib64/libstdc++.so.6 | grep GLIBC\n\ncp /usr/local/gcc-9.1.0/lib64/libstdc++.so.6.0.26 /usr/lib64/\nmv libstdc++.so.6 libstdc++.so.6.bak\nln libstdc++.so.6.0.26 libstdc++.so.6\n","slug":"linux/centos升级gcc到9.1.0","published":1,"date":"2020-08-12T16:05:46.091Z","updated":"2020-03-16T11:22:43.510Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmej001whohxchaj4jr3","content":"<p>centos 升级GCC到9.1.0<br>下载gcc-9.1.0源代码<br>cd gcc-9.1.0<br>vim contrib/download_prerequisites   #查看需要安装的依赖库<br> 30 gmp=’gmp-6.1.0.tar.bz2’<br> 31 mpfr=’mpfr-3.1.4.tar.bz2’<br> 32 mpc=’mpc-1.0.3.tar.gz’<br> 33 isl=’isl-0.18.tar.bz2’<br>直接搜索相应库下载对应版本或下面链接<br>1.gmp <a href=\"http://ftp.gnu.org/gnu/gmp/\" target=\"_blank\" rel=\"noopener\">http://ftp.gnu.org/gnu/gmp/</a><br>2.mpfr <a href=\"http://ftp.gnu.org/gnu/mpfr/\" target=\"_blank\" rel=\"noopener\">http://ftp.gnu.org/gnu/mpfr/</a><br>3.mpc <a href=\"http://ftp.gnu.org/gnu/mpc/\" target=\"_blank\" rel=\"noopener\">http://ftp.gnu.org/gnu/mpc/</a><br>4.isl <a href=\"http://isl.gforge.inria.fr/\" target=\"_blank\" rel=\"noopener\">http://isl.gforge.inria.fr/</a></p>\n<p>cd gmp-6.1.0<br>./configure –prefix=/usr/local/gmp-6.1.0 &amp;&amp; make<br>make install</p>\n<p>cd mpfr-3.1.4<br>./configure –prefix=/usr/local/mpfr-3.1.4 –with-gmp=/usr/local/gmp-6.1.0 &amp;&amp; make<br>make install</p>\n<p>cd mpc-1.0.3<br>./configure –prefix=/usr/local/mpc-1.0.3 –with-gmp=/usr/local/gmp-6.1.0 –with-mpfr=/usr/local/mpfr-3.1.4 &amp;&amp; make<br>make install</p>\n<p>cd isl-0.18<br>$./configure –prefix=/usr/local/isl-0.18 –with-gmp-prefix=/usr/local/gmp-6.1.0<br>$make<br>$make check<br>$make install</p>\n<p>$export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/isl-0.18/lib<br>或设置到所有tty<br>#vi ~/.bashrc<br>添加export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/isl-0.18/lib<br>再source bashrc</p>\n<p>如果报检测不到gmp,mpfr,mpc相关文件，则把下面对应的也加入进来<br>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/mpc-1.0.3/lib:/usr/local/gmp-6.1.0/lib:/usr/local/mpfr-3.1.4/lib:/usr/local/isl-0.18/lib</p>\n<p>cd gcc-9.1.0<br>$./configure –prefix=/usr/local/gcc-9.1.0 –enable-threads=posix –disable-checking –disable-multilib –enable-languages=c,c++ –with-gmp=/usr/local/gmp-6.1.0 –with-mpfr=/usr/local/mpfr-3.1.4 –with-mpc=/usr/local/mpc-1.0.3 –with-isl=/usr/local/isl-0.18<br>$make -j4 #启用4个job，需要大约25分钟时间<br>$make install<br>查看安装路径：<br>$whereis gcc<br>如果有旧的Gcc,替换版本：<br>$cd /usr/bin<br>$mv gcc gcc.bak<br>$mv g++ g++.bak<br>$ln -s /usr/local/gcc-9.1.0/bin/gcc /usr/bin/gcc<br>$ln -s /usr/local/gcc-9.1.0/bin/g++ /usr/bin/g++<br>查看版本：<br>$gcc -v<br>$g++ -v</p>\n<p>运行以下命令检查动态库：<br>strings /usr/lib64/libstdc++.so.6 | grep GLIBC</p>\n<p>cp /usr/local/gcc-9.1.0/lib64/libstdc++.so.6.0.26 /usr/lib64/<br>mv libstdc++.so.6 libstdc++.so.6.bak<br>ln libstdc++.so.6.0.26 libstdc++.so.6</p>\n","site":{"data":{}},"excerpt":"","more":"<p>centos 升级GCC到9.1.0<br>下载gcc-9.1.0源代码<br>cd gcc-9.1.0<br>vim contrib/download_prerequisites   #查看需要安装的依赖库<br> 30 gmp=’gmp-6.1.0.tar.bz2’<br> 31 mpfr=’mpfr-3.1.4.tar.bz2’<br> 32 mpc=’mpc-1.0.3.tar.gz’<br> 33 isl=’isl-0.18.tar.bz2’<br>直接搜索相应库下载对应版本或下面链接<br>1.gmp <a href=\"http://ftp.gnu.org/gnu/gmp/\" target=\"_blank\" rel=\"noopener\">http://ftp.gnu.org/gnu/gmp/</a><br>2.mpfr <a href=\"http://ftp.gnu.org/gnu/mpfr/\" target=\"_blank\" rel=\"noopener\">http://ftp.gnu.org/gnu/mpfr/</a><br>3.mpc <a href=\"http://ftp.gnu.org/gnu/mpc/\" target=\"_blank\" rel=\"noopener\">http://ftp.gnu.org/gnu/mpc/</a><br>4.isl <a href=\"http://isl.gforge.inria.fr/\" target=\"_blank\" rel=\"noopener\">http://isl.gforge.inria.fr/</a></p>\n<p>cd gmp-6.1.0<br>./configure –prefix=/usr/local/gmp-6.1.0 &amp;&amp; make<br>make install</p>\n<p>cd mpfr-3.1.4<br>./configure –prefix=/usr/local/mpfr-3.1.4 –with-gmp=/usr/local/gmp-6.1.0 &amp;&amp; make<br>make install</p>\n<p>cd mpc-1.0.3<br>./configure –prefix=/usr/local/mpc-1.0.3 –with-gmp=/usr/local/gmp-6.1.0 –with-mpfr=/usr/local/mpfr-3.1.4 &amp;&amp; make<br>make install</p>\n<p>cd isl-0.18<br>$./configure –prefix=/usr/local/isl-0.18 –with-gmp-prefix=/usr/local/gmp-6.1.0<br>$make<br>$make check<br>$make install</p>\n<p>$export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/isl-0.18/lib<br>或设置到所有tty<br>#vi ~/.bashrc<br>添加export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/isl-0.18/lib<br>再source bashrc</p>\n<p>如果报检测不到gmp,mpfr,mpc相关文件，则把下面对应的也加入进来<br>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/mpc-1.0.3/lib:/usr/local/gmp-6.1.0/lib:/usr/local/mpfr-3.1.4/lib:/usr/local/isl-0.18/lib</p>\n<p>cd gcc-9.1.0<br>$./configure –prefix=/usr/local/gcc-9.1.0 –enable-threads=posix –disable-checking –disable-multilib –enable-languages=c,c++ –with-gmp=/usr/local/gmp-6.1.0 –with-mpfr=/usr/local/mpfr-3.1.4 –with-mpc=/usr/local/mpc-1.0.3 –with-isl=/usr/local/isl-0.18<br>$make -j4 #启用4个job，需要大约25分钟时间<br>$make install<br>查看安装路径：<br>$whereis gcc<br>如果有旧的Gcc,替换版本：<br>$cd /usr/bin<br>$mv gcc gcc.bak<br>$mv g++ g++.bak<br>$ln -s /usr/local/gcc-9.1.0/bin/gcc /usr/bin/gcc<br>$ln -s /usr/local/gcc-9.1.0/bin/g++ /usr/bin/g++<br>查看版本：<br>$gcc -v<br>$g++ -v</p>\n<p>运行以下命令检查动态库：<br>strings /usr/lib64/libstdc++.so.6 | grep GLIBC</p>\n<p>cp /usr/local/gcc-9.1.0/lib64/libstdc++.so.6.0.26 /usr/lib64/<br>mv libstdc++.so.6 libstdc++.so.6.bak<br>ln libstdc++.so.6.0.26 libstdc++.so.6</p>\n"},{"title":"cppc动态调频","_content":"CPPC的全称是Collaborative Processor Performance Control\nCPC的全称是Per cpu table called，是bios提供的一组acpi表(ACPI表示高级配置和电源管理接口（Advanced Configuration and Power Management Interface))，用于设置cpu的频率。这组acpi表如下：\n\n1. /*\n2. * An example CPC table looks like the following.\n3. *\n4. *\tName(_CPC, Package()\n5. *\t\t\t{\n6. *\t\t\t17,\n7. *\t\t\tNumEntries\n8. *\t\t\t1,\n9. *\t\t\t// Revision\n10. *\t\t\tResourceTemplate(){Register(PCC, 32, 0, 0x120, 2)},\n11. *\t\t\t// Highest Performance\n12. *\t\t\tResourceTemplate(){Register(PCC, 32, 0, 0x124, 2)},\n13. *\t\t\t// Nominal Performance\n14. *\t\t\tResourceTemplate(){Register(PCC, 32, 0, 0x128, 2)},\n15. *\t\t\t// Lowest Nonlinear Performance\n16. *\t\t\tResourceTemplate(){Register(PCC, 32, 0, 0x12C, 2)},\n17. *\t\t\t// Lowest Performance\n18. *\t\t\tResourceTemplate(){Register(PCC, 32, 0, 0x130, 2)},\n19. *\t\t\t// Guaranteed Performance Register\n20. *\t\t\tResourceTemplate(){Register(PCC, 32, 0, 0x110, 2)},\n21. *\t\t\t// Desired Performance Register\n22. *\t\t\tResourceTemplate(){Register(SystemMemory, 0, 0, 0, 0)},\n23. *\t\t\t..\n24. *\t\t\t..\n25. *\t\t\t..\n26. *\n27. *\t\t}\n28. * Each Register() encodes how to access that specific register.\n29. * e.g. a sample PCC entry has the following encoding:\n30. *\n31. *\tRegister (\n32. *\t\tPCC,\n33. *\t\tAddressSpaceKeyword\n34. *\t\t8,\n35. *\t\t//RegisterBitWidth\n36. *\t\t8,\n37. *\t\t//RegisterBitOffset\n38. *\t\t0x30,\n39. *\t\t//RegisterAddress\n40. *\t\t9\n41. *\t\t//AccessSize (subspace ID)\n42. *\t\t0\n43. *\t\t)\n44. *\t}\n45. */\n那cppc表具体要怎么工作呢？具体在driver/cpufreq/cppc_cpufreq.c中。\n这里的cppc_cpufreq_init是入口函数，这个函数向cpufreq的framework注册了一个可以调频的cpu driver\n\n1. static int __init cppc_cpufreq_init(void)\n2. {\n3. ret = cpufreq_register_driver(&cppc_cpufreq_driver);\n4. if (ret)\n5. goto out;\n6. }\n7. static struct cpufreq_driver cppc_cpufreq_driver = {\n8. .flags = CPUFREQ_CONST_LOOPS,\n9. .verify = cppc_verify_policy,\n10. .target = cppc_cpufreq_set_target,\n11. .get = cppc_cpufreq_get_rate,\n12. .init = cppc_cpufreq_cpu_init,\n13. .stop_cpu = cppc_cpufreq_stop_cpu,\n14. .name = \"cppc_cpufreq\",\n15. };\n16. //cppc_cpufreq_driver 最终的函数就是target，最终cpu调频就是通过target 这个回调函数来实现\n17. static int cppc_cpufreq_set_target(struct cpufreq_policy *policy,\n18. unsigned int target_freq,\n19. unsigned int relation)\n20. {\n21. struct cppc_cpudata *cpu;\n22. struct cpufreq_freqs freqs;\n23. u32 desired_perf;\n24. int ret = 0;\n25. cpu = all_cpu_data[policy->cpu];\n26. //得到要设置的频率\n27. desired_perf = cppc_cpufreq_khz_to_perf(cpu, target_freq);\n28. /* Return if it is exactly the same perf */\n29. if (desired_perf == cpu->perf_ctrls.desired_perf)\n30. return ret;\n31. cpu->perf_ctrls.desired_perf = desired_perf;\n32. freqs.old = policy->cur;\n33. freqs.new = target_freq;\n34. cpufreq_freq_transition_begin(policy, &freqs);\n35. //通过acpi 提供的的接口来设置cpu 频率\n36. ret = cppc_set_perf(cpu->cpu, &cpu->perf_ctrls);\n37. cpufreq_freq_transition_end(policy, &freqs, ret != 0);\n38. if (ret)\n39. pr_debug(\"Failed to set target on CPU:%d. ret:%d\\n\",\n40. cpu->cpu, ret);\n41. return ret;\n42. }\n这里的cppc_set_perf实现在driver/acpi/cppc_acpi.c中实现，通过这个接口可以通过固件来设置cpu频率。\n","source":"_posts/linux/cppc动态调频.md","raw":"---\ntitle: cppc动态调频\ntags: \ncategories:\n- linux\n---\nCPPC的全称是Collaborative Processor Performance Control\nCPC的全称是Per cpu table called，是bios提供的一组acpi表(ACPI表示高级配置和电源管理接口（Advanced Configuration and Power Management Interface))，用于设置cpu的频率。这组acpi表如下：\n\n1. /*\n2. * An example CPC table looks like the following.\n3. *\n4. *\tName(_CPC, Package()\n5. *\t\t\t{\n6. *\t\t\t17,\n7. *\t\t\tNumEntries\n8. *\t\t\t1,\n9. *\t\t\t// Revision\n10. *\t\t\tResourceTemplate(){Register(PCC, 32, 0, 0x120, 2)},\n11. *\t\t\t// Highest Performance\n12. *\t\t\tResourceTemplate(){Register(PCC, 32, 0, 0x124, 2)},\n13. *\t\t\t// Nominal Performance\n14. *\t\t\tResourceTemplate(){Register(PCC, 32, 0, 0x128, 2)},\n15. *\t\t\t// Lowest Nonlinear Performance\n16. *\t\t\tResourceTemplate(){Register(PCC, 32, 0, 0x12C, 2)},\n17. *\t\t\t// Lowest Performance\n18. *\t\t\tResourceTemplate(){Register(PCC, 32, 0, 0x130, 2)},\n19. *\t\t\t// Guaranteed Performance Register\n20. *\t\t\tResourceTemplate(){Register(PCC, 32, 0, 0x110, 2)},\n21. *\t\t\t// Desired Performance Register\n22. *\t\t\tResourceTemplate(){Register(SystemMemory, 0, 0, 0, 0)},\n23. *\t\t\t..\n24. *\t\t\t..\n25. *\t\t\t..\n26. *\n27. *\t\t}\n28. * Each Register() encodes how to access that specific register.\n29. * e.g. a sample PCC entry has the following encoding:\n30. *\n31. *\tRegister (\n32. *\t\tPCC,\n33. *\t\tAddressSpaceKeyword\n34. *\t\t8,\n35. *\t\t//RegisterBitWidth\n36. *\t\t8,\n37. *\t\t//RegisterBitOffset\n38. *\t\t0x30,\n39. *\t\t//RegisterAddress\n40. *\t\t9\n41. *\t\t//AccessSize (subspace ID)\n42. *\t\t0\n43. *\t\t)\n44. *\t}\n45. */\n那cppc表具体要怎么工作呢？具体在driver/cpufreq/cppc_cpufreq.c中。\n这里的cppc_cpufreq_init是入口函数，这个函数向cpufreq的framework注册了一个可以调频的cpu driver\n\n1. static int __init cppc_cpufreq_init(void)\n2. {\n3. ret = cpufreq_register_driver(&cppc_cpufreq_driver);\n4. if (ret)\n5. goto out;\n6. }\n7. static struct cpufreq_driver cppc_cpufreq_driver = {\n8. .flags = CPUFREQ_CONST_LOOPS,\n9. .verify = cppc_verify_policy,\n10. .target = cppc_cpufreq_set_target,\n11. .get = cppc_cpufreq_get_rate,\n12. .init = cppc_cpufreq_cpu_init,\n13. .stop_cpu = cppc_cpufreq_stop_cpu,\n14. .name = \"cppc_cpufreq\",\n15. };\n16. //cppc_cpufreq_driver 最终的函数就是target，最终cpu调频就是通过target 这个回调函数来实现\n17. static int cppc_cpufreq_set_target(struct cpufreq_policy *policy,\n18. unsigned int target_freq,\n19. unsigned int relation)\n20. {\n21. struct cppc_cpudata *cpu;\n22. struct cpufreq_freqs freqs;\n23. u32 desired_perf;\n24. int ret = 0;\n25. cpu = all_cpu_data[policy->cpu];\n26. //得到要设置的频率\n27. desired_perf = cppc_cpufreq_khz_to_perf(cpu, target_freq);\n28. /* Return if it is exactly the same perf */\n29. if (desired_perf == cpu->perf_ctrls.desired_perf)\n30. return ret;\n31. cpu->perf_ctrls.desired_perf = desired_perf;\n32. freqs.old = policy->cur;\n33. freqs.new = target_freq;\n34. cpufreq_freq_transition_begin(policy, &freqs);\n35. //通过acpi 提供的的接口来设置cpu 频率\n36. ret = cppc_set_perf(cpu->cpu, &cpu->perf_ctrls);\n37. cpufreq_freq_transition_end(policy, &freqs, ret != 0);\n38. if (ret)\n39. pr_debug(\"Failed to set target on CPU:%d. ret:%d\\n\",\n40. cpu->cpu, ret);\n41. return ret;\n42. }\n这里的cppc_set_perf实现在driver/acpi/cppc_acpi.c中实现，通过这个接口可以通过固件来设置cpu频率。\n","slug":"linux/cppc动态调频","published":1,"date":"2020-08-12T16:05:46.110Z","updated":"2020-02-13T12:47:44.466Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmeo001yhohx4cb45v1z","content":"<p>CPPC的全称是Collaborative Processor Performance Control<br>CPC的全称是Per cpu table called，是bios提供的一组acpi表(ACPI表示高级配置和电源管理接口（Advanced Configuration and Power Management Interface))，用于设置cpu的频率。这组acpi表如下：</p>\n<ol>\n<li><p>/*</p>\n</li>\n<li><ul>\n<li>An example CPC table looks like the following.</li>\n</ul>\n</li>\n<li><p>*</p>\n</li>\n<li><ul>\n<li>Name(_CPC, Package()</li>\n</ul>\n</li>\n<li><ul>\n<li>{</li>\n</ul>\n</li>\n<li><ul>\n<li>17,</li>\n</ul>\n</li>\n<li><ul>\n<li>NumEntries</li>\n</ul>\n</li>\n<li><ul>\n<li>1,</li>\n</ul>\n</li>\n<li><ul>\n<li>// Revision</li>\n</ul>\n</li>\n<li><ul>\n<li>ResourceTemplate(){Register(PCC, 32, 0, 0x120, 2)},</li>\n</ul>\n</li>\n<li><ul>\n<li>// Highest Performance</li>\n</ul>\n</li>\n<li><ul>\n<li>ResourceTemplate(){Register(PCC, 32, 0, 0x124, 2)},</li>\n</ul>\n</li>\n<li><ul>\n<li>// Nominal Performance</li>\n</ul>\n</li>\n<li><ul>\n<li>ResourceTemplate(){Register(PCC, 32, 0, 0x128, 2)},</li>\n</ul>\n</li>\n<li><ul>\n<li>// Lowest Nonlinear Performance</li>\n</ul>\n</li>\n<li><ul>\n<li>ResourceTemplate(){Register(PCC, 32, 0, 0x12C, 2)},</li>\n</ul>\n</li>\n<li><ul>\n<li>// Lowest Performance</li>\n</ul>\n</li>\n<li><ul>\n<li>ResourceTemplate(){Register(PCC, 32, 0, 0x130, 2)},</li>\n</ul>\n</li>\n<li><ul>\n<li>// Guaranteed Performance Register</li>\n</ul>\n</li>\n<li><ul>\n<li>ResourceTemplate(){Register(PCC, 32, 0, 0x110, 2)},</li>\n</ul>\n</li>\n<li><ul>\n<li>// Desired Performance Register</li>\n</ul>\n</li>\n<li><ul>\n<li>ResourceTemplate(){Register(SystemMemory, 0, 0, 0, 0)},</li>\n</ul>\n</li>\n<li><ul>\n<li>..</li>\n</ul>\n</li>\n<li><ul>\n<li>..</li>\n</ul>\n</li>\n<li><ul>\n<li>..</li>\n</ul>\n</li>\n<li><p>*</p>\n</li>\n<li><ul>\n<li>}</li>\n</ul>\n</li>\n<li><ul>\n<li>Each Register() encodes how to access that specific register.</li>\n</ul>\n</li>\n<li><ul>\n<li>e.g. a sample PCC entry has the following encoding:</li>\n</ul>\n</li>\n<li><p>*</p>\n</li>\n<li><ul>\n<li>Register (</li>\n</ul>\n</li>\n<li><ul>\n<li>PCC,</li>\n</ul>\n</li>\n<li><ul>\n<li>AddressSpaceKeyword</li>\n</ul>\n</li>\n<li><ul>\n<li>8,</li>\n</ul>\n</li>\n<li><ul>\n<li>//RegisterBitWidth</li>\n</ul>\n</li>\n<li><ul>\n<li>8,</li>\n</ul>\n</li>\n<li><ul>\n<li>//RegisterBitOffset</li>\n</ul>\n</li>\n<li><ul>\n<li>0x30,</li>\n</ul>\n</li>\n<li><ul>\n<li>//RegisterAddress</li>\n</ul>\n</li>\n<li><ul>\n<li>9</li>\n</ul>\n</li>\n<li><ul>\n<li>//AccessSize (subspace ID)</li>\n</ul>\n</li>\n<li><ul>\n<li>0</li>\n</ul>\n</li>\n<li><ul>\n<li>)</li>\n</ul>\n</li>\n<li><ul>\n<li>}</li>\n</ul>\n</li>\n<li><p>*/<br>那cppc表具体要怎么工作呢？具体在driver/cpufreq/cppc_cpufreq.c中。<br>这里的cppc_cpufreq_init是入口函数，这个函数向cpufreq的framework注册了一个可以调频的cpu driver</p>\n</li>\n<li><p>static int __init cppc_cpufreq_init(void)</p>\n</li>\n<li><p>{</p>\n</li>\n<li><p>ret = cpufreq_register_driver(&amp;cppc_cpufreq_driver);</p>\n</li>\n<li><p>if (ret)</p>\n</li>\n<li><p>goto out;</p>\n</li>\n<li><p>}</p>\n</li>\n<li><p>static struct cpufreq_driver cppc_cpufreq_driver = {</p>\n</li>\n<li><p>.flags = CPUFREQ_CONST_LOOPS,</p>\n</li>\n<li><p>.verify = cppc_verify_policy,</p>\n</li>\n<li><p>.target = cppc_cpufreq_set_target,</p>\n</li>\n<li><p>.get = cppc_cpufreq_get_rate,</p>\n</li>\n<li><p>.init = cppc_cpufreq_cpu_init,</p>\n</li>\n<li><p>.stop_cpu = cppc_cpufreq_stop_cpu,</p>\n</li>\n<li><p>.name = “cppc_cpufreq”,</p>\n</li>\n<li><p>};</p>\n</li>\n<li><p>//cppc_cpufreq_driver 最终的函数就是target，最终cpu调频就是通过target 这个回调函数来实现</p>\n</li>\n<li><p>static int cppc_cpufreq_set_target(struct cpufreq_policy *policy,</p>\n</li>\n<li><p>unsigned int target_freq,</p>\n</li>\n<li><p>unsigned int relation)</p>\n</li>\n<li><p>{</p>\n</li>\n<li><p>struct cppc_cpudata *cpu;</p>\n</li>\n<li><p>struct cpufreq_freqs freqs;</p>\n</li>\n<li><p>u32 desired_perf;</p>\n</li>\n<li><p>int ret = 0;</p>\n</li>\n<li><p>cpu = all_cpu_data[policy-&gt;cpu];</p>\n</li>\n<li><p>//得到要设置的频率</p>\n</li>\n<li><p>desired_perf = cppc_cpufreq_khz_to_perf(cpu, target_freq);</p>\n</li>\n<li><p>/* Return if it is exactly the same perf */</p>\n</li>\n<li><p>if (desired_perf == cpu-&gt;perf_ctrls.desired_perf)</p>\n</li>\n<li><p>return ret;</p>\n</li>\n<li><p>cpu-&gt;perf_ctrls.desired_perf = desired_perf;</p>\n</li>\n<li><p>freqs.old = policy-&gt;cur;</p>\n</li>\n<li><p>freqs.new = target_freq;</p>\n</li>\n<li><p>cpufreq_freq_transition_begin(policy, &amp;freqs);</p>\n</li>\n<li><p>//通过acpi 提供的的接口来设置cpu 频率</p>\n</li>\n<li><p>ret = cppc_set_perf(cpu-&gt;cpu, &amp;cpu-&gt;perf_ctrls);</p>\n</li>\n<li><p>cpufreq_freq_transition_end(policy, &amp;freqs, ret != 0);</p>\n</li>\n<li><p>if (ret)</p>\n</li>\n<li><p>pr_debug(“Failed to set target on CPU:%d. ret:%d\\n”,</p>\n</li>\n<li><p>cpu-&gt;cpu, ret);</p>\n</li>\n<li><p>return ret;</p>\n</li>\n<li><p>}<br>这里的cppc_set_perf实现在driver/acpi/cppc_acpi.c中实现，通过这个接口可以通过固件来设置cpu频率。</p>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p>CPPC的全称是Collaborative Processor Performance Control<br>CPC的全称是Per cpu table called，是bios提供的一组acpi表(ACPI表示高级配置和电源管理接口（Advanced Configuration and Power Management Interface))，用于设置cpu的频率。这组acpi表如下：</p>\n<ol>\n<li><p>/*</p>\n</li>\n<li><ul>\n<li>An example CPC table looks like the following.</li>\n</ul>\n</li>\n<li><p>*</p>\n</li>\n<li><ul>\n<li>Name(_CPC, Package()</li>\n</ul>\n</li>\n<li><ul>\n<li>{</li>\n</ul>\n</li>\n<li><ul>\n<li>17,</li>\n</ul>\n</li>\n<li><ul>\n<li>NumEntries</li>\n</ul>\n</li>\n<li><ul>\n<li>1,</li>\n</ul>\n</li>\n<li><ul>\n<li>// Revision</li>\n</ul>\n</li>\n<li><ul>\n<li>ResourceTemplate(){Register(PCC, 32, 0, 0x120, 2)},</li>\n</ul>\n</li>\n<li><ul>\n<li>// Highest Performance</li>\n</ul>\n</li>\n<li><ul>\n<li>ResourceTemplate(){Register(PCC, 32, 0, 0x124, 2)},</li>\n</ul>\n</li>\n<li><ul>\n<li>// Nominal Performance</li>\n</ul>\n</li>\n<li><ul>\n<li>ResourceTemplate(){Register(PCC, 32, 0, 0x128, 2)},</li>\n</ul>\n</li>\n<li><ul>\n<li>// Lowest Nonlinear Performance</li>\n</ul>\n</li>\n<li><ul>\n<li>ResourceTemplate(){Register(PCC, 32, 0, 0x12C, 2)},</li>\n</ul>\n</li>\n<li><ul>\n<li>// Lowest Performance</li>\n</ul>\n</li>\n<li><ul>\n<li>ResourceTemplate(){Register(PCC, 32, 0, 0x130, 2)},</li>\n</ul>\n</li>\n<li><ul>\n<li>// Guaranteed Performance Register</li>\n</ul>\n</li>\n<li><ul>\n<li>ResourceTemplate(){Register(PCC, 32, 0, 0x110, 2)},</li>\n</ul>\n</li>\n<li><ul>\n<li>// Desired Performance Register</li>\n</ul>\n</li>\n<li><ul>\n<li>ResourceTemplate(){Register(SystemMemory, 0, 0, 0, 0)},</li>\n</ul>\n</li>\n<li><ul>\n<li>..</li>\n</ul>\n</li>\n<li><ul>\n<li>..</li>\n</ul>\n</li>\n<li><ul>\n<li>..</li>\n</ul>\n</li>\n<li><p>*</p>\n</li>\n<li><ul>\n<li>}</li>\n</ul>\n</li>\n<li><ul>\n<li>Each Register() encodes how to access that specific register.</li>\n</ul>\n</li>\n<li><ul>\n<li>e.g. a sample PCC entry has the following encoding:</li>\n</ul>\n</li>\n<li><p>*</p>\n</li>\n<li><ul>\n<li>Register (</li>\n</ul>\n</li>\n<li><ul>\n<li>PCC,</li>\n</ul>\n</li>\n<li><ul>\n<li>AddressSpaceKeyword</li>\n</ul>\n</li>\n<li><ul>\n<li>8,</li>\n</ul>\n</li>\n<li><ul>\n<li>//RegisterBitWidth</li>\n</ul>\n</li>\n<li><ul>\n<li>8,</li>\n</ul>\n</li>\n<li><ul>\n<li>//RegisterBitOffset</li>\n</ul>\n</li>\n<li><ul>\n<li>0x30,</li>\n</ul>\n</li>\n<li><ul>\n<li>//RegisterAddress</li>\n</ul>\n</li>\n<li><ul>\n<li>9</li>\n</ul>\n</li>\n<li><ul>\n<li>//AccessSize (subspace ID)</li>\n</ul>\n</li>\n<li><ul>\n<li>0</li>\n</ul>\n</li>\n<li><ul>\n<li>)</li>\n</ul>\n</li>\n<li><ul>\n<li>}</li>\n</ul>\n</li>\n<li><p>*/<br>那cppc表具体要怎么工作呢？具体在driver/cpufreq/cppc_cpufreq.c中。<br>这里的cppc_cpufreq_init是入口函数，这个函数向cpufreq的framework注册了一个可以调频的cpu driver</p>\n</li>\n<li><p>static int __init cppc_cpufreq_init(void)</p>\n</li>\n<li><p>{</p>\n</li>\n<li><p>ret = cpufreq_register_driver(&amp;cppc_cpufreq_driver);</p>\n</li>\n<li><p>if (ret)</p>\n</li>\n<li><p>goto out;</p>\n</li>\n<li><p>}</p>\n</li>\n<li><p>static struct cpufreq_driver cppc_cpufreq_driver = {</p>\n</li>\n<li><p>.flags = CPUFREQ_CONST_LOOPS,</p>\n</li>\n<li><p>.verify = cppc_verify_policy,</p>\n</li>\n<li><p>.target = cppc_cpufreq_set_target,</p>\n</li>\n<li><p>.get = cppc_cpufreq_get_rate,</p>\n</li>\n<li><p>.init = cppc_cpufreq_cpu_init,</p>\n</li>\n<li><p>.stop_cpu = cppc_cpufreq_stop_cpu,</p>\n</li>\n<li><p>.name = “cppc_cpufreq”,</p>\n</li>\n<li><p>};</p>\n</li>\n<li><p>//cppc_cpufreq_driver 最终的函数就是target，最终cpu调频就是通过target 这个回调函数来实现</p>\n</li>\n<li><p>static int cppc_cpufreq_set_target(struct cpufreq_policy *policy,</p>\n</li>\n<li><p>unsigned int target_freq,</p>\n</li>\n<li><p>unsigned int relation)</p>\n</li>\n<li><p>{</p>\n</li>\n<li><p>struct cppc_cpudata *cpu;</p>\n</li>\n<li><p>struct cpufreq_freqs freqs;</p>\n</li>\n<li><p>u32 desired_perf;</p>\n</li>\n<li><p>int ret = 0;</p>\n</li>\n<li><p>cpu = all_cpu_data[policy-&gt;cpu];</p>\n</li>\n<li><p>//得到要设置的频率</p>\n</li>\n<li><p>desired_perf = cppc_cpufreq_khz_to_perf(cpu, target_freq);</p>\n</li>\n<li><p>/* Return if it is exactly the same perf */</p>\n</li>\n<li><p>if (desired_perf == cpu-&gt;perf_ctrls.desired_perf)</p>\n</li>\n<li><p>return ret;</p>\n</li>\n<li><p>cpu-&gt;perf_ctrls.desired_perf = desired_perf;</p>\n</li>\n<li><p>freqs.old = policy-&gt;cur;</p>\n</li>\n<li><p>freqs.new = target_freq;</p>\n</li>\n<li><p>cpufreq_freq_transition_begin(policy, &amp;freqs);</p>\n</li>\n<li><p>//通过acpi 提供的的接口来设置cpu 频率</p>\n</li>\n<li><p>ret = cppc_set_perf(cpu-&gt;cpu, &amp;cpu-&gt;perf_ctrls);</p>\n</li>\n<li><p>cpufreq_freq_transition_end(policy, &amp;freqs, ret != 0);</p>\n</li>\n<li><p>if (ret)</p>\n</li>\n<li><p>pr_debug(“Failed to set target on CPU:%d. ret:%d\\n”,</p>\n</li>\n<li><p>cpu-&gt;cpu, ret);</p>\n</li>\n<li><p>return ret;</p>\n</li>\n<li><p>}<br>这里的cppc_set_perf实现在driver/acpi/cppc_acpi.c中实现，通过这个接口可以通过固件来设置cpu频率。</p>\n</li>\n</ol>\n"},{"title":"curl & wget","_content":"\n## Linux curl命令详解\n在Linux中curl是一个利用URL规则在命令行下工作的文件传输工具，可以说是一款很强大的http命令行工具。它支持文件的上传和下载，是综合传输工具，但按传统，习惯称url为下载工具。\n常见参数：\n\t-A/--user-agent <string>              设置用户代理发送给服务器\n\t-b/--cookie <name=string/file>    cookie字符串或文件读取位置\n\t-c/--cookie-jar <file>                    操作结束后把cookie写入到这个文件中\n\t-C/--continue-at <offset>            断点续转\n\t-D/--dump-header <file>              把header信息写入到该文件中\n\t-e/--referer                                  来源网址\n\t-f/--fail                                          连接失败时不显示http错误\n\t-o/--output                                  把输出写到该文件中\n\t-O/--remote-name                      把输出写到该文件中，保留远程文件的文件名\n\t-r/--range <range>                      检索来自HTTP/1.1或FTP服务器字节范围\n\t-s/--silent                                    静音模式。不输出任何东西\n\t-T/--upload-file <file>                  上传文件\n\t-u/--user <user[:password]>      设置服务器的用户和密码\n\t-w/--write-out [format]                什么输出完成后\n\t-x/--proxy <host[:port]>              在给定的端口上使用HTTP代理\n\t-#/--progress-bar                        进度条显示当前的传送状态\nwget更像一个迅雷，是个专门用来下载文件的下载利器.\n\n### 基本命令\n\tcurl -O http://man.linuxde.net/text.iso                    #O大写，不用O只是打印内容不会下载\n\twget http://www.linuxde.net/text.iso                       #不用参数，直接下载文件\n\troot@alpha:/home/test# curl -O http://man.linuxde.net/text.iso\n\t% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n\t\t\t\t\t\t\t\t\tDload  Upload   Total   Spent    Left  Speed\n\t100  6332  100  6332    0     0   441k      0 --:--:-- --:--:-- --:--:--  441k\n\troot@alpha:/home/test#\n\n### 保存网页\n\t$ curl http://www.linux.com >> linux.html\n\n### 下载文件\n\t$ curl -O http://man.linuxde.net/text.iso                    #O大写，不用O只是打印内容不会下载\n\t$ wget http://www.linuxde.net/text.iso                       #不用参数，直接下载文件\n\n### 下载文件并重命名\n\t$ curl -o rename.iso http://man.linuxde.net/text.iso         #o小写\n\t$ wget -O rename.zip http://www.linuxde.net/text.iso         #O大写\n\n### 断点续传\n在windows中，我们可以使用迅雷这样的软件进行断点续传。curl可以通过内置option:-C同样可以达到相同的效果\n如果在下载dodo1.JPG的过程中突然掉线了，可以使用以下的方式续传\n\tcurl -O -C -URL http://man.linuxde.net/text.iso            #C大写\n\twget -c http://www.linuxde.net/text.iso                    #c小写\n\n### 限速下载\n\t$ curl --limit-rate 50k -O http://man.linuxde.net/text.iso\n\t$ wget --limit-rate=50k http://www.linuxde.net/text.iso\n\n### 显示响应头部信息\n\t$ curl -I http://man.linuxde.net/text.iso\n\t$ wget --server-response http://www.linuxde.net/test.iso\n\n### wget利器--打包下载网站\n\t$ wget --mirror -p --convert-links -P /var/www/html http://man.linuxde.net/\n\n### -O(大写)保存网页中的文件, 要注意这里后面的url要具体到某个文件，不然抓不下来\n\t$ curl -O http://www.linux.com/hello.sh\n\n### -x来支持设置代理\n\t$ curl -x 192.168.100.100:1080 http://www.linux.com\t\n\n### 保存http的response里面的cookie信息。内置option:-c（小写）\n\t$ curl -c cookiec.txt  http://www.linux.com\n\n### 保存http的response里面的header信息。内置option: -D\n\t$ curl -D cookied.txt http://www.linux.com\n\n### 很多网站都是通过监视你的cookie信息来判断你是否按规矩访问他们的网站的，因此我们需要使用保存的cookie信息。内置option: -b\n\t$ curl -b cookiec.txt http://www.linux.com\n\n\n### 以服务器上的名称保存文件到本地: -O（大写)\n\t$ curl -O http://www.linux.com/dodo1.JPG\n\n### 循环下载\n\t$ curl -O http://www.linux.com/dodo[1-5].JPG\n\t$ curl -O http://www.linux.com/{hello,bb}/dodo[1-5].JPG\n\t下载http://www.linux.com/hello/dodo[1-5].JPG 和 http://www.linux.com/bb/dodo[1-5].JPG 文件\n\n### 显示进度条\n\t$ curl -# -O http://www.linux.com/dodo1.JPG\n\troot@alpha:/home/zhan/test# curl -# -O http://www.linux.com/dodo1.JPG\n\t####################################################################################### 100.0%\n\n\n### 上传文件\n\t$ curl -T dodo1.JPG -u 用户名:密码 ftp://www.linux.com/img/\n\n### Additional\n\n\troot@alpha:/home/zhan/images_test# curl 10.239.140.186:8081\n\tYou have hit fef0dd414fe4\n\troot@alpha:/home/zhan/images_test# wget 10.239.140.186:8081\n\t--2020-05-11 14:59:53--  http://10.239.140.186:8081/\n\tResolving child-prc.intel.com (child-prc.intel.com)... 10.239.4.100\n\tConnecting to child-prc.intel.com (child-prc.intel.com)|10.239.4.100|:913... connected.\n\tProxy request sent, awaiting response... 200 OK\n\tLength: unspecified\n\tSaving to: ‘index.html’\n\t\n\tindex.html                              [ <=>                                                                ]      24  --.-KB/s    in 0s\n\t\n\t2020-05-11 14:59:53 (3.27 MB/s) - ‘index.html’ saved [24]\n\t\n\troot@alpha:/home/zhan/images_test# ls\n\tindex.html\n\troot@alpha:/home/zhan/images_test# cat index.html\n\tYou have hit fef0dd414fe4\n\troot@alpha:/home/zhan/images_test#\n\n\n\n\n\n\n\n\n\n","source":"_posts/linux/curl_wget.md","raw":"---\ntitle: curl & wget\ntags: \ncategories:\n- linux\n---\n\n## Linux curl命令详解\n在Linux中curl是一个利用URL规则在命令行下工作的文件传输工具，可以说是一款很强大的http命令行工具。它支持文件的上传和下载，是综合传输工具，但按传统，习惯称url为下载工具。\n常见参数：\n\t-A/--user-agent <string>              设置用户代理发送给服务器\n\t-b/--cookie <name=string/file>    cookie字符串或文件读取位置\n\t-c/--cookie-jar <file>                    操作结束后把cookie写入到这个文件中\n\t-C/--continue-at <offset>            断点续转\n\t-D/--dump-header <file>              把header信息写入到该文件中\n\t-e/--referer                                  来源网址\n\t-f/--fail                                          连接失败时不显示http错误\n\t-o/--output                                  把输出写到该文件中\n\t-O/--remote-name                      把输出写到该文件中，保留远程文件的文件名\n\t-r/--range <range>                      检索来自HTTP/1.1或FTP服务器字节范围\n\t-s/--silent                                    静音模式。不输出任何东西\n\t-T/--upload-file <file>                  上传文件\n\t-u/--user <user[:password]>      设置服务器的用户和密码\n\t-w/--write-out [format]                什么输出完成后\n\t-x/--proxy <host[:port]>              在给定的端口上使用HTTP代理\n\t-#/--progress-bar                        进度条显示当前的传送状态\nwget更像一个迅雷，是个专门用来下载文件的下载利器.\n\n### 基本命令\n\tcurl -O http://man.linuxde.net/text.iso                    #O大写，不用O只是打印内容不会下载\n\twget http://www.linuxde.net/text.iso                       #不用参数，直接下载文件\n\troot@alpha:/home/test# curl -O http://man.linuxde.net/text.iso\n\t% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n\t\t\t\t\t\t\t\t\tDload  Upload   Total   Spent    Left  Speed\n\t100  6332  100  6332    0     0   441k      0 --:--:-- --:--:-- --:--:--  441k\n\troot@alpha:/home/test#\n\n### 保存网页\n\t$ curl http://www.linux.com >> linux.html\n\n### 下载文件\n\t$ curl -O http://man.linuxde.net/text.iso                    #O大写，不用O只是打印内容不会下载\n\t$ wget http://www.linuxde.net/text.iso                       #不用参数，直接下载文件\n\n### 下载文件并重命名\n\t$ curl -o rename.iso http://man.linuxde.net/text.iso         #o小写\n\t$ wget -O rename.zip http://www.linuxde.net/text.iso         #O大写\n\n### 断点续传\n在windows中，我们可以使用迅雷这样的软件进行断点续传。curl可以通过内置option:-C同样可以达到相同的效果\n如果在下载dodo1.JPG的过程中突然掉线了，可以使用以下的方式续传\n\tcurl -O -C -URL http://man.linuxde.net/text.iso            #C大写\n\twget -c http://www.linuxde.net/text.iso                    #c小写\n\n### 限速下载\n\t$ curl --limit-rate 50k -O http://man.linuxde.net/text.iso\n\t$ wget --limit-rate=50k http://www.linuxde.net/text.iso\n\n### 显示响应头部信息\n\t$ curl -I http://man.linuxde.net/text.iso\n\t$ wget --server-response http://www.linuxde.net/test.iso\n\n### wget利器--打包下载网站\n\t$ wget --mirror -p --convert-links -P /var/www/html http://man.linuxde.net/\n\n### -O(大写)保存网页中的文件, 要注意这里后面的url要具体到某个文件，不然抓不下来\n\t$ curl -O http://www.linux.com/hello.sh\n\n### -x来支持设置代理\n\t$ curl -x 192.168.100.100:1080 http://www.linux.com\t\n\n### 保存http的response里面的cookie信息。内置option:-c（小写）\n\t$ curl -c cookiec.txt  http://www.linux.com\n\n### 保存http的response里面的header信息。内置option: -D\n\t$ curl -D cookied.txt http://www.linux.com\n\n### 很多网站都是通过监视你的cookie信息来判断你是否按规矩访问他们的网站的，因此我们需要使用保存的cookie信息。内置option: -b\n\t$ curl -b cookiec.txt http://www.linux.com\n\n\n### 以服务器上的名称保存文件到本地: -O（大写)\n\t$ curl -O http://www.linux.com/dodo1.JPG\n\n### 循环下载\n\t$ curl -O http://www.linux.com/dodo[1-5].JPG\n\t$ curl -O http://www.linux.com/{hello,bb}/dodo[1-5].JPG\n\t下载http://www.linux.com/hello/dodo[1-5].JPG 和 http://www.linux.com/bb/dodo[1-5].JPG 文件\n\n### 显示进度条\n\t$ curl -# -O http://www.linux.com/dodo1.JPG\n\troot@alpha:/home/zhan/test# curl -# -O http://www.linux.com/dodo1.JPG\n\t####################################################################################### 100.0%\n\n\n### 上传文件\n\t$ curl -T dodo1.JPG -u 用户名:密码 ftp://www.linux.com/img/\n\n### Additional\n\n\troot@alpha:/home/zhan/images_test# curl 10.239.140.186:8081\n\tYou have hit fef0dd414fe4\n\troot@alpha:/home/zhan/images_test# wget 10.239.140.186:8081\n\t--2020-05-11 14:59:53--  http://10.239.140.186:8081/\n\tResolving child-prc.intel.com (child-prc.intel.com)... 10.239.4.100\n\tConnecting to child-prc.intel.com (child-prc.intel.com)|10.239.4.100|:913... connected.\n\tProxy request sent, awaiting response... 200 OK\n\tLength: unspecified\n\tSaving to: ‘index.html’\n\t\n\tindex.html                              [ <=>                                                                ]      24  --.-KB/s    in 0s\n\t\n\t2020-05-11 14:59:53 (3.27 MB/s) - ‘index.html’ saved [24]\n\t\n\troot@alpha:/home/zhan/images_test# ls\n\tindex.html\n\troot@alpha:/home/zhan/images_test# cat index.html\n\tYou have hit fef0dd414fe4\n\troot@alpha:/home/zhan/images_test#\n\n\n\n\n\n\n\n\n\n","slug":"linux/curl_wget","published":1,"date":"2020-08-12T16:05:46.133Z","updated":"2020-05-11T14:21:47.208Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmet0021hohxcrx12shh","content":"<h2 id=\"Linux-curl命令详解\"><a href=\"#Linux-curl命令详解\" class=\"headerlink\" title=\"Linux curl命令详解\"></a>Linux curl命令详解</h2><p>在Linux中curl是一个利用URL规则在命令行下工作的文件传输工具，可以说是一款很强大的http命令行工具。它支持文件的上传和下载，是综合传输工具，但按传统，习惯称url为下载工具。<br>常见参数：<br>    -A/–user-agent <string>              设置用户代理发送给服务器<br>    -b/–cookie &lt;name=string/file&gt;    cookie字符串或文件读取位置<br>    -c/–cookie-jar <file>                    操作结束后把cookie写入到这个文件中<br>    -C/–continue-at <offset>            断点续转<br>    -D/–dump-header <file>              把header信息写入到该文件中<br>    -e/–referer                                  来源网址<br>    -f/–fail                                          连接失败时不显示http错误<br>    -o/–output                                  把输出写到该文件中<br>    -O/–remote-name                      把输出写到该文件中，保留远程文件的文件名<br>    -r/–range <range>                      检索来自HTTP/1.1或FTP服务器字节范围<br>    -s/–silent                                    静音模式。不输出任何东西<br>    -T/–upload-file <file>                  上传文件<br>    -u/–user &lt;user[:password]&gt;      设置服务器的用户和密码<br>    -w/–write-out [format]                什么输出完成后<br>    -x/–proxy &lt;host[:port]&gt;              在给定的端口上使用HTTP代理<br>    -#/–progress-bar                        进度条显示当前的传送状态<br>wget更像一个迅雷，是个专门用来下载文件的下载利器.</p>\n<h3 id=\"基本命令\"><a href=\"#基本命令\" class=\"headerlink\" title=\"基本命令\"></a>基本命令</h3><pre><code>curl -O http://man.linuxde.net/text.iso                    #O大写，不用O只是打印内容不会下载\nwget http://www.linuxde.net/text.iso                       #不用参数，直接下载文件\nroot@alpha:/home/test# curl -O http://man.linuxde.net/text.iso\n% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                Dload  Upload   Total   Spent    Left  Speed\n100  6332  100  6332    0     0   441k      0 --:--:-- --:--:-- --:--:--  441k\nroot@alpha:/home/test#</code></pre><h3 id=\"保存网页\"><a href=\"#保存网页\" class=\"headerlink\" title=\"保存网页\"></a>保存网页</h3><pre><code>$ curl http://www.linux.com &gt;&gt; linux.html</code></pre><h3 id=\"下载文件\"><a href=\"#下载文件\" class=\"headerlink\" title=\"下载文件\"></a>下载文件</h3><pre><code>$ curl -O http://man.linuxde.net/text.iso                    #O大写，不用O只是打印内容不会下载\n$ wget http://www.linuxde.net/text.iso                       #不用参数，直接下载文件</code></pre><h3 id=\"下载文件并重命名\"><a href=\"#下载文件并重命名\" class=\"headerlink\" title=\"下载文件并重命名\"></a>下载文件并重命名</h3><pre><code>$ curl -o rename.iso http://man.linuxde.net/text.iso         #o小写\n$ wget -O rename.zip http://www.linuxde.net/text.iso         #O大写</code></pre><h3 id=\"断点续传\"><a href=\"#断点续传\" class=\"headerlink\" title=\"断点续传\"></a>断点续传</h3><p>在windows中，我们可以使用迅雷这样的软件进行断点续传。curl可以通过内置option:-C同样可以达到相同的效果<br>如果在下载dodo1.JPG的过程中突然掉线了，可以使用以下的方式续传<br>    curl -O -C -URL <a href=\"http://man.linuxde.net/text.iso\" target=\"_blank\" rel=\"noopener\">http://man.linuxde.net/text.iso</a>            #C大写<br>    wget -c <a href=\"http://www.linuxde.net/text.iso\" target=\"_blank\" rel=\"noopener\">http://www.linuxde.net/text.iso</a>                    #c小写</p>\n<h3 id=\"限速下载\"><a href=\"#限速下载\" class=\"headerlink\" title=\"限速下载\"></a>限速下载</h3><pre><code>$ curl --limit-rate 50k -O http://man.linuxde.net/text.iso\n$ wget --limit-rate=50k http://www.linuxde.net/text.iso</code></pre><h3 id=\"显示响应头部信息\"><a href=\"#显示响应头部信息\" class=\"headerlink\" title=\"显示响应头部信息\"></a>显示响应头部信息</h3><pre><code>$ curl -I http://man.linuxde.net/text.iso\n$ wget --server-response http://www.linuxde.net/test.iso</code></pre><h3 id=\"wget利器–打包下载网站\"><a href=\"#wget利器–打包下载网站\" class=\"headerlink\" title=\"wget利器–打包下载网站\"></a>wget利器–打包下载网站</h3><pre><code>$ wget --mirror -p --convert-links -P /var/www/html http://man.linuxde.net/</code></pre><h3 id=\"O-大写-保存网页中的文件-要注意这里后面的url要具体到某个文件，不然抓不下来\"><a href=\"#O-大写-保存网页中的文件-要注意这里后面的url要具体到某个文件，不然抓不下来\" class=\"headerlink\" title=\"-O(大写)保存网页中的文件, 要注意这里后面的url要具体到某个文件，不然抓不下来\"></a>-O(大写)保存网页中的文件, 要注意这里后面的url要具体到某个文件，不然抓不下来</h3><pre><code>$ curl -O http://www.linux.com/hello.sh</code></pre><h3 id=\"x来支持设置代理\"><a href=\"#x来支持设置代理\" class=\"headerlink\" title=\"-x来支持设置代理\"></a>-x来支持设置代理</h3><pre><code>$ curl -x 192.168.100.100:1080 http://www.linux.com    </code></pre><h3 id=\"保存http的response里面的cookie信息。内置option-c（小写）\"><a href=\"#保存http的response里面的cookie信息。内置option-c（小写）\" class=\"headerlink\" title=\"保存http的response里面的cookie信息。内置option:-c（小写）\"></a>保存http的response里面的cookie信息。内置option:-c（小写）</h3><pre><code>$ curl -c cookiec.txt  http://www.linux.com</code></pre><h3 id=\"保存http的response里面的header信息。内置option-D\"><a href=\"#保存http的response里面的header信息。内置option-D\" class=\"headerlink\" title=\"保存http的response里面的header信息。内置option: -D\"></a>保存http的response里面的header信息。内置option: -D</h3><pre><code>$ curl -D cookied.txt http://www.linux.com</code></pre><h3 id=\"很多网站都是通过监视你的cookie信息来判断你是否按规矩访问他们的网站的，因此我们需要使用保存的cookie信息。内置option-b\"><a href=\"#很多网站都是通过监视你的cookie信息来判断你是否按规矩访问他们的网站的，因此我们需要使用保存的cookie信息。内置option-b\" class=\"headerlink\" title=\"很多网站都是通过监视你的cookie信息来判断你是否按规矩访问他们的网站的，因此我们需要使用保存的cookie信息。内置option: -b\"></a>很多网站都是通过监视你的cookie信息来判断你是否按规矩访问他们的网站的，因此我们需要使用保存的cookie信息。内置option: -b</h3><pre><code>$ curl -b cookiec.txt http://www.linux.com</code></pre><h3 id=\"以服务器上的名称保存文件到本地-O（大写\"><a href=\"#以服务器上的名称保存文件到本地-O（大写\" class=\"headerlink\" title=\"以服务器上的名称保存文件到本地: -O（大写)\"></a>以服务器上的名称保存文件到本地: -O（大写)</h3><pre><code>$ curl -O http://www.linux.com/dodo1.JPG</code></pre><h3 id=\"循环下载\"><a href=\"#循环下载\" class=\"headerlink\" title=\"循环下载\"></a>循环下载</h3><pre><code>$ curl -O http://www.linux.com/dodo[1-5].JPG\n$ curl -O http://www.linux.com/{hello,bb}/dodo[1-5].JPG\n下载http://www.linux.com/hello/dodo[1-5].JPG 和 http://www.linux.com/bb/dodo[1-5].JPG 文件</code></pre><h3 id=\"显示进度条\"><a href=\"#显示进度条\" class=\"headerlink\" title=\"显示进度条\"></a>显示进度条</h3><pre><code>$ curl -# -O http://www.linux.com/dodo1.JPG\nroot@alpha:/home/zhan/test# curl -# -O http://www.linux.com/dodo1.JPG\n####################################################################################### 100.0%</code></pre><h3 id=\"上传文件\"><a href=\"#上传文件\" class=\"headerlink\" title=\"上传文件\"></a>上传文件</h3><pre><code>$ curl -T dodo1.JPG -u 用户名:密码 ftp://www.linux.com/img/</code></pre><h3 id=\"Additional\"><a href=\"#Additional\" class=\"headerlink\" title=\"Additional\"></a>Additional</h3><pre><code>root@alpha:/home/zhan/images_test# curl 10.239.140.186:8081\nYou have hit fef0dd414fe4\nroot@alpha:/home/zhan/images_test# wget 10.239.140.186:8081\n--2020-05-11 14:59:53--  http://10.239.140.186:8081/\nResolving child-prc.intel.com (child-prc.intel.com)... 10.239.4.100\nConnecting to child-prc.intel.com (child-prc.intel.com)|10.239.4.100|:913... connected.\nProxy request sent, awaiting response... 200 OK\nLength: unspecified\nSaving to: ‘index.html’\n\nindex.html                              [ &lt;=&gt;                                                                ]      24  --.-KB/s    in 0s\n\n2020-05-11 14:59:53 (3.27 MB/s) - ‘index.html’ saved [24]\n\nroot@alpha:/home/zhan/images_test# ls\nindex.html\nroot@alpha:/home/zhan/images_test# cat index.html\nYou have hit fef0dd414fe4\nroot@alpha:/home/zhan/images_test#</code></pre>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Linux-curl命令详解\"><a href=\"#Linux-curl命令详解\" class=\"headerlink\" title=\"Linux curl命令详解\"></a>Linux curl命令详解</h2><p>在Linux中curl是一个利用URL规则在命令行下工作的文件传输工具，可以说是一款很强大的http命令行工具。它支持文件的上传和下载，是综合传输工具，但按传统，习惯称url为下载工具。<br>常见参数：<br>    -A/–user-agent <string>              设置用户代理发送给服务器<br>    -b/–cookie &lt;name=string/file&gt;    cookie字符串或文件读取位置<br>    -c/–cookie-jar <file>                    操作结束后把cookie写入到这个文件中<br>    -C/–continue-at <offset>            断点续转<br>    -D/–dump-header <file>              把header信息写入到该文件中<br>    -e/–referer                                  来源网址<br>    -f/–fail                                          连接失败时不显示http错误<br>    -o/–output                                  把输出写到该文件中<br>    -O/–remote-name                      把输出写到该文件中，保留远程文件的文件名<br>    -r/–range <range>                      检索来自HTTP/1.1或FTP服务器字节范围<br>    -s/–silent                                    静音模式。不输出任何东西<br>    -T/–upload-file <file>                  上传文件<br>    -u/–user &lt;user[:password]&gt;      设置服务器的用户和密码<br>    -w/–write-out [format]                什么输出完成后<br>    -x/–proxy &lt;host[:port]&gt;              在给定的端口上使用HTTP代理<br>    -#/–progress-bar                        进度条显示当前的传送状态<br>wget更像一个迅雷，是个专门用来下载文件的下载利器.</p>\n<h3 id=\"基本命令\"><a href=\"#基本命令\" class=\"headerlink\" title=\"基本命令\"></a>基本命令</h3><pre><code>curl -O http://man.linuxde.net/text.iso                    #O大写，不用O只是打印内容不会下载\nwget http://www.linuxde.net/text.iso                       #不用参数，直接下载文件\nroot@alpha:/home/test# curl -O http://man.linuxde.net/text.iso\n% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                Dload  Upload   Total   Spent    Left  Speed\n100  6332  100  6332    0     0   441k      0 --:--:-- --:--:-- --:--:--  441k\nroot@alpha:/home/test#</code></pre><h3 id=\"保存网页\"><a href=\"#保存网页\" class=\"headerlink\" title=\"保存网页\"></a>保存网页</h3><pre><code>$ curl http://www.linux.com &gt;&gt; linux.html</code></pre><h3 id=\"下载文件\"><a href=\"#下载文件\" class=\"headerlink\" title=\"下载文件\"></a>下载文件</h3><pre><code>$ curl -O http://man.linuxde.net/text.iso                    #O大写，不用O只是打印内容不会下载\n$ wget http://www.linuxde.net/text.iso                       #不用参数，直接下载文件</code></pre><h3 id=\"下载文件并重命名\"><a href=\"#下载文件并重命名\" class=\"headerlink\" title=\"下载文件并重命名\"></a>下载文件并重命名</h3><pre><code>$ curl -o rename.iso http://man.linuxde.net/text.iso         #o小写\n$ wget -O rename.zip http://www.linuxde.net/text.iso         #O大写</code></pre><h3 id=\"断点续传\"><a href=\"#断点续传\" class=\"headerlink\" title=\"断点续传\"></a>断点续传</h3><p>在windows中，我们可以使用迅雷这样的软件进行断点续传。curl可以通过内置option:-C同样可以达到相同的效果<br>如果在下载dodo1.JPG的过程中突然掉线了，可以使用以下的方式续传<br>    curl -O -C -URL <a href=\"http://man.linuxde.net/text.iso\" target=\"_blank\" rel=\"noopener\">http://man.linuxde.net/text.iso</a>            #C大写<br>    wget -c <a href=\"http://www.linuxde.net/text.iso\" target=\"_blank\" rel=\"noopener\">http://www.linuxde.net/text.iso</a>                    #c小写</p>\n<h3 id=\"限速下载\"><a href=\"#限速下载\" class=\"headerlink\" title=\"限速下载\"></a>限速下载</h3><pre><code>$ curl --limit-rate 50k -O http://man.linuxde.net/text.iso\n$ wget --limit-rate=50k http://www.linuxde.net/text.iso</code></pre><h3 id=\"显示响应头部信息\"><a href=\"#显示响应头部信息\" class=\"headerlink\" title=\"显示响应头部信息\"></a>显示响应头部信息</h3><pre><code>$ curl -I http://man.linuxde.net/text.iso\n$ wget --server-response http://www.linuxde.net/test.iso</code></pre><h3 id=\"wget利器–打包下载网站\"><a href=\"#wget利器–打包下载网站\" class=\"headerlink\" title=\"wget利器–打包下载网站\"></a>wget利器–打包下载网站</h3><pre><code>$ wget --mirror -p --convert-links -P /var/www/html http://man.linuxde.net/</code></pre><h3 id=\"O-大写-保存网页中的文件-要注意这里后面的url要具体到某个文件，不然抓不下来\"><a href=\"#O-大写-保存网页中的文件-要注意这里后面的url要具体到某个文件，不然抓不下来\" class=\"headerlink\" title=\"-O(大写)保存网页中的文件, 要注意这里后面的url要具体到某个文件，不然抓不下来\"></a>-O(大写)保存网页中的文件, 要注意这里后面的url要具体到某个文件，不然抓不下来</h3><pre><code>$ curl -O http://www.linux.com/hello.sh</code></pre><h3 id=\"x来支持设置代理\"><a href=\"#x来支持设置代理\" class=\"headerlink\" title=\"-x来支持设置代理\"></a>-x来支持设置代理</h3><pre><code>$ curl -x 192.168.100.100:1080 http://www.linux.com    </code></pre><h3 id=\"保存http的response里面的cookie信息。内置option-c（小写）\"><a href=\"#保存http的response里面的cookie信息。内置option-c（小写）\" class=\"headerlink\" title=\"保存http的response里面的cookie信息。内置option:-c（小写）\"></a>保存http的response里面的cookie信息。内置option:-c（小写）</h3><pre><code>$ curl -c cookiec.txt  http://www.linux.com</code></pre><h3 id=\"保存http的response里面的header信息。内置option-D\"><a href=\"#保存http的response里面的header信息。内置option-D\" class=\"headerlink\" title=\"保存http的response里面的header信息。内置option: -D\"></a>保存http的response里面的header信息。内置option: -D</h3><pre><code>$ curl -D cookied.txt http://www.linux.com</code></pre><h3 id=\"很多网站都是通过监视你的cookie信息来判断你是否按规矩访问他们的网站的，因此我们需要使用保存的cookie信息。内置option-b\"><a href=\"#很多网站都是通过监视你的cookie信息来判断你是否按规矩访问他们的网站的，因此我们需要使用保存的cookie信息。内置option-b\" class=\"headerlink\" title=\"很多网站都是通过监视你的cookie信息来判断你是否按规矩访问他们的网站的，因此我们需要使用保存的cookie信息。内置option: -b\"></a>很多网站都是通过监视你的cookie信息来判断你是否按规矩访问他们的网站的，因此我们需要使用保存的cookie信息。内置option: -b</h3><pre><code>$ curl -b cookiec.txt http://www.linux.com</code></pre><h3 id=\"以服务器上的名称保存文件到本地-O（大写\"><a href=\"#以服务器上的名称保存文件到本地-O（大写\" class=\"headerlink\" title=\"以服务器上的名称保存文件到本地: -O（大写)\"></a>以服务器上的名称保存文件到本地: -O（大写)</h3><pre><code>$ curl -O http://www.linux.com/dodo1.JPG</code></pre><h3 id=\"循环下载\"><a href=\"#循环下载\" class=\"headerlink\" title=\"循环下载\"></a>循环下载</h3><pre><code>$ curl -O http://www.linux.com/dodo[1-5].JPG\n$ curl -O http://www.linux.com/{hello,bb}/dodo[1-5].JPG\n下载http://www.linux.com/hello/dodo[1-5].JPG 和 http://www.linux.com/bb/dodo[1-5].JPG 文件</code></pre><h3 id=\"显示进度条\"><a href=\"#显示进度条\" class=\"headerlink\" title=\"显示进度条\"></a>显示进度条</h3><pre><code>$ curl -# -O http://www.linux.com/dodo1.JPG\nroot@alpha:/home/zhan/test# curl -# -O http://www.linux.com/dodo1.JPG\n####################################################################################### 100.0%</code></pre><h3 id=\"上传文件\"><a href=\"#上传文件\" class=\"headerlink\" title=\"上传文件\"></a>上传文件</h3><pre><code>$ curl -T dodo1.JPG -u 用户名:密码 ftp://www.linux.com/img/</code></pre><h3 id=\"Additional\"><a href=\"#Additional\" class=\"headerlink\" title=\"Additional\"></a>Additional</h3><pre><code>root@alpha:/home/zhan/images_test# curl 10.239.140.186:8081\nYou have hit fef0dd414fe4\nroot@alpha:/home/zhan/images_test# wget 10.239.140.186:8081\n--2020-05-11 14:59:53--  http://10.239.140.186:8081/\nResolving child-prc.intel.com (child-prc.intel.com)... 10.239.4.100\nConnecting to child-prc.intel.com (child-prc.intel.com)|10.239.4.100|:913... connected.\nProxy request sent, awaiting response... 200 OK\nLength: unspecified\nSaving to: ‘index.html’\n\nindex.html                              [ &lt;=&gt;                                                                ]      24  --.-KB/s    in 0s\n\n2020-05-11 14:59:53 (3.27 MB/s) - ‘index.html’ saved [24]\n\nroot@alpha:/home/zhan/images_test# ls\nindex.html\nroot@alpha:/home/zhan/images_test# cat index.html\nYou have hit fef0dd414fe4\nroot@alpha:/home/zhan/images_test#</code></pre>"},{"title":"dd","_content":"\n## \n\nLinux dd 命令用于读取、转换并输出数据。\ndd可从标准输入或文件中读取数据，根据指定的格式来转换数据，再输出到文件、设备或标准输出。\n\n参数说明:\nif=文件名：输入文件名，默认为标准输入。即指定源文件。\nof=文件名：输出文件名，默认为标准输出。即指定目的文件。\n\nbs=bytes：同时设置读入/输出的块大小为bytes个字节\n\nconv=<关键字>，关键字可以有以下11种：\n  conversion：用指定的参数转换文件。\n  ascii：转换ebcdic为ascii\n  ebcdic：转换ascii为ebcdic\n  ibm：转换ascii为alternate ebcdic\n  block：把每一行转换为长度为cbs，不足部分用空格填充\n  unblock：使每一行的长度都为cbs，不足部分用空格填充\n  lcase：把大写字符转换为小写字符\n  ucase：把小写字符转换为大写字符\n  swab：交换输入的每对字节\n  noerror：出错时不停止\n  notrunc：不截短输出文件\n  sync：将每个输入块填充到ibs个字节，不足部分用空（NUL）字符补齐。\n\n--help：显示帮助信息\n--version：显示版本信息\n\n### 实例\n\n在Linux 下制作启动盘，可使用如下命令：\n\n\t$ dd if=boot.img of=/dev/fd0 bs=1440k\n\n将testfile文件中的所有英文字母转换为大写，然后转成为testfile_1文件，在命令提示符中使用如下命令：\n\n\t$ dd if=testfile_2 of=testfile_1 conv=ucase \n\n由标准输入设备读入字符串，并将字符串转换成大写后，再输出到标准输出设备\n\n\t$ dd conv=ucase \n输入以上命令后按回车键，输入字符串，再按回车键，按组合键Ctrl+D 退出\n\n\t$ dd conv=ucase \n\thello\t\t// 输入字符串后按回车键  \n\tHELLO\t\t// 按组合键Ctrl+D才会输出并退出，转换成大写结果  \n\t0+1 records in\n\t0+1 records out\n\t6 bytes (6 B) copied, 5.79589 s, 0.0 kB/s\n\n\n\n\n","source":"_posts/linux/dd_command.md","raw":"---\ntitle: dd\ntags: \ncategories:\n- linux\n---\n\n## \n\nLinux dd 命令用于读取、转换并输出数据。\ndd可从标准输入或文件中读取数据，根据指定的格式来转换数据，再输出到文件、设备或标准输出。\n\n参数说明:\nif=文件名：输入文件名，默认为标准输入。即指定源文件。\nof=文件名：输出文件名，默认为标准输出。即指定目的文件。\n\nbs=bytes：同时设置读入/输出的块大小为bytes个字节\n\nconv=<关键字>，关键字可以有以下11种：\n  conversion：用指定的参数转换文件。\n  ascii：转换ebcdic为ascii\n  ebcdic：转换ascii为ebcdic\n  ibm：转换ascii为alternate ebcdic\n  block：把每一行转换为长度为cbs，不足部分用空格填充\n  unblock：使每一行的长度都为cbs，不足部分用空格填充\n  lcase：把大写字符转换为小写字符\n  ucase：把小写字符转换为大写字符\n  swab：交换输入的每对字节\n  noerror：出错时不停止\n  notrunc：不截短输出文件\n  sync：将每个输入块填充到ibs个字节，不足部分用空（NUL）字符补齐。\n\n--help：显示帮助信息\n--version：显示版本信息\n\n### 实例\n\n在Linux 下制作启动盘，可使用如下命令：\n\n\t$ dd if=boot.img of=/dev/fd0 bs=1440k\n\n将testfile文件中的所有英文字母转换为大写，然后转成为testfile_1文件，在命令提示符中使用如下命令：\n\n\t$ dd if=testfile_2 of=testfile_1 conv=ucase \n\n由标准输入设备读入字符串，并将字符串转换成大写后，再输出到标准输出设备\n\n\t$ dd conv=ucase \n输入以上命令后按回车键，输入字符串，再按回车键，按组合键Ctrl+D 退出\n\n\t$ dd conv=ucase \n\thello\t\t// 输入字符串后按回车键  \n\tHELLO\t\t// 按组合键Ctrl+D才会输出并退出，转换成大写结果  \n\t0+1 records in\n\t0+1 records out\n\t6 bytes (6 B) copied, 5.79589 s, 0.0 kB/s\n\n\n\n\n","slug":"linux/dd_command","published":1,"date":"2020-08-12T16:05:46.138Z","updated":"2020-06-09T06:51:10.972Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmex0023hohx8kl4b11f","content":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Linux dd 命令用于读取、转换并输出数据。<br>dd可从标准输入或文件中读取数据，根据指定的格式来转换数据，再输出到文件、设备或标准输出。</p>\n<p>参数说明:<br>if=文件名：输入文件名，默认为标准输入。即指定源文件。<br>of=文件名：输出文件名，默认为标准输出。即指定目的文件。</p>\n<p>bs=bytes：同时设置读入/输出的块大小为bytes个字节</p>\n<p>conv=&lt;关键字&gt;，关键字可以有以下11种：<br>  conversion：用指定的参数转换文件。<br>  ascii：转换ebcdic为ascii<br>  ebcdic：转换ascii为ebcdic<br>  ibm：转换ascii为alternate ebcdic<br>  block：把每一行转换为长度为cbs，不足部分用空格填充<br>  unblock：使每一行的长度都为cbs，不足部分用空格填充<br>  lcase：把大写字符转换为小写字符<br>  ucase：把小写字符转换为大写字符<br>  swab：交换输入的每对字节<br>  noerror：出错时不停止<br>  notrunc：不截短输出文件<br>  sync：将每个输入块填充到ibs个字节，不足部分用空（NUL）字符补齐。</p>\n<p>–help：显示帮助信息<br>–version：显示版本信息</p>\n<h3 id=\"实例\"><a href=\"#实例\" class=\"headerlink\" title=\"实例\"></a>实例</h3><p>在Linux 下制作启动盘，可使用如下命令：</p>\n<pre><code>$ dd if=boot.img of=/dev/fd0 bs=1440k</code></pre><p>将testfile文件中的所有英文字母转换为大写，然后转成为testfile_1文件，在命令提示符中使用如下命令：</p>\n<pre><code>$ dd if=testfile_2 of=testfile_1 conv=ucase </code></pre><p>由标准输入设备读入字符串，并将字符串转换成大写后，再输出到标准输出设备</p>\n<pre><code>$ dd conv=ucase </code></pre><p>输入以上命令后按回车键，输入字符串，再按回车键，按组合键Ctrl+D 退出</p>\n<pre><code>$ dd conv=ucase \nhello        // 输入字符串后按回车键  \nHELLO        // 按组合键Ctrl+D才会输出并退出，转换成大写结果  \n0+1 records in\n0+1 records out\n6 bytes (6 B) copied, 5.79589 s, 0.0 kB/s</code></pre>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Linux dd 命令用于读取、转换并输出数据。<br>dd可从标准输入或文件中读取数据，根据指定的格式来转换数据，再输出到文件、设备或标准输出。</p>\n<p>参数说明:<br>if=文件名：输入文件名，默认为标准输入。即指定源文件。<br>of=文件名：输出文件名，默认为标准输出。即指定目的文件。</p>\n<p>bs=bytes：同时设置读入/输出的块大小为bytes个字节</p>\n<p>conv=&lt;关键字&gt;，关键字可以有以下11种：<br>  conversion：用指定的参数转换文件。<br>  ascii：转换ebcdic为ascii<br>  ebcdic：转换ascii为ebcdic<br>  ibm：转换ascii为alternate ebcdic<br>  block：把每一行转换为长度为cbs，不足部分用空格填充<br>  unblock：使每一行的长度都为cbs，不足部分用空格填充<br>  lcase：把大写字符转换为小写字符<br>  ucase：把小写字符转换为大写字符<br>  swab：交换输入的每对字节<br>  noerror：出错时不停止<br>  notrunc：不截短输出文件<br>  sync：将每个输入块填充到ibs个字节，不足部分用空（NUL）字符补齐。</p>\n<p>–help：显示帮助信息<br>–version：显示版本信息</p>\n<h3 id=\"实例\"><a href=\"#实例\" class=\"headerlink\" title=\"实例\"></a>实例</h3><p>在Linux 下制作启动盘，可使用如下命令：</p>\n<pre><code>$ dd if=boot.img of=/dev/fd0 bs=1440k</code></pre><p>将testfile文件中的所有英文字母转换为大写，然后转成为testfile_1文件，在命令提示符中使用如下命令：</p>\n<pre><code>$ dd if=testfile_2 of=testfile_1 conv=ucase </code></pre><p>由标准输入设备读入字符串，并将字符串转换成大写后，再输出到标准输出设备</p>\n<pre><code>$ dd conv=ucase </code></pre><p>输入以上命令后按回车键，输入字符串，再按回车键，按组合键Ctrl+D 退出</p>\n<pre><code>$ dd conv=ucase \nhello        // 输入字符串后按回车键  \nHELLO        // 按组合键Ctrl+D才会输出并退出，转换成大写结果  \n0+1 records in\n0+1 records out\n6 bytes (6 B) copied, 5.79589 s, 0.0 kB/s</code></pre>"},{"title":"dmidecode","tages":null,"_content":"查看服务器型号：dmidecode | grep \"Product Name\"\n查看主板的序列号：dmidecode | grep \"Serial Number\"\n查看系统序列号：dmidecode -s system-serial-number\n查看内存信息：dmidecode -t memory\n查看OEM信息：dmidecode -t 11\n不带选项执行dmidecode命令通常会输出所有的硬件信息。dmidecode命令有个很有用的选项-t，可以按指定类型输出相关信息，假如要获得处理器方面的信息，则可以执行：\n[root@localhost ~]# dmidecode -t processor\n","source":"_posts/linux/dmidecode.md","raw":"---\ntitle: dmidecode\ntages:\ncategories:\n- linux \n---\n查看服务器型号：dmidecode | grep \"Product Name\"\n查看主板的序列号：dmidecode | grep \"Serial Number\"\n查看系统序列号：dmidecode -s system-serial-number\n查看内存信息：dmidecode -t memory\n查看OEM信息：dmidecode -t 11\n不带选项执行dmidecode命令通常会输出所有的硬件信息。dmidecode命令有个很有用的选项-t，可以按指定类型输出相关信息，假如要获得处理器方面的信息，则可以执行：\n[root@localhost ~]# dmidecode -t processor\n","slug":"linux/dmidecode","published":1,"date":"2020-08-12T16:05:46.150Z","updated":"2020-02-13T12:47:44.470Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmf10026hohx8t2nc56b","content":"<p>查看服务器型号：dmidecode | grep “Product Name”<br>查看主板的序列号：dmidecode | grep “Serial Number”<br>查看系统序列号：dmidecode -s system-serial-number<br>查看内存信息：dmidecode -t memory<br>查看OEM信息：dmidecode -t 11<br>不带选项执行dmidecode命令通常会输出所有的硬件信息。dmidecode命令有个很有用的选项-t，可以按指定类型输出相关信息，假如要获得处理器方面的信息，则可以执行：<br>[root@localhost ~]# dmidecode -t processor</p>\n","site":{"data":{}},"excerpt":"","more":"<p>查看服务器型号：dmidecode | grep “Product Name”<br>查看主板的序列号：dmidecode | grep “Serial Number”<br>查看系统序列号：dmidecode -s system-serial-number<br>查看内存信息：dmidecode -t memory<br>查看OEM信息：dmidecode -t 11<br>不带选项执行dmidecode命令通常会输出所有的硬件信息。dmidecode命令有个很有用的选项-t，可以按指定类型输出相关信息，假如要获得处理器方面的信息，则可以执行：<br>[root@localhost ~]# dmidecode -t processor</p>\n"},{"title":"docker","_content":"复制镜像和复制容器都是通过保存为新镜像而进行的。\n具体为：\n保存镜像\ndocker save ID > xxx.tar\ndocker load < xxx.tar\ndocker load image-name:new < image.tar  \n//load期间使用$df -hl可以查看最下面docker绑定的根分区大小，如果image.tar要大于根分区大小则load会报空间不足的错误，解决方法下面有解.\n保存容器\ndocker export ID >xxx.tar\ndocker import xxx.tar container:v1\n然后再docker run -it container:v1 bash\n\n\t1. docker run --name faiss-gcc-9.1 -it faiss-images-gcc-9.1.0:1.0 /bin/bash  //用这个\n\t2. exit\n\t3. docker start faiss-gcc-9.1\n\t4. docker attach faiss-gcc-9.1\n\n软件镜像（如 weChat.exe）----> 运行镜像----> 产生一个容器（正在运行的软件，运行的 微信程序）；\n操作\t命令\t说明\n运行\tdocker run --name container-name -d image-name:tag /bin/bash\n\t运行一个名为 container-name的容器,并在容器里运行/bin/bash,如果不指定运行/bin/bash则docker启动后就立即退出，这跟docker机制有关，docker是后台运行，必须有前台进程，没有前台程序就退出\n\t#退出\n\texit\n\t#关闭\n\tdocker stop mycentos\n\t#重启\n\t1.docker start mycentos\n\t#重启后,在用mycentos再打开/bin/bash\n\t2.docker exec -ti mycentos /bin/bash    //1和2两步是合起来用的\n如:docker run --name myredis –d redis\t /bin/bash\n--name：自定义容器名\n-d：表示后台运行\nimage-name:指定运行的镜像名称\n\ntag:镜像的版本\n\n列表\tdocker ps（查看运行中的容器）；\t加上-a；可以查看所有容器\n停止\tdocker stop container-name/container-id\t停止当前运行的指定容器\n启动\tdocker start container-name/container-id\t启动容器\n删除\tdocker rm container-id\t删除指定容器\n端口映射\t-p 6379:6379\n如:docker run  --name myredis  -d -p 6379:6379 docker.io/redis\t\n-p:主机端口映射到容器内部的端口\n\n容器日志\tdocker logs container-name/container-id\t \n官网可查看更多命令：https://docs.docker.com/engine/reference/commandline/docker/\n\n删除Images\n\n$ docker rm      --   Remove one or more containers\n$ docker rmi     --   Remove one or more images\n想要删除运行过的images必须首先删除它的container。继续来看刚才的例子，\n[yaxin@ubox ~]$docker ps -a\nCONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS                   NAMES\n117843ade696        ed9c93747fe1        /bin/sh -c /usr/sbin   46 hours ago        Up 46 hours         0.0.0.0:49153->22/tcp   test_sshd\n可以看出ed9c93747fe1的image被117843ade696的container使用着，所以必须首先删除该container\n[yaxin@ubox ~]$docker rm 117843ade696\nError: container_delete: Impossible to remove a running container, please stop it first\n2014/03/22 16:36:44 Error: failed to remove one or more containers\n出现错误，这是因为该container正在运行中(运行docker ps查看)，先将其关闭\n[yaxin@ubox ~]$docker stop 117843ade696\n117843ade696\n[yaxin@ubox ~]$docker rm 117843ade696\n117843ade696\n[yaxin@ubox ~]$docker rmi ed9c93747fe1\nDeleted: ed9c93747fe16627be822ad3f7feeb8b4468200e5357877d3046aa83cc44c6af\nDeleted: c8a0c19429daf73074040a14e527ad5734e70363c644f18c6815388b63eedc9b\nDeleted: 95dba4c468f0e53e5f1e5d76b8581d6740aab9f59141f783f8e263ccd7cf2a8e\nDeleted: c25dc743e40af6858c34375d450851bd606a70ace5d04e231a7fcc6d2ea23cc1\nDeleted: 20562f5714a5ce764845119399ef75e652e23135cd5c54265ff8218b61ccbd33\nDeleted: c8af1dc23af7a7aea0c25ba9b28bdee68caa8866f056e4f2aa2a5fa1bcb12693\nDeleted: 38fdb2c5432e08ec6121f8dbb17e1fde17d5db4c1f149a9b702785dbf7b0f3be\nDeleted: 79ca14274c80ac1df1333b89b2a41c0e0e3b91cd1b267b31bef852ceab3b2044\n[yaxin@ubox ~]$docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE\nCentOS65            latest              e55a74a32125        2 days ago          360.6 MB\n可以看出，image已经被删除。\nFrom <https://blog.csdn.net/flydreamzhll/article/details/80900509> \n\nDocker 拷贝\n\n将主机/www/runoob目录拷贝到容器96f7f14e99ab的/www目录下。\ndocker cp /www/runoob 96f7f14e99ab:/www/\n将主机/www/runoob目录拷贝到容器96f7f14e99ab中，目录重命名为www。\ndocker cp /www/runoob 96f7f14e99ab:/www\n将容器96f7f14e99ab的/www目录拷贝到主机的/tmp目录中。\ndocker cp  96f7f14e99ab:/www /tmp/\n\n主机copy到docker\n$ docker cp /opt/test/file.txt mycontainer_id：/opt/testnew/\ndocker文件copy到主机\n$ docker cp mycontainer_id：/opt/testnew/file.txt /opt/test/\n\n\nFrom <http://www.runoob.com/docker/docker-cp-command.html> \n\n更新images\n\n  docker commit Container-id Images-name 将在某个image a 上做改动的新的container更新为最新的image \n[root@wlp10 test_hot2] docker commit a981e981ef65 faiss-images\n\t\t\t\t\t\t\t   Container-id    \n\n\nDocker run\n[root@a981e981ef65 test_faiss]# which python\n/usr/bin/python\n[root@a981e981ef65 test_faiss]# env\n\n[root@a981e981ef65 test_faiss]# vim test.sh\n\t#!/bin/bash\n\texport MKLROOT=/opt/intel/compilers_and_libraries/linux/mkl/\n\texport LD_PRELOAD=/opt/intel/compilers_and_libraries/linux/mkl//lib/intel64/libmkl_core.so:/opt/intel/compilers_and_libraries/linux/mkl//lib/intel64/libmkl_sequential.so\n\n\tcd /test_faiss\n\tpython /test_faiss/test_sift1M.py\n\n$ docker run -t image-name /bin/bash /test_faiss/test.sh\n\t\t\t\t此时image已是在最新container上更新过的image\n   Vtune 绑定docker运行\n$ amplxe-cl -collect hotspots -r test_hot docker run -t faiss-images /bin/bash /test_faiss/test.sh\n\t\t     \t\t     保存目录\n$ amplxe-cl -collect hotspots -r test_hot_1 ls\n\n\n设置镜像标签\n我们可以使用 docker tag 命令，为镜像添加一个新的标签。\nrunoob@runoob:~$ docker tag 860c279d2fec runoob/centos:dev\ndocker tag 镜像ID，这里是 860c279d2fec ,用户名称、镜像源名(repository name)和新的标签名(tag)。\n使用 docker images 命令可以看到，ID为860c279d2fec的镜像多一个标签。\nrunoob@runoob:~$ docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nrunoob/centos       6.7                 860c279d2fec        5 hours ago         190.6 MB\nrunoob/centos       dev                860c279d2fec        5 hours ago         190.6 MB\nrunoob/ubuntu       v2                  70bf1840fd7c        22 hours ago        158.5 MB\nubuntu              14.04               90d5884b1ee0        6 days ago          188 MB\nphp                 5.6                 f40e9e0f10c8        10 days ago         444.8 MB\nnginx               latest              6f8d099c3adc        13 days ago         182.7 MB\nmysql               5.6                 f2e8d6c772c0        3 weeks ago         324.6 MB\nhttpd               latest              02ef73cf1bc0        3 weeks ago         194.4 MB\nubuntu              15.10               4e3b13c8a266        5 weeks ago         136.3 MB\nhello-world         latest              690ed74de00f        6 months ago        960 B\ncentos              6.7                 d95b5ca17cc3        6 months ago        190.6 MB\ntraining/webapp     latest              6fae60ef3446        12 months ago       348.8 MB\n\n\n[Linux] -Docker修改空间大小\n第一种：\n[root@localhost home]# docker info\nContainers: 0\n Running: 0\n Paused: 0\n Stopped: 0\nImages: 0\nServer Version: 1.12.6\nStorage Driver: devicemapper\n Pool Name: docker-253:0-67125080-pool\n Pool Blocksize: 65.54 kB\n Base Device Size: 10.74 GB#这个就是限制，容器根分区的大小！\n Backing Filesystem: xfs\n Data file: /dev/loop0\n Metadata file: /dev/loop1\n Data Space Used: 11.8 MB\n Data Space Total: 107.4 GB\n Data Space Available: 36.95 GB\n Metadata Space Used: 581.6 kB\n Metadata Space Total: 2.147 GB\n Metadata Space Available: 2.147 GB\n Thin Pool Minimum Free Space: 10.74 GB\n Udev Sync Supported: true\n Deferred Removal Enabled: false\n Deferred Deletion Enabled: false\n Deferred Deleted Device Count: 0\ndocker的版本是1.12,修改容器根分区的大小即可：\n\n  dm.loopdatasize=100G是指存放数据的数据库空间为100g，默认是100g\ndm.loopmetadatasize=10G是存放Metadata数据空间为10g，默认是2g\ndm.fs=xft是指容器磁盘分区为xft\ndm.basesize=20G是指容器根分区默认为20g，默认是10g\n\nvi /etc/sysconfig/docker-storage\n修改下面参数即可\n \nDOCKER_STORAGE_OPTIONS=\"--storage-driver devicemapper --storage-opt dm.loopdatasize=200G --storage-opt dm.loopmetadatasize=10G -g /dev/docker/ --storage-opt dm.fs=xfs --storage-opt dm.basesize=30G\"\n利用-g参数即可指定存储挂载路径。比如，示例中的配置将存储目录挂载在/data/docker/路径下\n重新挂载新的路径后原来路径下的images和container都找不到，-g参数去掉回到默认挂载路径再按照下面重启docker服务会发现原来的images和container都存在.\n\n最后重启容器，问题解决\n停止docker服务的命令如下:\nsystemctl stop docker\n重新启动：\nsystemctl daemon-reload && systemctl start docker\n\n第二种： //试了试不怎么灵\nDocker默认空间大小分为两个，一个是池空间大小，另一个是容器空间大小。\n池空间大小默认为：100G\n容器空间大小默认为是：10G\n所以修改空间大小也分为两个：\n这里使用centos下的yum进行安装的Docker。\n \n首先，修改空间大小，必需使Docker运行在daemon环境下，即先停止正在运行的docker服务：\nservice docker stop\n然后使用命令使用daemon环境下运行docker：\ndocker -d          //可以不需要这条\n一、修改池空间大小方法：\ndd if=/dev/zero of=/var/lib/docker/devicemapper/devicemapper/data bs=1G count=0 seek=1000\ndd if=/dev/zero of=/var/lib/docker/devicemapper/devicemapper/metadata bs=1G count=0 seek=10\n上面的1000为1TB大小，即为数据池空间大小为1TB，而10则为Metadata的空间大小，10GB\n从运行完后，启动docker service\nservice docker start\n使用命令查看docker池空间大小：\ndocker info\n\n可以看到池空间已经被设置为data=1TB和metadata=10GB\n\n关于Docker目录挂载的总结\nDocker容器启动的时候，如果要挂载宿主机的一个目录，可以用-v参数指定。\n譬如我要启动一个centos容器，宿主机的/test目录挂载到容器的/soft目录，可通过以下方式指定：\n# docker run -it  --privileged=true -v /test:/soft  --name ContainerName ImagesName /bin/bash\n这样在容器启动后，容器内会自动创建/soft的目录。通过这种方式，我们可以明确一点，即-v参数中，冒号\":\"前面的目录是宿主机目录，后面的目录是容器内目录。\n挂载宿主机已存在目录后，在容器内对其进行操作，报“Permission denied”。\n可通过两种方式解决：\n1> 关闭selinux。\n临时关闭：# setenforce 0\n永久关闭：修改/etc/sysconfig/selinux文件，将SELINUX的值设置为disabled。\n2> 以特权方式启动容器 \n指定--privileged参数\n如：# docker run -it --privileged=true -v /test:/soft centos /bin/bash\n\n\n","source":"_posts/linux/docker.md","raw":"---\ntitle: docker\ntags: \ncategories:\n- linux\n---\n复制镜像和复制容器都是通过保存为新镜像而进行的。\n具体为：\n保存镜像\ndocker save ID > xxx.tar\ndocker load < xxx.tar\ndocker load image-name:new < image.tar  \n//load期间使用$df -hl可以查看最下面docker绑定的根分区大小，如果image.tar要大于根分区大小则load会报空间不足的错误，解决方法下面有解.\n保存容器\ndocker export ID >xxx.tar\ndocker import xxx.tar container:v1\n然后再docker run -it container:v1 bash\n\n\t1. docker run --name faiss-gcc-9.1 -it faiss-images-gcc-9.1.0:1.0 /bin/bash  //用这个\n\t2. exit\n\t3. docker start faiss-gcc-9.1\n\t4. docker attach faiss-gcc-9.1\n\n软件镜像（如 weChat.exe）----> 运行镜像----> 产生一个容器（正在运行的软件，运行的 微信程序）；\n操作\t命令\t说明\n运行\tdocker run --name container-name -d image-name:tag /bin/bash\n\t运行一个名为 container-name的容器,并在容器里运行/bin/bash,如果不指定运行/bin/bash则docker启动后就立即退出，这跟docker机制有关，docker是后台运行，必须有前台进程，没有前台程序就退出\n\t#退出\n\texit\n\t#关闭\n\tdocker stop mycentos\n\t#重启\n\t1.docker start mycentos\n\t#重启后,在用mycentos再打开/bin/bash\n\t2.docker exec -ti mycentos /bin/bash    //1和2两步是合起来用的\n如:docker run --name myredis –d redis\t /bin/bash\n--name：自定义容器名\n-d：表示后台运行\nimage-name:指定运行的镜像名称\n\ntag:镜像的版本\n\n列表\tdocker ps（查看运行中的容器）；\t加上-a；可以查看所有容器\n停止\tdocker stop container-name/container-id\t停止当前运行的指定容器\n启动\tdocker start container-name/container-id\t启动容器\n删除\tdocker rm container-id\t删除指定容器\n端口映射\t-p 6379:6379\n如:docker run  --name myredis  -d -p 6379:6379 docker.io/redis\t\n-p:主机端口映射到容器内部的端口\n\n容器日志\tdocker logs container-name/container-id\t \n官网可查看更多命令：https://docs.docker.com/engine/reference/commandline/docker/\n\n删除Images\n\n$ docker rm      --   Remove one or more containers\n$ docker rmi     --   Remove one or more images\n想要删除运行过的images必须首先删除它的container。继续来看刚才的例子，\n[yaxin@ubox ~]$docker ps -a\nCONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS                   NAMES\n117843ade696        ed9c93747fe1        /bin/sh -c /usr/sbin   46 hours ago        Up 46 hours         0.0.0.0:49153->22/tcp   test_sshd\n可以看出ed9c93747fe1的image被117843ade696的container使用着，所以必须首先删除该container\n[yaxin@ubox ~]$docker rm 117843ade696\nError: container_delete: Impossible to remove a running container, please stop it first\n2014/03/22 16:36:44 Error: failed to remove one or more containers\n出现错误，这是因为该container正在运行中(运行docker ps查看)，先将其关闭\n[yaxin@ubox ~]$docker stop 117843ade696\n117843ade696\n[yaxin@ubox ~]$docker rm 117843ade696\n117843ade696\n[yaxin@ubox ~]$docker rmi ed9c93747fe1\nDeleted: ed9c93747fe16627be822ad3f7feeb8b4468200e5357877d3046aa83cc44c6af\nDeleted: c8a0c19429daf73074040a14e527ad5734e70363c644f18c6815388b63eedc9b\nDeleted: 95dba4c468f0e53e5f1e5d76b8581d6740aab9f59141f783f8e263ccd7cf2a8e\nDeleted: c25dc743e40af6858c34375d450851bd606a70ace5d04e231a7fcc6d2ea23cc1\nDeleted: 20562f5714a5ce764845119399ef75e652e23135cd5c54265ff8218b61ccbd33\nDeleted: c8af1dc23af7a7aea0c25ba9b28bdee68caa8866f056e4f2aa2a5fa1bcb12693\nDeleted: 38fdb2c5432e08ec6121f8dbb17e1fde17d5db4c1f149a9b702785dbf7b0f3be\nDeleted: 79ca14274c80ac1df1333b89b2a41c0e0e3b91cd1b267b31bef852ceab3b2044\n[yaxin@ubox ~]$docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE\nCentOS65            latest              e55a74a32125        2 days ago          360.6 MB\n可以看出，image已经被删除。\nFrom <https://blog.csdn.net/flydreamzhll/article/details/80900509> \n\nDocker 拷贝\n\n将主机/www/runoob目录拷贝到容器96f7f14e99ab的/www目录下。\ndocker cp /www/runoob 96f7f14e99ab:/www/\n将主机/www/runoob目录拷贝到容器96f7f14e99ab中，目录重命名为www。\ndocker cp /www/runoob 96f7f14e99ab:/www\n将容器96f7f14e99ab的/www目录拷贝到主机的/tmp目录中。\ndocker cp  96f7f14e99ab:/www /tmp/\n\n主机copy到docker\n$ docker cp /opt/test/file.txt mycontainer_id：/opt/testnew/\ndocker文件copy到主机\n$ docker cp mycontainer_id：/opt/testnew/file.txt /opt/test/\n\n\nFrom <http://www.runoob.com/docker/docker-cp-command.html> \n\n更新images\n\n  docker commit Container-id Images-name 将在某个image a 上做改动的新的container更新为最新的image \n[root@wlp10 test_hot2] docker commit a981e981ef65 faiss-images\n\t\t\t\t\t\t\t   Container-id    \n\n\nDocker run\n[root@a981e981ef65 test_faiss]# which python\n/usr/bin/python\n[root@a981e981ef65 test_faiss]# env\n\n[root@a981e981ef65 test_faiss]# vim test.sh\n\t#!/bin/bash\n\texport MKLROOT=/opt/intel/compilers_and_libraries/linux/mkl/\n\texport LD_PRELOAD=/opt/intel/compilers_and_libraries/linux/mkl//lib/intel64/libmkl_core.so:/opt/intel/compilers_and_libraries/linux/mkl//lib/intel64/libmkl_sequential.so\n\n\tcd /test_faiss\n\tpython /test_faiss/test_sift1M.py\n\n$ docker run -t image-name /bin/bash /test_faiss/test.sh\n\t\t\t\t此时image已是在最新container上更新过的image\n   Vtune 绑定docker运行\n$ amplxe-cl -collect hotspots -r test_hot docker run -t faiss-images /bin/bash /test_faiss/test.sh\n\t\t     \t\t     保存目录\n$ amplxe-cl -collect hotspots -r test_hot_1 ls\n\n\n设置镜像标签\n我们可以使用 docker tag 命令，为镜像添加一个新的标签。\nrunoob@runoob:~$ docker tag 860c279d2fec runoob/centos:dev\ndocker tag 镜像ID，这里是 860c279d2fec ,用户名称、镜像源名(repository name)和新的标签名(tag)。\n使用 docker images 命令可以看到，ID为860c279d2fec的镜像多一个标签。\nrunoob@runoob:~$ docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nrunoob/centos       6.7                 860c279d2fec        5 hours ago         190.6 MB\nrunoob/centos       dev                860c279d2fec        5 hours ago         190.6 MB\nrunoob/ubuntu       v2                  70bf1840fd7c        22 hours ago        158.5 MB\nubuntu              14.04               90d5884b1ee0        6 days ago          188 MB\nphp                 5.6                 f40e9e0f10c8        10 days ago         444.8 MB\nnginx               latest              6f8d099c3adc        13 days ago         182.7 MB\nmysql               5.6                 f2e8d6c772c0        3 weeks ago         324.6 MB\nhttpd               latest              02ef73cf1bc0        3 weeks ago         194.4 MB\nubuntu              15.10               4e3b13c8a266        5 weeks ago         136.3 MB\nhello-world         latest              690ed74de00f        6 months ago        960 B\ncentos              6.7                 d95b5ca17cc3        6 months ago        190.6 MB\ntraining/webapp     latest              6fae60ef3446        12 months ago       348.8 MB\n\n\n[Linux] -Docker修改空间大小\n第一种：\n[root@localhost home]# docker info\nContainers: 0\n Running: 0\n Paused: 0\n Stopped: 0\nImages: 0\nServer Version: 1.12.6\nStorage Driver: devicemapper\n Pool Name: docker-253:0-67125080-pool\n Pool Blocksize: 65.54 kB\n Base Device Size: 10.74 GB#这个就是限制，容器根分区的大小！\n Backing Filesystem: xfs\n Data file: /dev/loop0\n Metadata file: /dev/loop1\n Data Space Used: 11.8 MB\n Data Space Total: 107.4 GB\n Data Space Available: 36.95 GB\n Metadata Space Used: 581.6 kB\n Metadata Space Total: 2.147 GB\n Metadata Space Available: 2.147 GB\n Thin Pool Minimum Free Space: 10.74 GB\n Udev Sync Supported: true\n Deferred Removal Enabled: false\n Deferred Deletion Enabled: false\n Deferred Deleted Device Count: 0\ndocker的版本是1.12,修改容器根分区的大小即可：\n\n  dm.loopdatasize=100G是指存放数据的数据库空间为100g，默认是100g\ndm.loopmetadatasize=10G是存放Metadata数据空间为10g，默认是2g\ndm.fs=xft是指容器磁盘分区为xft\ndm.basesize=20G是指容器根分区默认为20g，默认是10g\n\nvi /etc/sysconfig/docker-storage\n修改下面参数即可\n \nDOCKER_STORAGE_OPTIONS=\"--storage-driver devicemapper --storage-opt dm.loopdatasize=200G --storage-opt dm.loopmetadatasize=10G -g /dev/docker/ --storage-opt dm.fs=xfs --storage-opt dm.basesize=30G\"\n利用-g参数即可指定存储挂载路径。比如，示例中的配置将存储目录挂载在/data/docker/路径下\n重新挂载新的路径后原来路径下的images和container都找不到，-g参数去掉回到默认挂载路径再按照下面重启docker服务会发现原来的images和container都存在.\n\n最后重启容器，问题解决\n停止docker服务的命令如下:\nsystemctl stop docker\n重新启动：\nsystemctl daemon-reload && systemctl start docker\n\n第二种： //试了试不怎么灵\nDocker默认空间大小分为两个，一个是池空间大小，另一个是容器空间大小。\n池空间大小默认为：100G\n容器空间大小默认为是：10G\n所以修改空间大小也分为两个：\n这里使用centos下的yum进行安装的Docker。\n \n首先，修改空间大小，必需使Docker运行在daemon环境下，即先停止正在运行的docker服务：\nservice docker stop\n然后使用命令使用daemon环境下运行docker：\ndocker -d          //可以不需要这条\n一、修改池空间大小方法：\ndd if=/dev/zero of=/var/lib/docker/devicemapper/devicemapper/data bs=1G count=0 seek=1000\ndd if=/dev/zero of=/var/lib/docker/devicemapper/devicemapper/metadata bs=1G count=0 seek=10\n上面的1000为1TB大小，即为数据池空间大小为1TB，而10则为Metadata的空间大小，10GB\n从运行完后，启动docker service\nservice docker start\n使用命令查看docker池空间大小：\ndocker info\n\n可以看到池空间已经被设置为data=1TB和metadata=10GB\n\n关于Docker目录挂载的总结\nDocker容器启动的时候，如果要挂载宿主机的一个目录，可以用-v参数指定。\n譬如我要启动一个centos容器，宿主机的/test目录挂载到容器的/soft目录，可通过以下方式指定：\n# docker run -it  --privileged=true -v /test:/soft  --name ContainerName ImagesName /bin/bash\n这样在容器启动后，容器内会自动创建/soft的目录。通过这种方式，我们可以明确一点，即-v参数中，冒号\":\"前面的目录是宿主机目录，后面的目录是容器内目录。\n挂载宿主机已存在目录后，在容器内对其进行操作，报“Permission denied”。\n可通过两种方式解决：\n1> 关闭selinux。\n临时关闭：# setenforce 0\n永久关闭：修改/etc/sysconfig/selinux文件，将SELINUX的值设置为disabled。\n2> 以特权方式启动容器 \n指定--privileged参数\n如：# docker run -it --privileged=true -v /test:/soft centos /bin/bash\n\n\n","slug":"linux/docker","published":1,"date":"2020-08-12T16:05:46.153Z","updated":"2020-02-13T12:47:44.473Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmf60028hohxa776heq2","content":"<p>复制镜像和复制容器都是通过保存为新镜像而进行的。<br>具体为：<br>保存镜像<br>docker save ID &gt; xxx.tar<br>docker load &lt; xxx.tar<br>docker load image-name:new &lt; image.tar<br>//load期间使用$df -hl可以查看最下面docker绑定的根分区大小，如果image.tar要大于根分区大小则load会报空间不足的错误，解决方法下面有解.<br>保存容器<br>docker export ID &gt;xxx.tar<br>docker import xxx.tar container:v1<br>然后再docker run -it container:v1 bash</p>\n<pre><code>1. docker run --name faiss-gcc-9.1 -it faiss-images-gcc-9.1.0:1.0 /bin/bash  //用这个\n2. exit\n3. docker start faiss-gcc-9.1\n4. docker attach faiss-gcc-9.1</code></pre><p>软件镜像（如 weChat.exe）—-&gt; 运行镜像—-&gt; 产生一个容器（正在运行的软件，运行的 微信程序）；<br>操作    命令    说明<br>运行    docker run –name container-name -d image-name:tag /bin/bash<br>    运行一个名为 container-name的容器,并在容器里运行/bin/bash,如果不指定运行/bin/bash则docker启动后就立即退出，这跟docker机制有关，docker是后台运行，必须有前台进程，没有前台程序就退出<br>    #退出<br>    exit<br>    #关闭<br>    docker stop mycentos<br>    #重启<br>    1.docker start mycentos<br>    #重启后,在用mycentos再打开/bin/bash<br>    2.docker exec -ti mycentos /bin/bash    //1和2两步是合起来用的<br>如:docker run –name myredis –d redis     /bin/bash<br>–name：自定义容器名<br>-d：表示后台运行<br>image-name:指定运行的镜像名称</p>\n<p>tag:镜像的版本</p>\n<p>列表    docker ps（查看运行中的容器）；    加上-a；可以查看所有容器<br>停止    docker stop container-name/container-id    停止当前运行的指定容器<br>启动    docker start container-name/container-id    启动容器<br>删除    docker rm container-id    删除指定容器<br>端口映射    -p 6379:6379<br>如:docker run  –name myredis  -d -p 6379:6379 docker.io/redis<br>-p:主机端口映射到容器内部的端口</p>\n<p>容器日志    docker logs container-name/container-id<br>官网可查看更多命令：<a href=\"https://docs.docker.com/engine/reference/commandline/docker/\" target=\"_blank\" rel=\"noopener\">https://docs.docker.com/engine/reference/commandline/docker/</a></p>\n<p>删除Images</p>\n<p>$ docker rm      –   Remove one or more containers<br>$ docker rmi     –   Remove one or more images<br>想要删除运行过的images必须首先删除它的container。继续来看刚才的例子，<br>[yaxin@ubox ~]$docker ps -a<br>CONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS                   NAMES<br>117843ade696        ed9c93747fe1        /bin/sh -c /usr/sbin   46 hours ago        Up 46 hours         0.0.0.0:49153-&gt;22/tcp   test_sshd<br>可以看出ed9c93747fe1的image被117843ade696的container使用着，所以必须首先删除该container<br>[yaxin@ubox ~]$docker rm 117843ade696<br>Error: container_delete: Impossible to remove a running container, please stop it first<br>2014/03/22 16:36:44 Error: failed to remove one or more containers<br>出现错误，这是因为该container正在运行中(运行docker ps查看)，先将其关闭<br>[yaxin@ubox ~]$docker stop 117843ade696<br>117843ade696<br>[yaxin@ubox ~]$docker rm 117843ade696<br>117843ade696<br>[yaxin@ubox ~]$docker rmi ed9c93747fe1<br>Deleted: ed9c93747fe16627be822ad3f7feeb8b4468200e5357877d3046aa83cc44c6af<br>Deleted: c8a0c19429daf73074040a14e527ad5734e70363c644f18c6815388b63eedc9b<br>Deleted: 95dba4c468f0e53e5f1e5d76b8581d6740aab9f59141f783f8e263ccd7cf2a8e<br>Deleted: c25dc743e40af6858c34375d450851bd606a70ace5d04e231a7fcc6d2ea23cc1<br>Deleted: 20562f5714a5ce764845119399ef75e652e23135cd5c54265ff8218b61ccbd33<br>Deleted: c8af1dc23af7a7aea0c25ba9b28bdee68caa8866f056e4f2aa2a5fa1bcb12693<br>Deleted: 38fdb2c5432e08ec6121f8dbb17e1fde17d5db4c1f149a9b702785dbf7b0f3be<br>Deleted: 79ca14274c80ac1df1333b89b2a41c0e0e3b91cd1b267b31bef852ceab3b2044<br>[yaxin@ubox ~]$docker images<br>REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE<br>CentOS65            latest              e55a74a32125        2 days ago          360.6 MB<br>可以看出，image已经被删除。<br>From <a href=\"https://blog.csdn.net/flydreamzhll/article/details/80900509\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/flydreamzhll/article/details/80900509</a> </p>\n<p>Docker 拷贝</p>\n<p>将主机/www/runoob目录拷贝到容器96f7f14e99ab的/www目录下。<br>docker cp /www/runoob 96f7f14e99ab:/www/<br>将主机/www/runoob目录拷贝到容器96f7f14e99ab中，目录重命名为www。<br>docker cp /www/runoob 96f7f14e99ab:/www<br>将容器96f7f14e99ab的/www目录拷贝到主机的/tmp目录中。<br>docker cp  96f7f14e99ab:/www /tmp/</p>\n<p>主机copy到docker<br>$ docker cp /opt/test/file.txt mycontainer_id：/opt/testnew/<br>docker文件copy到主机<br>$ docker cp mycontainer_id：/opt/testnew/file.txt /opt/test/</p>\n<p>From <a href=\"http://www.runoob.com/docker/docker-cp-command.html\" target=\"_blank\" rel=\"noopener\">http://www.runoob.com/docker/docker-cp-command.html</a> </p>\n<p>更新images</p>\n<p>  docker commit Container-id Images-name 将在某个image a 上做改动的新的container更新为最新的image<br>[root@wlp10 test_hot2] docker commit a981e981ef65 faiss-images<br>                               Container-id    </p>\n<p>Docker run<br>[root@a981e981ef65 test_faiss]# which python<br>/usr/bin/python<br>[root@a981e981ef65 test_faiss]# env</p>\n<p>[root@a981e981ef65 test_faiss]# vim test.sh<br>    #!/bin/bash<br>    export MKLROOT=/opt/intel/compilers_and_libraries/linux/mkl/<br>    export LD_PRELOAD=/opt/intel/compilers_and_libraries/linux/mkl//lib/intel64/libmkl_core.so:/opt/intel/compilers_and_libraries/linux/mkl//lib/intel64/libmkl_sequential.so</p>\n<pre><code>cd /test_faiss\npython /test_faiss/test_sift1M.py</code></pre><p>$ docker run -t image-name /bin/bash /test_faiss/test.sh<br>                此时image已是在最新container上更新过的image<br>   Vtune 绑定docker运行<br>$ amplxe-cl -collect hotspots -r test_hot docker run -t faiss-images /bin/bash /test_faiss/test.sh<br>                          保存目录<br>$ amplxe-cl -collect hotspots -r test_hot_1 ls</p>\n<p>设置镜像标签<br>我们可以使用 docker tag 命令，为镜像添加一个新的标签。<br>runoob@runoob:<del>$ docker tag 860c279d2fec runoob/centos:dev<br>docker tag 镜像ID，这里是 860c279d2fec ,用户名称、镜像源名(repository name)和新的标签名(tag)。<br>使用 docker images 命令可以看到，ID为860c279d2fec的镜像多一个标签。<br>runoob@runoob:</del>$ docker images<br>REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE<br>runoob/centos       6.7                 860c279d2fec        5 hours ago         190.6 MB<br>runoob/centos       dev                860c279d2fec        5 hours ago         190.6 MB<br>runoob/ubuntu       v2                  70bf1840fd7c        22 hours ago        158.5 MB<br>ubuntu              14.04               90d5884b1ee0        6 days ago          188 MB<br>php                 5.6                 f40e9e0f10c8        10 days ago         444.8 MB<br>nginx               latest              6f8d099c3adc        13 days ago         182.7 MB<br>mysql               5.6                 f2e8d6c772c0        3 weeks ago         324.6 MB<br>httpd               latest              02ef73cf1bc0        3 weeks ago         194.4 MB<br>ubuntu              15.10               4e3b13c8a266        5 weeks ago         136.3 MB<br>hello-world         latest              690ed74de00f        6 months ago        960 B<br>centos              6.7                 d95b5ca17cc3        6 months ago        190.6 MB<br>training/webapp     latest              6fae60ef3446        12 months ago       348.8 MB</p>\n<p>[Linux] -Docker修改空间大小<br>第一种：<br>[root@localhost home]# docker info<br>Containers: 0<br> Running: 0<br> Paused: 0<br> Stopped: 0<br>Images: 0<br>Server Version: 1.12.6<br>Storage Driver: devicemapper<br> Pool Name: docker-253:0-67125080-pool<br> Pool Blocksize: 65.54 kB<br> Base Device Size: 10.74 GB#这个就是限制，容器根分区的大小！<br> Backing Filesystem: xfs<br> Data file: /dev/loop0<br> Metadata file: /dev/loop1<br> Data Space Used: 11.8 MB<br> Data Space Total: 107.4 GB<br> Data Space Available: 36.95 GB<br> Metadata Space Used: 581.6 kB<br> Metadata Space Total: 2.147 GB<br> Metadata Space Available: 2.147 GB<br> Thin Pool Minimum Free Space: 10.74 GB<br> Udev Sync Supported: true<br> Deferred Removal Enabled: false<br> Deferred Deletion Enabled: false<br> Deferred Deleted Device Count: 0<br>docker的版本是1.12,修改容器根分区的大小即可：</p>\n<p>  dm.loopdatasize=100G是指存放数据的数据库空间为100g，默认是100g<br>dm.loopmetadatasize=10G是存放Metadata数据空间为10g，默认是2g<br>dm.fs=xft是指容器磁盘分区为xft<br>dm.basesize=20G是指容器根分区默认为20g，默认是10g</p>\n<p>vi /etc/sysconfig/docker-storage<br>修改下面参数即可</p>\n<p>DOCKER_STORAGE_OPTIONS=”–storage-driver devicemapper –storage-opt dm.loopdatasize=200G –storage-opt dm.loopmetadatasize=10G -g /dev/docker/ –storage-opt dm.fs=xfs –storage-opt dm.basesize=30G”<br>利用-g参数即可指定存储挂载路径。比如，示例中的配置将存储目录挂载在/data/docker/路径下<br>重新挂载新的路径后原来路径下的images和container都找不到，-g参数去掉回到默认挂载路径再按照下面重启docker服务会发现原来的images和container都存在.</p>\n<p>最后重启容器，问题解决<br>停止docker服务的命令如下:<br>systemctl stop docker<br>重新启动：<br>systemctl daemon-reload &amp;&amp; systemctl start docker</p>\n<p>第二种： //试了试不怎么灵<br>Docker默认空间大小分为两个，一个是池空间大小，另一个是容器空间大小。<br>池空间大小默认为：100G<br>容器空间大小默认为是：10G<br>所以修改空间大小也分为两个：<br>这里使用centos下的yum进行安装的Docker。</p>\n<p>首先，修改空间大小，必需使Docker运行在daemon环境下，即先停止正在运行的docker服务：<br>service docker stop<br>然后使用命令使用daemon环境下运行docker：<br>docker -d          //可以不需要这条<br>一、修改池空间大小方法：<br>dd if=/dev/zero of=/var/lib/docker/devicemapper/devicemapper/data bs=1G count=0 seek=1000<br>dd if=/dev/zero of=/var/lib/docker/devicemapper/devicemapper/metadata bs=1G count=0 seek=10<br>上面的1000为1TB大小，即为数据池空间大小为1TB，而10则为Metadata的空间大小，10GB<br>从运行完后，启动docker service<br>service docker start<br>使用命令查看docker池空间大小：<br>docker info</p>\n<p>可以看到池空间已经被设置为data=1TB和metadata=10GB</p>\n<p>关于Docker目录挂载的总结<br>Docker容器启动的时候，如果要挂载宿主机的一个目录，可以用-v参数指定。<br>譬如我要启动一个centos容器，宿主机的/test目录挂载到容器的/soft目录，可通过以下方式指定：</p>\n<h1 id=\"docker-run-it-–privileged-true-v-test-soft-–name-ContainerName-ImagesName-bin-bash\"><a href=\"#docker-run-it-–privileged-true-v-test-soft-–name-ContainerName-ImagesName-bin-bash\" class=\"headerlink\" title=\"docker run -it  –privileged=true -v /test:/soft  –name ContainerName ImagesName /bin/bash\"></a>docker run -it  –privileged=true -v /test:/soft  –name ContainerName ImagesName /bin/bash</h1><p>这样在容器启动后，容器内会自动创建/soft的目录。通过这种方式，我们可以明确一点，即-v参数中，冒号”:”前面的目录是宿主机目录，后面的目录是容器内目录。<br>挂载宿主机已存在目录后，在容器内对其进行操作，报“Permission denied”。<br>可通过两种方式解决：<br>1&gt; 关闭selinux。<br>临时关闭：# setenforce 0<br>永久关闭：修改/etc/sysconfig/selinux文件，将SELINUX的值设置为disabled。<br>2&gt; 以特权方式启动容器<br>指定–privileged参数<br>如：# docker run -it –privileged=true -v /test:/soft centos /bin/bash</p>\n","site":{"data":{}},"excerpt":"","more":"<p>复制镜像和复制容器都是通过保存为新镜像而进行的。<br>具体为：<br>保存镜像<br>docker save ID &gt; xxx.tar<br>docker load &lt; xxx.tar<br>docker load image-name:new &lt; image.tar<br>//load期间使用$df -hl可以查看最下面docker绑定的根分区大小，如果image.tar要大于根分区大小则load会报空间不足的错误，解决方法下面有解.<br>保存容器<br>docker export ID &gt;xxx.tar<br>docker import xxx.tar container:v1<br>然后再docker run -it container:v1 bash</p>\n<pre><code>1. docker run --name faiss-gcc-9.1 -it faiss-images-gcc-9.1.0:1.0 /bin/bash  //用这个\n2. exit\n3. docker start faiss-gcc-9.1\n4. docker attach faiss-gcc-9.1</code></pre><p>软件镜像（如 weChat.exe）—-&gt; 运行镜像—-&gt; 产生一个容器（正在运行的软件，运行的 微信程序）；<br>操作    命令    说明<br>运行    docker run –name container-name -d image-name:tag /bin/bash<br>    运行一个名为 container-name的容器,并在容器里运行/bin/bash,如果不指定运行/bin/bash则docker启动后就立即退出，这跟docker机制有关，docker是后台运行，必须有前台进程，没有前台程序就退出<br>    #退出<br>    exit<br>    #关闭<br>    docker stop mycentos<br>    #重启<br>    1.docker start mycentos<br>    #重启后,在用mycentos再打开/bin/bash<br>    2.docker exec -ti mycentos /bin/bash    //1和2两步是合起来用的<br>如:docker run –name myredis –d redis     /bin/bash<br>–name：自定义容器名<br>-d：表示后台运行<br>image-name:指定运行的镜像名称</p>\n<p>tag:镜像的版本</p>\n<p>列表    docker ps（查看运行中的容器）；    加上-a；可以查看所有容器<br>停止    docker stop container-name/container-id    停止当前运行的指定容器<br>启动    docker start container-name/container-id    启动容器<br>删除    docker rm container-id    删除指定容器<br>端口映射    -p 6379:6379<br>如:docker run  –name myredis  -d -p 6379:6379 docker.io/redis<br>-p:主机端口映射到容器内部的端口</p>\n<p>容器日志    docker logs container-name/container-id<br>官网可查看更多命令：<a href=\"https://docs.docker.com/engine/reference/commandline/docker/\" target=\"_blank\" rel=\"noopener\">https://docs.docker.com/engine/reference/commandline/docker/</a></p>\n<p>删除Images</p>\n<p>$ docker rm      –   Remove one or more containers<br>$ docker rmi     –   Remove one or more images<br>想要删除运行过的images必须首先删除它的container。继续来看刚才的例子，<br>[yaxin@ubox ~]$docker ps -a<br>CONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS                   NAMES<br>117843ade696        ed9c93747fe1        /bin/sh -c /usr/sbin   46 hours ago        Up 46 hours         0.0.0.0:49153-&gt;22/tcp   test_sshd<br>可以看出ed9c93747fe1的image被117843ade696的container使用着，所以必须首先删除该container<br>[yaxin@ubox ~]$docker rm 117843ade696<br>Error: container_delete: Impossible to remove a running container, please stop it first<br>2014/03/22 16:36:44 Error: failed to remove one or more containers<br>出现错误，这是因为该container正在运行中(运行docker ps查看)，先将其关闭<br>[yaxin@ubox ~]$docker stop 117843ade696<br>117843ade696<br>[yaxin@ubox ~]$docker rm 117843ade696<br>117843ade696<br>[yaxin@ubox ~]$docker rmi ed9c93747fe1<br>Deleted: ed9c93747fe16627be822ad3f7feeb8b4468200e5357877d3046aa83cc44c6af<br>Deleted: c8a0c19429daf73074040a14e527ad5734e70363c644f18c6815388b63eedc9b<br>Deleted: 95dba4c468f0e53e5f1e5d76b8581d6740aab9f59141f783f8e263ccd7cf2a8e<br>Deleted: c25dc743e40af6858c34375d450851bd606a70ace5d04e231a7fcc6d2ea23cc1<br>Deleted: 20562f5714a5ce764845119399ef75e652e23135cd5c54265ff8218b61ccbd33<br>Deleted: c8af1dc23af7a7aea0c25ba9b28bdee68caa8866f056e4f2aa2a5fa1bcb12693<br>Deleted: 38fdb2c5432e08ec6121f8dbb17e1fde17d5db4c1f149a9b702785dbf7b0f3be<br>Deleted: 79ca14274c80ac1df1333b89b2a41c0e0e3b91cd1b267b31bef852ceab3b2044<br>[yaxin@ubox ~]$docker images<br>REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE<br>CentOS65            latest              e55a74a32125        2 days ago          360.6 MB<br>可以看出，image已经被删除。<br>From <a href=\"https://blog.csdn.net/flydreamzhll/article/details/80900509\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/flydreamzhll/article/details/80900509</a> </p>\n<p>Docker 拷贝</p>\n<p>将主机/www/runoob目录拷贝到容器96f7f14e99ab的/www目录下。<br>docker cp /www/runoob 96f7f14e99ab:/www/<br>将主机/www/runoob目录拷贝到容器96f7f14e99ab中，目录重命名为www。<br>docker cp /www/runoob 96f7f14e99ab:/www<br>将容器96f7f14e99ab的/www目录拷贝到主机的/tmp目录中。<br>docker cp  96f7f14e99ab:/www /tmp/</p>\n<p>主机copy到docker<br>$ docker cp /opt/test/file.txt mycontainer_id：/opt/testnew/<br>docker文件copy到主机<br>$ docker cp mycontainer_id：/opt/testnew/file.txt /opt/test/</p>\n<p>From <a href=\"http://www.runoob.com/docker/docker-cp-command.html\" target=\"_blank\" rel=\"noopener\">http://www.runoob.com/docker/docker-cp-command.html</a> </p>\n<p>更新images</p>\n<p>  docker commit Container-id Images-name 将在某个image a 上做改动的新的container更新为最新的image<br>[root@wlp10 test_hot2] docker commit a981e981ef65 faiss-images<br>                               Container-id    </p>\n<p>Docker run<br>[root@a981e981ef65 test_faiss]# which python<br>/usr/bin/python<br>[root@a981e981ef65 test_faiss]# env</p>\n<p>[root@a981e981ef65 test_faiss]# vim test.sh<br>    #!/bin/bash<br>    export MKLROOT=/opt/intel/compilers_and_libraries/linux/mkl/<br>    export LD_PRELOAD=/opt/intel/compilers_and_libraries/linux/mkl//lib/intel64/libmkl_core.so:/opt/intel/compilers_and_libraries/linux/mkl//lib/intel64/libmkl_sequential.so</p>\n<pre><code>cd /test_faiss\npython /test_faiss/test_sift1M.py</code></pre><p>$ docker run -t image-name /bin/bash /test_faiss/test.sh<br>                此时image已是在最新container上更新过的image<br>   Vtune 绑定docker运行<br>$ amplxe-cl -collect hotspots -r test_hot docker run -t faiss-images /bin/bash /test_faiss/test.sh<br>                          保存目录<br>$ amplxe-cl -collect hotspots -r test_hot_1 ls</p>\n<p>设置镜像标签<br>我们可以使用 docker tag 命令，为镜像添加一个新的标签。<br>runoob@runoob:<del>$ docker tag 860c279d2fec runoob/centos:dev<br>docker tag 镜像ID，这里是 860c279d2fec ,用户名称、镜像源名(repository name)和新的标签名(tag)。<br>使用 docker images 命令可以看到，ID为860c279d2fec的镜像多一个标签。<br>runoob@runoob:</del>$ docker images<br>REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE<br>runoob/centos       6.7                 860c279d2fec        5 hours ago         190.6 MB<br>runoob/centos       dev                860c279d2fec        5 hours ago         190.6 MB<br>runoob/ubuntu       v2                  70bf1840fd7c        22 hours ago        158.5 MB<br>ubuntu              14.04               90d5884b1ee0        6 days ago          188 MB<br>php                 5.6                 f40e9e0f10c8        10 days ago         444.8 MB<br>nginx               latest              6f8d099c3adc        13 days ago         182.7 MB<br>mysql               5.6                 f2e8d6c772c0        3 weeks ago         324.6 MB<br>httpd               latest              02ef73cf1bc0        3 weeks ago         194.4 MB<br>ubuntu              15.10               4e3b13c8a266        5 weeks ago         136.3 MB<br>hello-world         latest              690ed74de00f        6 months ago        960 B<br>centos              6.7                 d95b5ca17cc3        6 months ago        190.6 MB<br>training/webapp     latest              6fae60ef3446        12 months ago       348.8 MB</p>\n<p>[Linux] -Docker修改空间大小<br>第一种：<br>[root@localhost home]# docker info<br>Containers: 0<br> Running: 0<br> Paused: 0<br> Stopped: 0<br>Images: 0<br>Server Version: 1.12.6<br>Storage Driver: devicemapper<br> Pool Name: docker-253:0-67125080-pool<br> Pool Blocksize: 65.54 kB<br> Base Device Size: 10.74 GB#这个就是限制，容器根分区的大小！<br> Backing Filesystem: xfs<br> Data file: /dev/loop0<br> Metadata file: /dev/loop1<br> Data Space Used: 11.8 MB<br> Data Space Total: 107.4 GB<br> Data Space Available: 36.95 GB<br> Metadata Space Used: 581.6 kB<br> Metadata Space Total: 2.147 GB<br> Metadata Space Available: 2.147 GB<br> Thin Pool Minimum Free Space: 10.74 GB<br> Udev Sync Supported: true<br> Deferred Removal Enabled: false<br> Deferred Deletion Enabled: false<br> Deferred Deleted Device Count: 0<br>docker的版本是1.12,修改容器根分区的大小即可：</p>\n<p>  dm.loopdatasize=100G是指存放数据的数据库空间为100g，默认是100g<br>dm.loopmetadatasize=10G是存放Metadata数据空间为10g，默认是2g<br>dm.fs=xft是指容器磁盘分区为xft<br>dm.basesize=20G是指容器根分区默认为20g，默认是10g</p>\n<p>vi /etc/sysconfig/docker-storage<br>修改下面参数即可</p>\n<p>DOCKER_STORAGE_OPTIONS=”–storage-driver devicemapper –storage-opt dm.loopdatasize=200G –storage-opt dm.loopmetadatasize=10G -g /dev/docker/ –storage-opt dm.fs=xfs –storage-opt dm.basesize=30G”<br>利用-g参数即可指定存储挂载路径。比如，示例中的配置将存储目录挂载在/data/docker/路径下<br>重新挂载新的路径后原来路径下的images和container都找不到，-g参数去掉回到默认挂载路径再按照下面重启docker服务会发现原来的images和container都存在.</p>\n<p>最后重启容器，问题解决<br>停止docker服务的命令如下:<br>systemctl stop docker<br>重新启动：<br>systemctl daemon-reload &amp;&amp; systemctl start docker</p>\n<p>第二种： //试了试不怎么灵<br>Docker默认空间大小分为两个，一个是池空间大小，另一个是容器空间大小。<br>池空间大小默认为：100G<br>容器空间大小默认为是：10G<br>所以修改空间大小也分为两个：<br>这里使用centos下的yum进行安装的Docker。</p>\n<p>首先，修改空间大小，必需使Docker运行在daemon环境下，即先停止正在运行的docker服务：<br>service docker stop<br>然后使用命令使用daemon环境下运行docker：<br>docker -d          //可以不需要这条<br>一、修改池空间大小方法：<br>dd if=/dev/zero of=/var/lib/docker/devicemapper/devicemapper/data bs=1G count=0 seek=1000<br>dd if=/dev/zero of=/var/lib/docker/devicemapper/devicemapper/metadata bs=1G count=0 seek=10<br>上面的1000为1TB大小，即为数据池空间大小为1TB，而10则为Metadata的空间大小，10GB<br>从运行完后，启动docker service<br>service docker start<br>使用命令查看docker池空间大小：<br>docker info</p>\n<p>可以看到池空间已经被设置为data=1TB和metadata=10GB</p>\n<p>关于Docker目录挂载的总结<br>Docker容器启动的时候，如果要挂载宿主机的一个目录，可以用-v参数指定。<br>譬如我要启动一个centos容器，宿主机的/test目录挂载到容器的/soft目录，可通过以下方式指定：</p>\n<h1 id=\"docker-run-it-–privileged-true-v-test-soft-–name-ContainerName-ImagesName-bin-bash\"><a href=\"#docker-run-it-–privileged-true-v-test-soft-–name-ContainerName-ImagesName-bin-bash\" class=\"headerlink\" title=\"docker run -it  –privileged=true -v /test:/soft  –name ContainerName ImagesName /bin/bash\"></a>docker run -it  –privileged=true -v /test:/soft  –name ContainerName ImagesName /bin/bash</h1><p>这样在容器启动后，容器内会自动创建/soft的目录。通过这种方式，我们可以明确一点，即-v参数中，冒号”:”前面的目录是宿主机目录，后面的目录是容器内目录。<br>挂载宿主机已存在目录后，在容器内对其进行操作，报“Permission denied”。<br>可通过两种方式解决：<br>1&gt; 关闭selinux。<br>临时关闭：# setenforce 0<br>永久关闭：修改/etc/sysconfig/selinux文件，将SELINUX的值设置为disabled。<br>2&gt; 以特权方式启动容器<br>指定–privileged参数<br>如：# docker run -it –privileged=true -v /test:/soft centos /bin/bash</p>\n"},{"title":"emon","_content":"Sampling Enabling Product (SEP) and Event Monitor (EMON) are software tools used for performance analysis & tuning of Intel h/w platforms, and the software running on them. This is the site where you can download latest releases of the tools for PMU based analysis on various public/NDA/private Intel® processors/platforms, and also request technical support for any issues you may encounter. Check out the SEP user guide and EMON user guide.\n\nFrom <https://soco.intel.com/groups/perf-tools> \n\n\n\nEMON is a low-level command-line tool that provides the ability to profile application and system performance. The tool leverages counters from hardware Performance Monitoring Units (PMUs) to collect performance monitoring events.\n--------------------- \n","source":"_posts/linux/emon.md","raw":"---\ntitle: emon\ntags: \ncategories:\n- linux\n---\nSampling Enabling Product (SEP) and Event Monitor (EMON) are software tools used for performance analysis & tuning of Intel h/w platforms, and the software running on them. This is the site where you can download latest releases of the tools for PMU based analysis on various public/NDA/private Intel® processors/platforms, and also request technical support for any issues you may encounter. Check out the SEP user guide and EMON user guide.\n\nFrom <https://soco.intel.com/groups/perf-tools> \n\n\n\nEMON is a low-level command-line tool that provides the ability to profile application and system performance. The tool leverages counters from hardware Performance Monitoring Units (PMUs) to collect performance monitoring events.\n--------------------- \n","slug":"linux/emon","published":1,"date":"2020-08-12T16:05:46.185Z","updated":"2020-02-13T12:47:44.477Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfa002bhohx3sdrbsm1","content":"<p>Sampling Enabling Product (SEP) and Event Monitor (EMON) are software tools used for performance analysis &amp; tuning of Intel h/w platforms, and the software running on them. This is the site where you can download latest releases of the tools for PMU based analysis on various public/NDA/private Intel® processors/platforms, and also request technical support for any issues you may encounter. Check out the SEP user guide and EMON user guide.</p>\n<p>From <a href=\"https://soco.intel.com/groups/perf-tools\" target=\"_blank\" rel=\"noopener\">https://soco.intel.com/groups/perf-tools</a> </p>\n<h2 id=\"EMON-is-a-low-level-command-line-tool-that-provides-the-ability-to-profile-application-and-system-performance-The-tool-leverages-counters-from-hardware-Performance-Monitoring-Units-PMUs-to-collect-performance-monitoring-events\"><a href=\"#EMON-is-a-low-level-command-line-tool-that-provides-the-ability-to-profile-application-and-system-performance-The-tool-leverages-counters-from-hardware-Performance-Monitoring-Units-PMUs-to-collect-performance-monitoring-events\" class=\"headerlink\" title=\"EMON is a low-level command-line tool that provides the ability to profile application and system performance. The tool leverages counters from hardware Performance Monitoring Units (PMUs) to collect performance monitoring events.\"></a>EMON is a low-level command-line tool that provides the ability to profile application and system performance. The tool leverages counters from hardware Performance Monitoring Units (PMUs) to collect performance monitoring events.</h2>","site":{"data":{}},"excerpt":"","more":"<p>Sampling Enabling Product (SEP) and Event Monitor (EMON) are software tools used for performance analysis &amp; tuning of Intel h/w platforms, and the software running on them. This is the site where you can download latest releases of the tools for PMU based analysis on various public/NDA/private Intel® processors/platforms, and also request technical support for any issues you may encounter. Check out the SEP user guide and EMON user guide.</p>\n<p>From <a href=\"https://soco.intel.com/groups/perf-tools\" target=\"_blank\" rel=\"noopener\">https://soco.intel.com/groups/perf-tools</a> </p>\n<h2 id=\"EMON-is-a-low-level-command-line-tool-that-provides-the-ability-to-profile-application-and-system-performance-The-tool-leverages-counters-from-hardware-Performance-Monitoring-Units-PMUs-to-collect-performance-monitoring-events\"><a href=\"#EMON-is-a-low-level-command-line-tool-that-provides-the-ability-to-profile-application-and-system-performance-The-tool-leverages-counters-from-hardware-Performance-Monitoring-Units-PMUs-to-collect-performance-monitoring-events\" class=\"headerlink\" title=\"EMON is a low-level command-line tool that provides the ability to profile application and system performance. The tool leverages counters from hardware Performance Monitoring Units (PMUs) to collect performance monitoring events.\"></a>EMON is a low-level command-line tool that provides the ability to profile application and system performance. The tool leverages counters from hardware Performance Monitoring Units (PMUs) to collect performance monitoring events.</h2>"},{"title":"/etc/profile, /etc/bashrc, ~/.bashrc","_content":"1、Ubuntu保存环境变量的几个文件\n/etc/profile\n在用户登录时，操作系统定制用户环境时使用的第一个文件，此文件为系统的每个用户设置环境信息，当用户第一次登录时，该文件被执行。\n\n/etc /environment\n在用户登录时，操作系统使用的第二个文件， 系统在读取用户个人的profile前，设置环境文件的环境变量。\n\n~/.profile\n在用户登录时，用到的第三个文件 是.profile文件，每个用户都可使用该文件输入专用于自己使用的shell信息，当用户登录时，该文件仅仅执行一次！默认情况下，会设置一些环境变量，执行用户的.bashrc文件。\n\n/etc/bashrc\n为每一个运行bash shell的用户执行此文件，当bash shell被打开时，该文件被读取。\n\n~/.bashrc\n该文件包含专用于用户的bash shell的bash信息，当登录时以及每次打开新的shell时，该该文件被读取。\n       …\n 14 export http_proxy=http://child-prc.intel.com:913/\n 15 export https_proxy=http://child-prc.intel.com:913/\n这样修改每次yum,pip等工具下载文件时候不能再写policy\n使文件立刻生效，$ source ~/.profile\n\nNote： 以上文件可通过$ sudo gedit 文件名 或 $ sudo vim 文件名打开；建议只修改~/.profile文件，如果只修改~/.bashrc文件，后期使用go get 命令时，会提示GOPATH未设置。\n2、设置GOPATH和GOROOT\n$ sudo gedit ~/.profile\n在文件最后添加\n export GOROOT=\"/usr/lib/go-1.8\" // 引号内设置为你自己的go安装目录\n export GOBIN=$GOROOT/bin\n export GOPATH=\"/home/test/gopath\" // 引号内设置为自己的go项目的工作区间\n export PATH=$PATH:$GOPATH/bin    // 原路径后用冒号连接新路径\n1\n2\n3\n4\n使文件立刻生效，$ source ~/.profile\n重启系统即可\n","source":"_posts/linux/etc_profile-etc_bashrc-~.bashrc.md","raw":"---\ntitle: /etc/profile, /etc/bashrc, ~/.bashrc\ntags: \ncategories:\n- linux\n---\n1、Ubuntu保存环境变量的几个文件\n/etc/profile\n在用户登录时，操作系统定制用户环境时使用的第一个文件，此文件为系统的每个用户设置环境信息，当用户第一次登录时，该文件被执行。\n\n/etc /environment\n在用户登录时，操作系统使用的第二个文件， 系统在读取用户个人的profile前，设置环境文件的环境变量。\n\n~/.profile\n在用户登录时，用到的第三个文件 是.profile文件，每个用户都可使用该文件输入专用于自己使用的shell信息，当用户登录时，该文件仅仅执行一次！默认情况下，会设置一些环境变量，执行用户的.bashrc文件。\n\n/etc/bashrc\n为每一个运行bash shell的用户执行此文件，当bash shell被打开时，该文件被读取。\n\n~/.bashrc\n该文件包含专用于用户的bash shell的bash信息，当登录时以及每次打开新的shell时，该该文件被读取。\n       …\n 14 export http_proxy=http://child-prc.intel.com:913/\n 15 export https_proxy=http://child-prc.intel.com:913/\n这样修改每次yum,pip等工具下载文件时候不能再写policy\n使文件立刻生效，$ source ~/.profile\n\nNote： 以上文件可通过$ sudo gedit 文件名 或 $ sudo vim 文件名打开；建议只修改~/.profile文件，如果只修改~/.bashrc文件，后期使用go get 命令时，会提示GOPATH未设置。\n2、设置GOPATH和GOROOT\n$ sudo gedit ~/.profile\n在文件最后添加\n export GOROOT=\"/usr/lib/go-1.8\" // 引号内设置为你自己的go安装目录\n export GOBIN=$GOROOT/bin\n export GOPATH=\"/home/test/gopath\" // 引号内设置为自己的go项目的工作区间\n export PATH=$PATH:$GOPATH/bin    // 原路径后用冒号连接新路径\n1\n2\n3\n4\n使文件立刻生效，$ source ~/.profile\n重启系统即可\n","slug":"linux/etc_profile-etc_bashrc-~.bashrc","published":1,"date":"2020-08-12T16:05:46.210Z","updated":"2020-02-13T12:47:44.480Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmff002dhohx31y9hm9m","content":"<p>1、Ubuntu保存环境变量的几个文件<br>/etc/profile<br>在用户登录时，操作系统定制用户环境时使用的第一个文件，此文件为系统的每个用户设置环境信息，当用户第一次登录时，该文件被执行。</p>\n<p>/etc /environment<br>在用户登录时，操作系统使用的第二个文件， 系统在读取用户个人的profile前，设置环境文件的环境变量。</p>\n<p>~/.profile<br>在用户登录时，用到的第三个文件 是.profile文件，每个用户都可使用该文件输入专用于自己使用的shell信息，当用户登录时，该文件仅仅执行一次！默认情况下，会设置一些环境变量，执行用户的.bashrc文件。</p>\n<p>/etc/bashrc<br>为每一个运行bash shell的用户执行此文件，当bash shell被打开时，该文件被读取。</p>\n<p>~/.bashrc<br>该文件包含专用于用户的bash shell的bash信息，当登录时以及每次打开新的shell时，该该文件被读取。<br>       …<br> 14 export http_proxy=<a href=\"http://child-prc.intel.com:913/\" target=\"_blank\" rel=\"noopener\">http://child-prc.intel.com:913/</a><br> 15 export https_proxy=<a href=\"http://child-prc.intel.com:913/\" target=\"_blank\" rel=\"noopener\">http://child-prc.intel.com:913/</a><br>这样修改每次yum,pip等工具下载文件时候不能再写policy<br>使文件立刻生效，$ source ~/.profile</p>\n<p>Note： 以上文件可通过$ sudo gedit 文件名 或 $ sudo vim 文件名打开；建议只修改<del>/.profile文件，如果只修改</del>/.bashrc文件，后期使用go get 命令时，会提示GOPATH未设置。<br>2、设置GOPATH和GOROOT<br>$ sudo gedit ~/.profile<br>在文件最后添加<br> export GOROOT=”/usr/lib/go-1.8” // 引号内设置为你自己的go安装目录<br> export GOBIN=$GOROOT/bin<br> export GOPATH=”/home/test/gopath” // 引号内设置为自己的go项目的工作区间<br> export PATH=$PATH:$GOPATH/bin    // 原路径后用冒号连接新路径<br>1<br>2<br>3<br>4<br>使文件立刻生效，$ source ~/.profile<br>重启系统即可</p>\n","site":{"data":{}},"excerpt":"","more":"<p>1、Ubuntu保存环境变量的几个文件<br>/etc/profile<br>在用户登录时，操作系统定制用户环境时使用的第一个文件，此文件为系统的每个用户设置环境信息，当用户第一次登录时，该文件被执行。</p>\n<p>/etc /environment<br>在用户登录时，操作系统使用的第二个文件， 系统在读取用户个人的profile前，设置环境文件的环境变量。</p>\n<p>~/.profile<br>在用户登录时，用到的第三个文件 是.profile文件，每个用户都可使用该文件输入专用于自己使用的shell信息，当用户登录时，该文件仅仅执行一次！默认情况下，会设置一些环境变量，执行用户的.bashrc文件。</p>\n<p>/etc/bashrc<br>为每一个运行bash shell的用户执行此文件，当bash shell被打开时，该文件被读取。</p>\n<p>~/.bashrc<br>该文件包含专用于用户的bash shell的bash信息，当登录时以及每次打开新的shell时，该该文件被读取。<br>       …<br> 14 export http_proxy=<a href=\"http://child-prc.intel.com:913/\" target=\"_blank\" rel=\"noopener\">http://child-prc.intel.com:913/</a><br> 15 export https_proxy=<a href=\"http://child-prc.intel.com:913/\" target=\"_blank\" rel=\"noopener\">http://child-prc.intel.com:913/</a><br>这样修改每次yum,pip等工具下载文件时候不能再写policy<br>使文件立刻生效，$ source ~/.profile</p>\n<p>Note： 以上文件可通过$ sudo gedit 文件名 或 $ sudo vim 文件名打开；建议只修改<del>/.profile文件，如果只修改</del>/.bashrc文件，后期使用go get 命令时，会提示GOPATH未设置。<br>2、设置GOPATH和GOROOT<br>$ sudo gedit ~/.profile<br>在文件最后添加<br> export GOROOT=”/usr/lib/go-1.8” // 引号内设置为你自己的go安装目录<br> export GOBIN=$GOROOT/bin<br> export GOPATH=”/home/test/gopath” // 引号内设置为自己的go项目的工作区间<br> export PATH=$PATH:$GOPATH/bin    // 原路径后用冒号连接新路径<br>1<br>2<br>3<br>4<br>使文件立刻生效，$ source ~/.profile<br>重启系统即可</p>\n"},{"title":"Linux中禁用命令历史记录","_content":"\n## 关闭history记录功能\n\n\t$ set +o history\n## 打开history记录功能\n\n\t$ set -o history\n## 清空记录\n\n\t$ history -c 记录被清空，重新登录后恢复。\n\t$ rm -f $HOME/.bash_history 删除记录文件，清空历史。\n\n","source":"_posts/linux/history.md","raw":"---\ntitle: Linux中禁用命令历史记录\ntags: \ncategories: \n- linux\n---\n\n## 关闭history记录功能\n\n\t$ set +o history\n## 打开history记录功能\n\n\t$ set -o history\n## 清空记录\n\n\t$ history -c 记录被清空，重新登录后恢复。\n\t$ rm -f $HOME/.bash_history 删除记录文件，清空历史。\n\n","slug":"linux/history","published":1,"date":"2020-08-12T16:05:46.239Z","updated":"2020-08-10T08:40:34.014Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfg002ghohx90hnc481","content":"<h2 id=\"关闭history记录功能\"><a href=\"#关闭history记录功能\" class=\"headerlink\" title=\"关闭history记录功能\"></a>关闭history记录功能</h2><pre><code>$ set +o history</code></pre><h2 id=\"打开history记录功能\"><a href=\"#打开history记录功能\" class=\"headerlink\" title=\"打开history记录功能\"></a>打开history记录功能</h2><pre><code>$ set -o history</code></pre><h2 id=\"清空记录\"><a href=\"#清空记录\" class=\"headerlink\" title=\"清空记录\"></a>清空记录</h2><pre><code>$ history -c 记录被清空，重新登录后恢复。\n$ rm -f $HOME/.bash_history 删除记录文件，清空历史。</code></pre>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"关闭history记录功能\"><a href=\"#关闭history记录功能\" class=\"headerlink\" title=\"关闭history记录功能\"></a>关闭history记录功能</h2><pre><code>$ set +o history</code></pre><h2 id=\"打开history记录功能\"><a href=\"#打开history记录功能\" class=\"headerlink\" title=\"打开history记录功能\"></a>打开history记录功能</h2><pre><code>$ set -o history</code></pre><h2 id=\"清空记录\"><a href=\"#清空记录\" class=\"headerlink\" title=\"清空记录\"></a>清空记录</h2><pre><code>$ history -c 记录被清空，重新登录后恢复。\n$ rm -f $HOME/.bash_history 删除记录文件，清空历史。</code></pre>"},{"title":"fdisk磁盘分区","_content":"\n## **查看分区**\n查看磁盘格式类型, UUID, 挂载点\n\n\t$ lsblk -f\n\t NAME            FSTYPE      LABEL UUID                                   MOUNTPOINT\n\t sda\n\t ├─sda1          xfs               eadc654f-b75a-4d81-8e17-910031209006   /var/lib/kubelet/pods/0ef567bf-3636-455b-a585-6a9d8ab1b2dd/volumes/kubernetes.io~local-volume/local-pv-f\n\t ├─sda2          xfs               47f36b35-c3fd-4374-86d6-0e56bb72eb02   /mnt/disks/47f36b35-c3fd-4374-86d6-0e56bb72eb02\n\t ├─sda3          xfs               fea5b28a-8ac4-4736-9487-42517fd242de   /var/lib/kubelet/pods/e447c269-bbfd-4d59-9e01-432f14b75b26/volumes/kubernetes.io~local-volume/local-pv-3\n\t ├─sda4          xfs               516c6d3c-c639-4092-82b6-0a82d09edff3   /var/lib/kubelet/pods/794961eb-3eb7-4cc2-b252-8d39d496b298/volumes/kubernetes.io~local-volume/local-pv-b\n\t └─sda5          xfs               a7b1ca2d-5d08-411e-83e5-9fff59d554be   /mnt/disks/a7b1ca2d-5d08-411e-83e5-9fff59d554be\n\t sdb             LVM2_member       OvpWBO-5AmD-7b4H-Plsn-twvB-k2oC-A5Aaca\n\t └─ceph--7ee2d5aa--c451--44d1--8ff8--0d6394d5fb48-osd--data--9ca735f4--03c4--4f1d--89d8--bcd78778ce6c\n\t \n\t sdc             LVM2_member       3x1Vwv-POeH-igqu-yuRn-ex2l-oDp3-9FaFPi\n\t └─ceph--c0d1ccc4--5130--4697--b9a2--e9c58cbc5f7b-osd--data--91d305f7--cfc5--4ca1--b787--35fefcc6f938\n\t \n\t nvme0n1\n\t ├─nvme0n1p1     vfat              3E80-8EF9                              /boot/efi\n\t ├─nvme0n1p2     xfs               d4e9a380-5394-47ff-8682-9f3ec689060c   /boot\n\t └─nvme0n1p3     LVM2_member       2JVUdy-83cp-vH1n-LLAV-vMwZ-twiw-bhBNDH\n\t   ├─centos-root xfs               51083aeb-a167-4fe9-aced-fa14c2a18953   /\n\t   ├─centos-swap swap              ebcd1018-d259-4d2c-bfd0-46abdc143201\n\t   └─centos-home xfs               ada9d310-ffee-4b08-9350-3e222614c11b   /home\n查看磁盘大小等信息\n\n\t$ lsblk\n\t NAME                                    MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT\n\t sda                                       8:0    0   1.8T  0 disk\n\t ├─sda1                                    8:1    0    10G  0 part /var/lib/kubelet/pods/0ef567bf-3636-455b-a585-6a9d8ab1b2dd/volumes/kubernetes.io~local-volume/local-pv-f902c4d0\n\t ├─sda2                                    8:2    0    10G  0 part /mnt/disks/47f36b35-c3fd-4374-86d6-0e56bb72eb02\n\t ├─sda3                                    8:3    0    30G  0 part /var/lib/kubelet/pods/e447c269-bbfd-4d59-9e01-432f14b75b26/volumes/kubernetes.io~local-volume/local-pv-3f8c242c\n\t ├─sda4                                    8:4    0   200G  0 part /var/lib/kubelet/pods/794961eb-3eb7-4cc2-b252-8d39d496b298/volumes/kubernetes.io~local-volume/local-pv-bcf24291\n\t └─sda5                                    8:5    0   500G  0 part /mnt/disks/a7b1ca2d-5d08-411e-83e5-9fff59d554be\n\t sdb                                       8:16   0   1.8T  0 disk\n\t └─ceph--7ee2d5aa--c451--44d1--8ff8--0d6394d5fb48-osd--data--9ca735f4--03c4--4f1d--89d8--bcd78778ce6c\n\t                                         253:3    0   1.8T  0 lvm\n\t sdc                                       8:32   0   1.8T  0 disk\n\t └─ceph--c0d1ccc4--5130--4697--b9a2--e9c58cbc5f7b-osd--data--91d305f7--cfc5--4ca1--b787--35fefcc6f938\n\t                                         253:4    0   1.8T  0 lvm\n\t nvme0n1                                 259:0    0   477G  0 disk\n\t ├─nvme0n1p1                             259:1    0   200M  0 part /boot/efi\n\t ├─nvme0n1p2                             259:2    0     1G  0 part /boot\n\t └─nvme0n1p3                             259:3    0 475.8G  0 part\n\t   ├─centos-root                         253:0    0    50G  0 lvm  /\n\t   ├─centos-swap                         253:1    0     4G  0 lvm\n\t   └─centos-home                         253:2    0 421.8G  0 lvm  /home\n\n## **执行分区**\n\n\t$ fdisk /dev/sda\n\t WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion.\n\t Welcome to fdisk (util-linux 2.23.2).\n\t \n\t Changes will remain in memory only, until you decide to write them.\n\t Be careful before using the write command.\n\t \n\t Command (m for help): `p`\n\t \n\t Disk /dev/sda: 1920.4 GB, 1920383410176 bytes, 3750748848 sectors\n\t Units = sectors of 1 * 512 = 512 bytes\n\t Sector size (logical/physical): 512 bytes / 4096 bytes\n\t I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n\t Disk label type: gpt\n\t Disk identifier: 6427BFAE-2D0B-4DBB-91E7-80D20C8A1DA7\n\t \n\t #         Start          End    Size  Type            Name\n\t  1         4096     20971519     10G  Microsoft basic primary\n\t  2     20971520     41943039     10G  Microsoft basic primary\n\t  3     41943040    104857599     30G  Microsoft basic primary\n\t  4    104857600    524287999    200G  Microsoft basic primary\n\t  5    524288000   1572863999    500G  Microsoft basic primary\n\t \n\t Command (m for help): `n`\n\t Partition number (6-128, default 6):\n\t First sector (34-3750748814, default 1572864000):\n\t Last sector, +sectors or +size{K,M,G,T,P} (1572864000-3750748814, default 3750748814): `+10G`\n\t Created partition 6\n\t \n\t Command (m for help): `p`\n\t \n\t Disk /dev/sda: 1920.4 GB, 1920383410176 bytes, 3750748848 sectors\n\t Units = sectors of 1 * 512 = 512 bytes\n\t Sector size (logical/physical): 512 bytes / 4096 bytes\n\t I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n\t Disk label type: gpt\n\t Disk identifier: 6427BFAE-2D0B-4DBB-91E7-80D20C8A1DA7\n\t \n\t #         Start          End    Size  Type            Name\n\t  1         4096     20971519     10G  Microsoft basic primary\n\t  2     20971520     41943039     10G  Microsoft basic primary\n\t  3     41943040    104857599     30G  Microsoft basic primary\n\t  4    104857600    524287999    200G  Microsoft basic primary\n\t  5    524288000   1572863999    500G  Microsoft basic primary\n\t  6   1572864000   1593835519     10G  Linux filesyste\n\t \n\t Command (m for help): `w`\n\t The partition table has been altered!\n\t \n\t Calling ioctl() to re-read partition table.\n\t \n\t WARNING: Re-reading the partition table failed with error 16: Device or resource busy.\n\t The kernel still uses the old table. The new table will be used at\n\t the next reboot or after you run partprobe(8) or kpartx(8)\n\t Syncing disks.\n\n## **不重启机器,Kernel重新加载磁盘table**\n查看磁盘文件\n\n\t$ ls /dev/sda*\n\t /dev/sda  /dev/sda1  /dev/sda2  /dev/sda3  /dev/sda4  /dev/sda5 \t// 没有sda6磁盘\n进行Kernel sync disks\n\n\t$ partprobe /dev/sda\n\t$ lsblk -f\n\t NAME            FSTYPE      LABEL UUID                                   MOUNTPOINT\n\t sda\n\t ├─sda1          xfs               eadc654f-b75a-4d81-8e17-910031209006   /var/lib/kubelet/pods/0ef567bf-3636-455b-a585-6a9d8ab1b2dd/volumes/kubernetes.io~local-volume/local-pv-f\n\t ......\n\t └─sda6\n\t sdb             LVM2_member       OvpWBO-5AmD-7b4H-Plsn-twvB-k2oC-A5Aaca\n\t └─ceph--7ee2d5aa--c451--44d1--8ff8--0d6394d5fb48-osd--data--9ca735f4--03c4--4f1d--89d8--bcd78778ce6c\n\t \n\t sdc             LVM2_member       3x1Vwv-POeH-igqu-yuRn-ex2l-oDp3-9FaFPi\n\t └─ceph--c0d1ccc4--5130--4697--b9a2--e9c58cbc5f7b-osd--data--91d305f7--cfc5--4ca1--b787--35fefcc6f938\n\t ......\n\n## **删除分区**\n\n\t$ fdisk /dev/sda\n\t m \t\t// 查看命令\n\t d \t\t// 删除分区\n\t 6 \t\t// 选择要删除的partition\n\t w \t\t// 输入 w  保存，这个时候分区以及删除了\n\n## **格式化分区**\n在设备上格式化成指定格式的文件系统；  centos 7以后的版本默认使用xfs格式  ；也可以指定 ext3\\4格式\n\n\tfs：指定建立文件系统时的参数；\n\t-t<文件系统类型>：指定要建立何种文件系统；\n\t-v：显示版本信息与详细的使用方法；\n\t-V：显示简要的使用方法；\n\t-c：在制做档案系统前，检查该partition是否有坏轨。\n格式为xfs,所以使用mkfs.xfs命令。**`如果已有其他文件系统创建在此分区，必须加上\"-f\"参数来覆盖它`**\n\n\tmkfs.xfs -f  -i size=512 -l size=128m,lazy-count=1 -d agcount=64 /dev/xvda3\n\t-i size=512 : 默认的值是256KB，当内容小于这个值时，写到inode中，超过这个值时，写到block中。\n\t-l size=128m :默认值的是10m，修改这个参数成128m，可以显著的提高xfs文件系统删除文件的速度，当然还有其它，如拷贝文件的速度。\n\t-l lazy-count=1: 值可以是0或者1；默认值是0;在一些配置上显著提高性能；\n\t-d agcount=4 : 默认值是根据容量自动设置的。可以设置成1/2/4/16等等，这个参数可以调节对CPU的占用率，值越小，占用率越低；因为我的硬盘为2T的大硬盘，所以设置64；\n**Use Case:**\n\n\t$ mkfs.xfs -f /dev/sda6        格式化sda6磁盘\n\t mkfs.xfs -f /dev/sda6\n\t meta-data=/dev/sda6              isize=512    agcount=4, agsize=655360 blks\n\t          =                       sectsz=4096  attr=2, projid32bit=1\n\t          =                       crc=1        finobt=0, sparse=0\n\t data     =                       bsize=4096   blocks=2621440, imaxpct=25\n\t          =                       sunit=0      swidth=0 blks\n\t naming   =version 2              bsize=4096   ascii-ci=0 ftype=1\n\t log      =internal log           bsize=4096   blocks=2560, version=2\n\t          =                       sectsz=4096  sunit=1 blks, lazy-count=1\n\t realtime =none                   extsz=4096   blocks=0, rtextents=0\n\t$ lsblk\n\t NAME                                    MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT\n\t sda                                       8:0    0   1.8T  0 disk\n\t ├─sda1                                    8:1    0    10G  0 part /var/lib/kubelet/pods/0ef567bf-3636-455b-a585-6a9d8ab1b2dd/volumes/kubernetes.io~local-volume/local-pv-f902c4d0\n\t ......\n\t └─sda6                                    8:6    0    10G  0 part\n\t$ lsblk -f\n\t NAME            FSTYPE      LABEL UUID                                   MOUNTPOINT\n\t sda\n\t ├─sda1          xfs               eadc654f-b75a-4d81-8e17-910031209006   /var/lib/kubelet/pods/0ef567bf-3636-455b-a585-6a9d8ab1b2dd/volumes/kubernetes.io~local-volume/local-pv-f\n\t ......\n\t └─sda6          xfs               8c653ffc-4b28-47d1-9e7f-32f8d969757a\n\n## **挂载分区**\n\n\t$ mkdir /d1 \n\t$ mount /dev/sda6 /d1 \n**设置开机自动挂载新建分区**\n\n\t$ vim /etc/fstab\n\t #\n\t # /etc/fstab\n\t # Created by anaconda on Fri Apr  3 16:29:28 2020\n\t #\n\t # Accessible filesystems, by reference, are maintained under '/dev/disk'\n\t # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info\n\t #\n\t /dev/mapper/centos-root /                       xfs     defaults        0 0\n\t /dev/mapper/centos-home /home                   xfs     defaults        0 0\n\t UUID=eadc654f-b75a-4d81-8e17-910031209006 /mnt/disks/eadc654f-b75a-4d81-8e17-910031209006 xfs defaults 0 2\n\t UUID=47f36b35-c3fd-4374-86d6-0e56bb72eb02 /mnt/disks/47f36b35-c3fd-4374-86d6-0e56bb72eb02 xfs defaults 0 2\n\t UUID=fea5b28a-8ac4-4736-9487-42517fd242de /mnt/disks/fea5b28a-8ac4-4736-9487-42517fd242de xfs defaults 0 2\n\t UUID=516c6d3c-c639-4092-82b6-0a82d09edff3 /mnt/disks/516c6d3c-c639-4092-82b6-0a82d09edff3 xfs defaults 0 2\n\t UUID=a7b1ca2d-5d08-411e-83e5-9fff59d554be /mnt/disks/a7b1ca2d-5d08-411e-83e5-9fff59d554be xfs defaults 0 2\n\t UUID=8c653ffc-4b28-47d1-9e7f-32f8d969757a /mnt/disks/My-Directory xfs default 0 2\n/etc/fstab文件负责配置Linux开机时自动挂载的分区\n\n\t 第一列可以是实际分区名，也可以是实际分区的卷标（Lable）\n\t 第二列是挂载点,挂载点必须为当前已经存在的目录\n\t 第三列为此分区的文件系统类型\n\t 第四列是挂载的选项，用于设置挂载的参数\n\t * auto: 系统自动挂载，fstab默认就是这个选项\n\t * defaults: rw, suid, dev, exec, auto, nouser, and async.\n\t * noauto 开机不自动挂载\n\t * nouser 只有超级用户可以挂载\n\t * ro 按只读权限挂载\n\t * rw 按可读可写权限挂载\n\t * user 任何用户都可以挂载\n\t 请注意光驱和软驱只有在装有介质时才可以进行挂载，因此它是noauto\n\t 第五列是dump备份设置,当其值设置为1时，将允许dump备份程序备份；设置为0时，忽略备份操作；\n\t 第六列是fsck磁盘检查设置,其值是一个顺序。当其值为0时，永远不检查；而 / 根目录分区永远都为1。其它分区从2开始，数字越小越先检查，如果两个分区的数字相同，则同时检查。\n\n## **卸载分区**\n\n\t$ umount /dev/sda6\n\n\n\n\n","source":"_posts/linux/fdisk磁盘分区.md","raw":"---\ntitle: fdisk磁盘分区\ntags: \ncategories:\n- linux\n---\n\n## **查看分区**\n查看磁盘格式类型, UUID, 挂载点\n\n\t$ lsblk -f\n\t NAME            FSTYPE      LABEL UUID                                   MOUNTPOINT\n\t sda\n\t ├─sda1          xfs               eadc654f-b75a-4d81-8e17-910031209006   /var/lib/kubelet/pods/0ef567bf-3636-455b-a585-6a9d8ab1b2dd/volumes/kubernetes.io~local-volume/local-pv-f\n\t ├─sda2          xfs               47f36b35-c3fd-4374-86d6-0e56bb72eb02   /mnt/disks/47f36b35-c3fd-4374-86d6-0e56bb72eb02\n\t ├─sda3          xfs               fea5b28a-8ac4-4736-9487-42517fd242de   /var/lib/kubelet/pods/e447c269-bbfd-4d59-9e01-432f14b75b26/volumes/kubernetes.io~local-volume/local-pv-3\n\t ├─sda4          xfs               516c6d3c-c639-4092-82b6-0a82d09edff3   /var/lib/kubelet/pods/794961eb-3eb7-4cc2-b252-8d39d496b298/volumes/kubernetes.io~local-volume/local-pv-b\n\t └─sda5          xfs               a7b1ca2d-5d08-411e-83e5-9fff59d554be   /mnt/disks/a7b1ca2d-5d08-411e-83e5-9fff59d554be\n\t sdb             LVM2_member       OvpWBO-5AmD-7b4H-Plsn-twvB-k2oC-A5Aaca\n\t └─ceph--7ee2d5aa--c451--44d1--8ff8--0d6394d5fb48-osd--data--9ca735f4--03c4--4f1d--89d8--bcd78778ce6c\n\t \n\t sdc             LVM2_member       3x1Vwv-POeH-igqu-yuRn-ex2l-oDp3-9FaFPi\n\t └─ceph--c0d1ccc4--5130--4697--b9a2--e9c58cbc5f7b-osd--data--91d305f7--cfc5--4ca1--b787--35fefcc6f938\n\t \n\t nvme0n1\n\t ├─nvme0n1p1     vfat              3E80-8EF9                              /boot/efi\n\t ├─nvme0n1p2     xfs               d4e9a380-5394-47ff-8682-9f3ec689060c   /boot\n\t └─nvme0n1p3     LVM2_member       2JVUdy-83cp-vH1n-LLAV-vMwZ-twiw-bhBNDH\n\t   ├─centos-root xfs               51083aeb-a167-4fe9-aced-fa14c2a18953   /\n\t   ├─centos-swap swap              ebcd1018-d259-4d2c-bfd0-46abdc143201\n\t   └─centos-home xfs               ada9d310-ffee-4b08-9350-3e222614c11b   /home\n查看磁盘大小等信息\n\n\t$ lsblk\n\t NAME                                    MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT\n\t sda                                       8:0    0   1.8T  0 disk\n\t ├─sda1                                    8:1    0    10G  0 part /var/lib/kubelet/pods/0ef567bf-3636-455b-a585-6a9d8ab1b2dd/volumes/kubernetes.io~local-volume/local-pv-f902c4d0\n\t ├─sda2                                    8:2    0    10G  0 part /mnt/disks/47f36b35-c3fd-4374-86d6-0e56bb72eb02\n\t ├─sda3                                    8:3    0    30G  0 part /var/lib/kubelet/pods/e447c269-bbfd-4d59-9e01-432f14b75b26/volumes/kubernetes.io~local-volume/local-pv-3f8c242c\n\t ├─sda4                                    8:4    0   200G  0 part /var/lib/kubelet/pods/794961eb-3eb7-4cc2-b252-8d39d496b298/volumes/kubernetes.io~local-volume/local-pv-bcf24291\n\t └─sda5                                    8:5    0   500G  0 part /mnt/disks/a7b1ca2d-5d08-411e-83e5-9fff59d554be\n\t sdb                                       8:16   0   1.8T  0 disk\n\t └─ceph--7ee2d5aa--c451--44d1--8ff8--0d6394d5fb48-osd--data--9ca735f4--03c4--4f1d--89d8--bcd78778ce6c\n\t                                         253:3    0   1.8T  0 lvm\n\t sdc                                       8:32   0   1.8T  0 disk\n\t └─ceph--c0d1ccc4--5130--4697--b9a2--e9c58cbc5f7b-osd--data--91d305f7--cfc5--4ca1--b787--35fefcc6f938\n\t                                         253:4    0   1.8T  0 lvm\n\t nvme0n1                                 259:0    0   477G  0 disk\n\t ├─nvme0n1p1                             259:1    0   200M  0 part /boot/efi\n\t ├─nvme0n1p2                             259:2    0     1G  0 part /boot\n\t └─nvme0n1p3                             259:3    0 475.8G  0 part\n\t   ├─centos-root                         253:0    0    50G  0 lvm  /\n\t   ├─centos-swap                         253:1    0     4G  0 lvm\n\t   └─centos-home                         253:2    0 421.8G  0 lvm  /home\n\n## **执行分区**\n\n\t$ fdisk /dev/sda\n\t WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion.\n\t Welcome to fdisk (util-linux 2.23.2).\n\t \n\t Changes will remain in memory only, until you decide to write them.\n\t Be careful before using the write command.\n\t \n\t Command (m for help): `p`\n\t \n\t Disk /dev/sda: 1920.4 GB, 1920383410176 bytes, 3750748848 sectors\n\t Units = sectors of 1 * 512 = 512 bytes\n\t Sector size (logical/physical): 512 bytes / 4096 bytes\n\t I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n\t Disk label type: gpt\n\t Disk identifier: 6427BFAE-2D0B-4DBB-91E7-80D20C8A1DA7\n\t \n\t #         Start          End    Size  Type            Name\n\t  1         4096     20971519     10G  Microsoft basic primary\n\t  2     20971520     41943039     10G  Microsoft basic primary\n\t  3     41943040    104857599     30G  Microsoft basic primary\n\t  4    104857600    524287999    200G  Microsoft basic primary\n\t  5    524288000   1572863999    500G  Microsoft basic primary\n\t \n\t Command (m for help): `n`\n\t Partition number (6-128, default 6):\n\t First sector (34-3750748814, default 1572864000):\n\t Last sector, +sectors or +size{K,M,G,T,P} (1572864000-3750748814, default 3750748814): `+10G`\n\t Created partition 6\n\t \n\t Command (m for help): `p`\n\t \n\t Disk /dev/sda: 1920.4 GB, 1920383410176 bytes, 3750748848 sectors\n\t Units = sectors of 1 * 512 = 512 bytes\n\t Sector size (logical/physical): 512 bytes / 4096 bytes\n\t I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n\t Disk label type: gpt\n\t Disk identifier: 6427BFAE-2D0B-4DBB-91E7-80D20C8A1DA7\n\t \n\t #         Start          End    Size  Type            Name\n\t  1         4096     20971519     10G  Microsoft basic primary\n\t  2     20971520     41943039     10G  Microsoft basic primary\n\t  3     41943040    104857599     30G  Microsoft basic primary\n\t  4    104857600    524287999    200G  Microsoft basic primary\n\t  5    524288000   1572863999    500G  Microsoft basic primary\n\t  6   1572864000   1593835519     10G  Linux filesyste\n\t \n\t Command (m for help): `w`\n\t The partition table has been altered!\n\t \n\t Calling ioctl() to re-read partition table.\n\t \n\t WARNING: Re-reading the partition table failed with error 16: Device or resource busy.\n\t The kernel still uses the old table. The new table will be used at\n\t the next reboot or after you run partprobe(8) or kpartx(8)\n\t Syncing disks.\n\n## **不重启机器,Kernel重新加载磁盘table**\n查看磁盘文件\n\n\t$ ls /dev/sda*\n\t /dev/sda  /dev/sda1  /dev/sda2  /dev/sda3  /dev/sda4  /dev/sda5 \t// 没有sda6磁盘\n进行Kernel sync disks\n\n\t$ partprobe /dev/sda\n\t$ lsblk -f\n\t NAME            FSTYPE      LABEL UUID                                   MOUNTPOINT\n\t sda\n\t ├─sda1          xfs               eadc654f-b75a-4d81-8e17-910031209006   /var/lib/kubelet/pods/0ef567bf-3636-455b-a585-6a9d8ab1b2dd/volumes/kubernetes.io~local-volume/local-pv-f\n\t ......\n\t └─sda6\n\t sdb             LVM2_member       OvpWBO-5AmD-7b4H-Plsn-twvB-k2oC-A5Aaca\n\t └─ceph--7ee2d5aa--c451--44d1--8ff8--0d6394d5fb48-osd--data--9ca735f4--03c4--4f1d--89d8--bcd78778ce6c\n\t \n\t sdc             LVM2_member       3x1Vwv-POeH-igqu-yuRn-ex2l-oDp3-9FaFPi\n\t └─ceph--c0d1ccc4--5130--4697--b9a2--e9c58cbc5f7b-osd--data--91d305f7--cfc5--4ca1--b787--35fefcc6f938\n\t ......\n\n## **删除分区**\n\n\t$ fdisk /dev/sda\n\t m \t\t// 查看命令\n\t d \t\t// 删除分区\n\t 6 \t\t// 选择要删除的partition\n\t w \t\t// 输入 w  保存，这个时候分区以及删除了\n\n## **格式化分区**\n在设备上格式化成指定格式的文件系统；  centos 7以后的版本默认使用xfs格式  ；也可以指定 ext3\\4格式\n\n\tfs：指定建立文件系统时的参数；\n\t-t<文件系统类型>：指定要建立何种文件系统；\n\t-v：显示版本信息与详细的使用方法；\n\t-V：显示简要的使用方法；\n\t-c：在制做档案系统前，检查该partition是否有坏轨。\n格式为xfs,所以使用mkfs.xfs命令。**`如果已有其他文件系统创建在此分区，必须加上\"-f\"参数来覆盖它`**\n\n\tmkfs.xfs -f  -i size=512 -l size=128m,lazy-count=1 -d agcount=64 /dev/xvda3\n\t-i size=512 : 默认的值是256KB，当内容小于这个值时，写到inode中，超过这个值时，写到block中。\n\t-l size=128m :默认值的是10m，修改这个参数成128m，可以显著的提高xfs文件系统删除文件的速度，当然还有其它，如拷贝文件的速度。\n\t-l lazy-count=1: 值可以是0或者1；默认值是0;在一些配置上显著提高性能；\n\t-d agcount=4 : 默认值是根据容量自动设置的。可以设置成1/2/4/16等等，这个参数可以调节对CPU的占用率，值越小，占用率越低；因为我的硬盘为2T的大硬盘，所以设置64；\n**Use Case:**\n\n\t$ mkfs.xfs -f /dev/sda6        格式化sda6磁盘\n\t mkfs.xfs -f /dev/sda6\n\t meta-data=/dev/sda6              isize=512    agcount=4, agsize=655360 blks\n\t          =                       sectsz=4096  attr=2, projid32bit=1\n\t          =                       crc=1        finobt=0, sparse=0\n\t data     =                       bsize=4096   blocks=2621440, imaxpct=25\n\t          =                       sunit=0      swidth=0 blks\n\t naming   =version 2              bsize=4096   ascii-ci=0 ftype=1\n\t log      =internal log           bsize=4096   blocks=2560, version=2\n\t          =                       sectsz=4096  sunit=1 blks, lazy-count=1\n\t realtime =none                   extsz=4096   blocks=0, rtextents=0\n\t$ lsblk\n\t NAME                                    MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT\n\t sda                                       8:0    0   1.8T  0 disk\n\t ├─sda1                                    8:1    0    10G  0 part /var/lib/kubelet/pods/0ef567bf-3636-455b-a585-6a9d8ab1b2dd/volumes/kubernetes.io~local-volume/local-pv-f902c4d0\n\t ......\n\t └─sda6                                    8:6    0    10G  0 part\n\t$ lsblk -f\n\t NAME            FSTYPE      LABEL UUID                                   MOUNTPOINT\n\t sda\n\t ├─sda1          xfs               eadc654f-b75a-4d81-8e17-910031209006   /var/lib/kubelet/pods/0ef567bf-3636-455b-a585-6a9d8ab1b2dd/volumes/kubernetes.io~local-volume/local-pv-f\n\t ......\n\t └─sda6          xfs               8c653ffc-4b28-47d1-9e7f-32f8d969757a\n\n## **挂载分区**\n\n\t$ mkdir /d1 \n\t$ mount /dev/sda6 /d1 \n**设置开机自动挂载新建分区**\n\n\t$ vim /etc/fstab\n\t #\n\t # /etc/fstab\n\t # Created by anaconda on Fri Apr  3 16:29:28 2020\n\t #\n\t # Accessible filesystems, by reference, are maintained under '/dev/disk'\n\t # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info\n\t #\n\t /dev/mapper/centos-root /                       xfs     defaults        0 0\n\t /dev/mapper/centos-home /home                   xfs     defaults        0 0\n\t UUID=eadc654f-b75a-4d81-8e17-910031209006 /mnt/disks/eadc654f-b75a-4d81-8e17-910031209006 xfs defaults 0 2\n\t UUID=47f36b35-c3fd-4374-86d6-0e56bb72eb02 /mnt/disks/47f36b35-c3fd-4374-86d6-0e56bb72eb02 xfs defaults 0 2\n\t UUID=fea5b28a-8ac4-4736-9487-42517fd242de /mnt/disks/fea5b28a-8ac4-4736-9487-42517fd242de xfs defaults 0 2\n\t UUID=516c6d3c-c639-4092-82b6-0a82d09edff3 /mnt/disks/516c6d3c-c639-4092-82b6-0a82d09edff3 xfs defaults 0 2\n\t UUID=a7b1ca2d-5d08-411e-83e5-9fff59d554be /mnt/disks/a7b1ca2d-5d08-411e-83e5-9fff59d554be xfs defaults 0 2\n\t UUID=8c653ffc-4b28-47d1-9e7f-32f8d969757a /mnt/disks/My-Directory xfs default 0 2\n/etc/fstab文件负责配置Linux开机时自动挂载的分区\n\n\t 第一列可以是实际分区名，也可以是实际分区的卷标（Lable）\n\t 第二列是挂载点,挂载点必须为当前已经存在的目录\n\t 第三列为此分区的文件系统类型\n\t 第四列是挂载的选项，用于设置挂载的参数\n\t * auto: 系统自动挂载，fstab默认就是这个选项\n\t * defaults: rw, suid, dev, exec, auto, nouser, and async.\n\t * noauto 开机不自动挂载\n\t * nouser 只有超级用户可以挂载\n\t * ro 按只读权限挂载\n\t * rw 按可读可写权限挂载\n\t * user 任何用户都可以挂载\n\t 请注意光驱和软驱只有在装有介质时才可以进行挂载，因此它是noauto\n\t 第五列是dump备份设置,当其值设置为1时，将允许dump备份程序备份；设置为0时，忽略备份操作；\n\t 第六列是fsck磁盘检查设置,其值是一个顺序。当其值为0时，永远不检查；而 / 根目录分区永远都为1。其它分区从2开始，数字越小越先检查，如果两个分区的数字相同，则同时检查。\n\n## **卸载分区**\n\n\t$ umount /dev/sda6\n\n\n\n\n","slug":"linux/fdisk磁盘分区","published":1,"date":"2020-08-12T16:05:46.223Z","updated":"2020-08-03T12:15:46.989Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfh002ihohxhmzqc9m2","content":"<h2 id=\"查看分区\"><a href=\"#查看分区\" class=\"headerlink\" title=\"查看分区\"></a><strong>查看分区</strong></h2><p>查看磁盘格式类型, UUID, 挂载点</p>\n<pre><code>$ lsblk -f\n NAME            FSTYPE      LABEL UUID                                   MOUNTPOINT\n sda\n ├─sda1          xfs               eadc654f-b75a-4d81-8e17-910031209006   /var/lib/kubelet/pods/0ef567bf-3636-455b-a585-6a9d8ab1b2dd/volumes/kubernetes.io~local-volume/local-pv-f\n ├─sda2          xfs               47f36b35-c3fd-4374-86d6-0e56bb72eb02   /mnt/disks/47f36b35-c3fd-4374-86d6-0e56bb72eb02\n ├─sda3          xfs               fea5b28a-8ac4-4736-9487-42517fd242de   /var/lib/kubelet/pods/e447c269-bbfd-4d59-9e01-432f14b75b26/volumes/kubernetes.io~local-volume/local-pv-3\n ├─sda4          xfs               516c6d3c-c639-4092-82b6-0a82d09edff3   /var/lib/kubelet/pods/794961eb-3eb7-4cc2-b252-8d39d496b298/volumes/kubernetes.io~local-volume/local-pv-b\n └─sda5          xfs               a7b1ca2d-5d08-411e-83e5-9fff59d554be   /mnt/disks/a7b1ca2d-5d08-411e-83e5-9fff59d554be\n sdb             LVM2_member       OvpWBO-5AmD-7b4H-Plsn-twvB-k2oC-A5Aaca\n └─ceph--7ee2d5aa--c451--44d1--8ff8--0d6394d5fb48-osd--data--9ca735f4--03c4--4f1d--89d8--bcd78778ce6c\n\n sdc             LVM2_member       3x1Vwv-POeH-igqu-yuRn-ex2l-oDp3-9FaFPi\n └─ceph--c0d1ccc4--5130--4697--b9a2--e9c58cbc5f7b-osd--data--91d305f7--cfc5--4ca1--b787--35fefcc6f938\n\n nvme0n1\n ├─nvme0n1p1     vfat              3E80-8EF9                              /boot/efi\n ├─nvme0n1p2     xfs               d4e9a380-5394-47ff-8682-9f3ec689060c   /boot\n └─nvme0n1p3     LVM2_member       2JVUdy-83cp-vH1n-LLAV-vMwZ-twiw-bhBNDH\n   ├─centos-root xfs               51083aeb-a167-4fe9-aced-fa14c2a18953   /\n   ├─centos-swap swap              ebcd1018-d259-4d2c-bfd0-46abdc143201\n   └─centos-home xfs               ada9d310-ffee-4b08-9350-3e222614c11b   /home</code></pre><p>查看磁盘大小等信息</p>\n<pre><code>$ lsblk\n NAME                                    MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT\n sda                                       8:0    0   1.8T  0 disk\n ├─sda1                                    8:1    0    10G  0 part /var/lib/kubelet/pods/0ef567bf-3636-455b-a585-6a9d8ab1b2dd/volumes/kubernetes.io~local-volume/local-pv-f902c4d0\n ├─sda2                                    8:2    0    10G  0 part /mnt/disks/47f36b35-c3fd-4374-86d6-0e56bb72eb02\n ├─sda3                                    8:3    0    30G  0 part /var/lib/kubelet/pods/e447c269-bbfd-4d59-9e01-432f14b75b26/volumes/kubernetes.io~local-volume/local-pv-3f8c242c\n ├─sda4                                    8:4    0   200G  0 part /var/lib/kubelet/pods/794961eb-3eb7-4cc2-b252-8d39d496b298/volumes/kubernetes.io~local-volume/local-pv-bcf24291\n └─sda5                                    8:5    0   500G  0 part /mnt/disks/a7b1ca2d-5d08-411e-83e5-9fff59d554be\n sdb                                       8:16   0   1.8T  0 disk\n └─ceph--7ee2d5aa--c451--44d1--8ff8--0d6394d5fb48-osd--data--9ca735f4--03c4--4f1d--89d8--bcd78778ce6c\n                                         253:3    0   1.8T  0 lvm\n sdc                                       8:32   0   1.8T  0 disk\n └─ceph--c0d1ccc4--5130--4697--b9a2--e9c58cbc5f7b-osd--data--91d305f7--cfc5--4ca1--b787--35fefcc6f938\n                                         253:4    0   1.8T  0 lvm\n nvme0n1                                 259:0    0   477G  0 disk\n ├─nvme0n1p1                             259:1    0   200M  0 part /boot/efi\n ├─nvme0n1p2                             259:2    0     1G  0 part /boot\n └─nvme0n1p3                             259:3    0 475.8G  0 part\n   ├─centos-root                         253:0    0    50G  0 lvm  /\n   ├─centos-swap                         253:1    0     4G  0 lvm\n   └─centos-home                         253:2    0 421.8G  0 lvm  /home</code></pre><h2 id=\"执行分区\"><a href=\"#执行分区\" class=\"headerlink\" title=\"执行分区\"></a><strong>执行分区</strong></h2><pre><code>$ fdisk /dev/sda\n WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion.\n Welcome to fdisk (util-linux 2.23.2).\n\n Changes will remain in memory only, until you decide to write them.\n Be careful before using the write command.\n\n Command (m for help): `p`\n\n Disk /dev/sda: 1920.4 GB, 1920383410176 bytes, 3750748848 sectors\n Units = sectors of 1 * 512 = 512 bytes\n Sector size (logical/physical): 512 bytes / 4096 bytes\n I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n Disk label type: gpt\n Disk identifier: 6427BFAE-2D0B-4DBB-91E7-80D20C8A1DA7\n\n #         Start          End    Size  Type            Name\n  1         4096     20971519     10G  Microsoft basic primary\n  2     20971520     41943039     10G  Microsoft basic primary\n  3     41943040    104857599     30G  Microsoft basic primary\n  4    104857600    524287999    200G  Microsoft basic primary\n  5    524288000   1572863999    500G  Microsoft basic primary\n\n Command (m for help): `n`\n Partition number (6-128, default 6):\n First sector (34-3750748814, default 1572864000):\n Last sector, +sectors or +size{K,M,G,T,P} (1572864000-3750748814, default 3750748814): `+10G`\n Created partition 6\n\n Command (m for help): `p`\n\n Disk /dev/sda: 1920.4 GB, 1920383410176 bytes, 3750748848 sectors\n Units = sectors of 1 * 512 = 512 bytes\n Sector size (logical/physical): 512 bytes / 4096 bytes\n I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n Disk label type: gpt\n Disk identifier: 6427BFAE-2D0B-4DBB-91E7-80D20C8A1DA7\n\n #         Start          End    Size  Type            Name\n  1         4096     20971519     10G  Microsoft basic primary\n  2     20971520     41943039     10G  Microsoft basic primary\n  3     41943040    104857599     30G  Microsoft basic primary\n  4    104857600    524287999    200G  Microsoft basic primary\n  5    524288000   1572863999    500G  Microsoft basic primary\n  6   1572864000   1593835519     10G  Linux filesyste\n\n Command (m for help): `w`\n The partition table has been altered!\n\n Calling ioctl() to re-read partition table.\n\n WARNING: Re-reading the partition table failed with error 16: Device or resource busy.\n The kernel still uses the old table. The new table will be used at\n the next reboot or after you run partprobe(8) or kpartx(8)\n Syncing disks.</code></pre><h2 id=\"不重启机器-Kernel重新加载磁盘table\"><a href=\"#不重启机器-Kernel重新加载磁盘table\" class=\"headerlink\" title=\"不重启机器,Kernel重新加载磁盘table\"></a><strong>不重启机器,Kernel重新加载磁盘table</strong></h2><p>查看磁盘文件</p>\n<pre><code>$ ls /dev/sda*\n /dev/sda  /dev/sda1  /dev/sda2  /dev/sda3  /dev/sda4  /dev/sda5     // 没有sda6磁盘</code></pre><p>进行Kernel sync disks</p>\n<pre><code>$ partprobe /dev/sda\n$ lsblk -f\n NAME            FSTYPE      LABEL UUID                                   MOUNTPOINT\n sda\n ├─sda1          xfs               eadc654f-b75a-4d81-8e17-910031209006   /var/lib/kubelet/pods/0ef567bf-3636-455b-a585-6a9d8ab1b2dd/volumes/kubernetes.io~local-volume/local-pv-f\n ......\n └─sda6\n sdb             LVM2_member       OvpWBO-5AmD-7b4H-Plsn-twvB-k2oC-A5Aaca\n └─ceph--7ee2d5aa--c451--44d1--8ff8--0d6394d5fb48-osd--data--9ca735f4--03c4--4f1d--89d8--bcd78778ce6c\n\n sdc             LVM2_member       3x1Vwv-POeH-igqu-yuRn-ex2l-oDp3-9FaFPi\n └─ceph--c0d1ccc4--5130--4697--b9a2--e9c58cbc5f7b-osd--data--91d305f7--cfc5--4ca1--b787--35fefcc6f938\n ......</code></pre><h2 id=\"删除分区\"><a href=\"#删除分区\" class=\"headerlink\" title=\"删除分区\"></a><strong>删除分区</strong></h2><pre><code>$ fdisk /dev/sda\n m         // 查看命令\n d         // 删除分区\n 6         // 选择要删除的partition\n w         // 输入 w  保存，这个时候分区以及删除了</code></pre><h2 id=\"格式化分区\"><a href=\"#格式化分区\" class=\"headerlink\" title=\"格式化分区\"></a><strong>格式化分区</strong></h2><p>在设备上格式化成指定格式的文件系统；  centos 7以后的版本默认使用xfs格式  ；也可以指定 ext3\\4格式</p>\n<pre><code>fs：指定建立文件系统时的参数；\n-t&lt;文件系统类型&gt;：指定要建立何种文件系统；\n-v：显示版本信息与详细的使用方法；\n-V：显示简要的使用方法；\n-c：在制做档案系统前，检查该partition是否有坏轨。</code></pre><p>格式为xfs,所以使用mkfs.xfs命令。<strong><code>如果已有其他文件系统创建在此分区，必须加上&quot;-f&quot;参数来覆盖它</code></strong></p>\n<pre><code>mkfs.xfs -f  -i size=512 -l size=128m,lazy-count=1 -d agcount=64 /dev/xvda3\n-i size=512 : 默认的值是256KB，当内容小于这个值时，写到inode中，超过这个值时，写到block中。\n-l size=128m :默认值的是10m，修改这个参数成128m，可以显著的提高xfs文件系统删除文件的速度，当然还有其它，如拷贝文件的速度。\n-l lazy-count=1: 值可以是0或者1；默认值是0;在一些配置上显著提高性能；\n-d agcount=4 : 默认值是根据容量自动设置的。可以设置成1/2/4/16等等，这个参数可以调节对CPU的占用率，值越小，占用率越低；因为我的硬盘为2T的大硬盘，所以设置64；</code></pre><p><strong>Use Case:</strong></p>\n<pre><code>$ mkfs.xfs -f /dev/sda6        格式化sda6磁盘\n mkfs.xfs -f /dev/sda6\n meta-data=/dev/sda6              isize=512    agcount=4, agsize=655360 blks\n          =                       sectsz=4096  attr=2, projid32bit=1\n          =                       crc=1        finobt=0, sparse=0\n data     =                       bsize=4096   blocks=2621440, imaxpct=25\n          =                       sunit=0      swidth=0 blks\n naming   =version 2              bsize=4096   ascii-ci=0 ftype=1\n log      =internal log           bsize=4096   blocks=2560, version=2\n          =                       sectsz=4096  sunit=1 blks, lazy-count=1\n realtime =none                   extsz=4096   blocks=0, rtextents=0\n$ lsblk\n NAME                                    MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT\n sda                                       8:0    0   1.8T  0 disk\n ├─sda1                                    8:1    0    10G  0 part /var/lib/kubelet/pods/0ef567bf-3636-455b-a585-6a9d8ab1b2dd/volumes/kubernetes.io~local-volume/local-pv-f902c4d0\n ......\n └─sda6                                    8:6    0    10G  0 part\n$ lsblk -f\n NAME            FSTYPE      LABEL UUID                                   MOUNTPOINT\n sda\n ├─sda1          xfs               eadc654f-b75a-4d81-8e17-910031209006   /var/lib/kubelet/pods/0ef567bf-3636-455b-a585-6a9d8ab1b2dd/volumes/kubernetes.io~local-volume/local-pv-f\n ......\n └─sda6          xfs               8c653ffc-4b28-47d1-9e7f-32f8d969757a</code></pre><h2 id=\"挂载分区\"><a href=\"#挂载分区\" class=\"headerlink\" title=\"挂载分区\"></a><strong>挂载分区</strong></h2><pre><code>$ mkdir /d1 \n$ mount /dev/sda6 /d1 </code></pre><p><strong>设置开机自动挂载新建分区</strong></p>\n<pre><code>$ vim /etc/fstab\n #\n # /etc/fstab\n # Created by anaconda on Fri Apr  3 16:29:28 2020\n #\n # Accessible filesystems, by reference, are maintained under &apos;/dev/disk&apos;\n # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info\n #\n /dev/mapper/centos-root /                       xfs     defaults        0 0\n /dev/mapper/centos-home /home                   xfs     defaults        0 0\n UUID=eadc654f-b75a-4d81-8e17-910031209006 /mnt/disks/eadc654f-b75a-4d81-8e17-910031209006 xfs defaults 0 2\n UUID=47f36b35-c3fd-4374-86d6-0e56bb72eb02 /mnt/disks/47f36b35-c3fd-4374-86d6-0e56bb72eb02 xfs defaults 0 2\n UUID=fea5b28a-8ac4-4736-9487-42517fd242de /mnt/disks/fea5b28a-8ac4-4736-9487-42517fd242de xfs defaults 0 2\n UUID=516c6d3c-c639-4092-82b6-0a82d09edff3 /mnt/disks/516c6d3c-c639-4092-82b6-0a82d09edff3 xfs defaults 0 2\n UUID=a7b1ca2d-5d08-411e-83e5-9fff59d554be /mnt/disks/a7b1ca2d-5d08-411e-83e5-9fff59d554be xfs defaults 0 2\n UUID=8c653ffc-4b28-47d1-9e7f-32f8d969757a /mnt/disks/My-Directory xfs default 0 2</code></pre><p>/etc/fstab文件负责配置Linux开机时自动挂载的分区</p>\n<pre><code>第一列可以是实际分区名，也可以是实际分区的卷标（Lable）\n第二列是挂载点,挂载点必须为当前已经存在的目录\n第三列为此分区的文件系统类型\n第四列是挂载的选项，用于设置挂载的参数\n* auto: 系统自动挂载，fstab默认就是这个选项\n* defaults: rw, suid, dev, exec, auto, nouser, and async.\n* noauto 开机不自动挂载\n* nouser 只有超级用户可以挂载\n* ro 按只读权限挂载\n* rw 按可读可写权限挂载\n* user 任何用户都可以挂载\n请注意光驱和软驱只有在装有介质时才可以进行挂载，因此它是noauto\n第五列是dump备份设置,当其值设置为1时，将允许dump备份程序备份；设置为0时，忽略备份操作；\n第六列是fsck磁盘检查设置,其值是一个顺序。当其值为0时，永远不检查；而 / 根目录分区永远都为1。其它分区从2开始，数字越小越先检查，如果两个分区的数字相同，则同时检查。</code></pre><h2 id=\"卸载分区\"><a href=\"#卸载分区\" class=\"headerlink\" title=\"卸载分区\"></a><strong>卸载分区</strong></h2><pre><code>$ umount /dev/sda6</code></pre>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"查看分区\"><a href=\"#查看分区\" class=\"headerlink\" title=\"查看分区\"></a><strong>查看分区</strong></h2><p>查看磁盘格式类型, UUID, 挂载点</p>\n<pre><code>$ lsblk -f\n NAME            FSTYPE      LABEL UUID                                   MOUNTPOINT\n sda\n ├─sda1          xfs               eadc654f-b75a-4d81-8e17-910031209006   /var/lib/kubelet/pods/0ef567bf-3636-455b-a585-6a9d8ab1b2dd/volumes/kubernetes.io~local-volume/local-pv-f\n ├─sda2          xfs               47f36b35-c3fd-4374-86d6-0e56bb72eb02   /mnt/disks/47f36b35-c3fd-4374-86d6-0e56bb72eb02\n ├─sda3          xfs               fea5b28a-8ac4-4736-9487-42517fd242de   /var/lib/kubelet/pods/e447c269-bbfd-4d59-9e01-432f14b75b26/volumes/kubernetes.io~local-volume/local-pv-3\n ├─sda4          xfs               516c6d3c-c639-4092-82b6-0a82d09edff3   /var/lib/kubelet/pods/794961eb-3eb7-4cc2-b252-8d39d496b298/volumes/kubernetes.io~local-volume/local-pv-b\n └─sda5          xfs               a7b1ca2d-5d08-411e-83e5-9fff59d554be   /mnt/disks/a7b1ca2d-5d08-411e-83e5-9fff59d554be\n sdb             LVM2_member       OvpWBO-5AmD-7b4H-Plsn-twvB-k2oC-A5Aaca\n └─ceph--7ee2d5aa--c451--44d1--8ff8--0d6394d5fb48-osd--data--9ca735f4--03c4--4f1d--89d8--bcd78778ce6c\n\n sdc             LVM2_member       3x1Vwv-POeH-igqu-yuRn-ex2l-oDp3-9FaFPi\n └─ceph--c0d1ccc4--5130--4697--b9a2--e9c58cbc5f7b-osd--data--91d305f7--cfc5--4ca1--b787--35fefcc6f938\n\n nvme0n1\n ├─nvme0n1p1     vfat              3E80-8EF9                              /boot/efi\n ├─nvme0n1p2     xfs               d4e9a380-5394-47ff-8682-9f3ec689060c   /boot\n └─nvme0n1p3     LVM2_member       2JVUdy-83cp-vH1n-LLAV-vMwZ-twiw-bhBNDH\n   ├─centos-root xfs               51083aeb-a167-4fe9-aced-fa14c2a18953   /\n   ├─centos-swap swap              ebcd1018-d259-4d2c-bfd0-46abdc143201\n   └─centos-home xfs               ada9d310-ffee-4b08-9350-3e222614c11b   /home</code></pre><p>查看磁盘大小等信息</p>\n<pre><code>$ lsblk\n NAME                                    MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT\n sda                                       8:0    0   1.8T  0 disk\n ├─sda1                                    8:1    0    10G  0 part /var/lib/kubelet/pods/0ef567bf-3636-455b-a585-6a9d8ab1b2dd/volumes/kubernetes.io~local-volume/local-pv-f902c4d0\n ├─sda2                                    8:2    0    10G  0 part /mnt/disks/47f36b35-c3fd-4374-86d6-0e56bb72eb02\n ├─sda3                                    8:3    0    30G  0 part /var/lib/kubelet/pods/e447c269-bbfd-4d59-9e01-432f14b75b26/volumes/kubernetes.io~local-volume/local-pv-3f8c242c\n ├─sda4                                    8:4    0   200G  0 part /var/lib/kubelet/pods/794961eb-3eb7-4cc2-b252-8d39d496b298/volumes/kubernetes.io~local-volume/local-pv-bcf24291\n └─sda5                                    8:5    0   500G  0 part /mnt/disks/a7b1ca2d-5d08-411e-83e5-9fff59d554be\n sdb                                       8:16   0   1.8T  0 disk\n └─ceph--7ee2d5aa--c451--44d1--8ff8--0d6394d5fb48-osd--data--9ca735f4--03c4--4f1d--89d8--bcd78778ce6c\n                                         253:3    0   1.8T  0 lvm\n sdc                                       8:32   0   1.8T  0 disk\n └─ceph--c0d1ccc4--5130--4697--b9a2--e9c58cbc5f7b-osd--data--91d305f7--cfc5--4ca1--b787--35fefcc6f938\n                                         253:4    0   1.8T  0 lvm\n nvme0n1                                 259:0    0   477G  0 disk\n ├─nvme0n1p1                             259:1    0   200M  0 part /boot/efi\n ├─nvme0n1p2                             259:2    0     1G  0 part /boot\n └─nvme0n1p3                             259:3    0 475.8G  0 part\n   ├─centos-root                         253:0    0    50G  0 lvm  /\n   ├─centos-swap                         253:1    0     4G  0 lvm\n   └─centos-home                         253:2    0 421.8G  0 lvm  /home</code></pre><h2 id=\"执行分区\"><a href=\"#执行分区\" class=\"headerlink\" title=\"执行分区\"></a><strong>执行分区</strong></h2><pre><code>$ fdisk /dev/sda\n WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion.\n Welcome to fdisk (util-linux 2.23.2).\n\n Changes will remain in memory only, until you decide to write them.\n Be careful before using the write command.\n\n Command (m for help): `p`\n\n Disk /dev/sda: 1920.4 GB, 1920383410176 bytes, 3750748848 sectors\n Units = sectors of 1 * 512 = 512 bytes\n Sector size (logical/physical): 512 bytes / 4096 bytes\n I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n Disk label type: gpt\n Disk identifier: 6427BFAE-2D0B-4DBB-91E7-80D20C8A1DA7\n\n #         Start          End    Size  Type            Name\n  1         4096     20971519     10G  Microsoft basic primary\n  2     20971520     41943039     10G  Microsoft basic primary\n  3     41943040    104857599     30G  Microsoft basic primary\n  4    104857600    524287999    200G  Microsoft basic primary\n  5    524288000   1572863999    500G  Microsoft basic primary\n\n Command (m for help): `n`\n Partition number (6-128, default 6):\n First sector (34-3750748814, default 1572864000):\n Last sector, +sectors or +size{K,M,G,T,P} (1572864000-3750748814, default 3750748814): `+10G`\n Created partition 6\n\n Command (m for help): `p`\n\n Disk /dev/sda: 1920.4 GB, 1920383410176 bytes, 3750748848 sectors\n Units = sectors of 1 * 512 = 512 bytes\n Sector size (logical/physical): 512 bytes / 4096 bytes\n I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n Disk label type: gpt\n Disk identifier: 6427BFAE-2D0B-4DBB-91E7-80D20C8A1DA7\n\n #         Start          End    Size  Type            Name\n  1         4096     20971519     10G  Microsoft basic primary\n  2     20971520     41943039     10G  Microsoft basic primary\n  3     41943040    104857599     30G  Microsoft basic primary\n  4    104857600    524287999    200G  Microsoft basic primary\n  5    524288000   1572863999    500G  Microsoft basic primary\n  6   1572864000   1593835519     10G  Linux filesyste\n\n Command (m for help): `w`\n The partition table has been altered!\n\n Calling ioctl() to re-read partition table.\n\n WARNING: Re-reading the partition table failed with error 16: Device or resource busy.\n The kernel still uses the old table. The new table will be used at\n the next reboot or after you run partprobe(8) or kpartx(8)\n Syncing disks.</code></pre><h2 id=\"不重启机器-Kernel重新加载磁盘table\"><a href=\"#不重启机器-Kernel重新加载磁盘table\" class=\"headerlink\" title=\"不重启机器,Kernel重新加载磁盘table\"></a><strong>不重启机器,Kernel重新加载磁盘table</strong></h2><p>查看磁盘文件</p>\n<pre><code>$ ls /dev/sda*\n /dev/sda  /dev/sda1  /dev/sda2  /dev/sda3  /dev/sda4  /dev/sda5     // 没有sda6磁盘</code></pre><p>进行Kernel sync disks</p>\n<pre><code>$ partprobe /dev/sda\n$ lsblk -f\n NAME            FSTYPE      LABEL UUID                                   MOUNTPOINT\n sda\n ├─sda1          xfs               eadc654f-b75a-4d81-8e17-910031209006   /var/lib/kubelet/pods/0ef567bf-3636-455b-a585-6a9d8ab1b2dd/volumes/kubernetes.io~local-volume/local-pv-f\n ......\n └─sda6\n sdb             LVM2_member       OvpWBO-5AmD-7b4H-Plsn-twvB-k2oC-A5Aaca\n └─ceph--7ee2d5aa--c451--44d1--8ff8--0d6394d5fb48-osd--data--9ca735f4--03c4--4f1d--89d8--bcd78778ce6c\n\n sdc             LVM2_member       3x1Vwv-POeH-igqu-yuRn-ex2l-oDp3-9FaFPi\n └─ceph--c0d1ccc4--5130--4697--b9a2--e9c58cbc5f7b-osd--data--91d305f7--cfc5--4ca1--b787--35fefcc6f938\n ......</code></pre><h2 id=\"删除分区\"><a href=\"#删除分区\" class=\"headerlink\" title=\"删除分区\"></a><strong>删除分区</strong></h2><pre><code>$ fdisk /dev/sda\n m         // 查看命令\n d         // 删除分区\n 6         // 选择要删除的partition\n w         // 输入 w  保存，这个时候分区以及删除了</code></pre><h2 id=\"格式化分区\"><a href=\"#格式化分区\" class=\"headerlink\" title=\"格式化分区\"></a><strong>格式化分区</strong></h2><p>在设备上格式化成指定格式的文件系统；  centos 7以后的版本默认使用xfs格式  ；也可以指定 ext3\\4格式</p>\n<pre><code>fs：指定建立文件系统时的参数；\n-t&lt;文件系统类型&gt;：指定要建立何种文件系统；\n-v：显示版本信息与详细的使用方法；\n-V：显示简要的使用方法；\n-c：在制做档案系统前，检查该partition是否有坏轨。</code></pre><p>格式为xfs,所以使用mkfs.xfs命令。<strong><code>如果已有其他文件系统创建在此分区，必须加上&quot;-f&quot;参数来覆盖它</code></strong></p>\n<pre><code>mkfs.xfs -f  -i size=512 -l size=128m,lazy-count=1 -d agcount=64 /dev/xvda3\n-i size=512 : 默认的值是256KB，当内容小于这个值时，写到inode中，超过这个值时，写到block中。\n-l size=128m :默认值的是10m，修改这个参数成128m，可以显著的提高xfs文件系统删除文件的速度，当然还有其它，如拷贝文件的速度。\n-l lazy-count=1: 值可以是0或者1；默认值是0;在一些配置上显著提高性能；\n-d agcount=4 : 默认值是根据容量自动设置的。可以设置成1/2/4/16等等，这个参数可以调节对CPU的占用率，值越小，占用率越低；因为我的硬盘为2T的大硬盘，所以设置64；</code></pre><p><strong>Use Case:</strong></p>\n<pre><code>$ mkfs.xfs -f /dev/sda6        格式化sda6磁盘\n mkfs.xfs -f /dev/sda6\n meta-data=/dev/sda6              isize=512    agcount=4, agsize=655360 blks\n          =                       sectsz=4096  attr=2, projid32bit=1\n          =                       crc=1        finobt=0, sparse=0\n data     =                       bsize=4096   blocks=2621440, imaxpct=25\n          =                       sunit=0      swidth=0 blks\n naming   =version 2              bsize=4096   ascii-ci=0 ftype=1\n log      =internal log           bsize=4096   blocks=2560, version=2\n          =                       sectsz=4096  sunit=1 blks, lazy-count=1\n realtime =none                   extsz=4096   blocks=0, rtextents=0\n$ lsblk\n NAME                                    MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT\n sda                                       8:0    0   1.8T  0 disk\n ├─sda1                                    8:1    0    10G  0 part /var/lib/kubelet/pods/0ef567bf-3636-455b-a585-6a9d8ab1b2dd/volumes/kubernetes.io~local-volume/local-pv-f902c4d0\n ......\n └─sda6                                    8:6    0    10G  0 part\n$ lsblk -f\n NAME            FSTYPE      LABEL UUID                                   MOUNTPOINT\n sda\n ├─sda1          xfs               eadc654f-b75a-4d81-8e17-910031209006   /var/lib/kubelet/pods/0ef567bf-3636-455b-a585-6a9d8ab1b2dd/volumes/kubernetes.io~local-volume/local-pv-f\n ......\n └─sda6          xfs               8c653ffc-4b28-47d1-9e7f-32f8d969757a</code></pre><h2 id=\"挂载分区\"><a href=\"#挂载分区\" class=\"headerlink\" title=\"挂载分区\"></a><strong>挂载分区</strong></h2><pre><code>$ mkdir /d1 \n$ mount /dev/sda6 /d1 </code></pre><p><strong>设置开机自动挂载新建分区</strong></p>\n<pre><code>$ vim /etc/fstab\n #\n # /etc/fstab\n # Created by anaconda on Fri Apr  3 16:29:28 2020\n #\n # Accessible filesystems, by reference, are maintained under &apos;/dev/disk&apos;\n # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info\n #\n /dev/mapper/centos-root /                       xfs     defaults        0 0\n /dev/mapper/centos-home /home                   xfs     defaults        0 0\n UUID=eadc654f-b75a-4d81-8e17-910031209006 /mnt/disks/eadc654f-b75a-4d81-8e17-910031209006 xfs defaults 0 2\n UUID=47f36b35-c3fd-4374-86d6-0e56bb72eb02 /mnt/disks/47f36b35-c3fd-4374-86d6-0e56bb72eb02 xfs defaults 0 2\n UUID=fea5b28a-8ac4-4736-9487-42517fd242de /mnt/disks/fea5b28a-8ac4-4736-9487-42517fd242de xfs defaults 0 2\n UUID=516c6d3c-c639-4092-82b6-0a82d09edff3 /mnt/disks/516c6d3c-c639-4092-82b6-0a82d09edff3 xfs defaults 0 2\n UUID=a7b1ca2d-5d08-411e-83e5-9fff59d554be /mnt/disks/a7b1ca2d-5d08-411e-83e5-9fff59d554be xfs defaults 0 2\n UUID=8c653ffc-4b28-47d1-9e7f-32f8d969757a /mnt/disks/My-Directory xfs default 0 2</code></pre><p>/etc/fstab文件负责配置Linux开机时自动挂载的分区</p>\n<pre><code>第一列可以是实际分区名，也可以是实际分区的卷标（Lable）\n第二列是挂载点,挂载点必须为当前已经存在的目录\n第三列为此分区的文件系统类型\n第四列是挂载的选项，用于设置挂载的参数\n* auto: 系统自动挂载，fstab默认就是这个选项\n* defaults: rw, suid, dev, exec, auto, nouser, and async.\n* noauto 开机不自动挂载\n* nouser 只有超级用户可以挂载\n* ro 按只读权限挂载\n* rw 按可读可写权限挂载\n* user 任何用户都可以挂载\n请注意光驱和软驱只有在装有介质时才可以进行挂载，因此它是noauto\n第五列是dump备份设置,当其值设置为1时，将允许dump备份程序备份；设置为0时，忽略备份操作；\n第六列是fsck磁盘检查设置,其值是一个顺序。当其值为0时，永远不检查；而 / 根目录分区永远都为1。其它分区从2开始，数字越小越先检查，如果两个分区的数字相同，则同时检查。</code></pre><h2 id=\"卸载分区\"><a href=\"#卸载分区\" class=\"headerlink\" title=\"卸载分区\"></a><strong>卸载分区</strong></h2><pre><code>$ umount /dev/sda6</code></pre>"},{"title":"linux制作U盘启动盘","_content":"1. 找到U盘:\nsudo fdisk -l\n![](fdisk.png)\n\n2. 卸载U盘:\nsudo umount /dev/sdb1\n![](umount.png)\n\n3. 格式化U盘:\nsudo mkfs.vfat /dev/sdb -I\n![](mkfs.png)\n\n4. 制作启动盘:\ndd时候，of=跟上U盘的根，如sdc是U盘，分出的还有一个区(卷)sdc1, 那么of=/dev/sdc而不是sdc1\nsudo dd if=~/Downloads/ubuntu-16.04-desktop-amd64.iso of=/dev/sdb status=progress\n![](dd.png)\n\n小技巧, 加上status=progress 可以看到进度\n\n制作完成后发现32GB的U盘空间只有几百M，可以用如下命令清空U盘\n但是原来的U盘文件全部删除\n\t1. # dd if=/dev/zero of=/dev/${USB}\n\t注:\n\t(1).# 为 root\n\t(2).${USB} = 你的USB\n\t2. 格式化U盘\n\tmkfs.vfat /dev/sdb -I\n","source":"_posts/linux/linux制作U盘启动盘.md","raw":"---\ntitle: linux制作U盘启动盘\ntags:\ncategories:\n- linux\n---\n1. 找到U盘:\nsudo fdisk -l\n![](fdisk.png)\n\n2. 卸载U盘:\nsudo umount /dev/sdb1\n![](umount.png)\n\n3. 格式化U盘:\nsudo mkfs.vfat /dev/sdb -I\n![](mkfs.png)\n\n4. 制作启动盘:\ndd时候，of=跟上U盘的根，如sdc是U盘，分出的还有一个区(卷)sdc1, 那么of=/dev/sdc而不是sdc1\nsudo dd if=~/Downloads/ubuntu-16.04-desktop-amd64.iso of=/dev/sdb status=progress\n![](dd.png)\n\n小技巧, 加上status=progress 可以看到进度\n\n制作完成后发现32GB的U盘空间只有几百M，可以用如下命令清空U盘\n但是原来的U盘文件全部删除\n\t1. # dd if=/dev/zero of=/dev/${USB}\n\t注:\n\t(1).# 为 root\n\t(2).${USB} = 你的USB\n\t2. 格式化U盘\n\tmkfs.vfat /dev/sdb -I\n","slug":"linux/linux制作U盘启动盘","published":1,"date":"2020-08-12T16:05:46.290Z","updated":"2020-02-13T12:47:44.488Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfi002lhohxe7yn13q1","content":"<ol>\n<li><p>找到U盘:<br>sudo fdisk -l<br><img src=\"fdisk.png\" alt=\"\"></p>\n</li>\n<li><p>卸载U盘:<br>sudo umount /dev/sdb1<br><img src=\"umount.png\" alt=\"\"></p>\n</li>\n<li><p>格式化U盘:<br>sudo mkfs.vfat /dev/sdb -I<br><img src=\"mkfs.png\" alt=\"\"></p>\n</li>\n<li><p>制作启动盘:<br>dd时候，of=跟上U盘的根，如sdc是U盘，分出的还有一个区(卷)sdc1, 那么of=/dev/sdc而不是sdc1<br>sudo dd if=~/Downloads/ubuntu-16.04-desktop-amd64.iso of=/dev/sdb status=progress<br><img src=\"dd.png\" alt=\"\"></p>\n</li>\n</ol>\n<p>小技巧, 加上status=progress 可以看到进度</p>\n<p>制作完成后发现32GB的U盘空间只有几百M，可以用如下命令清空U盘<br>但是原来的U盘文件全部删除<br>    1. # dd if=/dev/zero of=/dev/${USB}<br>    注:<br>    (1).# 为 root<br>    (2).${USB} = 你的USB<br>    2. 格式化U盘<br>    mkfs.vfat /dev/sdb -I</p>\n","site":{"data":{}},"excerpt":"","more":"<ol>\n<li><p>找到U盘:<br>sudo fdisk -l<br><img src=\"fdisk.png\" alt=\"\"></p>\n</li>\n<li><p>卸载U盘:<br>sudo umount /dev/sdb1<br><img src=\"umount.png\" alt=\"\"></p>\n</li>\n<li><p>格式化U盘:<br>sudo mkfs.vfat /dev/sdb -I<br><img src=\"mkfs.png\" alt=\"\"></p>\n</li>\n<li><p>制作启动盘:<br>dd时候，of=跟上U盘的根，如sdc是U盘，分出的还有一个区(卷)sdc1, 那么of=/dev/sdc而不是sdc1<br>sudo dd if=~/Downloads/ubuntu-16.04-desktop-amd64.iso of=/dev/sdb status=progress<br><img src=\"dd.png\" alt=\"\"></p>\n</li>\n</ol>\n<p>小技巧, 加上status=progress 可以看到进度</p>\n<p>制作完成后发现32GB的U盘空间只有几百M，可以用如下命令清空U盘<br>但是原来的U盘文件全部删除<br>    1. # dd if=/dev/zero of=/dev/${USB}<br>    注:<br>    (1).# 为 root<br>    (2).${USB} = 你的USB<br>    2. 格式化U盘<br>    mkfs.vfat /dev/sdb -I</p>\n"},{"title":"intel_pstate/acpi-cpufreq驱动研究","_content":"查看intel_pstate & cpu-freq驱动\nTag: v5.0\n1.\nlinux/drivers/cpufreq/intel_pstate.c\n\tupdate_turbo_state(void)\n\t\n\tif (hwp_active)\n\t\tintel_pstate_hwp_enable(struct cpudata *cpudata)  \n\t\t\t0x773->0, 0x770->1\n\n\tPn: core_get_min_pstate(void)  \t\tCPU min MHz   // msr: 0x771 P0,P1,Pn HWP Performance Range Enumeration\n\t\t(0xce >> 40) & 0xFF = 0x0a = 10 -> 1000MHz\n\n\tP1: core_get_max_pstate_physical(void) \tCPU max MHz\n\t\t(0xce >> 8) & 0xFF  = 0x17 = 23 -> 2.3GHz\n\n\tP1: core_get_tdp_ratio(u64 plat_info) //1332\n\t\ttdp_msr = 0x64b(0x80000000) & 0x03 + 0x648 = 0x648\n\t\trdmsr 0x648 = 0x17 = 23 -> 2.3GHz\n\n\tP1: core_get_max_pstate(void) //1365\n\t\tif(hwp_active) return tdp_ratio = 2.3GHz\n\t\ttar_levels = 0x64c(80000000) & 0xff = 0\n\t\tif (tdp_ratio - 1 == tar_levels) max_pstate = tar_levels\n\n\tP0: core_get_turbo_pstate(void)  //1400\n\t\t0x1ad & 255 = 0x27 = 39 -> 3.9GHz   msr寄存器0x1ad前7bit值\n\n\tintel_pstate_set_pstate(struct cpudata *cpu, int pstate) // 1453\n\t\t0x199\n\t\t0x198 Core Voltage (R/O) P-state core voltage can be computed by MSR_PERF_STATUS[37:32] * (float) 1/(2^13).\n\n\tintel_pstate_hwp_boost_up(struct cpudata *cpu) // 1516\n\n\tintel_pstate_hwp_boost_down(struct cpudata *cpu) // 1562\n\n\tintel_pstate_calc_avg_perf(struct cpudata *cpu) //1618\n\t\tcore_avg_perf = (aperf << 14) / mperf\n\n\tget_avg_frequency(struct cpudata *cpu) // 1667\n\t\t(aperf << 14) / mperf * cpu_khz >> 14\t  cpu_khz /* TSC clocks / usec, not used here */\t\n\n\tget_avg_pstate(struct cpudata *cpu) //1672\n\t\t(aperf << 14) / mperf * max_pstate_physical >> 14\t\n\n\tstatic struct cpufreq_driver *default_driver = &intel_pstate; // 2327\n\t\t默认是intel_pstate驱动\n\t\t\n\tearly_param(\"intel_pstate\", intel_pstate_setup); //2682\n\t\t读取 /etc/default/grub 引导文件中的参数\n\n2.\nlinux/drivers/cpufreq/acpi-cpufreq.c\n\n3.\nlinux/drivers/cpufreq/cppc_cpufreq.c\n\n4.\nlinux/drivers/idle/intel_idle.c\n","source":"_posts/linux/intel_pstate-acpi-cpufreq驱动研究.md","raw":"---\ntitle: intel_pstate/acpi-cpufreq驱动研究\ntags: \ncategories:\n- linux\n---\n查看intel_pstate & cpu-freq驱动\nTag: v5.0\n1.\nlinux/drivers/cpufreq/intel_pstate.c\n\tupdate_turbo_state(void)\n\t\n\tif (hwp_active)\n\t\tintel_pstate_hwp_enable(struct cpudata *cpudata)  \n\t\t\t0x773->0, 0x770->1\n\n\tPn: core_get_min_pstate(void)  \t\tCPU min MHz   // msr: 0x771 P0,P1,Pn HWP Performance Range Enumeration\n\t\t(0xce >> 40) & 0xFF = 0x0a = 10 -> 1000MHz\n\n\tP1: core_get_max_pstate_physical(void) \tCPU max MHz\n\t\t(0xce >> 8) & 0xFF  = 0x17 = 23 -> 2.3GHz\n\n\tP1: core_get_tdp_ratio(u64 plat_info) //1332\n\t\ttdp_msr = 0x64b(0x80000000) & 0x03 + 0x648 = 0x648\n\t\trdmsr 0x648 = 0x17 = 23 -> 2.3GHz\n\n\tP1: core_get_max_pstate(void) //1365\n\t\tif(hwp_active) return tdp_ratio = 2.3GHz\n\t\ttar_levels = 0x64c(80000000) & 0xff = 0\n\t\tif (tdp_ratio - 1 == tar_levels) max_pstate = tar_levels\n\n\tP0: core_get_turbo_pstate(void)  //1400\n\t\t0x1ad & 255 = 0x27 = 39 -> 3.9GHz   msr寄存器0x1ad前7bit值\n\n\tintel_pstate_set_pstate(struct cpudata *cpu, int pstate) // 1453\n\t\t0x199\n\t\t0x198 Core Voltage (R/O) P-state core voltage can be computed by MSR_PERF_STATUS[37:32] * (float) 1/(2^13).\n\n\tintel_pstate_hwp_boost_up(struct cpudata *cpu) // 1516\n\n\tintel_pstate_hwp_boost_down(struct cpudata *cpu) // 1562\n\n\tintel_pstate_calc_avg_perf(struct cpudata *cpu) //1618\n\t\tcore_avg_perf = (aperf << 14) / mperf\n\n\tget_avg_frequency(struct cpudata *cpu) // 1667\n\t\t(aperf << 14) / mperf * cpu_khz >> 14\t  cpu_khz /* TSC clocks / usec, not used here */\t\n\n\tget_avg_pstate(struct cpudata *cpu) //1672\n\t\t(aperf << 14) / mperf * max_pstate_physical >> 14\t\n\n\tstatic struct cpufreq_driver *default_driver = &intel_pstate; // 2327\n\t\t默认是intel_pstate驱动\n\t\t\n\tearly_param(\"intel_pstate\", intel_pstate_setup); //2682\n\t\t读取 /etc/default/grub 引导文件中的参数\n\n2.\nlinux/drivers/cpufreq/acpi-cpufreq.c\n\n3.\nlinux/drivers/cpufreq/cppc_cpufreq.c\n\n4.\nlinux/drivers/idle/intel_idle.c\n","slug":"linux/intel_pstate-acpi-cpufreq驱动研究","published":1,"date":"2020-08-12T16:05:46.261Z","updated":"2020-02-13T12:47:44.484Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfi002nhohxdu01evvp","content":"<p>查看intel_pstate &amp; cpu-freq驱动<br>Tag: v5.0<br>1.<br>linux/drivers/cpufreq/intel_pstate.c<br>    update_turbo_state(void)</p>\n<pre><code>if (hwp_active)\n    intel_pstate_hwp_enable(struct cpudata *cpudata)  \n        0x773-&gt;0, 0x770-&gt;1\n\nPn: core_get_min_pstate(void)          CPU min MHz   // msr: 0x771 P0,P1,Pn HWP Performance Range Enumeration\n    (0xce &gt;&gt; 40) &amp; 0xFF = 0x0a = 10 -&gt; 1000MHz\n\nP1: core_get_max_pstate_physical(void)     CPU max MHz\n    (0xce &gt;&gt; 8) &amp; 0xFF  = 0x17 = 23 -&gt; 2.3GHz\n\nP1: core_get_tdp_ratio(u64 plat_info) //1332\n    tdp_msr = 0x64b(0x80000000) &amp; 0x03 + 0x648 = 0x648\n    rdmsr 0x648 = 0x17 = 23 -&gt; 2.3GHz\n\nP1: core_get_max_pstate(void) //1365\n    if(hwp_active) return tdp_ratio = 2.3GHz\n    tar_levels = 0x64c(80000000) &amp; 0xff = 0\n    if (tdp_ratio - 1 == tar_levels) max_pstate = tar_levels\n\nP0: core_get_turbo_pstate(void)  //1400\n    0x1ad &amp; 255 = 0x27 = 39 -&gt; 3.9GHz   msr寄存器0x1ad前7bit值\n\nintel_pstate_set_pstate(struct cpudata *cpu, int pstate) // 1453\n    0x199\n    0x198 Core Voltage (R/O) P-state core voltage can be computed by MSR_PERF_STATUS[37:32] * (float) 1/(2^13).\n\nintel_pstate_hwp_boost_up(struct cpudata *cpu) // 1516\n\nintel_pstate_hwp_boost_down(struct cpudata *cpu) // 1562\n\nintel_pstate_calc_avg_perf(struct cpudata *cpu) //1618\n    core_avg_perf = (aperf &lt;&lt; 14) / mperf\n\nget_avg_frequency(struct cpudata *cpu) // 1667\n    (aperf &lt;&lt; 14) / mperf * cpu_khz &gt;&gt; 14      cpu_khz /* TSC clocks / usec, not used here */    \n\nget_avg_pstate(struct cpudata *cpu) //1672\n    (aperf &lt;&lt; 14) / mperf * max_pstate_physical &gt;&gt; 14    \n\nstatic struct cpufreq_driver *default_driver = &amp;intel_pstate; // 2327\n    默认是intel_pstate驱动\n\nearly_param(&quot;intel_pstate&quot;, intel_pstate_setup); //2682\n    读取 /etc/default/grub 引导文件中的参数</code></pre><p>2.<br>linux/drivers/cpufreq/acpi-cpufreq.c</p>\n<p>3.<br>linux/drivers/cpufreq/cppc_cpufreq.c</p>\n<p>4.<br>linux/drivers/idle/intel_idle.c</p>\n","site":{"data":{}},"excerpt":"","more":"<p>查看intel_pstate &amp; cpu-freq驱动<br>Tag: v5.0<br>1.<br>linux/drivers/cpufreq/intel_pstate.c<br>    update_turbo_state(void)</p>\n<pre><code>if (hwp_active)\n    intel_pstate_hwp_enable(struct cpudata *cpudata)  \n        0x773-&gt;0, 0x770-&gt;1\n\nPn: core_get_min_pstate(void)          CPU min MHz   // msr: 0x771 P0,P1,Pn HWP Performance Range Enumeration\n    (0xce &gt;&gt; 40) &amp; 0xFF = 0x0a = 10 -&gt; 1000MHz\n\nP1: core_get_max_pstate_physical(void)     CPU max MHz\n    (0xce &gt;&gt; 8) &amp; 0xFF  = 0x17 = 23 -&gt; 2.3GHz\n\nP1: core_get_tdp_ratio(u64 plat_info) //1332\n    tdp_msr = 0x64b(0x80000000) &amp; 0x03 + 0x648 = 0x648\n    rdmsr 0x648 = 0x17 = 23 -&gt; 2.3GHz\n\nP1: core_get_max_pstate(void) //1365\n    if(hwp_active) return tdp_ratio = 2.3GHz\n    tar_levels = 0x64c(80000000) &amp; 0xff = 0\n    if (tdp_ratio - 1 == tar_levels) max_pstate = tar_levels\n\nP0: core_get_turbo_pstate(void)  //1400\n    0x1ad &amp; 255 = 0x27 = 39 -&gt; 3.9GHz   msr寄存器0x1ad前7bit值\n\nintel_pstate_set_pstate(struct cpudata *cpu, int pstate) // 1453\n    0x199\n    0x198 Core Voltage (R/O) P-state core voltage can be computed by MSR_PERF_STATUS[37:32] * (float) 1/(2^13).\n\nintel_pstate_hwp_boost_up(struct cpudata *cpu) // 1516\n\nintel_pstate_hwp_boost_down(struct cpudata *cpu) // 1562\n\nintel_pstate_calc_avg_perf(struct cpudata *cpu) //1618\n    core_avg_perf = (aperf &lt;&lt; 14) / mperf\n\nget_avg_frequency(struct cpudata *cpu) // 1667\n    (aperf &lt;&lt; 14) / mperf * cpu_khz &gt;&gt; 14      cpu_khz /* TSC clocks / usec, not used here */    \n\nget_avg_pstate(struct cpudata *cpu) //1672\n    (aperf &lt;&lt; 14) / mperf * max_pstate_physical &gt;&gt; 14    \n\nstatic struct cpufreq_driver *default_driver = &amp;intel_pstate; // 2327\n    默认是intel_pstate驱动\n\nearly_param(&quot;intel_pstate&quot;, intel_pstate_setup); //2682\n    读取 /etc/default/grub 引导文件中的参数</code></pre><p>2.<br>linux/drivers/cpufreq/acpi-cpufreq.c</p>\n<p>3.<br>linux/drivers/cpufreq/cppc_cpufreq.c</p>\n<p>4.<br>linux/drivers/idle/intel_idle.c</p>\n"},{"title":"linux向其它终端发送消息","_content":"\n## 查看所有打开的终端\n\n\t$ w -f // 或者只输入`w`查看打开的所有终端, `w`是who的简写而不是write\n\t   16:41:45 up 53 days, 47 min,  5 users,  load average: 0.17, 0.31, 0.38\n\t  USER     TTY        LOGIN@   IDLE   JCPU   PCPU WHAT\n\t  root     pts/0     14:23    1.00s  0.07s  0.00s w -f\n\t  ai       :0        18Jun20 ?xdm?   8days  7.89s /usr/libexec/gnome-session-binary --session gnome-classic\n\t  ai       pts/1     18Jun20 53days  3:28m  3:28m /usr/lib/virtualbox/VirtualBox\n\t  ai       pts/2     16:29   10:49   0.07s  0.02s bash\n\t  root     pts/3     16:27    9:37   0.02s  0.02s -bash\n\n## 向指定终端发送消息\n\n\t$ write ai pts/2\n\t  123\n\n## 广播消息, 向所有终端发送消息\n\n\t$ wall 123\n\t  Broadcast message from root@master-node (pts/0) (Mon Aug 10 16:40:49 2020):\n\t  123\n\n\n","source":"_posts/linux/linux向其它终端发送消息.md","raw":"---\ntitle: linux向其它终端发送消息\ntags: \ncategories: \n- linux\n---\n\n## 查看所有打开的终端\n\n\t$ w -f // 或者只输入`w`查看打开的所有终端, `w`是who的简写而不是write\n\t   16:41:45 up 53 days, 47 min,  5 users,  load average: 0.17, 0.31, 0.38\n\t  USER     TTY        LOGIN@   IDLE   JCPU   PCPU WHAT\n\t  root     pts/0     14:23    1.00s  0.07s  0.00s w -f\n\t  ai       :0        18Jun20 ?xdm?   8days  7.89s /usr/libexec/gnome-session-binary --session gnome-classic\n\t  ai       pts/1     18Jun20 53days  3:28m  3:28m /usr/lib/virtualbox/VirtualBox\n\t  ai       pts/2     16:29   10:49   0.07s  0.02s bash\n\t  root     pts/3     16:27    9:37   0.02s  0.02s -bash\n\n## 向指定终端发送消息\n\n\t$ write ai pts/2\n\t  123\n\n## 广播消息, 向所有终端发送消息\n\n\t$ wall 123\n\t  Broadcast message from root@master-node (pts/0) (Mon Aug 10 16:40:49 2020):\n\t  123\n\n\n","slug":"linux/linux向其它终端发送消息","published":1,"date":"2020-08-12T16:05:46.300Z","updated":"2020-08-10T08:46:40.444Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfj002phohx1th1cime","content":"<h2 id=\"查看所有打开的终端\"><a href=\"#查看所有打开的终端\" class=\"headerlink\" title=\"查看所有打开的终端\"></a>查看所有打开的终端</h2><pre><code>$ w -f // 或者只输入`w`查看打开的所有终端, `w`是who的简写而不是write\n   16:41:45 up 53 days, 47 min,  5 users,  load average: 0.17, 0.31, 0.38\n  USER     TTY        LOGIN@   IDLE   JCPU   PCPU WHAT\n  root     pts/0     14:23    1.00s  0.07s  0.00s w -f\n  ai       :0        18Jun20 ?xdm?   8days  7.89s /usr/libexec/gnome-session-binary --session gnome-classic\n  ai       pts/1     18Jun20 53days  3:28m  3:28m /usr/lib/virtualbox/VirtualBox\n  ai       pts/2     16:29   10:49   0.07s  0.02s bash\n  root     pts/3     16:27    9:37   0.02s  0.02s -bash</code></pre><h2 id=\"向指定终端发送消息\"><a href=\"#向指定终端发送消息\" class=\"headerlink\" title=\"向指定终端发送消息\"></a>向指定终端发送消息</h2><pre><code>$ write ai pts/2\n  123</code></pre><h2 id=\"广播消息-向所有终端发送消息\"><a href=\"#广播消息-向所有终端发送消息\" class=\"headerlink\" title=\"广播消息, 向所有终端发送消息\"></a>广播消息, 向所有终端发送消息</h2><pre><code>$ wall 123\n  Broadcast message from root@master-node (pts/0) (Mon Aug 10 16:40:49 2020):\n  123</code></pre>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"查看所有打开的终端\"><a href=\"#查看所有打开的终端\" class=\"headerlink\" title=\"查看所有打开的终端\"></a>查看所有打开的终端</h2><pre><code>$ w -f // 或者只输入`w`查看打开的所有终端, `w`是who的简写而不是write\n   16:41:45 up 53 days, 47 min,  5 users,  load average: 0.17, 0.31, 0.38\n  USER     TTY        LOGIN@   IDLE   JCPU   PCPU WHAT\n  root     pts/0     14:23    1.00s  0.07s  0.00s w -f\n  ai       :0        18Jun20 ?xdm?   8days  7.89s /usr/libexec/gnome-session-binary --session gnome-classic\n  ai       pts/1     18Jun20 53days  3:28m  3:28m /usr/lib/virtualbox/VirtualBox\n  ai       pts/2     16:29   10:49   0.07s  0.02s bash\n  root     pts/3     16:27    9:37   0.02s  0.02s -bash</code></pre><h2 id=\"向指定终端发送消息\"><a href=\"#向指定终端发送消息\" class=\"headerlink\" title=\"向指定终端发送消息\"></a>向指定终端发送消息</h2><pre><code>$ write ai pts/2\n  123</code></pre><h2 id=\"广播消息-向所有终端发送消息\"><a href=\"#广播消息-向所有终端发送消息\" class=\"headerlink\" title=\"广播消息, 向所有终端发送消息\"></a>广播消息, 向所有终端发送消息</h2><pre><code>$ wall 123\n  Broadcast message from root@master-node (pts/0) (Mon Aug 10 16:40:49 2020):\n  123</code></pre>"},{"title":"查看 linux 系统日志 和 服务的日志","_content":"\n## 查看linux 系统日志\n\n\t$ cat /var/log/messages\n\n## 查看某个服务日志\n\n\t$ journalctl -fu docker\n\t$ journalctl -fu kubelet\n\n## 重新加载系统配置\n\n\t$ systemctl daemon-reload\n","source":"_posts/linux/linux日志_服务日志.md","raw":"---\ntitle: 查看 linux 系统日志 和 服务的日志\ntags: \ncategories: \n- linux\n---\n\n## 查看linux 系统日志\n\n\t$ cat /var/log/messages\n\n## 查看某个服务日志\n\n\t$ journalctl -fu docker\n\t$ journalctl -fu kubelet\n\n## 重新加载系统配置\n\n\t$ systemctl daemon-reload\n","slug":"linux/linux日志_服务日志","published":1,"date":"2020-08-12T16:05:46.315Z","updated":"2020-07-06T08:31:46.431Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfk002rhohxdni184pe","content":"<h2 id=\"查看linux-系统日志\"><a href=\"#查看linux-系统日志\" class=\"headerlink\" title=\"查看linux 系统日志\"></a>查看linux 系统日志</h2><pre><code>$ cat /var/log/messages</code></pre><h2 id=\"查看某个服务日志\"><a href=\"#查看某个服务日志\" class=\"headerlink\" title=\"查看某个服务日志\"></a>查看某个服务日志</h2><pre><code>$ journalctl -fu docker\n$ journalctl -fu kubelet</code></pre><h2 id=\"重新加载系统配置\"><a href=\"#重新加载系统配置\" class=\"headerlink\" title=\"重新加载系统配置\"></a>重新加载系统配置</h2><pre><code>$ systemctl daemon-reload</code></pre>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"查看linux-系统日志\"><a href=\"#查看linux-系统日志\" class=\"headerlink\" title=\"查看linux 系统日志\"></a>查看linux 系统日志</h2><pre><code>$ cat /var/log/messages</code></pre><h2 id=\"查看某个服务日志\"><a href=\"#查看某个服务日志\" class=\"headerlink\" title=\"查看某个服务日志\"></a>查看某个服务日志</h2><pre><code>$ journalctl -fu docker\n$ journalctl -fu kubelet</code></pre><h2 id=\"重新加载系统配置\"><a href=\"#重新加载系统配置\" class=\"headerlink\" title=\"重新加载系统配置\"></a>重新加载系统配置</h2><pre><code>$ systemctl daemon-reload</code></pre>"},{"title":"linux查看运行的服务","_content":"\n## Centos\n\n\t$ systemctl list-units --type=service\n\n\n\n","source":"_posts/linux/linux查看运行的服务.md","raw":"---\ntitle: linux查看运行的服务\ntags: \ncategories: \n- linux\n---\n\n## Centos\n\n\t$ systemctl list-units --type=service\n\n\n\n","slug":"linux/linux查看运行的服务","published":1,"date":"2020-08-12T16:05:46.317Z","updated":"2020-08-10T16:05:01.357Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfl002thohx8api1uab","content":"<h2 id=\"Centos\"><a href=\"#Centos\" class=\"headerlink\" title=\"Centos\"></a>Centos</h2><pre><code>$ systemctl list-units --type=service</code></pre>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Centos\"><a href=\"#Centos\" class=\"headerlink\" title=\"Centos\"></a>Centos</h2><pre><code>$ systemctl list-units --type=service</code></pre>"},{"title":"ln -s - linux 软连接command","_content":"","source":"_posts/linux/ln_-s_-_linux 软连接command.md","raw":"---\ntitle: ln -s - linux 软连接command\ntags: \ncategories:\n- linux\n---\n","slug":"linux/ln_-s_-_linux 软连接command","published":1,"date":"2020-08-12T16:05:46.348Z","updated":"2020-02-13T12:47:44.518Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfm002vhohx01645frx","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"linux给grub添加内核启动参数","_content":"如果你想在系统启动时加载一个内核参数，需修改GRUB的配置模板(/etc/default /grub),添加\"名称=值”的键值对到GRUB_CMDLINE_LINUX变量,添加多个时用空格隔开,例如GRUB_CMDLINE_LINUX=\"...... name=value\"(如果没有GRUB_CMDLINE_LINUX变量时,用GRUB_CMDLINE_LINUX_DEFAULT替代即可).\n1. Debian or Ubuntu\n$ sudo update-grub  //生成grub的配置文件\n$ sudo apt-get install grub2-common  //没有 update-grub命令时,先运行这个安装命令  \n\n2. Fedora or CentOS7\n$ sudo grub2-mkconfig -o /boot/grub2/grub.cfg //生成grub2的配置文件\n$ sudo yum install grub2-tools.x86_64 //没有grub2-mkconfig命令时,先安装grub2-tools\n带EFI的系统,grub.cfg文件会是在/boot/efi下,比如CentOS7:/boot/efi/EFI/centos/grub.cfg\n","source":"_posts/linux/linux给grub添加内核启动参数.md","raw":"---\ntitle: linux给grub添加内核启动参数\ntags: \ncategories:\n- linux\n---\n如果你想在系统启动时加载一个内核参数，需修改GRUB的配置模板(/etc/default /grub),添加\"名称=值”的键值对到GRUB_CMDLINE_LINUX变量,添加多个时用空格隔开,例如GRUB_CMDLINE_LINUX=\"...... name=value\"(如果没有GRUB_CMDLINE_LINUX变量时,用GRUB_CMDLINE_LINUX_DEFAULT替代即可).\n1. Debian or Ubuntu\n$ sudo update-grub  //生成grub的配置文件\n$ sudo apt-get install grub2-common  //没有 update-grub命令时,先运行这个安装命令  \n\n2. Fedora or CentOS7\n$ sudo grub2-mkconfig -o /boot/grub2/grub.cfg //生成grub2的配置文件\n$ sudo yum install grub2-tools.x86_64 //没有grub2-mkconfig命令时,先安装grub2-tools\n带EFI的系统,grub.cfg文件会是在/boot/efi下,比如CentOS7:/boot/efi/EFI/centos/grub.cfg\n","slug":"linux/linux给grub添加内核启动参数","published":1,"date":"2020-08-12T16:05:46.337Z","updated":"2020-02-13T12:47:44.514Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfm002xhohxctwyboln","content":"<p>如果你想在系统启动时加载一个内核参数，需修改GRUB的配置模板(/etc/default /grub),添加”名称=值”的键值对到GRUB_CMDLINE_LINUX变量,添加多个时用空格隔开,例如GRUB_CMDLINE_LINUX=”…… name=value”(如果没有GRUB_CMDLINE_LINUX变量时,用GRUB_CMDLINE_LINUX_DEFAULT替代即可).</p>\n<ol>\n<li><p>Debian or Ubuntu<br>$ sudo update-grub  //生成grub的配置文件<br>$ sudo apt-get install grub2-common  //没有 update-grub命令时,先运行这个安装命令  </p>\n</li>\n<li><p>Fedora or CentOS7<br>$ sudo grub2-mkconfig -o /boot/grub2/grub.cfg //生成grub2的配置文件<br>$ sudo yum install grub2-tools.x86_64 //没有grub2-mkconfig命令时,先安装grub2-tools<br>带EFI的系统,grub.cfg文件会是在/boot/efi下,比如CentOS7:/boot/efi/EFI/centos/grub.cfg</p>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p>如果你想在系统启动时加载一个内核参数，需修改GRUB的配置模板(/etc/default /grub),添加”名称=值”的键值对到GRUB_CMDLINE_LINUX变量,添加多个时用空格隔开,例如GRUB_CMDLINE_LINUX=”…… name=value”(如果没有GRUB_CMDLINE_LINUX变量时,用GRUB_CMDLINE_LINUX_DEFAULT替代即可).</p>\n<ol>\n<li><p>Debian or Ubuntu<br>$ sudo update-grub  //生成grub的配置文件<br>$ sudo apt-get install grub2-common  //没有 update-grub命令时,先运行这个安装命令  </p>\n</li>\n<li><p>Fedora or CentOS7<br>$ sudo grub2-mkconfig -o /boot/grub2/grub.cfg //生成grub2的配置文件<br>$ sudo yum install grub2-tools.x86_64 //没有grub2-mkconfig命令时,先安装grub2-tools<br>带EFI的系统,grub.cfg文件会是在/boot/efi下,比如CentOS7:/boot/efi/EFI/centos/grub.cfg</p>\n</li>\n</ol>\n"},{"title":"ntpdate 同步各个系统时间","_content":"\n## ntpdate\nCentos下载ntpdate\n\n\t$ yum install ntp ntpdate -y\n\t\n集群操作，同步各个系统时间, 与某一台服务器时间保持一致.\n\n0 12 * * * */usr/sbin/ntpdate 192.168.0.1\n\n每天12点强制将系统时间设置为192.168.0.1服务器时间\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/linux/ntpdate_synchronize_os_time.md","raw":"---\ntitle: ntpdate 同步各个系统时间\ntags:\ncategories:\n- linux\n---\n\n## ntpdate\nCentos下载ntpdate\n\n\t$ yum install ntp ntpdate -y\n\t\n集群操作，同步各个系统时间, 与某一台服务器时间保持一致.\n\n0 12 * * * */usr/sbin/ntpdate 192.168.0.1\n\n每天12点强制将系统时间设置为192.168.0.1服务器时间\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"linux/ntpdate_synchronize_os_time","published":1,"date":"2020-08-12T16:05:46.382Z","updated":"2020-05-31T12:32:00.894Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfn002zhohx1fzu2ya9","content":"<h2 id=\"ntpdate\"><a href=\"#ntpdate\" class=\"headerlink\" title=\"ntpdate\"></a>ntpdate</h2><p>Centos下载ntpdate</p>\n<pre><code>$ yum install ntp ntpdate -y</code></pre><p>集群操作，同步各个系统时间, 与某一台服务器时间保持一致.</p>\n<p>0 12 * * * */usr/sbin/ntpdate 192.168.0.1</p>\n<p>每天12点强制将系统时间设置为192.168.0.1服务器时间</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"ntpdate\"><a href=\"#ntpdate\" class=\"headerlink\" title=\"ntpdate\"></a>ntpdate</h2><p>Centos下载ntpdate</p>\n<pre><code>$ yum install ntp ntpdate -y</code></pre><p>集群操作，同步各个系统时间, 与某一台服务器时间保持一致.</p>\n<p>0 12 * * * */usr/sbin/ntpdate 192.168.0.1</p>\n<p>每天12点强制将系统时间设置为192.168.0.1服务器时间</p>\n"},{"title":"perf","_content":"/root/spdk/examples/nvme/perf/perf -q 64 -s 1024 -w write -t 10 -c 0x01 -o 4096 -D -LL -r 'trtype:PCIe traddr:0000:5e:00.0' \n","source":"_posts/linux/perf.md","raw":"---\ntitle: perf\ntags: \ncategories:\n- linux\n---\n/root/spdk/examples/nvme/perf/perf -q 64 -s 1024 -w write -t 10 -c 0x01 -o 4096 -D -LL -r 'trtype:PCIe traddr:0000:5e:00.0' \n","slug":"linux/perf","published":1,"date":"2020-08-12T16:05:46.384Z","updated":"2020-02-13T12:47:44.522Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfo0031hohx9kx76r5j","content":"<p>/root/spdk/examples/nvme/perf/perf -q 64 -s 1024 -w write -t 10 -c 0x01 -o 4096 -D -LL -r ‘trtype:PCIe traddr:0000:5e:00.0’ </p>\n","site":{"data":{}},"excerpt":"","more":"<p>/root/spdk/examples/nvme/perf/perf -q 64 -s 1024 -w write -t 10 -c 0x01 -o 4096 -D -LL -r ‘trtype:PCIe traddr:0000:5e:00.0’ </p>\n"},{"title":"RPM, yum","_content":"\n## RPM\n> RPM是”Redhat Package Manager”的缩写，根据名字也能猜到这是Redhat公司开发出来的。RPM 是以一种数据库记录的方式来将你所需要的套件安装到你的Linux 主机的一套管理程序。也就是说，你的linux系统中存在着一个关于RPM的数据库，它记录了安装的包以及包与包之间依赖相关性。RPM包是预先在linux机器上编译好并打包好的文件，安装起来非常快捷。但是也有一些缺点，比如安装的环境必须与编译时的环境一致或者相当；包与包之间存在着相互依赖的情况；卸载包时需要先把依赖的包卸载掉，如果依赖的包是系统所必须的，那就不能卸载这个包，否则会造成系统崩溃。\n> 每一个rpm包的名称都由”-“和”.”分成了若干部分。就拿 a2ps-4.13b-57.2.el5.i386.rpm 这个包来解释一下，a2ps 为包名；4.13b则为版本信息；57.2.el5为发布版本号；i386为运行平台。其中运行平台常见的有i386, i586, i686, x86_64 ，需要你注意的是cpu目前是分32位和64位的，i386,i586和i686都为32位平台，x86_64则代表为64位的平台。另外有些rpm包并没有写具体的平台而是noarch，这代表这个rpm包没有硬件平台限制。例如 alacarte-0.10.0-1.fc6.noarch.rpm.\n\n### 安装一个rpm包\n\n\t$ rpm -ivh **.rpm\n-i ：安装的意思\n-v ：可视化\n-h ：显示安装进度\n--force 强制安装，即使覆盖属于其他包的文件也要安装\n--nodeps 当要安装的rpm包依赖其他包时，即使其他包没有安装，也要安装这个包\n\n### 升级一个rpm包\n\n\t$ rpm -Uvh filename -U ：即升级的意思\n\n### 卸载一个rpm包\n\n\t$ rpm -e filename 这里的filename是通过rpm的查询功能所查询到的\n\n### 查询一个包是否安装\n\n\t$ rpm -q rpm包名（这里的包名，是不带有平台信息以及后缀名的）\n\n### 查询当前系统中所安装的所有rpm包, 列出前十个\n\n\t$ rpm -qa | head -n 10\n\n### rpm包的相关信息\n\n\t$ rpm -qi 包名 （同样不需要加平台信息与后缀名）\n\n### 列出rpm包安装的文件\n\n\t$ rpm -ql 包名\n通过上面的命令可以看出vim是通过安装vim-enhanced-7.0.109-6.el5这个rpm包得来的。那么反过来如何通过一个文件去查找是由安装哪个rpm包得来的\n\n### 列出某一个文件属于哪个rpm包\n\n\t$ rpm -qf 文件的绝对路径\n\t$ rpm -qf `which tree`\n\t$ rpm -qf `which screen`\n\n### rpm包安装的时候要手动配置环境变量\n\n\n## Yum\n> yum是Redhat所特有的安装RPM程序包的工具，使用起来相当方便。因为使用RPM安装某一个程序包有可能会因为该程序包依赖另一个程序包而无法安装。而使用yum工具就可以连同依赖的程序包一起安装。当然CentOS同样可以使用yum工具，而且在CentOS中你可以免费使用yum，但Redhat中只有当你付费后才能使用yum，默认是无法使用yum的\n\n### 设置proxy\n\n\t# vim /etc/yum.conf\n\t[main]\n\tcachedir=/var/cache/yum/$basearch/$releasever\n\tkeepcache=0\n\tdebuglevel=2\n\tlogfile=/var/log/yum.log\n\texactarch=1\n\tobsoletes=1\n\tgpgcheck=1\n\tplugins=1\n\tinstallonly_limit=5\n\tbugtracker_url=http://bugs.centos.org/set_project.php?project_id=23&ref=http://bugs.centos.org/bug_report_page.php?category=yum\n\tdistroverpkg=centos-release\n\tproxy=http://child-prc.intel.com:913\n\n### k8s repo\n\n\t$ touch /etc/yum.repos.d/kubernetes.repo\n\t[kubernetes]\n\tname=Kubernetes\n\tbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64\n\tenabled=1\n\tgpgcheck=1\n\trepo_gpgcheck=1\n\tgpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg\n\n### 安装rpm包\n\n * 列出所有可用的rpm包\n\n\t$ yum list\n * 搜索一个rpm包\n\n\t$ yum search [相关关键词]\n * 安装一个rpm包\n\n\t$ yum install [-y] [rpm包名]\n * 卸载一个rpm包\n\n\t$ yum remove [-y] [rpm包名]\n * 升级一个rpm包\n\n\t$ yum update [-y] [rpm包]\n\n\n\n\n\n\n","source":"_posts/linux/rpm_yum.md","raw":"---\ntitle: RPM, yum\ntags:\ncategories:\n- linux\n---\n\n## RPM\n> RPM是”Redhat Package Manager”的缩写，根据名字也能猜到这是Redhat公司开发出来的。RPM 是以一种数据库记录的方式来将你所需要的套件安装到你的Linux 主机的一套管理程序。也就是说，你的linux系统中存在着一个关于RPM的数据库，它记录了安装的包以及包与包之间依赖相关性。RPM包是预先在linux机器上编译好并打包好的文件，安装起来非常快捷。但是也有一些缺点，比如安装的环境必须与编译时的环境一致或者相当；包与包之间存在着相互依赖的情况；卸载包时需要先把依赖的包卸载掉，如果依赖的包是系统所必须的，那就不能卸载这个包，否则会造成系统崩溃。\n> 每一个rpm包的名称都由”-“和”.”分成了若干部分。就拿 a2ps-4.13b-57.2.el5.i386.rpm 这个包来解释一下，a2ps 为包名；4.13b则为版本信息；57.2.el5为发布版本号；i386为运行平台。其中运行平台常见的有i386, i586, i686, x86_64 ，需要你注意的是cpu目前是分32位和64位的，i386,i586和i686都为32位平台，x86_64则代表为64位的平台。另外有些rpm包并没有写具体的平台而是noarch，这代表这个rpm包没有硬件平台限制。例如 alacarte-0.10.0-1.fc6.noarch.rpm.\n\n### 安装一个rpm包\n\n\t$ rpm -ivh **.rpm\n-i ：安装的意思\n-v ：可视化\n-h ：显示安装进度\n--force 强制安装，即使覆盖属于其他包的文件也要安装\n--nodeps 当要安装的rpm包依赖其他包时，即使其他包没有安装，也要安装这个包\n\n### 升级一个rpm包\n\n\t$ rpm -Uvh filename -U ：即升级的意思\n\n### 卸载一个rpm包\n\n\t$ rpm -e filename 这里的filename是通过rpm的查询功能所查询到的\n\n### 查询一个包是否安装\n\n\t$ rpm -q rpm包名（这里的包名，是不带有平台信息以及后缀名的）\n\n### 查询当前系统中所安装的所有rpm包, 列出前十个\n\n\t$ rpm -qa | head -n 10\n\n### rpm包的相关信息\n\n\t$ rpm -qi 包名 （同样不需要加平台信息与后缀名）\n\n### 列出rpm包安装的文件\n\n\t$ rpm -ql 包名\n通过上面的命令可以看出vim是通过安装vim-enhanced-7.0.109-6.el5这个rpm包得来的。那么反过来如何通过一个文件去查找是由安装哪个rpm包得来的\n\n### 列出某一个文件属于哪个rpm包\n\n\t$ rpm -qf 文件的绝对路径\n\t$ rpm -qf `which tree`\n\t$ rpm -qf `which screen`\n\n### rpm包安装的时候要手动配置环境变量\n\n\n## Yum\n> yum是Redhat所特有的安装RPM程序包的工具，使用起来相当方便。因为使用RPM安装某一个程序包有可能会因为该程序包依赖另一个程序包而无法安装。而使用yum工具就可以连同依赖的程序包一起安装。当然CentOS同样可以使用yum工具，而且在CentOS中你可以免费使用yum，但Redhat中只有当你付费后才能使用yum，默认是无法使用yum的\n\n### 设置proxy\n\n\t# vim /etc/yum.conf\n\t[main]\n\tcachedir=/var/cache/yum/$basearch/$releasever\n\tkeepcache=0\n\tdebuglevel=2\n\tlogfile=/var/log/yum.log\n\texactarch=1\n\tobsoletes=1\n\tgpgcheck=1\n\tplugins=1\n\tinstallonly_limit=5\n\tbugtracker_url=http://bugs.centos.org/set_project.php?project_id=23&ref=http://bugs.centos.org/bug_report_page.php?category=yum\n\tdistroverpkg=centos-release\n\tproxy=http://child-prc.intel.com:913\n\n### k8s repo\n\n\t$ touch /etc/yum.repos.d/kubernetes.repo\n\t[kubernetes]\n\tname=Kubernetes\n\tbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64\n\tenabled=1\n\tgpgcheck=1\n\trepo_gpgcheck=1\n\tgpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg\n\n### 安装rpm包\n\n * 列出所有可用的rpm包\n\n\t$ yum list\n * 搜索一个rpm包\n\n\t$ yum search [相关关键词]\n * 安装一个rpm包\n\n\t$ yum install [-y] [rpm包名]\n * 卸载一个rpm包\n\n\t$ yum remove [-y] [rpm包名]\n * 升级一个rpm包\n\n\t$ yum update [-y] [rpm包]\n\n\n\n\n\n\n","slug":"linux/rpm_yum","published":1,"date":"2020-08-12T16:05:46.426Z","updated":"2020-05-27T02:26:41.152Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfp0033hohx2l33armm","content":"<h2 id=\"RPM\"><a href=\"#RPM\" class=\"headerlink\" title=\"RPM\"></a>RPM</h2><blockquote>\n<p>RPM是”Redhat Package Manager”的缩写，根据名字也能猜到这是Redhat公司开发出来的。RPM 是以一种数据库记录的方式来将你所需要的套件安装到你的Linux 主机的一套管理程序。也就是说，你的linux系统中存在着一个关于RPM的数据库，它记录了安装的包以及包与包之间依赖相关性。RPM包是预先在linux机器上编译好并打包好的文件，安装起来非常快捷。但是也有一些缺点，比如安装的环境必须与编译时的环境一致或者相当；包与包之间存在着相互依赖的情况；卸载包时需要先把依赖的包卸载掉，如果依赖的包是系统所必须的，那就不能卸载这个包，否则会造成系统崩溃。<br>每一个rpm包的名称都由”-“和”.”分成了若干部分。就拿 a2ps-4.13b-57.2.el5.i386.rpm 这个包来解释一下，a2ps 为包名；4.13b则为版本信息；57.2.el5为发布版本号；i386为运行平台。其中运行平台常见的有i386, i586, i686, x86_64 ，需要你注意的是cpu目前是分32位和64位的，i386,i586和i686都为32位平台，x86_64则代表为64位的平台。另外有些rpm包并没有写具体的平台而是noarch，这代表这个rpm包没有硬件平台限制。例如 alacarte-0.10.0-1.fc6.noarch.rpm.</p>\n</blockquote>\n<h3 id=\"安装一个rpm包\"><a href=\"#安装一个rpm包\" class=\"headerlink\" title=\"安装一个rpm包\"></a>安装一个rpm包</h3><pre><code>$ rpm -ivh **.rpm</code></pre><p>-i ：安装的意思<br>-v ：可视化<br>-h ：显示安装进度<br>–force 强制安装，即使覆盖属于其他包的文件也要安装<br>–nodeps 当要安装的rpm包依赖其他包时，即使其他包没有安装，也要安装这个包</p>\n<h3 id=\"升级一个rpm包\"><a href=\"#升级一个rpm包\" class=\"headerlink\" title=\"升级一个rpm包\"></a>升级一个rpm包</h3><pre><code>$ rpm -Uvh filename -U ：即升级的意思</code></pre><h3 id=\"卸载一个rpm包\"><a href=\"#卸载一个rpm包\" class=\"headerlink\" title=\"卸载一个rpm包\"></a>卸载一个rpm包</h3><pre><code>$ rpm -e filename 这里的filename是通过rpm的查询功能所查询到的</code></pre><h3 id=\"查询一个包是否安装\"><a href=\"#查询一个包是否安装\" class=\"headerlink\" title=\"查询一个包是否安装\"></a>查询一个包是否安装</h3><pre><code>$ rpm -q rpm包名（这里的包名，是不带有平台信息以及后缀名的）</code></pre><h3 id=\"查询当前系统中所安装的所有rpm包-列出前十个\"><a href=\"#查询当前系统中所安装的所有rpm包-列出前十个\" class=\"headerlink\" title=\"查询当前系统中所安装的所有rpm包, 列出前十个\"></a>查询当前系统中所安装的所有rpm包, 列出前十个</h3><pre><code>$ rpm -qa | head -n 10</code></pre><h3 id=\"rpm包的相关信息\"><a href=\"#rpm包的相关信息\" class=\"headerlink\" title=\"rpm包的相关信息\"></a>rpm包的相关信息</h3><pre><code>$ rpm -qi 包名 （同样不需要加平台信息与后缀名）</code></pre><h3 id=\"列出rpm包安装的文件\"><a href=\"#列出rpm包安装的文件\" class=\"headerlink\" title=\"列出rpm包安装的文件\"></a>列出rpm包安装的文件</h3><pre><code>$ rpm -ql 包名</code></pre><p>通过上面的命令可以看出vim是通过安装vim-enhanced-7.0.109-6.el5这个rpm包得来的。那么反过来如何通过一个文件去查找是由安装哪个rpm包得来的</p>\n<h3 id=\"列出某一个文件属于哪个rpm包\"><a href=\"#列出某一个文件属于哪个rpm包\" class=\"headerlink\" title=\"列出某一个文件属于哪个rpm包\"></a>列出某一个文件属于哪个rpm包</h3><pre><code>$ rpm -qf 文件的绝对路径\n$ rpm -qf `which tree`\n$ rpm -qf `which screen`</code></pre><h3 id=\"rpm包安装的时候要手动配置环境变量\"><a href=\"#rpm包安装的时候要手动配置环境变量\" class=\"headerlink\" title=\"rpm包安装的时候要手动配置环境变量\"></a>rpm包安装的时候要手动配置环境变量</h3><h2 id=\"Yum\"><a href=\"#Yum\" class=\"headerlink\" title=\"Yum\"></a>Yum</h2><blockquote>\n<p>yum是Redhat所特有的安装RPM程序包的工具，使用起来相当方便。因为使用RPM安装某一个程序包有可能会因为该程序包依赖另一个程序包而无法安装。而使用yum工具就可以连同依赖的程序包一起安装。当然CentOS同样可以使用yum工具，而且在CentOS中你可以免费使用yum，但Redhat中只有当你付费后才能使用yum，默认是无法使用yum的</p>\n</blockquote>\n<h3 id=\"设置proxy\"><a href=\"#设置proxy\" class=\"headerlink\" title=\"设置proxy\"></a>设置proxy</h3><pre><code># vim /etc/yum.conf\n[main]\ncachedir=/var/cache/yum/$basearch/$releasever\nkeepcache=0\ndebuglevel=2\nlogfile=/var/log/yum.log\nexactarch=1\nobsoletes=1\ngpgcheck=1\nplugins=1\ninstallonly_limit=5\nbugtracker_url=http://bugs.centos.org/set_project.php?project_id=23&amp;ref=http://bugs.centos.org/bug_report_page.php?category=yum\ndistroverpkg=centos-release\nproxy=http://child-prc.intel.com:913</code></pre><h3 id=\"k8s-repo\"><a href=\"#k8s-repo\" class=\"headerlink\" title=\"k8s repo\"></a>k8s repo</h3><pre><code>$ touch /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg</code></pre><h3 id=\"安装rpm包\"><a href=\"#安装rpm包\" class=\"headerlink\" title=\"安装rpm包\"></a>安装rpm包</h3><ul>\n<li><p>列出所有可用的rpm包</p>\n<p> $ yum list</p>\n</li>\n<li><p>搜索一个rpm包</p>\n<p> $ yum search [相关关键词]</p>\n</li>\n<li><p>安装一个rpm包</p>\n<p> $ yum install [-y] [rpm包名]</p>\n</li>\n<li><p>卸载一个rpm包</p>\n<p> $ yum remove [-y] [rpm包名]</p>\n</li>\n<li><p>升级一个rpm包</p>\n<p> $ yum update [-y] [rpm包]</p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"RPM\"><a href=\"#RPM\" class=\"headerlink\" title=\"RPM\"></a>RPM</h2><blockquote>\n<p>RPM是”Redhat Package Manager”的缩写，根据名字也能猜到这是Redhat公司开发出来的。RPM 是以一种数据库记录的方式来将你所需要的套件安装到你的Linux 主机的一套管理程序。也就是说，你的linux系统中存在着一个关于RPM的数据库，它记录了安装的包以及包与包之间依赖相关性。RPM包是预先在linux机器上编译好并打包好的文件，安装起来非常快捷。但是也有一些缺点，比如安装的环境必须与编译时的环境一致或者相当；包与包之间存在着相互依赖的情况；卸载包时需要先把依赖的包卸载掉，如果依赖的包是系统所必须的，那就不能卸载这个包，否则会造成系统崩溃。<br>每一个rpm包的名称都由”-“和”.”分成了若干部分。就拿 a2ps-4.13b-57.2.el5.i386.rpm 这个包来解释一下，a2ps 为包名；4.13b则为版本信息；57.2.el5为发布版本号；i386为运行平台。其中运行平台常见的有i386, i586, i686, x86_64 ，需要你注意的是cpu目前是分32位和64位的，i386,i586和i686都为32位平台，x86_64则代表为64位的平台。另外有些rpm包并没有写具体的平台而是noarch，这代表这个rpm包没有硬件平台限制。例如 alacarte-0.10.0-1.fc6.noarch.rpm.</p>\n</blockquote>\n<h3 id=\"安装一个rpm包\"><a href=\"#安装一个rpm包\" class=\"headerlink\" title=\"安装一个rpm包\"></a>安装一个rpm包</h3><pre><code>$ rpm -ivh **.rpm</code></pre><p>-i ：安装的意思<br>-v ：可视化<br>-h ：显示安装进度<br>–force 强制安装，即使覆盖属于其他包的文件也要安装<br>–nodeps 当要安装的rpm包依赖其他包时，即使其他包没有安装，也要安装这个包</p>\n<h3 id=\"升级一个rpm包\"><a href=\"#升级一个rpm包\" class=\"headerlink\" title=\"升级一个rpm包\"></a>升级一个rpm包</h3><pre><code>$ rpm -Uvh filename -U ：即升级的意思</code></pre><h3 id=\"卸载一个rpm包\"><a href=\"#卸载一个rpm包\" class=\"headerlink\" title=\"卸载一个rpm包\"></a>卸载一个rpm包</h3><pre><code>$ rpm -e filename 这里的filename是通过rpm的查询功能所查询到的</code></pre><h3 id=\"查询一个包是否安装\"><a href=\"#查询一个包是否安装\" class=\"headerlink\" title=\"查询一个包是否安装\"></a>查询一个包是否安装</h3><pre><code>$ rpm -q rpm包名（这里的包名，是不带有平台信息以及后缀名的）</code></pre><h3 id=\"查询当前系统中所安装的所有rpm包-列出前十个\"><a href=\"#查询当前系统中所安装的所有rpm包-列出前十个\" class=\"headerlink\" title=\"查询当前系统中所安装的所有rpm包, 列出前十个\"></a>查询当前系统中所安装的所有rpm包, 列出前十个</h3><pre><code>$ rpm -qa | head -n 10</code></pre><h3 id=\"rpm包的相关信息\"><a href=\"#rpm包的相关信息\" class=\"headerlink\" title=\"rpm包的相关信息\"></a>rpm包的相关信息</h3><pre><code>$ rpm -qi 包名 （同样不需要加平台信息与后缀名）</code></pre><h3 id=\"列出rpm包安装的文件\"><a href=\"#列出rpm包安装的文件\" class=\"headerlink\" title=\"列出rpm包安装的文件\"></a>列出rpm包安装的文件</h3><pre><code>$ rpm -ql 包名</code></pre><p>通过上面的命令可以看出vim是通过安装vim-enhanced-7.0.109-6.el5这个rpm包得来的。那么反过来如何通过一个文件去查找是由安装哪个rpm包得来的</p>\n<h3 id=\"列出某一个文件属于哪个rpm包\"><a href=\"#列出某一个文件属于哪个rpm包\" class=\"headerlink\" title=\"列出某一个文件属于哪个rpm包\"></a>列出某一个文件属于哪个rpm包</h3><pre><code>$ rpm -qf 文件的绝对路径\n$ rpm -qf `which tree`\n$ rpm -qf `which screen`</code></pre><h3 id=\"rpm包安装的时候要手动配置环境变量\"><a href=\"#rpm包安装的时候要手动配置环境变量\" class=\"headerlink\" title=\"rpm包安装的时候要手动配置环境变量\"></a>rpm包安装的时候要手动配置环境变量</h3><h2 id=\"Yum\"><a href=\"#Yum\" class=\"headerlink\" title=\"Yum\"></a>Yum</h2><blockquote>\n<p>yum是Redhat所特有的安装RPM程序包的工具，使用起来相当方便。因为使用RPM安装某一个程序包有可能会因为该程序包依赖另一个程序包而无法安装。而使用yum工具就可以连同依赖的程序包一起安装。当然CentOS同样可以使用yum工具，而且在CentOS中你可以免费使用yum，但Redhat中只有当你付费后才能使用yum，默认是无法使用yum的</p>\n</blockquote>\n<h3 id=\"设置proxy\"><a href=\"#设置proxy\" class=\"headerlink\" title=\"设置proxy\"></a>设置proxy</h3><pre><code># vim /etc/yum.conf\n[main]\ncachedir=/var/cache/yum/$basearch/$releasever\nkeepcache=0\ndebuglevel=2\nlogfile=/var/log/yum.log\nexactarch=1\nobsoletes=1\ngpgcheck=1\nplugins=1\ninstallonly_limit=5\nbugtracker_url=http://bugs.centos.org/set_project.php?project_id=23&amp;ref=http://bugs.centos.org/bug_report_page.php?category=yum\ndistroverpkg=centos-release\nproxy=http://child-prc.intel.com:913</code></pre><h3 id=\"k8s-repo\"><a href=\"#k8s-repo\" class=\"headerlink\" title=\"k8s repo\"></a>k8s repo</h3><pre><code>$ touch /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg</code></pre><h3 id=\"安装rpm包\"><a href=\"#安装rpm包\" class=\"headerlink\" title=\"安装rpm包\"></a>安装rpm包</h3><ul>\n<li><p>列出所有可用的rpm包</p>\n<p> $ yum list</p>\n</li>\n<li><p>搜索一个rpm包</p>\n<p> $ yum search [相关关键词]</p>\n</li>\n<li><p>安装一个rpm包</p>\n<p> $ yum install [-y] [rpm包名]</p>\n</li>\n<li><p>卸载一个rpm包</p>\n<p> $ yum remove [-y] [rpm包名]</p>\n</li>\n<li><p>升级一个rpm包</p>\n<p> $ yum update [-y] [rpm包]</p>\n</li>\n</ul>\n"},{"title":"scp机器间复制文件","_content":"跨服务器拷贝需要用到的命令是scp.\n----------------------拷贝文件夹----------------------------------------------\n把当前文件夹tempA拷贝到 目标服务器10.127.40.25 服务器的 /tmp/wang/文件夹下\nscp -r /tmp/tempA/ wasadmin@10.127.40.25:/tmp/wang/\n其中wasadmin是目标服务器的用户名，执行命令提示输入密码，然后输入密码即可\n \n----------------------拷贝文件----------------------------------------------\n把当前文件夹tempA.txt拷贝到 目标服务器10.127.40.25 服务器的 /tmp/wang/文件夹下\nscp  /tmp/tempA.txt wasadmin@10.127.40.25:/tmp/wang/\n其中wasadmin是目标服务器的用户名，执行命令提示输入密码，然后输入密码即可\n\nFrom <https://www.cnblogs.com/xiayahui/p/5437556.html> \n\n","source":"_posts/linux/scp机器间复制文件.md","raw":"---\ntitle: scp机器间复制文件\ntags:\ncategories:\n- linux\n---\n跨服务器拷贝需要用到的命令是scp.\n----------------------拷贝文件夹----------------------------------------------\n把当前文件夹tempA拷贝到 目标服务器10.127.40.25 服务器的 /tmp/wang/文件夹下\nscp -r /tmp/tempA/ wasadmin@10.127.40.25:/tmp/wang/\n其中wasadmin是目标服务器的用户名，执行命令提示输入密码，然后输入密码即可\n \n----------------------拷贝文件----------------------------------------------\n把当前文件夹tempA.txt拷贝到 目标服务器10.127.40.25 服务器的 /tmp/wang/文件夹下\nscp  /tmp/tempA.txt wasadmin@10.127.40.25:/tmp/wang/\n其中wasadmin是目标服务器的用户名，执行命令提示输入密码，然后输入密码即可\n\nFrom <https://www.cnblogs.com/xiayahui/p/5437556.html> \n\n","slug":"linux/scp机器间复制文件","published":1,"date":"2020-08-12T16:05:46.440Z","updated":"2020-02-13T12:47:44.526Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfr0035hohxaunvgpo7","content":"<p>跨服务器拷贝需要用到的命令是scp.<br>———————-拷贝文件夹———————————————-<br>把当前文件夹tempA拷贝到 目标服务器10.127.40.25 服务器的 /tmp/wang/文件夹下<br>scp -r /tmp/tempA/ <a href=\"mailto:wasadmin@10.127.40.25\">wasadmin@10.127.40.25</a>:/tmp/wang/<br>其中wasadmin是目标服务器的用户名，执行命令提示输入密码，然后输入密码即可</p>\n<p>———————-拷贝文件———————————————-<br>把当前文件夹tempA.txt拷贝到 目标服务器10.127.40.25 服务器的 /tmp/wang/文件夹下<br>scp  /tmp/tempA.txt <a href=\"mailto:wasadmin@10.127.40.25\">wasadmin@10.127.40.25</a>:/tmp/wang/<br>其中wasadmin是目标服务器的用户名，执行命令提示输入密码，然后输入密码即可</p>\n<p>From <a href=\"https://www.cnblogs.com/xiayahui/p/5437556.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/xiayahui/p/5437556.html</a> </p>\n","site":{"data":{}},"excerpt":"","more":"<p>跨服务器拷贝需要用到的命令是scp.<br>———————-拷贝文件夹———————————————-<br>把当前文件夹tempA拷贝到 目标服务器10.127.40.25 服务器的 /tmp/wang/文件夹下<br>scp -r /tmp/tempA/ <a href=\"mailto:wasadmin@10.127.40.25\">wasadmin@10.127.40.25</a>:/tmp/wang/<br>其中wasadmin是目标服务器的用户名，执行命令提示输入密码，然后输入密码即可</p>\n<p>———————-拷贝文件———————————————-<br>把当前文件夹tempA.txt拷贝到 目标服务器10.127.40.25 服务器的 /tmp/wang/文件夹下<br>scp  /tmp/tempA.txt <a href=\"mailto:wasadmin@10.127.40.25\">wasadmin@10.127.40.25</a>:/tmp/wang/<br>其中wasadmin是目标服务器的用户名，执行命令提示输入密码，然后输入密码即可</p>\n<p>From <a href=\"https://www.cnblogs.com/xiayahui/p/5437556.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/xiayahui/p/5437556.html</a> </p>\n"},{"title":"screen程序在后台运行","_content":"\n## screen\n\nlinux下安装：\n\ncentos:   yum install screen\n\nubuntu:   apt-get install screen\n启动时添加选项-L（Turn on output logging.），会在当前目录下生成screenlog.0文件。\n![](screenlog.0.png)\n### 1. <font color='red'><b>screen -L -dmS test</b></font>的意思是启动一个开始就处于断开模式的会话，会话的名称是test。\nscreen -r test连接该会话，在会话中的所有屏幕输出都会记录到screenlog.0文件。\n\n让每个screen会话窗口有单独的日志文件。\n### 2. 在screen配置文件/etc/screenrc最后添加下面一行：\n<font color=\"red\" size=5><b>logfile /tmp/screenlog_%t.log</b></font>  \n%t是指window窗口的名称，对应screen的-t参数。所以我们启动screen的时候要指定窗口的名称，例如：\n![](screen_logs.png)\n<font color=\"red\" size=5><b>screen -L -t window1 -dmS test</b></font>的意思是启动test会话，test会话的窗口名称为window1。屏幕日志记录在/tmp/screenlog_window1.log。如果启动的时候不加-L参数，在screen session下按ctrl+a H，日志也会记录在/tmp/screenlog_window1.log。\n\nscreen -S yourname -> 新建一个叫yourname的session\n\n然后在里面执行你要执行的程序\n\n比如java -jar xxx.jar\n\n然后ctrl+a+d退出会话\n\nscreen -ls -> 列出当前所有的session\n\nscreen -r yourname -> 回到yourname这个session\n\nscreen -d yourname -> 远程detach某个session\n\nscreen -d -r yourname -> 结束当前session并回到yourname这个session\n\nscreen -ls\n会有如下显示：\n122128.test     (12/04/2017 08:35:43 PM)        (Attached)\n删除它\nscreen -X -S 122128 quit\n再screen -ls就没了\n\t[root@wlp10 test_faiss]# screen -ls\n\tThere are screens on:\n\t        11174.pts-1.wlp10       (Detached)\n\t        11054.zh        (Detached)\n\t2 Sockets in /var/run/screen/S-root.\n\t\n\t[root@wlp10 test_faiss]# screen -X -S 11174.pts-1 quit\n\tbash: screen -X -S 11174.pts-1 quit: command not found...\n\t[root@wlp10 test_faiss]# ps aux|grep 11174\n\troot      11174  0.0  0.0 127908  2888 ?        Ss   15:03   0:00 SCREEN -l\n\troot      11530  0.0  0.0 168680  5068 pts/1    S+   15:06   0:00 grep --color=auto 11174\n\t[root@wlp10 test_faiss]# kill 11174\n\t[root@wlp10 test_faiss]# pa aux|grep 11054\n\tbash: pa: command not found...\n\t[root@wlp10 test_faiss]# ps aux|grep 11054\n\troot      11054  0.0  0.0 127908  2848 ?        Ss   15:02   0:00 SCREEN -S zh\n\troot      11561  0.0  0.0 168680  5072 pts/1    S+   15:07   0:00 grep --color=auto 11054\n\t[root@wlp10 test_faiss]# screen -ls\n\tThere is a screen on:\n\t        11054.zh        (Detached)\n\t1 Socket in /var/run/screen/S-root.\n\t\n\t[root@wlp10 test_faiss]#\n\n\n1.想永远关闭screen的闪屏功能，需要修改配置文件。在CentOS中可以修改/etc/screenrc，修改这个文件将对所有用户生效。   \n    Vbell on 改为 vbell off\n    之后新建的screen按Backspace键到头就没有闪烁了\n\n2.只修改自己的配置文件，在$HOME/.screenrc(没有的话新建~/.screenrc文件)中     加入下面的话：\n    vbell off\n    之后新建的screen按Backspace键到头就没有闪烁了\n","source":"_posts/linux/screen程序在后台运行.md","raw":"---\ntitle: screen程序在后台运行\ntags:\ncategories:\n- linux\n---\n\n## screen\n\nlinux下安装：\n\ncentos:   yum install screen\n\nubuntu:   apt-get install screen\n启动时添加选项-L（Turn on output logging.），会在当前目录下生成screenlog.0文件。\n![](screenlog.0.png)\n### 1. <font color='red'><b>screen -L -dmS test</b></font>的意思是启动一个开始就处于断开模式的会话，会话的名称是test。\nscreen -r test连接该会话，在会话中的所有屏幕输出都会记录到screenlog.0文件。\n\n让每个screen会话窗口有单独的日志文件。\n### 2. 在screen配置文件/etc/screenrc最后添加下面一行：\n<font color=\"red\" size=5><b>logfile /tmp/screenlog_%t.log</b></font>  \n%t是指window窗口的名称，对应screen的-t参数。所以我们启动screen的时候要指定窗口的名称，例如：\n![](screen_logs.png)\n<font color=\"red\" size=5><b>screen -L -t window1 -dmS test</b></font>的意思是启动test会话，test会话的窗口名称为window1。屏幕日志记录在/tmp/screenlog_window1.log。如果启动的时候不加-L参数，在screen session下按ctrl+a H，日志也会记录在/tmp/screenlog_window1.log。\n\nscreen -S yourname -> 新建一个叫yourname的session\n\n然后在里面执行你要执行的程序\n\n比如java -jar xxx.jar\n\n然后ctrl+a+d退出会话\n\nscreen -ls -> 列出当前所有的session\n\nscreen -r yourname -> 回到yourname这个session\n\nscreen -d yourname -> 远程detach某个session\n\nscreen -d -r yourname -> 结束当前session并回到yourname这个session\n\nscreen -ls\n会有如下显示：\n122128.test     (12/04/2017 08:35:43 PM)        (Attached)\n删除它\nscreen -X -S 122128 quit\n再screen -ls就没了\n\t[root@wlp10 test_faiss]# screen -ls\n\tThere are screens on:\n\t        11174.pts-1.wlp10       (Detached)\n\t        11054.zh        (Detached)\n\t2 Sockets in /var/run/screen/S-root.\n\t\n\t[root@wlp10 test_faiss]# screen -X -S 11174.pts-1 quit\n\tbash: screen -X -S 11174.pts-1 quit: command not found...\n\t[root@wlp10 test_faiss]# ps aux|grep 11174\n\troot      11174  0.0  0.0 127908  2888 ?        Ss   15:03   0:00 SCREEN -l\n\troot      11530  0.0  0.0 168680  5068 pts/1    S+   15:06   0:00 grep --color=auto 11174\n\t[root@wlp10 test_faiss]# kill 11174\n\t[root@wlp10 test_faiss]# pa aux|grep 11054\n\tbash: pa: command not found...\n\t[root@wlp10 test_faiss]# ps aux|grep 11054\n\troot      11054  0.0  0.0 127908  2848 ?        Ss   15:02   0:00 SCREEN -S zh\n\troot      11561  0.0  0.0 168680  5072 pts/1    S+   15:07   0:00 grep --color=auto 11054\n\t[root@wlp10 test_faiss]# screen -ls\n\tThere is a screen on:\n\t        11054.zh        (Detached)\n\t1 Socket in /var/run/screen/S-root.\n\t\n\t[root@wlp10 test_faiss]#\n\n\n1.想永远关闭screen的闪屏功能，需要修改配置文件。在CentOS中可以修改/etc/screenrc，修改这个文件将对所有用户生效。   \n    Vbell on 改为 vbell off\n    之后新建的screen按Backspace键到头就没有闪烁了\n\n2.只修改自己的配置文件，在$HOME/.screenrc(没有的话新建~/.screenrc文件)中     加入下面的话：\n    vbell off\n    之后新建的screen按Backspace键到头就没有闪烁了\n","slug":"linux/screen程序在后台运行","published":1,"date":"2020-08-12T16:05:46.442Z","updated":"2020-02-13T12:47:44.530Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfs0037hohxf6bmav6w","content":"<h2 id=\"screen\"><a href=\"#screen\" class=\"headerlink\" title=\"screen\"></a>screen</h2><p>linux下安装：</p>\n<p>centos:   yum install screen</p>\n<p>ubuntu:   apt-get install screen<br>启动时添加选项-L（Turn on output logging.），会在当前目录下生成screenlog.0文件。<br><img src=\"screenlog.0.png\" alt=\"\"></p>\n<h3 id=\"1-screen-L-dmS-test的意思是启动一个开始就处于断开模式的会话，会话的名称是test。\"><a href=\"#1-screen-L-dmS-test的意思是启动一个开始就处于断开模式的会话，会话的名称是test。\" class=\"headerlink\" title=\"1. screen -L -dmS test的意思是启动一个开始就处于断开模式的会话，会话的名称是test。\"></a>1. <font color='red'><b>screen -L -dmS test</b></font>的意思是启动一个开始就处于断开模式的会话，会话的名称是test。</h3><p>screen -r test连接该会话，在会话中的所有屏幕输出都会记录到screenlog.0文件。</p>\n<p>让每个screen会话窗口有单独的日志文件。</p>\n<h3 id=\"2-在screen配置文件-etc-screenrc最后添加下面一行：\"><a href=\"#2-在screen配置文件-etc-screenrc最后添加下面一行：\" class=\"headerlink\" title=\"2. 在screen配置文件/etc/screenrc最后添加下面一行：\"></a>2. 在screen配置文件/etc/screenrc最后添加下面一行：</h3><p><font color=\"red\" size=5><b>logfile /tmp/screenlog_%t.log</b></font><br>%t是指window窗口的名称，对应screen的-t参数。所以我们启动screen的时候要指定窗口的名称，例如：<br><img src=\"screen_logs.png\" alt=\"\"><br><font color=\"red\" size=5><b>screen -L -t window1 -dmS test</b></font>的意思是启动test会话，test会话的窗口名称为window1。屏幕日志记录在/tmp/screenlog_window1.log。如果启动的时候不加-L参数，在screen session下按ctrl+a H，日志也会记录在/tmp/screenlog_window1.log。</p>\n<p>screen -S yourname -&gt; 新建一个叫yourname的session</p>\n<p>然后在里面执行你要执行的程序</p>\n<p>比如java -jar xxx.jar</p>\n<p>然后ctrl+a+d退出会话</p>\n<p>screen -ls -&gt; 列出当前所有的session</p>\n<p>screen -r yourname -&gt; 回到yourname这个session</p>\n<p>screen -d yourname -&gt; 远程detach某个session</p>\n<p>screen -d -r yourname -&gt; 结束当前session并回到yourname这个session</p>\n<p>screen -ls<br>会有如下显示：<br>122128.test     (12/04/2017 08:35:43 PM)        (Attached)<br>删除它<br>screen -X -S 122128 quit<br>再screen -ls就没了<br>    [root@wlp10 test_faiss]# screen -ls<br>    There are screens on:<br>            11174.pts-1.wlp10       (Detached)<br>            11054.zh        (Detached)<br>    2 Sockets in /var/run/screen/S-root.</p>\n<pre><code>[root@wlp10 test_faiss]# screen -X -S 11174.pts-1 quit\nbash: screen -X -S 11174.pts-1 quit: command not found...\n[root@wlp10 test_faiss]# ps aux|grep 11174\nroot      11174  0.0  0.0 127908  2888 ?        Ss   15:03   0:00 SCREEN -l\nroot      11530  0.0  0.0 168680  5068 pts/1    S+   15:06   0:00 grep --color=auto 11174\n[root@wlp10 test_faiss]# kill 11174\n[root@wlp10 test_faiss]# pa aux|grep 11054\nbash: pa: command not found...\n[root@wlp10 test_faiss]# ps aux|grep 11054\nroot      11054  0.0  0.0 127908  2848 ?        Ss   15:02   0:00 SCREEN -S zh\nroot      11561  0.0  0.0 168680  5072 pts/1    S+   15:07   0:00 grep --color=auto 11054\n[root@wlp10 test_faiss]# screen -ls\nThere is a screen on:\n        11054.zh        (Detached)\n1 Socket in /var/run/screen/S-root.\n\n[root@wlp10 test_faiss]#</code></pre><p>1.想永远关闭screen的闪屏功能，需要修改配置文件。在CentOS中可以修改/etc/screenrc，修改这个文件将对所有用户生效。<br>    Vbell on 改为 vbell off<br>    之后新建的screen按Backspace键到头就没有闪烁了</p>\n<p>2.只修改自己的配置文件，在$HOME/.screenrc(没有的话新建~/.screenrc文件)中     加入下面的话：<br>    vbell off<br>    之后新建的screen按Backspace键到头就没有闪烁了</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"screen\"><a href=\"#screen\" class=\"headerlink\" title=\"screen\"></a>screen</h2><p>linux下安装：</p>\n<p>centos:   yum install screen</p>\n<p>ubuntu:   apt-get install screen<br>启动时添加选项-L（Turn on output logging.），会在当前目录下生成screenlog.0文件。<br><img src=\"screenlog.0.png\" alt=\"\"></p>\n<h3 id=\"1-screen-L-dmS-test的意思是启动一个开始就处于断开模式的会话，会话的名称是test。\"><a href=\"#1-screen-L-dmS-test的意思是启动一个开始就处于断开模式的会话，会话的名称是test。\" class=\"headerlink\" title=\"1. screen -L -dmS test的意思是启动一个开始就处于断开模式的会话，会话的名称是test。\"></a>1. <font color='red'><b>screen -L -dmS test</b></font>的意思是启动一个开始就处于断开模式的会话，会话的名称是test。</h3><p>screen -r test连接该会话，在会话中的所有屏幕输出都会记录到screenlog.0文件。</p>\n<p>让每个screen会话窗口有单独的日志文件。</p>\n<h3 id=\"2-在screen配置文件-etc-screenrc最后添加下面一行：\"><a href=\"#2-在screen配置文件-etc-screenrc最后添加下面一行：\" class=\"headerlink\" title=\"2. 在screen配置文件/etc/screenrc最后添加下面一行：\"></a>2. 在screen配置文件/etc/screenrc最后添加下面一行：</h3><p><font color=\"red\" size=5><b>logfile /tmp/screenlog_%t.log</b></font><br>%t是指window窗口的名称，对应screen的-t参数。所以我们启动screen的时候要指定窗口的名称，例如：<br><img src=\"screen_logs.png\" alt=\"\"><br><font color=\"red\" size=5><b>screen -L -t window1 -dmS test</b></font>的意思是启动test会话，test会话的窗口名称为window1。屏幕日志记录在/tmp/screenlog_window1.log。如果启动的时候不加-L参数，在screen session下按ctrl+a H，日志也会记录在/tmp/screenlog_window1.log。</p>\n<p>screen -S yourname -&gt; 新建一个叫yourname的session</p>\n<p>然后在里面执行你要执行的程序</p>\n<p>比如java -jar xxx.jar</p>\n<p>然后ctrl+a+d退出会话</p>\n<p>screen -ls -&gt; 列出当前所有的session</p>\n<p>screen -r yourname -&gt; 回到yourname这个session</p>\n<p>screen -d yourname -&gt; 远程detach某个session</p>\n<p>screen -d -r yourname -&gt; 结束当前session并回到yourname这个session</p>\n<p>screen -ls<br>会有如下显示：<br>122128.test     (12/04/2017 08:35:43 PM)        (Attached)<br>删除它<br>screen -X -S 122128 quit<br>再screen -ls就没了<br>    [root@wlp10 test_faiss]# screen -ls<br>    There are screens on:<br>            11174.pts-1.wlp10       (Detached)<br>            11054.zh        (Detached)<br>    2 Sockets in /var/run/screen/S-root.</p>\n<pre><code>[root@wlp10 test_faiss]# screen -X -S 11174.pts-1 quit\nbash: screen -X -S 11174.pts-1 quit: command not found...\n[root@wlp10 test_faiss]# ps aux|grep 11174\nroot      11174  0.0  0.0 127908  2888 ?        Ss   15:03   0:00 SCREEN -l\nroot      11530  0.0  0.0 168680  5068 pts/1    S+   15:06   0:00 grep --color=auto 11174\n[root@wlp10 test_faiss]# kill 11174\n[root@wlp10 test_faiss]# pa aux|grep 11054\nbash: pa: command not found...\n[root@wlp10 test_faiss]# ps aux|grep 11054\nroot      11054  0.0  0.0 127908  2848 ?        Ss   15:02   0:00 SCREEN -S zh\nroot      11561  0.0  0.0 168680  5072 pts/1    S+   15:07   0:00 grep --color=auto 11054\n[root@wlp10 test_faiss]# screen -ls\nThere is a screen on:\n        11054.zh        (Detached)\n1 Socket in /var/run/screen/S-root.\n\n[root@wlp10 test_faiss]#</code></pre><p>1.想永远关闭screen的闪屏功能，需要修改配置文件。在CentOS中可以修改/etc/screenrc，修改这个文件将对所有用户生效。<br>    Vbell on 改为 vbell off<br>    之后新建的screen按Backspace键到头就没有闪烁了</p>\n<p>2.只修改自己的配置文件，在$HOME/.screenrc(没有的话新建~/.screenrc文件)中     加入下面的话：<br>    vbell off<br>    之后新建的screen按Backspace键到头就没有闪烁了</p>\n"},{"title":"sda hda","type":null,"_content":"\n## sda,hda\n\nhda一般是指IDE接口的硬盘，hda一般指第一块硬盘，类似的有hdb,hdc等\nsda一般是指SATA接口的硬盘，sda一般指第一块硬盘，类似的有sdb,sdc等\n\n现在的内核都会把硬盘，移动硬盘，U盘之类的识别为sdX的形式。\n\nSATA接口是串行数据接口，俗称串口。在硬盘外部传输速度目前最快可达250M/S 。\nIDE接口是并行数据接口，俗称并口，在硬盘外部传输速度最快可达133M/S。 \n![sda接口](sda_interface.png)\n\n![IDE接口](IDE_interface.png) ![](power_data_interface.png)\n\nIDE转SATA线如下，先把IDE一头接入到硬盘上，然后电源跟电脑电源线相连，然后把SATA则接入主板上面\n\n![ide接口](IDE_power_sata.png)\nIDE是英文IntegratedDriveElectronics的缩写，翻译成中文叫做“集成驱动器电子”，\nIDE接口即指并行IDE接口（PATA接口），使用并行接口的硬盘既称为并口硬盘，IDE是一种较老的技术，在几年前很常见，目前在在硬盘方面基本不再使用此接口，其接口连接比较简单，只需用一根40线电缆将它们与主板或接口卡连起来就可以了。\nsata接口\nSATA接口（SerialATA）又称为串行ATA，是一种接口技术，使用SATA接口的\n硬盘又叫串口硬盘，其最终将取代使用IDE接口的并口硬盘！SATA接口的历史：2001年，由Intel、APT、Dell、IBM、希捷、迈拓这几大厂商\n\nide接口与sata接口的区别是什么\n```\n1、SATA硬盘比IDE硬盘传输速度高。目前SATA可以提供150MB/s的高峰传输速率。今后将达到300 MB/s和600 MB/s。到时我们将得到比IDE硬盘快近10倍的传输速率。\n2、 相对于IDE硬盘的PATA40针的数据线，SATA的线缆少而细，传输距离远，可延伸至1米，使得安装设备和机内布线更加容易。连接器的体积小，这种线缆有效的改进了计算机内部的空气流动，也改善了机箱内的散热。\n3、相对于IDE硬盘系统功耗有所减少。SATA硬盘使用500毫伏的电压就可以工作。\n4、SATA可以通过使用多用途的芯片组或串行——并行转换器来向后兼容PATA设备。由于SATA和PATA可使用同样的驱动器，不需要对操作系统进行升级或其他改变。\n5、SATA不需要设置主从盘跳线。BIOS会为它按照1、2、3顺序编号。这取决于驱动器接在哪个SATA连接器上（安装方便）。而IDE硬盘需要设置通过跳线来设置主从盘。\n6、SATA还支持热插拔，可以象U盘一样使用。而IDE硬盘不支持热插拔.\n```\n","source":"_posts/linux/sda_hda.md","raw":"---\ntitle: sda hda\ntype: \ncategories:\n- linux\n---\n\n## sda,hda\n\nhda一般是指IDE接口的硬盘，hda一般指第一块硬盘，类似的有hdb,hdc等\nsda一般是指SATA接口的硬盘，sda一般指第一块硬盘，类似的有sdb,sdc等\n\n现在的内核都会把硬盘，移动硬盘，U盘之类的识别为sdX的形式。\n\nSATA接口是串行数据接口，俗称串口。在硬盘外部传输速度目前最快可达250M/S 。\nIDE接口是并行数据接口，俗称并口，在硬盘外部传输速度最快可达133M/S。 \n![sda接口](sda_interface.png)\n\n![IDE接口](IDE_interface.png) ![](power_data_interface.png)\n\nIDE转SATA线如下，先把IDE一头接入到硬盘上，然后电源跟电脑电源线相连，然后把SATA则接入主板上面\n\n![ide接口](IDE_power_sata.png)\nIDE是英文IntegratedDriveElectronics的缩写，翻译成中文叫做“集成驱动器电子”，\nIDE接口即指并行IDE接口（PATA接口），使用并行接口的硬盘既称为并口硬盘，IDE是一种较老的技术，在几年前很常见，目前在在硬盘方面基本不再使用此接口，其接口连接比较简单，只需用一根40线电缆将它们与主板或接口卡连起来就可以了。\nsata接口\nSATA接口（SerialATA）又称为串行ATA，是一种接口技术，使用SATA接口的\n硬盘又叫串口硬盘，其最终将取代使用IDE接口的并口硬盘！SATA接口的历史：2001年，由Intel、APT、Dell、IBM、希捷、迈拓这几大厂商\n\nide接口与sata接口的区别是什么\n```\n1、SATA硬盘比IDE硬盘传输速度高。目前SATA可以提供150MB/s的高峰传输速率。今后将达到300 MB/s和600 MB/s。到时我们将得到比IDE硬盘快近10倍的传输速率。\n2、 相对于IDE硬盘的PATA40针的数据线，SATA的线缆少而细，传输距离远，可延伸至1米，使得安装设备和机内布线更加容易。连接器的体积小，这种线缆有效的改进了计算机内部的空气流动，也改善了机箱内的散热。\n3、相对于IDE硬盘系统功耗有所减少。SATA硬盘使用500毫伏的电压就可以工作。\n4、SATA可以通过使用多用途的芯片组或串行——并行转换器来向后兼容PATA设备。由于SATA和PATA可使用同样的驱动器，不需要对操作系统进行升级或其他改变。\n5、SATA不需要设置主从盘跳线。BIOS会为它按照1、2、3顺序编号。这取决于驱动器接在哪个SATA连接器上（安装方便）。而IDE硬盘需要设置通过跳线来设置主从盘。\n6、SATA还支持热插拔，可以象U盘一样使用。而IDE硬盘不支持热插拔.\n```\n","slug":"linux/sda_hda","published":1,"date":"2020-08-12T16:05:46.453Z","updated":"2020-02-13T12:47:44.543Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmft0039hohx7tj48sc0","content":"<h2 id=\"sda-hda\"><a href=\"#sda-hda\" class=\"headerlink\" title=\"sda,hda\"></a>sda,hda</h2><p>hda一般是指IDE接口的硬盘，hda一般指第一块硬盘，类似的有hdb,hdc等<br>sda一般是指SATA接口的硬盘，sda一般指第一块硬盘，类似的有sdb,sdc等</p>\n<p>现在的内核都会把硬盘，移动硬盘，U盘之类的识别为sdX的形式。</p>\n<p>SATA接口是串行数据接口，俗称串口。在硬盘外部传输速度目前最快可达250M/S 。<br>IDE接口是并行数据接口，俗称并口，在硬盘外部传输速度最快可达133M/S。<br><img src=\"sda_interface.png\" alt=\"sda接口\"></p>\n<p><img src=\"IDE_interface.png\" alt=\"IDE接口\"> <img src=\"power_data_interface.png\" alt=\"\"></p>\n<p>IDE转SATA线如下，先把IDE一头接入到硬盘上，然后电源跟电脑电源线相连，然后把SATA则接入主板上面</p>\n<p><img src=\"IDE_power_sata.png\" alt=\"ide接口\"><br>IDE是英文IntegratedDriveElectronics的缩写，翻译成中文叫做“集成驱动器电子”，<br>IDE接口即指并行IDE接口（PATA接口），使用并行接口的硬盘既称为并口硬盘，IDE是一种较老的技术，在几年前很常见，目前在在硬盘方面基本不再使用此接口，其接口连接比较简单，只需用一根40线电缆将它们与主板或接口卡连起来就可以了。<br>sata接口<br>SATA接口（SerialATA）又称为串行ATA，是一种接口技术，使用SATA接口的<br>硬盘又叫串口硬盘，其最终将取代使用IDE接口的并口硬盘！SATA接口的历史：2001年，由Intel、APT、Dell、IBM、希捷、迈拓这几大厂商</p>\n<p>ide接口与sata接口的区别是什么</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1、SATA硬盘比IDE硬盘传输速度高。目前SATA可以提供150MB&#x2F;s的高峰传输速率。今后将达到300 MB&#x2F;s和600 MB&#x2F;s。到时我们将得到比IDE硬盘快近10倍的传输速率。</span><br><span class=\"line\">2、 相对于IDE硬盘的PATA40针的数据线，SATA的线缆少而细，传输距离远，可延伸至1米，使得安装设备和机内布线更加容易。连接器的体积小，这种线缆有效的改进了计算机内部的空气流动，也改善了机箱内的散热。</span><br><span class=\"line\">3、相对于IDE硬盘系统功耗有所减少。SATA硬盘使用500毫伏的电压就可以工作。</span><br><span class=\"line\">4、SATA可以通过使用多用途的芯片组或串行——并行转换器来向后兼容PATA设备。由于SATA和PATA可使用同样的驱动器，不需要对操作系统进行升级或其他改变。</span><br><span class=\"line\">5、SATA不需要设置主从盘跳线。BIOS会为它按照1、2、3顺序编号。这取决于驱动器接在哪个SATA连接器上（安装方便）。而IDE硬盘需要设置通过跳线来设置主从盘。</span><br><span class=\"line\">6、SATA还支持热插拔，可以象U盘一样使用。而IDE硬盘不支持热插拔.</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"sda-hda\"><a href=\"#sda-hda\" class=\"headerlink\" title=\"sda,hda\"></a>sda,hda</h2><p>hda一般是指IDE接口的硬盘，hda一般指第一块硬盘，类似的有hdb,hdc等<br>sda一般是指SATA接口的硬盘，sda一般指第一块硬盘，类似的有sdb,sdc等</p>\n<p>现在的内核都会把硬盘，移动硬盘，U盘之类的识别为sdX的形式。</p>\n<p>SATA接口是串行数据接口，俗称串口。在硬盘外部传输速度目前最快可达250M/S 。<br>IDE接口是并行数据接口，俗称并口，在硬盘外部传输速度最快可达133M/S。<br><img src=\"sda_interface.png\" alt=\"sda接口\"></p>\n<p><img src=\"IDE_interface.png\" alt=\"IDE接口\"> <img src=\"power_data_interface.png\" alt=\"\"></p>\n<p>IDE转SATA线如下，先把IDE一头接入到硬盘上，然后电源跟电脑电源线相连，然后把SATA则接入主板上面</p>\n<p><img src=\"IDE_power_sata.png\" alt=\"ide接口\"><br>IDE是英文IntegratedDriveElectronics的缩写，翻译成中文叫做“集成驱动器电子”，<br>IDE接口即指并行IDE接口（PATA接口），使用并行接口的硬盘既称为并口硬盘，IDE是一种较老的技术，在几年前很常见，目前在在硬盘方面基本不再使用此接口，其接口连接比较简单，只需用一根40线电缆将它们与主板或接口卡连起来就可以了。<br>sata接口<br>SATA接口（SerialATA）又称为串行ATA，是一种接口技术，使用SATA接口的<br>硬盘又叫串口硬盘，其最终将取代使用IDE接口的并口硬盘！SATA接口的历史：2001年，由Intel、APT、Dell、IBM、希捷、迈拓这几大厂商</p>\n<p>ide接口与sata接口的区别是什么</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1、SATA硬盘比IDE硬盘传输速度高。目前SATA可以提供150MB&#x2F;s的高峰传输速率。今后将达到300 MB&#x2F;s和600 MB&#x2F;s。到时我们将得到比IDE硬盘快近10倍的传输速率。</span><br><span class=\"line\">2、 相对于IDE硬盘的PATA40针的数据线，SATA的线缆少而细，传输距离远，可延伸至1米，使得安装设备和机内布线更加容易。连接器的体积小，这种线缆有效的改进了计算机内部的空气流动，也改善了机箱内的散热。</span><br><span class=\"line\">3、相对于IDE硬盘系统功耗有所减少。SATA硬盘使用500毫伏的电压就可以工作。</span><br><span class=\"line\">4、SATA可以通过使用多用途的芯片组或串行——并行转换器来向后兼容PATA设备。由于SATA和PATA可使用同样的驱动器，不需要对操作系统进行升级或其他改变。</span><br><span class=\"line\">5、SATA不需要设置主从盘跳线。BIOS会为它按照1、2、3顺序编号。这取决于驱动器接在哪个SATA连接器上（安装方便）。而IDE硬盘需要设置通过跳线来设置主从盘。</span><br><span class=\"line\">6、SATA还支持热插拔，可以象U盘一样使用。而IDE硬盘不支持热插拔.</span><br></pre></td></tr></table></figure>\n"},{"title":"ssh端口映射","_content":"\n# 简介\n可以将远端服务器一个端口remote_port绑定到本地端口port，其中-C是进行数据压缩，-f是后台操作，只有当提示用户名密码的时候才转向前台。-N是不执行远端命令，在只是端口转发时这条命令很有用处。-g 是允许远端主机连接本地转发端口。-R表明是将远端主机端口映射到本地端口。如果是-L，则是将本地端口映射到远端主机端口。\nssh的三个强大的端口转发命令：\n转发到远端：ssh -C -f -N -g -L 本地端口:目标IP:目标端口 用户名@目标IP\n转发到本地：ssh -C -f -N -g –R 本地端口:目标IP:目标端口 用户名@目标IP\n\n\tssh -C -f -N -g -D listen_port user@Tunnel_Host\n\t-C: 压缩数据传输。\n\t-f: 后台认证用户/密码，通常和-N连用，不用登录到远程主机。\n\t-N: 不执行脚本或命令，通常与-f连用。\n\t-g: 在-L/-R/-D参数中，允许远程主机连接到建立的转发的端口，如果不加这个参数，只允许本地主机建立连接。\n\t-L: localport:remotehost:remotehostport sshserver(本地机器端口:目标机器IP:目标机器端口 中转机器IP)\n\n## **本地端口转发**\n将访问本机的80端口访问转发到192.168.1.1的8080端口\nssh -C -f -N -g -L 80:192.168.1.1:8080  user@192.168.1.1\n如下图，假如host3和host1、host2都同互相通信，但是host1和host2之间不能通信，如何从host1连接上host2？\n\n对于实现ssh连接来说，实现方式很简单，从host1 ssh到host3，再ssh到host2，也就是将host3作为跳板的方式。但是如果不是ssh，而是http的80端口呢？如何让host1能访问host2的80端口？\n![](local_port_transmit.png)\nssh支持本地端口转发，语法格式为：\n\n\t ssh -L [local_bind_addr:]local_port:remote:remote_port middle_host\n以上图为例，实现方式是在host1上执行:\n\n\t[root@xuexi ~]# ssh -g -L 2222:host2:80 host3\n其中**\"-L\"**选项表示本地端口转发，其工作方式为：在本地指定一个由ssh监听的转发端口(2222)，将远程主机的端口(host2:80)映射为本地端口(2222)，当有主机连接本地映射端口(2222)时，本地ssh就将此端口的数据包转发给中间主机(host3)，然后host3再与远程主机的端口(host2:80)通信。\n现在就可以通过访问host1的2222端口来达到访问host2:80的目的了。例如：\n![](local_port_transmit1.png)\n再来解释下\"-g\"选项，指定该选项表示允许外界主机连接本地转发端口(2222)，如果不指定\"-g\"，则host4将无法通过访问host1:2222达到访问host2:80的目的。甚至，host1自身也不能使用172.16.10.5:2222，**而只能使用localhost:2222或127.0.0.1:2222这样的方式达到访问host2:80的目的，**之所以如此，是因为本地转发端口默认绑定在回环地址上。可以使用bind_addr来改变转发端口的绑定地址，例如：  \n\n\t[root@xuexi ~]# ssh -L 172.16.10.5:2222:host2:80 host3\n这样，**host1自身就能通过访问172.16.10.5:2222的方式达到访问host2:80的目的。**  \n一般来说，使用转发端口，都建议同时使用\"-g\"选项，否则将只有自身能访问转发端口.  \n\n### **再来分析下转发端口通信的过程**\n![](port_transmit_protocol.png)\n当host4发起172.16.10.5:2222的连接时(即步骤①)，数据包的目标地址和端口为\"172.16.10.5:2222\"。由于host1上ssh已经监听了2222端口，并且知道该端口映射自哪台主机哪个端口，所以将会把该数据包目标地址和端口替换为\"172.16.10.3:80\"，并将此数据包通过转发给host3。当host3收到该数据包时，发现是host1转发过来请求访问host2:80的数据包，所以host3将代为访问host2的80端口。  \n\n所以，**host1和host3之间的通信方式是SSH协议**，这段连接是安全加密的，因此称为\"安全隧道\"，**而host3和host2之间通信协议则是HTTP而不是ssh。**\n\n### **现在再来考虑下，通过本地端口转发的方式如何实现ssh跳板的功能呢？仍以上图为例**\n\n\t[root@xuexi ~]# ssh -g -L 22333:host2:22 host3]\n这样只需使用ssh连上host1的22333端口就等于连接了host2的22端口。\n\n### **最后，关于端口转发有一个需要注意的问题：ssh命令中带有要执行的命令。考虑了下面的三条在host1上执行的命令的区别。**\n\n\t[root@xuexi ~]# ssh -g -L 22333:host2:22 host3\n\t[root@xuexi ~]# ssh -g -L 22333:host2:22 host3 \"ifconfig\"\n\t[root@xuexi ~]# ssh -g -L 22333:host2:22 host3 \"sleep 10\"\n第一条命令开启了本地端口转发，且是以登录到host3的方式开启的，所以执行完该命令后，将跳到host3主机上，当退出host3时，端口转发功能将被关闭。另外，host1上之所以要开启端口转发，目的是为了与host2进行通信，而不是跳到host3上，所以应该在ssh命令行上加上\"-f\"选项让ssh在本机host1上以后台方式提供端口转发功能，而不是跳到host3上来提供端口转发功能。  \n\n第二条命令在开启本地转发的时候还指定了要在host3上执行\"ifconfig\"命令，但是ssh的工作机制是远程命令执行完毕的那一刻，ssh关闭连接，所以此命令开启的本地端口转发功能有效期只有执行ifconfig命令的一瞬间。  \n\n第三条命令和第二条命令类似，只不过指定的是睡眠10秒命令，所以此命令开启的本地转发功能有效期只有10秒。  \n\n结合上面的分析，开启端口转发功能时，建议让ssh以后台方式提供端口转发功能，且明确指示不要执行任何ssh命令行上的远程命令。即最佳开启方式为：  \n\n\t[root@xuexi ~]# ssh -f -N -g -L 22333:host2:22 host3\n\n\n## **远程端口转发**\n将访问192.168.1.1的8080访问转发到本机的80端口\nssh -C -f -N -g -R 80:192.168.1.1:8080 user@192.168.1.1\n请求开启的转发端口是在远程主机上的，所以称为\"远程端口转发\"\n\n\n## K8s:\n查看Server机上k8s部署的Pod\n\n\t$ kubectl get po -n rook-ceph\n\tNAME                               READY   STATUS      RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATES\n\trook-ceph-mgr-a-778576cbbc-mxvcp   1/1     Running     0          4h24m   10.36.0.11      hci-node04   <none>           <none>            app=rook-ceph-mgr,ceph_daemon_id=a,instance=a,mgr=a,pod-template-hash=778576cbbc,rook_cluster=rook-ceph\n\n\t$ kubectl get svc -n rook-ceph\n\tNAME                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE     LABELS\n\trook-ceph-mgr-dashboard    ClusterIP   10.108.115.137   <none>        8443/TCP            4h25m   app=rook-ceph-mgr,rook_cluster=rook-ceph\n将server机器的上部署的pod端口或svc的ClusterIP改为NodePort后的端口映射到自己的开发机上，并用浏览器访问两种方法:\n第一种: 也可以修改svc的ClusterIP类型为NodePort，这样就不用再运行下面的Pod端口映射到Node上了\n\n\t$ kubectl edit svc -n rook-ceph rook-ceph-mgr-dashboard\n\tspec:\n      clusterIP: 10.108.115.137\n\t  ......\n\t  type: NodePort\t// 把ClusterIP改为NodePort\n\t$ kubectl get svc -n rook-ceph\n\tNAME                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE\n\trook-ceph-mgr-dashboard    NodePort    10.101.80.177    <none>        8443:31180/TCP      46m\n在server机上用curl访问看看\n\n\t$ curl -v https://127.0.0.1:31180 --noproxy \"*\" -k\t//不通过机器配置的proxy访问\n可以看到映射到server的31180端口, 因此端口映射改为31180而不是8443，因为8443是svc的端口\n\n\t$ ssh -L MyLabIP:31180:10.67.108.211:31180 root@10.67.108.211\n\n第二种: Server机上将Pod端口映射到Node上\n\n\t$ kubectl port-forward rook-ceph-mgr-a-778576cbbc-mxvcp -n rook-ceph 8443:8443\nServer机上访问\n\n\t$ curl -v https://127.0.0.1:8443 --noproxy \"*\" -k\t// 访问不经过设置的公司Proxy, 直接用局域网访问\n\n在开发机上设置端口转发\n\n\t在自己开发机上运行下面command，将访问自己开发机的8443端口流量转发到server机器10.67.108.211的8443端口\n\t浏览器或curl访问路径为 https://10.67.108.211:8443\n\t$ ssh -L 8443:10.67.108.211:8443 root@10.67.108.211\n\t\n\t(管用!!!自己开发机上运行)运行下面command后浏览器或curl访问路径为 https://127.0.0.1:8443\n\t$ ssh -L 8443:127.0.0.1:8443 root@10.67.108.211\t\t// 将访问本机8443(第一个)端口的路由转发到10.67.108.211机器8443端口\n\t$ ssh -L MyLabIP:8443:127.0.0.1:8443 root@10.67.108.211\t//如果不在本机运行上面命令需要加上要转发8443端口的主机IP\n\t浏览器输入https://127.0.0.1:31440\n\n\n\n\n\n\n\n","source":"_posts/linux/ssh端口映射.md","raw":"---\ntitle: ssh端口映射\ntags: SSH-port\ncategories:\n- linux\n---\n\n# 简介\n可以将远端服务器一个端口remote_port绑定到本地端口port，其中-C是进行数据压缩，-f是后台操作，只有当提示用户名密码的时候才转向前台。-N是不执行远端命令，在只是端口转发时这条命令很有用处。-g 是允许远端主机连接本地转发端口。-R表明是将远端主机端口映射到本地端口。如果是-L，则是将本地端口映射到远端主机端口。\nssh的三个强大的端口转发命令：\n转发到远端：ssh -C -f -N -g -L 本地端口:目标IP:目标端口 用户名@目标IP\n转发到本地：ssh -C -f -N -g –R 本地端口:目标IP:目标端口 用户名@目标IP\n\n\tssh -C -f -N -g -D listen_port user@Tunnel_Host\n\t-C: 压缩数据传输。\n\t-f: 后台认证用户/密码，通常和-N连用，不用登录到远程主机。\n\t-N: 不执行脚本或命令，通常与-f连用。\n\t-g: 在-L/-R/-D参数中，允许远程主机连接到建立的转发的端口，如果不加这个参数，只允许本地主机建立连接。\n\t-L: localport:remotehost:remotehostport sshserver(本地机器端口:目标机器IP:目标机器端口 中转机器IP)\n\n## **本地端口转发**\n将访问本机的80端口访问转发到192.168.1.1的8080端口\nssh -C -f -N -g -L 80:192.168.1.1:8080  user@192.168.1.1\n如下图，假如host3和host1、host2都同互相通信，但是host1和host2之间不能通信，如何从host1连接上host2？\n\n对于实现ssh连接来说，实现方式很简单，从host1 ssh到host3，再ssh到host2，也就是将host3作为跳板的方式。但是如果不是ssh，而是http的80端口呢？如何让host1能访问host2的80端口？\n![](local_port_transmit.png)\nssh支持本地端口转发，语法格式为：\n\n\t ssh -L [local_bind_addr:]local_port:remote:remote_port middle_host\n以上图为例，实现方式是在host1上执行:\n\n\t[root@xuexi ~]# ssh -g -L 2222:host2:80 host3\n其中**\"-L\"**选项表示本地端口转发，其工作方式为：在本地指定一个由ssh监听的转发端口(2222)，将远程主机的端口(host2:80)映射为本地端口(2222)，当有主机连接本地映射端口(2222)时，本地ssh就将此端口的数据包转发给中间主机(host3)，然后host3再与远程主机的端口(host2:80)通信。\n现在就可以通过访问host1的2222端口来达到访问host2:80的目的了。例如：\n![](local_port_transmit1.png)\n再来解释下\"-g\"选项，指定该选项表示允许外界主机连接本地转发端口(2222)，如果不指定\"-g\"，则host4将无法通过访问host1:2222达到访问host2:80的目的。甚至，host1自身也不能使用172.16.10.5:2222，**而只能使用localhost:2222或127.0.0.1:2222这样的方式达到访问host2:80的目的，**之所以如此，是因为本地转发端口默认绑定在回环地址上。可以使用bind_addr来改变转发端口的绑定地址，例如：  \n\n\t[root@xuexi ~]# ssh -L 172.16.10.5:2222:host2:80 host3\n这样，**host1自身就能通过访问172.16.10.5:2222的方式达到访问host2:80的目的。**  \n一般来说，使用转发端口，都建议同时使用\"-g\"选项，否则将只有自身能访问转发端口.  \n\n### **再来分析下转发端口通信的过程**\n![](port_transmit_protocol.png)\n当host4发起172.16.10.5:2222的连接时(即步骤①)，数据包的目标地址和端口为\"172.16.10.5:2222\"。由于host1上ssh已经监听了2222端口，并且知道该端口映射自哪台主机哪个端口，所以将会把该数据包目标地址和端口替换为\"172.16.10.3:80\"，并将此数据包通过转发给host3。当host3收到该数据包时，发现是host1转发过来请求访问host2:80的数据包，所以host3将代为访问host2的80端口。  \n\n所以，**host1和host3之间的通信方式是SSH协议**，这段连接是安全加密的，因此称为\"安全隧道\"，**而host3和host2之间通信协议则是HTTP而不是ssh。**\n\n### **现在再来考虑下，通过本地端口转发的方式如何实现ssh跳板的功能呢？仍以上图为例**\n\n\t[root@xuexi ~]# ssh -g -L 22333:host2:22 host3]\n这样只需使用ssh连上host1的22333端口就等于连接了host2的22端口。\n\n### **最后，关于端口转发有一个需要注意的问题：ssh命令中带有要执行的命令。考虑了下面的三条在host1上执行的命令的区别。**\n\n\t[root@xuexi ~]# ssh -g -L 22333:host2:22 host3\n\t[root@xuexi ~]# ssh -g -L 22333:host2:22 host3 \"ifconfig\"\n\t[root@xuexi ~]# ssh -g -L 22333:host2:22 host3 \"sleep 10\"\n第一条命令开启了本地端口转发，且是以登录到host3的方式开启的，所以执行完该命令后，将跳到host3主机上，当退出host3时，端口转发功能将被关闭。另外，host1上之所以要开启端口转发，目的是为了与host2进行通信，而不是跳到host3上，所以应该在ssh命令行上加上\"-f\"选项让ssh在本机host1上以后台方式提供端口转发功能，而不是跳到host3上来提供端口转发功能。  \n\n第二条命令在开启本地转发的时候还指定了要在host3上执行\"ifconfig\"命令，但是ssh的工作机制是远程命令执行完毕的那一刻，ssh关闭连接，所以此命令开启的本地端口转发功能有效期只有执行ifconfig命令的一瞬间。  \n\n第三条命令和第二条命令类似，只不过指定的是睡眠10秒命令，所以此命令开启的本地转发功能有效期只有10秒。  \n\n结合上面的分析，开启端口转发功能时，建议让ssh以后台方式提供端口转发功能，且明确指示不要执行任何ssh命令行上的远程命令。即最佳开启方式为：  \n\n\t[root@xuexi ~]# ssh -f -N -g -L 22333:host2:22 host3\n\n\n## **远程端口转发**\n将访问192.168.1.1的8080访问转发到本机的80端口\nssh -C -f -N -g -R 80:192.168.1.1:8080 user@192.168.1.1\n请求开启的转发端口是在远程主机上的，所以称为\"远程端口转发\"\n\n\n## K8s:\n查看Server机上k8s部署的Pod\n\n\t$ kubectl get po -n rook-ceph\n\tNAME                               READY   STATUS      RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATES\n\trook-ceph-mgr-a-778576cbbc-mxvcp   1/1     Running     0          4h24m   10.36.0.11      hci-node04   <none>           <none>            app=rook-ceph-mgr,ceph_daemon_id=a,instance=a,mgr=a,pod-template-hash=778576cbbc,rook_cluster=rook-ceph\n\n\t$ kubectl get svc -n rook-ceph\n\tNAME                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE     LABELS\n\trook-ceph-mgr-dashboard    ClusterIP   10.108.115.137   <none>        8443/TCP            4h25m   app=rook-ceph-mgr,rook_cluster=rook-ceph\n将server机器的上部署的pod端口或svc的ClusterIP改为NodePort后的端口映射到自己的开发机上，并用浏览器访问两种方法:\n第一种: 也可以修改svc的ClusterIP类型为NodePort，这样就不用再运行下面的Pod端口映射到Node上了\n\n\t$ kubectl edit svc -n rook-ceph rook-ceph-mgr-dashboard\n\tspec:\n      clusterIP: 10.108.115.137\n\t  ......\n\t  type: NodePort\t// 把ClusterIP改为NodePort\n\t$ kubectl get svc -n rook-ceph\n\tNAME                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE\n\trook-ceph-mgr-dashboard    NodePort    10.101.80.177    <none>        8443:31180/TCP      46m\n在server机上用curl访问看看\n\n\t$ curl -v https://127.0.0.1:31180 --noproxy \"*\" -k\t//不通过机器配置的proxy访问\n可以看到映射到server的31180端口, 因此端口映射改为31180而不是8443，因为8443是svc的端口\n\n\t$ ssh -L MyLabIP:31180:10.67.108.211:31180 root@10.67.108.211\n\n第二种: Server机上将Pod端口映射到Node上\n\n\t$ kubectl port-forward rook-ceph-mgr-a-778576cbbc-mxvcp -n rook-ceph 8443:8443\nServer机上访问\n\n\t$ curl -v https://127.0.0.1:8443 --noproxy \"*\" -k\t// 访问不经过设置的公司Proxy, 直接用局域网访问\n\n在开发机上设置端口转发\n\n\t在自己开发机上运行下面command，将访问自己开发机的8443端口流量转发到server机器10.67.108.211的8443端口\n\t浏览器或curl访问路径为 https://10.67.108.211:8443\n\t$ ssh -L 8443:10.67.108.211:8443 root@10.67.108.211\n\t\n\t(管用!!!自己开发机上运行)运行下面command后浏览器或curl访问路径为 https://127.0.0.1:8443\n\t$ ssh -L 8443:127.0.0.1:8443 root@10.67.108.211\t\t// 将访问本机8443(第一个)端口的路由转发到10.67.108.211机器8443端口\n\t$ ssh -L MyLabIP:8443:127.0.0.1:8443 root@10.67.108.211\t//如果不在本机运行上面命令需要加上要转发8443端口的主机IP\n\t浏览器输入https://127.0.0.1:31440\n\n\n\n\n\n\n\n","slug":"linux/ssh端口映射","published":1,"date":"2020-08-12T16:05:46.457Z","updated":"2020-07-15T15:08:34.602Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfu003bhohxci6tf3f2","content":"<h1 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h1><p>可以将远端服务器一个端口remote_port绑定到本地端口port，其中-C是进行数据压缩，-f是后台操作，只有当提示用户名密码的时候才转向前台。-N是不执行远端命令，在只是端口转发时这条命令很有用处。-g 是允许远端主机连接本地转发端口。-R表明是将远端主机端口映射到本地端口。如果是-L，则是将本地端口映射到远端主机端口。<br>ssh的三个强大的端口转发命令：<br>转发到远端：ssh -C -f -N -g -L 本地端口:目标IP:目标端口 用户名@目标IP<br>转发到本地：ssh -C -f -N -g –R 本地端口:目标IP:目标端口 用户名@目标IP</p>\n<pre><code>ssh -C -f -N -g -D listen_port user@Tunnel_Host\n-C: 压缩数据传输。\n-f: 后台认证用户/密码，通常和-N连用，不用登录到远程主机。\n-N: 不执行脚本或命令，通常与-f连用。\n-g: 在-L/-R/-D参数中，允许远程主机连接到建立的转发的端口，如果不加这个参数，只允许本地主机建立连接。\n-L: localport:remotehost:remotehostport sshserver(本地机器端口:目标机器IP:目标机器端口 中转机器IP)</code></pre><h2 id=\"本地端口转发\"><a href=\"#本地端口转发\" class=\"headerlink\" title=\"本地端口转发\"></a><strong>本地端口转发</strong></h2><p>将访问本机的80端口访问转发到192.168.1.1的8080端口<br>ssh -C -f -N -g -L 80:192.168.1.1:8080  <a href=\"mailto:user@192.168.1.1\">user@192.168.1.1</a><br>如下图，假如host3和host1、host2都同互相通信，但是host1和host2之间不能通信，如何从host1连接上host2？</p>\n<p>对于实现ssh连接来说，实现方式很简单，从host1 ssh到host3，再ssh到host2，也就是将host3作为跳板的方式。但是如果不是ssh，而是http的80端口呢？如何让host1能访问host2的80端口？<br><img src=\"local_port_transmit.png\" alt=\"\"><br>ssh支持本地端口转发，语法格式为：</p>\n<pre><code>ssh -L [local_bind_addr:]local_port:remote:remote_port middle_host</code></pre><p>以上图为例，实现方式是在host1上执行:</p>\n<pre><code>[root@xuexi ~]# ssh -g -L 2222:host2:80 host3</code></pre><p>其中<strong>“-L”</strong>选项表示本地端口转发，其工作方式为：在本地指定一个由ssh监听的转发端口(2222)，将远程主机的端口(host2:80)映射为本地端口(2222)，当有主机连接本地映射端口(2222)时，本地ssh就将此端口的数据包转发给中间主机(host3)，然后host3再与远程主机的端口(host2:80)通信。<br>现在就可以通过访问host1的2222端口来达到访问host2:80的目的了。例如：<br><img src=\"local_port_transmit1.png\" alt=\"\"><br>再来解释下”-g”选项，指定该选项表示允许外界主机连接本地转发端口(2222)，如果不指定”-g”，则host4将无法通过访问host1:2222达到访问host2:80的目的。甚至，host1自身也不能使用172.16.10.5:2222，<strong>而只能使用localhost:2222或127.0.0.1:2222这样的方式达到访问host2:80的目的，</strong>之所以如此，是因为本地转发端口默认绑定在回环地址上。可以使用bind_addr来改变转发端口的绑定地址，例如：  </p>\n<pre><code>[root@xuexi ~]# ssh -L 172.16.10.5:2222:host2:80 host3</code></pre><p>这样，<strong>host1自身就能通过访问172.16.10.5:2222的方式达到访问host2:80的目的。</strong><br>一般来说，使用转发端口，都建议同时使用”-g”选项，否则将只有自身能访问转发端口.  </p>\n<h3 id=\"再来分析下转发端口通信的过程\"><a href=\"#再来分析下转发端口通信的过程\" class=\"headerlink\" title=\"再来分析下转发端口通信的过程\"></a><strong>再来分析下转发端口通信的过程</strong></h3><p><img src=\"port_transmit_protocol.png\" alt=\"\"><br>当host4发起172.16.10.5:2222的连接时(即步骤①)，数据包的目标地址和端口为”172.16.10.5:2222”。由于host1上ssh已经监听了2222端口，并且知道该端口映射自哪台主机哪个端口，所以将会把该数据包目标地址和端口替换为”172.16.10.3:80”，并将此数据包通过转发给host3。当host3收到该数据包时，发现是host1转发过来请求访问host2:80的数据包，所以host3将代为访问host2的80端口。  </p>\n<p>所以，<strong>host1和host3之间的通信方式是SSH协议</strong>，这段连接是安全加密的，因此称为”安全隧道”，<strong>而host3和host2之间通信协议则是HTTP而不是ssh。</strong></p>\n<h3 id=\"现在再来考虑下，通过本地端口转发的方式如何实现ssh跳板的功能呢？仍以上图为例\"><a href=\"#现在再来考虑下，通过本地端口转发的方式如何实现ssh跳板的功能呢？仍以上图为例\" class=\"headerlink\" title=\"现在再来考虑下，通过本地端口转发的方式如何实现ssh跳板的功能呢？仍以上图为例\"></a><strong>现在再来考虑下，通过本地端口转发的方式如何实现ssh跳板的功能呢？仍以上图为例</strong></h3><pre><code>[root@xuexi ~]# ssh -g -L 22333:host2:22 host3]</code></pre><p>这样只需使用ssh连上host1的22333端口就等于连接了host2的22端口。</p>\n<h3 id=\"最后，关于端口转发有一个需要注意的问题：ssh命令中带有要执行的命令。考虑了下面的三条在host1上执行的命令的区别。\"><a href=\"#最后，关于端口转发有一个需要注意的问题：ssh命令中带有要执行的命令。考虑了下面的三条在host1上执行的命令的区别。\" class=\"headerlink\" title=\"最后，关于端口转发有一个需要注意的问题：ssh命令中带有要执行的命令。考虑了下面的三条在host1上执行的命令的区别。\"></a><strong>最后，关于端口转发有一个需要注意的问题：ssh命令中带有要执行的命令。考虑了下面的三条在host1上执行的命令的区别。</strong></h3><pre><code>[root@xuexi ~]# ssh -g -L 22333:host2:22 host3\n[root@xuexi ~]# ssh -g -L 22333:host2:22 host3 &quot;ifconfig&quot;\n[root@xuexi ~]# ssh -g -L 22333:host2:22 host3 &quot;sleep 10&quot;</code></pre><p>第一条命令开启了本地端口转发，且是以登录到host3的方式开启的，所以执行完该命令后，将跳到host3主机上，当退出host3时，端口转发功能将被关闭。另外，host1上之所以要开启端口转发，目的是为了与host2进行通信，而不是跳到host3上，所以应该在ssh命令行上加上”-f”选项让ssh在本机host1上以后台方式提供端口转发功能，而不是跳到host3上来提供端口转发功能。  </p>\n<p>第二条命令在开启本地转发的时候还指定了要在host3上执行”ifconfig”命令，但是ssh的工作机制是远程命令执行完毕的那一刻，ssh关闭连接，所以此命令开启的本地端口转发功能有效期只有执行ifconfig命令的一瞬间。  </p>\n<p>第三条命令和第二条命令类似，只不过指定的是睡眠10秒命令，所以此命令开启的本地转发功能有效期只有10秒。  </p>\n<p>结合上面的分析，开启端口转发功能时，建议让ssh以后台方式提供端口转发功能，且明确指示不要执行任何ssh命令行上的远程命令。即最佳开启方式为：  </p>\n<pre><code>[root@xuexi ~]# ssh -f -N -g -L 22333:host2:22 host3</code></pre><h2 id=\"远程端口转发\"><a href=\"#远程端口转发\" class=\"headerlink\" title=\"远程端口转发\"></a><strong>远程端口转发</strong></h2><p>将访问192.168.1.1的8080访问转发到本机的80端口<br>ssh -C -f -N -g -R 80:192.168.1.1:8080 <a href=\"mailto:user@192.168.1.1\">user@192.168.1.1</a><br>请求开启的转发端口是在远程主机上的，所以称为”远程端口转发”</p>\n<h2 id=\"K8s\"><a href=\"#K8s\" class=\"headerlink\" title=\"K8s:\"></a>K8s:</h2><p>查看Server机上k8s部署的Pod</p>\n<pre><code>$ kubectl get po -n rook-ceph\nNAME                               READY   STATUS      RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATES\nrook-ceph-mgr-a-778576cbbc-mxvcp   1/1     Running     0          4h24m   10.36.0.11      hci-node04   &lt;none&gt;           &lt;none&gt;            app=rook-ceph-mgr,ceph_daemon_id=a,instance=a,mgr=a,pod-template-hash=778576cbbc,rook_cluster=rook-ceph\n\n$ kubectl get svc -n rook-ceph\nNAME                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE     LABELS\nrook-ceph-mgr-dashboard    ClusterIP   10.108.115.137   &lt;none&gt;        8443/TCP            4h25m   app=rook-ceph-mgr,rook_cluster=rook-ceph</code></pre><p>将server机器的上部署的pod端口或svc的ClusterIP改为NodePort后的端口映射到自己的开发机上，并用浏览器访问两种方法:<br>第一种: 也可以修改svc的ClusterIP类型为NodePort，这样就不用再运行下面的Pod端口映射到Node上了</p>\n<pre><code>$ kubectl edit svc -n rook-ceph rook-ceph-mgr-dashboard\nspec:\n  clusterIP: 10.108.115.137\n  ......\n  type: NodePort    // 把ClusterIP改为NodePort\n$ kubectl get svc -n rook-ceph\nNAME                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE\nrook-ceph-mgr-dashboard    NodePort    10.101.80.177    &lt;none&gt;        8443:31180/TCP      46m</code></pre><p>在server机上用curl访问看看</p>\n<pre><code>$ curl -v https://127.0.0.1:31180 --noproxy &quot;*&quot; -k    //不通过机器配置的proxy访问</code></pre><p>可以看到映射到server的31180端口, 因此端口映射改为31180而不是8443，因为8443是svc的端口</p>\n<pre><code>$ ssh -L MyLabIP:31180:10.67.108.211:31180 root@10.67.108.211</code></pre><p>第二种: Server机上将Pod端口映射到Node上</p>\n<pre><code>$ kubectl port-forward rook-ceph-mgr-a-778576cbbc-mxvcp -n rook-ceph 8443:8443</code></pre><p>Server机上访问</p>\n<pre><code>$ curl -v https://127.0.0.1:8443 --noproxy &quot;*&quot; -k    // 访问不经过设置的公司Proxy, 直接用局域网访问</code></pre><p>在开发机上设置端口转发</p>\n<pre><code>在自己开发机上运行下面command，将访问自己开发机的8443端口流量转发到server机器10.67.108.211的8443端口\n浏览器或curl访问路径为 https://10.67.108.211:8443\n$ ssh -L 8443:10.67.108.211:8443 root@10.67.108.211\n\n(管用!!!自己开发机上运行)运行下面command后浏览器或curl访问路径为 https://127.0.0.1:8443\n$ ssh -L 8443:127.0.0.1:8443 root@10.67.108.211        // 将访问本机8443(第一个)端口的路由转发到10.67.108.211机器8443端口\n$ ssh -L MyLabIP:8443:127.0.0.1:8443 root@10.67.108.211    //如果不在本机运行上面命令需要加上要转发8443端口的主机IP\n浏览器输入https://127.0.0.1:31440</code></pre>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h1><p>可以将远端服务器一个端口remote_port绑定到本地端口port，其中-C是进行数据压缩，-f是后台操作，只有当提示用户名密码的时候才转向前台。-N是不执行远端命令，在只是端口转发时这条命令很有用处。-g 是允许远端主机连接本地转发端口。-R表明是将远端主机端口映射到本地端口。如果是-L，则是将本地端口映射到远端主机端口。<br>ssh的三个强大的端口转发命令：<br>转发到远端：ssh -C -f -N -g -L 本地端口:目标IP:目标端口 用户名@目标IP<br>转发到本地：ssh -C -f -N -g –R 本地端口:目标IP:目标端口 用户名@目标IP</p>\n<pre><code>ssh -C -f -N -g -D listen_port user@Tunnel_Host\n-C: 压缩数据传输。\n-f: 后台认证用户/密码，通常和-N连用，不用登录到远程主机。\n-N: 不执行脚本或命令，通常与-f连用。\n-g: 在-L/-R/-D参数中，允许远程主机连接到建立的转发的端口，如果不加这个参数，只允许本地主机建立连接。\n-L: localport:remotehost:remotehostport sshserver(本地机器端口:目标机器IP:目标机器端口 中转机器IP)</code></pre><h2 id=\"本地端口转发\"><a href=\"#本地端口转发\" class=\"headerlink\" title=\"本地端口转发\"></a><strong>本地端口转发</strong></h2><p>将访问本机的80端口访问转发到192.168.1.1的8080端口<br>ssh -C -f -N -g -L 80:192.168.1.1:8080  <a href=\"mailto:user@192.168.1.1\">user@192.168.1.1</a><br>如下图，假如host3和host1、host2都同互相通信，但是host1和host2之间不能通信，如何从host1连接上host2？</p>\n<p>对于实现ssh连接来说，实现方式很简单，从host1 ssh到host3，再ssh到host2，也就是将host3作为跳板的方式。但是如果不是ssh，而是http的80端口呢？如何让host1能访问host2的80端口？<br><img src=\"local_port_transmit.png\" alt=\"\"><br>ssh支持本地端口转发，语法格式为：</p>\n<pre><code>ssh -L [local_bind_addr:]local_port:remote:remote_port middle_host</code></pre><p>以上图为例，实现方式是在host1上执行:</p>\n<pre><code>[root@xuexi ~]# ssh -g -L 2222:host2:80 host3</code></pre><p>其中<strong>“-L”</strong>选项表示本地端口转发，其工作方式为：在本地指定一个由ssh监听的转发端口(2222)，将远程主机的端口(host2:80)映射为本地端口(2222)，当有主机连接本地映射端口(2222)时，本地ssh就将此端口的数据包转发给中间主机(host3)，然后host3再与远程主机的端口(host2:80)通信。<br>现在就可以通过访问host1的2222端口来达到访问host2:80的目的了。例如：<br><img src=\"local_port_transmit1.png\" alt=\"\"><br>再来解释下”-g”选项，指定该选项表示允许外界主机连接本地转发端口(2222)，如果不指定”-g”，则host4将无法通过访问host1:2222达到访问host2:80的目的。甚至，host1自身也不能使用172.16.10.5:2222，<strong>而只能使用localhost:2222或127.0.0.1:2222这样的方式达到访问host2:80的目的，</strong>之所以如此，是因为本地转发端口默认绑定在回环地址上。可以使用bind_addr来改变转发端口的绑定地址，例如：  </p>\n<pre><code>[root@xuexi ~]# ssh -L 172.16.10.5:2222:host2:80 host3</code></pre><p>这样，<strong>host1自身就能通过访问172.16.10.5:2222的方式达到访问host2:80的目的。</strong><br>一般来说，使用转发端口，都建议同时使用”-g”选项，否则将只有自身能访问转发端口.  </p>\n<h3 id=\"再来分析下转发端口通信的过程\"><a href=\"#再来分析下转发端口通信的过程\" class=\"headerlink\" title=\"再来分析下转发端口通信的过程\"></a><strong>再来分析下转发端口通信的过程</strong></h3><p><img src=\"port_transmit_protocol.png\" alt=\"\"><br>当host4发起172.16.10.5:2222的连接时(即步骤①)，数据包的目标地址和端口为”172.16.10.5:2222”。由于host1上ssh已经监听了2222端口，并且知道该端口映射自哪台主机哪个端口，所以将会把该数据包目标地址和端口替换为”172.16.10.3:80”，并将此数据包通过转发给host3。当host3收到该数据包时，发现是host1转发过来请求访问host2:80的数据包，所以host3将代为访问host2的80端口。  </p>\n<p>所以，<strong>host1和host3之间的通信方式是SSH协议</strong>，这段连接是安全加密的，因此称为”安全隧道”，<strong>而host3和host2之间通信协议则是HTTP而不是ssh。</strong></p>\n<h3 id=\"现在再来考虑下，通过本地端口转发的方式如何实现ssh跳板的功能呢？仍以上图为例\"><a href=\"#现在再来考虑下，通过本地端口转发的方式如何实现ssh跳板的功能呢？仍以上图为例\" class=\"headerlink\" title=\"现在再来考虑下，通过本地端口转发的方式如何实现ssh跳板的功能呢？仍以上图为例\"></a><strong>现在再来考虑下，通过本地端口转发的方式如何实现ssh跳板的功能呢？仍以上图为例</strong></h3><pre><code>[root@xuexi ~]# ssh -g -L 22333:host2:22 host3]</code></pre><p>这样只需使用ssh连上host1的22333端口就等于连接了host2的22端口。</p>\n<h3 id=\"最后，关于端口转发有一个需要注意的问题：ssh命令中带有要执行的命令。考虑了下面的三条在host1上执行的命令的区别。\"><a href=\"#最后，关于端口转发有一个需要注意的问题：ssh命令中带有要执行的命令。考虑了下面的三条在host1上执行的命令的区别。\" class=\"headerlink\" title=\"最后，关于端口转发有一个需要注意的问题：ssh命令中带有要执行的命令。考虑了下面的三条在host1上执行的命令的区别。\"></a><strong>最后，关于端口转发有一个需要注意的问题：ssh命令中带有要执行的命令。考虑了下面的三条在host1上执行的命令的区别。</strong></h3><pre><code>[root@xuexi ~]# ssh -g -L 22333:host2:22 host3\n[root@xuexi ~]# ssh -g -L 22333:host2:22 host3 &quot;ifconfig&quot;\n[root@xuexi ~]# ssh -g -L 22333:host2:22 host3 &quot;sleep 10&quot;</code></pre><p>第一条命令开启了本地端口转发，且是以登录到host3的方式开启的，所以执行完该命令后，将跳到host3主机上，当退出host3时，端口转发功能将被关闭。另外，host1上之所以要开启端口转发，目的是为了与host2进行通信，而不是跳到host3上，所以应该在ssh命令行上加上”-f”选项让ssh在本机host1上以后台方式提供端口转发功能，而不是跳到host3上来提供端口转发功能。  </p>\n<p>第二条命令在开启本地转发的时候还指定了要在host3上执行”ifconfig”命令，但是ssh的工作机制是远程命令执行完毕的那一刻，ssh关闭连接，所以此命令开启的本地端口转发功能有效期只有执行ifconfig命令的一瞬间。  </p>\n<p>第三条命令和第二条命令类似，只不过指定的是睡眠10秒命令，所以此命令开启的本地转发功能有效期只有10秒。  </p>\n<p>结合上面的分析，开启端口转发功能时，建议让ssh以后台方式提供端口转发功能，且明确指示不要执行任何ssh命令行上的远程命令。即最佳开启方式为：  </p>\n<pre><code>[root@xuexi ~]# ssh -f -N -g -L 22333:host2:22 host3</code></pre><h2 id=\"远程端口转发\"><a href=\"#远程端口转发\" class=\"headerlink\" title=\"远程端口转发\"></a><strong>远程端口转发</strong></h2><p>将访问192.168.1.1的8080访问转发到本机的80端口<br>ssh -C -f -N -g -R 80:192.168.1.1:8080 <a href=\"mailto:user@192.168.1.1\">user@192.168.1.1</a><br>请求开启的转发端口是在远程主机上的，所以称为”远程端口转发”</p>\n<h2 id=\"K8s\"><a href=\"#K8s\" class=\"headerlink\" title=\"K8s:\"></a>K8s:</h2><p>查看Server机上k8s部署的Pod</p>\n<pre><code>$ kubectl get po -n rook-ceph\nNAME                               READY   STATUS      RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATES\nrook-ceph-mgr-a-778576cbbc-mxvcp   1/1     Running     0          4h24m   10.36.0.11      hci-node04   &lt;none&gt;           &lt;none&gt;            app=rook-ceph-mgr,ceph_daemon_id=a,instance=a,mgr=a,pod-template-hash=778576cbbc,rook_cluster=rook-ceph\n\n$ kubectl get svc -n rook-ceph\nNAME                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE     LABELS\nrook-ceph-mgr-dashboard    ClusterIP   10.108.115.137   &lt;none&gt;        8443/TCP            4h25m   app=rook-ceph-mgr,rook_cluster=rook-ceph</code></pre><p>将server机器的上部署的pod端口或svc的ClusterIP改为NodePort后的端口映射到自己的开发机上，并用浏览器访问两种方法:<br>第一种: 也可以修改svc的ClusterIP类型为NodePort，这样就不用再运行下面的Pod端口映射到Node上了</p>\n<pre><code>$ kubectl edit svc -n rook-ceph rook-ceph-mgr-dashboard\nspec:\n  clusterIP: 10.108.115.137\n  ......\n  type: NodePort    // 把ClusterIP改为NodePort\n$ kubectl get svc -n rook-ceph\nNAME                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE\nrook-ceph-mgr-dashboard    NodePort    10.101.80.177    &lt;none&gt;        8443:31180/TCP      46m</code></pre><p>在server机上用curl访问看看</p>\n<pre><code>$ curl -v https://127.0.0.1:31180 --noproxy &quot;*&quot; -k    //不通过机器配置的proxy访问</code></pre><p>可以看到映射到server的31180端口, 因此端口映射改为31180而不是8443，因为8443是svc的端口</p>\n<pre><code>$ ssh -L MyLabIP:31180:10.67.108.211:31180 root@10.67.108.211</code></pre><p>第二种: Server机上将Pod端口映射到Node上</p>\n<pre><code>$ kubectl port-forward rook-ceph-mgr-a-778576cbbc-mxvcp -n rook-ceph 8443:8443</code></pre><p>Server机上访问</p>\n<pre><code>$ curl -v https://127.0.0.1:8443 --noproxy &quot;*&quot; -k    // 访问不经过设置的公司Proxy, 直接用局域网访问</code></pre><p>在开发机上设置端口转发</p>\n<pre><code>在自己开发机上运行下面command，将访问自己开发机的8443端口流量转发到server机器10.67.108.211的8443端口\n浏览器或curl访问路径为 https://10.67.108.211:8443\n$ ssh -L 8443:10.67.108.211:8443 root@10.67.108.211\n\n(管用!!!自己开发机上运行)运行下面command后浏览器或curl访问路径为 https://127.0.0.1:8443\n$ ssh -L 8443:127.0.0.1:8443 root@10.67.108.211        // 将访问本机8443(第一个)端口的路由转发到10.67.108.211机器8443端口\n$ ssh -L MyLabIP:8443:127.0.0.1:8443 root@10.67.108.211    //如果不在本机运行上面命令需要加上要转发8443端口的主机IP\n浏览器输入https://127.0.0.1:31440</code></pre>"},{"title":"vim","_content":"\n================================================================================\n对比两个文件不同\n\n\t$ vimdiff file1 file2\n\n================================================================================\nLinux下复制粘贴快捷键\n 1. 在终端下：\n\n          复制命令：Ctrl + Shift + C  组合键.\n\n          粘贴命令：Ctrl + Shift + V  组合键.\n\n \n\n 2. 在控制台下：\n\n          复制命令：Ctrl + Insert  组合键　　或　　用鼠标选中即是复制。\n\n          粘贴命令：Shift + Insert  组合键　　或　　单击鼠标滚轮即为粘贴。\n\n================================================================================\n\nvi/vim 快速查找单词：\n\n1， 最快的方式是让光标停留在想要查找的单词的任意一个字母上面， 然后输入Shift + *  ，即可快速选中该单词，并且可以通过 n  或  N 进行下一个或上一个的匹配。\n\n2，在一个vim文件中选中单词，另vim文件中查找改单词:\n  让光标停留在vim文件中单词的第一个字母上， 然后直接敲击键盘yw两个按键拷贝该单词\n  另一个vim或本文件输入 / (Ctrl + R) 0 （即 /”0），回车， 就查找到了第一个匹配的单词， 并且可以  通过n或N进行下一个或上一个的匹配。\n\n================================================================================\n\nvi/vim多行注释和取消注释\n多行注释：\n\n1. 进入命令行模式，按ctrl + v进入 visual block模式，然后按j或↓, k或↑选中多行，把需要注释的行标记起来\n\n2. 按大写字母I，再插入注释符，例如//\n\n3. 按（两次）esc键就会全部注释了\n\n取消多行注释：\n\n1. 进入命令行模式，按ctrl + v进入 visual block模式，按字母l(小写\"L\")或←，→键横向选中列的个数，例如 // 需要选中2列\n\n2. 按字母j，或者k选中注释符号\n\n3. 按d键就可全部取消注释\n\n================================================================================\nvim全选，全部复制，全部删除\n全选（高亮显示）：按esc后，然后ggvG或者ggVG\n\n全部复制：按esc后，然后ggyG\n\n全部删除：按esc后，然后dG\n\n\n解析：\n\ngg：是让光标移到首行，在vim才有效，vi中无效 \n\nv ： 是进入Visual(可视）模式 \n\nG ：光标移到最后一行 \n\n选中内容以后就可以其他的操作了，比如： \nd  删除选中内容 \ny  复制选中内容到0号寄存器 \n\"+y  复制选中内容到＋寄存器，也就是系统的剪贴板，供其他程序用 \n\n\n================================================================================\nvi/vim 复制剪切n行\n\n\n剪切>:\n快捷键方式：\ndd：剪切光标所处当前行\nn + dd：剪切光标所在行及以下共 n 行\n按 p 粘贴在光标所在行\n命令行方式：\n例如剪切1到10行，并粘贴在12行处：\n1，10 m 12\n\n复制>：\n快捷键方式：\nyy：复制光标所处当前行\nn + yy：复制光标所在行及以下共 n 行\n按 p 粘贴在光标所在行\n命令行方式：\n例如复制1到10行，并粘贴在12行处：\n1，10 co 12\n\n删除>:\n快捷键方式：\ndd：删除光标所处当前行\nn + dd：删除光标所在行及以下共 n 行\n命令行方式：\n例如删除1到10行：\n1，10 de\n\n进入命令行:>\n\"shift + :\" ：进入命令行模式\n\"set nu\"或者\"set number\" ：显示行号, \"set nonu\"或者\"set nonumber\"取消显示行号\n\"etc + etc\" ：退出命令行模式\n实际情况下，按 p 粘贴时有的情况是粘贴在光标所在的下一行，自己操作下便可知晓。\n\n\n================================================================================\n\nvi/vim: 撤销上一次操作:\n\nu   撤销上一步的操作\nCtrl+r 恢复上一步被撤销的操作\n注意：\n    如果你输入“u”两次，你的文本恢复原样，那应该是你的Vim被配置在Vi兼容模式了。\n\n================================================================================\n问题：怎样在vim中实现代码折叠功能？\n \n \n解决方法：直接使用vim自带的快捷键和命令，便可以实现功能强大的折叠\n \n小试折叠：\n1  :set fdm=marker  在vim中执行该命令\n2  5G  将光标跳转到第5行\n3  zf10G  折叠第5行到第10行的代码，vim会在折叠的开始和结束自动添加三个连续的花括号作为标记\n4  zR  打开所有折叠\n5  zM  关闭所有折叠\n6  zE  删除所有的折叠标签\n7  退出vim窗口再次打开，执行2-6步。依然可以折叠，但是没有标记了。重新打开后折叠信息会丢失。\n \n折叠方法：\n1  manual  （不常用）默认折叠方法，如上面第7步即为该方法，关闭vim折叠会丢失。如果想保持折叠信息，可运行 :mkview 命令，重启后用 :loadview 命令回复。该命令生成的缓存文件位于 ~/.vim/view 文件夹中。移动或重命名文件，折叠信息依然会丢失。\n2  indent  （常用）缩进折叠方法，相同的缩进中代码会被折叠。 \n3  syntax  （不常用）语法高亮折叠，在c/c++中会折叠花括号部分，其它格式代码中有的不能自动折叠。 \n4  marker  （常用）标记折叠方法，如上面1-6所使用的方法。关闭vim折叠信息不会丢失，而且易用控制和标注。\n5  还有两种 diff 和 expr，目前我还没有用过。\n \n具体介绍：\n1  以 marker 为例，可以在vim中运行 :set fdm=marker 来设置折叠方法设置。折叠方法的时候，= 两边不能有空格。也可以将该命令添加到~/.vimrc中，实现vim自动加载。\n2  在使用小试折叠中 2 3 步折叠的时候，vim会自动添加三个连续的花括号作为标记，可在开始的花括号前添加介绍，花括号后添加级别号，级别号不能为0。\n\n3  级别的定义稍显复杂。在一般编码中，通常把不需要修改的代码添加标记折叠。没有必要在给折叠分等级。如果想快速折叠就切换为indent折叠方面，适用于任何有缩进的代码。\n \n折叠命令：\n1  zf  创建折叠，可以按照前面的方式进行折叠，也可以选中代码后进行折叠。 \n2  zF  在当前行创建折叠。当一开始就计划要折叠所写代码的时候，可以用该命令创建一对折叠符号，然后再往里面填写内容。\n3  :5,10fo  在vim中运行该命令会在折叠 5-10 行中的代码，可以用其它数字代替之。\n4  zd  删除光标下的折叠。\n5  zD  删除光标下的折叠，以及嵌套的折叠。\n6  zE  删除窗口内的所有折叠。仅当 manual 和 marker 折叠方法下有效。\n \n打开和关闭折叠：\n1  zo  打开光标下的折叠。\n2  zO  打开光标下的折叠，以及嵌套的折叠。\n3  zc  关闭光标下的折叠。\n4  zC  关闭光标下的折叠，以及嵌套的折叠。\n5  za  当光标在关闭折叠上时，打开之。在打开折叠上时，关闭之。\n6  zA  和za类似，不过对当前折叠和其嵌套折叠都有效。\n7  zv  打开当前光标所在折叠，仅打开足够的折叠使光标所在的行不被折叠。\n8  zr和zm  一层一层打开折叠和一层一层关闭折叠，这两个命令会递减和递增一个叫foldlevel的变量。如果你发现zm和zr不灵了，那有可能是你连续按的zr或zm次数多了，只要多按几次让foldlevel回到正常状态即可。执行以下zR和zM也可直接让foldlevel回到正常状态。\n9  zR和zM  打开所有折叠，设置foldlevel为最高级别。关闭所有折叠，设置foldlevel为0。\n \n在折叠间移动：\n1  [z  到当前打开折叠的开始。如果已在开始处，移到包含这个折叠的折叠开始处。\n2  ]z  到当前打开折叠的结束。如果已在结束处，移到包含这个折叠的折叠结束处。\n3  zj  把光标移动到下一个折叠的开始处。\n4  zk  把光标移动到前一个折叠的结束处。\n \n \n参考：\n在vim中运行 :h Folding 命令，查看折叠的帮助文档。\n\n\n\n================================================================================\n\n================================================================================\nturbostat 由 kernel-tools 数据包提供。\n是对 Intel® 64 位处理器中处理器的拓扑、频率、空闲的电源状态统计、温度和用电量的报告。\n================================================================================\n\nvim缩进参数解析\n缩进用 tab 制表符还是空格，个人爱好问题。但是在大多项目中，习惯使用空格。关于缩进，vim中可以通过如下四个参数进行配置\n\n\nset tabstop=4\n  <--->  set ts=4\nset softtabstop=4\n\nset shiftwidth=4\n\nset noexpandtab / expandtab\n解析： \n\ntabstop \n表示按一个tab之后，显示出来的相当于几个空格，默认的是8个。 \n\nsofttabstop \n表示在编辑模式的时候按退格键的时候退回缩进的长度。 \n\nshiftwidth \n表示每一级缩进的长度，一般设置成跟 softtabstop 一样 \n\nexpandtab与noexpandtab \n\n当设置成 expandtab 时，缩进用空格来表示，noexpandtab 则是用制表符表示一个缩进。个人习惯使用 ｀set expandtab｀ \n\n＃标志tab与空格 \n\n在vim中，默认情况下，没法区分空格和缩进，所以我们需要配置，使其能够区分。\n\n\n================================================================================\n\nvim内容左对齐\n:{range}left [margin]\n\":3,6 left\" 命令后，3~6行代码就左对齐，距离边缘0\n\":3,6 left 4\" 命令后，3~6行代码就左对齐，距离边缘4\n上面的命令会将代码直接都 “左对齐”了，但代码块并不都是左对齐的啊，所以，还是在命令行模式下，使用 ctrl+v 去选中代码块，按下=号，从而让代码块对齐比较好用。\n\n方法一:\n\n命令模式下：=:1,$\n\n方法二：\ngg（把关标定位到最上面），V（进入VISUAL模式），shift+g（选中整篇文本），然后＝。\n\n方法三：\ngg=G\n\n================================================================================\n\n查看某个函数定义\nshift + k\n\n水平分屏：\n：sp\t\t水平分屏打开当前文件\n：sp filename\t水平分屏打开另一个文件\nvim -o exe18.c Makefile hello.c\t\t默认打开3个文件并将它们水平分屏\nvim -o3 exe18.c Makefile hello.c\t打开3个文件并将它们水平分屏\nvim -on ... (n可以省略，表示分屏的个数)\n\nvim -o *.c 垂直打开所有.c文件\n\n垂直分屏\n：vsp\t\t垂直分屏打开当前文件\n：vsp filename\t垂直分屏打开另一个文件\nvim -O exe18.c Makefile hello.c\t\t默认打开3个文件并将它们垂直分屏\nvim -O3 exe18.c Makefile hello.c\t打开3个文件并将它们垂直分屏\n     ↓\n   （大写o）\n\n切换屏幕\nctrl+两次w，或者ctrl + ←||→ 切换屏幕\n\n退出屏幕\n:q \t退出当前光标在的屏幕\n：qall\t退出所有屏幕\n\n保存\n：w\t保存当前屏幕\n：wall\t保存所有打开的屏幕\n：wqall\t保存退出所有打开的屏幕\n\n为了让鼠标可以在几个屏幕间自由切换。\n按：\"Esc\"键 + “：”，输入：set mouse=a 。然后，回车(Enter)，这样鼠标就可以在多屏幕之间自由移动了，但是不能复制vim内容\n：set mouse=v，即可选中复制内容到粘贴板\n================================================================================\n\n显示所打开的文件名\n1、:set laststatus=2\n:file或:f\n\n2、CTRL+g\n\n3、在/etc/vim/vimrc中添加\nset statusline=%F\\ [%{&fenc}\\ %{&ff}\\ L%l/%L\\ C%c]\\ %=%{strftime('%Y-%m-%d\\ %H:%M')}\nset laststatus=2\n\n================================================================================\n\n#vim里面有个快捷键可以用来补全代码 C-n  （Ctrl+n）\n  需要先有头文件，如vim中输入str后，按ctrl+n不会显示strlen()函数，只有在vim中添加\n  #include<string.h>头文件后才会智能提示strlen()函数\n\n”Ctrl + }“ 可以跳转到函数或变量的定义处，“Ctrl + o”可以返回上一个跳转页面。\n\n================================================================================\n\n比较两个文件file1和file2\nvim file1 file2 -O\n\t-o(小写)水平打开两个文件\n\t-O(大写)垂直打开两个文件\n\n================================================================================\n4294967295000 / (1000 * 1000) = 4294967.295\n\n================================================================================\n垂直分屏\n：vsp filename\t垂直分屏打开另一个文件\n为了让鼠标可以在几个屏幕间自由切换。\n按：\"Esc\"键 + “：”，输入：set mouse=a 。然后，回车(Enter)，这样鼠标就可以在多屏幕之间自由移动了。\n\n================================================================================\nThe ycmd server SHUT DOWN (restart with ':YcmRestartServer'). \nUnexpect ...ype ':YcmToggleLogs ycmd_*.log' to check the logs\n:YcmToggleLogs ycmd_37783_stderr_zcxys8hw.log\n\tImprotError: Python version mismatch:module was compiled for Python 3.6, \n\tbut the interpreter version is incompatible:3.5.2(default), Nov 12 2018, 13:43:14\n:YcmToggleLogs ycmd_44993_stderr_uid3uor7.log\n:YcmToggleLogs ycmd_49853_stderr_yckx0mks.log\n\n================================================================================\nVim如何跳转到光标的上次位置\nCtrl + O\nCtrl + I\n装了Ctag的插件可以跳转 Ctrl+】。查看函数调用。 \n================================================================================\n\nvim复制代码包含注释格式如\"//\"会乱掉\n\t乱码问题\n\t一般来说只需要正确设置vim的编码识别序列就很少会遇到乱码问题：\n\tset fileencodings=ucs-bom,utf-8,utf-16,gbk,big5,gb18030,latin1\n\n\t1. 每次复制代码时，如果代码里有 // 这样的注释就容易让格式乱掉，通过下面的设置就可以避免这种情况。  \n\t2.   \n\t3. 粘贴代码时取消自动缩进  \n\t4. VIM在粘贴代码时会自动缩进，把代码搞得一团糟糕，甚至可能因为某行的一个注释造成后面的代码全部被注释掉，我知道有同学这个时候会用vi去打开文件再粘贴上去（鄙人以前就是这样），其实需要先设置一下  \n\t5. set paste  \n\t6. 然后再进入插入模式粘贴，代码就不会被自动缩进。可是敲代码的时候需要自动缩进，又得改回来:  \n\t7. set nopaste  \n\t8. 最方便的方法就是在.vimrc中加一句：  \n\t9. set pastetoggle=<F9>  \n\t10. 以后在插入模式下，只要按F9键就可以切换自动缩进。\n\nFrom <https://www.iteye.com/blog/haoningabc-1907479> \n\n\n\n================================================================================\n\n","source":"_posts/linux/vim.md","raw":"---\ntitle: vim\ntags:\ncategories:\n- linux\n---\n\n================================================================================\n对比两个文件不同\n\n\t$ vimdiff file1 file2\n\n================================================================================\nLinux下复制粘贴快捷键\n 1. 在终端下：\n\n          复制命令：Ctrl + Shift + C  组合键.\n\n          粘贴命令：Ctrl + Shift + V  组合键.\n\n \n\n 2. 在控制台下：\n\n          复制命令：Ctrl + Insert  组合键　　或　　用鼠标选中即是复制。\n\n          粘贴命令：Shift + Insert  组合键　　或　　单击鼠标滚轮即为粘贴。\n\n================================================================================\n\nvi/vim 快速查找单词：\n\n1， 最快的方式是让光标停留在想要查找的单词的任意一个字母上面， 然后输入Shift + *  ，即可快速选中该单词，并且可以通过 n  或  N 进行下一个或上一个的匹配。\n\n2，在一个vim文件中选中单词，另vim文件中查找改单词:\n  让光标停留在vim文件中单词的第一个字母上， 然后直接敲击键盘yw两个按键拷贝该单词\n  另一个vim或本文件输入 / (Ctrl + R) 0 （即 /”0），回车， 就查找到了第一个匹配的单词， 并且可以  通过n或N进行下一个或上一个的匹配。\n\n================================================================================\n\nvi/vim多行注释和取消注释\n多行注释：\n\n1. 进入命令行模式，按ctrl + v进入 visual block模式，然后按j或↓, k或↑选中多行，把需要注释的行标记起来\n\n2. 按大写字母I，再插入注释符，例如//\n\n3. 按（两次）esc键就会全部注释了\n\n取消多行注释：\n\n1. 进入命令行模式，按ctrl + v进入 visual block模式，按字母l(小写\"L\")或←，→键横向选中列的个数，例如 // 需要选中2列\n\n2. 按字母j，或者k选中注释符号\n\n3. 按d键就可全部取消注释\n\n================================================================================\nvim全选，全部复制，全部删除\n全选（高亮显示）：按esc后，然后ggvG或者ggVG\n\n全部复制：按esc后，然后ggyG\n\n全部删除：按esc后，然后dG\n\n\n解析：\n\ngg：是让光标移到首行，在vim才有效，vi中无效 \n\nv ： 是进入Visual(可视）模式 \n\nG ：光标移到最后一行 \n\n选中内容以后就可以其他的操作了，比如： \nd  删除选中内容 \ny  复制选中内容到0号寄存器 \n\"+y  复制选中内容到＋寄存器，也就是系统的剪贴板，供其他程序用 \n\n\n================================================================================\nvi/vim 复制剪切n行\n\n\n剪切>:\n快捷键方式：\ndd：剪切光标所处当前行\nn + dd：剪切光标所在行及以下共 n 行\n按 p 粘贴在光标所在行\n命令行方式：\n例如剪切1到10行，并粘贴在12行处：\n1，10 m 12\n\n复制>：\n快捷键方式：\nyy：复制光标所处当前行\nn + yy：复制光标所在行及以下共 n 行\n按 p 粘贴在光标所在行\n命令行方式：\n例如复制1到10行，并粘贴在12行处：\n1，10 co 12\n\n删除>:\n快捷键方式：\ndd：删除光标所处当前行\nn + dd：删除光标所在行及以下共 n 行\n命令行方式：\n例如删除1到10行：\n1，10 de\n\n进入命令行:>\n\"shift + :\" ：进入命令行模式\n\"set nu\"或者\"set number\" ：显示行号, \"set nonu\"或者\"set nonumber\"取消显示行号\n\"etc + etc\" ：退出命令行模式\n实际情况下，按 p 粘贴时有的情况是粘贴在光标所在的下一行，自己操作下便可知晓。\n\n\n================================================================================\n\nvi/vim: 撤销上一次操作:\n\nu   撤销上一步的操作\nCtrl+r 恢复上一步被撤销的操作\n注意：\n    如果你输入“u”两次，你的文本恢复原样，那应该是你的Vim被配置在Vi兼容模式了。\n\n================================================================================\n问题：怎样在vim中实现代码折叠功能？\n \n \n解决方法：直接使用vim自带的快捷键和命令，便可以实现功能强大的折叠\n \n小试折叠：\n1  :set fdm=marker  在vim中执行该命令\n2  5G  将光标跳转到第5行\n3  zf10G  折叠第5行到第10行的代码，vim会在折叠的开始和结束自动添加三个连续的花括号作为标记\n4  zR  打开所有折叠\n5  zM  关闭所有折叠\n6  zE  删除所有的折叠标签\n7  退出vim窗口再次打开，执行2-6步。依然可以折叠，但是没有标记了。重新打开后折叠信息会丢失。\n \n折叠方法：\n1  manual  （不常用）默认折叠方法，如上面第7步即为该方法，关闭vim折叠会丢失。如果想保持折叠信息，可运行 :mkview 命令，重启后用 :loadview 命令回复。该命令生成的缓存文件位于 ~/.vim/view 文件夹中。移动或重命名文件，折叠信息依然会丢失。\n2  indent  （常用）缩进折叠方法，相同的缩进中代码会被折叠。 \n3  syntax  （不常用）语法高亮折叠，在c/c++中会折叠花括号部分，其它格式代码中有的不能自动折叠。 \n4  marker  （常用）标记折叠方法，如上面1-6所使用的方法。关闭vim折叠信息不会丢失，而且易用控制和标注。\n5  还有两种 diff 和 expr，目前我还没有用过。\n \n具体介绍：\n1  以 marker 为例，可以在vim中运行 :set fdm=marker 来设置折叠方法设置。折叠方法的时候，= 两边不能有空格。也可以将该命令添加到~/.vimrc中，实现vim自动加载。\n2  在使用小试折叠中 2 3 步折叠的时候，vim会自动添加三个连续的花括号作为标记，可在开始的花括号前添加介绍，花括号后添加级别号，级别号不能为0。\n\n3  级别的定义稍显复杂。在一般编码中，通常把不需要修改的代码添加标记折叠。没有必要在给折叠分等级。如果想快速折叠就切换为indent折叠方面，适用于任何有缩进的代码。\n \n折叠命令：\n1  zf  创建折叠，可以按照前面的方式进行折叠，也可以选中代码后进行折叠。 \n2  zF  在当前行创建折叠。当一开始就计划要折叠所写代码的时候，可以用该命令创建一对折叠符号，然后再往里面填写内容。\n3  :5,10fo  在vim中运行该命令会在折叠 5-10 行中的代码，可以用其它数字代替之。\n4  zd  删除光标下的折叠。\n5  zD  删除光标下的折叠，以及嵌套的折叠。\n6  zE  删除窗口内的所有折叠。仅当 manual 和 marker 折叠方法下有效。\n \n打开和关闭折叠：\n1  zo  打开光标下的折叠。\n2  zO  打开光标下的折叠，以及嵌套的折叠。\n3  zc  关闭光标下的折叠。\n4  zC  关闭光标下的折叠，以及嵌套的折叠。\n5  za  当光标在关闭折叠上时，打开之。在打开折叠上时，关闭之。\n6  zA  和za类似，不过对当前折叠和其嵌套折叠都有效。\n7  zv  打开当前光标所在折叠，仅打开足够的折叠使光标所在的行不被折叠。\n8  zr和zm  一层一层打开折叠和一层一层关闭折叠，这两个命令会递减和递增一个叫foldlevel的变量。如果你发现zm和zr不灵了，那有可能是你连续按的zr或zm次数多了，只要多按几次让foldlevel回到正常状态即可。执行以下zR和zM也可直接让foldlevel回到正常状态。\n9  zR和zM  打开所有折叠，设置foldlevel为最高级别。关闭所有折叠，设置foldlevel为0。\n \n在折叠间移动：\n1  [z  到当前打开折叠的开始。如果已在开始处，移到包含这个折叠的折叠开始处。\n2  ]z  到当前打开折叠的结束。如果已在结束处，移到包含这个折叠的折叠结束处。\n3  zj  把光标移动到下一个折叠的开始处。\n4  zk  把光标移动到前一个折叠的结束处。\n \n \n参考：\n在vim中运行 :h Folding 命令，查看折叠的帮助文档。\n\n\n\n================================================================================\n\n================================================================================\nturbostat 由 kernel-tools 数据包提供。\n是对 Intel® 64 位处理器中处理器的拓扑、频率、空闲的电源状态统计、温度和用电量的报告。\n================================================================================\n\nvim缩进参数解析\n缩进用 tab 制表符还是空格，个人爱好问题。但是在大多项目中，习惯使用空格。关于缩进，vim中可以通过如下四个参数进行配置\n\n\nset tabstop=4\n  <--->  set ts=4\nset softtabstop=4\n\nset shiftwidth=4\n\nset noexpandtab / expandtab\n解析： \n\ntabstop \n表示按一个tab之后，显示出来的相当于几个空格，默认的是8个。 \n\nsofttabstop \n表示在编辑模式的时候按退格键的时候退回缩进的长度。 \n\nshiftwidth \n表示每一级缩进的长度，一般设置成跟 softtabstop 一样 \n\nexpandtab与noexpandtab \n\n当设置成 expandtab 时，缩进用空格来表示，noexpandtab 则是用制表符表示一个缩进。个人习惯使用 ｀set expandtab｀ \n\n＃标志tab与空格 \n\n在vim中，默认情况下，没法区分空格和缩进，所以我们需要配置，使其能够区分。\n\n\n================================================================================\n\nvim内容左对齐\n:{range}left [margin]\n\":3,6 left\" 命令后，3~6行代码就左对齐，距离边缘0\n\":3,6 left 4\" 命令后，3~6行代码就左对齐，距离边缘4\n上面的命令会将代码直接都 “左对齐”了，但代码块并不都是左对齐的啊，所以，还是在命令行模式下，使用 ctrl+v 去选中代码块，按下=号，从而让代码块对齐比较好用。\n\n方法一:\n\n命令模式下：=:1,$\n\n方法二：\ngg（把关标定位到最上面），V（进入VISUAL模式），shift+g（选中整篇文本），然后＝。\n\n方法三：\ngg=G\n\n================================================================================\n\n查看某个函数定义\nshift + k\n\n水平分屏：\n：sp\t\t水平分屏打开当前文件\n：sp filename\t水平分屏打开另一个文件\nvim -o exe18.c Makefile hello.c\t\t默认打开3个文件并将它们水平分屏\nvim -o3 exe18.c Makefile hello.c\t打开3个文件并将它们水平分屏\nvim -on ... (n可以省略，表示分屏的个数)\n\nvim -o *.c 垂直打开所有.c文件\n\n垂直分屏\n：vsp\t\t垂直分屏打开当前文件\n：vsp filename\t垂直分屏打开另一个文件\nvim -O exe18.c Makefile hello.c\t\t默认打开3个文件并将它们垂直分屏\nvim -O3 exe18.c Makefile hello.c\t打开3个文件并将它们垂直分屏\n     ↓\n   （大写o）\n\n切换屏幕\nctrl+两次w，或者ctrl + ←||→ 切换屏幕\n\n退出屏幕\n:q \t退出当前光标在的屏幕\n：qall\t退出所有屏幕\n\n保存\n：w\t保存当前屏幕\n：wall\t保存所有打开的屏幕\n：wqall\t保存退出所有打开的屏幕\n\n为了让鼠标可以在几个屏幕间自由切换。\n按：\"Esc\"键 + “：”，输入：set mouse=a 。然后，回车(Enter)，这样鼠标就可以在多屏幕之间自由移动了，但是不能复制vim内容\n：set mouse=v，即可选中复制内容到粘贴板\n================================================================================\n\n显示所打开的文件名\n1、:set laststatus=2\n:file或:f\n\n2、CTRL+g\n\n3、在/etc/vim/vimrc中添加\nset statusline=%F\\ [%{&fenc}\\ %{&ff}\\ L%l/%L\\ C%c]\\ %=%{strftime('%Y-%m-%d\\ %H:%M')}\nset laststatus=2\n\n================================================================================\n\n#vim里面有个快捷键可以用来补全代码 C-n  （Ctrl+n）\n  需要先有头文件，如vim中输入str后，按ctrl+n不会显示strlen()函数，只有在vim中添加\n  #include<string.h>头文件后才会智能提示strlen()函数\n\n”Ctrl + }“ 可以跳转到函数或变量的定义处，“Ctrl + o”可以返回上一个跳转页面。\n\n================================================================================\n\n比较两个文件file1和file2\nvim file1 file2 -O\n\t-o(小写)水平打开两个文件\n\t-O(大写)垂直打开两个文件\n\n================================================================================\n4294967295000 / (1000 * 1000) = 4294967.295\n\n================================================================================\n垂直分屏\n：vsp filename\t垂直分屏打开另一个文件\n为了让鼠标可以在几个屏幕间自由切换。\n按：\"Esc\"键 + “：”，输入：set mouse=a 。然后，回车(Enter)，这样鼠标就可以在多屏幕之间自由移动了。\n\n================================================================================\nThe ycmd server SHUT DOWN (restart with ':YcmRestartServer'). \nUnexpect ...ype ':YcmToggleLogs ycmd_*.log' to check the logs\n:YcmToggleLogs ycmd_37783_stderr_zcxys8hw.log\n\tImprotError: Python version mismatch:module was compiled for Python 3.6, \n\tbut the interpreter version is incompatible:3.5.2(default), Nov 12 2018, 13:43:14\n:YcmToggleLogs ycmd_44993_stderr_uid3uor7.log\n:YcmToggleLogs ycmd_49853_stderr_yckx0mks.log\n\n================================================================================\nVim如何跳转到光标的上次位置\nCtrl + O\nCtrl + I\n装了Ctag的插件可以跳转 Ctrl+】。查看函数调用。 \n================================================================================\n\nvim复制代码包含注释格式如\"//\"会乱掉\n\t乱码问题\n\t一般来说只需要正确设置vim的编码识别序列就很少会遇到乱码问题：\n\tset fileencodings=ucs-bom,utf-8,utf-16,gbk,big5,gb18030,latin1\n\n\t1. 每次复制代码时，如果代码里有 // 这样的注释就容易让格式乱掉，通过下面的设置就可以避免这种情况。  \n\t2.   \n\t3. 粘贴代码时取消自动缩进  \n\t4. VIM在粘贴代码时会自动缩进，把代码搞得一团糟糕，甚至可能因为某行的一个注释造成后面的代码全部被注释掉，我知道有同学这个时候会用vi去打开文件再粘贴上去（鄙人以前就是这样），其实需要先设置一下  \n\t5. set paste  \n\t6. 然后再进入插入模式粘贴，代码就不会被自动缩进。可是敲代码的时候需要自动缩进，又得改回来:  \n\t7. set nopaste  \n\t8. 最方便的方法就是在.vimrc中加一句：  \n\t9. set pastetoggle=<F9>  \n\t10. 以后在插入模式下，只要按F9键就可以切换自动缩进。\n\nFrom <https://www.iteye.com/blog/haoningabc-1907479> \n\n\n\n================================================================================\n\n","slug":"linux/vim","published":1,"date":"2020-08-12T16:05:46.507Z","updated":"2020-06-06T08:42:03.336Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfv003dhohx3lja7upo","content":"<p>================================================================================<br>对比两个文件不同</p>\n<pre><code>$ vimdiff file1 file2</code></pre><p>================================================================================<br>Linux下复制粘贴快捷键</p>\n<ol>\n<li><p>在终端下：</p>\n<pre><code>复制命令：Ctrl + Shift + C  组合键.\n\n粘贴命令：Ctrl + Shift + V  组合键.</code></pre></li>\n</ol>\n<ol start=\"2\">\n<li><p>在控制台下：</p>\n<pre><code>复制命令：Ctrl + Insert  组合键　　或　　用鼠标选中即是复制。\n\n粘贴命令：Shift + Insert  组合键　　或　　单击鼠标滚轮即为粘贴。</code></pre></li>\n</ol>\n<p>================================================================================</p>\n<p>vi/vim 快速查找单词：</p>\n<p>1， 最快的方式是让光标停留在想要查找的单词的任意一个字母上面， 然后输入Shift + *  ，即可快速选中该单词，并且可以通过 n  或  N 进行下一个或上一个的匹配。</p>\n<p>2，在一个vim文件中选中单词，另vim文件中查找改单词:<br>  让光标停留在vim文件中单词的第一个字母上， 然后直接敲击键盘yw两个按键拷贝该单词<br>  另一个vim或本文件输入 / (Ctrl + R) 0 （即 /”0），回车， 就查找到了第一个匹配的单词， 并且可以  通过n或N进行下一个或上一个的匹配。</p>\n<p>================================================================================</p>\n<p>vi/vim多行注释和取消注释<br>多行注释：</p>\n<ol>\n<li><p>进入命令行模式，按ctrl + v进入 visual block模式，然后按j或↓, k或↑选中多行，把需要注释的行标记起来</p>\n</li>\n<li><p>按大写字母I，再插入注释符，例如//</p>\n</li>\n<li><p>按（两次）esc键就会全部注释了</p>\n</li>\n</ol>\n<p>取消多行注释：</p>\n<ol>\n<li><p>进入命令行模式，按ctrl + v进入 visual block模式，按字母l(小写”L”)或←，→键横向选中列的个数，例如 // 需要选中2列</p>\n</li>\n<li><p>按字母j，或者k选中注释符号</p>\n</li>\n<li><p>按d键就可全部取消注释</p>\n</li>\n</ol>\n<p>================================================================================<br>vim全选，全部复制，全部删除<br>全选（高亮显示）：按esc后，然后ggvG或者ggVG</p>\n<p>全部复制：按esc后，然后ggyG</p>\n<p>全部删除：按esc后，然后dG</p>\n<p>解析：</p>\n<p>gg：是让光标移到首行，在vim才有效，vi中无效 </p>\n<p>v ： 是进入Visual(可视）模式 </p>\n<p>G ：光标移到最后一行 </p>\n<p>选中内容以后就可以其他的操作了，比如：<br>d  删除选中内容<br>y  复制选中内容到0号寄存器<br>“+y  复制选中内容到＋寄存器，也就是系统的剪贴板，供其他程序用 </p>\n<p>================================================================================<br>vi/vim 复制剪切n行</p>\n<p>剪切&gt;:<br>快捷键方式：<br>dd：剪切光标所处当前行<br>n + dd：剪切光标所在行及以下共 n 行<br>按 p 粘贴在光标所在行<br>命令行方式：<br>例如剪切1到10行，并粘贴在12行处：<br>1，10 m 12</p>\n<p>复制&gt;：<br>快捷键方式：<br>yy：复制光标所处当前行<br>n + yy：复制光标所在行及以下共 n 行<br>按 p 粘贴在光标所在行<br>命令行方式：<br>例如复制1到10行，并粘贴在12行处：<br>1，10 co 12</p>\n<p>删除&gt;:<br>快捷键方式：<br>dd：删除光标所处当前行<br>n + dd：删除光标所在行及以下共 n 行<br>命令行方式：<br>例如删除1到10行：<br>1，10 de</p>\n<p>进入命令行:&gt;<br>“shift + :” ：进入命令行模式<br>“set nu”或者”set number” ：显示行号, “set nonu”或者”set nonumber”取消显示行号<br>“etc + etc” ：退出命令行模式<br>实际情况下，按 p 粘贴时有的情况是粘贴在光标所在的下一行，自己操作下便可知晓。</p>\n<p>================================================================================</p>\n<p>vi/vim: 撤销上一次操作:</p>\n<p>u   撤销上一步的操作<br>Ctrl+r 恢复上一步被撤销的操作<br>注意：<br>    如果你输入“u”两次，你的文本恢复原样，那应该是你的Vim被配置在Vi兼容模式了。</p>\n<p>================================================================================<br>问题：怎样在vim中实现代码折叠功能？</p>\n<p>解决方法：直接使用vim自带的快捷键和命令，便可以实现功能强大的折叠</p>\n<p>小试折叠：<br>1  :set fdm=marker  在vim中执行该命令<br>2  5G  将光标跳转到第5行<br>3  zf10G  折叠第5行到第10行的代码，vim会在折叠的开始和结束自动添加三个连续的花括号作为标记<br>4  zR  打开所有折叠<br>5  zM  关闭所有折叠<br>6  zE  删除所有的折叠标签<br>7  退出vim窗口再次打开，执行2-6步。依然可以折叠，但是没有标记了。重新打开后折叠信息会丢失。</p>\n<p>折叠方法：<br>1  manual  （不常用）默认折叠方法，如上面第7步即为该方法，关闭vim折叠会丢失。如果想保持折叠信息，可运行 :mkview 命令，重启后用 :loadview 命令回复。该命令生成的缓存文件位于 ~/.vim/view 文件夹中。移动或重命名文件，折叠信息依然会丢失。<br>2  indent  （常用）缩进折叠方法，相同的缩进中代码会被折叠。<br>3  syntax  （不常用）语法高亮折叠，在c/c++中会折叠花括号部分，其它格式代码中有的不能自动折叠。<br>4  marker  （常用）标记折叠方法，如上面1-6所使用的方法。关闭vim折叠信息不会丢失，而且易用控制和标注。<br>5  还有两种 diff 和 expr，目前我还没有用过。</p>\n<p>具体介绍：<br>1  以 marker 为例，可以在vim中运行 :set fdm=marker 来设置折叠方法设置。折叠方法的时候，= 两边不能有空格。也可以将该命令添加到~/.vimrc中，实现vim自动加载。<br>2  在使用小试折叠中 2 3 步折叠的时候，vim会自动添加三个连续的花括号作为标记，可在开始的花括号前添加介绍，花括号后添加级别号，级别号不能为0。</p>\n<p>3  级别的定义稍显复杂。在一般编码中，通常把不需要修改的代码添加标记折叠。没有必要在给折叠分等级。如果想快速折叠就切换为indent折叠方面，适用于任何有缩进的代码。</p>\n<p>折叠命令：<br>1  zf  创建折叠，可以按照前面的方式进行折叠，也可以选中代码后进行折叠。<br>2  zF  在当前行创建折叠。当一开始就计划要折叠所写代码的时候，可以用该命令创建一对折叠符号，然后再往里面填写内容。<br>3  :5,10fo  在vim中运行该命令会在折叠 5-10 行中的代码，可以用其它数字代替之。<br>4  zd  删除光标下的折叠。<br>5  zD  删除光标下的折叠，以及嵌套的折叠。<br>6  zE  删除窗口内的所有折叠。仅当 manual 和 marker 折叠方法下有效。</p>\n<p>打开和关闭折叠：<br>1  zo  打开光标下的折叠。<br>2  zO  打开光标下的折叠，以及嵌套的折叠。<br>3  zc  关闭光标下的折叠。<br>4  zC  关闭光标下的折叠，以及嵌套的折叠。<br>5  za  当光标在关闭折叠上时，打开之。在打开折叠上时，关闭之。<br>6  zA  和za类似，不过对当前折叠和其嵌套折叠都有效。<br>7  zv  打开当前光标所在折叠，仅打开足够的折叠使光标所在的行不被折叠。<br>8  zr和zm  一层一层打开折叠和一层一层关闭折叠，这两个命令会递减和递增一个叫foldlevel的变量。如果你发现zm和zr不灵了，那有可能是你连续按的zr或zm次数多了，只要多按几次让foldlevel回到正常状态即可。执行以下zR和zM也可直接让foldlevel回到正常状态。<br>9  zR和zM  打开所有折叠，设置foldlevel为最高级别。关闭所有折叠，设置foldlevel为0。</p>\n<p>在折叠间移动：<br>1  [z  到当前打开折叠的开始。如果已在开始处，移到包含这个折叠的折叠开始处。<br>2  ]z  到当前打开折叠的结束。如果已在结束处，移到包含这个折叠的折叠结束处。<br>3  zj  把光标移动到下一个折叠的开始处。<br>4  zk  把光标移动到前一个折叠的结束处。</p>\n<p>参考：<br>在vim中运行 :h Folding 命令，查看折叠的帮助文档。</p>\n<p>================================================================================</p>\n<p>================================================================================<br>turbostat 由 kernel-tools 数据包提供。<br>是对 Intel® 64 位处理器中处理器的拓扑、频率、空闲的电源状态统计、温度和用电量的报告。<br>================================================================================</p>\n<p>vim缩进参数解析<br>缩进用 tab 制表符还是空格，个人爱好问题。但是在大多项目中，习惯使用空格。关于缩进，vim中可以通过如下四个参数进行配置</p>\n<p>set tabstop=4<br>  &lt;—&gt;  set ts=4<br>set softtabstop=4</p>\n<p>set shiftwidth=4</p>\n<p>set noexpandtab / expandtab<br>解析： </p>\n<p>tabstop<br>表示按一个tab之后，显示出来的相当于几个空格，默认的是8个。 </p>\n<p>softtabstop<br>表示在编辑模式的时候按退格键的时候退回缩进的长度。 </p>\n<p>shiftwidth<br>表示每一级缩进的长度，一般设置成跟 softtabstop 一样 </p>\n<p>expandtab与noexpandtab </p>\n<p>当设置成 expandtab 时，缩进用空格来表示，noexpandtab 则是用制表符表示一个缩进。个人习惯使用 ｀set expandtab｀ </p>\n<p>＃标志tab与空格 </p>\n<p>在vim中，默认情况下，没法区分空格和缩进，所以我们需要配置，使其能够区分。</p>\n<p>================================================================================</p>\n<p>vim内容左对齐<br>:{range}left [margin]<br>“:3,6 left” 命令后，3<del>6行代码就左对齐，距离边缘0<br>“:3,6 left 4” 命令后，3</del>6行代码就左对齐，距离边缘4<br>上面的命令会将代码直接都 “左对齐”了，但代码块并不都是左对齐的啊，所以，还是在命令行模式下，使用 ctrl+v 去选中代码块，按下=号，从而让代码块对齐比较好用。</p>\n<p>方法一:</p>\n<p>命令模式下：=:1,$</p>\n<p>方法二：<br>gg（把关标定位到最上面），V（进入VISUAL模式），shift+g（选中整篇文本），然后＝。</p>\n<p>方法三：<br>gg=G</p>\n<p>================================================================================</p>\n<p>查看某个函数定义<br>shift + k</p>\n<p>水平分屏：<br>：sp        水平分屏打开当前文件<br>：sp filename    水平分屏打开另一个文件<br>vim -o exe18.c Makefile hello.c        默认打开3个文件并将它们水平分屏<br>vim -o3 exe18.c Makefile hello.c    打开3个文件并将它们水平分屏<br>vim -on … (n可以省略，表示分屏的个数)</p>\n<p>vim -o *.c 垂直打开所有.c文件</p>\n<p>垂直分屏<br>：vsp        垂直分屏打开当前文件<br>：vsp filename    垂直分屏打开另一个文件<br>vim -O exe18.c Makefile hello.c        默认打开3个文件并将它们垂直分屏<br>vim -O3 exe18.c Makefile hello.c    打开3个文件并将它们垂直分屏<br>     ↓<br>   （大写o）</p>\n<p>切换屏幕<br>ctrl+两次w，或者ctrl + ←||→ 切换屏幕</p>\n<p>退出屏幕<br>:q     退出当前光标在的屏幕<br>：qall    退出所有屏幕</p>\n<p>保存<br>：w    保存当前屏幕<br>：wall    保存所有打开的屏幕<br>：wqall    保存退出所有打开的屏幕</p>\n<p>为了让鼠标可以在几个屏幕间自由切换。<br>按：”Esc”键 + “：”，输入：set mouse=a 。然后，回车(Enter)，这样鼠标就可以在多屏幕之间自由移动了，但是不能复制vim内容<br>：set mouse=v，即可选中复制内容到粘贴板<br>================================================================================</p>\n<p>显示所打开的文件名<br>1、:set laststatus=2<br>:file或:f</p>\n<p>2、CTRL+g</p>\n<p>3、在/etc/vim/vimrc中添加<br>set statusline=%F\\ [%{&amp;fenc}\\ %{&amp;ff}\\ L%l/%L\\ C%c]\\ %=%{strftime(‘%Y-%m-%d\\ %H:%M’)}<br>set laststatus=2</p>\n<p>================================================================================</p>\n<p>#vim里面有个快捷键可以用来补全代码 C-n  （Ctrl+n）<br>  需要先有头文件，如vim中输入str后，按ctrl+n不会显示strlen()函数，只有在vim中添加<br>  #include&lt;string.h&gt;头文件后才会智能提示strlen()函数</p>\n<p>”Ctrl + }“ 可以跳转到函数或变量的定义处，“Ctrl + o”可以返回上一个跳转页面。</p>\n<p>================================================================================</p>\n<p>比较两个文件file1和file2<br>vim file1 file2 -O<br>    -o(小写)水平打开两个文件<br>    -O(大写)垂直打开两个文件</p>\n<p>================================================================================<br>4294967295000 / (1000 * 1000) = 4294967.295</p>\n<p>================================================================================<br>垂直分屏<br>：vsp filename    垂直分屏打开另一个文件<br>为了让鼠标可以在几个屏幕间自由切换。<br>按：”Esc”键 + “：”，输入：set mouse=a 。然后，回车(Enter)，这样鼠标就可以在多屏幕之间自由移动了。</p>\n<p>================================================================================<br>The ycmd server SHUT DOWN (restart with ‘:YcmRestartServer’).<br>Unexpect …ype ‘:YcmToggleLogs ycmd_*.log’ to check the logs<br>:YcmToggleLogs ycmd_37783_stderr_zcxys8hw.log<br>    ImprotError: Python version mismatch:module was compiled for Python 3.6,<br>    but the interpreter version is incompatible:3.5.2(default), Nov 12 2018, 13:43:14<br>:YcmToggleLogs ycmd_44993_stderr_uid3uor7.log<br>:YcmToggleLogs ycmd_49853_stderr_yckx0mks.log</p>\n<p>================================================================================<br>Vim如何跳转到光标的上次位置<br>Ctrl + O<br>Ctrl + I<br>装了Ctag的插件可以跳转 Ctrl+】。查看函数调用。<br>================================================================================</p>\n<p>vim复制代码包含注释格式如”//“会乱掉<br>    乱码问题<br>    一般来说只需要正确设置vim的编码识别序列就很少会遇到乱码问题：<br>    set fileencodings=ucs-bom,utf-8,utf-16,gbk,big5,gb18030,latin1</p>\n<pre><code>1. 每次复制代码时，如果代码里有 // 这样的注释就容易让格式乱掉，通过下面的设置就可以避免这种情况。  \n2.   \n3. 粘贴代码时取消自动缩进  \n4. VIM在粘贴代码时会自动缩进，把代码搞得一团糟糕，甚至可能因为某行的一个注释造成后面的代码全部被注释掉，我知道有同学这个时候会用vi去打开文件再粘贴上去（鄙人以前就是这样），其实需要先设置一下  \n5. set paste  \n6. 然后再进入插入模式粘贴，代码就不会被自动缩进。可是敲代码的时候需要自动缩进，又得改回来:  \n7. set nopaste  \n8. 最方便的方法就是在.vimrc中加一句：  \n9. set pastetoggle=&lt;F9&gt;  \n10. 以后在插入模式下，只要按F9键就可以切换自动缩进。</code></pre><p>From <a href=\"https://www.iteye.com/blog/haoningabc-1907479\" target=\"_blank\" rel=\"noopener\">https://www.iteye.com/blog/haoningabc-1907479</a> </p>\n<p>================================================================================</p>\n","site":{"data":{}},"excerpt":"","more":"<p>================================================================================<br>对比两个文件不同</p>\n<pre><code>$ vimdiff file1 file2</code></pre><p>================================================================================<br>Linux下复制粘贴快捷键</p>\n<ol>\n<li><p>在终端下：</p>\n<pre><code>复制命令：Ctrl + Shift + C  组合键.\n\n粘贴命令：Ctrl + Shift + V  组合键.</code></pre></li>\n</ol>\n<ol start=\"2\">\n<li><p>在控制台下：</p>\n<pre><code>复制命令：Ctrl + Insert  组合键　　或　　用鼠标选中即是复制。\n\n粘贴命令：Shift + Insert  组合键　　或　　单击鼠标滚轮即为粘贴。</code></pre></li>\n</ol>\n<p>================================================================================</p>\n<p>vi/vim 快速查找单词：</p>\n<p>1， 最快的方式是让光标停留在想要查找的单词的任意一个字母上面， 然后输入Shift + *  ，即可快速选中该单词，并且可以通过 n  或  N 进行下一个或上一个的匹配。</p>\n<p>2，在一个vim文件中选中单词，另vim文件中查找改单词:<br>  让光标停留在vim文件中单词的第一个字母上， 然后直接敲击键盘yw两个按键拷贝该单词<br>  另一个vim或本文件输入 / (Ctrl + R) 0 （即 /”0），回车， 就查找到了第一个匹配的单词， 并且可以  通过n或N进行下一个或上一个的匹配。</p>\n<p>================================================================================</p>\n<p>vi/vim多行注释和取消注释<br>多行注释：</p>\n<ol>\n<li><p>进入命令行模式，按ctrl + v进入 visual block模式，然后按j或↓, k或↑选中多行，把需要注释的行标记起来</p>\n</li>\n<li><p>按大写字母I，再插入注释符，例如//</p>\n</li>\n<li><p>按（两次）esc键就会全部注释了</p>\n</li>\n</ol>\n<p>取消多行注释：</p>\n<ol>\n<li><p>进入命令行模式，按ctrl + v进入 visual block模式，按字母l(小写”L”)或←，→键横向选中列的个数，例如 // 需要选中2列</p>\n</li>\n<li><p>按字母j，或者k选中注释符号</p>\n</li>\n<li><p>按d键就可全部取消注释</p>\n</li>\n</ol>\n<p>================================================================================<br>vim全选，全部复制，全部删除<br>全选（高亮显示）：按esc后，然后ggvG或者ggVG</p>\n<p>全部复制：按esc后，然后ggyG</p>\n<p>全部删除：按esc后，然后dG</p>\n<p>解析：</p>\n<p>gg：是让光标移到首行，在vim才有效，vi中无效 </p>\n<p>v ： 是进入Visual(可视）模式 </p>\n<p>G ：光标移到最后一行 </p>\n<p>选中内容以后就可以其他的操作了，比如：<br>d  删除选中内容<br>y  复制选中内容到0号寄存器<br>“+y  复制选中内容到＋寄存器，也就是系统的剪贴板，供其他程序用 </p>\n<p>================================================================================<br>vi/vim 复制剪切n行</p>\n<p>剪切&gt;:<br>快捷键方式：<br>dd：剪切光标所处当前行<br>n + dd：剪切光标所在行及以下共 n 行<br>按 p 粘贴在光标所在行<br>命令行方式：<br>例如剪切1到10行，并粘贴在12行处：<br>1，10 m 12</p>\n<p>复制&gt;：<br>快捷键方式：<br>yy：复制光标所处当前行<br>n + yy：复制光标所在行及以下共 n 行<br>按 p 粘贴在光标所在行<br>命令行方式：<br>例如复制1到10行，并粘贴在12行处：<br>1，10 co 12</p>\n<p>删除&gt;:<br>快捷键方式：<br>dd：删除光标所处当前行<br>n + dd：删除光标所在行及以下共 n 行<br>命令行方式：<br>例如删除1到10行：<br>1，10 de</p>\n<p>进入命令行:&gt;<br>“shift + :” ：进入命令行模式<br>“set nu”或者”set number” ：显示行号, “set nonu”或者”set nonumber”取消显示行号<br>“etc + etc” ：退出命令行模式<br>实际情况下，按 p 粘贴时有的情况是粘贴在光标所在的下一行，自己操作下便可知晓。</p>\n<p>================================================================================</p>\n<p>vi/vim: 撤销上一次操作:</p>\n<p>u   撤销上一步的操作<br>Ctrl+r 恢复上一步被撤销的操作<br>注意：<br>    如果你输入“u”两次，你的文本恢复原样，那应该是你的Vim被配置在Vi兼容模式了。</p>\n<p>================================================================================<br>问题：怎样在vim中实现代码折叠功能？</p>\n<p>解决方法：直接使用vim自带的快捷键和命令，便可以实现功能强大的折叠</p>\n<p>小试折叠：<br>1  :set fdm=marker  在vim中执行该命令<br>2  5G  将光标跳转到第5行<br>3  zf10G  折叠第5行到第10行的代码，vim会在折叠的开始和结束自动添加三个连续的花括号作为标记<br>4  zR  打开所有折叠<br>5  zM  关闭所有折叠<br>6  zE  删除所有的折叠标签<br>7  退出vim窗口再次打开，执行2-6步。依然可以折叠，但是没有标记了。重新打开后折叠信息会丢失。</p>\n<p>折叠方法：<br>1  manual  （不常用）默认折叠方法，如上面第7步即为该方法，关闭vim折叠会丢失。如果想保持折叠信息，可运行 :mkview 命令，重启后用 :loadview 命令回复。该命令生成的缓存文件位于 ~/.vim/view 文件夹中。移动或重命名文件，折叠信息依然会丢失。<br>2  indent  （常用）缩进折叠方法，相同的缩进中代码会被折叠。<br>3  syntax  （不常用）语法高亮折叠，在c/c++中会折叠花括号部分，其它格式代码中有的不能自动折叠。<br>4  marker  （常用）标记折叠方法，如上面1-6所使用的方法。关闭vim折叠信息不会丢失，而且易用控制和标注。<br>5  还有两种 diff 和 expr，目前我还没有用过。</p>\n<p>具体介绍：<br>1  以 marker 为例，可以在vim中运行 :set fdm=marker 来设置折叠方法设置。折叠方法的时候，= 两边不能有空格。也可以将该命令添加到~/.vimrc中，实现vim自动加载。<br>2  在使用小试折叠中 2 3 步折叠的时候，vim会自动添加三个连续的花括号作为标记，可在开始的花括号前添加介绍，花括号后添加级别号，级别号不能为0。</p>\n<p>3  级别的定义稍显复杂。在一般编码中，通常把不需要修改的代码添加标记折叠。没有必要在给折叠分等级。如果想快速折叠就切换为indent折叠方面，适用于任何有缩进的代码。</p>\n<p>折叠命令：<br>1  zf  创建折叠，可以按照前面的方式进行折叠，也可以选中代码后进行折叠。<br>2  zF  在当前行创建折叠。当一开始就计划要折叠所写代码的时候，可以用该命令创建一对折叠符号，然后再往里面填写内容。<br>3  :5,10fo  在vim中运行该命令会在折叠 5-10 行中的代码，可以用其它数字代替之。<br>4  zd  删除光标下的折叠。<br>5  zD  删除光标下的折叠，以及嵌套的折叠。<br>6  zE  删除窗口内的所有折叠。仅当 manual 和 marker 折叠方法下有效。</p>\n<p>打开和关闭折叠：<br>1  zo  打开光标下的折叠。<br>2  zO  打开光标下的折叠，以及嵌套的折叠。<br>3  zc  关闭光标下的折叠。<br>4  zC  关闭光标下的折叠，以及嵌套的折叠。<br>5  za  当光标在关闭折叠上时，打开之。在打开折叠上时，关闭之。<br>6  zA  和za类似，不过对当前折叠和其嵌套折叠都有效。<br>7  zv  打开当前光标所在折叠，仅打开足够的折叠使光标所在的行不被折叠。<br>8  zr和zm  一层一层打开折叠和一层一层关闭折叠，这两个命令会递减和递增一个叫foldlevel的变量。如果你发现zm和zr不灵了，那有可能是你连续按的zr或zm次数多了，只要多按几次让foldlevel回到正常状态即可。执行以下zR和zM也可直接让foldlevel回到正常状态。<br>9  zR和zM  打开所有折叠，设置foldlevel为最高级别。关闭所有折叠，设置foldlevel为0。</p>\n<p>在折叠间移动：<br>1  [z  到当前打开折叠的开始。如果已在开始处，移到包含这个折叠的折叠开始处。<br>2  ]z  到当前打开折叠的结束。如果已在结束处，移到包含这个折叠的折叠结束处。<br>3  zj  把光标移动到下一个折叠的开始处。<br>4  zk  把光标移动到前一个折叠的结束处。</p>\n<p>参考：<br>在vim中运行 :h Folding 命令，查看折叠的帮助文档。</p>\n<p>================================================================================</p>\n<p>================================================================================<br>turbostat 由 kernel-tools 数据包提供。<br>是对 Intel® 64 位处理器中处理器的拓扑、频率、空闲的电源状态统计、温度和用电量的报告。<br>================================================================================</p>\n<p>vim缩进参数解析<br>缩进用 tab 制表符还是空格，个人爱好问题。但是在大多项目中，习惯使用空格。关于缩进，vim中可以通过如下四个参数进行配置</p>\n<p>set tabstop=4<br>  &lt;—&gt;  set ts=4<br>set softtabstop=4</p>\n<p>set shiftwidth=4</p>\n<p>set noexpandtab / expandtab<br>解析： </p>\n<p>tabstop<br>表示按一个tab之后，显示出来的相当于几个空格，默认的是8个。 </p>\n<p>softtabstop<br>表示在编辑模式的时候按退格键的时候退回缩进的长度。 </p>\n<p>shiftwidth<br>表示每一级缩进的长度，一般设置成跟 softtabstop 一样 </p>\n<p>expandtab与noexpandtab </p>\n<p>当设置成 expandtab 时，缩进用空格来表示，noexpandtab 则是用制表符表示一个缩进。个人习惯使用 ｀set expandtab｀ </p>\n<p>＃标志tab与空格 </p>\n<p>在vim中，默认情况下，没法区分空格和缩进，所以我们需要配置，使其能够区分。</p>\n<p>================================================================================</p>\n<p>vim内容左对齐<br>:{range}left [margin]<br>“:3,6 left” 命令后，3<del>6行代码就左对齐，距离边缘0<br>“:3,6 left 4” 命令后，3</del>6行代码就左对齐，距离边缘4<br>上面的命令会将代码直接都 “左对齐”了，但代码块并不都是左对齐的啊，所以，还是在命令行模式下，使用 ctrl+v 去选中代码块，按下=号，从而让代码块对齐比较好用。</p>\n<p>方法一:</p>\n<p>命令模式下：=:1,$</p>\n<p>方法二：<br>gg（把关标定位到最上面），V（进入VISUAL模式），shift+g（选中整篇文本），然后＝。</p>\n<p>方法三：<br>gg=G</p>\n<p>================================================================================</p>\n<p>查看某个函数定义<br>shift + k</p>\n<p>水平分屏：<br>：sp        水平分屏打开当前文件<br>：sp filename    水平分屏打开另一个文件<br>vim -o exe18.c Makefile hello.c        默认打开3个文件并将它们水平分屏<br>vim -o3 exe18.c Makefile hello.c    打开3个文件并将它们水平分屏<br>vim -on … (n可以省略，表示分屏的个数)</p>\n<p>vim -o *.c 垂直打开所有.c文件</p>\n<p>垂直分屏<br>：vsp        垂直分屏打开当前文件<br>：vsp filename    垂直分屏打开另一个文件<br>vim -O exe18.c Makefile hello.c        默认打开3个文件并将它们垂直分屏<br>vim -O3 exe18.c Makefile hello.c    打开3个文件并将它们垂直分屏<br>     ↓<br>   （大写o）</p>\n<p>切换屏幕<br>ctrl+两次w，或者ctrl + ←||→ 切换屏幕</p>\n<p>退出屏幕<br>:q     退出当前光标在的屏幕<br>：qall    退出所有屏幕</p>\n<p>保存<br>：w    保存当前屏幕<br>：wall    保存所有打开的屏幕<br>：wqall    保存退出所有打开的屏幕</p>\n<p>为了让鼠标可以在几个屏幕间自由切换。<br>按：”Esc”键 + “：”，输入：set mouse=a 。然后，回车(Enter)，这样鼠标就可以在多屏幕之间自由移动了，但是不能复制vim内容<br>：set mouse=v，即可选中复制内容到粘贴板<br>================================================================================</p>\n<p>显示所打开的文件名<br>1、:set laststatus=2<br>:file或:f</p>\n<p>2、CTRL+g</p>\n<p>3、在/etc/vim/vimrc中添加<br>set statusline=%F\\ [%{&amp;fenc}\\ %{&amp;ff}\\ L%l/%L\\ C%c]\\ %=%{strftime(‘%Y-%m-%d\\ %H:%M’)}<br>set laststatus=2</p>\n<p>================================================================================</p>\n<p>#vim里面有个快捷键可以用来补全代码 C-n  （Ctrl+n）<br>  需要先有头文件，如vim中输入str后，按ctrl+n不会显示strlen()函数，只有在vim中添加<br>  #include&lt;string.h&gt;头文件后才会智能提示strlen()函数</p>\n<p>”Ctrl + }“ 可以跳转到函数或变量的定义处，“Ctrl + o”可以返回上一个跳转页面。</p>\n<p>================================================================================</p>\n<p>比较两个文件file1和file2<br>vim file1 file2 -O<br>    -o(小写)水平打开两个文件<br>    -O(大写)垂直打开两个文件</p>\n<p>================================================================================<br>4294967295000 / (1000 * 1000) = 4294967.295</p>\n<p>================================================================================<br>垂直分屏<br>：vsp filename    垂直分屏打开另一个文件<br>为了让鼠标可以在几个屏幕间自由切换。<br>按：”Esc”键 + “：”，输入：set mouse=a 。然后，回车(Enter)，这样鼠标就可以在多屏幕之间自由移动了。</p>\n<p>================================================================================<br>The ycmd server SHUT DOWN (restart with ‘:YcmRestartServer’).<br>Unexpect …ype ‘:YcmToggleLogs ycmd_*.log’ to check the logs<br>:YcmToggleLogs ycmd_37783_stderr_zcxys8hw.log<br>    ImprotError: Python version mismatch:module was compiled for Python 3.6,<br>    but the interpreter version is incompatible:3.5.2(default), Nov 12 2018, 13:43:14<br>:YcmToggleLogs ycmd_44993_stderr_uid3uor7.log<br>:YcmToggleLogs ycmd_49853_stderr_yckx0mks.log</p>\n<p>================================================================================<br>Vim如何跳转到光标的上次位置<br>Ctrl + O<br>Ctrl + I<br>装了Ctag的插件可以跳转 Ctrl+】。查看函数调用。<br>================================================================================</p>\n<p>vim复制代码包含注释格式如”//“会乱掉<br>    乱码问题<br>    一般来说只需要正确设置vim的编码识别序列就很少会遇到乱码问题：<br>    set fileencodings=ucs-bom,utf-8,utf-16,gbk,big5,gb18030,latin1</p>\n<pre><code>1. 每次复制代码时，如果代码里有 // 这样的注释就容易让格式乱掉，通过下面的设置就可以避免这种情况。  \n2.   \n3. 粘贴代码时取消自动缩进  \n4. VIM在粘贴代码时会自动缩进，把代码搞得一团糟糕，甚至可能因为某行的一个注释造成后面的代码全部被注释掉，我知道有同学这个时候会用vi去打开文件再粘贴上去（鄙人以前就是这样），其实需要先设置一下  \n5. set paste  \n6. 然后再进入插入模式粘贴，代码就不会被自动缩进。可是敲代码的时候需要自动缩进，又得改回来:  \n7. set nopaste  \n8. 最方便的方法就是在.vimrc中加一句：  \n9. set pastetoggle=&lt;F9&gt;  \n10. 以后在插入模式下，只要按F9键就可以切换自动缩进。</code></pre><p>From <a href=\"https://www.iteye.com/blog/haoningabc-1907479\" target=\"_blank\" rel=\"noopener\">https://www.iteye.com/blog/haoningabc-1907479</a> </p>\n<p>================================================================================</p>\n"},{"title":"yum下载遇到XZ_5.1.2alpha问题","_content":"遇到如下问题：\n[root@localhost download]# yum -y install libopencv-dev\nThere was a problem importing one of the Python modules\nrequired to run yum. The error leading to this problem was:\n\n   /lib64/liblzma.so.5: version `XZ_5.1.2alpha' not found (required by /lib64/librpmio.so.3)\n\nPlease install a package which provides this module, or\nverify that the module is installed correctly.\n\nIt's possible that the above module doesn't match the\ncurrent version of Python, which is:\n2.7.5 (default, Jun 20 2019, 20:27:34)\n[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]\n\nIf you cannot solve this problem yourself, please go to\nthe yum faq at:\n  http://yum.baseurl.org/wiki/Faq\n[root@localhost download]#\n…\n\n解决方法：\n\n /lib64/liblzma.so.5: version `XZ_5.1.2alpha' not found (required by /lib64/librpmio.so.3)\n\t1. 下载安装 xz-5.2.2.tar.gz\n\t\t进入xz工具官网下载源码包：http://tukaani.org/xz/\n\t\t      下载版本：xz-5.2.2.tar.gz\n\ta. 下载之后，将压缩包解压 tar -vxf xz-5.2.2.tar.gz\n\t\n\t      b. 进入到xz源码目录 cd  xz-5.2.2.tar.gz\n\t\n\t      c. 配置 ./configure--enable-shared\n\t\n\t      d. 编译 make\n\t\n\t      e. 安装 makeinstall\n\t\n\t   如此，则系统安装了xz工具。\n\t   当然，如果用户自己希望安装到自己的特定路径下，可以在配置选项中，设定安装路径，如\n\t     ./configure --enable-shared --prefix=/opt/install/xz/bin\n\t\n\t     这样xz工具就被安装在/tmp/xz目录中，如果要导入到系统，则需要设置环境变量，编辑系统配置文件,\n\t\n\t     vi  /etc/bash.bashrc\n\t\n\t     在系统配置文件的末尾，加入路径：\n\t\n\t     export PATH=$PATH:/opt/install/xz/bin\n\t\n\t     export PATH\n\t\n\t     如果修改了环境变量，需要 \n\t\n\t      4.3 验证是否xz安装成功\n\t\n\t      在终端中，输入命令查看版本号：   xz -V\n\t      得到信息如下，则说明安装成功。\n\t      xz (XZ Utils) 5.2.2\n\t      liblzma 5.2.2\n\t\n\t2. 到/lib64/目录\n\tcp /lib64/liblzma.so.5.2.2 .\n\tsudo ln -s -f liblzma.so.5.2.2 liblzma.so.5\n\t就可以了\n\t\n\t\n","source":"_posts/linux/yum下载遇到XZ_5.1.2alpha问题.md","raw":"---\ntitle: yum下载遇到XZ_5.1.2alpha问题\ntags: \ncategories:\n- linux\n---\n遇到如下问题：\n[root@localhost download]# yum -y install libopencv-dev\nThere was a problem importing one of the Python modules\nrequired to run yum. The error leading to this problem was:\n\n   /lib64/liblzma.so.5: version `XZ_5.1.2alpha' not found (required by /lib64/librpmio.so.3)\n\nPlease install a package which provides this module, or\nverify that the module is installed correctly.\n\nIt's possible that the above module doesn't match the\ncurrent version of Python, which is:\n2.7.5 (default, Jun 20 2019, 20:27:34)\n[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]\n\nIf you cannot solve this problem yourself, please go to\nthe yum faq at:\n  http://yum.baseurl.org/wiki/Faq\n[root@localhost download]#\n…\n\n解决方法：\n\n /lib64/liblzma.so.5: version `XZ_5.1.2alpha' not found (required by /lib64/librpmio.so.3)\n\t1. 下载安装 xz-5.2.2.tar.gz\n\t\t进入xz工具官网下载源码包：http://tukaani.org/xz/\n\t\t      下载版本：xz-5.2.2.tar.gz\n\ta. 下载之后，将压缩包解压 tar -vxf xz-5.2.2.tar.gz\n\t\n\t      b. 进入到xz源码目录 cd  xz-5.2.2.tar.gz\n\t\n\t      c. 配置 ./configure--enable-shared\n\t\n\t      d. 编译 make\n\t\n\t      e. 安装 makeinstall\n\t\n\t   如此，则系统安装了xz工具。\n\t   当然，如果用户自己希望安装到自己的特定路径下，可以在配置选项中，设定安装路径，如\n\t     ./configure --enable-shared --prefix=/opt/install/xz/bin\n\t\n\t     这样xz工具就被安装在/tmp/xz目录中，如果要导入到系统，则需要设置环境变量，编辑系统配置文件,\n\t\n\t     vi  /etc/bash.bashrc\n\t\n\t     在系统配置文件的末尾，加入路径：\n\t\n\t     export PATH=$PATH:/opt/install/xz/bin\n\t\n\t     export PATH\n\t\n\t     如果修改了环境变量，需要 \n\t\n\t      4.3 验证是否xz安装成功\n\t\n\t      在终端中，输入命令查看版本号：   xz -V\n\t      得到信息如下，则说明安装成功。\n\t      xz (XZ Utils) 5.2.2\n\t      liblzma 5.2.2\n\t\n\t2. 到/lib64/目录\n\tcp /lib64/liblzma.so.5.2.2 .\n\tsudo ln -s -f liblzma.so.5.2.2 liblzma.so.5\n\t就可以了\n\t\n\t\n","slug":"linux/yum下载遇到XZ_5.1.2alpha问题","published":1,"date":"2020-08-12T16:05:46.553Z","updated":"2020-02-13T12:47:44.576Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfw003ghohx4n0fesgf","content":"<p>遇到如下问题：<br>[root@localhost download]# yum -y install libopencv-dev<br>There was a problem importing one of the Python modules<br>required to run yum. The error leading to this problem was:</p>\n<p>   /lib64/liblzma.so.5: version `XZ_5.1.2alpha’ not found (required by /lib64/librpmio.so.3)</p>\n<p>Please install a package which provides this module, or<br>verify that the module is installed correctly.</p>\n<p>It’s possible that the above module doesn’t match the<br>current version of Python, which is:<br>2.7.5 (default, Jun 20 2019, 20:27:34)<br>[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]</p>\n<p>If you cannot solve this problem yourself, please go to<br>the yum faq at:<br>  <a href=\"http://yum.baseurl.org/wiki/Faq\" target=\"_blank\" rel=\"noopener\">http://yum.baseurl.org/wiki/Faq</a><br>[root@localhost download]#<br>…</p>\n<p>解决方法：</p>\n<p> /lib64/liblzma.so.5: version `XZ_5.1.2alpha’ not found (required by /lib64/librpmio.so.3)<br>    1. 下载安装 xz-5.2.2.tar.gz<br>        进入xz工具官网下载源码包：<a href=\"http://tukaani.org/xz/\" target=\"_blank\" rel=\"noopener\">http://tukaani.org/xz/</a><br>              下载版本：xz-5.2.2.tar.gz<br>    a. 下载之后，将压缩包解压 tar -vxf xz-5.2.2.tar.gz</p>\n<pre><code>      b. 进入到xz源码目录 cd  xz-5.2.2.tar.gz\n\n      c. 配置 ./configure--enable-shared\n\n      d. 编译 make\n\n      e. 安装 makeinstall\n\n   如此，则系统安装了xz工具。\n   当然，如果用户自己希望安装到自己的特定路径下，可以在配置选项中，设定安装路径，如\n     ./configure --enable-shared --prefix=/opt/install/xz/bin\n\n     这样xz工具就被安装在/tmp/xz目录中，如果要导入到系统，则需要设置环境变量，编辑系统配置文件,\n\n     vi  /etc/bash.bashrc\n\n     在系统配置文件的末尾，加入路径：\n\n     export PATH=$PATH:/opt/install/xz/bin\n\n     export PATH\n\n     如果修改了环境变量，需要 \n\n      4.3 验证是否xz安装成功\n\n      在终端中，输入命令查看版本号：   xz -V\n      得到信息如下，则说明安装成功。\n      xz (XZ Utils) 5.2.2\n      liblzma 5.2.2\n\n2. 到/lib64/目录\ncp /lib64/liblzma.so.5.2.2 .\nsudo ln -s -f liblzma.so.5.2.2 liblzma.so.5\n就可以了</code></pre>","site":{"data":{}},"excerpt":"","more":"<p>遇到如下问题：<br>[root@localhost download]# yum -y install libopencv-dev<br>There was a problem importing one of the Python modules<br>required to run yum. The error leading to this problem was:</p>\n<p>   /lib64/liblzma.so.5: version `XZ_5.1.2alpha’ not found (required by /lib64/librpmio.so.3)</p>\n<p>Please install a package which provides this module, or<br>verify that the module is installed correctly.</p>\n<p>It’s possible that the above module doesn’t match the<br>current version of Python, which is:<br>2.7.5 (default, Jun 20 2019, 20:27:34)<br>[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]</p>\n<p>If you cannot solve this problem yourself, please go to<br>the yum faq at:<br>  <a href=\"http://yum.baseurl.org/wiki/Faq\" target=\"_blank\" rel=\"noopener\">http://yum.baseurl.org/wiki/Faq</a><br>[root@localhost download]#<br>…</p>\n<p>解决方法：</p>\n<p> /lib64/liblzma.so.5: version `XZ_5.1.2alpha’ not found (required by /lib64/librpmio.so.3)<br>    1. 下载安装 xz-5.2.2.tar.gz<br>        进入xz工具官网下载源码包：<a href=\"http://tukaani.org/xz/\" target=\"_blank\" rel=\"noopener\">http://tukaani.org/xz/</a><br>              下载版本：xz-5.2.2.tar.gz<br>    a. 下载之后，将压缩包解压 tar -vxf xz-5.2.2.tar.gz</p>\n<pre><code>      b. 进入到xz源码目录 cd  xz-5.2.2.tar.gz\n\n      c. 配置 ./configure--enable-shared\n\n      d. 编译 make\n\n      e. 安装 makeinstall\n\n   如此，则系统安装了xz工具。\n   当然，如果用户自己希望安装到自己的特定路径下，可以在配置选项中，设定安装路径，如\n     ./configure --enable-shared --prefix=/opt/install/xz/bin\n\n     这样xz工具就被安装在/tmp/xz目录中，如果要导入到系统，则需要设置环境变量，编辑系统配置文件,\n\n     vi  /etc/bash.bashrc\n\n     在系统配置文件的末尾，加入路径：\n\n     export PATH=$PATH:/opt/install/xz/bin\n\n     export PATH\n\n     如果修改了环境变量，需要 \n\n      4.3 验证是否xz安装成功\n\n      在终端中，输入命令查看版本号：   xz -V\n      得到信息如下，则说明安装成功。\n      xz (XZ Utils) 5.2.2\n      liblzma 5.2.2\n\n2. 到/lib64/目录\ncp /lib64/liblzma.so.5.2.2 .\nsudo ln -s -f liblzma.so.5.2.2 liblzma.so.5\n就可以了</code></pre>"},{"title":"yum使用和安装cmake 3 版本上","_content":"第一种安装cmake3\n$yum search cmake\n\t……\n\tcmake3.x86_64 : Cross-platform make system\n\t……\n\t\n$yum install cmake3.x86_64\n\t//但使用命令需用cmake3\n\t\n$cmake3 --version      //查看cmake版本\n\n$yum remove cmake3\n\n第二种:\n（1）移除旧版本：\nyum remove cmake\n（2）下载新版本\n1、下载：wget https://cmake.org/files/v3.6/cmake-3.6.0-Linux-x86_64.tar.gz\n2、解压：tar -zxvf cmake-3.6.0-Linux-x86_64.tar.gz\n注意：这个压缩包不是源码包，解压后直接用。\n3、增加环境变量，使其成为全局变量：\nvim /etc/profile  // 或者vim ~/.bashrc\n在文件末尾处增加以下代码\nexport PATH=$PATH:/lnmp/src/cmake-3.6.0-Linux-x86_64/bin\n注意：写自己刚安装cmake的bin的路径\n使修改的文件生效\nsource /etc/profile //或者 source ~/.bashrc\n4、查看环境变量：\necho $PATH\n5、检查cmake版本：\ncmake --version\n\n 扩展知识：\n百度百科的介绍：\nCMake是一个跨平台的安装（编译）工具，可以用简单的语句来描述所有平台的安装(编译过程)。\n他能够输出各种各样的makefile或者project文件，能测试编译器所支持的C++特性,类似UNIX下的automake。\n只是 CMake 的组态档取名为 CMakeLists.txt。Cmake 并不直接建构出最终的软件，而是产生标准的建构档\n（如 Unix 的 Makefile 或 Windows Visual C++ 的 projects/workspaces），然后再依一般的建构方式使用。\n这使得熟悉某个集成开发环境（IDE）的开发者可以用标准的方式建构他的软件，这种可以使用各平台的原生\n建构系统的能力是 CMake 和 SCons 等其他类似系统的区别之处。\n","source":"_posts/linux/yum使用和安装cmake-3版本上.md","raw":"---\ntitle: yum使用和安装cmake 3 版本上\ntags: \ncategories: \n- linux\n---\n第一种安装cmake3\n$yum search cmake\n\t……\n\tcmake3.x86_64 : Cross-platform make system\n\t……\n\t\n$yum install cmake3.x86_64\n\t//但使用命令需用cmake3\n\t\n$cmake3 --version      //查看cmake版本\n\n$yum remove cmake3\n\n第二种:\n（1）移除旧版本：\nyum remove cmake\n（2）下载新版本\n1、下载：wget https://cmake.org/files/v3.6/cmake-3.6.0-Linux-x86_64.tar.gz\n2、解压：tar -zxvf cmake-3.6.0-Linux-x86_64.tar.gz\n注意：这个压缩包不是源码包，解压后直接用。\n3、增加环境变量，使其成为全局变量：\nvim /etc/profile  // 或者vim ~/.bashrc\n在文件末尾处增加以下代码\nexport PATH=$PATH:/lnmp/src/cmake-3.6.0-Linux-x86_64/bin\n注意：写自己刚安装cmake的bin的路径\n使修改的文件生效\nsource /etc/profile //或者 source ~/.bashrc\n4、查看环境变量：\necho $PATH\n5、检查cmake版本：\ncmake --version\n\n 扩展知识：\n百度百科的介绍：\nCMake是一个跨平台的安装（编译）工具，可以用简单的语句来描述所有平台的安装(编译过程)。\n他能够输出各种各样的makefile或者project文件，能测试编译器所支持的C++特性,类似UNIX下的automake。\n只是 CMake 的组态档取名为 CMakeLists.txt。Cmake 并不直接建构出最终的软件，而是产生标准的建构档\n（如 Unix 的 Makefile 或 Windows Visual C++ 的 projects/workspaces），然后再依一般的建构方式使用。\n这使得熟悉某个集成开发环境（IDE）的开发者可以用标准的方式建构他的软件，这种可以使用各平台的原生\n建构系统的能力是 CMake 和 SCons 等其他类似系统的区别之处。\n","slug":"linux/yum使用和安装cmake-3版本上","published":1,"date":"2020-08-12T16:05:46.561Z","updated":"2020-02-13T12:47:44.581Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfx003ihohxhquvesbh","content":"<p>第一种安装cmake3<br>$yum search cmake<br>    ……<br>    cmake3.x86_64 : Cross-platform make system<br>    ……</p>\n<p>$yum install cmake3.x86_64<br>    //但使用命令需用cmake3</p>\n<p>$cmake3 –version      //查看cmake版本</p>\n<p>$yum remove cmake3</p>\n<p>第二种:<br>（1）移除旧版本：<br>yum remove cmake<br>（2）下载新版本<br>1、下载：wget <a href=\"https://cmake.org/files/v3.6/cmake-3.6.0-Linux-x86_64.tar.gz\" target=\"_blank\" rel=\"noopener\">https://cmake.org/files/v3.6/cmake-3.6.0-Linux-x86_64.tar.gz</a><br>2、解压：tar -zxvf cmake-3.6.0-Linux-x86_64.tar.gz<br>注意：这个压缩包不是源码包，解压后直接用。<br>3、增加环境变量，使其成为全局变量：<br>vim /etc/profile  // 或者vim ~/.bashrc<br>在文件末尾处增加以下代码<br>export PATH=$PATH:/lnmp/src/cmake-3.6.0-Linux-x86_64/bin<br>注意：写自己刚安装cmake的bin的路径<br>使修改的文件生效<br>source /etc/profile //或者 source ~/.bashrc<br>4、查看环境变量：<br>echo $PATH<br>5、检查cmake版本：<br>cmake –version</p>\n<p> 扩展知识：<br>百度百科的介绍：<br>CMake是一个跨平台的安装（编译）工具，可以用简单的语句来描述所有平台的安装(编译过程)。<br>他能够输出各种各样的makefile或者project文件，能测试编译器所支持的C++特性,类似UNIX下的automake。<br>只是 CMake 的组态档取名为 CMakeLists.txt。Cmake 并不直接建构出最终的软件，而是产生标准的建构档<br>（如 Unix 的 Makefile 或 Windows Visual C++ 的 projects/workspaces），然后再依一般的建构方式使用。<br>这使得熟悉某个集成开发环境（IDE）的开发者可以用标准的方式建构他的软件，这种可以使用各平台的原生<br>建构系统的能力是 CMake 和 SCons 等其他类似系统的区别之处。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>第一种安装cmake3<br>$yum search cmake<br>    ……<br>    cmake3.x86_64 : Cross-platform make system<br>    ……</p>\n<p>$yum install cmake3.x86_64<br>    //但使用命令需用cmake3</p>\n<p>$cmake3 –version      //查看cmake版本</p>\n<p>$yum remove cmake3</p>\n<p>第二种:<br>（1）移除旧版本：<br>yum remove cmake<br>（2）下载新版本<br>1、下载：wget <a href=\"https://cmake.org/files/v3.6/cmake-3.6.0-Linux-x86_64.tar.gz\" target=\"_blank\" rel=\"noopener\">https://cmake.org/files/v3.6/cmake-3.6.0-Linux-x86_64.tar.gz</a><br>2、解压：tar -zxvf cmake-3.6.0-Linux-x86_64.tar.gz<br>注意：这个压缩包不是源码包，解压后直接用。<br>3、增加环境变量，使其成为全局变量：<br>vim /etc/profile  // 或者vim ~/.bashrc<br>在文件末尾处增加以下代码<br>export PATH=$PATH:/lnmp/src/cmake-3.6.0-Linux-x86_64/bin<br>注意：写自己刚安装cmake的bin的路径<br>使修改的文件生效<br>source /etc/profile //或者 source ~/.bashrc<br>4、查看环境变量：<br>echo $PATH<br>5、检查cmake版本：<br>cmake –version</p>\n<p> 扩展知识：<br>百度百科的介绍：<br>CMake是一个跨平台的安装（编译）工具，可以用简单的语句来描述所有平台的安装(编译过程)。<br>他能够输出各种各样的makefile或者project文件，能测试编译器所支持的C++特性,类似UNIX下的automake。<br>只是 CMake 的组态档取名为 CMakeLists.txt。Cmake 并不直接建构出最终的软件，而是产生标准的建构档<br>（如 Unix 的 Makefile 或 Windows Visual C++ 的 projects/workspaces），然后再依一般的建构方式使用。<br>这使得熟悉某个集成开发环境（IDE）的开发者可以用标准的方式建构他的软件，这种可以使用各平台的原生<br>建构系统的能力是 CMake 和 SCons 等其他类似系统的区别之处。</p>\n"},{"title":"wget www.baidu.com","_content":"\nPing www.baidu.com 改为 ：wget www.baidu.com 来测试是否机器可以上网","source":"_posts/linux/wget_www.baidu.com.md","raw":"---\ntitle: wget www.baidu.com\ntags:\ncategories:\n- linux\n---\n\nPing www.baidu.com 改为 ：wget www.baidu.com 来测试是否机器可以上网","slug":"linux/wget_www.baidu.com","published":1,"date":"2020-08-12T16:05:46.521Z","updated":"2020-02-13T12:47:44.573Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfx003khohxgilshk8f","content":"<p>Ping <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a> 改为 ：wget <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a> 来测试是否机器可以上网</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Ping <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a> 改为 ：wget <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a> 来测试是否机器可以上网</p>\n"},{"title":"按字节/字寻址，字长，地址总线，数据总线关系","_content":"设一个1MB容量的存储器，字长为32位，问：\n\n1）按字节编址，地址寄存器和数据寄存器个几位？\n\n2）按字编址，地址寄存器和数据寄存器个几位？\n\n\n答案是：\n1）1MB=2^20×8 位，地址寄存器为20位，数据寄存器为8位\n\n2）1MB=2^18×32 位，地址寄存器为18位，数据寄存器为32位\n\n\n\n我的理解：\n字长是CPU一次处理数据也就是读取和写数据的长度(等于数据总线)，与按字编址(每个存储单元长度bit)是不同的概念\n按字节编址(寻址)每个存储单元8bit\n按字编址(32bit)每个存储单元32bit\n\n\t1. 按字节编址，字长需要出题人根据心情随意给出比如16位，则CPU一次读写32bit的数据，存储容量1MB\n\t\t存储容量1MB = 2^20*8bit = 2^19*16bit, 则地址总线19根，数据总线16根\n\t\t也就是地址寄存器19位，数据寄存器16位\n\t2. 按字节编址(8bit)，字长32bit\n\t\tCPU一次读写4个内存地址空间数据\n\t3. 按字编址(32bit)，字长32bit\n\t\tCPU一次读写1个内存地址空间数据\n\nCPU的地址总线是由其通用寄存器的地址总线决定\n我们生活中的笔记本电脑一般CPU通用寄存器的地址总线和数据总线都为32bit\n因为我们笔记本电脑内存4GB，字长32bit，一般(如果不指明默认情况下)都是按字节编址(寻址)\n\t1. 字长32bit因此确定数据总线为32根\n\t2. 4GB = 2^32*8bit, 因此地址总线32根\n\n\n如下图:\n![](address.png)\n\t\n地址00h直接跳到04h, 后缀h,前缀0x代表16进制，每一行32bit，说明：\n\t1. 字长32bit\n\t2. 按字节寻址\n\t因此CPU一次处理读写4个地址空间数据如地址00h~03h\n\n\n32位的处理器(CPU)强调的是数据总线的宽度，32位操作系统强调的是地址总线的宽度, 然后默认按字节寻址(8bit)则只能支持4GB大小内存, 地址总线确定最大可寻址内存范围.\n\n32位cpu，应该说清楚是cpu的地址总线位宽为32位的时候最大只能支持4G的寻址，所以只能支持4G。 如果这里的32位CPU指的是数据总线位宽就不能说明最大可以使用4G内存。 另外，还受制于操作系统的位数，如果操作系统是32位就意味着逻辑地址寻址范围在4G以内，这样就算是64位地址总线也无法使用4G以上的内存空间。\n\n百度百科里32位处理器和32位操作系统都和4G内存扯上了关系。说明32位处理器的地址总线宽度是32位，32位操作系统的地址总线宽度也是32位。\n\n\nCPU在执行指令时需要先将指令的逻辑地址变换为物理地址才能执行。\n\t地址总线数目\t最大支持内存\n32位系统\t32\t2的32次方 = 4G\n64位系统\t36或40\t2的36次方 = 64G 或 2的40次方= 1024G = 1T\n\n\n问题：\n• 自己装的是4G内存条，可是操作系统显示的内存却是3.75G\n• 自己装的是8G内存条，可是操作系统显示的内存也是3.75G\n在使用计算机时，其支持的最大内存是由操作系统和硬件两方面决定的。\n实际上用户在使用计算机时，进程访问到的地址都是逻辑地址，并不是真实的物理地址，逻辑地址是由操作系统提供的，并维护了逻辑地址和物理地址的映射\n对于32位的windows操作系统，提供的逻辑地址寻址范围是4G，但是对于这4G的逻辑地址，又要划分出来一份给CPU寄存器、ROM的这些物理地址进行映射，那么剩下和内存条的物理地址进行映射的空间肯定没有4G了,如下图所示:\n![](logical_physical.png)\n其实操作系统显示的内存3.75G，是逻辑地址。\n","source":"_posts/linux/按字节-字寻址_字长_地址总线_数据总线关系.md","raw":"---\ntitle: 按字节/字寻址，字长，地址总线，数据总线关系\ntags: \ncategories:\n- linux\n---\n设一个1MB容量的存储器，字长为32位，问：\n\n1）按字节编址，地址寄存器和数据寄存器个几位？\n\n2）按字编址，地址寄存器和数据寄存器个几位？\n\n\n答案是：\n1）1MB=2^20×8 位，地址寄存器为20位，数据寄存器为8位\n\n2）1MB=2^18×32 位，地址寄存器为18位，数据寄存器为32位\n\n\n\n我的理解：\n字长是CPU一次处理数据也就是读取和写数据的长度(等于数据总线)，与按字编址(每个存储单元长度bit)是不同的概念\n按字节编址(寻址)每个存储单元8bit\n按字编址(32bit)每个存储单元32bit\n\n\t1. 按字节编址，字长需要出题人根据心情随意给出比如16位，则CPU一次读写32bit的数据，存储容量1MB\n\t\t存储容量1MB = 2^20*8bit = 2^19*16bit, 则地址总线19根，数据总线16根\n\t\t也就是地址寄存器19位，数据寄存器16位\n\t2. 按字节编址(8bit)，字长32bit\n\t\tCPU一次读写4个内存地址空间数据\n\t3. 按字编址(32bit)，字长32bit\n\t\tCPU一次读写1个内存地址空间数据\n\nCPU的地址总线是由其通用寄存器的地址总线决定\n我们生活中的笔记本电脑一般CPU通用寄存器的地址总线和数据总线都为32bit\n因为我们笔记本电脑内存4GB，字长32bit，一般(如果不指明默认情况下)都是按字节编址(寻址)\n\t1. 字长32bit因此确定数据总线为32根\n\t2. 4GB = 2^32*8bit, 因此地址总线32根\n\n\n如下图:\n![](address.png)\n\t\n地址00h直接跳到04h, 后缀h,前缀0x代表16进制，每一行32bit，说明：\n\t1. 字长32bit\n\t2. 按字节寻址\n\t因此CPU一次处理读写4个地址空间数据如地址00h~03h\n\n\n32位的处理器(CPU)强调的是数据总线的宽度，32位操作系统强调的是地址总线的宽度, 然后默认按字节寻址(8bit)则只能支持4GB大小内存, 地址总线确定最大可寻址内存范围.\n\n32位cpu，应该说清楚是cpu的地址总线位宽为32位的时候最大只能支持4G的寻址，所以只能支持4G。 如果这里的32位CPU指的是数据总线位宽就不能说明最大可以使用4G内存。 另外，还受制于操作系统的位数，如果操作系统是32位就意味着逻辑地址寻址范围在4G以内，这样就算是64位地址总线也无法使用4G以上的内存空间。\n\n百度百科里32位处理器和32位操作系统都和4G内存扯上了关系。说明32位处理器的地址总线宽度是32位，32位操作系统的地址总线宽度也是32位。\n\n\nCPU在执行指令时需要先将指令的逻辑地址变换为物理地址才能执行。\n\t地址总线数目\t最大支持内存\n32位系统\t32\t2的32次方 = 4G\n64位系统\t36或40\t2的36次方 = 64G 或 2的40次方= 1024G = 1T\n\n\n问题：\n• 自己装的是4G内存条，可是操作系统显示的内存却是3.75G\n• 自己装的是8G内存条，可是操作系统显示的内存也是3.75G\n在使用计算机时，其支持的最大内存是由操作系统和硬件两方面决定的。\n实际上用户在使用计算机时，进程访问到的地址都是逻辑地址，并不是真实的物理地址，逻辑地址是由操作系统提供的，并维护了逻辑地址和物理地址的映射\n对于32位的windows操作系统，提供的逻辑地址寻址范围是4G，但是对于这4G的逻辑地址，又要划分出来一份给CPU寄存器、ROM的这些物理地址进行映射，那么剩下和内存条的物理地址进行映射的空间肯定没有4G了,如下图所示:\n![](logical_physical.png)\n其实操作系统显示的内存3.75G，是逻辑地址。\n","slug":"linux/按字节-字寻址_字长_地址总线_数据总线关系","published":1,"date":"2020-08-12T16:05:46.568Z","updated":"2020-02-13T12:47:44.584Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfy003nhohxeasngtzd","content":"<p>设一个1MB容量的存储器，字长为32位，问：</p>\n<p>1）按字节编址，地址寄存器和数据寄存器个几位？</p>\n<p>2）按字编址，地址寄存器和数据寄存器个几位？</p>\n<p>答案是：<br>1）1MB=2^20×8 位，地址寄存器为20位，数据寄存器为8位</p>\n<p>2）1MB=2^18×32 位，地址寄存器为18位，数据寄存器为32位</p>\n<p>我的理解：<br>字长是CPU一次处理数据也就是读取和写数据的长度(等于数据总线)，与按字编址(每个存储单元长度bit)是不同的概念<br>按字节编址(寻址)每个存储单元8bit<br>按字编址(32bit)每个存储单元32bit</p>\n<pre><code>1. 按字节编址，字长需要出题人根据心情随意给出比如16位，则CPU一次读写32bit的数据，存储容量1MB\n    存储容量1MB = 2^20*8bit = 2^19*16bit, 则地址总线19根，数据总线16根\n    也就是地址寄存器19位，数据寄存器16位\n2. 按字节编址(8bit)，字长32bit\n    CPU一次读写4个内存地址空间数据\n3. 按字编址(32bit)，字长32bit\n    CPU一次读写1个内存地址空间数据</code></pre><p>CPU的地址总线是由其通用寄存器的地址总线决定<br>我们生活中的笔记本电脑一般CPU通用寄存器的地址总线和数据总线都为32bit<br>因为我们笔记本电脑内存4GB，字长32bit，一般(如果不指明默认情况下)都是按字节编址(寻址)<br>    1. 字长32bit因此确定数据总线为32根<br>    2. 4GB = 2^32*8bit, 因此地址总线32根</p>\n<p>如下图:<br><img src=\"address.png\" alt=\"\"></p>\n<p>地址00h直接跳到04h, 后缀h,前缀0x代表16进制，每一行32bit，说明：<br>    1. 字长32bit<br>    2. 按字节寻址<br>    因此CPU一次处理读写4个地址空间数据如地址00h~03h</p>\n<p>32位的处理器(CPU)强调的是数据总线的宽度，32位操作系统强调的是地址总线的宽度, 然后默认按字节寻址(8bit)则只能支持4GB大小内存, 地址总线确定最大可寻址内存范围.</p>\n<p>32位cpu，应该说清楚是cpu的地址总线位宽为32位的时候最大只能支持4G的寻址，所以只能支持4G。 如果这里的32位CPU指的是数据总线位宽就不能说明最大可以使用4G内存。 另外，还受制于操作系统的位数，如果操作系统是32位就意味着逻辑地址寻址范围在4G以内，这样就算是64位地址总线也无法使用4G以上的内存空间。</p>\n<p>百度百科里32位处理器和32位操作系统都和4G内存扯上了关系。说明32位处理器的地址总线宽度是32位，32位操作系统的地址总线宽度也是32位。</p>\n<p>CPU在执行指令时需要先将指令的逻辑地址变换为物理地址才能执行。<br>    地址总线数目    最大支持内存<br>32位系统    32    2的32次方 = 4G<br>64位系统    36或40    2的36次方 = 64G 或 2的40次方= 1024G = 1T</p>\n<p>问题：<br>• 自己装的是4G内存条，可是操作系统显示的内存却是3.75G<br>• 自己装的是8G内存条，可是操作系统显示的内存也是3.75G<br>在使用计算机时，其支持的最大内存是由操作系统和硬件两方面决定的。<br>实际上用户在使用计算机时，进程访问到的地址都是逻辑地址，并不是真实的物理地址，逻辑地址是由操作系统提供的，并维护了逻辑地址和物理地址的映射<br>对于32位的windows操作系统，提供的逻辑地址寻址范围是4G，但是对于这4G的逻辑地址，又要划分出来一份给CPU寄存器、ROM的这些物理地址进行映射，那么剩下和内存条的物理地址进行映射的空间肯定没有4G了,如下图所示:<br><img src=\"logical_physical.png\" alt=\"\"><br>其实操作系统显示的内存3.75G，是逻辑地址。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>设一个1MB容量的存储器，字长为32位，问：</p>\n<p>1）按字节编址，地址寄存器和数据寄存器个几位？</p>\n<p>2）按字编址，地址寄存器和数据寄存器个几位？</p>\n<p>答案是：<br>1）1MB=2^20×8 位，地址寄存器为20位，数据寄存器为8位</p>\n<p>2）1MB=2^18×32 位，地址寄存器为18位，数据寄存器为32位</p>\n<p>我的理解：<br>字长是CPU一次处理数据也就是读取和写数据的长度(等于数据总线)，与按字编址(每个存储单元长度bit)是不同的概念<br>按字节编址(寻址)每个存储单元8bit<br>按字编址(32bit)每个存储单元32bit</p>\n<pre><code>1. 按字节编址，字长需要出题人根据心情随意给出比如16位，则CPU一次读写32bit的数据，存储容量1MB\n    存储容量1MB = 2^20*8bit = 2^19*16bit, 则地址总线19根，数据总线16根\n    也就是地址寄存器19位，数据寄存器16位\n2. 按字节编址(8bit)，字长32bit\n    CPU一次读写4个内存地址空间数据\n3. 按字编址(32bit)，字长32bit\n    CPU一次读写1个内存地址空间数据</code></pre><p>CPU的地址总线是由其通用寄存器的地址总线决定<br>我们生活中的笔记本电脑一般CPU通用寄存器的地址总线和数据总线都为32bit<br>因为我们笔记本电脑内存4GB，字长32bit，一般(如果不指明默认情况下)都是按字节编址(寻址)<br>    1. 字长32bit因此确定数据总线为32根<br>    2. 4GB = 2^32*8bit, 因此地址总线32根</p>\n<p>如下图:<br><img src=\"address.png\" alt=\"\"></p>\n<p>地址00h直接跳到04h, 后缀h,前缀0x代表16进制，每一行32bit，说明：<br>    1. 字长32bit<br>    2. 按字节寻址<br>    因此CPU一次处理读写4个地址空间数据如地址00h~03h</p>\n<p>32位的处理器(CPU)强调的是数据总线的宽度，32位操作系统强调的是地址总线的宽度, 然后默认按字节寻址(8bit)则只能支持4GB大小内存, 地址总线确定最大可寻址内存范围.</p>\n<p>32位cpu，应该说清楚是cpu的地址总线位宽为32位的时候最大只能支持4G的寻址，所以只能支持4G。 如果这里的32位CPU指的是数据总线位宽就不能说明最大可以使用4G内存。 另外，还受制于操作系统的位数，如果操作系统是32位就意味着逻辑地址寻址范围在4G以内，这样就算是64位地址总线也无法使用4G以上的内存空间。</p>\n<p>百度百科里32位处理器和32位操作系统都和4G内存扯上了关系。说明32位处理器的地址总线宽度是32位，32位操作系统的地址总线宽度也是32位。</p>\n<p>CPU在执行指令时需要先将指令的逻辑地址变换为物理地址才能执行。<br>    地址总线数目    最大支持内存<br>32位系统    32    2的32次方 = 4G<br>64位系统    36或40    2的36次方 = 64G 或 2的40次方= 1024G = 1T</p>\n<p>问题：<br>• 自己装的是4G内存条，可是操作系统显示的内存却是3.75G<br>• 自己装的是8G内存条，可是操作系统显示的内存也是3.75G<br>在使用计算机时，其支持的最大内存是由操作系统和硬件两方面决定的。<br>实际上用户在使用计算机时，进程访问到的地址都是逻辑地址，并不是真实的物理地址，逻辑地址是由操作系统提供的，并维护了逻辑地址和物理地址的映射<br>对于32位的windows操作系统，提供的逻辑地址寻址范围是4G，但是对于这4G的逻辑地址，又要划分出来一份给CPU寄存器、ROM的这些物理地址进行映射，那么剩下和内存条的物理地址进行映射的空间肯定没有4G了,如下图所示:<br><img src=\"logical_physical.png\" alt=\"\"><br>其实操作系统显示的内存3.75G，是逻辑地址。</p>\n"},{"title":"查看SSD","_content":"[root@wlp10 ~]# lsscsi -ls\n[6:0:0:0]    disk    ATA      INTEL SSDSC2BB48 0370  /dev/sda    480GB\n  state=running queue_depth=32 scsi_level=6 type=0 device_blocked=0 timeout=30\n[7:0:0:0]    disk    ATA      INTEL SSDSC2BB48 0101  /dev/sdb    480GB\n  state=running queue_depth=32 scsi_level=6 type=0 device_blocked=0 timeout=30\n[8:0:0:0]    disk    ATA      INTEL SSDSC2BB48 0370  /dev/sdc    480GB\n  state=running queue_depth=32 scsi_level=6 type=0 device_blocked=0 timeout=30\n[9:0:0:0]    disk    ATA      INTEL SSDSC2BG01 0015  /dev/sdd   1.20TB\n  state=running queue_depth=32 scsi_level=6 type=0 device_blocked=0 timeout=30\n[root@wlp10 ~]#\n看第四列就知道是否是SSD硬盘了\n\n\n[root@wlp10 ~]# lsscsi -h\nUsage: lsscsi   [--classic] [--device] [--generic] [--help] [--hosts]\n                [--kname] [--list] [--lunhex] [--long] [--protection]\n                [--scsi_id] [--size] [--sysfsroot=PATH] [--transport]\n                [--verbose] [--version] [--wwn] [<h:c:t:l>]\n  where:\n    --classic|-c      alternate output similar to 'cat /proc/scsi/scsi'\n    --device|-d       show device node's major + minor numbers\n    --generic|-g      show scsi generic device name\n    --help|-h         this usage information\n    --hosts|-H        lists scsi hosts rather than scsi devices\n    --kname|-k        show kernel name instead of device node name\n    --list|-L         additional information output one\n                      attribute=value per line\n    --long|-l         additional information output\n    --lunhex|-x       show LUN part of tuple as hex number in T10 format;\n                      use twice to get full 16 digit hexadecimal LUN\n    --protection|-p   show target and initiator protection information\n    --protmode|-P     show negotiated protection information mode\n    --scsi_id|-i      show udev derived /dev/disk/by-id/scsi* entry\n    --size|-s         show disk size\n    --sysfsroot=PATH|-y PATH    set sysfs mount point to PATH (def: /sys)\n    --transport|-t    transport information for target or, if '--hosts'\n                      given, for initiator\n    --verbose|-v      output path names where data is found\n    --version|-V      output version string and exit\n    --wwn|-w          output WWN for disks (from /dev/disk/by-id/wwn*)\n    <h:c:t:l>         filter output list (def: '*:*:*:*' (all))\n\nList SCSI devices or hosts, optionally with additional information\n[root@wlp10 ~]#\n\nFrom <https://www.cnblogs.com/laozhuang/p/7110438.html> \n","source":"_posts/linux/查看SSD.md","raw":"---\ntitle: 查看SSD\ntags:\ncategories:\n- linux\n---\n[root@wlp10 ~]# lsscsi -ls\n[6:0:0:0]    disk    ATA      INTEL SSDSC2BB48 0370  /dev/sda    480GB\n  state=running queue_depth=32 scsi_level=6 type=0 device_blocked=0 timeout=30\n[7:0:0:0]    disk    ATA      INTEL SSDSC2BB48 0101  /dev/sdb    480GB\n  state=running queue_depth=32 scsi_level=6 type=0 device_blocked=0 timeout=30\n[8:0:0:0]    disk    ATA      INTEL SSDSC2BB48 0370  /dev/sdc    480GB\n  state=running queue_depth=32 scsi_level=6 type=0 device_blocked=0 timeout=30\n[9:0:0:0]    disk    ATA      INTEL SSDSC2BG01 0015  /dev/sdd   1.20TB\n  state=running queue_depth=32 scsi_level=6 type=0 device_blocked=0 timeout=30\n[root@wlp10 ~]#\n看第四列就知道是否是SSD硬盘了\n\n\n[root@wlp10 ~]# lsscsi -h\nUsage: lsscsi   [--classic] [--device] [--generic] [--help] [--hosts]\n                [--kname] [--list] [--lunhex] [--long] [--protection]\n                [--scsi_id] [--size] [--sysfsroot=PATH] [--transport]\n                [--verbose] [--version] [--wwn] [<h:c:t:l>]\n  where:\n    --classic|-c      alternate output similar to 'cat /proc/scsi/scsi'\n    --device|-d       show device node's major + minor numbers\n    --generic|-g      show scsi generic device name\n    --help|-h         this usage information\n    --hosts|-H        lists scsi hosts rather than scsi devices\n    --kname|-k        show kernel name instead of device node name\n    --list|-L         additional information output one\n                      attribute=value per line\n    --long|-l         additional information output\n    --lunhex|-x       show LUN part of tuple as hex number in T10 format;\n                      use twice to get full 16 digit hexadecimal LUN\n    --protection|-p   show target and initiator protection information\n    --protmode|-P     show negotiated protection information mode\n    --scsi_id|-i      show udev derived /dev/disk/by-id/scsi* entry\n    --size|-s         show disk size\n    --sysfsroot=PATH|-y PATH    set sysfs mount point to PATH (def: /sys)\n    --transport|-t    transport information for target or, if '--hosts'\n                      given, for initiator\n    --verbose|-v      output path names where data is found\n    --version|-V      output version string and exit\n    --wwn|-w          output WWN for disks (from /dev/disk/by-id/wwn*)\n    <h:c:t:l>         filter output list (def: '*:*:*:*' (all))\n\nList SCSI devices or hosts, optionally with additional information\n[root@wlp10 ~]#\n\nFrom <https://www.cnblogs.com/laozhuang/p/7110438.html> \n","slug":"linux/查看SSD","published":1,"date":"2020-08-12T16:05:46.570Z","updated":"2020-02-13T12:47:44.605Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfz003phohxfv2pdhga","content":"<p>[root@wlp10 ~]# lsscsi -ls<br>[6:0:0:0]    disk    ATA      INTEL SSDSC2BB48 0370  /dev/sda    480GB<br>  state=running queue_depth=32 scsi_level=6 type=0 device_blocked=0 timeout=30<br>[7:0:0:0]    disk    ATA      INTEL SSDSC2BB48 0101  /dev/sdb    480GB<br>  state=running queue_depth=32 scsi_level=6 type=0 device_blocked=0 timeout=30<br>[8:0:0:0]    disk    ATA      INTEL SSDSC2BB48 0370  /dev/sdc    480GB<br>  state=running queue_depth=32 scsi_level=6 type=0 device_blocked=0 timeout=30<br>[9:0:0:0]    disk    ATA      INTEL SSDSC2BG01 0015  /dev/sdd   1.20TB<br>  state=running queue_depth=32 scsi_level=6 type=0 device_blocked=0 timeout=30<br>[root@wlp10 ~]#<br>看第四列就知道是否是SSD硬盘了</p>\n<p>[root@wlp10 ~]# lsscsi -h<br>Usage: lsscsi   [–classic] [–device] [–generic] [–help] [–hosts]<br>                [–kname] [–list] [–lunhex] [–long] [–protection]<br>                [–scsi_id] [–size] [–sysfsroot=PATH] [–transport]<br>                [–verbose] [–version] [–wwn] [&lt;h:c:t:l&gt;]<br>  where:<br>    –classic|-c      alternate output similar to ‘cat /proc/scsi/scsi’<br>    –device|-d       show device node’s major + minor numbers<br>    –generic|-g      show scsi generic device name<br>    –help|-h         this usage information<br>    –hosts|-H        lists scsi hosts rather than scsi devices<br>    –kname|-k        show kernel name instead of device node name<br>    –list|-L         additional information output one<br>                      attribute=value per line<br>    –long|-l         additional information output<br>    –lunhex|-x       show LUN part of tuple as hex number in T10 format;<br>                      use twice to get full 16 digit hexadecimal LUN<br>    –protection|-p   show target and initiator protection information<br>    –protmode|-P     show negotiated protection information mode<br>    –scsi_id|-i      show udev derived /dev/disk/by-id/scsi* entry<br>    –size|-s         show disk size<br>    –sysfsroot=PATH|-y PATH    set sysfs mount point to PATH (def: /sys)<br>    –transport|-t    transport information for target or, if ‘–hosts’<br>                      given, for initiator<br>    –verbose|-v      output path names where data is found<br>    –version|-V      output version string and exit<br>    –wwn|-w          output WWN for disks (from /dev/disk/by-id/wwn<em>)<br>    &lt;h:c:t:l&gt;         filter output list (def: ‘</em>:<em>:</em>:*’ (all))</p>\n<p>List SCSI devices or hosts, optionally with additional information<br>[root@wlp10 ~]#</p>\n<p>From <a href=\"https://www.cnblogs.com/laozhuang/p/7110438.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/laozhuang/p/7110438.html</a> </p>\n","site":{"data":{}},"excerpt":"","more":"<p>[root@wlp10 ~]# lsscsi -ls<br>[6:0:0:0]    disk    ATA      INTEL SSDSC2BB48 0370  /dev/sda    480GB<br>  state=running queue_depth=32 scsi_level=6 type=0 device_blocked=0 timeout=30<br>[7:0:0:0]    disk    ATA      INTEL SSDSC2BB48 0101  /dev/sdb    480GB<br>  state=running queue_depth=32 scsi_level=6 type=0 device_blocked=0 timeout=30<br>[8:0:0:0]    disk    ATA      INTEL SSDSC2BB48 0370  /dev/sdc    480GB<br>  state=running queue_depth=32 scsi_level=6 type=0 device_blocked=0 timeout=30<br>[9:0:0:0]    disk    ATA      INTEL SSDSC2BG01 0015  /dev/sdd   1.20TB<br>  state=running queue_depth=32 scsi_level=6 type=0 device_blocked=0 timeout=30<br>[root@wlp10 ~]#<br>看第四列就知道是否是SSD硬盘了</p>\n<p>[root@wlp10 ~]# lsscsi -h<br>Usage: lsscsi   [–classic] [–device] [–generic] [–help] [–hosts]<br>                [–kname] [–list] [–lunhex] [–long] [–protection]<br>                [–scsi_id] [–size] [–sysfsroot=PATH] [–transport]<br>                [–verbose] [–version] [–wwn] [&lt;h:c:t:l&gt;]<br>  where:<br>    –classic|-c      alternate output similar to ‘cat /proc/scsi/scsi’<br>    –device|-d       show device node’s major + minor numbers<br>    –generic|-g      show scsi generic device name<br>    –help|-h         this usage information<br>    –hosts|-H        lists scsi hosts rather than scsi devices<br>    –kname|-k        show kernel name instead of device node name<br>    –list|-L         additional information output one<br>                      attribute=value per line<br>    –long|-l         additional information output<br>    –lunhex|-x       show LUN part of tuple as hex number in T10 format;<br>                      use twice to get full 16 digit hexadecimal LUN<br>    –protection|-p   show target and initiator protection information<br>    –protmode|-P     show negotiated protection information mode<br>    –scsi_id|-i      show udev derived /dev/disk/by-id/scsi* entry<br>    –size|-s         show disk size<br>    –sysfsroot=PATH|-y PATH    set sysfs mount point to PATH (def: /sys)<br>    –transport|-t    transport information for target or, if ‘–hosts’<br>                      given, for initiator<br>    –verbose|-v      output path names where data is found<br>    –version|-V      output version string and exit<br>    –wwn|-w          output WWN for disks (from /dev/disk/by-id/wwn<em>)<br>    &lt;h:c:t:l&gt;         filter output list (def: ‘</em>:<em>:</em>:*’ (all))</p>\n<p>List SCSI devices or hosts, optionally with additional information<br>[root@wlp10 ~]#</p>\n<p>From <a href=\"https://www.cnblogs.com/laozhuang/p/7110438.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/laozhuang/p/7110438.html</a> </p>\n"},{"title":"用户态和内核共享内存----使用 /dev/mem & mmap","_content":"想法的来源是看到chinaunix上有人转载了wheelz的博客，但是wheelz的代码在我的实验平台上是不能正常工作的，可能是wheelz的代码太过久远，我试验的内核版本是：3.4.13。wheelz的源代码如下：\n// 内核模块\n#include <linux/config.h>\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/mm.h>\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Wheelz\");\nMODULE_DESCRIPTION(\"mmap demo\");\nstatic unsigned long p = 0;\nstatic int __init init(void)\n{\n        //分配共享内存（一个页面）\n        p = __get_free_pages(GFP_KERNEL, 0);\n        SetPageReserved(virt_to_page(p));\n        printk(\"<1> p = 0x%08x\\n\", p); \n    //p是内核中的虚拟地址  \n        //在共享内存中写上一个字符串\n        strcpy(p, \"Hello world!\\n\");\n        return 0;\n}\nstatic void __exit fini(void)\n{\n        ClearPageReserved(virt_to_page(p));\n        free_pages(p, 0);        \n}\nmodule_init(init);\nmodule_exit(fini);\n----------------------------------------------------------------------------------------------------------------------------------------\n// 用户态程序\n#include <sys/mman.h> \n#include <sys/types.h>\n#include <sys/stat.h>\n#include <fcntl.h> \n#include <stdio.h> \n#define PAGE_SIZE (4*1024)\n#define PAGE_OFFSET                0xc0000000\n#define KERNEL_VIRT_ADDR        0xc5e3c000\nint main() \n{ \n        char *buf; \n        int fd; \n        unsigned long phy_addr; \nfd=open(\"/dev/mem\",O_RDWR); \nif(fd == -1)\n                perror(\"open\");\n        phy_addr=KERNEL_VIRT_ADDR - PAGE_OFFSET; \n        //此处不太懂，不能理解物理地址phy_addr的计算方法\n        buf=mmap(0, PAGE_SIZE, \n                PROT_READ|PROT_WRITE, MAP_SHARED, \n                fd, phy_addr); \n        if(buf == MAP_FAILED)\n                perror(\"mmap\");\nputs(buf);//打印共享内存的内容\n        munmap(buf,PAGE_SIZE); \n        close(fd); \n        return 0; \n} \n在网上找了一些资料，导致这段代码不工作的原因可能有一下几个：\n（1）在编译内核时设置了CONFIG_STRICT_DEVMEM（某些版本中是CONFIG_NONPROMISC_DEVMEM），应该将此设置删除。\n（2）请求的地址没有通过内核中devmem_is_allowed函数对/dev/mem的保护。\n（3）物理地址phy_addr计算错误。（PS：wheelz的计算方法是怎么得到的？）\n \n我对上面的几个问题一一做了修改：\n（1）修改了.config文件\n# CONFIG_STRICT_DEVMEM is not set\n（２）重写arch/x86/mm/init.c下的devmem_is_allowed函数，这里我没有做太细致的修改，只是让函数一直返回1。当然这可能会存在一些问题。\n\n/*\n * devmem_is_allowed() checks to see if /dev/mem access to a certain address\n * is valid. The argument is a physical page number.\n *\n *\n * On x86, access has to be given to the first megabyte of ram because that area\n * contains bios code and data regions used by X and dosemu and similar apps.\n * Access has to be given to non-kernel-ram areas as well, these contain the PCI\n * mmio resources as well as potential bios/acpi data regions.\n */\nint devmem_is_allowed(unsigned long pagenr)\n{\nreturn 1;\n        if (pagenr <= 256)\n                return 1;\n        if (iomem_is_exclusive(pagenr << PAGE_SHIFT))\n                return 0;\n        if (!page_is_ram(pagenr))\n                return 1;\n        return 0;\n}\n（3）修改物理地址的计算，这里我们直接使用内核中提供的转换函数virt_to_phy()或者__pa()。\n\n// 内核模块\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/mm.h>\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"godjesse\");\nMODULE_DESCRIPTION(\"mmap demo\");\nstatic unsigned long p = 0;\nstatic unsigned long pp = 0;\nstatic int __init init(void)\n{\n        p = __get_free_pages(GFP_KERNEL, 0);\nif(!p)\n        {\n                printk(\"Allocate memory failure!/n\");\n        }\n        else\n        {\n                SetPageReserved(virt_to_page(p));\n// 使用virt_to_phys计算物理地址，供用户态程序使用\n                pp = (unsigned long)virt_to_phys((void *)p);\n                printk(\"<1> page : pp = 0x%lx\\n\",pp);\n        }\n        strcpy((char *)p, \"Hello world !\\n\");\n        return 0;\n}\nstatic void __exit fini(void)\n{\nprintk(\"The content written by user is: %s/n\", (unsigned char *)p);\n        ClearPageReserved(virt_to_page(p));\n        free_pages(p, 0);\n        printk(\" exit \\n\");\n}\nmodule_init(init);\nmodule_exit(fini);\n---------------------------------------------------------------------------------------------------------------------------------------\n// 用户态程序\n#include <sys/mman.h>\n#include <sys/types.h>\n#include <sys/stat.h>\n#include <fcntl.h>\n#include <stdio.h>\n#include <string.h>\n//hard coding read after the module installed\n#define KERNEL_PHY_ADDR  0x3737c000\nint main()\n{\nchar *buf;\n        int fd;\n        unsigned long phy_addr;\n        int  pagesize = getpagesize();\nphy_addr=KERNEL_PHY_ADDR;\nfd=open(\"/dev/mem\",O_RDWR);\nif(fd == -1)\n                perror(\"open\");\nbuf=mmap(0, pagesize, PROT_READ|PROT_WRITE, MAP_SHARED, fd, phy_addr);\nif(buf == MAP_FAILED)\n        {\n                perror(\"mmap\");\n        }\nprintf(\"buf : %s\\n\",buf);\n// test the write \n        buf[0] = 'X';\nmunmap(buf,pagesize);\n        close(fd);\n        return 0;\n}\n\n 经过这些修改后，demo可以正常工作。\n上文中提到修改devmem_is_allowed实际上是存在问题的，存在其他一些较为优雅的方法，如某牛人写的博客：bypassing devmem_is_allowed with kernel probes，博客链接：\nhttp://www.libcrack.so/2012/09/02/bypassing-devmem_is_allowed-with-kprobes/\n相关资料：\nhttp://stackoverflow.com/questions/11891979/accessing-mmaped-dev-mem \n\nFrom <https://www.cnblogs.com/godjesse/archive/2012/11/23/2784093.html> \n","source":"_posts/linux/用户态和内核共享内存-使用dev_mem&mmap.md","raw":"---\ntitle: 用户态和内核共享内存----使用 /dev/mem & mmap\ntags: \ncategories:\n- linux\n---\n想法的来源是看到chinaunix上有人转载了wheelz的博客，但是wheelz的代码在我的实验平台上是不能正常工作的，可能是wheelz的代码太过久远，我试验的内核版本是：3.4.13。wheelz的源代码如下：\n// 内核模块\n#include <linux/config.h>\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/mm.h>\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Wheelz\");\nMODULE_DESCRIPTION(\"mmap demo\");\nstatic unsigned long p = 0;\nstatic int __init init(void)\n{\n        //分配共享内存（一个页面）\n        p = __get_free_pages(GFP_KERNEL, 0);\n        SetPageReserved(virt_to_page(p));\n        printk(\"<1> p = 0x%08x\\n\", p); \n    //p是内核中的虚拟地址  \n        //在共享内存中写上一个字符串\n        strcpy(p, \"Hello world!\\n\");\n        return 0;\n}\nstatic void __exit fini(void)\n{\n        ClearPageReserved(virt_to_page(p));\n        free_pages(p, 0);        \n}\nmodule_init(init);\nmodule_exit(fini);\n----------------------------------------------------------------------------------------------------------------------------------------\n// 用户态程序\n#include <sys/mman.h> \n#include <sys/types.h>\n#include <sys/stat.h>\n#include <fcntl.h> \n#include <stdio.h> \n#define PAGE_SIZE (4*1024)\n#define PAGE_OFFSET                0xc0000000\n#define KERNEL_VIRT_ADDR        0xc5e3c000\nint main() \n{ \n        char *buf; \n        int fd; \n        unsigned long phy_addr; \nfd=open(\"/dev/mem\",O_RDWR); \nif(fd == -1)\n                perror(\"open\");\n        phy_addr=KERNEL_VIRT_ADDR - PAGE_OFFSET; \n        //此处不太懂，不能理解物理地址phy_addr的计算方法\n        buf=mmap(0, PAGE_SIZE, \n                PROT_READ|PROT_WRITE, MAP_SHARED, \n                fd, phy_addr); \n        if(buf == MAP_FAILED)\n                perror(\"mmap\");\nputs(buf);//打印共享内存的内容\n        munmap(buf,PAGE_SIZE); \n        close(fd); \n        return 0; \n} \n在网上找了一些资料，导致这段代码不工作的原因可能有一下几个：\n（1）在编译内核时设置了CONFIG_STRICT_DEVMEM（某些版本中是CONFIG_NONPROMISC_DEVMEM），应该将此设置删除。\n（2）请求的地址没有通过内核中devmem_is_allowed函数对/dev/mem的保护。\n（3）物理地址phy_addr计算错误。（PS：wheelz的计算方法是怎么得到的？）\n \n我对上面的几个问题一一做了修改：\n（1）修改了.config文件\n# CONFIG_STRICT_DEVMEM is not set\n（２）重写arch/x86/mm/init.c下的devmem_is_allowed函数，这里我没有做太细致的修改，只是让函数一直返回1。当然这可能会存在一些问题。\n\n/*\n * devmem_is_allowed() checks to see if /dev/mem access to a certain address\n * is valid. The argument is a physical page number.\n *\n *\n * On x86, access has to be given to the first megabyte of ram because that area\n * contains bios code and data regions used by X and dosemu and similar apps.\n * Access has to be given to non-kernel-ram areas as well, these contain the PCI\n * mmio resources as well as potential bios/acpi data regions.\n */\nint devmem_is_allowed(unsigned long pagenr)\n{\nreturn 1;\n        if (pagenr <= 256)\n                return 1;\n        if (iomem_is_exclusive(pagenr << PAGE_SHIFT))\n                return 0;\n        if (!page_is_ram(pagenr))\n                return 1;\n        return 0;\n}\n（3）修改物理地址的计算，这里我们直接使用内核中提供的转换函数virt_to_phy()或者__pa()。\n\n// 内核模块\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/mm.h>\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"godjesse\");\nMODULE_DESCRIPTION(\"mmap demo\");\nstatic unsigned long p = 0;\nstatic unsigned long pp = 0;\nstatic int __init init(void)\n{\n        p = __get_free_pages(GFP_KERNEL, 0);\nif(!p)\n        {\n                printk(\"Allocate memory failure!/n\");\n        }\n        else\n        {\n                SetPageReserved(virt_to_page(p));\n// 使用virt_to_phys计算物理地址，供用户态程序使用\n                pp = (unsigned long)virt_to_phys((void *)p);\n                printk(\"<1> page : pp = 0x%lx\\n\",pp);\n        }\n        strcpy((char *)p, \"Hello world !\\n\");\n        return 0;\n}\nstatic void __exit fini(void)\n{\nprintk(\"The content written by user is: %s/n\", (unsigned char *)p);\n        ClearPageReserved(virt_to_page(p));\n        free_pages(p, 0);\n        printk(\" exit \\n\");\n}\nmodule_init(init);\nmodule_exit(fini);\n---------------------------------------------------------------------------------------------------------------------------------------\n// 用户态程序\n#include <sys/mman.h>\n#include <sys/types.h>\n#include <sys/stat.h>\n#include <fcntl.h>\n#include <stdio.h>\n#include <string.h>\n//hard coding read after the module installed\n#define KERNEL_PHY_ADDR  0x3737c000\nint main()\n{\nchar *buf;\n        int fd;\n        unsigned long phy_addr;\n        int  pagesize = getpagesize();\nphy_addr=KERNEL_PHY_ADDR;\nfd=open(\"/dev/mem\",O_RDWR);\nif(fd == -1)\n                perror(\"open\");\nbuf=mmap(0, pagesize, PROT_READ|PROT_WRITE, MAP_SHARED, fd, phy_addr);\nif(buf == MAP_FAILED)\n        {\n                perror(\"mmap\");\n        }\nprintf(\"buf : %s\\n\",buf);\n// test the write \n        buf[0] = 'X';\nmunmap(buf,pagesize);\n        close(fd);\n        return 0;\n}\n\n 经过这些修改后，demo可以正常工作。\n上文中提到修改devmem_is_allowed实际上是存在问题的，存在其他一些较为优雅的方法，如某牛人写的博客：bypassing devmem_is_allowed with kernel probes，博客链接：\nhttp://www.libcrack.so/2012/09/02/bypassing-devmem_is_allowed-with-kprobes/\n相关资料：\nhttp://stackoverflow.com/questions/11891979/accessing-mmaped-dev-mem \n\nFrom <https://www.cnblogs.com/godjesse/archive/2012/11/23/2784093.html> \n","slug":"linux/用户态和内核共享内存-使用dev_mem&mmap","published":1,"date":"2020-08-12T16:05:46.575Z","updated":"2020-02-13T12:47:44.609Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmfz003rhohxepb8fwh2","content":"<p>想法的来源是看到chinaunix上有人转载了wheelz的博客，但是wheelz的代码在我的实验平台上是不能正常工作的，可能是wheelz的代码太过久远，我试验的内核版本是：3.4.13。wheelz的源代码如下：<br>// 内核模块<br>#include &lt;linux/config.h&gt;<br>#include &lt;linux/module.h&gt;<br>#include &lt;linux/kernel.h&gt;<br>#include &lt;linux/mm.h&gt;<br>MODULE_LICENSE(“GPL”);<br>MODULE_AUTHOR(“Wheelz”);<br>MODULE_DESCRIPTION(“mmap demo”);<br>static unsigned long p = 0;<br>static int __init init(void)<br>{<br>        //分配共享内存（一个页面）<br>        p = __get_free_pages(GFP_KERNEL, 0);<br>        SetPageReserved(virt_to_page(p));<br>        printk(“&lt;1&gt; p = 0x%08x\\n”, p);<br>    //p是内核中的虚拟地址<br>        //在共享内存中写上一个字符串<br>        strcpy(p, “Hello world!\\n”);<br>        return 0;<br>}<br>static void __exit fini(void)<br>{<br>        ClearPageReserved(virt_to_page(p));<br>        free_pages(p, 0);<br>}<br>module_init(init);<br>module_exit(fini);</p>\n<hr>\n<p>// 用户态程序<br>#include &lt;sys/mman.h&gt;<br>#include &lt;sys/types.h&gt;<br>#include &lt;sys/stat.h&gt;<br>#include &lt;fcntl.h&gt;<br>#include &lt;stdio.h&gt;<br>#define PAGE_SIZE (4*1024)<br>#define PAGE_OFFSET                0xc0000000<br>#define KERNEL_VIRT_ADDR        0xc5e3c000<br>int main()<br>{<br>        char *buf;<br>        int fd;<br>        unsigned long phy_addr;<br>fd=open(“/dev/mem”,O_RDWR);<br>if(fd == -1)<br>                perror(“open”);<br>        phy_addr=KERNEL_VIRT_ADDR - PAGE_OFFSET;<br>        //此处不太懂，不能理解物理地址phy_addr的计算方法<br>        buf=mmap(0, PAGE_SIZE,<br>                PROT_READ|PROT_WRITE, MAP_SHARED,<br>                fd, phy_addr);<br>        if(buf == MAP_FAILED)<br>                perror(“mmap”);<br>puts(buf);//打印共享内存的内容<br>        munmap(buf,PAGE_SIZE);<br>        close(fd);<br>        return 0;<br>}<br>在网上找了一些资料，导致这段代码不工作的原因可能有一下几个：<br>（1）在编译内核时设置了CONFIG_STRICT_DEVMEM（某些版本中是CONFIG_NONPROMISC_DEVMEM），应该将此设置删除。<br>（2）请求的地址没有通过内核中devmem_is_allowed函数对/dev/mem的保护。<br>（3）物理地址phy_addr计算错误。（PS：wheelz的计算方法是怎么得到的？）</p>\n<p>我对上面的几个问题一一做了修改：<br>（1）修改了.config文件</p>\n<h1 id=\"CONFIG-STRICT-DEVMEM-is-not-set\"><a href=\"#CONFIG-STRICT-DEVMEM-is-not-set\" class=\"headerlink\" title=\"CONFIG_STRICT_DEVMEM is not set\"></a>CONFIG_STRICT_DEVMEM is not set</h1><p>（２）重写arch/x86/mm/init.c下的devmem_is_allowed函数，这里我没有做太细致的修改，只是让函数一直返回1。当然这可能会存在一些问题。</p>\n<p>/*</p>\n<ul>\n<li>devmem_is_allowed() checks to see if /dev/mem access to a certain address</li>\n<li>is valid. The argument is a physical page number.</li>\n<li></li>\n<li></li>\n<li>On x86, access has to be given to the first megabyte of ram because that area</li>\n<li>contains bios code and data regions used by X and dosemu and similar apps.</li>\n<li>Access has to be given to non-kernel-ram areas as well, these contain the PCI</li>\n<li>mmio resources as well as potential bios/acpi data regions.</li>\n<li>/<br>int devmem_is_allowed(unsigned long pagenr)<br>{<br>return 1;<pre><code>if (pagenr &lt;= 256)\n        return 1;\nif (iomem_is_exclusive(pagenr &lt;&lt; PAGE_SHIFT))\n        return 0;\nif (!page_is_ram(pagenr))\n        return 1;\nreturn 0;</code></pre>}<br>（3）修改物理地址的计算，这里我们直接使用内核中提供的转换函数virt_to_phy()或者__pa()。</li>\n</ul>\n<p>// 内核模块<br>#include &lt;linux/module.h&gt;<br>#include &lt;linux/kernel.h&gt;<br>#include &lt;linux/mm.h&gt;<br>MODULE_LICENSE(“GPL”);<br>MODULE_AUTHOR(“godjesse”);<br>MODULE_DESCRIPTION(“mmap demo”);<br>static unsigned long p = 0;<br>static unsigned long pp = 0;<br>static int __init init(void)<br>{<br>        p = __get_free_pages(GFP_KERNEL, 0);<br>if(!p)<br>        {<br>                printk(“Allocate memory failure!/n”);<br>        }<br>        else<br>        {<br>                SetPageReserved(virt_to_page(p));<br>// 使用virt_to_phys计算物理地址，供用户态程序使用<br>                pp = (unsigned long)virt_to_phys((void *)p);<br>                printk(“&lt;1&gt; page : pp = 0x%lx\\n”,pp);<br>        }<br>        strcpy((char *)p, “Hello world !\\n”);<br>        return 0;<br>}<br>static void __exit fini(void)<br>{<br>printk(“The content written by user is: %s/n”, (unsigned char *)p);<br>        ClearPageReserved(virt_to_page(p));<br>        free_pages(p, 0);<br>        printk(“ exit \\n”);<br>}<br>module_init(init);<br>module_exit(fini);</p>\n<hr>\n<p>// 用户态程序<br>#include &lt;sys/mman.h&gt;<br>#include &lt;sys/types.h&gt;<br>#include &lt;sys/stat.h&gt;<br>#include &lt;fcntl.h&gt;<br>#include &lt;stdio.h&gt;<br>#include &lt;string.h&gt;<br>//hard coding read after the module installed<br>#define KERNEL_PHY_ADDR  0x3737c000<br>int main()<br>{<br>char *buf;<br>        int fd;<br>        unsigned long phy_addr;<br>        int  pagesize = getpagesize();<br>phy_addr=KERNEL_PHY_ADDR;<br>fd=open(“/dev/mem”,O_RDWR);<br>if(fd == -1)<br>                perror(“open”);<br>buf=mmap(0, pagesize, PROT_READ|PROT_WRITE, MAP_SHARED, fd, phy_addr);<br>if(buf == MAP_FAILED)<br>        {<br>                perror(“mmap”);<br>        }<br>printf(“buf : %s\\n”,buf);<br>// test the write<br>        buf[0] = ‘X’;<br>munmap(buf,pagesize);<br>        close(fd);<br>        return 0;<br>}</p>\n<p> 经过这些修改后，demo可以正常工作。<br>上文中提到修改devmem_is_allowed实际上是存在问题的，存在其他一些较为优雅的方法，如某牛人写的博客：bypassing devmem_is_allowed with kernel probes，博客链接：<br><a href=\"http://www.libcrack.so/2012/09/02/bypassing-devmem_is_allowed-with-kprobes/\" target=\"_blank\" rel=\"noopener\">http://www.libcrack.so/2012/09/02/bypassing-devmem_is_allowed-with-kprobes/</a><br>相关资料：<br><a href=\"http://stackoverflow.com/questions/11891979/accessing-mmaped-dev-mem\" target=\"_blank\" rel=\"noopener\">http://stackoverflow.com/questions/11891979/accessing-mmaped-dev-mem</a> </p>\n<p>From <a href=\"https://www.cnblogs.com/godjesse/archive/2012/11/23/2784093.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/godjesse/archive/2012/11/23/2784093.html</a> </p>\n","site":{"data":{}},"excerpt":"","more":"<p>想法的来源是看到chinaunix上有人转载了wheelz的博客，但是wheelz的代码在我的实验平台上是不能正常工作的，可能是wheelz的代码太过久远，我试验的内核版本是：3.4.13。wheelz的源代码如下：<br>// 内核模块<br>#include &lt;linux/config.h&gt;<br>#include &lt;linux/module.h&gt;<br>#include &lt;linux/kernel.h&gt;<br>#include &lt;linux/mm.h&gt;<br>MODULE_LICENSE(“GPL”);<br>MODULE_AUTHOR(“Wheelz”);<br>MODULE_DESCRIPTION(“mmap demo”);<br>static unsigned long p = 0;<br>static int __init init(void)<br>{<br>        //分配共享内存（一个页面）<br>        p = __get_free_pages(GFP_KERNEL, 0);<br>        SetPageReserved(virt_to_page(p));<br>        printk(“&lt;1&gt; p = 0x%08x\\n”, p);<br>    //p是内核中的虚拟地址<br>        //在共享内存中写上一个字符串<br>        strcpy(p, “Hello world!\\n”);<br>        return 0;<br>}<br>static void __exit fini(void)<br>{<br>        ClearPageReserved(virt_to_page(p));<br>        free_pages(p, 0);<br>}<br>module_init(init);<br>module_exit(fini);</p>\n<hr>\n<p>// 用户态程序<br>#include &lt;sys/mman.h&gt;<br>#include &lt;sys/types.h&gt;<br>#include &lt;sys/stat.h&gt;<br>#include &lt;fcntl.h&gt;<br>#include &lt;stdio.h&gt;<br>#define PAGE_SIZE (4*1024)<br>#define PAGE_OFFSET                0xc0000000<br>#define KERNEL_VIRT_ADDR        0xc5e3c000<br>int main()<br>{<br>        char *buf;<br>        int fd;<br>        unsigned long phy_addr;<br>fd=open(“/dev/mem”,O_RDWR);<br>if(fd == -1)<br>                perror(“open”);<br>        phy_addr=KERNEL_VIRT_ADDR - PAGE_OFFSET;<br>        //此处不太懂，不能理解物理地址phy_addr的计算方法<br>        buf=mmap(0, PAGE_SIZE,<br>                PROT_READ|PROT_WRITE, MAP_SHARED,<br>                fd, phy_addr);<br>        if(buf == MAP_FAILED)<br>                perror(“mmap”);<br>puts(buf);//打印共享内存的内容<br>        munmap(buf,PAGE_SIZE);<br>        close(fd);<br>        return 0;<br>}<br>在网上找了一些资料，导致这段代码不工作的原因可能有一下几个：<br>（1）在编译内核时设置了CONFIG_STRICT_DEVMEM（某些版本中是CONFIG_NONPROMISC_DEVMEM），应该将此设置删除。<br>（2）请求的地址没有通过内核中devmem_is_allowed函数对/dev/mem的保护。<br>（3）物理地址phy_addr计算错误。（PS：wheelz的计算方法是怎么得到的？）</p>\n<p>我对上面的几个问题一一做了修改：<br>（1）修改了.config文件</p>\n<h1 id=\"CONFIG-STRICT-DEVMEM-is-not-set\"><a href=\"#CONFIG-STRICT-DEVMEM-is-not-set\" class=\"headerlink\" title=\"CONFIG_STRICT_DEVMEM is not set\"></a>CONFIG_STRICT_DEVMEM is not set</h1><p>（２）重写arch/x86/mm/init.c下的devmem_is_allowed函数，这里我没有做太细致的修改，只是让函数一直返回1。当然这可能会存在一些问题。</p>\n<p>/*</p>\n<ul>\n<li>devmem_is_allowed() checks to see if /dev/mem access to a certain address</li>\n<li>is valid. The argument is a physical page number.</li>\n<li></li>\n<li></li>\n<li>On x86, access has to be given to the first megabyte of ram because that area</li>\n<li>contains bios code and data regions used by X and dosemu and similar apps.</li>\n<li>Access has to be given to non-kernel-ram areas as well, these contain the PCI</li>\n<li>mmio resources as well as potential bios/acpi data regions.</li>\n<li>/<br>int devmem_is_allowed(unsigned long pagenr)<br>{<br>return 1;<pre><code>if (pagenr &lt;= 256)\n        return 1;\nif (iomem_is_exclusive(pagenr &lt;&lt; PAGE_SHIFT))\n        return 0;\nif (!page_is_ram(pagenr))\n        return 1;\nreturn 0;</code></pre>}<br>（3）修改物理地址的计算，这里我们直接使用内核中提供的转换函数virt_to_phy()或者__pa()。</li>\n</ul>\n<p>// 内核模块<br>#include &lt;linux/module.h&gt;<br>#include &lt;linux/kernel.h&gt;<br>#include &lt;linux/mm.h&gt;<br>MODULE_LICENSE(“GPL”);<br>MODULE_AUTHOR(“godjesse”);<br>MODULE_DESCRIPTION(“mmap demo”);<br>static unsigned long p = 0;<br>static unsigned long pp = 0;<br>static int __init init(void)<br>{<br>        p = __get_free_pages(GFP_KERNEL, 0);<br>if(!p)<br>        {<br>                printk(“Allocate memory failure!/n”);<br>        }<br>        else<br>        {<br>                SetPageReserved(virt_to_page(p));<br>// 使用virt_to_phys计算物理地址，供用户态程序使用<br>                pp = (unsigned long)virt_to_phys((void *)p);<br>                printk(“&lt;1&gt; page : pp = 0x%lx\\n”,pp);<br>        }<br>        strcpy((char *)p, “Hello world !\\n”);<br>        return 0;<br>}<br>static void __exit fini(void)<br>{<br>printk(“The content written by user is: %s/n”, (unsigned char *)p);<br>        ClearPageReserved(virt_to_page(p));<br>        free_pages(p, 0);<br>        printk(“ exit \\n”);<br>}<br>module_init(init);<br>module_exit(fini);</p>\n<hr>\n<p>// 用户态程序<br>#include &lt;sys/mman.h&gt;<br>#include &lt;sys/types.h&gt;<br>#include &lt;sys/stat.h&gt;<br>#include &lt;fcntl.h&gt;<br>#include &lt;stdio.h&gt;<br>#include &lt;string.h&gt;<br>//hard coding read after the module installed<br>#define KERNEL_PHY_ADDR  0x3737c000<br>int main()<br>{<br>char *buf;<br>        int fd;<br>        unsigned long phy_addr;<br>        int  pagesize = getpagesize();<br>phy_addr=KERNEL_PHY_ADDR;<br>fd=open(“/dev/mem”,O_RDWR);<br>if(fd == -1)<br>                perror(“open”);<br>buf=mmap(0, pagesize, PROT_READ|PROT_WRITE, MAP_SHARED, fd, phy_addr);<br>if(buf == MAP_FAILED)<br>        {<br>                perror(“mmap”);<br>        }<br>printf(“buf : %s\\n”,buf);<br>// test the write<br>        buf[0] = ‘X’;<br>munmap(buf,pagesize);<br>        close(fd);<br>        return 0;<br>}</p>\n<p> 经过这些修改后，demo可以正常工作。<br>上文中提到修改devmem_is_allowed实际上是存在问题的，存在其他一些较为优雅的方法，如某牛人写的博客：bypassing devmem_is_allowed with kernel probes，博客链接：<br><a href=\"http://www.libcrack.so/2012/09/02/bypassing-devmem_is_allowed-with-kprobes/\" target=\"_blank\" rel=\"noopener\">http://www.libcrack.so/2012/09/02/bypassing-devmem_is_allowed-with-kprobes/</a><br>相关资料：<br><a href=\"http://stackoverflow.com/questions/11891979/accessing-mmaped-dev-mem\" target=\"_blank\" rel=\"noopener\">http://stackoverflow.com/questions/11891979/accessing-mmaped-dev-mem</a> </p>\n<p>From <a href=\"https://www.cnblogs.com/godjesse/archive/2012/11/23/2784093.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/godjesse/archive/2012/11/23/2784093.html</a> </p>\n"},{"title":"硬盘存储空间单位GB","_content":"信息技术的存储设备常用B、KB、MB、GB等作为存储设备的单位,例如,我们常说的某计算机的硬盘容量是320GB,某移动硬盘的容量是80GB,某个文件夹的大小是156KB等,其中1GB=210MB,1MB=210KB,1KB=210B(字节),对于一个容量为8GB的内存盘,其容量为____B(字节).\n![](unit_GB.gif)\n\nFrom <http://www.manfen5.com/stinfo/CZ_SX/SYS201808030701323019115696/> \n","source":"_posts/linux/硬盘存储空间单位GB.md","raw":"---\ntitle: 硬盘存储空间单位GB\ntags: \ncategories:\n- linux\n---\n信息技术的存储设备常用B、KB、MB、GB等作为存储设备的单位,例如,我们常说的某计算机的硬盘容量是320GB,某移动硬盘的容量是80GB,某个文件夹的大小是156KB等,其中1GB=210MB,1MB=210KB,1KB=210B(字节),对于一个容量为8GB的内存盘,其容量为____B(字节).\n![](unit_GB.gif)\n\nFrom <http://www.manfen5.com/stinfo/CZ_SX/SYS201808030701323019115696/> \n","slug":"linux/硬盘存储空间单位GB","published":1,"date":"2020-08-12T16:05:46.587Z","updated":"2020-02-13T12:47:44.613Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmg0003thohx327agzf6","content":"<p>信息技术的存储设备常用B、KB、MB、GB等作为存储设备的单位,例如,我们常说的某计算机的硬盘容量是320GB,某移动硬盘的容量是80GB,某个文件夹的大小是156KB等,其中1GB=210MB,1MB=210KB,1KB=210B(字节),对于一个容量为8GB的内存盘,其容量为____B(字节).<br><img src=\"unit_GB.gif\" alt=\"\"></p>\n<p>From <a href=\"http://www.manfen5.com/stinfo/CZ_SX/SYS201808030701323019115696/\" target=\"_blank\" rel=\"noopener\">http://www.manfen5.com/stinfo/CZ_SX/SYS201808030701323019115696/</a> </p>\n","site":{"data":{}},"excerpt":"","more":"<p>信息技术的存储设备常用B、KB、MB、GB等作为存储设备的单位,例如,我们常说的某计算机的硬盘容量是320GB,某移动硬盘的容量是80GB,某个文件夹的大小是156KB等,其中1GB=210MB,1MB=210KB,1KB=210B(字节),对于一个容量为8GB的内存盘,其容量为____B(字节).<br><img src=\"unit_GB.gif\" alt=\"\"></p>\n<p>From <a href=\"http://www.manfen5.com/stinfo/CZ_SX/SYS201808030701323019115696/\" target=\"_blank\" rel=\"noopener\">http://www.manfen5.com/stinfo/CZ_SX/SYS201808030701323019115696/</a> </p>\n"},{"title":"脚本执行错误 $'\\r':command not found","_content":"shell脚本执行错误 $'\\r':command not found\n第一种解决方案：\nLinux下有命令dos2unix\n你只要输入dos2unix *.sh就可以完成转换工作了\n如果命令不存在的话就用如下命令安装\nyum install dos2unix -y\n \n第二种解决方案：\n这种情况发生的原因是因为你所处理的文件换行符是dos格式的\"\\r\\n\"\n可以使用cat -v 文件名 来查看换行符是否是，如果是上述的，则行结尾会是^m\n需要转换成linux/unix格式的\"\\n\nsed 's/\\r//' 原文件 >转换后文件\n第三种解决方案：\n首先要确保文件有可执行权限\n#sh>chmod a+x filename\n利用如下命令查看文件格式\n:set ff 或 :set fileformat\n可以看到如下信息\nfileformat=dos 或 fileformat=unix\n利用如下命令修改文件格式\n:set ff=unix 或 :set fileformat=unix\n","source":"_posts/linux/脚本执行错误_r_command not found.md","raw":"---\ntitle: 脚本执行错误 $'\\r':command not found\ntags: \ncategories:\n- linux\n---\nshell脚本执行错误 $'\\r':command not found\n第一种解决方案：\nLinux下有命令dos2unix\n你只要输入dos2unix *.sh就可以完成转换工作了\n如果命令不存在的话就用如下命令安装\nyum install dos2unix -y\n \n第二种解决方案：\n这种情况发生的原因是因为你所处理的文件换行符是dos格式的\"\\r\\n\"\n可以使用cat -v 文件名 来查看换行符是否是，如果是上述的，则行结尾会是^m\n需要转换成linux/unix格式的\"\\n\nsed 's/\\r//' 原文件 >转换后文件\n第三种解决方案：\n首先要确保文件有可执行权限\n#sh>chmod a+x filename\n利用如下命令查看文件格式\n:set ff 或 :set fileformat\n可以看到如下信息\nfileformat=dos 或 fileformat=unix\n利用如下命令修改文件格式\n:set ff=unix 或 :set fileformat=unix\n","slug":"linux/脚本执行错误_r_command not found","published":1,"date":"2020-08-12T16:05:46.590Z","updated":"2020-02-13T12:47:44.622Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmg1003vhohxg3gv6s4s","content":"<p>shell脚本执行错误 $’\\r’:command not found<br>第一种解决方案：<br>Linux下有命令dos2unix<br>你只要输入dos2unix *.sh就可以完成转换工作了<br>如果命令不存在的话就用如下命令安装<br>yum install dos2unix -y</p>\n<p>第二种解决方案：<br>这种情况发生的原因是因为你所处理的文件换行符是dos格式的”\\r\\n”<br>可以使用cat -v 文件名 来查看换行符是否是，如果是上述的，则行结尾会是^m<br>需要转换成linux/unix格式的”\\n<br>sed ‘s/\\r//‘ 原文件 &gt;转换后文件<br>第三种解决方案：<br>首先要确保文件有可执行权限<br>#sh&gt;chmod a+x filename<br>利用如下命令查看文件格式<br>:set ff 或 :set fileformat<br>可以看到如下信息<br>fileformat=dos 或 fileformat=unix<br>利用如下命令修改文件格式<br>:set ff=unix 或 :set fileformat=unix</p>\n","site":{"data":{}},"excerpt":"","more":"<p>shell脚本执行错误 $’\\r’:command not found<br>第一种解决方案：<br>Linux下有命令dos2unix<br>你只要输入dos2unix *.sh就可以完成转换工作了<br>如果命令不存在的话就用如下命令安装<br>yum install dos2unix -y</p>\n<p>第二种解决方案：<br>这种情况发生的原因是因为你所处理的文件换行符是dos格式的”\\r\\n”<br>可以使用cat -v 文件名 来查看换行符是否是，如果是上述的，则行结尾会是^m<br>需要转换成linux/unix格式的”\\n<br>sed ‘s/\\r//‘ 原文件 &gt;转换后文件<br>第三种解决方案：<br>首先要确保文件有可执行权限<br>#sh&gt;chmod a+x filename<br>利用如下命令查看文件格式<br>:set ff 或 :set fileformat<br>可以看到如下信息<br>fileformat=dos 或 fileformat=unix<br>利用如下命令修改文件格式<br>:set ff=unix 或 :set fileformat=unix</p>\n"},{"title":"解压缩命令合集","_content":"tar\n-c: 建立压缩档案\n-x：解压\n-t：查看内容\n-r：向压缩归档文件末尾追加文件\n-u：更新原压缩包中的文件\n\n这五个是独立的命令，压缩解压都要用到其中一个，可以和别的命令连用但只能用其中一个。下面的参数是根据需要在压缩或解压档案时可选的。\n\n-z：有gzip属性的\n-j：有bz2属性的\n-Z：有compress属性的\n-v：显示所有过程\n-O：将文件解开到标准输出\n\n下面的参数-f是必须的\n\n-f: 使用档案名字，切记，这个参数是最后一个参数，后面只能接档案名。\n\n# tar -cf all.tar *.jpg \n这条命令是将所有.jpg的文件打成一个名为all.tar的包。-c是表示产生新的包，-f指定包的文件名。 \n\n# tar -rf all.tar *.gif \n这条命令是将所有.gif的文件增加到all.tar的包里面去。-r是表示增加文件的意思。 \n\n# tar -uf all.tar logo.gif \n这条命令是更新原来tar包all.tar中logo.gif文件，-u是表示更新文件的意思。 \n\n# tar -tf all.tar \n这条命令是列出all.tar包中所有文件，-t是列出文件的意思 \n\n# tar -xf all.tar \n这条命令是解出all.tar包中所有文件，-x是解开的意思 \n\n压缩\n\ntar –cvf jpg.tar *.jpg //将目录里所有jpg文件打包成tar.jpg\n\ntar –czf jpg.tar.gz *.jpg   //将目录里所有jpg文件打包成jpg.tar后，并且将其用gzip压缩，生成一个gzip压缩过的包，命名为jpg.tar.gz\n\ntar –cjf jpg.tar.bz2 *.jpg //将目录里所有jpg文件打包成jpg.tar后，并且将其用bzip2压缩，生成一个bzip2压缩过的包，命名为jpg.tar.bz2\n\ntar –cZf jpg.tar.Z *.jpg   //将目录里所有jpg文件打包成jpg.tar后，并且将其用compress压缩，生成一个umcompress压缩过的包，命名为jpg.tar.Z\n\nrar a jpg.rar *.jpg //rar格式的压缩，需要先下载rar for linux\n\nzip jpg.zip *.jpg //zip格式的压缩，需要先下载zip for linux\n\n解压\n\ntar –xvf file.tar //解压 tar包\n\ntar -xzvf file.tar.gz //解压tar.gz\n\ntar -xjvf file.tar.bz2   //解压 tar.bz2\n\ntar –xZvf file.tar.Z   //解压tar.Z\n\nunrar e file.rar //解压rar\n\nunzip file.zip //解压zip\n\n总结\n\n1、*.tar 用 tar –xvf 解压\n\n2、*.gz 用 gzip -d或者gunzip 解压\n\n3、*.tar.gz和*.tgz 用 tar -xzf 解压\n\n4、*.bz2 用 bzip2 -d或者用bunzip2 解压\n\n5、*.tar.bz2用tar -xjf 解压\n\n6、*.Z 用 uncompress 解压\n\n7、*.tar.Z 用tar –xZf 解压\n\n8、*.rar 用 unrar e解压\n\n9、*.zip 用 unzip 解压\n\n10、*.tgz 用tar zxvf  *.tgz  -C  ./\n\n\n\nStay hungry, stay foolish!\n\nFrom <https://www.cnblogs.com/wi100sh/p/4178021.html> \n\n","source":"_posts/linux/解压缩命令合集.md","raw":"---\ntitle: 解压缩命令合集\ntags: \ncategories:\n- linux\n---\ntar\n-c: 建立压缩档案\n-x：解压\n-t：查看内容\n-r：向压缩归档文件末尾追加文件\n-u：更新原压缩包中的文件\n\n这五个是独立的命令，压缩解压都要用到其中一个，可以和别的命令连用但只能用其中一个。下面的参数是根据需要在压缩或解压档案时可选的。\n\n-z：有gzip属性的\n-j：有bz2属性的\n-Z：有compress属性的\n-v：显示所有过程\n-O：将文件解开到标准输出\n\n下面的参数-f是必须的\n\n-f: 使用档案名字，切记，这个参数是最后一个参数，后面只能接档案名。\n\n# tar -cf all.tar *.jpg \n这条命令是将所有.jpg的文件打成一个名为all.tar的包。-c是表示产生新的包，-f指定包的文件名。 \n\n# tar -rf all.tar *.gif \n这条命令是将所有.gif的文件增加到all.tar的包里面去。-r是表示增加文件的意思。 \n\n# tar -uf all.tar logo.gif \n这条命令是更新原来tar包all.tar中logo.gif文件，-u是表示更新文件的意思。 \n\n# tar -tf all.tar \n这条命令是列出all.tar包中所有文件，-t是列出文件的意思 \n\n# tar -xf all.tar \n这条命令是解出all.tar包中所有文件，-x是解开的意思 \n\n压缩\n\ntar –cvf jpg.tar *.jpg //将目录里所有jpg文件打包成tar.jpg\n\ntar –czf jpg.tar.gz *.jpg   //将目录里所有jpg文件打包成jpg.tar后，并且将其用gzip压缩，生成一个gzip压缩过的包，命名为jpg.tar.gz\n\ntar –cjf jpg.tar.bz2 *.jpg //将目录里所有jpg文件打包成jpg.tar后，并且将其用bzip2压缩，生成一个bzip2压缩过的包，命名为jpg.tar.bz2\n\ntar –cZf jpg.tar.Z *.jpg   //将目录里所有jpg文件打包成jpg.tar后，并且将其用compress压缩，生成一个umcompress压缩过的包，命名为jpg.tar.Z\n\nrar a jpg.rar *.jpg //rar格式的压缩，需要先下载rar for linux\n\nzip jpg.zip *.jpg //zip格式的压缩，需要先下载zip for linux\n\n解压\n\ntar –xvf file.tar //解压 tar包\n\ntar -xzvf file.tar.gz //解压tar.gz\n\ntar -xjvf file.tar.bz2   //解压 tar.bz2\n\ntar –xZvf file.tar.Z   //解压tar.Z\n\nunrar e file.rar //解压rar\n\nunzip file.zip //解压zip\n\n总结\n\n1、*.tar 用 tar –xvf 解压\n\n2、*.gz 用 gzip -d或者gunzip 解压\n\n3、*.tar.gz和*.tgz 用 tar -xzf 解压\n\n4、*.bz2 用 bzip2 -d或者用bunzip2 解压\n\n5、*.tar.bz2用tar -xjf 解压\n\n6、*.Z 用 uncompress 解压\n\n7、*.tar.Z 用tar –xZf 解压\n\n8、*.rar 用 unrar e解压\n\n9、*.zip 用 unzip 解压\n\n10、*.tgz 用tar zxvf  *.tgz  -C  ./\n\n\n\nStay hungry, stay foolish!\n\nFrom <https://www.cnblogs.com/wi100sh/p/4178021.html> \n\n","slug":"linux/解压缩命令合集","published":1,"date":"2020-08-12T16:05:46.600Z","updated":"2020-02-13T12:47:44.625Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmg1003xhohxhwsn472z","content":"<p>tar<br>-c: 建立压缩档案<br>-x：解压<br>-t：查看内容<br>-r：向压缩归档文件末尾追加文件<br>-u：更新原压缩包中的文件</p>\n<p>这五个是独立的命令，压缩解压都要用到其中一个，可以和别的命令连用但只能用其中一个。下面的参数是根据需要在压缩或解压档案时可选的。</p>\n<p>-z：有gzip属性的<br>-j：有bz2属性的<br>-Z：有compress属性的<br>-v：显示所有过程<br>-O：将文件解开到标准输出</p>\n<p>下面的参数-f是必须的</p>\n<p>-f: 使用档案名字，切记，这个参数是最后一个参数，后面只能接档案名。</p>\n<h1 id=\"tar-cf-all-tar-jpg\"><a href=\"#tar-cf-all-tar-jpg\" class=\"headerlink\" title=\"tar -cf all.tar *.jpg\"></a>tar -cf all.tar *.jpg</h1><p>这条命令是将所有.jpg的文件打成一个名为all.tar的包。-c是表示产生新的包，-f指定包的文件名。 </p>\n<h1 id=\"tar-rf-all-tar-gif\"><a href=\"#tar-rf-all-tar-gif\" class=\"headerlink\" title=\"tar -rf all.tar *.gif\"></a>tar -rf all.tar *.gif</h1><p>这条命令是将所有.gif的文件增加到all.tar的包里面去。-r是表示增加文件的意思。 </p>\n<h1 id=\"tar-uf-all-tar-logo-gif\"><a href=\"#tar-uf-all-tar-logo-gif\" class=\"headerlink\" title=\"tar -uf all.tar logo.gif\"></a>tar -uf all.tar logo.gif</h1><p>这条命令是更新原来tar包all.tar中logo.gif文件，-u是表示更新文件的意思。 </p>\n<h1 id=\"tar-tf-all-tar\"><a href=\"#tar-tf-all-tar\" class=\"headerlink\" title=\"tar -tf all.tar\"></a>tar -tf all.tar</h1><p>这条命令是列出all.tar包中所有文件，-t是列出文件的意思 </p>\n<h1 id=\"tar-xf-all-tar\"><a href=\"#tar-xf-all-tar\" class=\"headerlink\" title=\"tar -xf all.tar\"></a>tar -xf all.tar</h1><p>这条命令是解出all.tar包中所有文件，-x是解开的意思 </p>\n<p>压缩</p>\n<p>tar –cvf jpg.tar *.jpg //将目录里所有jpg文件打包成tar.jpg</p>\n<p>tar –czf jpg.tar.gz *.jpg   //将目录里所有jpg文件打包成jpg.tar后，并且将其用gzip压缩，生成一个gzip压缩过的包，命名为jpg.tar.gz</p>\n<p>tar –cjf jpg.tar.bz2 *.jpg //将目录里所有jpg文件打包成jpg.tar后，并且将其用bzip2压缩，生成一个bzip2压缩过的包，命名为jpg.tar.bz2</p>\n<p>tar –cZf jpg.tar.Z *.jpg   //将目录里所有jpg文件打包成jpg.tar后，并且将其用compress压缩，生成一个umcompress压缩过的包，命名为jpg.tar.Z</p>\n<p>rar a jpg.rar *.jpg //rar格式的压缩，需要先下载rar for linux</p>\n<p>zip jpg.zip *.jpg //zip格式的压缩，需要先下载zip for linux</p>\n<p>解压</p>\n<p>tar –xvf file.tar //解压 tar包</p>\n<p>tar -xzvf file.tar.gz //解压tar.gz</p>\n<p>tar -xjvf file.tar.bz2   //解压 tar.bz2</p>\n<p>tar –xZvf file.tar.Z   //解压tar.Z</p>\n<p>unrar e file.rar //解压rar</p>\n<p>unzip file.zip //解压zip</p>\n<p>总结</p>\n<p>1、*.tar 用 tar –xvf 解压</p>\n<p>2、*.gz 用 gzip -d或者gunzip 解压</p>\n<p>3、<em>.tar.gz和</em>.tgz 用 tar -xzf 解压</p>\n<p>4、*.bz2 用 bzip2 -d或者用bunzip2 解压</p>\n<p>5、*.tar.bz2用tar -xjf 解压</p>\n<p>6、*.Z 用 uncompress 解压</p>\n<p>7、*.tar.Z 用tar –xZf 解压</p>\n<p>8、*.rar 用 unrar e解压</p>\n<p>9、*.zip 用 unzip 解压</p>\n<p>10、*.tgz 用tar zxvf  *.tgz  -C  ./</p>\n<p>Stay hungry, stay foolish!</p>\n<p>From <a href=\"https://www.cnblogs.com/wi100sh/p/4178021.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/wi100sh/p/4178021.html</a> </p>\n","site":{"data":{}},"excerpt":"","more":"<p>tar<br>-c: 建立压缩档案<br>-x：解压<br>-t：查看内容<br>-r：向压缩归档文件末尾追加文件<br>-u：更新原压缩包中的文件</p>\n<p>这五个是独立的命令，压缩解压都要用到其中一个，可以和别的命令连用但只能用其中一个。下面的参数是根据需要在压缩或解压档案时可选的。</p>\n<p>-z：有gzip属性的<br>-j：有bz2属性的<br>-Z：有compress属性的<br>-v：显示所有过程<br>-O：将文件解开到标准输出</p>\n<p>下面的参数-f是必须的</p>\n<p>-f: 使用档案名字，切记，这个参数是最后一个参数，后面只能接档案名。</p>\n<h1 id=\"tar-cf-all-tar-jpg\"><a href=\"#tar-cf-all-tar-jpg\" class=\"headerlink\" title=\"tar -cf all.tar *.jpg\"></a>tar -cf all.tar *.jpg</h1><p>这条命令是将所有.jpg的文件打成一个名为all.tar的包。-c是表示产生新的包，-f指定包的文件名。 </p>\n<h1 id=\"tar-rf-all-tar-gif\"><a href=\"#tar-rf-all-tar-gif\" class=\"headerlink\" title=\"tar -rf all.tar *.gif\"></a>tar -rf all.tar *.gif</h1><p>这条命令是将所有.gif的文件增加到all.tar的包里面去。-r是表示增加文件的意思。 </p>\n<h1 id=\"tar-uf-all-tar-logo-gif\"><a href=\"#tar-uf-all-tar-logo-gif\" class=\"headerlink\" title=\"tar -uf all.tar logo.gif\"></a>tar -uf all.tar logo.gif</h1><p>这条命令是更新原来tar包all.tar中logo.gif文件，-u是表示更新文件的意思。 </p>\n<h1 id=\"tar-tf-all-tar\"><a href=\"#tar-tf-all-tar\" class=\"headerlink\" title=\"tar -tf all.tar\"></a>tar -tf all.tar</h1><p>这条命令是列出all.tar包中所有文件，-t是列出文件的意思 </p>\n<h1 id=\"tar-xf-all-tar\"><a href=\"#tar-xf-all-tar\" class=\"headerlink\" title=\"tar -xf all.tar\"></a>tar -xf all.tar</h1><p>这条命令是解出all.tar包中所有文件，-x是解开的意思 </p>\n<p>压缩</p>\n<p>tar –cvf jpg.tar *.jpg //将目录里所有jpg文件打包成tar.jpg</p>\n<p>tar –czf jpg.tar.gz *.jpg   //将目录里所有jpg文件打包成jpg.tar后，并且将其用gzip压缩，生成一个gzip压缩过的包，命名为jpg.tar.gz</p>\n<p>tar –cjf jpg.tar.bz2 *.jpg //将目录里所有jpg文件打包成jpg.tar后，并且将其用bzip2压缩，生成一个bzip2压缩过的包，命名为jpg.tar.bz2</p>\n<p>tar –cZf jpg.tar.Z *.jpg   //将目录里所有jpg文件打包成jpg.tar后，并且将其用compress压缩，生成一个umcompress压缩过的包，命名为jpg.tar.Z</p>\n<p>rar a jpg.rar *.jpg //rar格式的压缩，需要先下载rar for linux</p>\n<p>zip jpg.zip *.jpg //zip格式的压缩，需要先下载zip for linux</p>\n<p>解压</p>\n<p>tar –xvf file.tar //解压 tar包</p>\n<p>tar -xzvf file.tar.gz //解压tar.gz</p>\n<p>tar -xjvf file.tar.bz2   //解压 tar.bz2</p>\n<p>tar –xZvf file.tar.Z   //解压tar.Z</p>\n<p>unrar e file.rar //解压rar</p>\n<p>unzip file.zip //解压zip</p>\n<p>总结</p>\n<p>1、*.tar 用 tar –xvf 解压</p>\n<p>2、*.gz 用 gzip -d或者gunzip 解压</p>\n<p>3、<em>.tar.gz和</em>.tgz 用 tar -xzf 解压</p>\n<p>4、*.bz2 用 bzip2 -d或者用bunzip2 解压</p>\n<p>5、*.tar.bz2用tar -xjf 解压</p>\n<p>6、*.Z 用 uncompress 解压</p>\n<p>7、*.tar.Z 用tar –xZf 解压</p>\n<p>8、*.rar 用 unrar e解压</p>\n<p>9、*.zip 用 unzip 解压</p>\n<p>10、*.tgz 用tar zxvf  *.tgz  -C  ./</p>\n<p>Stay hungry, stay foolish!</p>\n<p>From <a href=\"https://www.cnblogs.com/wi100sh/p/4178021.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/wi100sh/p/4178021.html</a> </p>\n"},{"title":"连接router后机器连不上外网","_content":"几台机器连接同一个路由器router后，centos机器连不上外网\n[root@sphm001 ~]# route -n\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n0.0.0.0         192.168.1.1    0.0.0.0         UG    100    0        0 enp0s31f6\n0.0.0.0         10.239.173.1    0.0.0.0         UG    101    0        0 enp0s20f0u8\n10.239.173.0    0.0.0.0         255.255.255.0   U     101    0        0 enp0s20f0u8\n192.168.1.0     0.0.0.0         255.255.255.0   U     100    0        0 enp0s31f6\n[root@sphm001 ~]#\n[root@sphm001 ~]# route del -net 0.0.0.0 gw 192.168.1.1\n[root@sphm001 ~]# route -n\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n0.0.0.0         10.239.173.1    0.0.0.0         UG    101    0        0 enp0s20f0u8\n10.239.173.0    0.0.0.0         255.255.255.0   U     101    0        0 enp0s20f0u8\n192.168.1.0     0.0.0.0         255.255.255.0   U     100    0        0 enp0s31f6\n[root@sphm001 ~]#\n[root@sphm001 ~]# wget www.baidu.com\n--1998-01-29 23:28:17--  http://www.baidu.com/\nResolving child-prc.intel.com (child-prc.intel.com)... 10.239.4.101\nConnecting to child-prc.intel.com (child-prc.intel.com)|10.239.4.101|:913... connected.\nProxy request sent, awaiting response... 200 OK\nLength: 2381 (2.3K) [text/html]\nSaving to: ‘index.html.1’\n\n100%[============================================================================================>] 2,381       --.-K/s   in 0s\n\n1998-01-29 23:28:17 (81.6 MB/s) - ‘index.html.1’ saved [2381/2381]\n修改完路由如果还不行就重启机器试试\n[root@sphm001 ~]#\n\n\nlinux上用route添加/删除路由\n1. 查看\nroute -n\n 2. 添加\nroute add -net 9.123.0.0 netmask 255.255.0.0 gw 9.123.0.1\n 3. 删除\nroute del -net 9.123.0.0 netmask 255.255.0.0 gw 9.123.0.1\n \n有些童鞋问怎么加永久路由，很简单，把 “route add -net 9.123.0.0 netmask 255.255.0.0 gw 9.123.0.1” 写到/etc/rc.local最后就行了，\n或者复制编辑好执行也可以：\necho “route add -net 9.123.0.0 netmask 255.255.0.0 gw 9.123.0.1” >> /etc/rc.local\n \n实际中发现，CentOS7.4默认环境下，rc.local中不会执行，需要赋权才可以\nchmod +x /etc/rc.local\n\nFrom <https://www.cnblogs.com/lynsen/p/8027446.html> \n\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nSPH + RVP\nroot@imie:~# route -n\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n0.0.0.0         10.239.173.1    0.0.0.0         UG    0      0        0 eth1\n10.239.173.0    0.0.0.0         255.255.255.0   U     0      0        0 eth1\n172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0\n192.168.1.0     0.0.0.0         255.255.255.0   U     0      0        0 eth0\nroot@imie:~#\n\n\nroot@imie:~# vim /etc/network/interfaces\niface lo inet loopback\n\n# Wired interfaces\nauto eth0 eth1\niface eth0 inet dhcp\niface eth1 inet dhcp\n\n# iface eth0 inet manual\n# iface eth1 inet manual\n\n# Network bridge\n# auto br0\n# iface br0 inet dhcp\n#   bridge_ports eth0 eth1\n","source":"_posts/linux/连接router后机器连不上外网.md","raw":"---\ntitle: 连接router后机器连不上外网\ntags: \ncategories:\n- linux\n---\n几台机器连接同一个路由器router后，centos机器连不上外网\n[root@sphm001 ~]# route -n\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n0.0.0.0         192.168.1.1    0.0.0.0         UG    100    0        0 enp0s31f6\n0.0.0.0         10.239.173.1    0.0.0.0         UG    101    0        0 enp0s20f0u8\n10.239.173.0    0.0.0.0         255.255.255.0   U     101    0        0 enp0s20f0u8\n192.168.1.0     0.0.0.0         255.255.255.0   U     100    0        0 enp0s31f6\n[root@sphm001 ~]#\n[root@sphm001 ~]# route del -net 0.0.0.0 gw 192.168.1.1\n[root@sphm001 ~]# route -n\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n0.0.0.0         10.239.173.1    0.0.0.0         UG    101    0        0 enp0s20f0u8\n10.239.173.0    0.0.0.0         255.255.255.0   U     101    0        0 enp0s20f0u8\n192.168.1.0     0.0.0.0         255.255.255.0   U     100    0        0 enp0s31f6\n[root@sphm001 ~]#\n[root@sphm001 ~]# wget www.baidu.com\n--1998-01-29 23:28:17--  http://www.baidu.com/\nResolving child-prc.intel.com (child-prc.intel.com)... 10.239.4.101\nConnecting to child-prc.intel.com (child-prc.intel.com)|10.239.4.101|:913... connected.\nProxy request sent, awaiting response... 200 OK\nLength: 2381 (2.3K) [text/html]\nSaving to: ‘index.html.1’\n\n100%[============================================================================================>] 2,381       --.-K/s   in 0s\n\n1998-01-29 23:28:17 (81.6 MB/s) - ‘index.html.1’ saved [2381/2381]\n修改完路由如果还不行就重启机器试试\n[root@sphm001 ~]#\n\n\nlinux上用route添加/删除路由\n1. 查看\nroute -n\n 2. 添加\nroute add -net 9.123.0.0 netmask 255.255.0.0 gw 9.123.0.1\n 3. 删除\nroute del -net 9.123.0.0 netmask 255.255.0.0 gw 9.123.0.1\n \n有些童鞋问怎么加永久路由，很简单，把 “route add -net 9.123.0.0 netmask 255.255.0.0 gw 9.123.0.1” 写到/etc/rc.local最后就行了，\n或者复制编辑好执行也可以：\necho “route add -net 9.123.0.0 netmask 255.255.0.0 gw 9.123.0.1” >> /etc/rc.local\n \n实际中发现，CentOS7.4默认环境下，rc.local中不会执行，需要赋权才可以\nchmod +x /etc/rc.local\n\nFrom <https://www.cnblogs.com/lynsen/p/8027446.html> \n\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nSPH + RVP\nroot@imie:~# route -n\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n0.0.0.0         10.239.173.1    0.0.0.0         UG    0      0        0 eth1\n10.239.173.0    0.0.0.0         255.255.255.0   U     0      0        0 eth1\n172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0\n192.168.1.0     0.0.0.0         255.255.255.0   U     0      0        0 eth0\nroot@imie:~#\n\n\nroot@imie:~# vim /etc/network/interfaces\niface lo inet loopback\n\n# Wired interfaces\nauto eth0 eth1\niface eth0 inet dhcp\niface eth1 inet dhcp\n\n# iface eth0 inet manual\n# iface eth1 inet manual\n\n# Network bridge\n# auto br0\n# iface br0 inet dhcp\n#   bridge_ports eth0 eth1\n","slug":"linux/连接router后机器连不上外网","published":1,"date":"2020-08-12T16:05:46.610Z","updated":"2020-02-13T12:47:44.629Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmg2003zhohxbndicd3v","content":"<p>几台机器连接同一个路由器router后，centos机器连不上外网<br>[root@sphm001 ~]# route -n<br>Kernel IP routing table<br>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface<br>0.0.0.0         192.168.1.1    0.0.0.0         UG    100    0        0 enp0s31f6<br>0.0.0.0         10.239.173.1    0.0.0.0         UG    101    0        0 enp0s20f0u8<br>10.239.173.0    0.0.0.0         255.255.255.0   U     101    0        0 enp0s20f0u8<br>192.168.1.0     0.0.0.0         255.255.255.0   U     100    0        0 enp0s31f6<br>[root@sphm001 ~]#<br>[root@sphm001 ~]# route del -net 0.0.0.0 gw 192.168.1.1<br>[root@sphm001 ~]# route -n<br>Kernel IP routing table<br>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface<br>0.0.0.0         10.239.173.1    0.0.0.0         UG    101    0        0 enp0s20f0u8<br>10.239.173.0    0.0.0.0         255.255.255.0   U     101    0        0 enp0s20f0u8<br>192.168.1.0     0.0.0.0         255.255.255.0   U     100    0        0 enp0s31f6<br>[root@sphm001 ~]#<br>[root@sphm001 ~]# wget <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>–1998-01-29 23:28:17–  <a href=\"http://www.baidu.com/\" target=\"_blank\" rel=\"noopener\">http://www.baidu.com/</a><br>Resolving child-prc.intel.com (child-prc.intel.com)… 10.239.4.101<br>Connecting to child-prc.intel.com (child-prc.intel.com)|10.239.4.101|:913… connected.<br>Proxy request sent, awaiting response… 200 OK<br>Length: 2381 (2.3K) [text/html]<br>Saving to: ‘index.html.1’</p>\n<p>100%[============================================================================================&gt;] 2,381       –.-K/s   in 0s</p>\n<p>1998-01-29 23:28:17 (81.6 MB/s) - ‘index.html.1’ saved [2381/2381]<br>修改完路由如果还不行就重启机器试试<br>[root@sphm001 ~]#</p>\n<p>linux上用route添加/删除路由</p>\n<ol>\n<li>查看<br>route -n<ol start=\"2\">\n<li>添加<br>route add -net 9.123.0.0 netmask 255.255.0.0 gw 9.123.0.1</li>\n<li>删除<br>route del -net 9.123.0.0 netmask 255.255.0.0 gw 9.123.0.1</li>\n</ol>\n</li>\n</ol>\n<p>有些童鞋问怎么加永久路由，很简单，把 “route add -net 9.123.0.0 netmask 255.255.0.0 gw 9.123.0.1” 写到/etc/rc.local最后就行了，<br>或者复制编辑好执行也可以：<br>echo “route add -net 9.123.0.0 netmask 255.255.0.0 gw 9.123.0.1” &gt;&gt; /etc/rc.local</p>\n<p>实际中发现，CentOS7.4默认环境下，rc.local中不会执行，需要赋权才可以<br>chmod +x /etc/rc.local</p>\n<p>From <a href=\"https://www.cnblogs.com/lynsen/p/8027446.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/lynsen/p/8027446.html</a> </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">~~</span><br></pre></td></tr></table></figure>\n<pre><code>SPH + RVP\nroot@imie:~# route -n\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n0.0.0.0         10.239.173.1    0.0.0.0         UG    0      0        0 eth1\n10.239.173.0    0.0.0.0         255.255.255.0   U     0      0        0 eth1\n172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0\n192.168.1.0     0.0.0.0         255.255.255.0   U     0      0        0 eth0\nroot@imie:~#\n\n\nroot@imie:~# vim /etc/network/interfaces\niface lo inet loopback\n\n# Wired interfaces\nauto eth0 eth1\niface eth0 inet dhcp\niface eth1 inet dhcp\n\n# iface eth0 inet manual\n# iface eth1 inet manual\n\n# Network bridge\n# auto br0\n# iface br0 inet dhcp\n#   bridge_ports eth0 eth1</code></pre>","site":{"data":{}},"excerpt":"","more":"<p>几台机器连接同一个路由器router后，centos机器连不上外网<br>[root@sphm001 ~]# route -n<br>Kernel IP routing table<br>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface<br>0.0.0.0         192.168.1.1    0.0.0.0         UG    100    0        0 enp0s31f6<br>0.0.0.0         10.239.173.1    0.0.0.0         UG    101    0        0 enp0s20f0u8<br>10.239.173.0    0.0.0.0         255.255.255.0   U     101    0        0 enp0s20f0u8<br>192.168.1.0     0.0.0.0         255.255.255.0   U     100    0        0 enp0s31f6<br>[root@sphm001 ~]#<br>[root@sphm001 ~]# route del -net 0.0.0.0 gw 192.168.1.1<br>[root@sphm001 ~]# route -n<br>Kernel IP routing table<br>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface<br>0.0.0.0         10.239.173.1    0.0.0.0         UG    101    0        0 enp0s20f0u8<br>10.239.173.0    0.0.0.0         255.255.255.0   U     101    0        0 enp0s20f0u8<br>192.168.1.0     0.0.0.0         255.255.255.0   U     100    0        0 enp0s31f6<br>[root@sphm001 ~]#<br>[root@sphm001 ~]# wget <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>–1998-01-29 23:28:17–  <a href=\"http://www.baidu.com/\" target=\"_blank\" rel=\"noopener\">http://www.baidu.com/</a><br>Resolving child-prc.intel.com (child-prc.intel.com)… 10.239.4.101<br>Connecting to child-prc.intel.com (child-prc.intel.com)|10.239.4.101|:913… connected.<br>Proxy request sent, awaiting response… 200 OK<br>Length: 2381 (2.3K) [text/html]<br>Saving to: ‘index.html.1’</p>\n<p>100%[============================================================================================&gt;] 2,381       –.-K/s   in 0s</p>\n<p>1998-01-29 23:28:17 (81.6 MB/s) - ‘index.html.1’ saved [2381/2381]<br>修改完路由如果还不行就重启机器试试<br>[root@sphm001 ~]#</p>\n<p>linux上用route添加/删除路由</p>\n<ol>\n<li>查看<br>route -n<ol start=\"2\">\n<li>添加<br>route add -net 9.123.0.0 netmask 255.255.0.0 gw 9.123.0.1</li>\n<li>删除<br>route del -net 9.123.0.0 netmask 255.255.0.0 gw 9.123.0.1</li>\n</ol>\n</li>\n</ol>\n<p>有些童鞋问怎么加永久路由，很简单，把 “route add -net 9.123.0.0 netmask 255.255.0.0 gw 9.123.0.1” 写到/etc/rc.local最后就行了，<br>或者复制编辑好执行也可以：<br>echo “route add -net 9.123.0.0 netmask 255.255.0.0 gw 9.123.0.1” &gt;&gt; /etc/rc.local</p>\n<p>实际中发现，CentOS7.4默认环境下，rc.local中不会执行，需要赋权才可以<br>chmod +x /etc/rc.local</p>\n<p>From <a href=\"https://www.cnblogs.com/lynsen/p/8027446.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/lynsen/p/8027446.html</a> </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">~~</span><br></pre></td></tr></table></figure>\n<pre><code>SPH + RVP\nroot@imie:~# route -n\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n0.0.0.0         10.239.173.1    0.0.0.0         UG    0      0        0 eth1\n10.239.173.0    0.0.0.0         255.255.255.0   U     0      0        0 eth1\n172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0\n192.168.1.0     0.0.0.0         255.255.255.0   U     0      0        0 eth0\nroot@imie:~#\n\n\nroot@imie:~# vim /etc/network/interfaces\niface lo inet loopback\n\n# Wired interfaces\nauto eth0 eth1\niface eth0 inet dhcp\niface eth1 inet dhcp\n\n# iface eth0 inet manual\n# iface eth1 inet manual\n\n# Network bridge\n# auto br0\n# iface br0 inet dhcp\n#   bridge_ports eth0 eth1</code></pre>"},{"title":"01 Kubernetes build","top":1,"_content":"\n### Kubernetes 简介\n ![](1.JPG)\n ![](2.JPG)\n \n### 主要特征\n> * 以服务为中心: 不关心服务运行的环境和细节，所以构建在kubernetes上的系统可以部署在物理机、虚拟机、公有云、私有云，在什么地方运行都是无差别的.\n> * 自动化: 在kubernetes里的系统可以自动扩缩容、自动升级、更新、部署. 比如:\n>  - K8s收到某个指令后，会触发调度流程，选中目标节点，部署或者停止响应服务.\n>  - 如果有新的pod启动，会被自动加入负载均衡器，自动生效\n>  - 服务运行过程中，K8s会定期的检查它们的实例数，以及这些实例的状态是否正常，当发现某个实例不可用的时候会自动销毁不可用的实例然后重新调度一个新的实例，以上所有都是自动化完成，不需要人工参与.\n\n### 架构\n![](K8s_arch1.JPG)\n\n### Kubernetes VS Docker\n> K8s可以看成是Docker的上层架构, 就像是javaee和java的关系,Java是一问语言，J2EE是Java语言的一门使用技术，Java为J2EE提供了库和语法，J2EE使用Java的库和语法应用在WEB上。这是概念性的区别。\n> * Java SE（Java Platform，Standard Edition）。Java SE 以前称为 J2SE。它允许开发和部署在桌面、服务器、嵌入式环境和实时环境中使用的 Java 应用程序。Java SE 包含了支持 Java Web 服务开发的类，并为 Java Platform，Enterprise Edition（Java EE）提供基础。\n> * Java EE（Java Platform，Enterprise Edition）。这个版本以前称为 J2EE。企业版本帮助开发和部署可移植、健壮、可伸缩且安全的服务器端 Java 应用程序。Java EE 是在 Java SE 的基础上构建的，它提供 Web 服务、组件模型、管理和通信 API，可以用来实现企业级的面向服务体系结构（service-oriented architecture，SOA）和 Web 2.0 应用程序。\n> * Java ME（Java Platform，Micro Edition）。这个版本以前称为 J2ME。Java ME 为在移动设备和嵌入式设备（比如手机、PDA、电视机顶盒和打印机）上运行的应用程序提供一个健壮且灵活的环境。Java ME 包括灵活的用户界面、健壮的安全模型、许多内置的网络协议以及对可以动态下载的连网和离线应用程序的丰富支持。基于 Java ME 规范的应用程序只需编写一次，就可以用于许多设备，而且可以利用每个设备的本机功能。\n\n> K8s是以Docker技术的标准为基础去打造一个全新的分布式架构系统，K8s不是一定要依赖Docker，Docker是一个产品，而Docker技术是一些列的标准，只要实现了这些标准的产品都可以替代Docker，所以说K8s在底层可以支持它自己的容器技术并且经过Google的持续优化，号称在某些方面做得比Docker更加优秀，所以用不用Docker可以自己选择.\n\n\n### 核心概念\n![](3.JPG)\n![](4.JPG)\n![](5.JPG)\n\n### Label 标签\n> POD，Deployment，Node等都可以打标签启到标识作用.\n\n### POD (可以称为实例)\n> * 所有的服务，所有的应用最终都是跑在Pod中,Pod是Kubernetes概念中最小的单元，可以理解为是Kubernetes的一个原子.\n> * POD 里面可以有一个或多个容器，\n> * POD里面所有的容器都是运行在一台机器上\n> * POD里面的容器共享网络，有一个唯一的IP\n> * POD里面都会有一个容器叫做Pause容器\n>  - 有特定的image镜像比如pause:v1.0\n>  - 作为根容器，把POD里其它的容器都link到一起，当我们的业务里面有两个或多个容器关系非常紧密，这时候就可以考虑把它们放到同一个POD里\n>  - 负责整个POD的健康检查，然后汇报给K8s\n![](K8s_arch2.JPG)\n![](K8s_arch3.JPG)\n \n### Pod 通讯\n> * Pod内容器之间通讯: 通过localhost加上端口就可以访问.\n![](Pod_communication1.JPG)\n\n> * 同一个Node上不同Pod之间的通讯: 同一个Node上的Pod，它们默认的路由都是Docker0，都关联在同一个Docker0网桥，地址网段是相同的，它们之间可以直接通过网桥进行通讯，访问方式是可以通过 Pod IP 直接进行访问.\n![](Pod_communication2.JPG)\n\n> 不同Node不同Pod直接通讯: Pod的IP不能冲突，Pod的IP和Node的IP关联起来，通过关联让Pod之间可以通讯.\n![](Pod_communication3.JPG)\n\n### Service\n![](K8s_arch4.JPG)\n> Pod具体运行在某个Node上\n> Service在Pod外再包一层IP\n> 当某个Pod提供服务出现问题，会在其它地方再启动一个Pod和新的Pod的IP，我们还可以通过Service IP找到新的Pod\n> 上面2台Node，3个Pod可以看做同一个应用的多个副本，对一个应用进行扩容，从一个实例扩成三个实例对外提供相同服务\n> Service除了上面可以定位到Pod地址外还可以对Pod地址进行负载均衡，比如轮训访问每个Pod\n> Pod也不一定是一模一样的，也可以是同一个应用的不同版本\n\n> 通过什么方式来确定哪些Pod是一个Service? 怎么定位哪个Pod或哪几个Pod属于某个Service?\n> Kubernetes使用的是Laber Selector\n> 通过配置好的Service的Select()，选择标签然后自动寻找POD, Service 对外有一个ClusterIP(Kube-proxy)，其它服务或者Client客户端就可以通过ClusterIP访问到这个Service，进而访问到最底层的POD服务\n\n### ReplicaSet(RS)副本集 (副本集这一层运行的程序可以称为应用)\n> RS是POD的上一层, 管理关联POD，如果应用运行过程中某个POD出现了异常或异常退出，RS就会保证副本始终为R，会在另一台机器重新调度一个POD\n\n### Deployment\n> * 扩容: 如对一个应用(Pod)扩容，把1个Pod扩容成四个实例，扩容的是Pod而不是Service, 4个Pod拥有相同标签，ServiceIP不变并对这4个Pod实行负载均衡\n![](Pod_Scaling.JPG)\n\n> * 滚动更新: 一个旧的应用(RS这一层)运行了两个实例(两个POD), 更新这个应用的时候，Deployment会自动帮我们创建一个RS，并且滚动的先启动一个新版本的不改变服务的POD, 修改的可能是image(login-image:V1->V2),这时候Deployment管理的是三个实例(3个POD)，新的POD启动完成，健康检查结束，会停掉原来的POD并删掉，然后RS会再新建一个与另一个旧版本提供相同服务的POD，然后停掉另外一个旧版本POD，旧版POD停掉之后Deployment会清理掉管理旧版本的RS, 服务更新完成.\n![](Rolling_update1.JPG)\n![](Rolling_update2.JPG)\n\n### 架构设计 \n![](k8s_architecture1.JPG)\n![](k8s_architecture2.JPG)\n\n### 密码学原理\n> * 对称加密:\n![](Symmetric_encryption.JPG)\n \n> * 非对称加密:\n![](Asymmetric_encryption.JPG)\n\n### 服务之间通信加密:\n![](6.JPG)\n> 非对称加密非常复杂，不管是加密还是解密都非常耗时， 如果每次通信都进行非对称加密性能损耗是无法接受的\n> 对称加密性能非常高，因此考虑把两者结合在一起来通信\n> * Server B 公开了自己的公钥pub_key, 任何人都可以看到\n> * 第一次通信，Server A 用Server B的pub_key 加密自己的秘钥，把秘钥变成密文，然后发到Server B，除了Server B可以用自己的私钥解密看到是对称加密的秘钥，中间黑客因为没有Server B的私钥因此无法解密, Server B 就知道要跟 Server A 进行对称加密的通信，并且使用的就是这个秘钥\n> * 之后通信, Server A就可以用发送给Server B 的秘钥对要发送的信息使用对称加密算法进行加密变成密文，然后发送给Server B， Server B收到信息后再用第一次拿到的秘钥进行对称加密算法解密.\n> - 上面的就是 SSL/TLS 协议， https底层就是通过这两个协议进行通信.\n> + 上面有个不完美地方，Server B公开pub_key， 黑客截获后再把黑客自己Server的pub_key发送给Server A, Server A拿着这个pub_key加密了自己的私钥，之后又被黑客截获并解密，虽然这些工作对黑客来说很复杂，但这种情况是有可能发生的.\n> + 解决方法: CA 证书认证机构，一个中间商，给所有Server颁发证书,所有正常网站的证书都在这一个地方存储，当Server A 拿到 pub_key之后会向 CA 查询这个公钥是不是合法的是不是可以信任的，CA会查自己的数据库这个pub_key是哪个公司的，它的域名是什么，包括所有人是谁等各种信息在CA都有备案，CA告诉Server A这个pub_key是我颁发的没有问题，Server A再拿着这个公钥去通信, 有时候我们访问一些网站时候，https会显示红色警告，这就说明这个网站的证书不是通过CA认证过的，一般是自己生成的.\n\n### 服务发现\n> * Kube-proxy(ClusterIP)： 为Pod创建虚拟IP，只能在集群内部访问，并且是固定的, 只要Service不删除，这个IP是不变的.\n> * Kube-proxy(NodePort): 在每个Node上都启一个线程端口，把服务暴露在节点上，这样就可以让集群外的服务通过Node IP 和 NodePort去访问集群内的服务.\n> * Kube-DNS: Kubernetes的一个插件，负责集群内部的DNS解析，目的是让集群内部的Pod之间通过名字去访问\n\n### 环境搭建\n> * 官方推荐使用Kubeadmin进行方便快捷的搭建.\n> * 网上找的个人搭建的Kubernetes, 在绿色网络环境下安装kubernetes集群，并在安装过程中加深对Kubernetes组件以及架构的理解.\n>  - [https://github.com/liuyi01/kubernetes-starter](https://github.com/liuyi01/kubernetes-starter)\n\n### Download & Install\n> 官网步骤: https://kubernetes.io/docs/tasks/tools/install-kubectl/\n\n#### 机器配置\n搭建K8s集群只用了一台安装Ubuntu18.04的酷睿机器.\n> 1. Ubuntu18.04宿主主机上 download & install virtualbox\n> $ apt-get install virtualbox\n> 2. 下载Ubuntu18.04镜像: http://releases.ubuntu.com/18.04/ 选择 ubuntu-18.04.4-live-server-amd64.iso 2020-02-03 18:36 870M\tServer install image for 64-bit PC (AMD64) computers (standard download)\n> 3. 用virtualbox安装两台Ubuntu18.04虚拟机\n>  * 虚拟机server01 作为 master; \n>  * 虚拟机server02 作为 worker01; \n>  * 宿主主机 作为 worker02\n> 每台虚拟机 内存要大于等于 2 G ，CPU核数需要大于等于 4 核\n\n#### 每个node都在 /etc/environment 添加如下信息\n> http_proxy=\"http://child-prc.intel.com:913/\"\n> https_proxy=\"http://child-prc.intel.com:913/\"\n> ftp_proxy=\"ftp://child-prc.intel.com:913/\"\n> no_proxy=\"K8S_MASTER_IP,K8S_MASTER_HostName\"  如: no_proxy=\"10.67.108.200,hci-node01\"  // [iotg@hci-node01 ~]$\n\n\n#### kubeadm, kubelet, kubectl\n> 每台机器都安装kubeadm(二进制文件工具), kubelet(服务), master上安装kubectl(二进制文件工具), 也可以在需要kubectl控制k8s资源的node上也安装(也就是下载或拷贝)kubectl二进制文件工具.\n\n\t$ sudo apt-get update && sudo apt-get install -y apt-transport-https gnupg2\n\t$ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n\t$ echo \"deb https://apt.kubernetes.io/ kubernetes-xenial main\" | sudo tee -a /etc/apt/sources.list.d/kubernetes.list\n\t$ sudo apt-get update\n\t$ sudo apt-get install -y kubectl\n\t$ sudo apt-get install -y kubeadm\n\t$ sudo apt-get install -y kubelet\n\t$ kubeadm version\t\t// 通过 kubectl 命令行客户端向运行在主节点上的 Kubemetes API 服务器发出 REST 请求以与集群交互\n\t$ kubectl version\t\t// 客户端工具\n\t$ kubelet --version\t\t// kubelet是一个服务，可通过systemctl restart kubelet重启服务，每台master和worker节点都需要安装\n\t$ systemctl enable --now kubelet\n\t$ kubeadm reset\n\t$ sudo hostnamectl set-hostname master-node //修改机器名字, 重开终端就可以看到机器名变了\n\n#### 机器环境配置\n\n\t关闭交换区, K8s认为swap性能开销比较大, 性能会大幅降低, 使用swap做云基础架构会减少性能, 因此k8s关闭swap\n\t另外重新装系统OS时候就可以不给swap分配分区.\n\t$ swapoff -a\t\t\t// 临时关闭交换区，$ free -h 可以查看 Swap: 0B...\n\t$ vim /etc/fstab  // 设置重启后自动关闭swapoff, 将含有swap的那一行前面加\"#\"注释掉就可以了\n\t  /dev/mapper/centos-swap swap                    swap    defaults        0 0\n\t$ sed -i '/swap/d' /etc/fstab\t//永久关闭\n\t\n\t关闭防火墙\n\t$ systemctl stop firewalld.service\n\t$ systemctl status firewalld.service\t// 查看防火墙是否有 Active: inactive (dead) since......\n\t$ systemctl disable firewalld \t\t\t// 设置开机不启动防火墙\n\t$ sysctl net.bridge.bridge-nf-call-iptables=1\n\t$ sysctl net.bridge.bridge-nf-call-ip6tables=1\n> Iptables原理\n> linux的防火墙由netfilter和iptables组成\n> 用户空间的iptables制定防火墙规则，内核空间的netfilter实现防火墙功能netfilter（内核空间）位于Linux内核中的包过滤防火墙功能体系，称为Linux防火墙的“内核态”\n> iptables(用户空间)位于/sbin/iptables，是用来管理防火墙的命令的工具，为防火墙体系提供过滤规则/策略，决定如何过滤或处理到达防火墙主机的数据包，称为Linux防火墙的“用户态\"\n\n\t关闭selinux:\t\t// 限制访问linux资源文件上下文\n\t$ getenforce\t\t\t// 查看是否disabled\n\t$ setenforce 0\t\t\t//临时关闭selinux(Security-Enhanced Linux), 终端会输出\"setenforce: SELinux is disabled\"\n\t$ vim /etc/selinux/config --> 将 SELINUX=permissive 改为 SELINUX=disabled, 设置重启后自动关闭selinux\n\t$ sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config\t//永久关闭(试了好像没反应): \n\n#### 同步系统时间\n> 涉及到验证签发的证书的有效性, 如果签发证书的服务器时间比使用证书的服务器时间早, 就会导致校验不成功或证书错误, 一直等到使用证书的服务器时间也运行到证书开始生效的时间后才会解决这个问题.\n\n\t$ ntpdate time.windows.com \t\t// 同步 windows 系统时间\n\n#### 设置docker的proxy\n\t$ mkdir docker.service.d\n\t$ vim /etc/systemd/system/docker.service.d/http-proxy.conf\n\n\t[Service]\n\tEnvironment=\"HTTP_PROXY=http://child-prc.intel.com:913/\"\n\tEnvironment=\"HTTPS_PROXY=http://child-prc.intel.com:913/\"\n\n#### 安装镜像\n\t$ docker images\n\t$ docker pull gcr.io/google_containers/kube-apiserver-amd64:v1.9.3\n\t$ docker pull gcr.io/google_containers/kube-controller-manager-amd64:v1.9.3\n\t$ docker pull gcr.io/google_containers/kube-scheduler-amd64:v1.9.3\n\n#### 添加机器到K8s集群\n> 1. 在Master主机 server01 上运行\n\n\t$ kubeadm init\n\n返回部分数据如下\n\n\t......\n\tThen you can join any number of worker nodes by running the following on each as root:\n\t\n\tkubeadm join 10.239.141.112:6443 --token uvm0zr.ndg144wcga276j16 \\\n\t    --discovery-token-ca-cert-hash sha256:e1535452b32ed4039fa2f261197c0b91179fb168e8da3dd58b99fc11fe2213b8\n\troot@server01:~#\n> 添加kubeadm部署k8s后生成的administrator访问证书到环境变量或~/.kube目录, 使得root或其它user登陆后可以通过kubectl访问或生成k8s资源如pod等, 有如下两种方式.\n\n第一种:\n\n\t$ export KUBECONFIG=/etc/kubernetes/admin.conf\n\t$ echo \"export KUBECONFIG=/etc/kubernetes/admin.conf\" | tee -a ~/.bashrc\n\t$ source ~/.bashrc\n第二种(其它user而非root登陆后需要做如下操作才能通过kubectl访问或生成k8s资源如pod等):\n\n\t$ mkdir -p $HOME/.kube\n\t$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n\t$ sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\n添加容器之间的通信网络, 第三方资源weave, 官网上也推荐部署其它几种通信网络方式\n\n\t$ kubectl apply -f https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')\n\n> 2. 之后用上面命令返回的 kubeadm join 10.239.141.112:6443 --t ... 复制 并 在其它node机器(server02和宿主主机) 上运行就可以把node加进上面创建的Cluster了\n\n#### 在master server01 机器上查看集群节点信息\n\n\t$ kubectl get nodes\n\t$ kubectl get namespaces\n\n#### 查看node节点信息\n\n\t$ kubectl describe node server02\n\n### 重新(reset)在原来(机器上搭建k8s集群操作\n> 主机名和IP解析, 通过主机名访问机器, 修改下各个节点 /etc/hosts 文件内容(实验环境没有修改，跳过这个步骤), 也可以只在master上配置, 因为很多操作都是在master上执行\n\n\t......\n\t10.239.141.106 server01\n\t10.239.140.184 server02\n\t10.239.140.186 alpha\n> 1. 需要在master节点上执行 \n\n\t$ rm -rf /etc/kubernetes/pki/etcd/\n\t$ rm -rf /var/lib/etcd\n\t$ rm -rf $HOME/.kube\n\t$ kubeadm reset\n\t$ swapoff -a\n\t$ setenforce 0\n\t$ systemctl stop firewalld.service\n\t$ sysctl net.bridge.bridge-nf-call-iptables=1\n\t$ kubeadm init, 再用返回的 \"kubeadm join...\" 在其它节点执行\n\t$ echo \"export KUBECONFIG=/etc/kubernetes/admin.conf\" | tee -a ~/.bashrc\n\t$ source ~/.bashrc\n\n> 2. 在worker节点执行:\n\n\t$ systemctl enable docker.service\n\t$ kubeadm reset\n\t$ swapoff -a\n\t$ setenforce 0\n\t$ systemctl stop firewalld.service\n\t$ sysctl net.bridge.bridge-nf-call-iptables=1\n\t$ systemctl daemon-reload\t\t// 重新加载 systemctl 的配置文件\n\t$ systemctl restart kubelet\n\t // $ iptables -F && iptables -t nat -F && iptables -t mangle -F && iptables -X\t\t// will reset iptables\n\t$ kubeadm join ......\n\n> 3. 再次在master节点上执行\n如果不执行下面命令安装weave pod, kube-system命名空间下的coredns会一直处于containercreating状态.\n\n\t$ kubectl apply -f https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')\n\n### k8s重新生成token\n主机上执行如下命令，主机IP:10.239.140.186\n\n\t$ kubeadm token create\n\tv6rgnu.ydqgkuujayykkanv\n\t\n\t$ kubeadm token list\n\tTOKEN                     TTL   EXPIRES                     USAGES                   DESCRIPTION   EXTRA GROUPS\n\tv6rgnu.ydqgkuujayykkanv   23h   2020-05-30T13:24:41+08:00   authentication,signing   <none>        system:bootstrappers:kubeadm:default-node-token\n\n\t$ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //'\n\tbe6606e3e081afc6f9785fbe0e129e048e5a2a5557cb2e7747d727edd20c6ed4\n用上面master主机上生成的token在worker节点执行如下命令:\n\n\t$ kubeadm reset\n\t$ swapoff -a\n\t$ setenforce 0\n\t$ systemctl stop firewalld.service\n\t$ sysctl net.bridge.bridge-nf-call-iptables=1\n\t$ sysctl net.bridge.bridge-nf-call-ip6tables=1\n\t$ kubeadm join --token v6rgnu.ydqgkuujayykkanv --discovery-token-ca-cert-hash sha256:be6606e3e081afc6f9785fbe0e129e048e5a2a5557cb2e7747d727edd20c6ed4  10.239.140.186:6443\n\n### k8s命令自动补全\n\n\t$ yum install bash-completion\n\t$ echo \"source <(kubectl completion bash)\" >> ~/.bashrc\n\t$ source ~/.bashrc\n试试 输入 `kubectl get n` 按 `tab` 查看提示.\n\n### Additional\n\n#### 重新reset K8s集群，然后kubeadm init遇到如下问题\n#### 问题1\n> [kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get http://localhost:10248/healthz: dial tcp [::1]:10248: connect: connection refused.\n解决方法:\n\n\t$ systemctl restart docker\n\t$ rm -rf /etc/systemd/system/kubelet.service.d/*\n\t$ systemctl daemon-reload\n\n#### 问题2\nUnable to connect to the server: x509: certificate signed by unknown authority\n需要删除上一次部署后cp到~/.kube的证书文件, 再重新部署一遍k8s集群\n\n\t$ rm -rf $HOME/.kube\n\n#### 问题3\nThe connection to the server localhost:8080 was refused - did you specify the right host or port?\n需要添加administrator访问证书\n第一种:\n\n\t$ export KUBECONFIG=/etc/kubernetes/admin.conf\n\t$ echo \"export KUBECONFIG=/etc/kubernetes/admin.conf\" | tee -a ~/.bashrc\n\t$ source ~/.bashrc\n第二种:\n\n\t$ mkdir -p $HOME/.kube\n\t$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n\t$ sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\n#### 问题n\nhttps://istio.io/docs/examples/bookinfo/\nIstio 部署bookinfo 到bookinfo命名空间， 发现只部署了svc，RS，但是没有部署pod.\n\n\t$ kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml -n bookinfo\n用以下命令可以查看出错信息, 发现是webhook相关错误\n\n\t$ kubectl describe rs/RS-NAME -n bookinfo\n\n解决方法是注释掉kubernetes的proxy\n\n/etc/kubernetes/manifests/kube-apiserver.yaml\n\n\t env:\t\t\t\t\t\t\t\t\t// K8s安装会用系统的proxy，加#注释掉.\n\t#- name: HTTP_PROXY\n\t#  value: http://child-prc.intel.com:913\n\t#- name: https_proxy\n\t#  value: http://child-prc.intel.com:913\n\t#- name: http_proxy\n\t#  value: http://child-prc.intel.com:913\n\t#- name: HTTPS_PROXY\n\t#  value: http://child-prc.intel.com:913\n\t - name: no_proxy\n\t   value: 10.239.140.186,10.239.140.200\t\t// master和一个worker节点的NodeIP.\n稍等一会$ kubectl get po -n bookinfo 就可以看到pod慢慢部署成功了.\n\n\n\n\n","source":"_posts/micro_service/01_kubernetes_build.md","raw":"---\ntitle: 01 Kubernetes build\ntags:\n- kubernetes\ncategories:\n- microService\n- kubernetes\ntop: 1\n---\n\n### Kubernetes 简介\n ![](1.JPG)\n ![](2.JPG)\n \n### 主要特征\n> * 以服务为中心: 不关心服务运行的环境和细节，所以构建在kubernetes上的系统可以部署在物理机、虚拟机、公有云、私有云，在什么地方运行都是无差别的.\n> * 自动化: 在kubernetes里的系统可以自动扩缩容、自动升级、更新、部署. 比如:\n>  - K8s收到某个指令后，会触发调度流程，选中目标节点，部署或者停止响应服务.\n>  - 如果有新的pod启动，会被自动加入负载均衡器，自动生效\n>  - 服务运行过程中，K8s会定期的检查它们的实例数，以及这些实例的状态是否正常，当发现某个实例不可用的时候会自动销毁不可用的实例然后重新调度一个新的实例，以上所有都是自动化完成，不需要人工参与.\n\n### 架构\n![](K8s_arch1.JPG)\n\n### Kubernetes VS Docker\n> K8s可以看成是Docker的上层架构, 就像是javaee和java的关系,Java是一问语言，J2EE是Java语言的一门使用技术，Java为J2EE提供了库和语法，J2EE使用Java的库和语法应用在WEB上。这是概念性的区别。\n> * Java SE（Java Platform，Standard Edition）。Java SE 以前称为 J2SE。它允许开发和部署在桌面、服务器、嵌入式环境和实时环境中使用的 Java 应用程序。Java SE 包含了支持 Java Web 服务开发的类，并为 Java Platform，Enterprise Edition（Java EE）提供基础。\n> * Java EE（Java Platform，Enterprise Edition）。这个版本以前称为 J2EE。企业版本帮助开发和部署可移植、健壮、可伸缩且安全的服务器端 Java 应用程序。Java EE 是在 Java SE 的基础上构建的，它提供 Web 服务、组件模型、管理和通信 API，可以用来实现企业级的面向服务体系结构（service-oriented architecture，SOA）和 Web 2.0 应用程序。\n> * Java ME（Java Platform，Micro Edition）。这个版本以前称为 J2ME。Java ME 为在移动设备和嵌入式设备（比如手机、PDA、电视机顶盒和打印机）上运行的应用程序提供一个健壮且灵活的环境。Java ME 包括灵活的用户界面、健壮的安全模型、许多内置的网络协议以及对可以动态下载的连网和离线应用程序的丰富支持。基于 Java ME 规范的应用程序只需编写一次，就可以用于许多设备，而且可以利用每个设备的本机功能。\n\n> K8s是以Docker技术的标准为基础去打造一个全新的分布式架构系统，K8s不是一定要依赖Docker，Docker是一个产品，而Docker技术是一些列的标准，只要实现了这些标准的产品都可以替代Docker，所以说K8s在底层可以支持它自己的容器技术并且经过Google的持续优化，号称在某些方面做得比Docker更加优秀，所以用不用Docker可以自己选择.\n\n\n### 核心概念\n![](3.JPG)\n![](4.JPG)\n![](5.JPG)\n\n### Label 标签\n> POD，Deployment，Node等都可以打标签启到标识作用.\n\n### POD (可以称为实例)\n> * 所有的服务，所有的应用最终都是跑在Pod中,Pod是Kubernetes概念中最小的单元，可以理解为是Kubernetes的一个原子.\n> * POD 里面可以有一个或多个容器，\n> * POD里面所有的容器都是运行在一台机器上\n> * POD里面的容器共享网络，有一个唯一的IP\n> * POD里面都会有一个容器叫做Pause容器\n>  - 有特定的image镜像比如pause:v1.0\n>  - 作为根容器，把POD里其它的容器都link到一起，当我们的业务里面有两个或多个容器关系非常紧密，这时候就可以考虑把它们放到同一个POD里\n>  - 负责整个POD的健康检查，然后汇报给K8s\n![](K8s_arch2.JPG)\n![](K8s_arch3.JPG)\n \n### Pod 通讯\n> * Pod内容器之间通讯: 通过localhost加上端口就可以访问.\n![](Pod_communication1.JPG)\n\n> * 同一个Node上不同Pod之间的通讯: 同一个Node上的Pod，它们默认的路由都是Docker0，都关联在同一个Docker0网桥，地址网段是相同的，它们之间可以直接通过网桥进行通讯，访问方式是可以通过 Pod IP 直接进行访问.\n![](Pod_communication2.JPG)\n\n> 不同Node不同Pod直接通讯: Pod的IP不能冲突，Pod的IP和Node的IP关联起来，通过关联让Pod之间可以通讯.\n![](Pod_communication3.JPG)\n\n### Service\n![](K8s_arch4.JPG)\n> Pod具体运行在某个Node上\n> Service在Pod外再包一层IP\n> 当某个Pod提供服务出现问题，会在其它地方再启动一个Pod和新的Pod的IP，我们还可以通过Service IP找到新的Pod\n> 上面2台Node，3个Pod可以看做同一个应用的多个副本，对一个应用进行扩容，从一个实例扩成三个实例对外提供相同服务\n> Service除了上面可以定位到Pod地址外还可以对Pod地址进行负载均衡，比如轮训访问每个Pod\n> Pod也不一定是一模一样的，也可以是同一个应用的不同版本\n\n> 通过什么方式来确定哪些Pod是一个Service? 怎么定位哪个Pod或哪几个Pod属于某个Service?\n> Kubernetes使用的是Laber Selector\n> 通过配置好的Service的Select()，选择标签然后自动寻找POD, Service 对外有一个ClusterIP(Kube-proxy)，其它服务或者Client客户端就可以通过ClusterIP访问到这个Service，进而访问到最底层的POD服务\n\n### ReplicaSet(RS)副本集 (副本集这一层运行的程序可以称为应用)\n> RS是POD的上一层, 管理关联POD，如果应用运行过程中某个POD出现了异常或异常退出，RS就会保证副本始终为R，会在另一台机器重新调度一个POD\n\n### Deployment\n> * 扩容: 如对一个应用(Pod)扩容，把1个Pod扩容成四个实例，扩容的是Pod而不是Service, 4个Pod拥有相同标签，ServiceIP不变并对这4个Pod实行负载均衡\n![](Pod_Scaling.JPG)\n\n> * 滚动更新: 一个旧的应用(RS这一层)运行了两个实例(两个POD), 更新这个应用的时候，Deployment会自动帮我们创建一个RS，并且滚动的先启动一个新版本的不改变服务的POD, 修改的可能是image(login-image:V1->V2),这时候Deployment管理的是三个实例(3个POD)，新的POD启动完成，健康检查结束，会停掉原来的POD并删掉，然后RS会再新建一个与另一个旧版本提供相同服务的POD，然后停掉另外一个旧版本POD，旧版POD停掉之后Deployment会清理掉管理旧版本的RS, 服务更新完成.\n![](Rolling_update1.JPG)\n![](Rolling_update2.JPG)\n\n### 架构设计 \n![](k8s_architecture1.JPG)\n![](k8s_architecture2.JPG)\n\n### 密码学原理\n> * 对称加密:\n![](Symmetric_encryption.JPG)\n \n> * 非对称加密:\n![](Asymmetric_encryption.JPG)\n\n### 服务之间通信加密:\n![](6.JPG)\n> 非对称加密非常复杂，不管是加密还是解密都非常耗时， 如果每次通信都进行非对称加密性能损耗是无法接受的\n> 对称加密性能非常高，因此考虑把两者结合在一起来通信\n> * Server B 公开了自己的公钥pub_key, 任何人都可以看到\n> * 第一次通信，Server A 用Server B的pub_key 加密自己的秘钥，把秘钥变成密文，然后发到Server B，除了Server B可以用自己的私钥解密看到是对称加密的秘钥，中间黑客因为没有Server B的私钥因此无法解密, Server B 就知道要跟 Server A 进行对称加密的通信，并且使用的就是这个秘钥\n> * 之后通信, Server A就可以用发送给Server B 的秘钥对要发送的信息使用对称加密算法进行加密变成密文，然后发送给Server B， Server B收到信息后再用第一次拿到的秘钥进行对称加密算法解密.\n> - 上面的就是 SSL/TLS 协议， https底层就是通过这两个协议进行通信.\n> + 上面有个不完美地方，Server B公开pub_key， 黑客截获后再把黑客自己Server的pub_key发送给Server A, Server A拿着这个pub_key加密了自己的私钥，之后又被黑客截获并解密，虽然这些工作对黑客来说很复杂，但这种情况是有可能发生的.\n> + 解决方法: CA 证书认证机构，一个中间商，给所有Server颁发证书,所有正常网站的证书都在这一个地方存储，当Server A 拿到 pub_key之后会向 CA 查询这个公钥是不是合法的是不是可以信任的，CA会查自己的数据库这个pub_key是哪个公司的，它的域名是什么，包括所有人是谁等各种信息在CA都有备案，CA告诉Server A这个pub_key是我颁发的没有问题，Server A再拿着这个公钥去通信, 有时候我们访问一些网站时候，https会显示红色警告，这就说明这个网站的证书不是通过CA认证过的，一般是自己生成的.\n\n### 服务发现\n> * Kube-proxy(ClusterIP)： 为Pod创建虚拟IP，只能在集群内部访问，并且是固定的, 只要Service不删除，这个IP是不变的.\n> * Kube-proxy(NodePort): 在每个Node上都启一个线程端口，把服务暴露在节点上，这样就可以让集群外的服务通过Node IP 和 NodePort去访问集群内的服务.\n> * Kube-DNS: Kubernetes的一个插件，负责集群内部的DNS解析，目的是让集群内部的Pod之间通过名字去访问\n\n### 环境搭建\n> * 官方推荐使用Kubeadmin进行方便快捷的搭建.\n> * 网上找的个人搭建的Kubernetes, 在绿色网络环境下安装kubernetes集群，并在安装过程中加深对Kubernetes组件以及架构的理解.\n>  - [https://github.com/liuyi01/kubernetes-starter](https://github.com/liuyi01/kubernetes-starter)\n\n### Download & Install\n> 官网步骤: https://kubernetes.io/docs/tasks/tools/install-kubectl/\n\n#### 机器配置\n搭建K8s集群只用了一台安装Ubuntu18.04的酷睿机器.\n> 1. Ubuntu18.04宿主主机上 download & install virtualbox\n> $ apt-get install virtualbox\n> 2. 下载Ubuntu18.04镜像: http://releases.ubuntu.com/18.04/ 选择 ubuntu-18.04.4-live-server-amd64.iso 2020-02-03 18:36 870M\tServer install image for 64-bit PC (AMD64) computers (standard download)\n> 3. 用virtualbox安装两台Ubuntu18.04虚拟机\n>  * 虚拟机server01 作为 master; \n>  * 虚拟机server02 作为 worker01; \n>  * 宿主主机 作为 worker02\n> 每台虚拟机 内存要大于等于 2 G ，CPU核数需要大于等于 4 核\n\n#### 每个node都在 /etc/environment 添加如下信息\n> http_proxy=\"http://child-prc.intel.com:913/\"\n> https_proxy=\"http://child-prc.intel.com:913/\"\n> ftp_proxy=\"ftp://child-prc.intel.com:913/\"\n> no_proxy=\"K8S_MASTER_IP,K8S_MASTER_HostName\"  如: no_proxy=\"10.67.108.200,hci-node01\"  // [iotg@hci-node01 ~]$\n\n\n#### kubeadm, kubelet, kubectl\n> 每台机器都安装kubeadm(二进制文件工具), kubelet(服务), master上安装kubectl(二进制文件工具), 也可以在需要kubectl控制k8s资源的node上也安装(也就是下载或拷贝)kubectl二进制文件工具.\n\n\t$ sudo apt-get update && sudo apt-get install -y apt-transport-https gnupg2\n\t$ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n\t$ echo \"deb https://apt.kubernetes.io/ kubernetes-xenial main\" | sudo tee -a /etc/apt/sources.list.d/kubernetes.list\n\t$ sudo apt-get update\n\t$ sudo apt-get install -y kubectl\n\t$ sudo apt-get install -y kubeadm\n\t$ sudo apt-get install -y kubelet\n\t$ kubeadm version\t\t// 通过 kubectl 命令行客户端向运行在主节点上的 Kubemetes API 服务器发出 REST 请求以与集群交互\n\t$ kubectl version\t\t// 客户端工具\n\t$ kubelet --version\t\t// kubelet是一个服务，可通过systemctl restart kubelet重启服务，每台master和worker节点都需要安装\n\t$ systemctl enable --now kubelet\n\t$ kubeadm reset\n\t$ sudo hostnamectl set-hostname master-node //修改机器名字, 重开终端就可以看到机器名变了\n\n#### 机器环境配置\n\n\t关闭交换区, K8s认为swap性能开销比较大, 性能会大幅降低, 使用swap做云基础架构会减少性能, 因此k8s关闭swap\n\t另外重新装系统OS时候就可以不给swap分配分区.\n\t$ swapoff -a\t\t\t// 临时关闭交换区，$ free -h 可以查看 Swap: 0B...\n\t$ vim /etc/fstab  // 设置重启后自动关闭swapoff, 将含有swap的那一行前面加\"#\"注释掉就可以了\n\t  /dev/mapper/centos-swap swap                    swap    defaults        0 0\n\t$ sed -i '/swap/d' /etc/fstab\t//永久关闭\n\t\n\t关闭防火墙\n\t$ systemctl stop firewalld.service\n\t$ systemctl status firewalld.service\t// 查看防火墙是否有 Active: inactive (dead) since......\n\t$ systemctl disable firewalld \t\t\t// 设置开机不启动防火墙\n\t$ sysctl net.bridge.bridge-nf-call-iptables=1\n\t$ sysctl net.bridge.bridge-nf-call-ip6tables=1\n> Iptables原理\n> linux的防火墙由netfilter和iptables组成\n> 用户空间的iptables制定防火墙规则，内核空间的netfilter实现防火墙功能netfilter（内核空间）位于Linux内核中的包过滤防火墙功能体系，称为Linux防火墙的“内核态”\n> iptables(用户空间)位于/sbin/iptables，是用来管理防火墙的命令的工具，为防火墙体系提供过滤规则/策略，决定如何过滤或处理到达防火墙主机的数据包，称为Linux防火墙的“用户态\"\n\n\t关闭selinux:\t\t// 限制访问linux资源文件上下文\n\t$ getenforce\t\t\t// 查看是否disabled\n\t$ setenforce 0\t\t\t//临时关闭selinux(Security-Enhanced Linux), 终端会输出\"setenforce: SELinux is disabled\"\n\t$ vim /etc/selinux/config --> 将 SELINUX=permissive 改为 SELINUX=disabled, 设置重启后自动关闭selinux\n\t$ sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config\t//永久关闭(试了好像没反应): \n\n#### 同步系统时间\n> 涉及到验证签发的证书的有效性, 如果签发证书的服务器时间比使用证书的服务器时间早, 就会导致校验不成功或证书错误, 一直等到使用证书的服务器时间也运行到证书开始生效的时间后才会解决这个问题.\n\n\t$ ntpdate time.windows.com \t\t// 同步 windows 系统时间\n\n#### 设置docker的proxy\n\t$ mkdir docker.service.d\n\t$ vim /etc/systemd/system/docker.service.d/http-proxy.conf\n\n\t[Service]\n\tEnvironment=\"HTTP_PROXY=http://child-prc.intel.com:913/\"\n\tEnvironment=\"HTTPS_PROXY=http://child-prc.intel.com:913/\"\n\n#### 安装镜像\n\t$ docker images\n\t$ docker pull gcr.io/google_containers/kube-apiserver-amd64:v1.9.3\n\t$ docker pull gcr.io/google_containers/kube-controller-manager-amd64:v1.9.3\n\t$ docker pull gcr.io/google_containers/kube-scheduler-amd64:v1.9.3\n\n#### 添加机器到K8s集群\n> 1. 在Master主机 server01 上运行\n\n\t$ kubeadm init\n\n返回部分数据如下\n\n\t......\n\tThen you can join any number of worker nodes by running the following on each as root:\n\t\n\tkubeadm join 10.239.141.112:6443 --token uvm0zr.ndg144wcga276j16 \\\n\t    --discovery-token-ca-cert-hash sha256:e1535452b32ed4039fa2f261197c0b91179fb168e8da3dd58b99fc11fe2213b8\n\troot@server01:~#\n> 添加kubeadm部署k8s后生成的administrator访问证书到环境变量或~/.kube目录, 使得root或其它user登陆后可以通过kubectl访问或生成k8s资源如pod等, 有如下两种方式.\n\n第一种:\n\n\t$ export KUBECONFIG=/etc/kubernetes/admin.conf\n\t$ echo \"export KUBECONFIG=/etc/kubernetes/admin.conf\" | tee -a ~/.bashrc\n\t$ source ~/.bashrc\n第二种(其它user而非root登陆后需要做如下操作才能通过kubectl访问或生成k8s资源如pod等):\n\n\t$ mkdir -p $HOME/.kube\n\t$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n\t$ sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\n添加容器之间的通信网络, 第三方资源weave, 官网上也推荐部署其它几种通信网络方式\n\n\t$ kubectl apply -f https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')\n\n> 2. 之后用上面命令返回的 kubeadm join 10.239.141.112:6443 --t ... 复制 并 在其它node机器(server02和宿主主机) 上运行就可以把node加进上面创建的Cluster了\n\n#### 在master server01 机器上查看集群节点信息\n\n\t$ kubectl get nodes\n\t$ kubectl get namespaces\n\n#### 查看node节点信息\n\n\t$ kubectl describe node server02\n\n### 重新(reset)在原来(机器上搭建k8s集群操作\n> 主机名和IP解析, 通过主机名访问机器, 修改下各个节点 /etc/hosts 文件内容(实验环境没有修改，跳过这个步骤), 也可以只在master上配置, 因为很多操作都是在master上执行\n\n\t......\n\t10.239.141.106 server01\n\t10.239.140.184 server02\n\t10.239.140.186 alpha\n> 1. 需要在master节点上执行 \n\n\t$ rm -rf /etc/kubernetes/pki/etcd/\n\t$ rm -rf /var/lib/etcd\n\t$ rm -rf $HOME/.kube\n\t$ kubeadm reset\n\t$ swapoff -a\n\t$ setenforce 0\n\t$ systemctl stop firewalld.service\n\t$ sysctl net.bridge.bridge-nf-call-iptables=1\n\t$ kubeadm init, 再用返回的 \"kubeadm join...\" 在其它节点执行\n\t$ echo \"export KUBECONFIG=/etc/kubernetes/admin.conf\" | tee -a ~/.bashrc\n\t$ source ~/.bashrc\n\n> 2. 在worker节点执行:\n\n\t$ systemctl enable docker.service\n\t$ kubeadm reset\n\t$ swapoff -a\n\t$ setenforce 0\n\t$ systemctl stop firewalld.service\n\t$ sysctl net.bridge.bridge-nf-call-iptables=1\n\t$ systemctl daemon-reload\t\t// 重新加载 systemctl 的配置文件\n\t$ systemctl restart kubelet\n\t // $ iptables -F && iptables -t nat -F && iptables -t mangle -F && iptables -X\t\t// will reset iptables\n\t$ kubeadm join ......\n\n> 3. 再次在master节点上执行\n如果不执行下面命令安装weave pod, kube-system命名空间下的coredns会一直处于containercreating状态.\n\n\t$ kubectl apply -f https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')\n\n### k8s重新生成token\n主机上执行如下命令，主机IP:10.239.140.186\n\n\t$ kubeadm token create\n\tv6rgnu.ydqgkuujayykkanv\n\t\n\t$ kubeadm token list\n\tTOKEN                     TTL   EXPIRES                     USAGES                   DESCRIPTION   EXTRA GROUPS\n\tv6rgnu.ydqgkuujayykkanv   23h   2020-05-30T13:24:41+08:00   authentication,signing   <none>        system:bootstrappers:kubeadm:default-node-token\n\n\t$ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //'\n\tbe6606e3e081afc6f9785fbe0e129e048e5a2a5557cb2e7747d727edd20c6ed4\n用上面master主机上生成的token在worker节点执行如下命令:\n\n\t$ kubeadm reset\n\t$ swapoff -a\n\t$ setenforce 0\n\t$ systemctl stop firewalld.service\n\t$ sysctl net.bridge.bridge-nf-call-iptables=1\n\t$ sysctl net.bridge.bridge-nf-call-ip6tables=1\n\t$ kubeadm join --token v6rgnu.ydqgkuujayykkanv --discovery-token-ca-cert-hash sha256:be6606e3e081afc6f9785fbe0e129e048e5a2a5557cb2e7747d727edd20c6ed4  10.239.140.186:6443\n\n### k8s命令自动补全\n\n\t$ yum install bash-completion\n\t$ echo \"source <(kubectl completion bash)\" >> ~/.bashrc\n\t$ source ~/.bashrc\n试试 输入 `kubectl get n` 按 `tab` 查看提示.\n\n### Additional\n\n#### 重新reset K8s集群，然后kubeadm init遇到如下问题\n#### 问题1\n> [kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get http://localhost:10248/healthz: dial tcp [::1]:10248: connect: connection refused.\n解决方法:\n\n\t$ systemctl restart docker\n\t$ rm -rf /etc/systemd/system/kubelet.service.d/*\n\t$ systemctl daemon-reload\n\n#### 问题2\nUnable to connect to the server: x509: certificate signed by unknown authority\n需要删除上一次部署后cp到~/.kube的证书文件, 再重新部署一遍k8s集群\n\n\t$ rm -rf $HOME/.kube\n\n#### 问题3\nThe connection to the server localhost:8080 was refused - did you specify the right host or port?\n需要添加administrator访问证书\n第一种:\n\n\t$ export KUBECONFIG=/etc/kubernetes/admin.conf\n\t$ echo \"export KUBECONFIG=/etc/kubernetes/admin.conf\" | tee -a ~/.bashrc\n\t$ source ~/.bashrc\n第二种:\n\n\t$ mkdir -p $HOME/.kube\n\t$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n\t$ sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\n#### 问题n\nhttps://istio.io/docs/examples/bookinfo/\nIstio 部署bookinfo 到bookinfo命名空间， 发现只部署了svc，RS，但是没有部署pod.\n\n\t$ kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml -n bookinfo\n用以下命令可以查看出错信息, 发现是webhook相关错误\n\n\t$ kubectl describe rs/RS-NAME -n bookinfo\n\n解决方法是注释掉kubernetes的proxy\n\n/etc/kubernetes/manifests/kube-apiserver.yaml\n\n\t env:\t\t\t\t\t\t\t\t\t// K8s安装会用系统的proxy，加#注释掉.\n\t#- name: HTTP_PROXY\n\t#  value: http://child-prc.intel.com:913\n\t#- name: https_proxy\n\t#  value: http://child-prc.intel.com:913\n\t#- name: http_proxy\n\t#  value: http://child-prc.intel.com:913\n\t#- name: HTTPS_PROXY\n\t#  value: http://child-prc.intel.com:913\n\t - name: no_proxy\n\t   value: 10.239.140.186,10.239.140.200\t\t// master和一个worker节点的NodeIP.\n稍等一会$ kubectl get po -n bookinfo 就可以看到pod慢慢部署成功了.\n\n\n\n\n","slug":"micro_service/01_kubernetes_build","published":1,"date":"2020-08-12T16:05:47.340Z","updated":"2020-08-17T13:08:45.105Z","_id":"ckdt3hmg30041hohxfufqcm73","comments":1,"layout":"post","photos":[],"link":"","content":"<h3 id=\"Kubernetes-简介\"><a href=\"#Kubernetes-简介\" class=\"headerlink\" title=\"Kubernetes 简介\"></a>Kubernetes 简介</h3><p> <img src=\"1.JPG\" alt=\"\"><br> <img src=\"2.JPG\" alt=\"\"></p>\n<h3 id=\"主要特征\"><a href=\"#主要特征\" class=\"headerlink\" title=\"主要特征\"></a>主要特征</h3><blockquote>\n<ul>\n<li>以服务为中心: 不关心服务运行的环境和细节，所以构建在kubernetes上的系统可以部署在物理机、虚拟机、公有云、私有云，在什么地方运行都是无差别的.</li>\n<li>自动化: 在kubernetes里的系统可以自动扩缩容、自动升级、更新、部署. 比如:<ul>\n<li>K8s收到某个指令后，会触发调度流程，选中目标节点，部署或者停止响应服务.</li>\n<li>如果有新的pod启动，会被自动加入负载均衡器，自动生效</li>\n<li>服务运行过程中，K8s会定期的检查它们的实例数，以及这些实例的状态是否正常，当发现某个实例不可用的时候会自动销毁不可用的实例然后重新调度一个新的实例，以上所有都是自动化完成，不需要人工参与.</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<h3 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h3><p><img src=\"K8s_arch1.JPG\" alt=\"\"></p>\n<h3 id=\"Kubernetes-VS-Docker\"><a href=\"#Kubernetes-VS-Docker\" class=\"headerlink\" title=\"Kubernetes VS Docker\"></a>Kubernetes VS Docker</h3><blockquote>\n<p>K8s可以看成是Docker的上层架构, 就像是javaee和java的关系,Java是一问语言，J2EE是Java语言的一门使用技术，Java为J2EE提供了库和语法，J2EE使用Java的库和语法应用在WEB上。这是概念性的区别。</p>\n<ul>\n<li>Java SE（Java Platform，Standard Edition）。Java SE 以前称为 J2SE。它允许开发和部署在桌面、服务器、嵌入式环境和实时环境中使用的 Java 应用程序。Java SE 包含了支持 Java Web 服务开发的类，并为 Java Platform，Enterprise Edition（Java EE）提供基础。</li>\n<li>Java EE（Java Platform，Enterprise Edition）。这个版本以前称为 J2EE。企业版本帮助开发和部署可移植、健壮、可伸缩且安全的服务器端 Java 应用程序。Java EE 是在 Java SE 的基础上构建的，它提供 Web 服务、组件模型、管理和通信 API，可以用来实现企业级的面向服务体系结构（service-oriented architecture，SOA）和 Web 2.0 应用程序。</li>\n<li>Java ME（Java Platform，Micro Edition）。这个版本以前称为 J2ME。Java ME 为在移动设备和嵌入式设备（比如手机、PDA、电视机顶盒和打印机）上运行的应用程序提供一个健壮且灵活的环境。Java ME 包括灵活的用户界面、健壮的安全模型、许多内置的网络协议以及对可以动态下载的连网和离线应用程序的丰富支持。基于 Java ME 规范的应用程序只需编写一次，就可以用于许多设备，而且可以利用每个设备的本机功能。</li>\n</ul>\n</blockquote>\n<blockquote>\n<p>K8s是以Docker技术的标准为基础去打造一个全新的分布式架构系统，K8s不是一定要依赖Docker，Docker是一个产品，而Docker技术是一些列的标准，只要实现了这些标准的产品都可以替代Docker，所以说K8s在底层可以支持它自己的容器技术并且经过Google的持续优化，号称在某些方面做得比Docker更加优秀，所以用不用Docker可以自己选择.</p>\n</blockquote>\n<h3 id=\"核心概念\"><a href=\"#核心概念\" class=\"headerlink\" title=\"核心概念\"></a>核心概念</h3><p><img src=\"3.JPG\" alt=\"\"><br><img src=\"4.JPG\" alt=\"\"><br><img src=\"5.JPG\" alt=\"\"></p>\n<h3 id=\"Label-标签\"><a href=\"#Label-标签\" class=\"headerlink\" title=\"Label 标签\"></a>Label 标签</h3><blockquote>\n<p>POD，Deployment，Node等都可以打标签启到标识作用.</p>\n</blockquote>\n<h3 id=\"POD-可以称为实例\"><a href=\"#POD-可以称为实例\" class=\"headerlink\" title=\"POD (可以称为实例)\"></a>POD (可以称为实例)</h3><blockquote>\n<ul>\n<li>所有的服务，所有的应用最终都是跑在Pod中,Pod是Kubernetes概念中最小的单元，可以理解为是Kubernetes的一个原子.</li>\n<li>POD 里面可以有一个或多个容器，</li>\n<li>POD里面所有的容器都是运行在一台机器上</li>\n<li>POD里面的容器共享网络，有一个唯一的IP</li>\n<li>POD里面都会有一个容器叫做Pause容器<ul>\n<li>有特定的image镜像比如pause:v1.0</li>\n<li>作为根容器，把POD里其它的容器都link到一起，当我们的业务里面有两个或多个容器关系非常紧密，这时候就可以考虑把它们放到同一个POD里</li>\n<li>负责整个POD的健康检查，然后汇报给K8s<br><img src=\"K8s_arch2.JPG\" alt=\"\"><br><img src=\"K8s_arch3.JPG\" alt=\"\"></li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<h3 id=\"Pod-通讯\"><a href=\"#Pod-通讯\" class=\"headerlink\" title=\"Pod 通讯\"></a>Pod 通讯</h3><blockquote>\n<ul>\n<li>Pod内容器之间通讯: 通过localhost加上端口就可以访问.<br><img src=\"Pod_communication1.JPG\" alt=\"\"></li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>同一个Node上不同Pod之间的通讯: 同一个Node上的Pod，它们默认的路由都是Docker0，都关联在同一个Docker0网桥，地址网段是相同的，它们之间可以直接通过网桥进行通讯，访问方式是可以通过 Pod IP 直接进行访问.<br><img src=\"Pod_communication2.JPG\" alt=\"\"></li>\n</ul>\n</blockquote>\n<blockquote>\n<p>不同Node不同Pod直接通讯: Pod的IP不能冲突，Pod的IP和Node的IP关联起来，通过关联让Pod之间可以通讯.<br><img src=\"Pod_communication3.JPG\" alt=\"\"></p>\n</blockquote>\n<h3 id=\"Service\"><a href=\"#Service\" class=\"headerlink\" title=\"Service\"></a>Service</h3><p><img src=\"K8s_arch4.JPG\" alt=\"\"></p>\n<blockquote>\n<p>Pod具体运行在某个Node上<br>Service在Pod外再包一层IP<br>当某个Pod提供服务出现问题，会在其它地方再启动一个Pod和新的Pod的IP，我们还可以通过Service IP找到新的Pod<br>上面2台Node，3个Pod可以看做同一个应用的多个副本，对一个应用进行扩容，从一个实例扩成三个实例对外提供相同服务<br>Service除了上面可以定位到Pod地址外还可以对Pod地址进行负载均衡，比如轮训访问每个Pod<br>Pod也不一定是一模一样的，也可以是同一个应用的不同版本</p>\n</blockquote>\n<blockquote>\n<p>通过什么方式来确定哪些Pod是一个Service? 怎么定位哪个Pod或哪几个Pod属于某个Service?<br>Kubernetes使用的是Laber Selector<br>通过配置好的Service的Select()，选择标签然后自动寻找POD, Service 对外有一个ClusterIP(Kube-proxy)，其它服务或者Client客户端就可以通过ClusterIP访问到这个Service，进而访问到最底层的POD服务</p>\n</blockquote>\n<h3 id=\"ReplicaSet-RS-副本集-副本集这一层运行的程序可以称为应用\"><a href=\"#ReplicaSet-RS-副本集-副本集这一层运行的程序可以称为应用\" class=\"headerlink\" title=\"ReplicaSet(RS)副本集 (副本集这一层运行的程序可以称为应用)\"></a>ReplicaSet(RS)副本集 (副本集这一层运行的程序可以称为应用)</h3><blockquote>\n<p>RS是POD的上一层, 管理关联POD，如果应用运行过程中某个POD出现了异常或异常退出，RS就会保证副本始终为R，会在另一台机器重新调度一个POD</p>\n</blockquote>\n<h3 id=\"Deployment\"><a href=\"#Deployment\" class=\"headerlink\" title=\"Deployment\"></a>Deployment</h3><blockquote>\n<ul>\n<li>扩容: 如对一个应用(Pod)扩容，把1个Pod扩容成四个实例，扩容的是Pod而不是Service, 4个Pod拥有相同标签，ServiceIP不变并对这4个Pod实行负载均衡<br><img src=\"Pod_Scaling.JPG\" alt=\"\"></li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>滚动更新: 一个旧的应用(RS这一层)运行了两个实例(两个POD), 更新这个应用的时候，Deployment会自动帮我们创建一个RS，并且滚动的先启动一个新版本的不改变服务的POD, 修改的可能是image(login-image:V1-&gt;V2),这时候Deployment管理的是三个实例(3个POD)，新的POD启动完成，健康检查结束，会停掉原来的POD并删掉，然后RS会再新建一个与另一个旧版本提供相同服务的POD，然后停掉另外一个旧版本POD，旧版POD停掉之后Deployment会清理掉管理旧版本的RS, 服务更新完成.<br><img src=\"Rolling_update1.JPG\" alt=\"\"><br><img src=\"Rolling_update2.JPG\" alt=\"\"></li>\n</ul>\n</blockquote>\n<h3 id=\"架构设计\"><a href=\"#架构设计\" class=\"headerlink\" title=\"架构设计\"></a>架构设计</h3><p><img src=\"k8s_architecture1.JPG\" alt=\"\"><br><img src=\"k8s_architecture2.JPG\" alt=\"\"></p>\n<h3 id=\"密码学原理\"><a href=\"#密码学原理\" class=\"headerlink\" title=\"密码学原理\"></a>密码学原理</h3><blockquote>\n<ul>\n<li>对称加密:<br><img src=\"Symmetric_encryption.JPG\" alt=\"\"></li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>非对称加密:<br><img src=\"Asymmetric_encryption.JPG\" alt=\"\"></li>\n</ul>\n</blockquote>\n<h3 id=\"服务之间通信加密\"><a href=\"#服务之间通信加密\" class=\"headerlink\" title=\"服务之间通信加密:\"></a>服务之间通信加密:</h3><p><img src=\"6.JPG\" alt=\"\"></p>\n<blockquote>\n<p>非对称加密非常复杂，不管是加密还是解密都非常耗时， 如果每次通信都进行非对称加密性能损耗是无法接受的<br>对称加密性能非常高，因此考虑把两者结合在一起来通信</p>\n<ul>\n<li>Server B 公开了自己的公钥pub_key, 任何人都可以看到</li>\n<li>第一次通信，Server A 用Server B的pub_key 加密自己的秘钥，把秘钥变成密文，然后发到Server B，除了Server B可以用自己的私钥解密看到是对称加密的秘钥，中间黑客因为没有Server B的私钥因此无法解密, Server B 就知道要跟 Server A 进行对称加密的通信，并且使用的就是这个秘钥</li>\n<li>之后通信, Server A就可以用发送给Server B 的秘钥对要发送的信息使用对称加密算法进行加密变成密文，然后发送给Server B， Server B收到信息后再用第一次拿到的秘钥进行对称加密算法解密.</li>\n</ul>\n<ul>\n<li>上面的就是 SSL/TLS 协议， https底层就是通过这两个协议进行通信.</li>\n</ul>\n<ul>\n<li>上面有个不完美地方，Server B公开pub_key， 黑客截获后再把黑客自己Server的pub_key发送给Server A, Server A拿着这个pub_key加密了自己的私钥，之后又被黑客截获并解密，虽然这些工作对黑客来说很复杂，但这种情况是有可能发生的.</li>\n<li>解决方法: CA 证书认证机构，一个中间商，给所有Server颁发证书,所有正常网站的证书都在这一个地方存储，当Server A 拿到 pub_key之后会向 CA 查询这个公钥是不是合法的是不是可以信任的，CA会查自己的数据库这个pub_key是哪个公司的，它的域名是什么，包括所有人是谁等各种信息在CA都有备案，CA告诉Server A这个pub_key是我颁发的没有问题，Server A再拿着这个公钥去通信, 有时候我们访问一些网站时候，https会显示红色警告，这就说明这个网站的证书不是通过CA认证过的，一般是自己生成的.</li>\n</ul>\n</blockquote>\n<h3 id=\"服务发现\"><a href=\"#服务发现\" class=\"headerlink\" title=\"服务发现\"></a>服务发现</h3><blockquote>\n<ul>\n<li>Kube-proxy(ClusterIP)： 为Pod创建虚拟IP，只能在集群内部访问，并且是固定的, 只要Service不删除，这个IP是不变的.</li>\n<li>Kube-proxy(NodePort): 在每个Node上都启一个线程端口，把服务暴露在节点上，这样就可以让集群外的服务通过Node IP 和 NodePort去访问集群内的服务.</li>\n<li>Kube-DNS: Kubernetes的一个插件，负责集群内部的DNS解析，目的是让集群内部的Pod之间通过名字去访问</li>\n</ul>\n</blockquote>\n<h3 id=\"环境搭建\"><a href=\"#环境搭建\" class=\"headerlink\" title=\"环境搭建\"></a>环境搭建</h3><blockquote>\n<ul>\n<li>官方推荐使用Kubeadmin进行方便快捷的搭建.</li>\n<li>网上找的个人搭建的Kubernetes, 在绿色网络环境下安装kubernetes集群，并在安装过程中加深对Kubernetes组件以及架构的理解.<ul>\n<li><a href=\"https://github.com/liuyi01/kubernetes-starter\" target=\"_blank\" rel=\"noopener\">https://github.com/liuyi01/kubernetes-starter</a></li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<h3 id=\"Download-amp-Install\"><a href=\"#Download-amp-Install\" class=\"headerlink\" title=\"Download &amp; Install\"></a>Download &amp; Install</h3><blockquote>\n<p>官网步骤: <a href=\"https://kubernetes.io/docs/tasks/tools/install-kubectl/\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/docs/tasks/tools/install-kubectl/</a></p>\n</blockquote>\n<h4 id=\"机器配置\"><a href=\"#机器配置\" class=\"headerlink\" title=\"机器配置\"></a>机器配置</h4><p>搭建K8s集群只用了一台安装Ubuntu18.04的酷睿机器.</p>\n<blockquote>\n<ol>\n<li>Ubuntu18.04宿主主机上 download &amp; install virtualbox<br>$ apt-get install virtualbox</li>\n<li>下载Ubuntu18.04镜像: <a href=\"http://releases.ubuntu.com/18.04/\" target=\"_blank\" rel=\"noopener\">http://releases.ubuntu.com/18.04/</a> 选择 ubuntu-18.04.4-live-server-amd64.iso 2020-02-03 18:36 870M    Server install image for 64-bit PC (AMD64) computers (standard download)</li>\n<li>用virtualbox安装两台Ubuntu18.04虚拟机<ul>\n<li>虚拟机server01 作为 master; </li>\n<li>虚拟机server02 作为 worker01; </li>\n<li>宿主主机 作为 worker02<br>每台虚拟机 内存要大于等于 2 G ，CPU核数需要大于等于 4 核</li>\n</ul>\n</li>\n</ol>\n</blockquote>\n<h4 id=\"每个node都在-etc-environment-添加如下信息\"><a href=\"#每个node都在-etc-environment-添加如下信息\" class=\"headerlink\" title=\"每个node都在 /etc/environment 添加如下信息\"></a>每个node都在 /etc/environment 添加如下信息</h4><blockquote>\n<p>http_proxy=”<a href=\"http://child-prc.intel.com:913/&quot;\" target=\"_blank\" rel=\"noopener\">http://child-prc.intel.com:913/&quot;</a><br>https_proxy=”<a href=\"http://child-prc.intel.com:913/&quot;\" target=\"_blank\" rel=\"noopener\">http://child-prc.intel.com:913/&quot;</a><br>ftp_proxy=”<a href=\"ftp://child-prc.intel.com:913/&quot;\" target=\"_blank\" rel=\"noopener\">ftp://child-prc.intel.com:913/&quot;</a><br>no_proxy=”K8S_MASTER_IP,K8S_MASTER_HostName”  如: no_proxy=”10.67.108.200,hci-node01”  // [iotg@hci-node01 ~]$</p>\n</blockquote>\n<h4 id=\"kubeadm-kubelet-kubectl\"><a href=\"#kubeadm-kubelet-kubectl\" class=\"headerlink\" title=\"kubeadm, kubelet, kubectl\"></a>kubeadm, kubelet, kubectl</h4><blockquote>\n<p>每台机器都安装kubeadm(二进制文件工具), kubelet(服务), master上安装kubectl(二进制文件工具), 也可以在需要kubectl控制k8s资源的node上也安装(也就是下载或拷贝)kubectl二进制文件工具.</p>\n</blockquote>\n<pre><code>$ sudo apt-get update &amp;&amp; sudo apt-get install -y apt-transport-https gnupg2\n$ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n$ echo &quot;deb https://apt.kubernetes.io/ kubernetes-xenial main&quot; | sudo tee -a /etc/apt/sources.list.d/kubernetes.list\n$ sudo apt-get update\n$ sudo apt-get install -y kubectl\n$ sudo apt-get install -y kubeadm\n$ sudo apt-get install -y kubelet\n$ kubeadm version        // 通过 kubectl 命令行客户端向运行在主节点上的 Kubemetes API 服务器发出 REST 请求以与集群交互\n$ kubectl version        // 客户端工具\n$ kubelet --version        // kubelet是一个服务，可通过systemctl restart kubelet重启服务，每台master和worker节点都需要安装\n$ systemctl enable --now kubelet\n$ kubeadm reset\n$ sudo hostnamectl set-hostname master-node //修改机器名字, 重开终端就可以看到机器名变了</code></pre><h4 id=\"机器环境配置\"><a href=\"#机器环境配置\" class=\"headerlink\" title=\"机器环境配置\"></a>机器环境配置</h4><pre><code>关闭交换区, K8s认为swap性能开销比较大, 性能会大幅降低, 使用swap做云基础架构会减少性能, 因此k8s关闭swap\n另外重新装系统OS时候就可以不给swap分配分区.\n$ swapoff -a            // 临时关闭交换区，$ free -h 可以查看 Swap: 0B...\n$ vim /etc/fstab  // 设置重启后自动关闭swapoff, 将含有swap的那一行前面加&quot;#&quot;注释掉就可以了\n  /dev/mapper/centos-swap swap                    swap    defaults        0 0\n$ sed -i &apos;/swap/d&apos; /etc/fstab    //永久关闭\n\n关闭防火墙\n$ systemctl stop firewalld.service\n$ systemctl status firewalld.service    // 查看防火墙是否有 Active: inactive (dead) since......\n$ systemctl disable firewalld             // 设置开机不启动防火墙\n$ sysctl net.bridge.bridge-nf-call-iptables=1\n$ sysctl net.bridge.bridge-nf-call-ip6tables=1</code></pre><blockquote>\n<p>Iptables原理<br>linux的防火墙由netfilter和iptables组成<br>用户空间的iptables制定防火墙规则，内核空间的netfilter实现防火墙功能netfilter（内核空间）位于Linux内核中的包过滤防火墙功能体系，称为Linux防火墙的“内核态”<br>iptables(用户空间)位于/sbin/iptables，是用来管理防火墙的命令的工具，为防火墙体系提供过滤规则/策略，决定如何过滤或处理到达防火墙主机的数据包，称为Linux防火墙的“用户态”</p>\n</blockquote>\n<pre><code>关闭selinux:        // 限制访问linux资源文件上下文\n$ getenforce            // 查看是否disabled\n$ setenforce 0            //临时关闭selinux(Security-Enhanced Linux), 终端会输出&quot;setenforce: SELinux is disabled&quot;\n$ vim /etc/selinux/config --&gt; 将 SELINUX=permissive 改为 SELINUX=disabled, 设置重启后自动关闭selinux\n$ sed -i &apos;s/^SELINUX=enforcing$/SELINUX=permissive/&apos; /etc/selinux/config    //永久关闭(试了好像没反应): </code></pre><h4 id=\"同步系统时间\"><a href=\"#同步系统时间\" class=\"headerlink\" title=\"同步系统时间\"></a>同步系统时间</h4><blockquote>\n<p>涉及到验证签发的证书的有效性, 如果签发证书的服务器时间比使用证书的服务器时间早, 就会导致校验不成功或证书错误, 一直等到使用证书的服务器时间也运行到证书开始生效的时间后才会解决这个问题.</p>\n</blockquote>\n<pre><code>$ ntpdate time.windows.com         // 同步 windows 系统时间</code></pre><h4 id=\"设置docker的proxy\"><a href=\"#设置docker的proxy\" class=\"headerlink\" title=\"设置docker的proxy\"></a>设置docker的proxy</h4><pre><code>$ mkdir docker.service.d\n$ vim /etc/systemd/system/docker.service.d/http-proxy.conf\n\n[Service]\nEnvironment=&quot;HTTP_PROXY=http://child-prc.intel.com:913/&quot;\nEnvironment=&quot;HTTPS_PROXY=http://child-prc.intel.com:913/&quot;</code></pre><h4 id=\"安装镜像\"><a href=\"#安装镜像\" class=\"headerlink\" title=\"安装镜像\"></a>安装镜像</h4><pre><code>$ docker images\n$ docker pull gcr.io/google_containers/kube-apiserver-amd64:v1.9.3\n$ docker pull gcr.io/google_containers/kube-controller-manager-amd64:v1.9.3\n$ docker pull gcr.io/google_containers/kube-scheduler-amd64:v1.9.3</code></pre><h4 id=\"添加机器到K8s集群\"><a href=\"#添加机器到K8s集群\" class=\"headerlink\" title=\"添加机器到K8s集群\"></a>添加机器到K8s集群</h4><blockquote>\n<ol>\n<li>在Master主机 server01 上运行</li>\n</ol>\n</blockquote>\n<pre><code>$ kubeadm init</code></pre><p>返回部分数据如下</p>\n<pre><code>......\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join 10.239.141.112:6443 --token uvm0zr.ndg144wcga276j16 \\\n    --discovery-token-ca-cert-hash sha256:e1535452b32ed4039fa2f261197c0b91179fb168e8da3dd58b99fc11fe2213b8\nroot@server01:~#</code></pre><blockquote>\n<p>添加kubeadm部署k8s后生成的administrator访问证书到环境变量或~/.kube目录, 使得root或其它user登陆后可以通过kubectl访问或生成k8s资源如pod等, 有如下两种方式.</p>\n</blockquote>\n<p>第一种:</p>\n<pre><code>$ export KUBECONFIG=/etc/kubernetes/admin.conf\n$ echo &quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot; | tee -a ~/.bashrc\n$ source ~/.bashrc</code></pre><p>第二种(其它user而非root登陆后需要做如下操作才能通过kubectl访问或生成k8s资源如pod等):</p>\n<pre><code>$ mkdir -p $HOME/.kube\n$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n$ sudo chown $(id -u):$(id -g) $HOME/.kube/config</code></pre><p>添加容器之间的通信网络, 第三方资源weave, 官网上也推荐部署其它几种通信网络方式</p>\n<pre><code>$ kubectl apply -f https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d &apos;\\n&apos;)</code></pre><blockquote>\n<ol start=\"2\">\n<li>之后用上面命令返回的 kubeadm join 10.239.141.112:6443 –t … 复制 并 在其它node机器(server02和宿主主机) 上运行就可以把node加进上面创建的Cluster了</li>\n</ol>\n</blockquote>\n<h4 id=\"在master-server01-机器上查看集群节点信息\"><a href=\"#在master-server01-机器上查看集群节点信息\" class=\"headerlink\" title=\"在master server01 机器上查看集群节点信息\"></a>在master server01 机器上查看集群节点信息</h4><pre><code>$ kubectl get nodes\n$ kubectl get namespaces</code></pre><h4 id=\"查看node节点信息\"><a href=\"#查看node节点信息\" class=\"headerlink\" title=\"查看node节点信息\"></a>查看node节点信息</h4><pre><code>$ kubectl describe node server02</code></pre><h3 id=\"重新-reset-在原来-机器上搭建k8s集群操作\"><a href=\"#重新-reset-在原来-机器上搭建k8s集群操作\" class=\"headerlink\" title=\"重新(reset)在原来(机器上搭建k8s集群操作\"></a>重新(reset)在原来(机器上搭建k8s集群操作</h3><blockquote>\n<p>主机名和IP解析, 通过主机名访问机器, 修改下各个节点 /etc/hosts 文件内容(实验环境没有修改，跳过这个步骤), 也可以只在master上配置, 因为很多操作都是在master上执行</p>\n</blockquote>\n<pre><code>......\n10.239.141.106 server01\n10.239.140.184 server02\n10.239.140.186 alpha</code></pre><blockquote>\n<ol>\n<li>需要在master节点上执行 </li>\n</ol>\n</blockquote>\n<pre><code>$ rm -rf /etc/kubernetes/pki/etcd/\n$ rm -rf /var/lib/etcd\n$ rm -rf $HOME/.kube\n$ kubeadm reset\n$ swapoff -a\n$ setenforce 0\n$ systemctl stop firewalld.service\n$ sysctl net.bridge.bridge-nf-call-iptables=1\n$ kubeadm init, 再用返回的 &quot;kubeadm join...&quot; 在其它节点执行\n$ echo &quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot; | tee -a ~/.bashrc\n$ source ~/.bashrc</code></pre><blockquote>\n<ol start=\"2\">\n<li>在worker节点执行:</li>\n</ol>\n</blockquote>\n<pre><code>$ systemctl enable docker.service\n$ kubeadm reset\n$ swapoff -a\n$ setenforce 0\n$ systemctl stop firewalld.service\n$ sysctl net.bridge.bridge-nf-call-iptables=1\n$ systemctl daemon-reload        // 重新加载 systemctl 的配置文件\n$ systemctl restart kubelet\n // $ iptables -F &amp;&amp; iptables -t nat -F &amp;&amp; iptables -t mangle -F &amp;&amp; iptables -X        // will reset iptables\n$ kubeadm join ......</code></pre><blockquote>\n<ol start=\"3\">\n<li>再次在master节点上执行<br>如果不执行下面命令安装weave pod, kube-system命名空间下的coredns会一直处于containercreating状态.</li>\n</ol>\n</blockquote>\n<pre><code>$ kubectl apply -f https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d &apos;\\n&apos;)</code></pre><h3 id=\"k8s重新生成token\"><a href=\"#k8s重新生成token\" class=\"headerlink\" title=\"k8s重新生成token\"></a>k8s重新生成token</h3><p>主机上执行如下命令，主机IP:10.239.140.186</p>\n<pre><code>$ kubeadm token create\nv6rgnu.ydqgkuujayykkanv\n\n$ kubeadm token list\nTOKEN                     TTL   EXPIRES                     USAGES                   DESCRIPTION   EXTRA GROUPS\nv6rgnu.ydqgkuujayykkanv   23h   2020-05-30T13:24:41+08:00   authentication,signing   &lt;none&gt;        system:bootstrappers:kubeadm:default-node-token\n\n$ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &apos;s/^.* //&apos;\nbe6606e3e081afc6f9785fbe0e129e048e5a2a5557cb2e7747d727edd20c6ed4</code></pre><p>用上面master主机上生成的token在worker节点执行如下命令:</p>\n<pre><code>$ kubeadm reset\n$ swapoff -a\n$ setenforce 0\n$ systemctl stop firewalld.service\n$ sysctl net.bridge.bridge-nf-call-iptables=1\n$ sysctl net.bridge.bridge-nf-call-ip6tables=1\n$ kubeadm join --token v6rgnu.ydqgkuujayykkanv --discovery-token-ca-cert-hash sha256:be6606e3e081afc6f9785fbe0e129e048e5a2a5557cb2e7747d727edd20c6ed4  10.239.140.186:6443</code></pre><h3 id=\"k8s命令自动补全\"><a href=\"#k8s命令自动补全\" class=\"headerlink\" title=\"k8s命令自动补全\"></a>k8s命令自动补全</h3><pre><code>$ yum install bash-completion\n$ echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc\n$ source ~/.bashrc</code></pre><p>试试 输入 <code>kubectl get n</code> 按 <code>tab</code> 查看提示.</p>\n<h3 id=\"Additional\"><a href=\"#Additional\" class=\"headerlink\" title=\"Additional\"></a>Additional</h3><h4 id=\"重新reset-K8s集群，然后kubeadm-init遇到如下问题\"><a href=\"#重新reset-K8s集群，然后kubeadm-init遇到如下问题\" class=\"headerlink\" title=\"重新reset K8s集群，然后kubeadm init遇到如下问题\"></a>重新reset K8s集群，然后kubeadm init遇到如下问题</h4><h4 id=\"问题1\"><a href=\"#问题1\" class=\"headerlink\" title=\"问题1\"></a>问题1</h4><blockquote>\n<p>[kubelet-check] The HTTP call equal to ‘curl -sSL <a href=\"http://localhost:10248/healthz&#39;\" target=\"_blank\" rel=\"noopener\">http://localhost:10248/healthz&#39;</a> failed with error: Get <a href=\"http://localhost:10248/healthz\" target=\"_blank\" rel=\"noopener\">http://localhost:10248/healthz</a>: dial tcp [::1]:10248: connect: connection refused.<br>解决方法:</p>\n</blockquote>\n<pre><code>$ systemctl restart docker\n$ rm -rf /etc/systemd/system/kubelet.service.d/*\n$ systemctl daemon-reload</code></pre><h4 id=\"问题2\"><a href=\"#问题2\" class=\"headerlink\" title=\"问题2\"></a>问题2</h4><p>Unable to connect to the server: x509: certificate signed by unknown authority<br>需要删除上一次部署后cp到~/.kube的证书文件, 再重新部署一遍k8s集群</p>\n<pre><code>$ rm -rf $HOME/.kube</code></pre><h4 id=\"问题3\"><a href=\"#问题3\" class=\"headerlink\" title=\"问题3\"></a>问题3</h4><p>The connection to the server localhost:8080 was refused - did you specify the right host or port?<br>需要添加administrator访问证书<br>第一种:</p>\n<pre><code>$ export KUBECONFIG=/etc/kubernetes/admin.conf\n$ echo &quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot; | tee -a ~/.bashrc\n$ source ~/.bashrc</code></pre><p>第二种:</p>\n<pre><code>$ mkdir -p $HOME/.kube\n$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n$ sudo chown $(id -u):$(id -g) $HOME/.kube/config</code></pre><h4 id=\"问题n\"><a href=\"#问题n\" class=\"headerlink\" title=\"问题n\"></a>问题n</h4><p><a href=\"https://istio.io/docs/examples/bookinfo/\" target=\"_blank\" rel=\"noopener\">https://istio.io/docs/examples/bookinfo/</a><br>Istio 部署bookinfo 到bookinfo命名空间， 发现只部署了svc，RS，但是没有部署pod.</p>\n<pre><code>$ kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml -n bookinfo</code></pre><p>用以下命令可以查看出错信息, 发现是webhook相关错误</p>\n<pre><code>$ kubectl describe rs/RS-NAME -n bookinfo</code></pre><p>解决方法是注释掉kubernetes的proxy</p>\n<p>/etc/kubernetes/manifests/kube-apiserver.yaml</p>\n<pre><code> env:                                    // K8s安装会用系统的proxy，加#注释掉.\n#- name: HTTP_PROXY\n#  value: http://child-prc.intel.com:913\n#- name: https_proxy\n#  value: http://child-prc.intel.com:913\n#- name: http_proxy\n#  value: http://child-prc.intel.com:913\n#- name: HTTPS_PROXY\n#  value: http://child-prc.intel.com:913\n - name: no_proxy\n   value: 10.239.140.186,10.239.140.200        // master和一个worker节点的NodeIP.</code></pre><p>稍等一会$ kubectl get po -n bookinfo 就可以看到pod慢慢部署成功了.</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Kubernetes-简介\"><a href=\"#Kubernetes-简介\" class=\"headerlink\" title=\"Kubernetes 简介\"></a>Kubernetes 简介</h3><p> <img src=\"1.JPG\" alt=\"\"><br> <img src=\"2.JPG\" alt=\"\"></p>\n<h3 id=\"主要特征\"><a href=\"#主要特征\" class=\"headerlink\" title=\"主要特征\"></a>主要特征</h3><blockquote>\n<ul>\n<li>以服务为中心: 不关心服务运行的环境和细节，所以构建在kubernetes上的系统可以部署在物理机、虚拟机、公有云、私有云，在什么地方运行都是无差别的.</li>\n<li>自动化: 在kubernetes里的系统可以自动扩缩容、自动升级、更新、部署. 比如:<ul>\n<li>K8s收到某个指令后，会触发调度流程，选中目标节点，部署或者停止响应服务.</li>\n<li>如果有新的pod启动，会被自动加入负载均衡器，自动生效</li>\n<li>服务运行过程中，K8s会定期的检查它们的实例数，以及这些实例的状态是否正常，当发现某个实例不可用的时候会自动销毁不可用的实例然后重新调度一个新的实例，以上所有都是自动化完成，不需要人工参与.</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<h3 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h3><p><img src=\"K8s_arch1.JPG\" alt=\"\"></p>\n<h3 id=\"Kubernetes-VS-Docker\"><a href=\"#Kubernetes-VS-Docker\" class=\"headerlink\" title=\"Kubernetes VS Docker\"></a>Kubernetes VS Docker</h3><blockquote>\n<p>K8s可以看成是Docker的上层架构, 就像是javaee和java的关系,Java是一问语言，J2EE是Java语言的一门使用技术，Java为J2EE提供了库和语法，J2EE使用Java的库和语法应用在WEB上。这是概念性的区别。</p>\n<ul>\n<li>Java SE（Java Platform，Standard Edition）。Java SE 以前称为 J2SE。它允许开发和部署在桌面、服务器、嵌入式环境和实时环境中使用的 Java 应用程序。Java SE 包含了支持 Java Web 服务开发的类，并为 Java Platform，Enterprise Edition（Java EE）提供基础。</li>\n<li>Java EE（Java Platform，Enterprise Edition）。这个版本以前称为 J2EE。企业版本帮助开发和部署可移植、健壮、可伸缩且安全的服务器端 Java 应用程序。Java EE 是在 Java SE 的基础上构建的，它提供 Web 服务、组件模型、管理和通信 API，可以用来实现企业级的面向服务体系结构（service-oriented architecture，SOA）和 Web 2.0 应用程序。</li>\n<li>Java ME（Java Platform，Micro Edition）。这个版本以前称为 J2ME。Java ME 为在移动设备和嵌入式设备（比如手机、PDA、电视机顶盒和打印机）上运行的应用程序提供一个健壮且灵活的环境。Java ME 包括灵活的用户界面、健壮的安全模型、许多内置的网络协议以及对可以动态下载的连网和离线应用程序的丰富支持。基于 Java ME 规范的应用程序只需编写一次，就可以用于许多设备，而且可以利用每个设备的本机功能。</li>\n</ul>\n</blockquote>\n<blockquote>\n<p>K8s是以Docker技术的标准为基础去打造一个全新的分布式架构系统，K8s不是一定要依赖Docker，Docker是一个产品，而Docker技术是一些列的标准，只要实现了这些标准的产品都可以替代Docker，所以说K8s在底层可以支持它自己的容器技术并且经过Google的持续优化，号称在某些方面做得比Docker更加优秀，所以用不用Docker可以自己选择.</p>\n</blockquote>\n<h3 id=\"核心概念\"><a href=\"#核心概念\" class=\"headerlink\" title=\"核心概念\"></a>核心概念</h3><p><img src=\"3.JPG\" alt=\"\"><br><img src=\"4.JPG\" alt=\"\"><br><img src=\"5.JPG\" alt=\"\"></p>\n<h3 id=\"Label-标签\"><a href=\"#Label-标签\" class=\"headerlink\" title=\"Label 标签\"></a>Label 标签</h3><blockquote>\n<p>POD，Deployment，Node等都可以打标签启到标识作用.</p>\n</blockquote>\n<h3 id=\"POD-可以称为实例\"><a href=\"#POD-可以称为实例\" class=\"headerlink\" title=\"POD (可以称为实例)\"></a>POD (可以称为实例)</h3><blockquote>\n<ul>\n<li>所有的服务，所有的应用最终都是跑在Pod中,Pod是Kubernetes概念中最小的单元，可以理解为是Kubernetes的一个原子.</li>\n<li>POD 里面可以有一个或多个容器，</li>\n<li>POD里面所有的容器都是运行在一台机器上</li>\n<li>POD里面的容器共享网络，有一个唯一的IP</li>\n<li>POD里面都会有一个容器叫做Pause容器<ul>\n<li>有特定的image镜像比如pause:v1.0</li>\n<li>作为根容器，把POD里其它的容器都link到一起，当我们的业务里面有两个或多个容器关系非常紧密，这时候就可以考虑把它们放到同一个POD里</li>\n<li>负责整个POD的健康检查，然后汇报给K8s<br><img src=\"K8s_arch2.JPG\" alt=\"\"><br><img src=\"K8s_arch3.JPG\" alt=\"\"></li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<h3 id=\"Pod-通讯\"><a href=\"#Pod-通讯\" class=\"headerlink\" title=\"Pod 通讯\"></a>Pod 通讯</h3><blockquote>\n<ul>\n<li>Pod内容器之间通讯: 通过localhost加上端口就可以访问.<br><img src=\"Pod_communication1.JPG\" alt=\"\"></li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>同一个Node上不同Pod之间的通讯: 同一个Node上的Pod，它们默认的路由都是Docker0，都关联在同一个Docker0网桥，地址网段是相同的，它们之间可以直接通过网桥进行通讯，访问方式是可以通过 Pod IP 直接进行访问.<br><img src=\"Pod_communication2.JPG\" alt=\"\"></li>\n</ul>\n</blockquote>\n<blockquote>\n<p>不同Node不同Pod直接通讯: Pod的IP不能冲突，Pod的IP和Node的IP关联起来，通过关联让Pod之间可以通讯.<br><img src=\"Pod_communication3.JPG\" alt=\"\"></p>\n</blockquote>\n<h3 id=\"Service\"><a href=\"#Service\" class=\"headerlink\" title=\"Service\"></a>Service</h3><p><img src=\"K8s_arch4.JPG\" alt=\"\"></p>\n<blockquote>\n<p>Pod具体运行在某个Node上<br>Service在Pod外再包一层IP<br>当某个Pod提供服务出现问题，会在其它地方再启动一个Pod和新的Pod的IP，我们还可以通过Service IP找到新的Pod<br>上面2台Node，3个Pod可以看做同一个应用的多个副本，对一个应用进行扩容，从一个实例扩成三个实例对外提供相同服务<br>Service除了上面可以定位到Pod地址外还可以对Pod地址进行负载均衡，比如轮训访问每个Pod<br>Pod也不一定是一模一样的，也可以是同一个应用的不同版本</p>\n</blockquote>\n<blockquote>\n<p>通过什么方式来确定哪些Pod是一个Service? 怎么定位哪个Pod或哪几个Pod属于某个Service?<br>Kubernetes使用的是Laber Selector<br>通过配置好的Service的Select()，选择标签然后自动寻找POD, Service 对外有一个ClusterIP(Kube-proxy)，其它服务或者Client客户端就可以通过ClusterIP访问到这个Service，进而访问到最底层的POD服务</p>\n</blockquote>\n<h3 id=\"ReplicaSet-RS-副本集-副本集这一层运行的程序可以称为应用\"><a href=\"#ReplicaSet-RS-副本集-副本集这一层运行的程序可以称为应用\" class=\"headerlink\" title=\"ReplicaSet(RS)副本集 (副本集这一层运行的程序可以称为应用)\"></a>ReplicaSet(RS)副本集 (副本集这一层运行的程序可以称为应用)</h3><blockquote>\n<p>RS是POD的上一层, 管理关联POD，如果应用运行过程中某个POD出现了异常或异常退出，RS就会保证副本始终为R，会在另一台机器重新调度一个POD</p>\n</blockquote>\n<h3 id=\"Deployment\"><a href=\"#Deployment\" class=\"headerlink\" title=\"Deployment\"></a>Deployment</h3><blockquote>\n<ul>\n<li>扩容: 如对一个应用(Pod)扩容，把1个Pod扩容成四个实例，扩容的是Pod而不是Service, 4个Pod拥有相同标签，ServiceIP不变并对这4个Pod实行负载均衡<br><img src=\"Pod_Scaling.JPG\" alt=\"\"></li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>滚动更新: 一个旧的应用(RS这一层)运行了两个实例(两个POD), 更新这个应用的时候，Deployment会自动帮我们创建一个RS，并且滚动的先启动一个新版本的不改变服务的POD, 修改的可能是image(login-image:V1-&gt;V2),这时候Deployment管理的是三个实例(3个POD)，新的POD启动完成，健康检查结束，会停掉原来的POD并删掉，然后RS会再新建一个与另一个旧版本提供相同服务的POD，然后停掉另外一个旧版本POD，旧版POD停掉之后Deployment会清理掉管理旧版本的RS, 服务更新完成.<br><img src=\"Rolling_update1.JPG\" alt=\"\"><br><img src=\"Rolling_update2.JPG\" alt=\"\"></li>\n</ul>\n</blockquote>\n<h3 id=\"架构设计\"><a href=\"#架构设计\" class=\"headerlink\" title=\"架构设计\"></a>架构设计</h3><p><img src=\"k8s_architecture1.JPG\" alt=\"\"><br><img src=\"k8s_architecture2.JPG\" alt=\"\"></p>\n<h3 id=\"密码学原理\"><a href=\"#密码学原理\" class=\"headerlink\" title=\"密码学原理\"></a>密码学原理</h3><blockquote>\n<ul>\n<li>对称加密:<br><img src=\"Symmetric_encryption.JPG\" alt=\"\"></li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>非对称加密:<br><img src=\"Asymmetric_encryption.JPG\" alt=\"\"></li>\n</ul>\n</blockquote>\n<h3 id=\"服务之间通信加密\"><a href=\"#服务之间通信加密\" class=\"headerlink\" title=\"服务之间通信加密:\"></a>服务之间通信加密:</h3><p><img src=\"6.JPG\" alt=\"\"></p>\n<blockquote>\n<p>非对称加密非常复杂，不管是加密还是解密都非常耗时， 如果每次通信都进行非对称加密性能损耗是无法接受的<br>对称加密性能非常高，因此考虑把两者结合在一起来通信</p>\n<ul>\n<li>Server B 公开了自己的公钥pub_key, 任何人都可以看到</li>\n<li>第一次通信，Server A 用Server B的pub_key 加密自己的秘钥，把秘钥变成密文，然后发到Server B，除了Server B可以用自己的私钥解密看到是对称加密的秘钥，中间黑客因为没有Server B的私钥因此无法解密, Server B 就知道要跟 Server A 进行对称加密的通信，并且使用的就是这个秘钥</li>\n<li>之后通信, Server A就可以用发送给Server B 的秘钥对要发送的信息使用对称加密算法进行加密变成密文，然后发送给Server B， Server B收到信息后再用第一次拿到的秘钥进行对称加密算法解密.</li>\n</ul>\n<ul>\n<li>上面的就是 SSL/TLS 协议， https底层就是通过这两个协议进行通信.</li>\n</ul>\n<ul>\n<li>上面有个不完美地方，Server B公开pub_key， 黑客截获后再把黑客自己Server的pub_key发送给Server A, Server A拿着这个pub_key加密了自己的私钥，之后又被黑客截获并解密，虽然这些工作对黑客来说很复杂，但这种情况是有可能发生的.</li>\n<li>解决方法: CA 证书认证机构，一个中间商，给所有Server颁发证书,所有正常网站的证书都在这一个地方存储，当Server A 拿到 pub_key之后会向 CA 查询这个公钥是不是合法的是不是可以信任的，CA会查自己的数据库这个pub_key是哪个公司的，它的域名是什么，包括所有人是谁等各种信息在CA都有备案，CA告诉Server A这个pub_key是我颁发的没有问题，Server A再拿着这个公钥去通信, 有时候我们访问一些网站时候，https会显示红色警告，这就说明这个网站的证书不是通过CA认证过的，一般是自己生成的.</li>\n</ul>\n</blockquote>\n<h3 id=\"服务发现\"><a href=\"#服务发现\" class=\"headerlink\" title=\"服务发现\"></a>服务发现</h3><blockquote>\n<ul>\n<li>Kube-proxy(ClusterIP)： 为Pod创建虚拟IP，只能在集群内部访问，并且是固定的, 只要Service不删除，这个IP是不变的.</li>\n<li>Kube-proxy(NodePort): 在每个Node上都启一个线程端口，把服务暴露在节点上，这样就可以让集群外的服务通过Node IP 和 NodePort去访问集群内的服务.</li>\n<li>Kube-DNS: Kubernetes的一个插件，负责集群内部的DNS解析，目的是让集群内部的Pod之间通过名字去访问</li>\n</ul>\n</blockquote>\n<h3 id=\"环境搭建\"><a href=\"#环境搭建\" class=\"headerlink\" title=\"环境搭建\"></a>环境搭建</h3><blockquote>\n<ul>\n<li>官方推荐使用Kubeadmin进行方便快捷的搭建.</li>\n<li>网上找的个人搭建的Kubernetes, 在绿色网络环境下安装kubernetes集群，并在安装过程中加深对Kubernetes组件以及架构的理解.<ul>\n<li><a href=\"https://github.com/liuyi01/kubernetes-starter\" target=\"_blank\" rel=\"noopener\">https://github.com/liuyi01/kubernetes-starter</a></li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<h3 id=\"Download-amp-Install\"><a href=\"#Download-amp-Install\" class=\"headerlink\" title=\"Download &amp; Install\"></a>Download &amp; Install</h3><blockquote>\n<p>官网步骤: <a href=\"https://kubernetes.io/docs/tasks/tools/install-kubectl/\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/docs/tasks/tools/install-kubectl/</a></p>\n</blockquote>\n<h4 id=\"机器配置\"><a href=\"#机器配置\" class=\"headerlink\" title=\"机器配置\"></a>机器配置</h4><p>搭建K8s集群只用了一台安装Ubuntu18.04的酷睿机器.</p>\n<blockquote>\n<ol>\n<li>Ubuntu18.04宿主主机上 download &amp; install virtualbox<br>$ apt-get install virtualbox</li>\n<li>下载Ubuntu18.04镜像: <a href=\"http://releases.ubuntu.com/18.04/\" target=\"_blank\" rel=\"noopener\">http://releases.ubuntu.com/18.04/</a> 选择 ubuntu-18.04.4-live-server-amd64.iso 2020-02-03 18:36 870M    Server install image for 64-bit PC (AMD64) computers (standard download)</li>\n<li>用virtualbox安装两台Ubuntu18.04虚拟机<ul>\n<li>虚拟机server01 作为 master; </li>\n<li>虚拟机server02 作为 worker01; </li>\n<li>宿主主机 作为 worker02<br>每台虚拟机 内存要大于等于 2 G ，CPU核数需要大于等于 4 核</li>\n</ul>\n</li>\n</ol>\n</blockquote>\n<h4 id=\"每个node都在-etc-environment-添加如下信息\"><a href=\"#每个node都在-etc-environment-添加如下信息\" class=\"headerlink\" title=\"每个node都在 /etc/environment 添加如下信息\"></a>每个node都在 /etc/environment 添加如下信息</h4><blockquote>\n<p>http_proxy=”<a href=\"http://child-prc.intel.com:913/&quot;\" target=\"_blank\" rel=\"noopener\">http://child-prc.intel.com:913/&quot;</a><br>https_proxy=”<a href=\"http://child-prc.intel.com:913/&quot;\" target=\"_blank\" rel=\"noopener\">http://child-prc.intel.com:913/&quot;</a><br>ftp_proxy=”<a href=\"ftp://child-prc.intel.com:913/&quot;\" target=\"_blank\" rel=\"noopener\">ftp://child-prc.intel.com:913/&quot;</a><br>no_proxy=”K8S_MASTER_IP,K8S_MASTER_HostName”  如: no_proxy=”10.67.108.200,hci-node01”  // [iotg@hci-node01 ~]$</p>\n</blockquote>\n<h4 id=\"kubeadm-kubelet-kubectl\"><a href=\"#kubeadm-kubelet-kubectl\" class=\"headerlink\" title=\"kubeadm, kubelet, kubectl\"></a>kubeadm, kubelet, kubectl</h4><blockquote>\n<p>每台机器都安装kubeadm(二进制文件工具), kubelet(服务), master上安装kubectl(二进制文件工具), 也可以在需要kubectl控制k8s资源的node上也安装(也就是下载或拷贝)kubectl二进制文件工具.</p>\n</blockquote>\n<pre><code>$ sudo apt-get update &amp;&amp; sudo apt-get install -y apt-transport-https gnupg2\n$ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n$ echo &quot;deb https://apt.kubernetes.io/ kubernetes-xenial main&quot; | sudo tee -a /etc/apt/sources.list.d/kubernetes.list\n$ sudo apt-get update\n$ sudo apt-get install -y kubectl\n$ sudo apt-get install -y kubeadm\n$ sudo apt-get install -y kubelet\n$ kubeadm version        // 通过 kubectl 命令行客户端向运行在主节点上的 Kubemetes API 服务器发出 REST 请求以与集群交互\n$ kubectl version        // 客户端工具\n$ kubelet --version        // kubelet是一个服务，可通过systemctl restart kubelet重启服务，每台master和worker节点都需要安装\n$ systemctl enable --now kubelet\n$ kubeadm reset\n$ sudo hostnamectl set-hostname master-node //修改机器名字, 重开终端就可以看到机器名变了</code></pre><h4 id=\"机器环境配置\"><a href=\"#机器环境配置\" class=\"headerlink\" title=\"机器环境配置\"></a>机器环境配置</h4><pre><code>关闭交换区, K8s认为swap性能开销比较大, 性能会大幅降低, 使用swap做云基础架构会减少性能, 因此k8s关闭swap\n另外重新装系统OS时候就可以不给swap分配分区.\n$ swapoff -a            // 临时关闭交换区，$ free -h 可以查看 Swap: 0B...\n$ vim /etc/fstab  // 设置重启后自动关闭swapoff, 将含有swap的那一行前面加&quot;#&quot;注释掉就可以了\n  /dev/mapper/centos-swap swap                    swap    defaults        0 0\n$ sed -i &apos;/swap/d&apos; /etc/fstab    //永久关闭\n\n关闭防火墙\n$ systemctl stop firewalld.service\n$ systemctl status firewalld.service    // 查看防火墙是否有 Active: inactive (dead) since......\n$ systemctl disable firewalld             // 设置开机不启动防火墙\n$ sysctl net.bridge.bridge-nf-call-iptables=1\n$ sysctl net.bridge.bridge-nf-call-ip6tables=1</code></pre><blockquote>\n<p>Iptables原理<br>linux的防火墙由netfilter和iptables组成<br>用户空间的iptables制定防火墙规则，内核空间的netfilter实现防火墙功能netfilter（内核空间）位于Linux内核中的包过滤防火墙功能体系，称为Linux防火墙的“内核态”<br>iptables(用户空间)位于/sbin/iptables，是用来管理防火墙的命令的工具，为防火墙体系提供过滤规则/策略，决定如何过滤或处理到达防火墙主机的数据包，称为Linux防火墙的“用户态”</p>\n</blockquote>\n<pre><code>关闭selinux:        // 限制访问linux资源文件上下文\n$ getenforce            // 查看是否disabled\n$ setenforce 0            //临时关闭selinux(Security-Enhanced Linux), 终端会输出&quot;setenforce: SELinux is disabled&quot;\n$ vim /etc/selinux/config --&gt; 将 SELINUX=permissive 改为 SELINUX=disabled, 设置重启后自动关闭selinux\n$ sed -i &apos;s/^SELINUX=enforcing$/SELINUX=permissive/&apos; /etc/selinux/config    //永久关闭(试了好像没反应): </code></pre><h4 id=\"同步系统时间\"><a href=\"#同步系统时间\" class=\"headerlink\" title=\"同步系统时间\"></a>同步系统时间</h4><blockquote>\n<p>涉及到验证签发的证书的有效性, 如果签发证书的服务器时间比使用证书的服务器时间早, 就会导致校验不成功或证书错误, 一直等到使用证书的服务器时间也运行到证书开始生效的时间后才会解决这个问题.</p>\n</blockquote>\n<pre><code>$ ntpdate time.windows.com         // 同步 windows 系统时间</code></pre><h4 id=\"设置docker的proxy\"><a href=\"#设置docker的proxy\" class=\"headerlink\" title=\"设置docker的proxy\"></a>设置docker的proxy</h4><pre><code>$ mkdir docker.service.d\n$ vim /etc/systemd/system/docker.service.d/http-proxy.conf\n\n[Service]\nEnvironment=&quot;HTTP_PROXY=http://child-prc.intel.com:913/&quot;\nEnvironment=&quot;HTTPS_PROXY=http://child-prc.intel.com:913/&quot;</code></pre><h4 id=\"安装镜像\"><a href=\"#安装镜像\" class=\"headerlink\" title=\"安装镜像\"></a>安装镜像</h4><pre><code>$ docker images\n$ docker pull gcr.io/google_containers/kube-apiserver-amd64:v1.9.3\n$ docker pull gcr.io/google_containers/kube-controller-manager-amd64:v1.9.3\n$ docker pull gcr.io/google_containers/kube-scheduler-amd64:v1.9.3</code></pre><h4 id=\"添加机器到K8s集群\"><a href=\"#添加机器到K8s集群\" class=\"headerlink\" title=\"添加机器到K8s集群\"></a>添加机器到K8s集群</h4><blockquote>\n<ol>\n<li>在Master主机 server01 上运行</li>\n</ol>\n</blockquote>\n<pre><code>$ kubeadm init</code></pre><p>返回部分数据如下</p>\n<pre><code>......\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join 10.239.141.112:6443 --token uvm0zr.ndg144wcga276j16 \\\n    --discovery-token-ca-cert-hash sha256:e1535452b32ed4039fa2f261197c0b91179fb168e8da3dd58b99fc11fe2213b8\nroot@server01:~#</code></pre><blockquote>\n<p>添加kubeadm部署k8s后生成的administrator访问证书到环境变量或~/.kube目录, 使得root或其它user登陆后可以通过kubectl访问或生成k8s资源如pod等, 有如下两种方式.</p>\n</blockquote>\n<p>第一种:</p>\n<pre><code>$ export KUBECONFIG=/etc/kubernetes/admin.conf\n$ echo &quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot; | tee -a ~/.bashrc\n$ source ~/.bashrc</code></pre><p>第二种(其它user而非root登陆后需要做如下操作才能通过kubectl访问或生成k8s资源如pod等):</p>\n<pre><code>$ mkdir -p $HOME/.kube\n$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n$ sudo chown $(id -u):$(id -g) $HOME/.kube/config</code></pre><p>添加容器之间的通信网络, 第三方资源weave, 官网上也推荐部署其它几种通信网络方式</p>\n<pre><code>$ kubectl apply -f https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d &apos;\\n&apos;)</code></pre><blockquote>\n<ol start=\"2\">\n<li>之后用上面命令返回的 kubeadm join 10.239.141.112:6443 –t … 复制 并 在其它node机器(server02和宿主主机) 上运行就可以把node加进上面创建的Cluster了</li>\n</ol>\n</blockquote>\n<h4 id=\"在master-server01-机器上查看集群节点信息\"><a href=\"#在master-server01-机器上查看集群节点信息\" class=\"headerlink\" title=\"在master server01 机器上查看集群节点信息\"></a>在master server01 机器上查看集群节点信息</h4><pre><code>$ kubectl get nodes\n$ kubectl get namespaces</code></pre><h4 id=\"查看node节点信息\"><a href=\"#查看node节点信息\" class=\"headerlink\" title=\"查看node节点信息\"></a>查看node节点信息</h4><pre><code>$ kubectl describe node server02</code></pre><h3 id=\"重新-reset-在原来-机器上搭建k8s集群操作\"><a href=\"#重新-reset-在原来-机器上搭建k8s集群操作\" class=\"headerlink\" title=\"重新(reset)在原来(机器上搭建k8s集群操作\"></a>重新(reset)在原来(机器上搭建k8s集群操作</h3><blockquote>\n<p>主机名和IP解析, 通过主机名访问机器, 修改下各个节点 /etc/hosts 文件内容(实验环境没有修改，跳过这个步骤), 也可以只在master上配置, 因为很多操作都是在master上执行</p>\n</blockquote>\n<pre><code>......\n10.239.141.106 server01\n10.239.140.184 server02\n10.239.140.186 alpha</code></pre><blockquote>\n<ol>\n<li>需要在master节点上执行 </li>\n</ol>\n</blockquote>\n<pre><code>$ rm -rf /etc/kubernetes/pki/etcd/\n$ rm -rf /var/lib/etcd\n$ rm -rf $HOME/.kube\n$ kubeadm reset\n$ swapoff -a\n$ setenforce 0\n$ systemctl stop firewalld.service\n$ sysctl net.bridge.bridge-nf-call-iptables=1\n$ kubeadm init, 再用返回的 &quot;kubeadm join...&quot; 在其它节点执行\n$ echo &quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot; | tee -a ~/.bashrc\n$ source ~/.bashrc</code></pre><blockquote>\n<ol start=\"2\">\n<li>在worker节点执行:</li>\n</ol>\n</blockquote>\n<pre><code>$ systemctl enable docker.service\n$ kubeadm reset\n$ swapoff -a\n$ setenforce 0\n$ systemctl stop firewalld.service\n$ sysctl net.bridge.bridge-nf-call-iptables=1\n$ systemctl daemon-reload        // 重新加载 systemctl 的配置文件\n$ systemctl restart kubelet\n // $ iptables -F &amp;&amp; iptables -t nat -F &amp;&amp; iptables -t mangle -F &amp;&amp; iptables -X        // will reset iptables\n$ kubeadm join ......</code></pre><blockquote>\n<ol start=\"3\">\n<li>再次在master节点上执行<br>如果不执行下面命令安装weave pod, kube-system命名空间下的coredns会一直处于containercreating状态.</li>\n</ol>\n</blockquote>\n<pre><code>$ kubectl apply -f https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d &apos;\\n&apos;)</code></pre><h3 id=\"k8s重新生成token\"><a href=\"#k8s重新生成token\" class=\"headerlink\" title=\"k8s重新生成token\"></a>k8s重新生成token</h3><p>主机上执行如下命令，主机IP:10.239.140.186</p>\n<pre><code>$ kubeadm token create\nv6rgnu.ydqgkuujayykkanv\n\n$ kubeadm token list\nTOKEN                     TTL   EXPIRES                     USAGES                   DESCRIPTION   EXTRA GROUPS\nv6rgnu.ydqgkuujayykkanv   23h   2020-05-30T13:24:41+08:00   authentication,signing   &lt;none&gt;        system:bootstrappers:kubeadm:default-node-token\n\n$ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &apos;s/^.* //&apos;\nbe6606e3e081afc6f9785fbe0e129e048e5a2a5557cb2e7747d727edd20c6ed4</code></pre><p>用上面master主机上生成的token在worker节点执行如下命令:</p>\n<pre><code>$ kubeadm reset\n$ swapoff -a\n$ setenforce 0\n$ systemctl stop firewalld.service\n$ sysctl net.bridge.bridge-nf-call-iptables=1\n$ sysctl net.bridge.bridge-nf-call-ip6tables=1\n$ kubeadm join --token v6rgnu.ydqgkuujayykkanv --discovery-token-ca-cert-hash sha256:be6606e3e081afc6f9785fbe0e129e048e5a2a5557cb2e7747d727edd20c6ed4  10.239.140.186:6443</code></pre><h3 id=\"k8s命令自动补全\"><a href=\"#k8s命令自动补全\" class=\"headerlink\" title=\"k8s命令自动补全\"></a>k8s命令自动补全</h3><pre><code>$ yum install bash-completion\n$ echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc\n$ source ~/.bashrc</code></pre><p>试试 输入 <code>kubectl get n</code> 按 <code>tab</code> 查看提示.</p>\n<h3 id=\"Additional\"><a href=\"#Additional\" class=\"headerlink\" title=\"Additional\"></a>Additional</h3><h4 id=\"重新reset-K8s集群，然后kubeadm-init遇到如下问题\"><a href=\"#重新reset-K8s集群，然后kubeadm-init遇到如下问题\" class=\"headerlink\" title=\"重新reset K8s集群，然后kubeadm init遇到如下问题\"></a>重新reset K8s集群，然后kubeadm init遇到如下问题</h4><h4 id=\"问题1\"><a href=\"#问题1\" class=\"headerlink\" title=\"问题1\"></a>问题1</h4><blockquote>\n<p>[kubelet-check] The HTTP call equal to ‘curl -sSL <a href=\"http://localhost:10248/healthz&#39;\" target=\"_blank\" rel=\"noopener\">http://localhost:10248/healthz&#39;</a> failed with error: Get <a href=\"http://localhost:10248/healthz\" target=\"_blank\" rel=\"noopener\">http://localhost:10248/healthz</a>: dial tcp [::1]:10248: connect: connection refused.<br>解决方法:</p>\n</blockquote>\n<pre><code>$ systemctl restart docker\n$ rm -rf /etc/systemd/system/kubelet.service.d/*\n$ systemctl daemon-reload</code></pre><h4 id=\"问题2\"><a href=\"#问题2\" class=\"headerlink\" title=\"问题2\"></a>问题2</h4><p>Unable to connect to the server: x509: certificate signed by unknown authority<br>需要删除上一次部署后cp到~/.kube的证书文件, 再重新部署一遍k8s集群</p>\n<pre><code>$ rm -rf $HOME/.kube</code></pre><h4 id=\"问题3\"><a href=\"#问题3\" class=\"headerlink\" title=\"问题3\"></a>问题3</h4><p>The connection to the server localhost:8080 was refused - did you specify the right host or port?<br>需要添加administrator访问证书<br>第一种:</p>\n<pre><code>$ export KUBECONFIG=/etc/kubernetes/admin.conf\n$ echo &quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot; | tee -a ~/.bashrc\n$ source ~/.bashrc</code></pre><p>第二种:</p>\n<pre><code>$ mkdir -p $HOME/.kube\n$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n$ sudo chown $(id -u):$(id -g) $HOME/.kube/config</code></pre><h4 id=\"问题n\"><a href=\"#问题n\" class=\"headerlink\" title=\"问题n\"></a>问题n</h4><p><a href=\"https://istio.io/docs/examples/bookinfo/\" target=\"_blank\" rel=\"noopener\">https://istio.io/docs/examples/bookinfo/</a><br>Istio 部署bookinfo 到bookinfo命名空间， 发现只部署了svc，RS，但是没有部署pod.</p>\n<pre><code>$ kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml -n bookinfo</code></pre><p>用以下命令可以查看出错信息, 发现是webhook相关错误</p>\n<pre><code>$ kubectl describe rs/RS-NAME -n bookinfo</code></pre><p>解决方法是注释掉kubernetes的proxy</p>\n<p>/etc/kubernetes/manifests/kube-apiserver.yaml</p>\n<pre><code> env:                                    // K8s安装会用系统的proxy，加#注释掉.\n#- name: HTTP_PROXY\n#  value: http://child-prc.intel.com:913\n#- name: https_proxy\n#  value: http://child-prc.intel.com:913\n#- name: http_proxy\n#  value: http://child-prc.intel.com:913\n#- name: HTTPS_PROXY\n#  value: http://child-prc.intel.com:913\n - name: no_proxy\n   value: 10.239.140.186,10.239.140.200        // master和一个worker节点的NodeIP.</code></pre><p>稍等一会$ kubectl get po -n bookinfo 就可以看到pod慢慢部署成功了.</p>\n"},{"title":"02 kubernetes introduction","top":2,"_content":"\n\n## kubernetes组件官网介绍\nhttps://kubernetes.io/docs/reference/\n\n\n### REST\n> REST（representational state transfer）是由roy博士在他的论文中提出的一个术语，rest本身只是为分布式超媒体系统设计的一种架构风格，而不是标准\n> * 无状态性：\n> \t这是在客户-服务器的基础上添加的又一层规范，它要求通信必须在本质上是无状态的，即从客户端到服务器的每个request都必须包含理解该request所必须的所有信息。这个规范改善了系统的可见性（无状态性使得客户端和服务端不必保存对方的详细信息，服务器只需要处理当前的request，而不必了解所有request的历史）、可靠性（无状态性减少了服务器从局部错误中恢复的任务量）、可伸缩性（无状态使得服务器端可以很容易地释放资源，因为服务端不必在多个request中保存状态）。同时，这种规范的缺点也是显而易见的，由于不能将状态数据保存在服务器上，因此增加了在一系列request中发生重复数据的开销，严重降低了效率。\n> * 缓存：\n> \t为了改善无状态性带来的网络低效性，我们添加了缓存约束，缓存约束允许隐式或显式标记一个response中的数据，赋予了客户端缓存response数据的功能，这样就可以为以后的request公用缓存的数据，部分或全部地消除一部分交互，提高了网络效率。但是由于客户端缓存了信息，所以增加了客户端与服务器数据不一致的可能性，从而降低了可靠性。\n> REST中的资源所指的不是数据，而是数据和表现形式的组合，比如“最新访问的10位会员”和“最活跃的10位会员”在数据上可能有重叠或者完全相同，而由于它们的表现形式不同，所以被归于不同的资源，这也就是为什么REST的全名是representational state transfer，资源标识符就是URI（uniform resource identifier），不管是图片，word还是视频文件，也不管是什么格式，全部通过URI对资源进行唯一标识.\n> kubernetes API是集群系统中的重要组成部分，kubernetes中各种资源的数据通过该API接口被提交到后端的持久性存储etcd中，kubernetes集群中的各部分之间通过该API接口实现解耦合，同时kubernetes集群中一个重要且便捷的管理工具kubectl也是通过访问该API接口实现其强大的管理功能的。kubernetes API中的资源对象都拥有通用的元数据，资源对象也可能存在嵌套现象，比如在一个pod里面嵌套多个container。创建一个API对象是指通过API调用一条有意义的记录，该记录一旦被创建，kubernetes将确保对应的资源对象会被自动创建并托管维护\n\n### 标签\n> 我们不会特别说明pod应该调度到哪个节点上， 因为这将会使应用程序与基础架构强耦合， 从而违背了Kubemetes对运行在其上的应用程序隐藏实际 的基础架构的整个构想。 \n> 但如果你想对一个 pod应该调度到哪里拥有发言权， 那就不应该直接指定一个确切的节点， 而应该用某种方式描述对节点的需求， 使Kubemetes选择一个符合这些需求的节点。这恰恰可以通过节点标签和节点标签选择器完成\n> pod并不是唯一可以附加标签的Kubemetes资源。 标签可以附加到任何Kubemetes对象上， 包括节点。 通常来说， 当运维团队向集群添加新节点时，他们将通过附加标签来对节点进行分类， 这些 标签指定节点提供 的硬件类型 ， 或者任何在调度pod 时能提供便利的其他信息\n\n## roles\n\n\n\n\n\n\n\n\n\n","source":"_posts/micro_service/02_kubernetes_roles_introduction.md","raw":"---\ntitle: 02 kubernetes introduction\ntags:\n- kubernetes\ncategories:\n- microService\n- kubernetes\ntop: 2\n---\n\n\n## kubernetes组件官网介绍\nhttps://kubernetes.io/docs/reference/\n\n\n### REST\n> REST（representational state transfer）是由roy博士在他的论文中提出的一个术语，rest本身只是为分布式超媒体系统设计的一种架构风格，而不是标准\n> * 无状态性：\n> \t这是在客户-服务器的基础上添加的又一层规范，它要求通信必须在本质上是无状态的，即从客户端到服务器的每个request都必须包含理解该request所必须的所有信息。这个规范改善了系统的可见性（无状态性使得客户端和服务端不必保存对方的详细信息，服务器只需要处理当前的request，而不必了解所有request的历史）、可靠性（无状态性减少了服务器从局部错误中恢复的任务量）、可伸缩性（无状态使得服务器端可以很容易地释放资源，因为服务端不必在多个request中保存状态）。同时，这种规范的缺点也是显而易见的，由于不能将状态数据保存在服务器上，因此增加了在一系列request中发生重复数据的开销，严重降低了效率。\n> * 缓存：\n> \t为了改善无状态性带来的网络低效性，我们添加了缓存约束，缓存约束允许隐式或显式标记一个response中的数据，赋予了客户端缓存response数据的功能，这样就可以为以后的request公用缓存的数据，部分或全部地消除一部分交互，提高了网络效率。但是由于客户端缓存了信息，所以增加了客户端与服务器数据不一致的可能性，从而降低了可靠性。\n> REST中的资源所指的不是数据，而是数据和表现形式的组合，比如“最新访问的10位会员”和“最活跃的10位会员”在数据上可能有重叠或者完全相同，而由于它们的表现形式不同，所以被归于不同的资源，这也就是为什么REST的全名是representational state transfer，资源标识符就是URI（uniform resource identifier），不管是图片，word还是视频文件，也不管是什么格式，全部通过URI对资源进行唯一标识.\n> kubernetes API是集群系统中的重要组成部分，kubernetes中各种资源的数据通过该API接口被提交到后端的持久性存储etcd中，kubernetes集群中的各部分之间通过该API接口实现解耦合，同时kubernetes集群中一个重要且便捷的管理工具kubectl也是通过访问该API接口实现其强大的管理功能的。kubernetes API中的资源对象都拥有通用的元数据，资源对象也可能存在嵌套现象，比如在一个pod里面嵌套多个container。创建一个API对象是指通过API调用一条有意义的记录，该记录一旦被创建，kubernetes将确保对应的资源对象会被自动创建并托管维护\n\n### 标签\n> 我们不会特别说明pod应该调度到哪个节点上， 因为这将会使应用程序与基础架构强耦合， 从而违背了Kubemetes对运行在其上的应用程序隐藏实际 的基础架构的整个构想。 \n> 但如果你想对一个 pod应该调度到哪里拥有发言权， 那就不应该直接指定一个确切的节点， 而应该用某种方式描述对节点的需求， 使Kubemetes选择一个符合这些需求的节点。这恰恰可以通过节点标签和节点标签选择器完成\n> pod并不是唯一可以附加标签的Kubemetes资源。 标签可以附加到任何Kubemetes对象上， 包括节点。 通常来说， 当运维团队向集群添加新节点时，他们将通过附加标签来对节点进行分类， 这些 标签指定节点提供 的硬件类型 ， 或者任何在调度pod 时能提供便利的其他信息\n\n## roles\n\n\n\n\n\n\n\n\n\n","slug":"micro_service/02_kubernetes_roles_introduction","published":1,"date":"2020-08-12T16:05:47.351Z","updated":"2020-08-10T16:36:16.615Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmg30043hohxfvja1uu1","content":"<h2 id=\"kubernetes组件官网介绍\"><a href=\"#kubernetes组件官网介绍\" class=\"headerlink\" title=\"kubernetes组件官网介绍\"></a>kubernetes组件官网介绍</h2><p><a href=\"https://kubernetes.io/docs/reference/\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/docs/reference/</a></p>\n<h3 id=\"REST\"><a href=\"#REST\" class=\"headerlink\" title=\"REST\"></a>REST</h3><blockquote>\n<p>REST（representational state transfer）是由roy博士在他的论文中提出的一个术语，rest本身只是为分布式超媒体系统设计的一种架构风格，而不是标准</p>\n<ul>\n<li>无状态性：<br>  这是在客户-服务器的基础上添加的又一层规范，它要求通信必须在本质上是无状态的，即从客户端到服务器的每个request都必须包含理解该request所必须的所有信息。这个规范改善了系统的可见性（无状态性使得客户端和服务端不必保存对方的详细信息，服务器只需要处理当前的request，而不必了解所有request的历史）、可靠性（无状态性减少了服务器从局部错误中恢复的任务量）、可伸缩性（无状态使得服务器端可以很容易地释放资源，因为服务端不必在多个request中保存状态）。同时，这种规范的缺点也是显而易见的，由于不能将状态数据保存在服务器上，因此增加了在一系列request中发生重复数据的开销，严重降低了效率。</li>\n<li>缓存：<br>  为了改善无状态性带来的网络低效性，我们添加了缓存约束，缓存约束允许隐式或显式标记一个response中的数据，赋予了客户端缓存response数据的功能，这样就可以为以后的request公用缓存的数据，部分或全部地消除一部分交互，提高了网络效率。但是由于客户端缓存了信息，所以增加了客户端与服务器数据不一致的可能性，从而降低了可靠性。<br>REST中的资源所指的不是数据，而是数据和表现形式的组合，比如“最新访问的10位会员”和“最活跃的10位会员”在数据上可能有重叠或者完全相同，而由于它们的表现形式不同，所以被归于不同的资源，这也就是为什么REST的全名是representational state transfer，资源标识符就是URI（uniform resource identifier），不管是图片，word还是视频文件，也不管是什么格式，全部通过URI对资源进行唯一标识.<br>kubernetes API是集群系统中的重要组成部分，kubernetes中各种资源的数据通过该API接口被提交到后端的持久性存储etcd中，kubernetes集群中的各部分之间通过该API接口实现解耦合，同时kubernetes集群中一个重要且便捷的管理工具kubectl也是通过访问该API接口实现其强大的管理功能的。kubernetes API中的资源对象都拥有通用的元数据，资源对象也可能存在嵌套现象，比如在一个pod里面嵌套多个container。创建一个API对象是指通过API调用一条有意义的记录，该记录一旦被创建，kubernetes将确保对应的资源对象会被自动创建并托管维护</li>\n</ul>\n</blockquote>\n<h3 id=\"标签\"><a href=\"#标签\" class=\"headerlink\" title=\"标签\"></a>标签</h3><blockquote>\n<p>我们不会特别说明pod应该调度到哪个节点上， 因为这将会使应用程序与基础架构强耦合， 从而违背了Kubemetes对运行在其上的应用程序隐藏实际 的基础架构的整个构想。<br>但如果你想对一个 pod应该调度到哪里拥有发言权， 那就不应该直接指定一个确切的节点， 而应该用某种方式描述对节点的需求， 使Kubemetes选择一个符合这些需求的节点。这恰恰可以通过节点标签和节点标签选择器完成<br>pod并不是唯一可以附加标签的Kubemetes资源。 标签可以附加到任何Kubemetes对象上， 包括节点。 通常来说， 当运维团队向集群添加新节点时，他们将通过附加标签来对节点进行分类， 这些 标签指定节点提供 的硬件类型 ， 或者任何在调度pod 时能提供便利的其他信息</p>\n</blockquote>\n<h2 id=\"roles\"><a href=\"#roles\" class=\"headerlink\" title=\"roles\"></a>roles</h2>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"kubernetes组件官网介绍\"><a href=\"#kubernetes组件官网介绍\" class=\"headerlink\" title=\"kubernetes组件官网介绍\"></a>kubernetes组件官网介绍</h2><p><a href=\"https://kubernetes.io/docs/reference/\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/docs/reference/</a></p>\n<h3 id=\"REST\"><a href=\"#REST\" class=\"headerlink\" title=\"REST\"></a>REST</h3><blockquote>\n<p>REST（representational state transfer）是由roy博士在他的论文中提出的一个术语，rest本身只是为分布式超媒体系统设计的一种架构风格，而不是标准</p>\n<ul>\n<li>无状态性：<br>  这是在客户-服务器的基础上添加的又一层规范，它要求通信必须在本质上是无状态的，即从客户端到服务器的每个request都必须包含理解该request所必须的所有信息。这个规范改善了系统的可见性（无状态性使得客户端和服务端不必保存对方的详细信息，服务器只需要处理当前的request，而不必了解所有request的历史）、可靠性（无状态性减少了服务器从局部错误中恢复的任务量）、可伸缩性（无状态使得服务器端可以很容易地释放资源，因为服务端不必在多个request中保存状态）。同时，这种规范的缺点也是显而易见的，由于不能将状态数据保存在服务器上，因此增加了在一系列request中发生重复数据的开销，严重降低了效率。</li>\n<li>缓存：<br>  为了改善无状态性带来的网络低效性，我们添加了缓存约束，缓存约束允许隐式或显式标记一个response中的数据，赋予了客户端缓存response数据的功能，这样就可以为以后的request公用缓存的数据，部分或全部地消除一部分交互，提高了网络效率。但是由于客户端缓存了信息，所以增加了客户端与服务器数据不一致的可能性，从而降低了可靠性。<br>REST中的资源所指的不是数据，而是数据和表现形式的组合，比如“最新访问的10位会员”和“最活跃的10位会员”在数据上可能有重叠或者完全相同，而由于它们的表现形式不同，所以被归于不同的资源，这也就是为什么REST的全名是representational state transfer，资源标识符就是URI（uniform resource identifier），不管是图片，word还是视频文件，也不管是什么格式，全部通过URI对资源进行唯一标识.<br>kubernetes API是集群系统中的重要组成部分，kubernetes中各种资源的数据通过该API接口被提交到后端的持久性存储etcd中，kubernetes集群中的各部分之间通过该API接口实现解耦合，同时kubernetes集群中一个重要且便捷的管理工具kubectl也是通过访问该API接口实现其强大的管理功能的。kubernetes API中的资源对象都拥有通用的元数据，资源对象也可能存在嵌套现象，比如在一个pod里面嵌套多个container。创建一个API对象是指通过API调用一条有意义的记录，该记录一旦被创建，kubernetes将确保对应的资源对象会被自动创建并托管维护</li>\n</ul>\n</blockquote>\n<h3 id=\"标签\"><a href=\"#标签\" class=\"headerlink\" title=\"标签\"></a>标签</h3><blockquote>\n<p>我们不会特别说明pod应该调度到哪个节点上， 因为这将会使应用程序与基础架构强耦合， 从而违背了Kubemetes对运行在其上的应用程序隐藏实际 的基础架构的整个构想。<br>但如果你想对一个 pod应该调度到哪里拥有发言权， 那就不应该直接指定一个确切的节点， 而应该用某种方式描述对节点的需求， 使Kubemetes选择一个符合这些需求的节点。这恰恰可以通过节点标签和节点标签选择器完成<br>pod并不是唯一可以附加标签的Kubemetes资源。 标签可以附加到任何Kubemetes对象上， 包括节点。 通常来说， 当运维团队向集群添加新节点时，他们将通过附加标签来对节点进行分类， 这些 标签指定节点提供 的硬件类型 ， 或者任何在调度pod 时能提供便利的其他信息</p>\n</blockquote>\n<h2 id=\"roles\"><a href=\"#roles\" class=\"headerlink\" title=\"roles\"></a>roles</h2>"},{"title":"04 Kubernetes service","top":4,"_content":"\n## Kubernetes Service\n> Kubemetes 服务是一种为一组功能相同的 pod 提供单一不变的接入点的资源.\n> 当服务存在时，它的 IP 地址和端口不会改变。 客户端通过 IP 地址和端口号建立连接，这些连接会被路由到提供该服务的任意一个 pod上.\n> 通过这种方式， 客户端不需要知道每个单独的提供服务的 pod 的地址， 这样这些 pod 就可以在集群中随时被创建或移除.\n\n通过为前端 pod 创建服务， 并且将其配置成可以在集群外部访问，可以暴露一个单一不变的 IP 地址让外部的客户端连接 pod。 \n同理，可以为后台数据库 pod 创建服务，并为其分配一个固定的 IP 地址。尽管 pod 的 IP 地址会改变，但是服务的 IP 地址固定不变。\n另外，通过创建服务，能够让前端的 pod 通过环境变量或 DNS 以及服务名来访问后端服务\nPod 控制器中使用标签选择器来指定哪些 pod 属于同一 Service。\n\n## service\n> 如果 pod 的标签与服务的 pod 选择器相匹配，那么 pod 就将作为服务的后端.只要创建了具有适当标签的新 pod ，它就成为服务的一部分，并且请求开始被重定向到 pod.\n如下所示Service和POD都采用命名端口的方式, 最大的好处就是即使更换spec pod中的端口号也无须更改服务 spec.\n * 第一步，创建service\n创建service yaml文件 kubia-svc.yaml\n\n\n\tapiVersion: v1\n\tkind: Service\n\tmetadata:\n\t  name: kubia\n\tsepc:\n\t// sessionAffinity: ClientIP\t// 默认此值是None, 若改为ClientIP，则SVC接受到的请求连接只会固定转发给同一个pod\n\t  ports:\n\t  - name: http\t\t\t// 端口别名，可以当作端口号用\n\t    port: 80\t\t\t// 该服务可用的端口\n\t    targetPort: http\t// 服务将连接转发到的POD端口, pod需要将http映射pod本身的8080或其它端口，否则这里只能填写端口号\n\t  - name: https\n\t    port: 443\n\t    targetPort: https\t// 含有label:app=kubia的pod需要将https映射pod本身8443或其它端口，否则这里只能填写端口号\n\t  selector:\n\t    app: kubia\t\t\t// 具有app=kubia标签的pod都属于该服务\n创建了 一个名叫kubia的服务，它将在端口80接收请求并将连接路由到具有标签选择器是app=kubia的pod的8080端口上.\n在发布完YAML文件后， 可以在命名空间下列出来所有的服务资源, 新的服务已经被分配了一个内部集群IP, 只能在集群内部可以被访问.\n\n\t$ kubectl get svc\n\tNAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE\n\tkubernetes   ClusterIP   10.96.0.1      <none>        443/TCP   23h\n\tkubia        ClusterIP   10.98.229.76   <none>        80/TCP    20s\n\n * 第二步，创建两个pod，一个添加标签app=kubia，另一个用来执行测试通过kubectl exec来访问第一个pod\nkubia.yaml\n\n\n\tapiVersion: v1\n\tkind: Pod\n\tmetadata:\n\t  name: kubia\t// name: kubia1; name: kubia2\n\tspec:\n\t  nodeSelector:\t\t// pod被分配到含有标签gpu=true的node上，当然也可以注释掉这两行\n\t    gpu: \"true\"\n\t  containers:\n\t  - image: luksa/kubia\n\t    name: kubia\n\nkubia-label.yaml\n\n\t apiVersion: v1\t\t\t\t\t// api服务版本\n\t kind : Pod\t\t\t\t\t\t// 资源类型\n\t metadata:\n\t   name: kubia-label\t\t\t// pod 名字\n\t   labels:\n\t     app: kubia\t\t\t\t\t// pod添加label\n\t spec :\n\t   nodeSelector:\n\t     gpu: \"true\"\t\t\t\t// node 选择器\n\t   containers:\n\t   - image: luksa/kubia\t\t\t// image 名字\n\t     name: kubia\t\t\t\t// container 名字\n\t     ports:\n\t     - name: http\t\t\t\t// pod端口映射，用http名字代替8080，名字随便取, 可以跟上面的service的targetPort对应起来\n\t       containerPort: 8080\t\t// 用上面的名字定义这个端口号的别名\n\t     - name: https\n\t       containerPort: 8443\n查看POD并执行一个POD去通过上面创建的service(通过label)包含的pod提供的服务.\n其中pod kubia-label中container运行的服务进程监听了8080端口, POD对外也暴露了8080端口\n\n\t$ kubectl get pod --show-labels\n\tNAME           READY   STATUS    RESTARTS   AGE    LABELS\n\tkubia          1/1     Running   0          101m   <none>\n\tkubia-label    1/1     Running   0          98m    app=kubia\n\tkubia-label1   1/1     Running   0          99s    app=kubia\n\tkubia-label2   1/1     Running   0          79s    app=kubia\n\n * 第三步: 执行一个pod用curl命令访问另一个pod提供的服务\n双横杠(--)代表着kubectl命令项的结束.在两个横杠之后的内容是指在pod内部需要执行的命令.\nk8s 服务代理接续curl请求连接，三个包含label为app=kubia的pod任意选择一个pod\n访问服务三种方式,加不加端口都可以\n\n\n\t<p>$ kubectl exec kubia -- curl -s http://10.98.229.76:http</p>\n\t$ kubectl exec kubia -- curl -s http://10.98.229.76:80\n\t$ kubectl exec kubia -- curl -s http://10.98.229.76\n\tYou've hit kubia-label\n\n\t$ kubectl exec kubia -- curl -s http://10.98.229.76\n\tYou've hit kubia-label2\n\t$ kubectl exec kubia -- curl -s http://10.98.229.76\n\tYou've hit kubia-label1\n\n### Affinity 亲和性\nKubernetes 仅仅支持两种形式的会话亲和性服务： None 和 ClientIP\n这种方式将会使服务代理将来自同 一个 client IP 的所有请求转发至同 一个 pod上.\nKubernetes 服务不是在 HTTP 层面上工作。服务处理 TCP 和 UDP 包，并不关心其中的载荷内容。\n因为 cookie 是 HTTP 协议中的一部分，服务并不知道它们，这就解释了为什么会话亲和性不能基千 cookie。\n如果希望特定客户端产生的所有请求每次都指向同 一个 pod, 可以设置服务的 sessionAffinity 属性为 ClientIP (而不是 None,None 是默认值）\n\n\tapiVersion: vl\n\tkind: Service\n\tspec:\n\t  sessionAffinity: ClientIP\n\t......\n\n\n## 环境变量发现service\n### 创建replicaSet 管理 3 个 POD\n\n\tapiVersion: apps/v1\n\tkind: ReplicaSet\n\tmetadata:\n\t  name: kubia\n\tspec:\n\t  replicas: 3\n\t  selector:\n\t    matchLabels:\n\t      app: kubia\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: kubia\n\t    spec:\n\t      nodeSelector:\n\t        gpu: \"true\"\n\t      containers:\n\t      - name: kubia\n\t        image: luksa/kubia\n\t        ports:\n\t        - name: http\n\t          containerPort: 8080\n\t        - name: https\n\t          containerPort: 8443\n\n\t$ kubectl get svc \n\tNAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\n\tkubernetes   ClusterIP   10.96.0.1       <none>        443/TCP          29h\n\tkubia        ClusterIP   10.111.88.195   <none>        80/TCP,443/TCP   3h46m\n查看pod所在的service对应的IP和端口\n\n\t$ kubectl exec kubia-5rvfq env\n\t......\n\tKUBERNETES_SERVICE_PORT=443\n\tKUBIA_SERVICE_PORT=80\t\t\t\t// 服务的集群IP\n\t......\n\tKUBERNETES_SERVICE_HOST=10.96.0.1\n\tKUBIA_SERVICE_HOST=10.111.88.195\t// 服务所在的端口\n\t......\npod 是否使用 内 部的 DNS 服务器是根据 pod 中 spec 的 dnsPolicy 属性来决定的\n\n进入容器后执行如下命令\n\n\t$ kubectl exec kubia-5rvfq -it -- bash\t\t// -- 表示kubectl 命令执行完了，开始执行pod容器里要运行的命令\n\t$ curl http://kubia.default.svc.cluster.local\n\t$ curl http://kubia.default\n\t$ curl http://kubia\n\tYou've hit kubia-5rvfq\n\n\t$ cat /etc/resolv.conf\n\tnameserver 10.96.0.10\t\t// 对应kube-system 里的服务kube-dns服务IP\n\tsearch default.svc.cluster.local svc.cluster.local cluster.local sh.intel.com\n\toptions ndots:5\n\troot@kubia-5rvfq:/# curl http://svc.cluster.local\n\tcurl: (6) Could not resolve host: svc.cluster.local\n\n\t$ ping kubia\n\tPING kubia.default.svc.cluster.local (10.111.88.195): 56 data bytes\n\t^C--- kubia.default.svc.cluster.local ping statistics ---\n\t4 packets transmitted, 0 packets received, 100% packet loss\n上面的 curl 这个服务是工作的，但是却 ping 不通。这是 因为服务的集群 IP 是一个虚拟 IP，并且只有在与服务端口结合时才有意义。 \n\n查看kube-system下面kube-dns信息\n\n\t$ kubectl get svc -n kube-system\n\tNAME       TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE\n\tkube-dns   ClusterIP   10.96.0.10   <none>        53/UDP,53/TCP,9153/TCP   2d3h\n\n### 删除service\n\n\t$ kubectl delete svc kubia\n\n## Service samples\n### 查看service\n\n\t$ kubectl get svc -n kube-system\n\t$ kubectl get svc -n istio-system\n\tNAME                        TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                                                                                                      AGE\n\tgrafana                     ClusterIP      10.104.1.236     <none>        3000/TCP                                                                                                                                     3d5h\n\tistio-egressgateway         ClusterIP      10.107.177.52    <none>        80/TCP,443/TCP,15443/TCP                                                                                                                     3d5h\n\tistio-ingressgateway        LoadBalancer   10.97.82.221     <pending>     15020:31237/TCP,80:31556/TCP,443:30614/TCP,15029:32511/TCP,15030:32423/TCP,15031:30670/TCP,15032:30961/TCP,31400:30196/TCP,15443:31028/TCP   3d5h\n\tistio-pilot                 ClusterIP      10.97.192.70     <none>        15010/TCP,15011/TCP,15012/TCP,8080/TCP,15014/TCP,443/TCP                                                                                     3d5h\n\tistiod                      ClusterIP      10.107.202.199   <none>        15012/TCP,443/TCP\n\t......\n\n\t$ kubectl get services\n\tNAME                        TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE\n\tkubernetes                  ClusterIP      10.3.240.l       <none>        443/TCP          34m\n\tkubia-http                  LoadBalancer   10.3.246.185     <pending>     8080:31348/TCP   4s\n\t暂时忽略 kubernetes 服务，仔细查看创建的kubian-http 服务 。 它还没有外部 IP 地址 ，因为 Kubernetes 运行的云基础设施创建负载均衡需要一段时间\n\t$ kubectl get services\n\tNAME                        TYPE           CLUSTER-IP       EXTERNAL-IP       PORT(S)          AGE\n\tkubernetes                  ClusterIP      10.3.240.l       <none>            443/TCP          34m\n\tkubia-http                  LoadBalancer   103.246.185      104 155.74.57     8080:31348/TCP   4s\n\t现在有外部 IP 了，应用就可以从任何地方通过 http://104.155.74.57:8080 访问\n\t$ curl 104.155.74.57:8080\n\tYou’ve hit kubia-4jfyf\n\n### 查看service的CRD信息\n\n\t$ kubectl get svc istio-ingressgateway -n istio-system -oyaml\n\n## endpoint 服务\n\n\t$ kubectl describe svc kubia\n\tName:              kubia\n\tNamespace:         default\n\tLabels:            <none>\n\tAnnotations:       <none>\n\tSelector:          app=kubia\t\t// 用于创建endpoint列表的服务pod选择器\n\tType:              ClusterIP\n\tIP:                10.111.88.195\n\tPort:              http  80/TCP\n\tTargetPort:        8080/TCP\n\tEndpoints:         10.44.0.1:8080,10.44.0.2:8080,10.44.0.3:8080\t\t// 服务endpoint的pod的IP和端口列表\n\tPort:              https  443/TCP\n\tTargetPort:        8443/TCP\n\tEndpoints:         10.44.0.1:8443,10.44.0.2:8443,10.44.0.3:8443\n\tSession Affinity:  ClientIP\n\tEvents:            <none>\n\n\t$ kubectl get po -o wide\n\tNAME          READY   STATUS    RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES\n\tkubia         1/1     Running   0          15h   10.44.0.4   server02   <none>           <none>\n\tkubia-5rvfq   1/1     Running   0          15h   10.44.0.2   server02   <none>           <none>\n\tkubia-8cgnm   1/1     Running   0          15h   10.44.0.1   server02   <none>           <none>\n\tkubia-8kv8d   1/1     Running   0          15h   10.44.0.3   server02   <none>           <none>\nEndpoint 资源和其他Kubernetes 资源一样，所以可以使用 kubectl info 来获取它的基本信息\n\n\t$ kubectl get endpoints kubia\n\tNAME    ENDPOINTS                                                  AGE\n\tkubia   10.44.0.1:8443,10.44.0.2:8443,10.44.0.3:8443 + 3 more...   16h\n\nEndpoint是一个单独的资源并不 是服务的一个属性, 必须手动创建\nexternal-service.yaml\n\n\tapiVersion: v1\n\tkind: Service\n\tmetadata:\n\t  name: external-service\n\tspec:\n\t  ports:\n\t  - port: 80\nexternal-service-endpoints.yaml\n\n\tapiVersion: v1\n\tkind: Endpoints\n\tmetadata:\n\t  name: external-service\n\tsubsets:\n\t  - addresses:\n\t    - ip: 11.11.11.11\n\t    - ip: 22.22.22.22\n\t    ports:\n\t    - port: 80\n部署service和endpoint\n\n\t$ kubectl create -f external-service.yaml\n\t$ kubectl create -f external-service-endpoints.yaml\n\t$ kubectl describe svc/external-service\n\tName:              external-service\n\tNamespace:         default\n\tLabels:            <none>\n\tAnnotations:       <none>\n\tSelector:          <none>\n\tType:              ClusterIP\n\tIP:                10.97.153.150\n\tPort:              <unset>  80/TCP\n\tTargetPort:        80/TCP\n\tEndpoints:         11.11.11.11:80,22.22.22.22:80\n\tSession Affinity:  None\n\tEvents:            <none>\n\n## 暴露service\n • 将服务的类型设置成NodePort -- 每个集群节点都会在节点上打开一个端口， 对于NodePort服务， 每个集群节点在节点本身（因此得名叫NodePort)上打开一个端口，并将在该端口上接收到的流量重定向到基础服务。\n   该服务仅在内部集群 IP 和端口上才可访间， 但也可通过所有节点上的专用端口访问.\n • 将服务的类型设置成LoadBalance, NodePort类型的一种扩展 -- 这使得服务可以通过一个专用的负载均衡器来访问， 这是由Kubernetes中正在运行的云基础设施提供的。 负载均衡器将流量重定向到跨所有节点的节点端口。\n   客户端通过负载均衡器的 IP 连接到服务\n • 创建一 个Ingress资源， 这是一 个完全不同的机制， 通过一 个IP地址公开多个服务——它运行在 HTTP 层（网络协议第 7 层）上， 因此可以提供比工作在第4层的服务更多的功能\n\n\n### NodePort 类型 service\n指定端口不是强制性的。 如果忽略它，Kubemetes将选择一个随机端口.\n客户端发送请求的节点并不重要, 整个互联网可以通过任何节点上的30123(用户自己定义的)端口访问到pod,如下所示\n如在个人机器上生成如下service和pod，可以在以前做的项目的任何机器上通过如下访问\n\n\tcurl -s http://10.239.140.186:30123 (master节点的NodeIP:port)访问服务\n\tcurl -s http://10.239.140.200:30123 (worker02节点的NodeIP:port)访问服务\n\n\nkubia-svc-nodeport.yaml\n\n\tapiVersion: v1\n\tkind: Service\n\tmetadata:\n\t  name: kubia-nodeport\n\tspec:\n\t  type: NodePort\t\t\t// 设置服务类型\n\t  ports:\n\t  - port: 80\t\t\t\t// 服务集群IP端口号\n\t    targetPort: 8080\n\t    nodePort: 30123\t\t\t// 通过集群节点(master或worker)的NodeIP，加上30123端口可以访问服务\n\t  selector:\n\t    app: kubia\n\n\t$ kubectl create -f kubia-svc-nodeport.yaml\n\t\n\t$ kubectl get svc\n\tNAME                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\n\tkubernetes           ClusterIP      10.96.0.1       <none>        443/TCP          43h\n\tkubia-nodeport       NodePort       10.103.7.50     <none>        80:30123/TCP     99m\n\t\n\t$ kubectl describe svc kubia-nodeport\n\tName:                     kubia-nodeport\n\tNamespace:                default\n\tLabels:                   <none>\n\tAnnotations:              <none>\n\tSelector:                 app=kubia\n\tType:                     NodePort\n\tIP:                       10.103.7.50\n\tPort:                     <unset>  80/TCP\n\tTargetPort:               8080/TCP\n\tNodePort:                 <unset>  30123/TCP\n\tEndpoints:                10.44.0.1:8080,10.44.0.2:8080,10.44.0.3:8080\n\tSession Affinity:         None\n\tExternal Traffic Policy:  Cluster\n\tEvents:                   <none>\n\n\t$ kubectl get po -o wide\n\tNAME          READY   STATUS    RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES\n\tkubia         1/1     Running   0          17h   10.44.0.4   server02   <none>           <none>\n\tkubia-5rvfq   1/1     Running   0          17h   10.44.0.2   server02   <none>           <none>\n\tkubia-8cgnm   1/1     Running   0          17h   10.44.0.1   server02   <none>           <none>\n\tkubia-8kv8d   1/1     Running   0          17h   10.44.0.3   server02   <none>           <none>\n查看server02机器IP\n\n\t$kubectl get node -o wide\n\tNAME       STATUS   ROLES    AGE     VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME\n\talpha      Ready    master   2d18h   v1.18.2   10.239.140.186   <none>        Ubuntu 18.04.4 LTS   5.3.0-28-generic    docker://19.3.6\n\tserver02   Ready    <none>   2d17h   v1.18.2   10.239.140.200   <none>        Ubuntu 18.04.4 LTS   4.15.0-76-generic   docker://19.3.6\n两种访问方式\n * 第一种: 通过NodeIP:Port 访问:\n\n\n\t$ curl -s http://10.239.140.200:30123\n\tYou've hit kubia-8kv8d\n\t$ curl -s http://10.239.140.186:30123\n\tYou've hit kubia-5rvfq\n\n * 第二种: 通过 service的CLUSTER-IP：port 进入port进行访问\n\n\n\t$ kubectl exec kubia -- curl -s http://10.103.7.50:80\n\tYou've hit kubia-8kv8d\n\n\n### LoadBalancer 方式访问\n> 如果Kubemetes在不支持Load Badancer服务的环境中运行， 则不会调配负载平衡器， 但该服务仍将表现得像 一 个NodePort服 务。 这是因为LoadBadancer服务是NodePo江服务的扩展\n如果没有指定特定的节点端口， Kubernetes将会选择一个端口\n创建服务后， 云基础架构需要一段时间才能创建负载均衡器并将其 IP 地址写入服务对象。 一旦这样做了， IP 地址将被列为服务的外部 IP 地址\n\nkubia-svc-loadbalancer.yaml\n\n\tapiVersion: v1\n\tkind: Service\n\tmetadata:\n\t  name: kubia-loadbalancer\n\tspec:\n\t  type: LoadBalancer\n\t  ports:\n\t  - port: 80\n\t    targetPort: 8080\n\t  selector:\n\t    app: kubia\n\n\t$ kubectl create -f kubia-svc-loadbalancer.yaml\n\n\t$ kubectl describe svc/kubia-loadbalancer\n\tName:                     kubia-loadbalancer\n\tNamespace:                default\n\tLabels:                   <none>\n\tAnnotations:              <none>\n\tSelector:                 app=kubia\n\tType:                     LoadBalancer\n\tIP:                       10.99.184.62\n\tPort:                     <unset>  80/TCP\n\tTargetPort:               8080/TCP\n\tNodePort:                 <unset>  30994/TCP\t\t// yaml资源文件里没有指定, Kubemetes将会选择一个端口\n\tEndpoints:                10.44.0.1:8080,10.44.0.2:8080,10.44.0.3:8080\n\tSession Affinity:         None\n\tExternal Traffic Policy:  Cluster\n\tEvents:                   <none>\n\n\t$ kubectl get svc\n\tNAME                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\n\tkubernetes           ClusterIP      10.96.0.1       <none>        443/TCP          43h\n\tkubia-loadbalancer   LoadBalancer   10.99.184.62    <pending>     80:30994/TCP     4m11s\n可以看到Kubemetes在不支持Load Badancer服务的环境中运行 EXTERNAL-IP显示为 <pending>状态，但仍然可以像NodePort方式一样访问服务\n\n\t$ kubectl exec kubia -- curl -s http://10.99.184.62:80\n\tYou've hit kubia-8cgnm\n\t$ curl -s 10.239.140.186:30994\t\t// masterIP：svcPort\n\tYou've hit kubia-5rvfq\n\t$ curl -s 10.239.140.200:30994\t\t// worker01：svcPort\n\tYou've hit kubia-8kv8d\n如果支持LoadBalancer且获得EXTERNAL-IP为 130.211.53.173\n可以通过 $ curl http://130.211.53.173 进行访问\n\n\n### Ingress 暴露服务\n> 需要 Ingress一个重要的原因是每个 LoadBalancer 服务都需要自己的负载均衡器， 以及独有的公有 IP 地址， 而 Ingress 只需要一个公网 IP 就能为许多服务提供访问\n> Ingress 在网络栈 (HTTP) 的应用层操作， 并且可以提供一 些服务不能实现的功能， 诸如基于 cookie 的会话亲和性 (session affinity) 等功能\n> Ingress 对象提供的功能之前，必须强调只有 Ingress控制器在集群中运行，Ingress 资源才能正常工作。 不同的 Kubernetes 环境使用不同的控制器实现， 但有些并不提供默认控制器\nIngress通常向外暴露 Service.Type=NodePort 或者 Service.Type=LoadBalancer 类型的服务，因此先创建一个NodePort类型svc.\n\n\t$ kubectl get svc\n\tNAME                  TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\n\tkubia-nodeport        NodePort       10.103.7.50     <none>        80:30123/TCP     144m\n\n创建kubia-ingress.yaml资源文件\n\n\tapiVersion: networking.k8s.io/v1beta1\n\tkind: Ingress\n\tmetadata:\n\t  name: kubia\n\tspec:\n\t  rules:\n\t  - host: kubia.example.com\t\t\t\t// Ingress 将域名kubia.example.com映射到您的服务\n\t    http:\n\t      paths:\n\t      - path: /\n\t        backend:\n\t          serviceName: kubia-nodeport\t// 将所有请求发送到kubia-nodeport服务的80端口\n\t          servicePort: 80\n> kubectl创建ingress.yaml资源文件遇到webhook ...错误时修改master节点上/etc/kubernetes/manifests/kube-apiserver.yaml，将K8s默认用系统配置的proxy注释掉，稍后再运行kubectl create ...就可以了\n\n\t$ kubectl create -f kubia-ingress.yaml\n\t$ kubectl get ingress\t\t// 自己机器上没有获得ADDRESS这列IP\n\tNAME    CLASS    HOSTS               ADDRESS            PORTS   AGE\n\tkubia   <none>   kubia.example.com   192.168.99.100     80      92s\n> 一旦知道 IP 地址，通过配置 DNS 服务器将 kubia.example.com 解析为此 IP地址，或者在/ect/hosts(Windows系统为C:\\windows\\system32\\drivers\\etc\\hosts ）文件中添加下面一行内容：\n\n\t192 168.99.100 kubia.example.com\n通过Ingress访问pod, 环境都己经建立完毕，可以通过 http ：此ubia.example.com 地址访 问服务 （使用浏览器或者 curl 命令）\n\n\t$ curl http://kubia.example.com\n> 客户端如何通过 Ingress 控制器连接到 其 中 一个 pod。客户端首先对 kubia.example.com 执行 DNS 查 找， DNS 服务器（或本地操作系统）返回了In gress 控制器的 IP。\n> 客户端然后 向 Ingress 控制器发送 HTTP 请求，并在 Host 头中指定 kubia . example.com。\n> 控制器从该头部确定客户端尝试访 问哪个服务，通过与该服务关联 的 Endpo int 对象查看 pod IP ， 并将客户端的请求转发给其中一个pod。\n> Ingress 控制器不会将请求转发给该服务，只用它来选择一个pod。大多数（即使不是全部）控制器都是这样工作的.\n\nIngress规范的 rules 和 paths 都是数组，因此它们可以包含多个条目 \n一个 Ingress 可以将 多个主机和路径映射到多个服务\n * 客户端可以通过一个 IP 地址（ Ingress 控制器的 IP 地址 〉访问两种不同的服务\n * 同样，可以使用 Ingress 根据 HTTP 请求中的主机而不是（仅）路径映射到不同的服务\nkubia-ingress.yaml\n\n\n\tapiVersion: networking.k8s.io/v1beta1\n\tkind: Ingress\n\tmetadata:\n\t  name: kubia\n\tspec:\n\t  rules:\n\t  - host: kubia.example.com\t\t\t\t// 对 kubia.example.com 的请求将会转发至kubia服务\n\t    http:\n\t      paths:\n\t      - path: /\n\t        backend:\n\t          serviceName: kubia-nodeport\n\t          servicePort: 80\n\t      - path: /kubia\t\t\t\t\t// 对 kubia.example.com/kubia 的请求将会转发至kubia服务\n\t        backend:\n\t          serviceName: kubia\n\t          servicePort: 80\n\t      - path: /foo\t\t\t\t\t\t// 对 kubia.example.com/foo 的请求将会转发至bar服务\n\t        backend:\n\t          serviceName: bar\n\t          servicePort: 80\n\t  - host: bar.example.com\t\t\t\t// 对 bar.example.com 的请求将会转发至bar服务\n\t    http:\n\t      paths:\n\t      - path: /\n\t        backend:\n\t          serviceName: bar\n\t          servicePort: 80\n\n\t$ kubectl get ingress\n\tNAME    CLASS    HOSTS                               ADDRESS   PORTS   AGE\n\tkubia   <none>   kubia.example.com,bar.example.com             80      3s\nDNS 需要将 foo .example.com 和 bar.example.com 域名都指向 Ingress 控制器的 IP 地址.\n然后像上面一样配置/ect/hosts文件内容,就可以通过域名访问了\n\n### Ingress处理TLS传输\n配置 Ingress 以支持 TLS, Ingress 转发 HTTP 流量.\n\n\n\n## readiness Probe 就绪探针\n> 了解了存活探针，以及它们如何通过确保异常容器自动重启来保持应用程序的正常运行 。 与存活探针类似， Kubernetes 还允许为容器定义准备就绪探针\n> 就绪探测器会定期调用，并确定特定的 pod 是否接收客户端请求 。 当容器的准备就绪探测返回成功时，表示容器己准备好接收请求 \n就绪探针有三种类型:\n * Exec 探针，执行进程的地方。容器的状态由进程的退出状态代码确定 。\n * HTTP GET 探针，向容器发送 HTTP GET 请求，通过响应的 HTTP 状态代码判断容器是否准备好 。\n * TCP socket 探针，它打开一个 TCP 连接到容器的指定端口。如果连接己建立，则认为容器己准备就绪 \n\n启动容器时，可以为 Kubernetes 配置一个等待时间，经过等待时间后才可以执行第一次准备就绪检查。\n之后，它会周期性地调用探针，并根据就绪探针的结果采取行动。\n如果某个 pod 报告它尚未准备就绪，则会从该服务中删除该 pod。如果 pod再次准备就绪，则重新添加 pod.\n存活探针通过杀死异常的容器并用新的正常容器替代它们来保持 pod 正常工作，\n就绪探针确保只有准备好处理请求的 pod 才可以接收它们（请求）\n> 设想一组pod (例如， 运行应用程序服务器的pod)取决于另 一 个pod (例如，后端数据库）提供的服务。 如果任何一个前端连接点出现连接间题并且无法再访问数据库， 那么就绪探针可能会告知Kubemet es该pod没有准备好处理任何请求。 如果其他pod实例没有遇到类似的连接问题， 则它们可以正常处理请求。 就绪探针确保客户端只与正常的pod交互， 并且永远不会知道系统存在问题.\n通过kubectl ed江命令来向已存在的ReplicationController中的pod模板添加探针\nkubia-replicaset-renameport.yaml\n\n\tapiVersion: apps/v1\n\tkind: ReplicaSet\n\tmetadata:\n\t  name: kubia\n\tspec:\n\t  replicas: 3\n\t  selector:\n\t    matchLabels:\n\t      app: kubia\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: kubia\n\t    spec:\n\t      nodeSelector:\n\t        gpu: \"true\"\n\t      containers:\n\t      - name: kubia\n\t        image: luksa/kubia\n\t        readinessProbe:\t\t\t// pod中的每个容器都会有一个就绪探针\n\t          exec:\n\t            command:\n\t            - ls\n\t            - /var/ready\n\t        ports:\n\t        - name: http\n\t          containerPort: 8080\n\t        - name: https\n\t          containerPort: 8443\n创建RS资源并查看READY状态\n\n\t$ kubectl create -f kubia-replicaset-renameport.yaml\n\t$ kubectl get po\n\tNAME          READY   STATUS    RESTARTS   AGE\n\tkubia-2xk54   0/1     Running   0          6m20s\n\tkubia-bj4tz   0/1     Running   0          6m20s\n\tkubia-hr9bx   0/1     Running   0          6m21s\n\n通过创建/var/ready文件使其中一个文件的就绪探针返回成功，该文件的存在可以模拟就绪探针成功\n准备就绪探针会定期检查 默认情况下每 10 秒检查一次, 最晚 10 秒钟内， 该 pod 应该已经准备就绪.\n\n\t$ kubectl exec po/kubia-2xk54 -- touch /var/ready\n\t$ kubectl get po\n\tNAME          READY   STATUS    RESTARTS   AGE\n\tkubia-2xk54   1/1     Running   0          6m26s\n\tkubia-bj4tz   0/1     Running   0          6m26s\n\tkubia-hr9bx   0/1     Running   0          6m27s\n\n\t$ kubectl describe po/kubia-2xk54\n\t......\n\tReadiness:      exec [ls /var/ready] delay=0s timeout=1s period=10s #success=1 #failure=3\n\t......\n\n修改创建过的RS的资源文件里的readiness命令是不生效的, 除非删了重建, 查看readiness Probe如下\n\n\t$ kubectl edit rc kubia\n\n### 再次测试 readiness\n\n\t$ kubectl get po\n\tNAME          READY   STATUS    RESTARTS   AGE\n\tkubia-2xk54   1/1     Running   0          6m20s\n\tkubia-bj4tz   0/1     Running   0          6m20s\n\tkubia-hr9bx   0/1     Running   0          6m21s\n\n\t$ exec kubia-2xk54 -- rm -rf /var/ready\t\t// 过大概10s后\n\n\t$ kubectl get po\n\tNAME          READY   STATUS    RESTARTS   AGE\n\tkubia-2xk54   0/1     Running   0          6m30s\n\tkubia-bj4tz   0/1     Running   0          6m30s\n\tkubia-hr9bx   0/1     Running   0          6m31s\n\n\t$ kubectl exec kubia-bj4tz -- touch /var/ready\t// 过大概10s后\n\t$ kubectl get svc\n\tNAME          READY   STATUS    RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES\n\tkubia-2xk54   0/1     Running   0          6m40s   10.44.0.2   server02   <none>           <none>\n\tkubia-bj4tz   1/1     Running   0          6m40s   10.44.0.3   server02   <none>           <none>\n\tkubia-hr9bx   0/1     Running   0          6m40s   10.44.0.1   server02   <none>           <none>\n查看SVC\n\n\t$ kubectl get svc\t// 也可以通过kubectl exec kubia-bj4tz env 来查看POD所支持的所有SVC的IP等信息\n\tNAME                  TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\n\tkubia                 ClusterIP      10.111.88.195   <none>        80/TCP,443/TCP   22h\n\tkubia-loadbalancer    LoadBalancer   10.102.224.77   <pending>     80:32671/TCP     3h8m\n\n两种访问方式，POD和Node\n第一种POD访问SvcIP:SvcPort方式\n\n\t$kubectl exec kubia -- curl -s  http://10.111.88.195:80\t\t// SvcIP:SvcPort, SvcPort映射到PodIP, 可以通过describe svc查看\n\tYou've hit kubia-bj4tz\n第二种NodeIP:NodePOrt方式\n\n\t$ curl -s 10.239.140.186:32671\t\t// NodeIP:NodePort\n\tYou've hit kubia-bj4tz\n应该通过删除 pod 或更改 pod 标签而不是手动更改探针来从服务中手动移除pod.\n如果想要从某个服务中手动添加或删除 pod, 请将 enabled=true 作为标签添加到 pod, 以及服务的标签选择器中。 当想要从服务中移除 pod 时，删除标签\n应该始终定义一 个就绪探针， 即使它只是向基准 URL 发送 HTTP 请求一样简单。\n\n## headless 服务\n让客户端连接到所有 pod, 需要找出每个 pod 的 IP.Kubemetes 允许客户通过 DNS 查找发现 pod IP.\n但是对千 headless 服务， 由于 DNS 返回了 pod 的 IP,客户端直接连接到该 pod, 而不是通过服务代理.\nheadless 服务仍然提供跨 pod 的负载平衡， 但是通过 DNS 轮询机制不是通过服务代理.\n> 如果告诉Kubemetes, 不需要为服务提供集群 IP (通过在服务 spec 中将 clusterIP 字段设置为 None 来完成此操作）， 则 DNS 服务器将返回 pod IP 而不是单个服务 IP\n> 将服务 spec中的clusterIP字段设置为None 会使服务成 为headless 服务，因为Kubemetes 不会 为其分配集群IP, 客户端可通过该IP将其连接到支持它的pod\nkubia-svc-headless.yaml\n\n\tapiersion: v1\n\tkin: Service\n\tmetdata:\n\t  nme: kubia-headless\n\tspe:\n\t  custerIP: None\t\t// clusterIP字段设置为None 会使服务成 为headless服务\n\t  prts:\n\t  -port: 80\n\t   targetPort: 8080\n\t  slector:\n\t    app: kubia\n\n\t$ kubectl create -f kubia-svc-headless.yaml\n\t$ kubectl get svc\n\tNAME                  TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\n\tkubia-headless        ClusterIP      None            <none>        80/TCP           103s\n\n\n\n\n\n","source":"_posts/micro_service/04_kubernetes_service.md","raw":"---\ntitle: 04 Kubernetes service\ntags: kubernetes\ncategories:\n- microService\n- kubernetes\ntop: 4\n---\n\n## Kubernetes Service\n> Kubemetes 服务是一种为一组功能相同的 pod 提供单一不变的接入点的资源.\n> 当服务存在时，它的 IP 地址和端口不会改变。 客户端通过 IP 地址和端口号建立连接，这些连接会被路由到提供该服务的任意一个 pod上.\n> 通过这种方式， 客户端不需要知道每个单独的提供服务的 pod 的地址， 这样这些 pod 就可以在集群中随时被创建或移除.\n\n通过为前端 pod 创建服务， 并且将其配置成可以在集群外部访问，可以暴露一个单一不变的 IP 地址让外部的客户端连接 pod。 \n同理，可以为后台数据库 pod 创建服务，并为其分配一个固定的 IP 地址。尽管 pod 的 IP 地址会改变，但是服务的 IP 地址固定不变。\n另外，通过创建服务，能够让前端的 pod 通过环境变量或 DNS 以及服务名来访问后端服务\nPod 控制器中使用标签选择器来指定哪些 pod 属于同一 Service。\n\n## service\n> 如果 pod 的标签与服务的 pod 选择器相匹配，那么 pod 就将作为服务的后端.只要创建了具有适当标签的新 pod ，它就成为服务的一部分，并且请求开始被重定向到 pod.\n如下所示Service和POD都采用命名端口的方式, 最大的好处就是即使更换spec pod中的端口号也无须更改服务 spec.\n * 第一步，创建service\n创建service yaml文件 kubia-svc.yaml\n\n\n\tapiVersion: v1\n\tkind: Service\n\tmetadata:\n\t  name: kubia\n\tsepc:\n\t// sessionAffinity: ClientIP\t// 默认此值是None, 若改为ClientIP，则SVC接受到的请求连接只会固定转发给同一个pod\n\t  ports:\n\t  - name: http\t\t\t// 端口别名，可以当作端口号用\n\t    port: 80\t\t\t// 该服务可用的端口\n\t    targetPort: http\t// 服务将连接转发到的POD端口, pod需要将http映射pod本身的8080或其它端口，否则这里只能填写端口号\n\t  - name: https\n\t    port: 443\n\t    targetPort: https\t// 含有label:app=kubia的pod需要将https映射pod本身8443或其它端口，否则这里只能填写端口号\n\t  selector:\n\t    app: kubia\t\t\t// 具有app=kubia标签的pod都属于该服务\n创建了 一个名叫kubia的服务，它将在端口80接收请求并将连接路由到具有标签选择器是app=kubia的pod的8080端口上.\n在发布完YAML文件后， 可以在命名空间下列出来所有的服务资源, 新的服务已经被分配了一个内部集群IP, 只能在集群内部可以被访问.\n\n\t$ kubectl get svc\n\tNAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE\n\tkubernetes   ClusterIP   10.96.0.1      <none>        443/TCP   23h\n\tkubia        ClusterIP   10.98.229.76   <none>        80/TCP    20s\n\n * 第二步，创建两个pod，一个添加标签app=kubia，另一个用来执行测试通过kubectl exec来访问第一个pod\nkubia.yaml\n\n\n\tapiVersion: v1\n\tkind: Pod\n\tmetadata:\n\t  name: kubia\t// name: kubia1; name: kubia2\n\tspec:\n\t  nodeSelector:\t\t// pod被分配到含有标签gpu=true的node上，当然也可以注释掉这两行\n\t    gpu: \"true\"\n\t  containers:\n\t  - image: luksa/kubia\n\t    name: kubia\n\nkubia-label.yaml\n\n\t apiVersion: v1\t\t\t\t\t// api服务版本\n\t kind : Pod\t\t\t\t\t\t// 资源类型\n\t metadata:\n\t   name: kubia-label\t\t\t// pod 名字\n\t   labels:\n\t     app: kubia\t\t\t\t\t// pod添加label\n\t spec :\n\t   nodeSelector:\n\t     gpu: \"true\"\t\t\t\t// node 选择器\n\t   containers:\n\t   - image: luksa/kubia\t\t\t// image 名字\n\t     name: kubia\t\t\t\t// container 名字\n\t     ports:\n\t     - name: http\t\t\t\t// pod端口映射，用http名字代替8080，名字随便取, 可以跟上面的service的targetPort对应起来\n\t       containerPort: 8080\t\t// 用上面的名字定义这个端口号的别名\n\t     - name: https\n\t       containerPort: 8443\n查看POD并执行一个POD去通过上面创建的service(通过label)包含的pod提供的服务.\n其中pod kubia-label中container运行的服务进程监听了8080端口, POD对外也暴露了8080端口\n\n\t$ kubectl get pod --show-labels\n\tNAME           READY   STATUS    RESTARTS   AGE    LABELS\n\tkubia          1/1     Running   0          101m   <none>\n\tkubia-label    1/1     Running   0          98m    app=kubia\n\tkubia-label1   1/1     Running   0          99s    app=kubia\n\tkubia-label2   1/1     Running   0          79s    app=kubia\n\n * 第三步: 执行一个pod用curl命令访问另一个pod提供的服务\n双横杠(--)代表着kubectl命令项的结束.在两个横杠之后的内容是指在pod内部需要执行的命令.\nk8s 服务代理接续curl请求连接，三个包含label为app=kubia的pod任意选择一个pod\n访问服务三种方式,加不加端口都可以\n\n\n\t<p>$ kubectl exec kubia -- curl -s http://10.98.229.76:http</p>\n\t$ kubectl exec kubia -- curl -s http://10.98.229.76:80\n\t$ kubectl exec kubia -- curl -s http://10.98.229.76\n\tYou've hit kubia-label\n\n\t$ kubectl exec kubia -- curl -s http://10.98.229.76\n\tYou've hit kubia-label2\n\t$ kubectl exec kubia -- curl -s http://10.98.229.76\n\tYou've hit kubia-label1\n\n### Affinity 亲和性\nKubernetes 仅仅支持两种形式的会话亲和性服务： None 和 ClientIP\n这种方式将会使服务代理将来自同 一个 client IP 的所有请求转发至同 一个 pod上.\nKubernetes 服务不是在 HTTP 层面上工作。服务处理 TCP 和 UDP 包，并不关心其中的载荷内容。\n因为 cookie 是 HTTP 协议中的一部分，服务并不知道它们，这就解释了为什么会话亲和性不能基千 cookie。\n如果希望特定客户端产生的所有请求每次都指向同 一个 pod, 可以设置服务的 sessionAffinity 属性为 ClientIP (而不是 None,None 是默认值）\n\n\tapiVersion: vl\n\tkind: Service\n\tspec:\n\t  sessionAffinity: ClientIP\n\t......\n\n\n## 环境变量发现service\n### 创建replicaSet 管理 3 个 POD\n\n\tapiVersion: apps/v1\n\tkind: ReplicaSet\n\tmetadata:\n\t  name: kubia\n\tspec:\n\t  replicas: 3\n\t  selector:\n\t    matchLabels:\n\t      app: kubia\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: kubia\n\t    spec:\n\t      nodeSelector:\n\t        gpu: \"true\"\n\t      containers:\n\t      - name: kubia\n\t        image: luksa/kubia\n\t        ports:\n\t        - name: http\n\t          containerPort: 8080\n\t        - name: https\n\t          containerPort: 8443\n\n\t$ kubectl get svc \n\tNAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\n\tkubernetes   ClusterIP   10.96.0.1       <none>        443/TCP          29h\n\tkubia        ClusterIP   10.111.88.195   <none>        80/TCP,443/TCP   3h46m\n查看pod所在的service对应的IP和端口\n\n\t$ kubectl exec kubia-5rvfq env\n\t......\n\tKUBERNETES_SERVICE_PORT=443\n\tKUBIA_SERVICE_PORT=80\t\t\t\t// 服务的集群IP\n\t......\n\tKUBERNETES_SERVICE_HOST=10.96.0.1\n\tKUBIA_SERVICE_HOST=10.111.88.195\t// 服务所在的端口\n\t......\npod 是否使用 内 部的 DNS 服务器是根据 pod 中 spec 的 dnsPolicy 属性来决定的\n\n进入容器后执行如下命令\n\n\t$ kubectl exec kubia-5rvfq -it -- bash\t\t// -- 表示kubectl 命令执行完了，开始执行pod容器里要运行的命令\n\t$ curl http://kubia.default.svc.cluster.local\n\t$ curl http://kubia.default\n\t$ curl http://kubia\n\tYou've hit kubia-5rvfq\n\n\t$ cat /etc/resolv.conf\n\tnameserver 10.96.0.10\t\t// 对应kube-system 里的服务kube-dns服务IP\n\tsearch default.svc.cluster.local svc.cluster.local cluster.local sh.intel.com\n\toptions ndots:5\n\troot@kubia-5rvfq:/# curl http://svc.cluster.local\n\tcurl: (6) Could not resolve host: svc.cluster.local\n\n\t$ ping kubia\n\tPING kubia.default.svc.cluster.local (10.111.88.195): 56 data bytes\n\t^C--- kubia.default.svc.cluster.local ping statistics ---\n\t4 packets transmitted, 0 packets received, 100% packet loss\n上面的 curl 这个服务是工作的，但是却 ping 不通。这是 因为服务的集群 IP 是一个虚拟 IP，并且只有在与服务端口结合时才有意义。 \n\n查看kube-system下面kube-dns信息\n\n\t$ kubectl get svc -n kube-system\n\tNAME       TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE\n\tkube-dns   ClusterIP   10.96.0.10   <none>        53/UDP,53/TCP,9153/TCP   2d3h\n\n### 删除service\n\n\t$ kubectl delete svc kubia\n\n## Service samples\n### 查看service\n\n\t$ kubectl get svc -n kube-system\n\t$ kubectl get svc -n istio-system\n\tNAME                        TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                                                                                                      AGE\n\tgrafana                     ClusterIP      10.104.1.236     <none>        3000/TCP                                                                                                                                     3d5h\n\tistio-egressgateway         ClusterIP      10.107.177.52    <none>        80/TCP,443/TCP,15443/TCP                                                                                                                     3d5h\n\tistio-ingressgateway        LoadBalancer   10.97.82.221     <pending>     15020:31237/TCP,80:31556/TCP,443:30614/TCP,15029:32511/TCP,15030:32423/TCP,15031:30670/TCP,15032:30961/TCP,31400:30196/TCP,15443:31028/TCP   3d5h\n\tistio-pilot                 ClusterIP      10.97.192.70     <none>        15010/TCP,15011/TCP,15012/TCP,8080/TCP,15014/TCP,443/TCP                                                                                     3d5h\n\tistiod                      ClusterIP      10.107.202.199   <none>        15012/TCP,443/TCP\n\t......\n\n\t$ kubectl get services\n\tNAME                        TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE\n\tkubernetes                  ClusterIP      10.3.240.l       <none>        443/TCP          34m\n\tkubia-http                  LoadBalancer   10.3.246.185     <pending>     8080:31348/TCP   4s\n\t暂时忽略 kubernetes 服务，仔细查看创建的kubian-http 服务 。 它还没有外部 IP 地址 ，因为 Kubernetes 运行的云基础设施创建负载均衡需要一段时间\n\t$ kubectl get services\n\tNAME                        TYPE           CLUSTER-IP       EXTERNAL-IP       PORT(S)          AGE\n\tkubernetes                  ClusterIP      10.3.240.l       <none>            443/TCP          34m\n\tkubia-http                  LoadBalancer   103.246.185      104 155.74.57     8080:31348/TCP   4s\n\t现在有外部 IP 了，应用就可以从任何地方通过 http://104.155.74.57:8080 访问\n\t$ curl 104.155.74.57:8080\n\tYou’ve hit kubia-4jfyf\n\n### 查看service的CRD信息\n\n\t$ kubectl get svc istio-ingressgateway -n istio-system -oyaml\n\n## endpoint 服务\n\n\t$ kubectl describe svc kubia\n\tName:              kubia\n\tNamespace:         default\n\tLabels:            <none>\n\tAnnotations:       <none>\n\tSelector:          app=kubia\t\t// 用于创建endpoint列表的服务pod选择器\n\tType:              ClusterIP\n\tIP:                10.111.88.195\n\tPort:              http  80/TCP\n\tTargetPort:        8080/TCP\n\tEndpoints:         10.44.0.1:8080,10.44.0.2:8080,10.44.0.3:8080\t\t// 服务endpoint的pod的IP和端口列表\n\tPort:              https  443/TCP\n\tTargetPort:        8443/TCP\n\tEndpoints:         10.44.0.1:8443,10.44.0.2:8443,10.44.0.3:8443\n\tSession Affinity:  ClientIP\n\tEvents:            <none>\n\n\t$ kubectl get po -o wide\n\tNAME          READY   STATUS    RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES\n\tkubia         1/1     Running   0          15h   10.44.0.4   server02   <none>           <none>\n\tkubia-5rvfq   1/1     Running   0          15h   10.44.0.2   server02   <none>           <none>\n\tkubia-8cgnm   1/1     Running   0          15h   10.44.0.1   server02   <none>           <none>\n\tkubia-8kv8d   1/1     Running   0          15h   10.44.0.3   server02   <none>           <none>\nEndpoint 资源和其他Kubernetes 资源一样，所以可以使用 kubectl info 来获取它的基本信息\n\n\t$ kubectl get endpoints kubia\n\tNAME    ENDPOINTS                                                  AGE\n\tkubia   10.44.0.1:8443,10.44.0.2:8443,10.44.0.3:8443 + 3 more...   16h\n\nEndpoint是一个单独的资源并不 是服务的一个属性, 必须手动创建\nexternal-service.yaml\n\n\tapiVersion: v1\n\tkind: Service\n\tmetadata:\n\t  name: external-service\n\tspec:\n\t  ports:\n\t  - port: 80\nexternal-service-endpoints.yaml\n\n\tapiVersion: v1\n\tkind: Endpoints\n\tmetadata:\n\t  name: external-service\n\tsubsets:\n\t  - addresses:\n\t    - ip: 11.11.11.11\n\t    - ip: 22.22.22.22\n\t    ports:\n\t    - port: 80\n部署service和endpoint\n\n\t$ kubectl create -f external-service.yaml\n\t$ kubectl create -f external-service-endpoints.yaml\n\t$ kubectl describe svc/external-service\n\tName:              external-service\n\tNamespace:         default\n\tLabels:            <none>\n\tAnnotations:       <none>\n\tSelector:          <none>\n\tType:              ClusterIP\n\tIP:                10.97.153.150\n\tPort:              <unset>  80/TCP\n\tTargetPort:        80/TCP\n\tEndpoints:         11.11.11.11:80,22.22.22.22:80\n\tSession Affinity:  None\n\tEvents:            <none>\n\n## 暴露service\n • 将服务的类型设置成NodePort -- 每个集群节点都会在节点上打开一个端口， 对于NodePort服务， 每个集群节点在节点本身（因此得名叫NodePort)上打开一个端口，并将在该端口上接收到的流量重定向到基础服务。\n   该服务仅在内部集群 IP 和端口上才可访间， 但也可通过所有节点上的专用端口访问.\n • 将服务的类型设置成LoadBalance, NodePort类型的一种扩展 -- 这使得服务可以通过一个专用的负载均衡器来访问， 这是由Kubernetes中正在运行的云基础设施提供的。 负载均衡器将流量重定向到跨所有节点的节点端口。\n   客户端通过负载均衡器的 IP 连接到服务\n • 创建一 个Ingress资源， 这是一 个完全不同的机制， 通过一 个IP地址公开多个服务——它运行在 HTTP 层（网络协议第 7 层）上， 因此可以提供比工作在第4层的服务更多的功能\n\n\n### NodePort 类型 service\n指定端口不是强制性的。 如果忽略它，Kubemetes将选择一个随机端口.\n客户端发送请求的节点并不重要, 整个互联网可以通过任何节点上的30123(用户自己定义的)端口访问到pod,如下所示\n如在个人机器上生成如下service和pod，可以在以前做的项目的任何机器上通过如下访问\n\n\tcurl -s http://10.239.140.186:30123 (master节点的NodeIP:port)访问服务\n\tcurl -s http://10.239.140.200:30123 (worker02节点的NodeIP:port)访问服务\n\n\nkubia-svc-nodeport.yaml\n\n\tapiVersion: v1\n\tkind: Service\n\tmetadata:\n\t  name: kubia-nodeport\n\tspec:\n\t  type: NodePort\t\t\t// 设置服务类型\n\t  ports:\n\t  - port: 80\t\t\t\t// 服务集群IP端口号\n\t    targetPort: 8080\n\t    nodePort: 30123\t\t\t// 通过集群节点(master或worker)的NodeIP，加上30123端口可以访问服务\n\t  selector:\n\t    app: kubia\n\n\t$ kubectl create -f kubia-svc-nodeport.yaml\n\t\n\t$ kubectl get svc\n\tNAME                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\n\tkubernetes           ClusterIP      10.96.0.1       <none>        443/TCP          43h\n\tkubia-nodeport       NodePort       10.103.7.50     <none>        80:30123/TCP     99m\n\t\n\t$ kubectl describe svc kubia-nodeport\n\tName:                     kubia-nodeport\n\tNamespace:                default\n\tLabels:                   <none>\n\tAnnotations:              <none>\n\tSelector:                 app=kubia\n\tType:                     NodePort\n\tIP:                       10.103.7.50\n\tPort:                     <unset>  80/TCP\n\tTargetPort:               8080/TCP\n\tNodePort:                 <unset>  30123/TCP\n\tEndpoints:                10.44.0.1:8080,10.44.0.2:8080,10.44.0.3:8080\n\tSession Affinity:         None\n\tExternal Traffic Policy:  Cluster\n\tEvents:                   <none>\n\n\t$ kubectl get po -o wide\n\tNAME          READY   STATUS    RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES\n\tkubia         1/1     Running   0          17h   10.44.0.4   server02   <none>           <none>\n\tkubia-5rvfq   1/1     Running   0          17h   10.44.0.2   server02   <none>           <none>\n\tkubia-8cgnm   1/1     Running   0          17h   10.44.0.1   server02   <none>           <none>\n\tkubia-8kv8d   1/1     Running   0          17h   10.44.0.3   server02   <none>           <none>\n查看server02机器IP\n\n\t$kubectl get node -o wide\n\tNAME       STATUS   ROLES    AGE     VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME\n\talpha      Ready    master   2d18h   v1.18.2   10.239.140.186   <none>        Ubuntu 18.04.4 LTS   5.3.0-28-generic    docker://19.3.6\n\tserver02   Ready    <none>   2d17h   v1.18.2   10.239.140.200   <none>        Ubuntu 18.04.4 LTS   4.15.0-76-generic   docker://19.3.6\n两种访问方式\n * 第一种: 通过NodeIP:Port 访问:\n\n\n\t$ curl -s http://10.239.140.200:30123\n\tYou've hit kubia-8kv8d\n\t$ curl -s http://10.239.140.186:30123\n\tYou've hit kubia-5rvfq\n\n * 第二种: 通过 service的CLUSTER-IP：port 进入port进行访问\n\n\n\t$ kubectl exec kubia -- curl -s http://10.103.7.50:80\n\tYou've hit kubia-8kv8d\n\n\n### LoadBalancer 方式访问\n> 如果Kubemetes在不支持Load Badancer服务的环境中运行， 则不会调配负载平衡器， 但该服务仍将表现得像 一 个NodePort服 务。 这是因为LoadBadancer服务是NodePo江服务的扩展\n如果没有指定特定的节点端口， Kubernetes将会选择一个端口\n创建服务后， 云基础架构需要一段时间才能创建负载均衡器并将其 IP 地址写入服务对象。 一旦这样做了， IP 地址将被列为服务的外部 IP 地址\n\nkubia-svc-loadbalancer.yaml\n\n\tapiVersion: v1\n\tkind: Service\n\tmetadata:\n\t  name: kubia-loadbalancer\n\tspec:\n\t  type: LoadBalancer\n\t  ports:\n\t  - port: 80\n\t    targetPort: 8080\n\t  selector:\n\t    app: kubia\n\n\t$ kubectl create -f kubia-svc-loadbalancer.yaml\n\n\t$ kubectl describe svc/kubia-loadbalancer\n\tName:                     kubia-loadbalancer\n\tNamespace:                default\n\tLabels:                   <none>\n\tAnnotations:              <none>\n\tSelector:                 app=kubia\n\tType:                     LoadBalancer\n\tIP:                       10.99.184.62\n\tPort:                     <unset>  80/TCP\n\tTargetPort:               8080/TCP\n\tNodePort:                 <unset>  30994/TCP\t\t// yaml资源文件里没有指定, Kubemetes将会选择一个端口\n\tEndpoints:                10.44.0.1:8080,10.44.0.2:8080,10.44.0.3:8080\n\tSession Affinity:         None\n\tExternal Traffic Policy:  Cluster\n\tEvents:                   <none>\n\n\t$ kubectl get svc\n\tNAME                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\n\tkubernetes           ClusterIP      10.96.0.1       <none>        443/TCP          43h\n\tkubia-loadbalancer   LoadBalancer   10.99.184.62    <pending>     80:30994/TCP     4m11s\n可以看到Kubemetes在不支持Load Badancer服务的环境中运行 EXTERNAL-IP显示为 <pending>状态，但仍然可以像NodePort方式一样访问服务\n\n\t$ kubectl exec kubia -- curl -s http://10.99.184.62:80\n\tYou've hit kubia-8cgnm\n\t$ curl -s 10.239.140.186:30994\t\t// masterIP：svcPort\n\tYou've hit kubia-5rvfq\n\t$ curl -s 10.239.140.200:30994\t\t// worker01：svcPort\n\tYou've hit kubia-8kv8d\n如果支持LoadBalancer且获得EXTERNAL-IP为 130.211.53.173\n可以通过 $ curl http://130.211.53.173 进行访问\n\n\n### Ingress 暴露服务\n> 需要 Ingress一个重要的原因是每个 LoadBalancer 服务都需要自己的负载均衡器， 以及独有的公有 IP 地址， 而 Ingress 只需要一个公网 IP 就能为许多服务提供访问\n> Ingress 在网络栈 (HTTP) 的应用层操作， 并且可以提供一 些服务不能实现的功能， 诸如基于 cookie 的会话亲和性 (session affinity) 等功能\n> Ingress 对象提供的功能之前，必须强调只有 Ingress控制器在集群中运行，Ingress 资源才能正常工作。 不同的 Kubernetes 环境使用不同的控制器实现， 但有些并不提供默认控制器\nIngress通常向外暴露 Service.Type=NodePort 或者 Service.Type=LoadBalancer 类型的服务，因此先创建一个NodePort类型svc.\n\n\t$ kubectl get svc\n\tNAME                  TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\n\tkubia-nodeport        NodePort       10.103.7.50     <none>        80:30123/TCP     144m\n\n创建kubia-ingress.yaml资源文件\n\n\tapiVersion: networking.k8s.io/v1beta1\n\tkind: Ingress\n\tmetadata:\n\t  name: kubia\n\tspec:\n\t  rules:\n\t  - host: kubia.example.com\t\t\t\t// Ingress 将域名kubia.example.com映射到您的服务\n\t    http:\n\t      paths:\n\t      - path: /\n\t        backend:\n\t          serviceName: kubia-nodeport\t// 将所有请求发送到kubia-nodeport服务的80端口\n\t          servicePort: 80\n> kubectl创建ingress.yaml资源文件遇到webhook ...错误时修改master节点上/etc/kubernetes/manifests/kube-apiserver.yaml，将K8s默认用系统配置的proxy注释掉，稍后再运行kubectl create ...就可以了\n\n\t$ kubectl create -f kubia-ingress.yaml\n\t$ kubectl get ingress\t\t// 自己机器上没有获得ADDRESS这列IP\n\tNAME    CLASS    HOSTS               ADDRESS            PORTS   AGE\n\tkubia   <none>   kubia.example.com   192.168.99.100     80      92s\n> 一旦知道 IP 地址，通过配置 DNS 服务器将 kubia.example.com 解析为此 IP地址，或者在/ect/hosts(Windows系统为C:\\windows\\system32\\drivers\\etc\\hosts ）文件中添加下面一行内容：\n\n\t192 168.99.100 kubia.example.com\n通过Ingress访问pod, 环境都己经建立完毕，可以通过 http ：此ubia.example.com 地址访 问服务 （使用浏览器或者 curl 命令）\n\n\t$ curl http://kubia.example.com\n> 客户端如何通过 Ingress 控制器连接到 其 中 一个 pod。客户端首先对 kubia.example.com 执行 DNS 查 找， DNS 服务器（或本地操作系统）返回了In gress 控制器的 IP。\n> 客户端然后 向 Ingress 控制器发送 HTTP 请求，并在 Host 头中指定 kubia . example.com。\n> 控制器从该头部确定客户端尝试访 问哪个服务，通过与该服务关联 的 Endpo int 对象查看 pod IP ， 并将客户端的请求转发给其中一个pod。\n> Ingress 控制器不会将请求转发给该服务，只用它来选择一个pod。大多数（即使不是全部）控制器都是这样工作的.\n\nIngress规范的 rules 和 paths 都是数组，因此它们可以包含多个条目 \n一个 Ingress 可以将 多个主机和路径映射到多个服务\n * 客户端可以通过一个 IP 地址（ Ingress 控制器的 IP 地址 〉访问两种不同的服务\n * 同样，可以使用 Ingress 根据 HTTP 请求中的主机而不是（仅）路径映射到不同的服务\nkubia-ingress.yaml\n\n\n\tapiVersion: networking.k8s.io/v1beta1\n\tkind: Ingress\n\tmetadata:\n\t  name: kubia\n\tspec:\n\t  rules:\n\t  - host: kubia.example.com\t\t\t\t// 对 kubia.example.com 的请求将会转发至kubia服务\n\t    http:\n\t      paths:\n\t      - path: /\n\t        backend:\n\t          serviceName: kubia-nodeport\n\t          servicePort: 80\n\t      - path: /kubia\t\t\t\t\t// 对 kubia.example.com/kubia 的请求将会转发至kubia服务\n\t        backend:\n\t          serviceName: kubia\n\t          servicePort: 80\n\t      - path: /foo\t\t\t\t\t\t// 对 kubia.example.com/foo 的请求将会转发至bar服务\n\t        backend:\n\t          serviceName: bar\n\t          servicePort: 80\n\t  - host: bar.example.com\t\t\t\t// 对 bar.example.com 的请求将会转发至bar服务\n\t    http:\n\t      paths:\n\t      - path: /\n\t        backend:\n\t          serviceName: bar\n\t          servicePort: 80\n\n\t$ kubectl get ingress\n\tNAME    CLASS    HOSTS                               ADDRESS   PORTS   AGE\n\tkubia   <none>   kubia.example.com,bar.example.com             80      3s\nDNS 需要将 foo .example.com 和 bar.example.com 域名都指向 Ingress 控制器的 IP 地址.\n然后像上面一样配置/ect/hosts文件内容,就可以通过域名访问了\n\n### Ingress处理TLS传输\n配置 Ingress 以支持 TLS, Ingress 转发 HTTP 流量.\n\n\n\n## readiness Probe 就绪探针\n> 了解了存活探针，以及它们如何通过确保异常容器自动重启来保持应用程序的正常运行 。 与存活探针类似， Kubernetes 还允许为容器定义准备就绪探针\n> 就绪探测器会定期调用，并确定特定的 pod 是否接收客户端请求 。 当容器的准备就绪探测返回成功时，表示容器己准备好接收请求 \n就绪探针有三种类型:\n * Exec 探针，执行进程的地方。容器的状态由进程的退出状态代码确定 。\n * HTTP GET 探针，向容器发送 HTTP GET 请求，通过响应的 HTTP 状态代码判断容器是否准备好 。\n * TCP socket 探针，它打开一个 TCP 连接到容器的指定端口。如果连接己建立，则认为容器己准备就绪 \n\n启动容器时，可以为 Kubernetes 配置一个等待时间，经过等待时间后才可以执行第一次准备就绪检查。\n之后，它会周期性地调用探针，并根据就绪探针的结果采取行动。\n如果某个 pod 报告它尚未准备就绪，则会从该服务中删除该 pod。如果 pod再次准备就绪，则重新添加 pod.\n存活探针通过杀死异常的容器并用新的正常容器替代它们来保持 pod 正常工作，\n就绪探针确保只有准备好处理请求的 pod 才可以接收它们（请求）\n> 设想一组pod (例如， 运行应用程序服务器的pod)取决于另 一 个pod (例如，后端数据库）提供的服务。 如果任何一个前端连接点出现连接间题并且无法再访问数据库， 那么就绪探针可能会告知Kubemet es该pod没有准备好处理任何请求。 如果其他pod实例没有遇到类似的连接问题， 则它们可以正常处理请求。 就绪探针确保客户端只与正常的pod交互， 并且永远不会知道系统存在问题.\n通过kubectl ed江命令来向已存在的ReplicationController中的pod模板添加探针\nkubia-replicaset-renameport.yaml\n\n\tapiVersion: apps/v1\n\tkind: ReplicaSet\n\tmetadata:\n\t  name: kubia\n\tspec:\n\t  replicas: 3\n\t  selector:\n\t    matchLabels:\n\t      app: kubia\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: kubia\n\t    spec:\n\t      nodeSelector:\n\t        gpu: \"true\"\n\t      containers:\n\t      - name: kubia\n\t        image: luksa/kubia\n\t        readinessProbe:\t\t\t// pod中的每个容器都会有一个就绪探针\n\t          exec:\n\t            command:\n\t            - ls\n\t            - /var/ready\n\t        ports:\n\t        - name: http\n\t          containerPort: 8080\n\t        - name: https\n\t          containerPort: 8443\n创建RS资源并查看READY状态\n\n\t$ kubectl create -f kubia-replicaset-renameport.yaml\n\t$ kubectl get po\n\tNAME          READY   STATUS    RESTARTS   AGE\n\tkubia-2xk54   0/1     Running   0          6m20s\n\tkubia-bj4tz   0/1     Running   0          6m20s\n\tkubia-hr9bx   0/1     Running   0          6m21s\n\n通过创建/var/ready文件使其中一个文件的就绪探针返回成功，该文件的存在可以模拟就绪探针成功\n准备就绪探针会定期检查 默认情况下每 10 秒检查一次, 最晚 10 秒钟内， 该 pod 应该已经准备就绪.\n\n\t$ kubectl exec po/kubia-2xk54 -- touch /var/ready\n\t$ kubectl get po\n\tNAME          READY   STATUS    RESTARTS   AGE\n\tkubia-2xk54   1/1     Running   0          6m26s\n\tkubia-bj4tz   0/1     Running   0          6m26s\n\tkubia-hr9bx   0/1     Running   0          6m27s\n\n\t$ kubectl describe po/kubia-2xk54\n\t......\n\tReadiness:      exec [ls /var/ready] delay=0s timeout=1s period=10s #success=1 #failure=3\n\t......\n\n修改创建过的RS的资源文件里的readiness命令是不生效的, 除非删了重建, 查看readiness Probe如下\n\n\t$ kubectl edit rc kubia\n\n### 再次测试 readiness\n\n\t$ kubectl get po\n\tNAME          READY   STATUS    RESTARTS   AGE\n\tkubia-2xk54   1/1     Running   0          6m20s\n\tkubia-bj4tz   0/1     Running   0          6m20s\n\tkubia-hr9bx   0/1     Running   0          6m21s\n\n\t$ exec kubia-2xk54 -- rm -rf /var/ready\t\t// 过大概10s后\n\n\t$ kubectl get po\n\tNAME          READY   STATUS    RESTARTS   AGE\n\tkubia-2xk54   0/1     Running   0          6m30s\n\tkubia-bj4tz   0/1     Running   0          6m30s\n\tkubia-hr9bx   0/1     Running   0          6m31s\n\n\t$ kubectl exec kubia-bj4tz -- touch /var/ready\t// 过大概10s后\n\t$ kubectl get svc\n\tNAME          READY   STATUS    RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES\n\tkubia-2xk54   0/1     Running   0          6m40s   10.44.0.2   server02   <none>           <none>\n\tkubia-bj4tz   1/1     Running   0          6m40s   10.44.0.3   server02   <none>           <none>\n\tkubia-hr9bx   0/1     Running   0          6m40s   10.44.0.1   server02   <none>           <none>\n查看SVC\n\n\t$ kubectl get svc\t// 也可以通过kubectl exec kubia-bj4tz env 来查看POD所支持的所有SVC的IP等信息\n\tNAME                  TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\n\tkubia                 ClusterIP      10.111.88.195   <none>        80/TCP,443/TCP   22h\n\tkubia-loadbalancer    LoadBalancer   10.102.224.77   <pending>     80:32671/TCP     3h8m\n\n两种访问方式，POD和Node\n第一种POD访问SvcIP:SvcPort方式\n\n\t$kubectl exec kubia -- curl -s  http://10.111.88.195:80\t\t// SvcIP:SvcPort, SvcPort映射到PodIP, 可以通过describe svc查看\n\tYou've hit kubia-bj4tz\n第二种NodeIP:NodePOrt方式\n\n\t$ curl -s 10.239.140.186:32671\t\t// NodeIP:NodePort\n\tYou've hit kubia-bj4tz\n应该通过删除 pod 或更改 pod 标签而不是手动更改探针来从服务中手动移除pod.\n如果想要从某个服务中手动添加或删除 pod, 请将 enabled=true 作为标签添加到 pod, 以及服务的标签选择器中。 当想要从服务中移除 pod 时，删除标签\n应该始终定义一 个就绪探针， 即使它只是向基准 URL 发送 HTTP 请求一样简单。\n\n## headless 服务\n让客户端连接到所有 pod, 需要找出每个 pod 的 IP.Kubemetes 允许客户通过 DNS 查找发现 pod IP.\n但是对千 headless 服务， 由于 DNS 返回了 pod 的 IP,客户端直接连接到该 pod, 而不是通过服务代理.\nheadless 服务仍然提供跨 pod 的负载平衡， 但是通过 DNS 轮询机制不是通过服务代理.\n> 如果告诉Kubemetes, 不需要为服务提供集群 IP (通过在服务 spec 中将 clusterIP 字段设置为 None 来完成此操作）， 则 DNS 服务器将返回 pod IP 而不是单个服务 IP\n> 将服务 spec中的clusterIP字段设置为None 会使服务成 为headless 服务，因为Kubemetes 不会 为其分配集群IP, 客户端可通过该IP将其连接到支持它的pod\nkubia-svc-headless.yaml\n\n\tapiersion: v1\n\tkin: Service\n\tmetdata:\n\t  nme: kubia-headless\n\tspe:\n\t  custerIP: None\t\t// clusterIP字段设置为None 会使服务成 为headless服务\n\t  prts:\n\t  -port: 80\n\t   targetPort: 8080\n\t  slector:\n\t    app: kubia\n\n\t$ kubectl create -f kubia-svc-headless.yaml\n\t$ kubectl get svc\n\tNAME                  TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\n\tkubia-headless        ClusterIP      None            <none>        80/TCP           103s\n\n\n\n\n\n","slug":"micro_service/04_kubernetes_service","published":1,"date":"2020-08-12T16:05:47.372Z","updated":"2020-08-10T16:36:25.691Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmg40047hohx0rqj1c2t","content":"<h2 id=\"Kubernetes-Service\"><a href=\"#Kubernetes-Service\" class=\"headerlink\" title=\"Kubernetes Service\"></a>Kubernetes Service</h2><blockquote>\n<p>Kubemetes 服务是一种为一组功能相同的 pod 提供单一不变的接入点的资源.<br>当服务存在时，它的 IP 地址和端口不会改变。 客户端通过 IP 地址和端口号建立连接，这些连接会被路由到提供该服务的任意一个 pod上.<br>通过这种方式， 客户端不需要知道每个单独的提供服务的 pod 的地址， 这样这些 pod 就可以在集群中随时被创建或移除.</p>\n</blockquote>\n<p>通过为前端 pod 创建服务， 并且将其配置成可以在集群外部访问，可以暴露一个单一不变的 IP 地址让外部的客户端连接 pod。<br>同理，可以为后台数据库 pod 创建服务，并为其分配一个固定的 IP 地址。尽管 pod 的 IP 地址会改变，但是服务的 IP 地址固定不变。<br>另外，通过创建服务，能够让前端的 pod 通过环境变量或 DNS 以及服务名来访问后端服务<br>Pod 控制器中使用标签选择器来指定哪些 pod 属于同一 Service。</p>\n<h2 id=\"service\"><a href=\"#service\" class=\"headerlink\" title=\"service\"></a>service</h2><blockquote>\n<p>如果 pod 的标签与服务的 pod 选择器相匹配，那么 pod 就将作为服务的后端.只要创建了具有适当标签的新 pod ，它就成为服务的一部分，并且请求开始被重定向到 pod.<br>如下所示Service和POD都采用命名端口的方式, 最大的好处就是即使更换spec pod中的端口号也无须更改服务 spec.</p>\n</blockquote>\n<ul>\n<li>第一步，创建service<br>创建service yaml文件 kubia-svc.yaml</li>\n</ul>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: kubia\nsepc:\n// sessionAffinity: ClientIP    // 默认此值是None, 若改为ClientIP，则SVC接受到的请求连接只会固定转发给同一个pod\n  ports:\n  - name: http            // 端口别名，可以当作端口号用\n    port: 80            // 该服务可用的端口\n    targetPort: http    // 服务将连接转发到的POD端口, pod需要将http映射pod本身的8080或其它端口，否则这里只能填写端口号\n  - name: https\n    port: 443\n    targetPort: https    // 含有label:app=kubia的pod需要将https映射pod本身8443或其它端口，否则这里只能填写端口号\n  selector:\n    app: kubia            // 具有app=kubia标签的pod都属于该服务</code></pre><p>创建了 一个名叫kubia的服务，它将在端口80接收请求并将连接路由到具有标签选择器是app=kubia的pod的8080端口上.<br>在发布完YAML文件后， 可以在命名空间下列出来所有的服务资源, 新的服务已经被分配了一个内部集群IP, 只能在集群内部可以被访问.</p>\n<pre><code>$ kubectl get svc\nNAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE\nkubernetes   ClusterIP   10.96.0.1      &lt;none&gt;        443/TCP   23h\nkubia        ClusterIP   10.98.229.76   &lt;none&gt;        80/TCP    20s</code></pre><ul>\n<li>第二步，创建两个pod，一个添加标签app=kubia，另一个用来执行测试通过kubectl exec来访问第一个pod<br>kubia.yaml</li>\n</ul>\n<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: kubia    // name: kubia1; name: kubia2\nspec:\n  nodeSelector:        // pod被分配到含有标签gpu=true的node上，当然也可以注释掉这两行\n    gpu: &quot;true&quot;\n  containers:\n  - image: luksa/kubia\n    name: kubia</code></pre><p>kubia-label.yaml</p>\n<pre><code>apiVersion: v1                    // api服务版本\nkind : Pod                        // 资源类型\nmetadata:\n  name: kubia-label            // pod 名字\n  labels:\n    app: kubia                    // pod添加label\nspec :\n  nodeSelector:\n    gpu: &quot;true&quot;                // node 选择器\n  containers:\n  - image: luksa/kubia            // image 名字\n    name: kubia                // container 名字\n    ports:\n    - name: http                // pod端口映射，用http名字代替8080，名字随便取, 可以跟上面的service的targetPort对应起来\n      containerPort: 8080        // 用上面的名字定义这个端口号的别名\n    - name: https\n      containerPort: 8443</code></pre><p>查看POD并执行一个POD去通过上面创建的service(通过label)包含的pod提供的服务.<br>其中pod kubia-label中container运行的服务进程监听了8080端口, POD对外也暴露了8080端口</p>\n<pre><code>$ kubectl get pod --show-labels\nNAME           READY   STATUS    RESTARTS   AGE    LABELS\nkubia          1/1     Running   0          101m   &lt;none&gt;\nkubia-label    1/1     Running   0          98m    app=kubia\nkubia-label1   1/1     Running   0          99s    app=kubia\nkubia-label2   1/1     Running   0          79s    app=kubia</code></pre><ul>\n<li>第三步: 执行一个pod用curl命令访问另一个pod提供的服务<br>双横杠(–)代表着kubectl命令项的结束.在两个横杠之后的内容是指在pod内部需要执行的命令.<br>k8s 服务代理接续curl请求连接，三个包含label为app=kubia的pod任意选择一个pod<br>访问服务三种方式,加不加端口都可以</li>\n</ul>\n<pre><code>&lt;p&gt;$ kubectl exec kubia -- curl -s http://10.98.229.76:http&lt;/p&gt;\n$ kubectl exec kubia -- curl -s http://10.98.229.76:80\n$ kubectl exec kubia -- curl -s http://10.98.229.76\nYou&apos;ve hit kubia-label\n\n$ kubectl exec kubia -- curl -s http://10.98.229.76\nYou&apos;ve hit kubia-label2\n$ kubectl exec kubia -- curl -s http://10.98.229.76\nYou&apos;ve hit kubia-label1</code></pre><h3 id=\"Affinity-亲和性\"><a href=\"#Affinity-亲和性\" class=\"headerlink\" title=\"Affinity 亲和性\"></a>Affinity 亲和性</h3><p>Kubernetes 仅仅支持两种形式的会话亲和性服务： None 和 ClientIP<br>这种方式将会使服务代理将来自同 一个 client IP 的所有请求转发至同 一个 pod上.<br>Kubernetes 服务不是在 HTTP 层面上工作。服务处理 TCP 和 UDP 包，并不关心其中的载荷内容。<br>因为 cookie 是 HTTP 协议中的一部分，服务并不知道它们，这就解释了为什么会话亲和性不能基千 cookie。<br>如果希望特定客户端产生的所有请求每次都指向同 一个 pod, 可以设置服务的 sessionAffinity 属性为 ClientIP (而不是 None,None 是默认值）</p>\n<pre><code>apiVersion: vl\nkind: Service\nspec:\n  sessionAffinity: ClientIP\n......</code></pre><h2 id=\"环境变量发现service\"><a href=\"#环境变量发现service\" class=\"headerlink\" title=\"环境变量发现service\"></a>环境变量发现service</h2><h3 id=\"创建replicaSet-管理-3-个-POD\"><a href=\"#创建replicaSet-管理-3-个-POD\" class=\"headerlink\" title=\"创建replicaSet 管理 3 个 POD\"></a>创建replicaSet 管理 3 个 POD</h3><pre><code>apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: kubia\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: kubia\n  template:\n    metadata:\n      labels:\n        app: kubia\n    spec:\n      nodeSelector:\n        gpu: &quot;true&quot;\n      containers:\n      - name: kubia\n        image: luksa/kubia\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: https\n          containerPort: 8443\n\n$ kubectl get svc \nNAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\nkubernetes   ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP          29h\nkubia        ClusterIP   10.111.88.195   &lt;none&gt;        80/TCP,443/TCP   3h46m</code></pre><p>查看pod所在的service对应的IP和端口</p>\n<pre><code>$ kubectl exec kubia-5rvfq env\n......\nKUBERNETES_SERVICE_PORT=443\nKUBIA_SERVICE_PORT=80                // 服务的集群IP\n......\nKUBERNETES_SERVICE_HOST=10.96.0.1\nKUBIA_SERVICE_HOST=10.111.88.195    // 服务所在的端口\n......</code></pre><p>pod 是否使用 内 部的 DNS 服务器是根据 pod 中 spec 的 dnsPolicy 属性来决定的</p>\n<p>进入容器后执行如下命令</p>\n<pre><code>$ kubectl exec kubia-5rvfq -it -- bash        // -- 表示kubectl 命令执行完了，开始执行pod容器里要运行的命令\n$ curl http://kubia.default.svc.cluster.local\n$ curl http://kubia.default\n$ curl http://kubia\nYou&apos;ve hit kubia-5rvfq\n\n$ cat /etc/resolv.conf\nnameserver 10.96.0.10        // 对应kube-system 里的服务kube-dns服务IP\nsearch default.svc.cluster.local svc.cluster.local cluster.local sh.intel.com\noptions ndots:5\nroot@kubia-5rvfq:/# curl http://svc.cluster.local\ncurl: (6) Could not resolve host: svc.cluster.local\n\n$ ping kubia\nPING kubia.default.svc.cluster.local (10.111.88.195): 56 data bytes\n^C--- kubia.default.svc.cluster.local ping statistics ---\n4 packets transmitted, 0 packets received, 100% packet loss</code></pre><p>上面的 curl 这个服务是工作的，但是却 ping 不通。这是 因为服务的集群 IP 是一个虚拟 IP，并且只有在与服务端口结合时才有意义。 </p>\n<p>查看kube-system下面kube-dns信息</p>\n<pre><code>$ kubectl get svc -n kube-system\nNAME       TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE\nkube-dns   ClusterIP   10.96.0.10   &lt;none&gt;        53/UDP,53/TCP,9153/TCP   2d3h</code></pre><h3 id=\"删除service\"><a href=\"#删除service\" class=\"headerlink\" title=\"删除service\"></a>删除service</h3><pre><code>$ kubectl delete svc kubia</code></pre><h2 id=\"Service-samples\"><a href=\"#Service-samples\" class=\"headerlink\" title=\"Service samples\"></a>Service samples</h2><h3 id=\"查看service\"><a href=\"#查看service\" class=\"headerlink\" title=\"查看service\"></a>查看service</h3><pre><code>$ kubectl get svc -n kube-system\n$ kubectl get svc -n istio-system\nNAME                        TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                                                                                                      AGE\ngrafana                     ClusterIP      10.104.1.236     &lt;none&gt;        3000/TCP                                                                                                                                     3d5h\nistio-egressgateway         ClusterIP      10.107.177.52    &lt;none&gt;        80/TCP,443/TCP,15443/TCP                                                                                                                     3d5h\nistio-ingressgateway        LoadBalancer   10.97.82.221     &lt;pending&gt;     15020:31237/TCP,80:31556/TCP,443:30614/TCP,15029:32511/TCP,15030:32423/TCP,15031:30670/TCP,15032:30961/TCP,31400:30196/TCP,15443:31028/TCP   3d5h\nistio-pilot                 ClusterIP      10.97.192.70     &lt;none&gt;        15010/TCP,15011/TCP,15012/TCP,8080/TCP,15014/TCP,443/TCP                                                                                     3d5h\nistiod                      ClusterIP      10.107.202.199   &lt;none&gt;        15012/TCP,443/TCP\n......\n\n$ kubectl get services\nNAME                        TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE\nkubernetes                  ClusterIP      10.3.240.l       &lt;none&gt;        443/TCP          34m\nkubia-http                  LoadBalancer   10.3.246.185     &lt;pending&gt;     8080:31348/TCP   4s\n暂时忽略 kubernetes 服务，仔细查看创建的kubian-http 服务 。 它还没有外部 IP 地址 ，因为 Kubernetes 运行的云基础设施创建负载均衡需要一段时间\n$ kubectl get services\nNAME                        TYPE           CLUSTER-IP       EXTERNAL-IP       PORT(S)          AGE\nkubernetes                  ClusterIP      10.3.240.l       &lt;none&gt;            443/TCP          34m\nkubia-http                  LoadBalancer   103.246.185      104 155.74.57     8080:31348/TCP   4s\n现在有外部 IP 了，应用就可以从任何地方通过 http://104.155.74.57:8080 访问\n$ curl 104.155.74.57:8080\nYou’ve hit kubia-4jfyf</code></pre><h3 id=\"查看service的CRD信息\"><a href=\"#查看service的CRD信息\" class=\"headerlink\" title=\"查看service的CRD信息\"></a>查看service的CRD信息</h3><pre><code>$ kubectl get svc istio-ingressgateway -n istio-system -oyaml</code></pre><h2 id=\"endpoint-服务\"><a href=\"#endpoint-服务\" class=\"headerlink\" title=\"endpoint 服务\"></a>endpoint 服务</h2><pre><code>$ kubectl describe svc kubia\nName:              kubia\nNamespace:         default\nLabels:            &lt;none&gt;\nAnnotations:       &lt;none&gt;\nSelector:          app=kubia        // 用于创建endpoint列表的服务pod选择器\nType:              ClusterIP\nIP:                10.111.88.195\nPort:              http  80/TCP\nTargetPort:        8080/TCP\nEndpoints:         10.44.0.1:8080,10.44.0.2:8080,10.44.0.3:8080        // 服务endpoint的pod的IP和端口列表\nPort:              https  443/TCP\nTargetPort:        8443/TCP\nEndpoints:         10.44.0.1:8443,10.44.0.2:8443,10.44.0.3:8443\nSession Affinity:  ClientIP\nEvents:            &lt;none&gt;\n\n$ kubectl get po -o wide\nNAME          READY   STATUS    RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES\nkubia         1/1     Running   0          15h   10.44.0.4   server02   &lt;none&gt;           &lt;none&gt;\nkubia-5rvfq   1/1     Running   0          15h   10.44.0.2   server02   &lt;none&gt;           &lt;none&gt;\nkubia-8cgnm   1/1     Running   0          15h   10.44.0.1   server02   &lt;none&gt;           &lt;none&gt;\nkubia-8kv8d   1/1     Running   0          15h   10.44.0.3   server02   &lt;none&gt;           &lt;none&gt;</code></pre><p>Endpoint 资源和其他Kubernetes 资源一样，所以可以使用 kubectl info 来获取它的基本信息</p>\n<pre><code>$ kubectl get endpoints kubia\nNAME    ENDPOINTS                                                  AGE\nkubia   10.44.0.1:8443,10.44.0.2:8443,10.44.0.3:8443 + 3 more...   16h</code></pre><p>Endpoint是一个单独的资源并不 是服务的一个属性, 必须手动创建<br>external-service.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: external-service\nspec:\n  ports:\n  - port: 80</code></pre><p>external-service-endpoints.yaml</p>\n<pre><code>apiVersion: v1\nkind: Endpoints\nmetadata:\n  name: external-service\nsubsets:\n  - addresses:\n    - ip: 11.11.11.11\n    - ip: 22.22.22.22\n    ports:\n    - port: 80</code></pre><p>部署service和endpoint</p>\n<pre><code>$ kubectl create -f external-service.yaml\n$ kubectl create -f external-service-endpoints.yaml\n$ kubectl describe svc/external-service\nName:              external-service\nNamespace:         default\nLabels:            &lt;none&gt;\nAnnotations:       &lt;none&gt;\nSelector:          &lt;none&gt;\nType:              ClusterIP\nIP:                10.97.153.150\nPort:              &lt;unset&gt;  80/TCP\nTargetPort:        80/TCP\nEndpoints:         11.11.11.11:80,22.22.22.22:80\nSession Affinity:  None\nEvents:            &lt;none&gt;</code></pre><h2 id=\"暴露service\"><a href=\"#暴露service\" class=\"headerlink\" title=\"暴露service\"></a>暴露service</h2><p> • 将服务的类型设置成NodePort – 每个集群节点都会在节点上打开一个端口， 对于NodePort服务， 每个集群节点在节点本身（因此得名叫NodePort)上打开一个端口，并将在该端口上接收到的流量重定向到基础服务。<br>   该服务仅在内部集群 IP 和端口上才可访间， 但也可通过所有节点上的专用端口访问.<br> • 将服务的类型设置成LoadBalance, NodePort类型的一种扩展 – 这使得服务可以通过一个专用的负载均衡器来访问， 这是由Kubernetes中正在运行的云基础设施提供的。 负载均衡器将流量重定向到跨所有节点的节点端口。<br>   客户端通过负载均衡器的 IP 连接到服务<br> • 创建一 个Ingress资源， 这是一 个完全不同的机制， 通过一 个IP地址公开多个服务——它运行在 HTTP 层（网络协议第 7 层）上， 因此可以提供比工作在第4层的服务更多的功能</p>\n<h3 id=\"NodePort-类型-service\"><a href=\"#NodePort-类型-service\" class=\"headerlink\" title=\"NodePort 类型 service\"></a>NodePort 类型 service</h3><p>指定端口不是强制性的。 如果忽略它，Kubemetes将选择一个随机端口.<br>客户端发送请求的节点并不重要, 整个互联网可以通过任何节点上的30123(用户自己定义的)端口访问到pod,如下所示<br>如在个人机器上生成如下service和pod，可以在以前做的项目的任何机器上通过如下访问</p>\n<pre><code>curl -s http://10.239.140.186:30123 (master节点的NodeIP:port)访问服务\ncurl -s http://10.239.140.200:30123 (worker02节点的NodeIP:port)访问服务</code></pre><p>kubia-svc-nodeport.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: kubia-nodeport\nspec:\n  type: NodePort            // 设置服务类型\n  ports:\n  - port: 80                // 服务集群IP端口号\n    targetPort: 8080\n    nodePort: 30123            // 通过集群节点(master或worker)的NodeIP，加上30123端口可以访问服务\n  selector:\n    app: kubia\n\n$ kubectl create -f kubia-svc-nodeport.yaml\n\n$ kubectl get svc\nNAME                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\nkubernetes           ClusterIP      10.96.0.1       &lt;none&gt;        443/TCP          43h\nkubia-nodeport       NodePort       10.103.7.50     &lt;none&gt;        80:30123/TCP     99m\n\n$ kubectl describe svc kubia-nodeport\nName:                     kubia-nodeport\nNamespace:                default\nLabels:                   &lt;none&gt;\nAnnotations:              &lt;none&gt;\nSelector:                 app=kubia\nType:                     NodePort\nIP:                       10.103.7.50\nPort:                     &lt;unset&gt;  80/TCP\nTargetPort:               8080/TCP\nNodePort:                 &lt;unset&gt;  30123/TCP\nEndpoints:                10.44.0.1:8080,10.44.0.2:8080,10.44.0.3:8080\nSession Affinity:         None\nExternal Traffic Policy:  Cluster\nEvents:                   &lt;none&gt;\n\n$ kubectl get po -o wide\nNAME          READY   STATUS    RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES\nkubia         1/1     Running   0          17h   10.44.0.4   server02   &lt;none&gt;           &lt;none&gt;\nkubia-5rvfq   1/1     Running   0          17h   10.44.0.2   server02   &lt;none&gt;           &lt;none&gt;\nkubia-8cgnm   1/1     Running   0          17h   10.44.0.1   server02   &lt;none&gt;           &lt;none&gt;\nkubia-8kv8d   1/1     Running   0          17h   10.44.0.3   server02   &lt;none&gt;           &lt;none&gt;</code></pre><p>查看server02机器IP</p>\n<pre><code>$kubectl get node -o wide\nNAME       STATUS   ROLES    AGE     VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME\nalpha      Ready    master   2d18h   v1.18.2   10.239.140.186   &lt;none&gt;        Ubuntu 18.04.4 LTS   5.3.0-28-generic    docker://19.3.6\nserver02   Ready    &lt;none&gt;   2d17h   v1.18.2   10.239.140.200   &lt;none&gt;        Ubuntu 18.04.4 LTS   4.15.0-76-generic   docker://19.3.6</code></pre><p>两种访问方式</p>\n<ul>\n<li>第一种: 通过NodeIP:Port 访问:</li>\n</ul>\n<pre><code>$ curl -s http://10.239.140.200:30123\nYou&apos;ve hit kubia-8kv8d\n$ curl -s http://10.239.140.186:30123\nYou&apos;ve hit kubia-5rvfq</code></pre><ul>\n<li>第二种: 通过 service的CLUSTER-IP：port 进入port进行访问</li>\n</ul>\n<pre><code>$ kubectl exec kubia -- curl -s http://10.103.7.50:80\nYou&apos;ve hit kubia-8kv8d</code></pre><h3 id=\"LoadBalancer-方式访问\"><a href=\"#LoadBalancer-方式访问\" class=\"headerlink\" title=\"LoadBalancer 方式访问\"></a>LoadBalancer 方式访问</h3><blockquote>\n<p>如果Kubemetes在不支持Load Badancer服务的环境中运行， 则不会调配负载平衡器， 但该服务仍将表现得像 一 个NodePort服 务。 这是因为LoadBadancer服务是NodePo江服务的扩展<br>如果没有指定特定的节点端口， Kubernetes将会选择一个端口<br>创建服务后， 云基础架构需要一段时间才能创建负载均衡器并将其 IP 地址写入服务对象。 一旦这样做了， IP 地址将被列为服务的外部 IP 地址</p>\n</blockquote>\n<p>kubia-svc-loadbalancer.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: kubia-loadbalancer\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 80\n    targetPort: 8080\n  selector:\n    app: kubia\n\n$ kubectl create -f kubia-svc-loadbalancer.yaml\n\n$ kubectl describe svc/kubia-loadbalancer\nName:                     kubia-loadbalancer\nNamespace:                default\nLabels:                   &lt;none&gt;\nAnnotations:              &lt;none&gt;\nSelector:                 app=kubia\nType:                     LoadBalancer\nIP:                       10.99.184.62\nPort:                     &lt;unset&gt;  80/TCP\nTargetPort:               8080/TCP\nNodePort:                 &lt;unset&gt;  30994/TCP        // yaml资源文件里没有指定, Kubemetes将会选择一个端口\nEndpoints:                10.44.0.1:8080,10.44.0.2:8080,10.44.0.3:8080\nSession Affinity:         None\nExternal Traffic Policy:  Cluster\nEvents:                   &lt;none&gt;\n\n$ kubectl get svc\nNAME                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\nkubernetes           ClusterIP      10.96.0.1       &lt;none&gt;        443/TCP          43h\nkubia-loadbalancer   LoadBalancer   10.99.184.62    &lt;pending&gt;     80:30994/TCP     4m11s</code></pre><p>可以看到Kubemetes在不支持Load Badancer服务的环境中运行 EXTERNAL-IP显示为 <pending>状态，但仍然可以像NodePort方式一样访问服务</p>\n<pre><code>$ kubectl exec kubia -- curl -s http://10.99.184.62:80\nYou&apos;ve hit kubia-8cgnm\n$ curl -s 10.239.140.186:30994        // masterIP：svcPort\nYou&apos;ve hit kubia-5rvfq\n$ curl -s 10.239.140.200:30994        // worker01：svcPort\nYou&apos;ve hit kubia-8kv8d</code></pre><p>如果支持LoadBalancer且获得EXTERNAL-IP为 130.211.53.173<br>可以通过 $ curl <a href=\"http://130.211.53.173\" target=\"_blank\" rel=\"noopener\">http://130.211.53.173</a> 进行访问</p>\n<h3 id=\"Ingress-暴露服务\"><a href=\"#Ingress-暴露服务\" class=\"headerlink\" title=\"Ingress 暴露服务\"></a>Ingress 暴露服务</h3><blockquote>\n<p>需要 Ingress一个重要的原因是每个 LoadBalancer 服务都需要自己的负载均衡器， 以及独有的公有 IP 地址， 而 Ingress 只需要一个公网 IP 就能为许多服务提供访问<br>Ingress 在网络栈 (HTTP) 的应用层操作， 并且可以提供一 些服务不能实现的功能， 诸如基于 cookie 的会话亲和性 (session affinity) 等功能<br>Ingress 对象提供的功能之前，必须强调只有 Ingress控制器在集群中运行，Ingress 资源才能正常工作。 不同的 Kubernetes 环境使用不同的控制器实现， 但有些并不提供默认控制器<br>Ingress通常向外暴露 Service.Type=NodePort 或者 Service.Type=LoadBalancer 类型的服务，因此先创建一个NodePort类型svc.</p>\n</blockquote>\n<pre><code>$ kubectl get svc\nNAME                  TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\nkubia-nodeport        NodePort       10.103.7.50     &lt;none&gt;        80:30123/TCP     144m</code></pre><p>创建kubia-ingress.yaml资源文件</p>\n<pre><code>apiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  name: kubia\nspec:\n  rules:\n  - host: kubia.example.com                // Ingress 将域名kubia.example.com映射到您的服务\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: kubia-nodeport    // 将所有请求发送到kubia-nodeport服务的80端口\n          servicePort: 80</code></pre><blockquote>\n<p>kubectl创建ingress.yaml资源文件遇到webhook …错误时修改master节点上/etc/kubernetes/manifests/kube-apiserver.yaml，将K8s默认用系统配置的proxy注释掉，稍后再运行kubectl create …就可以了</p>\n</blockquote>\n<pre><code>$ kubectl create -f kubia-ingress.yaml\n$ kubectl get ingress        // 自己机器上没有获得ADDRESS这列IP\nNAME    CLASS    HOSTS               ADDRESS            PORTS   AGE\nkubia   &lt;none&gt;   kubia.example.com   192.168.99.100     80      92s</code></pre><blockquote>\n<p>一旦知道 IP 地址，通过配置 DNS 服务器将 kubia.example.com 解析为此 IP地址，或者在/ect/hosts(Windows系统为C:\\windows\\system32\\drivers\\etc\\hosts ）文件中添加下面一行内容：</p>\n</blockquote>\n<pre><code>192 168.99.100 kubia.example.com</code></pre><p>通过Ingress访问pod, 环境都己经建立完毕，可以通过 http ：此ubia.example.com 地址访 问服务 （使用浏览器或者 curl 命令）</p>\n<pre><code>$ curl http://kubia.example.com</code></pre><blockquote>\n<p>客户端如何通过 Ingress 控制器连接到 其 中 一个 pod。客户端首先对 kubia.example.com 执行 DNS 查 找， DNS 服务器（或本地操作系统）返回了In gress 控制器的 IP。<br>客户端然后 向 Ingress 控制器发送 HTTP 请求，并在 Host 头中指定 kubia . example.com。<br>控制器从该头部确定客户端尝试访 问哪个服务，通过与该服务关联 的 Endpo int 对象查看 pod IP ， 并将客户端的请求转发给其中一个pod。<br>Ingress 控制器不会将请求转发给该服务，只用它来选择一个pod。大多数（即使不是全部）控制器都是这样工作的.</p>\n</blockquote>\n<p>Ingress规范的 rules 和 paths 都是数组，因此它们可以包含多个条目<br>一个 Ingress 可以将 多个主机和路径映射到多个服务</p>\n<ul>\n<li>客户端可以通过一个 IP 地址（ Ingress 控制器的 IP 地址 〉访问两种不同的服务</li>\n<li>同样，可以使用 Ingress 根据 HTTP 请求中的主机而不是（仅）路径映射到不同的服务<br>kubia-ingress.yaml</li>\n</ul>\n<pre><code>apiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  name: kubia\nspec:\n  rules:\n  - host: kubia.example.com                // 对 kubia.example.com 的请求将会转发至kubia服务\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: kubia-nodeport\n          servicePort: 80\n      - path: /kubia                    // 对 kubia.example.com/kubia 的请求将会转发至kubia服务\n        backend:\n          serviceName: kubia\n          servicePort: 80\n      - path: /foo                        // 对 kubia.example.com/foo 的请求将会转发至bar服务\n        backend:\n          serviceName: bar\n          servicePort: 80\n  - host: bar.example.com                // 对 bar.example.com 的请求将会转发至bar服务\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: bar\n          servicePort: 80\n\n$ kubectl get ingress\nNAME    CLASS    HOSTS                               ADDRESS   PORTS   AGE\nkubia   &lt;none&gt;   kubia.example.com,bar.example.com             80      3s</code></pre><p>DNS 需要将 foo .example.com 和 bar.example.com 域名都指向 Ingress 控制器的 IP 地址.<br>然后像上面一样配置/ect/hosts文件内容,就可以通过域名访问了</p>\n<h3 id=\"Ingress处理TLS传输\"><a href=\"#Ingress处理TLS传输\" class=\"headerlink\" title=\"Ingress处理TLS传输\"></a>Ingress处理TLS传输</h3><p>配置 Ingress 以支持 TLS, Ingress 转发 HTTP 流量.</p>\n<h2 id=\"readiness-Probe-就绪探针\"><a href=\"#readiness-Probe-就绪探针\" class=\"headerlink\" title=\"readiness Probe 就绪探针\"></a>readiness Probe 就绪探针</h2><blockquote>\n<p>了解了存活探针，以及它们如何通过确保异常容器自动重启来保持应用程序的正常运行 。 与存活探针类似， Kubernetes 还允许为容器定义准备就绪探针<br>就绪探测器会定期调用，并确定特定的 pod 是否接收客户端请求 。 当容器的准备就绪探测返回成功时，表示容器己准备好接收请求<br>就绪探针有三种类型:</p>\n</blockquote>\n<ul>\n<li>Exec 探针，执行进程的地方。容器的状态由进程的退出状态代码确定 。</li>\n<li>HTTP GET 探针，向容器发送 HTTP GET 请求，通过响应的 HTTP 状态代码判断容器是否准备好 。</li>\n<li>TCP socket 探针，它打开一个 TCP 连接到容器的指定端口。如果连接己建立，则认为容器己准备就绪 </li>\n</ul>\n<p>启动容器时，可以为 Kubernetes 配置一个等待时间，经过等待时间后才可以执行第一次准备就绪检查。<br>之后，它会周期性地调用探针，并根据就绪探针的结果采取行动。<br>如果某个 pod 报告它尚未准备就绪，则会从该服务中删除该 pod。如果 pod再次准备就绪，则重新添加 pod.<br>存活探针通过杀死异常的容器并用新的正常容器替代它们来保持 pod 正常工作，<br>就绪探针确保只有准备好处理请求的 pod 才可以接收它们（请求）</p>\n<blockquote>\n<p>设想一组pod (例如， 运行应用程序服务器的pod)取决于另 一 个pod (例如，后端数据库）提供的服务。 如果任何一个前端连接点出现连接间题并且无法再访问数据库， 那么就绪探针可能会告知Kubemet es该pod没有准备好处理任何请求。 如果其他pod实例没有遇到类似的连接问题， 则它们可以正常处理请求。 就绪探针确保客户端只与正常的pod交互， 并且永远不会知道系统存在问题.<br>通过kubectl ed江命令来向已存在的ReplicationController中的pod模板添加探针<br>kubia-replicaset-renameport.yaml</p>\n</blockquote>\n<pre><code>apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: kubia\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: kubia\n  template:\n    metadata:\n      labels:\n        app: kubia\n    spec:\n      nodeSelector:\n        gpu: &quot;true&quot;\n      containers:\n      - name: kubia\n        image: luksa/kubia\n        readinessProbe:            // pod中的每个容器都会有一个就绪探针\n          exec:\n            command:\n            - ls\n            - /var/ready\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: https\n          containerPort: 8443</code></pre><p>创建RS资源并查看READY状态</p>\n<pre><code>$ kubectl create -f kubia-replicaset-renameport.yaml\n$ kubectl get po\nNAME          READY   STATUS    RESTARTS   AGE\nkubia-2xk54   0/1     Running   0          6m20s\nkubia-bj4tz   0/1     Running   0          6m20s\nkubia-hr9bx   0/1     Running   0          6m21s</code></pre><p>通过创建/var/ready文件使其中一个文件的就绪探针返回成功，该文件的存在可以模拟就绪探针成功<br>准备就绪探针会定期检查 默认情况下每 10 秒检查一次, 最晚 10 秒钟内， 该 pod 应该已经准备就绪.</p>\n<pre><code>$ kubectl exec po/kubia-2xk54 -- touch /var/ready\n$ kubectl get po\nNAME          READY   STATUS    RESTARTS   AGE\nkubia-2xk54   1/1     Running   0          6m26s\nkubia-bj4tz   0/1     Running   0          6m26s\nkubia-hr9bx   0/1     Running   0          6m27s\n\n$ kubectl describe po/kubia-2xk54\n......\nReadiness:      exec [ls /var/ready] delay=0s timeout=1s period=10s #success=1 #failure=3\n......</code></pre><p>修改创建过的RS的资源文件里的readiness命令是不生效的, 除非删了重建, 查看readiness Probe如下</p>\n<pre><code>$ kubectl edit rc kubia</code></pre><h3 id=\"再次测试-readiness\"><a href=\"#再次测试-readiness\" class=\"headerlink\" title=\"再次测试 readiness\"></a>再次测试 readiness</h3><pre><code>$ kubectl get po\nNAME          READY   STATUS    RESTARTS   AGE\nkubia-2xk54   1/1     Running   0          6m20s\nkubia-bj4tz   0/1     Running   0          6m20s\nkubia-hr9bx   0/1     Running   0          6m21s\n\n$ exec kubia-2xk54 -- rm -rf /var/ready        // 过大概10s后\n\n$ kubectl get po\nNAME          READY   STATUS    RESTARTS   AGE\nkubia-2xk54   0/1     Running   0          6m30s\nkubia-bj4tz   0/1     Running   0          6m30s\nkubia-hr9bx   0/1     Running   0          6m31s\n\n$ kubectl exec kubia-bj4tz -- touch /var/ready    // 过大概10s后\n$ kubectl get svc\nNAME          READY   STATUS    RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES\nkubia-2xk54   0/1     Running   0          6m40s   10.44.0.2   server02   &lt;none&gt;           &lt;none&gt;\nkubia-bj4tz   1/1     Running   0          6m40s   10.44.0.3   server02   &lt;none&gt;           &lt;none&gt;\nkubia-hr9bx   0/1     Running   0          6m40s   10.44.0.1   server02   &lt;none&gt;           &lt;none&gt;</code></pre><p>查看SVC</p>\n<pre><code>$ kubectl get svc    // 也可以通过kubectl exec kubia-bj4tz env 来查看POD所支持的所有SVC的IP等信息\nNAME                  TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\nkubia                 ClusterIP      10.111.88.195   &lt;none&gt;        80/TCP,443/TCP   22h\nkubia-loadbalancer    LoadBalancer   10.102.224.77   &lt;pending&gt;     80:32671/TCP     3h8m</code></pre><p>两种访问方式，POD和Node<br>第一种POD访问SvcIP:SvcPort方式</p>\n<pre><code>$kubectl exec kubia -- curl -s  http://10.111.88.195:80        // SvcIP:SvcPort, SvcPort映射到PodIP, 可以通过describe svc查看\nYou&apos;ve hit kubia-bj4tz</code></pre><p>第二种NodeIP:NodePOrt方式</p>\n<pre><code>$ curl -s 10.239.140.186:32671        // NodeIP:NodePort\nYou&apos;ve hit kubia-bj4tz</code></pre><p>应该通过删除 pod 或更改 pod 标签而不是手动更改探针来从服务中手动移除pod.<br>如果想要从某个服务中手动添加或删除 pod, 请将 enabled=true 作为标签添加到 pod, 以及服务的标签选择器中。 当想要从服务中移除 pod 时，删除标签<br>应该始终定义一 个就绪探针， 即使它只是向基准 URL 发送 HTTP 请求一样简单。</p>\n<h2 id=\"headless-服务\"><a href=\"#headless-服务\" class=\"headerlink\" title=\"headless 服务\"></a>headless 服务</h2><p>让客户端连接到所有 pod, 需要找出每个 pod 的 IP.Kubemetes 允许客户通过 DNS 查找发现 pod IP.<br>但是对千 headless 服务， 由于 DNS 返回了 pod 的 IP,客户端直接连接到该 pod, 而不是通过服务代理.<br>headless 服务仍然提供跨 pod 的负载平衡， 但是通过 DNS 轮询机制不是通过服务代理.</p>\n<blockquote>\n<p>如果告诉Kubemetes, 不需要为服务提供集群 IP (通过在服务 spec 中将 clusterIP 字段设置为 None 来完成此操作）， 则 DNS 服务器将返回 pod IP 而不是单个服务 IP<br>将服务 spec中的clusterIP字段设置为None 会使服务成 为headless 服务，因为Kubemetes 不会 为其分配集群IP, 客户端可通过该IP将其连接到支持它的pod<br>kubia-svc-headless.yaml</p>\n</blockquote>\n<pre><code>apiersion: v1\nkin: Service\nmetdata:\n  nme: kubia-headless\nspe:\n  custerIP: None        // clusterIP字段设置为None 会使服务成 为headless服务\n  prts:\n  -port: 80\n   targetPort: 8080\n  slector:\n    app: kubia\n\n$ kubectl create -f kubia-svc-headless.yaml\n$ kubectl get svc\nNAME                  TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\nkubia-headless        ClusterIP      None            &lt;none&gt;        80/TCP           103s</code></pre>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Kubernetes-Service\"><a href=\"#Kubernetes-Service\" class=\"headerlink\" title=\"Kubernetes Service\"></a>Kubernetes Service</h2><blockquote>\n<p>Kubemetes 服务是一种为一组功能相同的 pod 提供单一不变的接入点的资源.<br>当服务存在时，它的 IP 地址和端口不会改变。 客户端通过 IP 地址和端口号建立连接，这些连接会被路由到提供该服务的任意一个 pod上.<br>通过这种方式， 客户端不需要知道每个单独的提供服务的 pod 的地址， 这样这些 pod 就可以在集群中随时被创建或移除.</p>\n</blockquote>\n<p>通过为前端 pod 创建服务， 并且将其配置成可以在集群外部访问，可以暴露一个单一不变的 IP 地址让外部的客户端连接 pod。<br>同理，可以为后台数据库 pod 创建服务，并为其分配一个固定的 IP 地址。尽管 pod 的 IP 地址会改变，但是服务的 IP 地址固定不变。<br>另外，通过创建服务，能够让前端的 pod 通过环境变量或 DNS 以及服务名来访问后端服务<br>Pod 控制器中使用标签选择器来指定哪些 pod 属于同一 Service。</p>\n<h2 id=\"service\"><a href=\"#service\" class=\"headerlink\" title=\"service\"></a>service</h2><blockquote>\n<p>如果 pod 的标签与服务的 pod 选择器相匹配，那么 pod 就将作为服务的后端.只要创建了具有适当标签的新 pod ，它就成为服务的一部分，并且请求开始被重定向到 pod.<br>如下所示Service和POD都采用命名端口的方式, 最大的好处就是即使更换spec pod中的端口号也无须更改服务 spec.</p>\n</blockquote>\n<ul>\n<li>第一步，创建service<br>创建service yaml文件 kubia-svc.yaml</li>\n</ul>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: kubia\nsepc:\n// sessionAffinity: ClientIP    // 默认此值是None, 若改为ClientIP，则SVC接受到的请求连接只会固定转发给同一个pod\n  ports:\n  - name: http            // 端口别名，可以当作端口号用\n    port: 80            // 该服务可用的端口\n    targetPort: http    // 服务将连接转发到的POD端口, pod需要将http映射pod本身的8080或其它端口，否则这里只能填写端口号\n  - name: https\n    port: 443\n    targetPort: https    // 含有label:app=kubia的pod需要将https映射pod本身8443或其它端口，否则这里只能填写端口号\n  selector:\n    app: kubia            // 具有app=kubia标签的pod都属于该服务</code></pre><p>创建了 一个名叫kubia的服务，它将在端口80接收请求并将连接路由到具有标签选择器是app=kubia的pod的8080端口上.<br>在发布完YAML文件后， 可以在命名空间下列出来所有的服务资源, 新的服务已经被分配了一个内部集群IP, 只能在集群内部可以被访问.</p>\n<pre><code>$ kubectl get svc\nNAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE\nkubernetes   ClusterIP   10.96.0.1      &lt;none&gt;        443/TCP   23h\nkubia        ClusterIP   10.98.229.76   &lt;none&gt;        80/TCP    20s</code></pre><ul>\n<li>第二步，创建两个pod，一个添加标签app=kubia，另一个用来执行测试通过kubectl exec来访问第一个pod<br>kubia.yaml</li>\n</ul>\n<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: kubia    // name: kubia1; name: kubia2\nspec:\n  nodeSelector:        // pod被分配到含有标签gpu=true的node上，当然也可以注释掉这两行\n    gpu: &quot;true&quot;\n  containers:\n  - image: luksa/kubia\n    name: kubia</code></pre><p>kubia-label.yaml</p>\n<pre><code>apiVersion: v1                    // api服务版本\nkind : Pod                        // 资源类型\nmetadata:\n  name: kubia-label            // pod 名字\n  labels:\n    app: kubia                    // pod添加label\nspec :\n  nodeSelector:\n    gpu: &quot;true&quot;                // node 选择器\n  containers:\n  - image: luksa/kubia            // image 名字\n    name: kubia                // container 名字\n    ports:\n    - name: http                // pod端口映射，用http名字代替8080，名字随便取, 可以跟上面的service的targetPort对应起来\n      containerPort: 8080        // 用上面的名字定义这个端口号的别名\n    - name: https\n      containerPort: 8443</code></pre><p>查看POD并执行一个POD去通过上面创建的service(通过label)包含的pod提供的服务.<br>其中pod kubia-label中container运行的服务进程监听了8080端口, POD对外也暴露了8080端口</p>\n<pre><code>$ kubectl get pod --show-labels\nNAME           READY   STATUS    RESTARTS   AGE    LABELS\nkubia          1/1     Running   0          101m   &lt;none&gt;\nkubia-label    1/1     Running   0          98m    app=kubia\nkubia-label1   1/1     Running   0          99s    app=kubia\nkubia-label2   1/1     Running   0          79s    app=kubia</code></pre><ul>\n<li>第三步: 执行一个pod用curl命令访问另一个pod提供的服务<br>双横杠(–)代表着kubectl命令项的结束.在两个横杠之后的内容是指在pod内部需要执行的命令.<br>k8s 服务代理接续curl请求连接，三个包含label为app=kubia的pod任意选择一个pod<br>访问服务三种方式,加不加端口都可以</li>\n</ul>\n<pre><code>&lt;p&gt;$ kubectl exec kubia -- curl -s http://10.98.229.76:http&lt;/p&gt;\n$ kubectl exec kubia -- curl -s http://10.98.229.76:80\n$ kubectl exec kubia -- curl -s http://10.98.229.76\nYou&apos;ve hit kubia-label\n\n$ kubectl exec kubia -- curl -s http://10.98.229.76\nYou&apos;ve hit kubia-label2\n$ kubectl exec kubia -- curl -s http://10.98.229.76\nYou&apos;ve hit kubia-label1</code></pre><h3 id=\"Affinity-亲和性\"><a href=\"#Affinity-亲和性\" class=\"headerlink\" title=\"Affinity 亲和性\"></a>Affinity 亲和性</h3><p>Kubernetes 仅仅支持两种形式的会话亲和性服务： None 和 ClientIP<br>这种方式将会使服务代理将来自同 一个 client IP 的所有请求转发至同 一个 pod上.<br>Kubernetes 服务不是在 HTTP 层面上工作。服务处理 TCP 和 UDP 包，并不关心其中的载荷内容。<br>因为 cookie 是 HTTP 协议中的一部分，服务并不知道它们，这就解释了为什么会话亲和性不能基千 cookie。<br>如果希望特定客户端产生的所有请求每次都指向同 一个 pod, 可以设置服务的 sessionAffinity 属性为 ClientIP (而不是 None,None 是默认值）</p>\n<pre><code>apiVersion: vl\nkind: Service\nspec:\n  sessionAffinity: ClientIP\n......</code></pre><h2 id=\"环境变量发现service\"><a href=\"#环境变量发现service\" class=\"headerlink\" title=\"环境变量发现service\"></a>环境变量发现service</h2><h3 id=\"创建replicaSet-管理-3-个-POD\"><a href=\"#创建replicaSet-管理-3-个-POD\" class=\"headerlink\" title=\"创建replicaSet 管理 3 个 POD\"></a>创建replicaSet 管理 3 个 POD</h3><pre><code>apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: kubia\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: kubia\n  template:\n    metadata:\n      labels:\n        app: kubia\n    spec:\n      nodeSelector:\n        gpu: &quot;true&quot;\n      containers:\n      - name: kubia\n        image: luksa/kubia\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: https\n          containerPort: 8443\n\n$ kubectl get svc \nNAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\nkubernetes   ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP          29h\nkubia        ClusterIP   10.111.88.195   &lt;none&gt;        80/TCP,443/TCP   3h46m</code></pre><p>查看pod所在的service对应的IP和端口</p>\n<pre><code>$ kubectl exec kubia-5rvfq env\n......\nKUBERNETES_SERVICE_PORT=443\nKUBIA_SERVICE_PORT=80                // 服务的集群IP\n......\nKUBERNETES_SERVICE_HOST=10.96.0.1\nKUBIA_SERVICE_HOST=10.111.88.195    // 服务所在的端口\n......</code></pre><p>pod 是否使用 内 部的 DNS 服务器是根据 pod 中 spec 的 dnsPolicy 属性来决定的</p>\n<p>进入容器后执行如下命令</p>\n<pre><code>$ kubectl exec kubia-5rvfq -it -- bash        // -- 表示kubectl 命令执行完了，开始执行pod容器里要运行的命令\n$ curl http://kubia.default.svc.cluster.local\n$ curl http://kubia.default\n$ curl http://kubia\nYou&apos;ve hit kubia-5rvfq\n\n$ cat /etc/resolv.conf\nnameserver 10.96.0.10        // 对应kube-system 里的服务kube-dns服务IP\nsearch default.svc.cluster.local svc.cluster.local cluster.local sh.intel.com\noptions ndots:5\nroot@kubia-5rvfq:/# curl http://svc.cluster.local\ncurl: (6) Could not resolve host: svc.cluster.local\n\n$ ping kubia\nPING kubia.default.svc.cluster.local (10.111.88.195): 56 data bytes\n^C--- kubia.default.svc.cluster.local ping statistics ---\n4 packets transmitted, 0 packets received, 100% packet loss</code></pre><p>上面的 curl 这个服务是工作的，但是却 ping 不通。这是 因为服务的集群 IP 是一个虚拟 IP，并且只有在与服务端口结合时才有意义。 </p>\n<p>查看kube-system下面kube-dns信息</p>\n<pre><code>$ kubectl get svc -n kube-system\nNAME       TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE\nkube-dns   ClusterIP   10.96.0.10   &lt;none&gt;        53/UDP,53/TCP,9153/TCP   2d3h</code></pre><h3 id=\"删除service\"><a href=\"#删除service\" class=\"headerlink\" title=\"删除service\"></a>删除service</h3><pre><code>$ kubectl delete svc kubia</code></pre><h2 id=\"Service-samples\"><a href=\"#Service-samples\" class=\"headerlink\" title=\"Service samples\"></a>Service samples</h2><h3 id=\"查看service\"><a href=\"#查看service\" class=\"headerlink\" title=\"查看service\"></a>查看service</h3><pre><code>$ kubectl get svc -n kube-system\n$ kubectl get svc -n istio-system\nNAME                        TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                                                                                                      AGE\ngrafana                     ClusterIP      10.104.1.236     &lt;none&gt;        3000/TCP                                                                                                                                     3d5h\nistio-egressgateway         ClusterIP      10.107.177.52    &lt;none&gt;        80/TCP,443/TCP,15443/TCP                                                                                                                     3d5h\nistio-ingressgateway        LoadBalancer   10.97.82.221     &lt;pending&gt;     15020:31237/TCP,80:31556/TCP,443:30614/TCP,15029:32511/TCP,15030:32423/TCP,15031:30670/TCP,15032:30961/TCP,31400:30196/TCP,15443:31028/TCP   3d5h\nistio-pilot                 ClusterIP      10.97.192.70     &lt;none&gt;        15010/TCP,15011/TCP,15012/TCP,8080/TCP,15014/TCP,443/TCP                                                                                     3d5h\nistiod                      ClusterIP      10.107.202.199   &lt;none&gt;        15012/TCP,443/TCP\n......\n\n$ kubectl get services\nNAME                        TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE\nkubernetes                  ClusterIP      10.3.240.l       &lt;none&gt;        443/TCP          34m\nkubia-http                  LoadBalancer   10.3.246.185     &lt;pending&gt;     8080:31348/TCP   4s\n暂时忽略 kubernetes 服务，仔细查看创建的kubian-http 服务 。 它还没有外部 IP 地址 ，因为 Kubernetes 运行的云基础设施创建负载均衡需要一段时间\n$ kubectl get services\nNAME                        TYPE           CLUSTER-IP       EXTERNAL-IP       PORT(S)          AGE\nkubernetes                  ClusterIP      10.3.240.l       &lt;none&gt;            443/TCP          34m\nkubia-http                  LoadBalancer   103.246.185      104 155.74.57     8080:31348/TCP   4s\n现在有外部 IP 了，应用就可以从任何地方通过 http://104.155.74.57:8080 访问\n$ curl 104.155.74.57:8080\nYou’ve hit kubia-4jfyf</code></pre><h3 id=\"查看service的CRD信息\"><a href=\"#查看service的CRD信息\" class=\"headerlink\" title=\"查看service的CRD信息\"></a>查看service的CRD信息</h3><pre><code>$ kubectl get svc istio-ingressgateway -n istio-system -oyaml</code></pre><h2 id=\"endpoint-服务\"><a href=\"#endpoint-服务\" class=\"headerlink\" title=\"endpoint 服务\"></a>endpoint 服务</h2><pre><code>$ kubectl describe svc kubia\nName:              kubia\nNamespace:         default\nLabels:            &lt;none&gt;\nAnnotations:       &lt;none&gt;\nSelector:          app=kubia        // 用于创建endpoint列表的服务pod选择器\nType:              ClusterIP\nIP:                10.111.88.195\nPort:              http  80/TCP\nTargetPort:        8080/TCP\nEndpoints:         10.44.0.1:8080,10.44.0.2:8080,10.44.0.3:8080        // 服务endpoint的pod的IP和端口列表\nPort:              https  443/TCP\nTargetPort:        8443/TCP\nEndpoints:         10.44.0.1:8443,10.44.0.2:8443,10.44.0.3:8443\nSession Affinity:  ClientIP\nEvents:            &lt;none&gt;\n\n$ kubectl get po -o wide\nNAME          READY   STATUS    RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES\nkubia         1/1     Running   0          15h   10.44.0.4   server02   &lt;none&gt;           &lt;none&gt;\nkubia-5rvfq   1/1     Running   0          15h   10.44.0.2   server02   &lt;none&gt;           &lt;none&gt;\nkubia-8cgnm   1/1     Running   0          15h   10.44.0.1   server02   &lt;none&gt;           &lt;none&gt;\nkubia-8kv8d   1/1     Running   0          15h   10.44.0.3   server02   &lt;none&gt;           &lt;none&gt;</code></pre><p>Endpoint 资源和其他Kubernetes 资源一样，所以可以使用 kubectl info 来获取它的基本信息</p>\n<pre><code>$ kubectl get endpoints kubia\nNAME    ENDPOINTS                                                  AGE\nkubia   10.44.0.1:8443,10.44.0.2:8443,10.44.0.3:8443 + 3 more...   16h</code></pre><p>Endpoint是一个单独的资源并不 是服务的一个属性, 必须手动创建<br>external-service.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: external-service\nspec:\n  ports:\n  - port: 80</code></pre><p>external-service-endpoints.yaml</p>\n<pre><code>apiVersion: v1\nkind: Endpoints\nmetadata:\n  name: external-service\nsubsets:\n  - addresses:\n    - ip: 11.11.11.11\n    - ip: 22.22.22.22\n    ports:\n    - port: 80</code></pre><p>部署service和endpoint</p>\n<pre><code>$ kubectl create -f external-service.yaml\n$ kubectl create -f external-service-endpoints.yaml\n$ kubectl describe svc/external-service\nName:              external-service\nNamespace:         default\nLabels:            &lt;none&gt;\nAnnotations:       &lt;none&gt;\nSelector:          &lt;none&gt;\nType:              ClusterIP\nIP:                10.97.153.150\nPort:              &lt;unset&gt;  80/TCP\nTargetPort:        80/TCP\nEndpoints:         11.11.11.11:80,22.22.22.22:80\nSession Affinity:  None\nEvents:            &lt;none&gt;</code></pre><h2 id=\"暴露service\"><a href=\"#暴露service\" class=\"headerlink\" title=\"暴露service\"></a>暴露service</h2><p> • 将服务的类型设置成NodePort – 每个集群节点都会在节点上打开一个端口， 对于NodePort服务， 每个集群节点在节点本身（因此得名叫NodePort)上打开一个端口，并将在该端口上接收到的流量重定向到基础服务。<br>   该服务仅在内部集群 IP 和端口上才可访间， 但也可通过所有节点上的专用端口访问.<br> • 将服务的类型设置成LoadBalance, NodePort类型的一种扩展 – 这使得服务可以通过一个专用的负载均衡器来访问， 这是由Kubernetes中正在运行的云基础设施提供的。 负载均衡器将流量重定向到跨所有节点的节点端口。<br>   客户端通过负载均衡器的 IP 连接到服务<br> • 创建一 个Ingress资源， 这是一 个完全不同的机制， 通过一 个IP地址公开多个服务——它运行在 HTTP 层（网络协议第 7 层）上， 因此可以提供比工作在第4层的服务更多的功能</p>\n<h3 id=\"NodePort-类型-service\"><a href=\"#NodePort-类型-service\" class=\"headerlink\" title=\"NodePort 类型 service\"></a>NodePort 类型 service</h3><p>指定端口不是强制性的。 如果忽略它，Kubemetes将选择一个随机端口.<br>客户端发送请求的节点并不重要, 整个互联网可以通过任何节点上的30123(用户自己定义的)端口访问到pod,如下所示<br>如在个人机器上生成如下service和pod，可以在以前做的项目的任何机器上通过如下访问</p>\n<pre><code>curl -s http://10.239.140.186:30123 (master节点的NodeIP:port)访问服务\ncurl -s http://10.239.140.200:30123 (worker02节点的NodeIP:port)访问服务</code></pre><p>kubia-svc-nodeport.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: kubia-nodeport\nspec:\n  type: NodePort            // 设置服务类型\n  ports:\n  - port: 80                // 服务集群IP端口号\n    targetPort: 8080\n    nodePort: 30123            // 通过集群节点(master或worker)的NodeIP，加上30123端口可以访问服务\n  selector:\n    app: kubia\n\n$ kubectl create -f kubia-svc-nodeport.yaml\n\n$ kubectl get svc\nNAME                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\nkubernetes           ClusterIP      10.96.0.1       &lt;none&gt;        443/TCP          43h\nkubia-nodeport       NodePort       10.103.7.50     &lt;none&gt;        80:30123/TCP     99m\n\n$ kubectl describe svc kubia-nodeport\nName:                     kubia-nodeport\nNamespace:                default\nLabels:                   &lt;none&gt;\nAnnotations:              &lt;none&gt;\nSelector:                 app=kubia\nType:                     NodePort\nIP:                       10.103.7.50\nPort:                     &lt;unset&gt;  80/TCP\nTargetPort:               8080/TCP\nNodePort:                 &lt;unset&gt;  30123/TCP\nEndpoints:                10.44.0.1:8080,10.44.0.2:8080,10.44.0.3:8080\nSession Affinity:         None\nExternal Traffic Policy:  Cluster\nEvents:                   &lt;none&gt;\n\n$ kubectl get po -o wide\nNAME          READY   STATUS    RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES\nkubia         1/1     Running   0          17h   10.44.0.4   server02   &lt;none&gt;           &lt;none&gt;\nkubia-5rvfq   1/1     Running   0          17h   10.44.0.2   server02   &lt;none&gt;           &lt;none&gt;\nkubia-8cgnm   1/1     Running   0          17h   10.44.0.1   server02   &lt;none&gt;           &lt;none&gt;\nkubia-8kv8d   1/1     Running   0          17h   10.44.0.3   server02   &lt;none&gt;           &lt;none&gt;</code></pre><p>查看server02机器IP</p>\n<pre><code>$kubectl get node -o wide\nNAME       STATUS   ROLES    AGE     VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME\nalpha      Ready    master   2d18h   v1.18.2   10.239.140.186   &lt;none&gt;        Ubuntu 18.04.4 LTS   5.3.0-28-generic    docker://19.3.6\nserver02   Ready    &lt;none&gt;   2d17h   v1.18.2   10.239.140.200   &lt;none&gt;        Ubuntu 18.04.4 LTS   4.15.0-76-generic   docker://19.3.6</code></pre><p>两种访问方式</p>\n<ul>\n<li>第一种: 通过NodeIP:Port 访问:</li>\n</ul>\n<pre><code>$ curl -s http://10.239.140.200:30123\nYou&apos;ve hit kubia-8kv8d\n$ curl -s http://10.239.140.186:30123\nYou&apos;ve hit kubia-5rvfq</code></pre><ul>\n<li>第二种: 通过 service的CLUSTER-IP：port 进入port进行访问</li>\n</ul>\n<pre><code>$ kubectl exec kubia -- curl -s http://10.103.7.50:80\nYou&apos;ve hit kubia-8kv8d</code></pre><h3 id=\"LoadBalancer-方式访问\"><a href=\"#LoadBalancer-方式访问\" class=\"headerlink\" title=\"LoadBalancer 方式访问\"></a>LoadBalancer 方式访问</h3><blockquote>\n<p>如果Kubemetes在不支持Load Badancer服务的环境中运行， 则不会调配负载平衡器， 但该服务仍将表现得像 一 个NodePort服 务。 这是因为LoadBadancer服务是NodePo江服务的扩展<br>如果没有指定特定的节点端口， Kubernetes将会选择一个端口<br>创建服务后， 云基础架构需要一段时间才能创建负载均衡器并将其 IP 地址写入服务对象。 一旦这样做了， IP 地址将被列为服务的外部 IP 地址</p>\n</blockquote>\n<p>kubia-svc-loadbalancer.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: kubia-loadbalancer\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 80\n    targetPort: 8080\n  selector:\n    app: kubia\n\n$ kubectl create -f kubia-svc-loadbalancer.yaml\n\n$ kubectl describe svc/kubia-loadbalancer\nName:                     kubia-loadbalancer\nNamespace:                default\nLabels:                   &lt;none&gt;\nAnnotations:              &lt;none&gt;\nSelector:                 app=kubia\nType:                     LoadBalancer\nIP:                       10.99.184.62\nPort:                     &lt;unset&gt;  80/TCP\nTargetPort:               8080/TCP\nNodePort:                 &lt;unset&gt;  30994/TCP        // yaml资源文件里没有指定, Kubemetes将会选择一个端口\nEndpoints:                10.44.0.1:8080,10.44.0.2:8080,10.44.0.3:8080\nSession Affinity:         None\nExternal Traffic Policy:  Cluster\nEvents:                   &lt;none&gt;\n\n$ kubectl get svc\nNAME                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\nkubernetes           ClusterIP      10.96.0.1       &lt;none&gt;        443/TCP          43h\nkubia-loadbalancer   LoadBalancer   10.99.184.62    &lt;pending&gt;     80:30994/TCP     4m11s</code></pre><p>可以看到Kubemetes在不支持Load Badancer服务的环境中运行 EXTERNAL-IP显示为 <pending>状态，但仍然可以像NodePort方式一样访问服务</p>\n<pre><code>$ kubectl exec kubia -- curl -s http://10.99.184.62:80\nYou&apos;ve hit kubia-8cgnm\n$ curl -s 10.239.140.186:30994        // masterIP：svcPort\nYou&apos;ve hit kubia-5rvfq\n$ curl -s 10.239.140.200:30994        // worker01：svcPort\nYou&apos;ve hit kubia-8kv8d</code></pre><p>如果支持LoadBalancer且获得EXTERNAL-IP为 130.211.53.173<br>可以通过 $ curl <a href=\"http://130.211.53.173\" target=\"_blank\" rel=\"noopener\">http://130.211.53.173</a> 进行访问</p>\n<h3 id=\"Ingress-暴露服务\"><a href=\"#Ingress-暴露服务\" class=\"headerlink\" title=\"Ingress 暴露服务\"></a>Ingress 暴露服务</h3><blockquote>\n<p>需要 Ingress一个重要的原因是每个 LoadBalancer 服务都需要自己的负载均衡器， 以及独有的公有 IP 地址， 而 Ingress 只需要一个公网 IP 就能为许多服务提供访问<br>Ingress 在网络栈 (HTTP) 的应用层操作， 并且可以提供一 些服务不能实现的功能， 诸如基于 cookie 的会话亲和性 (session affinity) 等功能<br>Ingress 对象提供的功能之前，必须强调只有 Ingress控制器在集群中运行，Ingress 资源才能正常工作。 不同的 Kubernetes 环境使用不同的控制器实现， 但有些并不提供默认控制器<br>Ingress通常向外暴露 Service.Type=NodePort 或者 Service.Type=LoadBalancer 类型的服务，因此先创建一个NodePort类型svc.</p>\n</blockquote>\n<pre><code>$ kubectl get svc\nNAME                  TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\nkubia-nodeport        NodePort       10.103.7.50     &lt;none&gt;        80:30123/TCP     144m</code></pre><p>创建kubia-ingress.yaml资源文件</p>\n<pre><code>apiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  name: kubia\nspec:\n  rules:\n  - host: kubia.example.com                // Ingress 将域名kubia.example.com映射到您的服务\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: kubia-nodeport    // 将所有请求发送到kubia-nodeport服务的80端口\n          servicePort: 80</code></pre><blockquote>\n<p>kubectl创建ingress.yaml资源文件遇到webhook …错误时修改master节点上/etc/kubernetes/manifests/kube-apiserver.yaml，将K8s默认用系统配置的proxy注释掉，稍后再运行kubectl create …就可以了</p>\n</blockquote>\n<pre><code>$ kubectl create -f kubia-ingress.yaml\n$ kubectl get ingress        // 自己机器上没有获得ADDRESS这列IP\nNAME    CLASS    HOSTS               ADDRESS            PORTS   AGE\nkubia   &lt;none&gt;   kubia.example.com   192.168.99.100     80      92s</code></pre><blockquote>\n<p>一旦知道 IP 地址，通过配置 DNS 服务器将 kubia.example.com 解析为此 IP地址，或者在/ect/hosts(Windows系统为C:\\windows\\system32\\drivers\\etc\\hosts ）文件中添加下面一行内容：</p>\n</blockquote>\n<pre><code>192 168.99.100 kubia.example.com</code></pre><p>通过Ingress访问pod, 环境都己经建立完毕，可以通过 http ：此ubia.example.com 地址访 问服务 （使用浏览器或者 curl 命令）</p>\n<pre><code>$ curl http://kubia.example.com</code></pre><blockquote>\n<p>客户端如何通过 Ingress 控制器连接到 其 中 一个 pod。客户端首先对 kubia.example.com 执行 DNS 查 找， DNS 服务器（或本地操作系统）返回了In gress 控制器的 IP。<br>客户端然后 向 Ingress 控制器发送 HTTP 请求，并在 Host 头中指定 kubia . example.com。<br>控制器从该头部确定客户端尝试访 问哪个服务，通过与该服务关联 的 Endpo int 对象查看 pod IP ， 并将客户端的请求转发给其中一个pod。<br>Ingress 控制器不会将请求转发给该服务，只用它来选择一个pod。大多数（即使不是全部）控制器都是这样工作的.</p>\n</blockquote>\n<p>Ingress规范的 rules 和 paths 都是数组，因此它们可以包含多个条目<br>一个 Ingress 可以将 多个主机和路径映射到多个服务</p>\n<ul>\n<li>客户端可以通过一个 IP 地址（ Ingress 控制器的 IP 地址 〉访问两种不同的服务</li>\n<li>同样，可以使用 Ingress 根据 HTTP 请求中的主机而不是（仅）路径映射到不同的服务<br>kubia-ingress.yaml</li>\n</ul>\n<pre><code>apiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  name: kubia\nspec:\n  rules:\n  - host: kubia.example.com                // 对 kubia.example.com 的请求将会转发至kubia服务\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: kubia-nodeport\n          servicePort: 80\n      - path: /kubia                    // 对 kubia.example.com/kubia 的请求将会转发至kubia服务\n        backend:\n          serviceName: kubia\n          servicePort: 80\n      - path: /foo                        // 对 kubia.example.com/foo 的请求将会转发至bar服务\n        backend:\n          serviceName: bar\n          servicePort: 80\n  - host: bar.example.com                // 对 bar.example.com 的请求将会转发至bar服务\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: bar\n          servicePort: 80\n\n$ kubectl get ingress\nNAME    CLASS    HOSTS                               ADDRESS   PORTS   AGE\nkubia   &lt;none&gt;   kubia.example.com,bar.example.com             80      3s</code></pre><p>DNS 需要将 foo .example.com 和 bar.example.com 域名都指向 Ingress 控制器的 IP 地址.<br>然后像上面一样配置/ect/hosts文件内容,就可以通过域名访问了</p>\n<h3 id=\"Ingress处理TLS传输\"><a href=\"#Ingress处理TLS传输\" class=\"headerlink\" title=\"Ingress处理TLS传输\"></a>Ingress处理TLS传输</h3><p>配置 Ingress 以支持 TLS, Ingress 转发 HTTP 流量.</p>\n<h2 id=\"readiness-Probe-就绪探针\"><a href=\"#readiness-Probe-就绪探针\" class=\"headerlink\" title=\"readiness Probe 就绪探针\"></a>readiness Probe 就绪探针</h2><blockquote>\n<p>了解了存活探针，以及它们如何通过确保异常容器自动重启来保持应用程序的正常运行 。 与存活探针类似， Kubernetes 还允许为容器定义准备就绪探针<br>就绪探测器会定期调用，并确定特定的 pod 是否接收客户端请求 。 当容器的准备就绪探测返回成功时，表示容器己准备好接收请求<br>就绪探针有三种类型:</p>\n</blockquote>\n<ul>\n<li>Exec 探针，执行进程的地方。容器的状态由进程的退出状态代码确定 。</li>\n<li>HTTP GET 探针，向容器发送 HTTP GET 请求，通过响应的 HTTP 状态代码判断容器是否准备好 。</li>\n<li>TCP socket 探针，它打开一个 TCP 连接到容器的指定端口。如果连接己建立，则认为容器己准备就绪 </li>\n</ul>\n<p>启动容器时，可以为 Kubernetes 配置一个等待时间，经过等待时间后才可以执行第一次准备就绪检查。<br>之后，它会周期性地调用探针，并根据就绪探针的结果采取行动。<br>如果某个 pod 报告它尚未准备就绪，则会从该服务中删除该 pod。如果 pod再次准备就绪，则重新添加 pod.<br>存活探针通过杀死异常的容器并用新的正常容器替代它们来保持 pod 正常工作，<br>就绪探针确保只有准备好处理请求的 pod 才可以接收它们（请求）</p>\n<blockquote>\n<p>设想一组pod (例如， 运行应用程序服务器的pod)取决于另 一 个pod (例如，后端数据库）提供的服务。 如果任何一个前端连接点出现连接间题并且无法再访问数据库， 那么就绪探针可能会告知Kubemet es该pod没有准备好处理任何请求。 如果其他pod实例没有遇到类似的连接问题， 则它们可以正常处理请求。 就绪探针确保客户端只与正常的pod交互， 并且永远不会知道系统存在问题.<br>通过kubectl ed江命令来向已存在的ReplicationController中的pod模板添加探针<br>kubia-replicaset-renameport.yaml</p>\n</blockquote>\n<pre><code>apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: kubia\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: kubia\n  template:\n    metadata:\n      labels:\n        app: kubia\n    spec:\n      nodeSelector:\n        gpu: &quot;true&quot;\n      containers:\n      - name: kubia\n        image: luksa/kubia\n        readinessProbe:            // pod中的每个容器都会有一个就绪探针\n          exec:\n            command:\n            - ls\n            - /var/ready\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: https\n          containerPort: 8443</code></pre><p>创建RS资源并查看READY状态</p>\n<pre><code>$ kubectl create -f kubia-replicaset-renameport.yaml\n$ kubectl get po\nNAME          READY   STATUS    RESTARTS   AGE\nkubia-2xk54   0/1     Running   0          6m20s\nkubia-bj4tz   0/1     Running   0          6m20s\nkubia-hr9bx   0/1     Running   0          6m21s</code></pre><p>通过创建/var/ready文件使其中一个文件的就绪探针返回成功，该文件的存在可以模拟就绪探针成功<br>准备就绪探针会定期检查 默认情况下每 10 秒检查一次, 最晚 10 秒钟内， 该 pod 应该已经准备就绪.</p>\n<pre><code>$ kubectl exec po/kubia-2xk54 -- touch /var/ready\n$ kubectl get po\nNAME          READY   STATUS    RESTARTS   AGE\nkubia-2xk54   1/1     Running   0          6m26s\nkubia-bj4tz   0/1     Running   0          6m26s\nkubia-hr9bx   0/1     Running   0          6m27s\n\n$ kubectl describe po/kubia-2xk54\n......\nReadiness:      exec [ls /var/ready] delay=0s timeout=1s period=10s #success=1 #failure=3\n......</code></pre><p>修改创建过的RS的资源文件里的readiness命令是不生效的, 除非删了重建, 查看readiness Probe如下</p>\n<pre><code>$ kubectl edit rc kubia</code></pre><h3 id=\"再次测试-readiness\"><a href=\"#再次测试-readiness\" class=\"headerlink\" title=\"再次测试 readiness\"></a>再次测试 readiness</h3><pre><code>$ kubectl get po\nNAME          READY   STATUS    RESTARTS   AGE\nkubia-2xk54   1/1     Running   0          6m20s\nkubia-bj4tz   0/1     Running   0          6m20s\nkubia-hr9bx   0/1     Running   0          6m21s\n\n$ exec kubia-2xk54 -- rm -rf /var/ready        // 过大概10s后\n\n$ kubectl get po\nNAME          READY   STATUS    RESTARTS   AGE\nkubia-2xk54   0/1     Running   0          6m30s\nkubia-bj4tz   0/1     Running   0          6m30s\nkubia-hr9bx   0/1     Running   0          6m31s\n\n$ kubectl exec kubia-bj4tz -- touch /var/ready    // 过大概10s后\n$ kubectl get svc\nNAME          READY   STATUS    RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES\nkubia-2xk54   0/1     Running   0          6m40s   10.44.0.2   server02   &lt;none&gt;           &lt;none&gt;\nkubia-bj4tz   1/1     Running   0          6m40s   10.44.0.3   server02   &lt;none&gt;           &lt;none&gt;\nkubia-hr9bx   0/1     Running   0          6m40s   10.44.0.1   server02   &lt;none&gt;           &lt;none&gt;</code></pre><p>查看SVC</p>\n<pre><code>$ kubectl get svc    // 也可以通过kubectl exec kubia-bj4tz env 来查看POD所支持的所有SVC的IP等信息\nNAME                  TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\nkubia                 ClusterIP      10.111.88.195   &lt;none&gt;        80/TCP,443/TCP   22h\nkubia-loadbalancer    LoadBalancer   10.102.224.77   &lt;pending&gt;     80:32671/TCP     3h8m</code></pre><p>两种访问方式，POD和Node<br>第一种POD访问SvcIP:SvcPort方式</p>\n<pre><code>$kubectl exec kubia -- curl -s  http://10.111.88.195:80        // SvcIP:SvcPort, SvcPort映射到PodIP, 可以通过describe svc查看\nYou&apos;ve hit kubia-bj4tz</code></pre><p>第二种NodeIP:NodePOrt方式</p>\n<pre><code>$ curl -s 10.239.140.186:32671        // NodeIP:NodePort\nYou&apos;ve hit kubia-bj4tz</code></pre><p>应该通过删除 pod 或更改 pod 标签而不是手动更改探针来从服务中手动移除pod.<br>如果想要从某个服务中手动添加或删除 pod, 请将 enabled=true 作为标签添加到 pod, 以及服务的标签选择器中。 当想要从服务中移除 pod 时，删除标签<br>应该始终定义一 个就绪探针， 即使它只是向基准 URL 发送 HTTP 请求一样简单。</p>\n<h2 id=\"headless-服务\"><a href=\"#headless-服务\" class=\"headerlink\" title=\"headless 服务\"></a>headless 服务</h2><p>让客户端连接到所有 pod, 需要找出每个 pod 的 IP.Kubemetes 允许客户通过 DNS 查找发现 pod IP.<br>但是对千 headless 服务， 由于 DNS 返回了 pod 的 IP,客户端直接连接到该 pod, 而不是通过服务代理.<br>headless 服务仍然提供跨 pod 的负载平衡， 但是通过 DNS 轮询机制不是通过服务代理.</p>\n<blockquote>\n<p>如果告诉Kubemetes, 不需要为服务提供集群 IP (通过在服务 spec 中将 clusterIP 字段设置为 None 来完成此操作）， 则 DNS 服务器将返回 pod IP 而不是单个服务 IP<br>将服务 spec中的clusterIP字段设置为None 会使服务成 为headless 服务，因为Kubemetes 不会 为其分配集群IP, 客户端可通过该IP将其连接到支持它的pod<br>kubia-svc-headless.yaml</p>\n</blockquote>\n<pre><code>apiersion: v1\nkin: Service\nmetdata:\n  nme: kubia-headless\nspe:\n  custerIP: None        // clusterIP字段设置为None 会使服务成 为headless服务\n  prts:\n  -port: 80\n   targetPort: 8080\n  slector:\n    app: kubia\n\n$ kubectl create -f kubia-svc-headless.yaml\n$ kubectl get svc\nNAME                  TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\nkubia-headless        ClusterIP      None            &lt;none&gt;        80/TCP           103s</code></pre>"},{"title":"03 Kubernetes nodes, namespace, pod","top":3,"_content":"\n## nodes\n\n\t$ kubectl get nodes -o wide\n\tNAME         STATUS   ROLES    AGE   VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION           CONTAINER-RUNTIME\n\thci-node01   Ready    master   5d    v1.18.1   10.67.108.211   <none>        CentOS Linux 7 (Core)   3.10.0-1062.el7.x86_64   docker://19.3.8\n\thci-node02   Ready    <none>   5d    v1.18.1   10.67.109.142   <none>        CentOS Linux 7 (Core)   3.10.0-1062.el7.x86_64   docker://19.3.8\n\thci-node03   Ready    <none>   5d    v1.18.1   10.67.109.147   <none>        CentOS Linux 7 (Core)   3.10.0-1062.el7.x86_64   docker://19.3.8\n\thci-node04   Ready    <none>   5d    v1.18.1   10.67.109.144   <none>        CentOS Linux 7 (Core)   3.10.0-1062.el7.x86_64   docker://19.3.8\n\t$ kubectl describe node hci-node02\n\t输出显示了节点的状态、 CPU 和内存数据、系统信息、运行容器的节点等\n\n\t查看某台机器的资源\n\t$ kubectl describe node hci-node01\n\n### 创建别名和补全\nkubectl 会被经常使用。很快你就会发现每次不得不打全命令是非常痛苦的。\n将下面的代码添加到 ~/.bashrc 或类似的文件中 ：\n\n\talias k=kubectl\n为kuebctl配置 tab 补全\n需要先安装一个叫作 bashcompletio口的包来启用 bash 中的 tab 命令补全， 然后可以运行接下来的命令（也需要加到 ~/.bashrc 或类似的文件中）\n\n\t$ source <{kubectl completion bash)\n\t$ kubectl desc<TAB> nod<TAB> hci<TAB>\n但是需要注意的是， tab 命令行补全只在使用完整的 kubectl 命令时会起作用,(当使用别名 k 时不会起作用). 需要改变 kubectl completion 的输出来修复：\n\n\t$ source <(kubectl completion bash | sed s/kubectl/k/g)\n\n### node 标签\n\n\t$ kubectl get nodes\n\t$ kubectl label node server02 gpu=false\n\t$ kubectl label node server02 gpu=true --overwrite\t//修改node标签\n\t$ kubectl get node -L gpu\t\t// 列出所有node，并添加GPU一列进行展示\n\t$ kubectl get node -l gpu\t\t// 只列出含标签的key为gpu的node\n\t$ kubectl get node -l gpu=false\t// 只列出含gpu=false的node\n\n将POD调度到指定的node上: kubia-gpu.yaml\n\n\tapiVersion: v1\n\tkind: Pod\n\tmetadata:\n\tname: kubia-gpu\t\t// 指定生成的POD名字\n\tspec:\n\tnodeSelector:\t\t// node选择器,选择含标签gpu=true的node机器\n\t\tgpu: \"true\"\t\t\n\tcontainers:\n\t- image: luksa/kubia\t// 要拉取的 image 名字\n\t\tname: kubia\t\t\t// 生成的 container 名字\n\n\t$ kubectl create -f kubia-gpu.yaml\n如果没有标签为gpu=true的合适node， 通过 $ kubectl describe pod/kubia-nogpu 查看Message， 会报 0/2 nodes are available: 2 node(s) didn't match node selector.信息\n\n\t$ kubectl describe pod/kubia-gpu\n\t......\n\tNode-Selectors:  gpu=true\n\t......\n\n### taint污点\n给Node添加污点可以让配置tolerations的Pod部署上来，而不让平常的Pod部署.\n配置tolerations的Pod可以部署到添加污点的机器也可以部署到其它平常机器\n\n\t$ kubectl taint nodes NodeName gpu=true:NoSchedule\n\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\t  name: web-demo\n\t  namespace: dev\n\tspec:\n\t  selector:\n\t    matchLabels:\n\t      app: web-demo\n\t  replicas: 3\t\t\t// 副本数3来测试能部署到哪些机器\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: web-demo\n\t    spec:\n\t      selector:\n\t        matchLabels:\n\t          app: web-demo\n\t      replicas: 1\n\t      template:\n\t        metadata:\n\t          labels:\n\t            app: web-demo\n\t        spec:\n\t          containers:\n\t          - name: web-demo\n\t            image: hub.mooc.com/kubernetes/web:v1\n\t            ports:\n\t            - containerPort: 8080\n\t          tolerations:\t\t// 可以部署到有设置taint的机器，也可以部署到其它机器\n\t          - key: \"gpu\"\n\t            operator: \"Equal\"\n\t            value: \"true\"\n\t            effect: \"NoSchedule\"\n> 典型的使用kubeadm部署和初始化的Kubernetes集群，master节点被设置了一个node-role.kubernetes.io/master:NoSchedule的污点，可以使用kubectl describe node <node-name>命令查看\n> 这个污点表示默认情况下master节点将不会调度运行Pod，即不运行工作负载, 对于使用二进制手动部署的集群设置和移除这个污点的命令如下:\n\n\t$ kubectl taint nodes <node-name> node-role.kubernetes.io/master=:NoSchedule\n\t$ kubectl taint nodes <node-name> node-role.kubernetes.io/master:NoSchedule-\n> kubeadm初始化的Kubernetes集群，master节点也被打上了一个node-role.kubernetes.io/master=的label，标识这个节点的角色为master。给Node设置Label和设置污点是两个不同的操作。设置Label和移除Label的操作命令如下\n\n设置Label\n\n\t$ kubectl label node node1 node-role.kubernetes.io/master=\n移除Label\n\n\t$ kubectl label node node1 node-role.kubernetes.io/master-\n\n\n## Namespace\n> 大多数对象的名称必须符合 RFC 1035 （域名）中规定的命名规范 ，这意味着它们可能只包含字母、数字、横杠（－）和点号，但命名空间（和另外几个）不允许包含点号\n\n### 隔离性\n> 名字的隔离只是 通过svc名称(DNS) 访问的隔离，通过svc的IP和Pod的IP再加上端口号(Port) 照样可以访问不同命名空间下的服务.\n\n### 设置默认命名空间\n> 默认Kubeclt获取default命名空间下的资源，可以通过设置K8s上下文配置文件如kube.config 使得某个命名空间变为默认namespace，获取pod时候不需要在加上 -n 参数\n\n### 创建命名空间\n> namespace不提供网络隔离, 如果命名空间 foo 中的某个 pod 知道命名空间 bar 中 pod 的 IP 地址，那它就可以将流量（例如 HTTP 请求）发送到另一个 pod\n第一种： commands方式\n\n\t$ kubectl create namespace custom-namespace\n\t$ kubectl create ns custom-namespace\n\n第二种： Yaml方式， 之所以选择使用 YAML 文件，只是为了强化Kubemetes中的所有内容都是一 个 API 对象这一概念\n\n\t$ touch custom-namespace.yaml\n\tapiVersion: v1\n\tkind: Namespace\n\tmetadata:\n\t  name: custom-namespace\n\t$ kubectl create -f custom-namespace.yaml\n\n### 划分方式\n\n\t* 按环境划分: dev(开发), test(测试)\n\t* 按团队划分\n\t* 自定义多级划分\n\n### 标记命名空间\n\n\t$ kubectl label namespace default istio-injection=enabled --overwrite         // enabled\n\t$ kubectl label namespace default istio-injection=disabled --overwrite        // disabled\n\t$ kubectl label namespace default istio-injection= --overwrite                // cancel set\n\tnamespace/default labeled\n\n### 查看标记 istio-injection=enabled 标签的命名空间\n\n\t$ kubectl get namespace -L istio-injection\n\tNAME              STATUS   AGE   ISTIO-INJECTION\n\tdefault           Active   85m   enabled\n\tistio-system      Active   25m   disabled\n\tkube-node-lease   Active   85m\n\tkube-public       Active   85m\n\tkube-system       Active   85m\n\t[root@hci-node01 istio-1.5.2]#\n\n### 删除namespace\n删除当前命名空间中的所有资源，可以删除ReplicationCcontroller和pod,以及我们创建的所有service\n第一个 all 指定正在删除所有资源类型, --all 选项指定将删除所有资源实例, 而不是按名称指定它们\n使用 all 关键字删除所有内容并不是真的完全删除所有内容。 一些资源比如Secret会被保留下来， 并且需要被明确指定删除\n\n\t$ kubectl delete all --all\t\t// 命令也会删除名为 kubernetes 的Service, 但它应该会在几分钟后自动重新创建\n可以简单地删除整个命名空间（ pod 将会伴随命名空间 自动删除〉\n\n\t$ kubectl delete ns custom-namespace\n强制删除NAMESPACE\n\n\t$ kubectl delete namespace NAMESPACENAME --force --grace-period=0\n进入kube-system下得etcd pod 删除需要删除的NAMESPACE\n\n\t$ kubectl get po -n kube-system\n\tNAME                                 READY   STATUS    RESTARTS   AGE\n\tetcd-hci-node01                      1/1     Running   5          16d\n\t......\n\t\n\t$ kubectl exec -it etcd-hci-node01 sh -n kube-system\n\t$ etcdctl del /registry/namespaces/NAMESPACENAME\n\n## POD\n\n### 查看pod解释\n\n\t$ kubectl explain pod\n\tKIND:     Pod\n\tVERSION:  v1\n\t\n\tDESCRIPTION:\n\t\tPod is a collection of containers that can run on a host. This resource is\n\t\tcreated by clients and scheduled onto hosts.\n\t\n\tFIELDS:\n\tapiVersion   <string>\n\t\tAPIVersion defines the versioned schema of this representation of an\n\t\tobject. Servers should convert recognized schemas to the latest internal\n\t\tvalue, and may reject unrecognized values. More info:\n\t\thttps://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\t\n\tkind <string>\n\t\tKind is a string value representing the REST resource this object\n\t\trepresents. Servers may infer this from the endpoint the client submits\n\t\trequests to. Cannot be updated. In CamelCase. More info:\n\t\thttps://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\t\n\tmetadata     <Object>\n\t\tStandard object's metadata. More info:\n\t\thttps://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\t\n\tspec <Object>\n\t\tSpecification of the desired behavior of the pod. More info:\n\t\thttps://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status\n\t\n\tstatus       <Object>\n\t\tMost recently observed status of the pod. This data may not be up to date.\n\t\tPopulated by the system. Read-only. More info:\n\t\thttps://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status\n\n深入理解POD属性\n\n\t$ kubectl explain pod.apiVersion\n\t$ kubectl explain pod.kind\n\t$ kubectl explain pod.spec\npods 的缩写是 po, service 的缩写是 SVC, replicationcontroller 的缩写 rc\n\n\t$ kubectl get pods -n kube-system\n> 我们提到过每个 pod 都有自己的 IP 地址，但是这个地址是集群 内部的，不能从集群外部访问。\n> 要让 pod 能够从外部访问 ， 需要通过服务对象公开它， 要创建一个特殊的 LoadBalancer 类型的服务。\n> 因为如果你创建一个常规服务（ 一个 Cluster IP 服务）， 比如 pod ，它也 只能从集群内部访问。\n> 通过创建 LoadBalanc er 类型 的服务，将创建一个外部的负载均衡 ，可以通过 负载均衡的公共 IP 访问 pod \n\n### 创建POD\n通过上传 JSON 或 YAML 描述文件到 Kubemetes API 服务器来创建 pod.\nkubectl create -f 命令用于从YAML或JSON文件创建任何资源（不只是 pod).\n\t$ kubectl create -f kubia-manual.yaml\n\t$ kubectl create -f kubia-gpu.yaml -n custom-namespace\t//船舰pod到custom-namespace命名空间下\n\n\t$ kubectl describe pod/kubia\n\t......\n\tEvents:\n\tType    Reason     Age    From               Message\n\t----    ------     ----   ----               -------\n\tNormal  Scheduled  5m12s  default-scheduler  Successfully assigned default/kubia-liveness to server02\n\tNormal  Pulling    5m8s   kubelet, server02  Pulling image \"luksa/kubia-unhealthy\"\n\n### pod标签labels\n\n\t$ kubectl get po --show-labels\n查看pod标签的key值为creation_method 和 env 的信息\n\n\t$ kubectl get po -L creation_method,env\n\tNAME                           READY   STATUS    RESTARTS   AGE   CREATION_METHOD   ENV\n\tkubia                          1/1     Running   0          16h\n\tkubia-manual-v2                1/1     Running   0          34m   manual            pod\nPOD添加标签\n\n\t$ kubectl label po kubia  creation_method=manual\n\tNAME                           READY   STATUS    RESTARTS   AGE   CREATION_METHOD   ENV\n\tkubia                          1/1     Running   0          16h   manual\n\tkubia-manual-v2                1/1     Running   0          43m   manual            pod\n更改现有标签, 在更改现有标签时， 需要使用--overwrite选项\n\n\t$ kubectl label po kubia-manual-v2 env=debug --overwrite\n使用标签列出POD\n\n\t$ kubectl get po -1 creation_method=manual\n\t$ kubectl get po -l env\n同样列出没有env标签的pod\n确保使用单引号来圈引 !env, 这样bash shell才不会解释感叹号（译者注：感叹号在bash中有特殊含义， 表示事件指示器)\n\n\t$ kubectl get po -l '!env'\n\tcreation_method!=manual 选择带有creation_method标签， 并且值不等于manual的pod\n\tenv in (prod, devel)选择带有env标签且值为prod或devel的pod\n\tenv notin (prod, devel)选择带有env标签， 但其 值不是prod或devel的pod\n\tapp=pc,rel=beta 选择pc微服务的beta版本pod\n\n\n## pod 注解\n\n\t$ kubectl annotate pod kubia-gpu mycompany.com/someannotion=\"foo bar\"\n\t$ kubectl describe pod/kubia-gpu\n\t......\n\tAnnotations:  mycompany.com/someannotion: foo bar\n\t......\n\n### 查看该 pod 的完整描述文件：\n\t$ kubectl get po kubia-manual -o yaml\t// 获取yaml格式信息\n\t$ kubect1 get po kubia-manual -o json\t// 获取json格式信息\n\n\n### 执行pod容器\n直接执行:\n\n\t$ kubectl exec fortioclient-f8d65c6bb-5k4td -c captured date -n twopods\n进入容器执行, 当pod中只有一个容器时可以不加-c参数指定某个容器\n\n\t$ kubectl exec fortioclient-f8d65c6bb-5k4td -c captured -i -t /bin/sh -n twopods\n\n### 容器进程, 网络等\n查看进程command完整信息\n\n\t$ ps auxwww\n\t$ pa -ef\n查看网络\n\n\t$ netstat -ntlp\n\n### 查看Pod, svc日志\n\n\t$ kubectl logs pod/istiod-774777b79-ddfk4 -n istio-system\n\t$ kubectl logs -f pod/<pod_name> #类似tail -f的方式查看(tail -f 实时查看日志文件 tail -f 日志文件log)\n\t$ kubectl logs svc/istiod -n istio-system\n\t如果该pod中有其他容器， 可以通过如下命令获取其日志：\n\t$ kubectl logs kubia-manual -c kubia\n\n查看容器重启后前一个容器为什么重启的日志信息\n\t$ kubectl logs mypod --previous\n\n### 部署应用程序\n\n\t$ kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml\n\n### 重启Pod\n\n\t$ kubectl get pod {podname} -n {namespace} -o yaml | kubectl replace --force -f -\n\n### 删除Pod\n\n\t$ kubectl delete pod PODNAME -n custom-namespace\t\t// 删除指定命名空间下的POD\n\t$ kubectl delete po -l creation_method=manual\t\t\t// 通过标签选择器来删除\n\t$ kubectl delete po --all -n custom-namespace\t\t\t// 删除当前命名空间中的所有 pod\n\t$ kubectl delete all --all -n custom-namespace\t\t\t// 删除所有pod和svc，系统带的kubernetes服务会过一会重启\n可使用kubectl中的强制删除命令删除POD\n\n\t$ kubectl delete pod PODNAME --force --grace-period=0\n直接从ETCD中删除源数据\n删除default namespace下的pod名为pod-to-be-deleted-0\n\n\t$ ETCDCTL_API=3 etcdctl del /registry/pods/default/pod-to-be-deleted-0\n\n## livenessProbe 存活探针, readinessProbe\nKubemetes 可以通过存活探针 (liveness probe) 检查容器是否还在运行.\nKubemetes 可以通过readinessProbe探针 检查容器是否准备完毕可以挂到负载均衡上供外部访问.\nlivenessProbe与readinessProbe探针用法完全一样, 都有三种，下面介绍这三种健康检查方式.\n\n可以为 pod 中的每个容器单独指定存活探针。 如果探测失败， Kubemetes 将定期执行探针并重新启动容器\n\n * 第一种健康检查方式: 执行命令检查存活探针是否存活\n\n\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\t  name: web-demo\n\t  namespace: dev\n\tspec:\n\t  selector:\n\t    matchLabels:\n\t      app: web-demo\n\t  replicas: 1\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: web-demo\n\t    spec:\n\t      selector:\n\t        matchLabels:\n\t          app: web-demo\n\t      replicas: 1\n\t      template:\n\t        metadata:\n\t          labels:\n\t            app: web-demo\n\t        spec:\n\t          containers:\n\t          - name: web-demo\n\t            image: hub.mooc.com/kubernetes/web:v1\n\t            ports:\n\t            - containerPort: 8080\n\t            livenessProbe:\t\t\t\t// 检查应用是否存活的探针, 和容器一个级别\n\t              exec:\t\t\t\t\t\t// 第一种健康检查方式, 通过执行命令\n\t                command:\n\t                - /bin/sh\n\t                - -c\n\t                - ps -ef|grep java|grep -v grep\n\t              initialDelaySeconds: 10\t\t// 容器起来后过10s开始检查\n\t              periodSeconds: 10\t\t\t\t// 每隔10s检查一次\n\t              failureThreshold: 2\t\t\t// 连续健康检查失败2次放弃检查, 重启容器\n\t              successThreshold: 1\t\t\t// 检查一次满足条件就认为健康检查通过\n\t              timeoutSeconds: 5\t\t\t\t// 每次健康检查delay时间是5s, 超时也认为健康检查失败, 重启容器\n\t            readinessProbe:\t\t\t\t// readinessProbe与livenessProbe用法完全一样.\n\t              exec:\t\t\t\t\t\t// 第一种检查方式, 通过执行命令\n\t                command:\n\t                - /bin/sh\n\t                - -c\n\t                - ps -ef|grep java|grep -v grep\n\t              initialDelaySeconds: 10\t\t// 容器起来后过10s开始检查\n\t              periodSeconds: 10\t\t\t\t// 每隔10s检查一次\n\t              failureThreshold: 2\t\t\t// 连续健康检查失败2次放弃检查, 重启容器\n\t              successThreshold: 1\t\t\t// 检查一次满足条件就认为健康检查通过\n\t              timeoutSeconds: 5\t\t\t\t// 每次健康检查delay时间是5s, 超时也认为健康检查失败, 重启容器\n\n * 第二种健康检查方式: 执行网络请求检查存活探针是否存活\n\n\n\t$ touch kubia-liveness-probe.yaml\n\tapiVersion: v1\n\tkind: Pod\n\tmetadata:\n\t  name: kubia-liveness\n\tspec:\n\t  containers:\n\t  - image: luksa/kubia-unhealthy\n\t    name: kubia\n\t    livenessProbe:\t\t// 一个 HTTP GET 存活探针\n\t      httpGet:\t\t\t// 第二种健康检查方式, 通过httpGet\n\t        path: /\t\t\t// 应用要访问的路径\n\t        port: 8080\t\t// 容器本身启动的端口\n\t        scheme: HTTP\n\t      initialDelaySeconds: 15\t\t// 容器起来后过10s开始检查\n\t      periodSeconds: 5\n\n\t$ kubectl get pods\n\tNAME                           READY   STATUS    RESTARTS   AGE\n\tkubia-liveness                 1/1     Running   1          13m\n查看该pod描述\n\n\t$ kubectl describe pod/kubia-liveness\n\t......\n\tLast State:     Terminated\n\t  Reason:       Error\n\t  Exit Code:    137\n\t  Started:      Wed, 13 May 2020 15:49:36 +0800\n\t  Finished:     Wed, 13 May 2020 15:51:25 +0800\n\tReady:          True\n\tRestart Count:  1\n\tLiveness:       http-get http://:8080/ delay=0s timeout=1s period=10s #success=1 #failure=3\n\t......\n数字137是两个 数字的总和：128+x, 其中x是终止进程的信号编号.\n在这个例子中，x等于9, 这是SIGKILL的信号编号，意味着这个进程被强行终止.\n当容器被强行终止时，会创建一个全新的容器—-而不是重启原来的容器.\ndelay=Os部分显示在容器启动后立即开始探测.\ntimeout仅设置为1秒，因此容器必须在1秒内进行响应， 不然这次探测记作失败.\n每10秒探测一次容器(period=lOs), 并在探测连续三次失败(#failure=3)后重启容器.\n定义探 针时可以自定义这些附加参数。例如，要设 置初始延迟，请将initialDelaySeconds属性添加到存活探针的配置中.\n\n\t    livenessProbe:\t\t// 一个 HTTP GET 存活探针\n\t      httpGet:\n\t        path: /\n\t        port: 8080\n\t      initialDelaySeconds: 15\t// Kubernetes会在第—次探测前等待15秒 \n\n\t$ kubectl describe pod/kubia-liveness\n\t......\n\tLiveness:       http-get http://:8080/ delay=15s timeout=1s period=10s #success=1 #failure=3\n\n * 第三种健康检查方式: 通过TCP检查端口是否处于监听状态\n\t    livenessProbe:\t\t// 一个 HTTP GET 存活探针\n\t      tcpSocket:\n\t        port: 8080\n\t      initialDelaySeconds: 20\t// Kubernetes会在第—次探测前等待15秒 \n\t      periodSeconds: 5\n\n> 如果没有设置初始延迟，探针将在启动时立即开始探测容器， 这通常会导致探测失败， 因为应用程序还没准备好开始接收请求.\n> 务必记得设置一个初始延迟未说明应用程序的启动时间.\n> 对于在生产中运行的pod, 一定要定义一个存活探针。没有探针的话，Kubemetes无法知道你的应用是否还活着。只要进程还在运行， Kubemetes会认为容器是健康的\n> Kubernetes会在你的容器崩溃或其存活探针失败时， 通过重启容器来保持运行。 这项任务由承载pod的节点上的Kubelet 执行 一— 在主服务器上运行的Kubernetes Control Plane组件不会参与此过程.\n> 但如果节点本身崩溃， 那么Control Plane 必须为所有随节点停止运行的pod创建替代品。 它不 会为你直接创建的pod执行此操作 。 这些pod只被Kubelet 管理.\n\n### 查看 readinessProbe, healthProbe\n\t\n\t$ kubectl edit po -n istio-system istio-ingressgateway-6489d9556d-wjr58\n\t$ kubectl edit deployment -n istio-system istio-ingressgateway\n\t$ kubectl logs po/istio-ingressgateway-6489d9556d-wjr58 -n istio-system\n\t$ kubectl get po -A\n\n### affinity\n匹配Node标签, Pod部署到哪台机器上.\n\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\t  name: web-demo\n\t  namespace: dev\n\tspec:\n\t  selector:\n\t    matchLabels:\n\t      app: web-demo\n\t  replicas: 1\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: web-demo\n\t    spec:\n\t      selector:\n\t        matchLabels:\n\t          app: web-demo\n\t      replicas: 1\n\t      template:\n\t        metadata:\n\t          labels:\n\t            app: web-demo\n\t        spec:\n\t          containers:\n\t          - name: web-demo\n\t            image: hub.mooc.com/kubernetes/web:v1\n\t            ports:\n\t            - containerPort: 8080\n\t          affinity:\n\t            nodeAffinity:\t\t// node亲和性, 要部署到哪台机器，不要部署到哪台机器\n\t              requiredDuringSchedulingIgnoredDuringExecution:\t// 必须满足下面条件才会执行调度\n\t                nodeSelectorTerms:\t\t// 数组形式, 下面可以定义多个Terms, 它们之间是或的关系\n\t                - matchExpressions:\t\t// 数组形式, 如果定义多个matchExpressions它们之间是与的关系\n\t                  - key: beta.kubernetes.io/arch\t// 节点的label含有的key名字, 这里的是由K8s根据机器自动生成的\n\t                    operator: In\n\t                    values:\t\t\t\t// 前提是Node机器有amd64标签K8s才会把容器部署到次Node机器\n\t                    - amd64\t\t\t\t// 通过kubectl get nodes NodeName -o yaml进行查看\n\t              preferredDuringSchedulingIgnoredDuringExecution:\t// 最好是怎样调度\n\t              - weight: 1\t\t\t\t// 权重\n\t                perference:\n\t                  matchExpressions:\n\t                  - key: disktype\t\t// 通过kubectl get nodes --show-labels查看\n\t                    operator: NotIn\n\t                    values:\n\t                    - ssd\n\t            podAffinity:\t\t// Pod亲和性, 想和哪些Pod部署到一台机器, 不想和哪些Pod部署在一台机器\n\t              requiredDuringSchedulingIgnoredDuringExecution:\n\t              - labelSelector:\n\t                  matchExpressions:\n\t                  - key: app\n\t                    operator: In\t\t// 要跟app=web-demo的Pod运行在同一个节点上\n\t                    values:\n\t                    - web-demo-node\n\t                topologyKey: kubernetes.io/hostname\t\t// 节点的label名字\n\t              preferredDuringSchedulingIgnoredDuringExecution:\n\t              - weight: 100\n\t                podAffinityTerm:\n\t                  labelSelector:\n\t                    matchExpressions:\n\t                    - key: app\n\t                      operator: In\n\t                      values:\n\t                      - web-demo-node\n\t                  topologyKey: kubernetes.io/hostname\n\t            podAntiAffinity:\t\t// Pod反亲和性, 不想和哪些Pod部署到一台机器, 用法和podAffinity用法完全一样\n\t            pod反亲和性用的很多的是上面的replicas: 的值 >=2 时候会把容器副本分别部署到不同机器\n\n### Pod启动停止控制\nPod容器启动时候和停止前所做的事\n\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\t  name: web-demo\n\t  namespace: dev\n\tspec:\n\t  selector:\n\t    matchLabels:\n\t      app: web-demo\n\t  replicas: 1\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: web-demo\n\t    spec:\n\t      selector:\n\t        matchLabels:\n\t          app: web-demo\n\t      replicas: 1\n\t      template:\n\t        metadata:\n\t          labels:\n\t            app: web-demo\n\t        spec:\n\t          containers:\n\t          - name: web-demo\n\t            image: hub.mooc.com/kubernetes/web:v1\n\t            ports:\n\t            - containerPort: 8080\n\t            volumeMounts:\n\t            - name: shared-volume\n\t              mounthPath: /shared-web\n\t            lifecycle:\t\t\t\tPod里容器启动前和停止前要做的事\n\t              postStart:\n\t                exec:\n\t                  command: [\"/bin/sh\", \"-c\", \"echo web starting ... >> /var/log/messages\"]\n\t              preStop:\n\t                exec:\n\t                  command: [\"/bin/sh\", \"-c\", \"echo web stopping ... >> /var/log/messages && sleep 3\"]\n\n\n## ReplicationController\n一个ReplicationController有三个主要部分\n • label selector ( 标签选择器）， 用于确定ReplicationController作用域中有哪些pod\n • replica count (副本个数）， 指定应运行的pod 数量\n • pod template (pod模板）， 用于创建新的pod 副本\n使用 ReplicationController 的好处\n •确保一 个 pod (或多个 pod副本）持续运行， 方法是在现有pod 丢失时启动一个新 pod。\n • 集群节点发生故障时， 它将为故障节 点 上运 行的所有 pod (即受ReplicationController 控制的节点上的那些 pod) 创建替代副本。\n • 它能轻松实现 pod的水平伸缩 手动和自动都可以\n\n### 由RC创建POD\nkubia-rc.yaml, 内容如下:\n\n\tapiVersion: v1\n\tkind: ReplicationController\t\t// 这里的配置定义了ReplicationController(RC)\n\tmetadata:\n\t  name: kubia\t\t// ReplicationController 的名字\n\tspec:\n\t  replicas: 3\t\t// pod 实例的目标数目\n\t  selector:\t\t\t// selector也可以不写，replica 直接根据下面的template模板里的lables标签选择创建POD\n\t    app: kubia\t\t// pod 选择器决定了 RC 的操作对象\n\t  template:\t\t\t// 从此以下都是创建新 pod 所用的 pod 模板, 与单独创建的pod定义yaml文件内容几乎相同\n\t    metadata:\n\t      labels:\n\t        app: kubia\n\t    spec:\n\t      containers:\n\t      - name: kubia\n\t        image: luksa/kubia\n\t        ports:\n\t        - containerPort: 8080\n创建ReplicationController并由其创建pod\n\n\t$ kubectl create -f kubia-rc.yaml\n\t$ kubectl get po -o wide\n\tNAME          READY   STATUS    RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES\n\tkubia-6wnj5   1/1     Running   0          56s   10.44.0.3   server02   <none>           <none>\n\tkubia-788p8   1/1     Running   0          56s   10.44.0.2   server02   <none>           <none>\n\tkubia-c9kn6   1/1     Running   0          56s   10.44.0.1   server02   <none>           <none>\n\n\t$ kubectl delete po kubia-6wnj5\n\tNAME          READY   STATUS              RESTARTS   AGE\n\tkubia-6ntgt   0/1     ContainerCreating   0          12s\n\tkubia-6wnj5   1/1     Terminating         0          3m3s\n\tkubia-788p8   1/1     Running             0          3m3s\n\tkubia-c9kn6   1/1     Running             0          3m3s\n上面重新列出pod会显示四个， 因为你删除的pod己终止， 并且己创建一个新的pod\n虽然ReplicationController会立即收到删除pod的通知 (API 服务器允许客户端监听资源和资源列表的更改），但这不是它创建替代pod的原因。\n该通知会触发控制器检查实际的pod数量并采取适当的措施.\n\n\t$ kubectl get po -o wide\n\tNAME          READY   STATUS    RESTARTS   AGE     IP          NODE       NOMINATED NODE   READINESS GATES\n\tkubia-6ntgt   1/1     Running   0          53s     10.44.0.4   server02   <none>           <none>\n\tkubia-788p8   1/1     Running   0          3m44s   10.44.0.2   server02   <none>           <none>\n\tkubia-c9kn6   1/1     Running   0          3m44s   10.44.0.1   server02   <none>           <none>\n\n### 获取有关 ReplicationController 的信息\n\n\t$ kubectl get rc -o wide\n\t$ kubectl get rc -o wide -n default\t\t// RC是针对某个namespace下做的副本pod控制\n\tNAME    DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES        SELECTOR\n\tkubia   3         3         3       17m   kubia        luksa/kubia   app=kubia\n\t获取RC的详细信息\n\t$ kubectl describe rc kubia\n\n如果你更改了 一个 pod 的标签，使它不再 与 ReplicationController 的标签选择器相匹配 ， 那么该 pod 就变得和其他手动创建的 pod 一样了\n更改 pod 的标签时， ReplicationController 发现一个 pod 丢失了 ， 并启动一个新的pod替换它.\n\n给其中一个 pod 添加了 type=special 标签，再次列出所有 pod 会显示和以前一样的三个 pod 。 因为从 ReplicationCon位oiler 角度而言， 没发生任何更改.\n\n\t$ kubectl label pod/kubia-6ntgt type=special\n\t$ kubectl get pod --show-labels\n\tNAME          READY   STATUS    RESTARTS   AGE   LABELS\n\tkubia-6ntgt   1/1     Running   0          27m   app=kubia,type=special\n\tkubia-788p8   1/1     Running   0          30m   app=kubia\n\tkubia-c9kn6   1/1     Running   0          30m   app=kubia\n\n更改app标签该 pod 不再与 RC 的标签选择器相匹配\n\n\t$ kubectl label pod/kubia-6ntgt app=foo --overwrite\n\t$ kubectl get pod --show-labels\n\tNAME          READY   STATUS              RESTARTS   AGE   LABELS\n\tkubia-6ntgt   1/1     Running             0          30m   app=foo,type=special\n\tkubia-788p8   1/1     Running             0          33m   app=kubia\n\tkubia-c9kn6   1/1     Running             0          33m   app=kubia\n\tkubia-dqshz   0/1     ContainerCreating   0          4s    app=kubia\n使用 -L app 选项在列 中显示 app 标签\n\n\t$ kubectl get pod -L app\n\tNAME          READY   STATUS    RESTARTS   AGE     APP\n\tkubia-6ntgt   1/1     Running   0          32m     foo\n\tkubia-788p8   1/1     Running   0          35m     kubia\n\tkubia-c9kn6   1/1     Running   0          35m     kubia\n\tkubia-dqshz   1/1     Running   0          2m17s   kubia\n可能有一个 bug 导致你的 pod 在特定时间或特定事件后开始出问题。\n如果你知道某个 pod 发生了故障， 就可以将它从 Replication-Controller 的管理范围中移除， 让控制器将它替换为新 pod, 接着这个 pod 就任你处置了。 完成后删除该pod 即可。\n\n### 编辑RC的YAML配置\n用默认文本编辑器中打开ReplicationController的YAML配置，会在/tmp目录生成一个临时yaml文件，退出后/tmp目录下的yaml文件也会删掉\n如果你想使用nano编辑Kubernetes资源，请执行以下命令（或将其放入 ~/.bashrc或等效文件中）\nexport KUBE_EDITOR=\"/usr/bin/nano\"\n\n\t$ kubectl edit rc kubia\n\t......\n\t spec:\n\t   replicas: 3\n\t   selector:\n\t     app: kubia1\t\t\t\t RC selector 修改，需要配合下面的label一起修改\n\t   template:\n\t     metadata:\n\t       creationTimestamp: null\n\t       labels:\n\t         app: kubia1\t\t\t Pod label 修改，需要配合上面的 RC selector 一起修改\n\t     spec:\n\t       containers:\n\t       - image: luksa/kubia\n\t         imagePullPolicy: Always\n\t         name: kubia\n\t         ports:\n\t         - containerPort: 8080\n\t           protocol: TCP\n\t......\n\n\t$ kubectl get pod\n\tNAME          READY   STATUS              RESTARTS   AGE   APP\n\tkubia-279wl   0/1     ContainerCreating   0          2s    kubia1\n\tkubia-6ntgt   1/1     Running             0          44m   foo\n\tkubia-788p8   1/1     Running             0          47m   kubia\n\tkubia-c9kn6   1/1     Running             0          47m   kubia\n\tkubia-dqshz   1/1     Running             0          14m   kubia\n\tkubia-m6vml   0/1     Pending             0          2s    kubia1\n\tkubia-xxjqr   0/1     ContainerCreating   0          2s    kubia1\n\n### RC 扩容\n扩展/缩容 RC管理的pod为5个\n第一种，commands方式:\n\n\t$ kubectl scale rc kubia --replicas=5\n\n第二种， edit rc yaml文件\n\n\t$ kubectl edit rc kubia\n\t......\n\tspec:\n\t  replicas: 5\n\t......\n\n### 删除RC\n当使用 kubectl delete 删除 ReplicationController 时， 可以通过给命令增加 --cascade= false 选项来保持 pod 的运行.\n\n\t$ kubectl delete rc kubia --cascade=false\n已经删除了 ReplicationController, 所以这些 pod 独立了， 它们不再被管理。但是你始终可以使用适当的标签选择器创建新的 ReplicationController, 并再次将它们管理起来\n\n\n## ReplicaSet\n> 最 初， ReplicationController 是用于复制和在异常时重新调度节点的唯 一Kubemetes 组件， 后来又引入了 一个名为 ReplicaSet 的类似资源 。 它是新一代的ReplicationController, 并且将其完全替换掉 (ReplicationController 最终将被弃用）。\n> 也就是说从现在起， 你应该始终创建 ReplicaSet 而不是 ReplicationController。 它们几乎完全相同， 所以你不会碰到任何麻烦\n> ReplicaSet 的行为与ReplicationController 完全相同， 但pod 选择器的表达能力更强\n> ReplicationController 都无法仅基千标签名的存在来匹配 pod, 而ReplicaSet 则可以。 例如， ReplicaSet 可匹配所有包含名为 env 的标签的 pod, 无论ReplicaSet 的实际值是什么（可以理解为 env=*)\n\nkubia-replicaset.yaml\n\n\tapiVersion: apps/v1\n\tkind: ReplicaSet\n\tmetadata:\n\t  name: kubia\n\tspec:\n\t  replicas: 3\n\t  selector:\n\t    matchLabels:\n\t      app: kubia\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: kubia\n\t    spec:\n\t      containers:\n\t      - name: kubia\n\t        image: luksa/kubia\n\t        ports:\n\t        - containerPort: 8080\n检查replicaset:\n\n\t$ kubectl get rs\n\n### matchExpressions选择器\n创建个yaml文件\nkubia-replicaset-matchexpressions.yaml\n\n\t selector:\n\t   matchExpressions:\n\t     - key: app\n\t       operator: In\n\t       values:\n\t         - kubia\n每个表达式都必须 包含一个key, 一个operator (运算符），并且可能还有一个values的列表（取决于 运算符）.\n• In : Label的值 必须与其中 一个指定的values 匹配。\n• Notln : Label的值与任何指定的values 不匹配。\n• Exists : pod 必须包含一个指定名称的标签（值不重要）。使用此运算符时，\n不应指定 values字段。\n• DoesNotExist : pod不得包含有指定名称的标签。values属性不得指定\n如果同时指定matchLabels和matchExpressions, 则所有标签都必须匹配，并且所有表达式必须计算为true以使该pod与选择器匹配.\n\n### 查看 replicaset 和 deployment 的详细信息\n\n\t$ kubectl describe deployment details-v1\n\t$ kubectl describe rs details-v1-6fc55d65c9\n\n### 删除ReplicaSet\n删除ReplicaSet会删除所有的pod,这种情况下是需要列出pod来确认.\n\n\t$ kubectl delete rs kubia\n\n## DaemonSet\n如果节点下线， DaemonSet不会在其他地方重新创建pod。 但是， 当将一个新节点添加到集群中时， DaemonSet会立刻部署一个新的pod实例。\n如果有人无意中删除了 一个 pod ， 那么它也会重新创建 一个新的 pod。\n与 ReplicaSet一样，DaemonSet 从配置的 pod 模板创建 pod.\n\n> 如果节点可以被设置为不可调度的 ， 防止 pod 被部署到节点上. DaemonSet 甚至会将 pod 部署到这些节点上，因为无法调度的属性只会被调度器使用，而 DaemonSet 管理的 pod 则完全绕过调度器. 这是预期的，因为DaemonSet的目的是运行系统服务，即使是在不可调度的节点上，系统服务通常也需要运行.\n\n给node节点打上label\n\n\t$ kubectl label node server02 disk=ssd\n\nssd-monitor-daemonset.yaml\n\n\tapiVersion: apps/v1\t\t\t// DaemooSet在apps的API组 中，版本是v1\n\tkind: DaemonSet\n\tmetadata:\n\t  name: ssd-monitor\n\tspec:\n\t  selector:\n\t    matchLabels:\n\t      app: ssd-monitor\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: ssd-monitor\n\t    spec:\n\t      nodeSelector:\t\t\t// pod模板包含 会选择有disk=ssd标签的节点 一个节点选择器\n\t        disk: ssd\n\t      containers:\n\t      - name: main\n\t        image: luksa/ssd-monitor\n\n\t$ kubectl create -f ssd-monitor-daemonset.yaml\n\n### 查看DaemonSet\n\n\t$ kubectl get ds\n\tNAME          DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE     CONTAINERS   IMAGES              SELECTOR\n\tssd-monitor   1         1         1       1            1           disk=ssd        3m29s   main         luksa/ssd-monitor   app=ssd-monitor\n如果你有多个节点并且其他的节点也加上了同样的标签，将会看到 DaemonSet 在每个节点上都启动 pod.\n给其中一个节点修改标签disk=hdd, 假设它的硬盘换成磁盘而不是SSD, 那个节点上的pod会如预期中被终止.\n如果还有其他的 pod在运行， 删除 DaemonSet 也会一起删除这些 pod。\n\n### 删除ds\n删除ds会删除由ds控制schedule到每个节点的pod\n\n\t$ kubectl delete ds ssd-monitor\n\n## Job资源\nKubemetes 通过 Job 资源提供了对此的支持，它允许你运行一种 pod, 该 pod 在内部进程成功结束时， 不重启容器。\n一旦任务完成， pod 就被认为处于完成状态.\n由Job管理的pod会一直被重新安排，直到它们成功完成任务.\n\nexporter.yaml\n\n\tapiVersion: batch/v1\n\tkind: Job\n\tmetadata:\n\t  name: batch-job\n\tspec:\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: batch-job\n\t    spec:\n\t      restartPolicy: OnFailure\t\t// 默认为Always,Job pod不能使用默认策略， 因为它们不是要无限期地运行\n\t      containers:\n\t      - name: main\n\t        image: luksa/batch-job\t\t// 运行luksa/batch-job镜像，该镜像调用 一个运行120秒的进程，然后退出\n需要明确地将重启策略 restartPolicy 设置为 OnFailure 或 Never。 此设置防止容器在完成任务时重新启动\n\n\t$ kubectl create -f exporter.yaml\n\n\t$ kubectl get pod\n\tNAME                READY   STATUS    RESTARTS   AGE\n\tbatch-job-lhnfg     1/1     Running   0          113s\n\t\n\t$ kubectl get jobs\n\tNAME        COMPLETIONS   DURATION   AGE\n\tbatch-job   0/1           111s       111s\n\n等待两三分钟后\n\n\t$ kubectl get pod\n\tNAME                READY   STATUS      RESTARTS   AGE\n\tbatch-job-lhnfg     0/1     Completed   0          3m21s\n\n\t$ kubectl get job\n\tNAME        COMPLETIONS   DURATION   AGE\n\tbatch-job   1/1           2m41s      3m27s\n完成后pod未被删除的原因是允许你查阅其日志\n\n\t$ kubectl logs po/batch-job-lhnfg\n\tThu May 14 05:04:38 UTC 2020 Batch job starting\n\tThu May 14 05:06:38 UTC 2020 Finished succesfully\npod 可以被直接删除， 或者在删除创建它的Job时被删除\n作业可以配置为创建多个pod实例，并以并行或串行方式运行它们\n在Job配置中设置 completions和parallelism属性来完成的\n如果你需要 一个Job运行多次，则可以将comple巨ons设为你希望作业的pod运行多少次\n\n\tapiVersion: batch/v1\n\tkind: Job\n\tmetadata:\n\t  name: multi-completion-batch-job\n\tspec:\n\t  completions: 5\t// job将一个接一个地运行五个pod\n\t  parallelism: 2\t// 最多两个pod可以并行运行\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: batch-job\n\t    spec:\n\t      restartPolicy: OnFailure\n\t      containers:\n\t      - name: main\n\t        image: luksa/batch-job\n它最初创建一个pod, 当pod的容器运行完成时，它创建第二个pod, 以此类推，直到五个pod成功完成。\n如果其中 一个pod发生故障，工作会创建一个新的pod, 所以Job总共可以创建五个以上的pod.\n\n\t$ kubectl create -f multi-completion-batch-job.yaml\n\tNAME                               READY   STATUS              RESTARTS   AGE\n\tmulti-completion-batch-job-8kzd5   0/1     ContainerCreating   0          4s\n\tmulti-completion-batch-job-9rnxs   0/1     ContainerCreating   0          4s\n只要其中 一个pod完成任务，工作将运行下 一个pod, 直到五个pod都成功完成任务.\n\n\tkubectl get po\n\tNAME                               READY   STATUS    RESTARTS   AGE\n\tmulti-completion-batch-job-8kzd5   1/1     Running   0          2m8s\n\tmulti-completion-batch-job-9rnxs   1/1     Running   0          2m8s\n\t\n\t$ kubectl get job\n\tNAME                         COMPLETIONS   DURATION   AGE\n\tmulti-completion-batch-job   0/5           2m13s      2m13s\nPOD虽然创建，但是POD里的进程任务还没有完成，因此job显示任然是0/5没有一个pod任务完成\n再等待一会时间\n\n\t$ kubectl get po\n\tNAME                               READY   STATUS      RESTARTS   AGE\n\tmulti-completion-batch-job-8kzd5   0/1     Completed   0          4m18s\n\tmulti-completion-batch-job-9rnxs   0/1     Completed   0          4m18s\n\tmulti-completion-batch-job-blntb   1/1     Running     0          107s\n\tmulti-completion-batch-job-qhsr5   1/1     Running     0          92s\n\tssd-monitor-jbhpd                  1/1     Running     0          176m\n\n\t$ kubectl get job\n\tNAME                         COMPLETIONS   DURATION   AGE\n\tmulti-completion-batch-job   2/5           4m16s      4m16s\n如上显示已经有2个POD任务完成，POD退出.\n甚至可以在 Job 运行时更改 Job 的 parallelism 属性, command如下，实验环境没有成功使用\n\n\t$ kubectl scale job multi-completion-batch-job --replicas 3\n\n> 通过在 pod 配置中设置 activeDeadlineSeconds 属性，可以限制 pod的时间。如果 pod 运行时间超过此时间， 系统将尝试终止 pod, 并将 Job 标记为失败。\n> 通过指定 Job manifest 中的 spec.backoff巨m辽字段， 可以配置 Job在被标记为失败之前可以重试的次数。 如果你没有明确指定它， 则默认为6\n\n### 删除job\n删除job时，由job创建的pod也被直接删除\n\n\t $ kubectl delete job multi-completion-batch-job\n\n## CornJob 资源\n> 批处理任务需要在特定的时间运行，或者在指定的时间间隔内重复运行,在 Linux 和类 UNIX 操作系统中， 这些任务通常被称为 cron 任务。 Kubemetes 也支持这种任务\n> Kubemetes 中的 cron 任务通过创建 CronJob 资源进行配置, 运行任务的时间表以知名的 cron 格式指定\n时间表从左到右包含以下五个条目\n• 分钟\n• 小时\n• 每月中的第几天\n• 月\n• 星期几\n\n创建资源文件(kube API 对象文件)cronjob.yaml\n\n\tapiVersion: batch/v1beta1\n\tkind: CronJob\n\tmetadata:\n\t  name: batch-job-every-fifteen-minutes\n\tspec:\n\t  schedule: \"0,15,30,55 * * * *\"\n\t  startingDeadlineSeconds: 15\t// pod最迟必须在预定时间后15秒开始运行， 如果因为任何原因到该启动时间15s后仍不启动，任务将不会运行，并将显示为Failed\n\t  jobTemplate:\n\t    spec:\n\t      template:\n\t        metadata:\n\t          labels:\n\t            app: periodic-batch-job\n\t        spec:\n\t          restartPolicy: OnFailure\n\t          containers:\n\t          - name: main\n\t            image: luksa/batch-job\n\n> 希望每 15 分钟运行一 次任务因此 schedule 字段的值应该是\"0, 15, 30, 45****\" 这意味着每小时的 0 、 15 、 30和 45 分钟（第一个星号），每月的每一天（第二个星号），每月（第三个星号）和每周的每一天（第四个星号）。\n> 相反，如果你希望每隔 30 分钟运行一 次，但仅在每月的第一天运行，则应将计划设置为 \"0,30 * 1 * *\", 并且如果你希望它每个星期天的 3AM 运行，将它设置为 \"0 3 * * 0\" (最后一个零代表星期天）。\n\n### 查看cronjob\n\t$ kubectl get cronjob -o wide\n\tNAME                              SCHEDULE             SUSPEND   ACTIVE   LAST SCHEDULE   AGE    CONTAINERS   IMAGES            SELECTOR\n\tbatch-job-every-fifteen-minutes   0,15,30,55 * * * *   False     0        18m             112m   main         luksa/batch-job   <none>\n\n### cronjob运行状态\n\t$ kubectl get po\n\tNAME                                               READY   STATUS      RESTARTS   AGE\n\tbatch-job-every-fifteen-minutes-1589439300-4v8wd   0/1     Completed   0          36m\n\tbatch-job-every-fifteen-minutes-1589439600-99pns   0/1     Completed   0          31m\n\tbatch-job-every-fifteen-minutes-1589440500-vs5vm   0/1     Completed   0          16m\n\tbatch-job-every-fifteen-minutes-1589441400-52rzb   1/1     Running     0          112s\n\n\t$ kubectl get job\n\tNAME                                         COMPLETIONS   DURATION   AGE\n\tbatch-job-every-fifteen-minutes-1589439300   1/1           2m24s      36m\n\tbatch-job-every-fifteen-minutes-1589439600   1/1           2m24s      31m\n\tbatch-job-every-fifteen-minutes-1589440500   1/1           2m22s      16m\n\tbatch-job-every-fifteen-minutes-1589441400   0/1           116s       116s\n\n再过一点时间查看\n\n\t$ kubectl get po\n\tNAME                                               READY   STATUS      RESTARTS   AGE\n\tbatch-job-every-fifteen-minutes-1589439600-99pns   0/1     Completed   0          32m\n\tbatch-job-every-fifteen-minutes-1589440500-vs5vm   0/1     Completed   0          17m\n\tbatch-job-every-fifteen-minutes-1589441400-52rzb   0/1     Completed   0          2m34s\n\n\t$ kubectl get job\n\tNAME                                         COMPLETIONS   DURATION   AGE\n\tbatch-job-every-fifteen-minutes-1589439600   1/1           2m24s      32m\n\tbatch-job-every-fifteen-minutes-1589440500   1/1           2m22s      17m\n\tbatch-job-every-fifteen-minutes-1589441400   1/1           2m20s      2m37s\n\n总结: CornJob过指定的时间执行一次POD，执行完退出，会保留三个POD和Job记录.\n\n### 删除cronjob\n运行中的 Job 将不会被终止，不会删除 Job 或 它们的 Pod。为了清理那些 Job 和 Pod，需要列出该 Cron Job 创建的Job，然后删除它们.\n\n\t$ batch-job-every-fifteen-minutes\n\tcronjob.batch \"batch-job-every-fifteen-minutes\" deleted\n\n## secret\n\n\t$ kubectl get secret -n default\n\tNAME                  TYPE                                  DATA   AGE\n\tdefault-token-gtcjx   kubernetes.io/service-account-token   3      32d\n\n\t$ kubectl get pods -o wide\n\tNAME                               READY   STATUS    RESTARTS   AGE     IP           NODE         NOMINATED NODE   READINESS GATES\n\twordpress-7bfc545758-vtfvm         1/1     Running   5          10d     10.36.0.10   hci-node04   <none>           <none>\n\twordpress-mysql-764fc64f97-sjnjk   1/1     Running   0          10d     10.36.0.8    hci-node04   <none>           <none>\n\n\t$ kubectl get po/wordpress-7bfc545758-vtfvm -o yaml\n\t......\n\tspec:\n\t  containers:\n\t  - env:\n\t    volumeMounts:\n\t    - mountPath: /var/www/html\n\t      name: wordpress-persistent-storage\n\t    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\n\t      name: default-token-gtcjx\n\t      readOnly: true\n\t......\n\t  volumes:\n\t  - name: wordpress-persistent-storage\n\t    persistentVolumeClaim:\n\t      claimName: wp-pv-claim\n\t  - name: default-token-gtcjx\n\t    secret:\n\t      defaultMode: 420\t\t// 访问权限\n\t      secretName: default-token-gtcjx\n\t......\n进入wordpress-7bfc545758-vtfvm所在机器的容器里查看/var/run/secrets/kubernetes.io/serviceaccount路径文件\n\n\t$ docker exec -it daec0458a397 /bin/sh\n\t# ls /var/run/secrets/kubernetes.io/serviceaccount\n\t  ca.crt  namespace  token\n\n### 创建自己的Secret\nserviceAccount 用来跟Apiserver通信，用来授权, 可以创建自己的Secret\n编写Secret配置文件 secret.yaml\n\n\tapiVersion: v1\n\tkind: Secret\n\tmetadata:\n\t  name: dbpass\n\ttype: Opaque\t\t// 不透明，浑浊的.\n\tdata:\n\t  username: aW1vb2M=\t\t// base64加密的用户名\n\t  passwd: aW1vb2MxMjM=\t\t// base64加密的密码\n把字符串生成base64很简单，命令如下\n\n\t$ echo -n imooc | base64\t// -n 表示换行\n\taW1vb2M=\n编写Pod资源配置文件 pod-secret.yaml\n\n\tapiVersion: v1\n\tkind: Pod\n\tmetadata:\n\t  name: pod-secret\n\tspec:\n\t  containers:\n\t  - name: springbook-web\n\t    image: hub.mooc.com/kubernetes/springboot-web:v1\n\t    ports:\n\t    - containerPort: 8080\n\t    volumeMounts:\n\t    - name: db-secret\n\t      mountPath: /db-secret\n\t      readOnly: true\n\t  volumes:\n\t  - name: db-secret\n\t    projected:\n\t      sources:\t\t\t// secret 来源\n\t      - secret:\n\t        name: dbpass\t// secret 名字\n生成Pod并进入查看\n\n\t$ / # cd /db-secret/\n\t$ ls\n\t  passwd username\n\t$ cat -n username\t\t// 查看容器里存放的是base64解码过的数据\n\t  immoc\n\t$ cat -n passwd\n\t  imooc123\n\n可以通过修改secret.yaml文件修改secret账号密码等再$ kubectl apply -f secret.yaml来更改密码.\n\n## Configmap\n> configmap常用来存储不需要加密的数据, 比如应用的启动参数，一些参数的配置等\n * 第一种向k8s添加很多key value的键值对属性值，就可以用configmap\n\n\n\t$ touch game.properties\n\t$ vim game.properties\n\t  enemies=aliens\n\t  lives=3\n\t  enemies.cheat=true\n\t  secret.code.allowed=true\n\t  ......\n配置到K8S里\n\n\t$ kubectl create configmap web-game --from-file game.properties\n\t$ kubectl get cm\n\n使用configmap, Pod-game.yaml\n\n\tapiVersion: v1\n\tkind: Pod\n\tmetadata:\n\t  name: pod-game\n\tspec:\n\t  containers:\n\t  - name: web\n\t    image: hub.mooc.com/kubernetes/springboot-web:v1\n\t    ports:\n\t    - containerPort: 8080\n\t    volumeMounts:\n\t    - name: game\n\t      mountPath: /etc/config/game\n\t      readOnly: true\n\t  volumes:\n\t  - name: game\n\t    configMap:\n\t      name: web-game\n生成Pod并进入查看\n\n\t$ cd /etc/config/game\n\t$ ls\n\t  game.properties\n\t$ cat game.properties\n\t  enemies=aliens\n\t  lives=3\n\t  enemies.cheat=true\n\t  secret.code.allowed=true\n\t  ......\n\n可以通过kubectl edit 修改configMap账号密码等\n\n\t$ kubectl edit cm web-game -o yaml\n\t  enemies.cheat=false\t//等等操作\n\n * 第二种配置文件方式创建configMap\nconfigmap.yaml\n\n\n\tapeVersion: v1\n\tkind: Configmap\n\tmetadata:\n\t  name: configs\n\tdata:\n\t  Java_OPTS: -Xms1024m\n\t  LOG_LEVEL: DEBUG\n\n\t$ kubectl create -f configmap.yaml\n编写资源配置文件pod-env.yaml\n\n\tapiVersion: v1\n\tkind: Pod\n\tmetadata:\n\t  name: pod-env\n\tspec:\n\t  containers:\n\t  - name: web\n\t    image: hub.mooc.com/kubernetes/springboot-web:v1\n\t    ports:\n\t    - containerPort: 8080\n\t    env:\n\t      - name: LOG_LEVEL_CONFIG\n\t        valueFrom:\n\t          configMapKeyRef:\n\t            name: configs\t\t// 指定configMap名字\n\t            key: LOG_LEVEL\t\t// configs下面的LOG_LEVEL\n进入容器查看环境变量\n\n\t$ env | grep LOG\n\t  LOG_LEVEL_CONFIG=DEBUG\n之后次容器就可以通过环境变量获取值\n\n * 第三种 通过命令行方式传进参数\n也是先跟第二种一样创建configMap资源\n\n\n\t$ kubectl create -f configmap.yaml\n编写资源配置文件pod-cmd.yaml\n\n\tapiVersion: v1\n\tkind: Pod\n\tmetadata:\n\t  name: pod-cmd\n\tspec:\n\t  containers:\n\t  - name: web\n\t    image: hub.mooc.com/kubernetes/springboot-web:v1\n\t    command: [\"/bin/sh\", \"-c\", \"java -jar /springboot-web.jar -DJAVA_OPTS=$(JAVA_OPTS)\"]\n\t    ports:\n\t    - containerPort: 8080\n\t    env:\n\t      - name: Java_OPTS\n\t        valueFrom:\n\t          configMapKeyRef:\n\t            name: configs\t\t// 指定configMap名字\n\t            key: Java_OPTS\t\t// configs下面的LOG_LEVEL\n进入容器查看进程\n\n\t$ ps -ef\n\t  java -jar /springboot-web.jar -DJAVA_OPTS=-Xms1024m\n\n## downwardAPI\ndownwardAPI主要作用是在程序中取得Pod对象本身的一些相关信息\npod-downwardapi.yaml\n\n\tapiVersion: v1\n\tkind: Pod\n\tmetadata:\n\t  name: pod-downwardapi\n\t  labels:\n\t    app： downwardapi\n\t    type: webapp\n\tspec:\n\t  containers:\n\t  - name: web\n\t    image: hub.mooc.com/kubernetes/springboot-web:v1\n\t    ports:\n\t    - containerPort: 8080\n\t    volumeMounts:\n\t      - name: podinfo\n\t        mountPath: /etc/podinfo\n\t  volumes:\n\t    - name: podinfo\n\t      projected:\n\t        sources:\n\t        - downwardAPI:\n\t          items:\n\t            - path: \"labels\"\n\t              fieldRef:\n\t                fieldPath: metadata.labels\n\t            - path: \"name\"\n\t              fieldRef:\n\t                fieldPath: metadata.name\n\t            - path: \"namespace\"\n\t              fieldRef:\n\t                fieldPath: metadata.namespace\n\t            - path: \"mem-request\"\n\t              resourceFieldRef:\n\t                containerName: web\n\t                resource: limits.memory\n进入容器查看文件信息\n\n\t$ cd /etc/podinfo\n\t$ ls -l\n\t  labels mem-request name namespace\n\t$ cat -n labels\n\t  app=\"downwardapi\"\n\t  type=\"webapp\"\n\t$ cat -n namespace\n\t  default\n\t$ cat -n name\n\t  pod-downwardapi\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/micro_service/03_kubernetes_ns_pod.md","raw":"---\ntitle: 03 Kubernetes nodes, namespace, pod\ntags: kubernetes\ncategories:\n- microService\n- kubernetes\ntop: 3\n---\n\n## nodes\n\n\t$ kubectl get nodes -o wide\n\tNAME         STATUS   ROLES    AGE   VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION           CONTAINER-RUNTIME\n\thci-node01   Ready    master   5d    v1.18.1   10.67.108.211   <none>        CentOS Linux 7 (Core)   3.10.0-1062.el7.x86_64   docker://19.3.8\n\thci-node02   Ready    <none>   5d    v1.18.1   10.67.109.142   <none>        CentOS Linux 7 (Core)   3.10.0-1062.el7.x86_64   docker://19.3.8\n\thci-node03   Ready    <none>   5d    v1.18.1   10.67.109.147   <none>        CentOS Linux 7 (Core)   3.10.0-1062.el7.x86_64   docker://19.3.8\n\thci-node04   Ready    <none>   5d    v1.18.1   10.67.109.144   <none>        CentOS Linux 7 (Core)   3.10.0-1062.el7.x86_64   docker://19.3.8\n\t$ kubectl describe node hci-node02\n\t输出显示了节点的状态、 CPU 和内存数据、系统信息、运行容器的节点等\n\n\t查看某台机器的资源\n\t$ kubectl describe node hci-node01\n\n### 创建别名和补全\nkubectl 会被经常使用。很快你就会发现每次不得不打全命令是非常痛苦的。\n将下面的代码添加到 ~/.bashrc 或类似的文件中 ：\n\n\talias k=kubectl\n为kuebctl配置 tab 补全\n需要先安装一个叫作 bashcompletio口的包来启用 bash 中的 tab 命令补全， 然后可以运行接下来的命令（也需要加到 ~/.bashrc 或类似的文件中）\n\n\t$ source <{kubectl completion bash)\n\t$ kubectl desc<TAB> nod<TAB> hci<TAB>\n但是需要注意的是， tab 命令行补全只在使用完整的 kubectl 命令时会起作用,(当使用别名 k 时不会起作用). 需要改变 kubectl completion 的输出来修复：\n\n\t$ source <(kubectl completion bash | sed s/kubectl/k/g)\n\n### node 标签\n\n\t$ kubectl get nodes\n\t$ kubectl label node server02 gpu=false\n\t$ kubectl label node server02 gpu=true --overwrite\t//修改node标签\n\t$ kubectl get node -L gpu\t\t// 列出所有node，并添加GPU一列进行展示\n\t$ kubectl get node -l gpu\t\t// 只列出含标签的key为gpu的node\n\t$ kubectl get node -l gpu=false\t// 只列出含gpu=false的node\n\n将POD调度到指定的node上: kubia-gpu.yaml\n\n\tapiVersion: v1\n\tkind: Pod\n\tmetadata:\n\tname: kubia-gpu\t\t// 指定生成的POD名字\n\tspec:\n\tnodeSelector:\t\t// node选择器,选择含标签gpu=true的node机器\n\t\tgpu: \"true\"\t\t\n\tcontainers:\n\t- image: luksa/kubia\t// 要拉取的 image 名字\n\t\tname: kubia\t\t\t// 生成的 container 名字\n\n\t$ kubectl create -f kubia-gpu.yaml\n如果没有标签为gpu=true的合适node， 通过 $ kubectl describe pod/kubia-nogpu 查看Message， 会报 0/2 nodes are available: 2 node(s) didn't match node selector.信息\n\n\t$ kubectl describe pod/kubia-gpu\n\t......\n\tNode-Selectors:  gpu=true\n\t......\n\n### taint污点\n给Node添加污点可以让配置tolerations的Pod部署上来，而不让平常的Pod部署.\n配置tolerations的Pod可以部署到添加污点的机器也可以部署到其它平常机器\n\n\t$ kubectl taint nodes NodeName gpu=true:NoSchedule\n\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\t  name: web-demo\n\t  namespace: dev\n\tspec:\n\t  selector:\n\t    matchLabels:\n\t      app: web-demo\n\t  replicas: 3\t\t\t// 副本数3来测试能部署到哪些机器\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: web-demo\n\t    spec:\n\t      selector:\n\t        matchLabels:\n\t          app: web-demo\n\t      replicas: 1\n\t      template:\n\t        metadata:\n\t          labels:\n\t            app: web-demo\n\t        spec:\n\t          containers:\n\t          - name: web-demo\n\t            image: hub.mooc.com/kubernetes/web:v1\n\t            ports:\n\t            - containerPort: 8080\n\t          tolerations:\t\t// 可以部署到有设置taint的机器，也可以部署到其它机器\n\t          - key: \"gpu\"\n\t            operator: \"Equal\"\n\t            value: \"true\"\n\t            effect: \"NoSchedule\"\n> 典型的使用kubeadm部署和初始化的Kubernetes集群，master节点被设置了一个node-role.kubernetes.io/master:NoSchedule的污点，可以使用kubectl describe node <node-name>命令查看\n> 这个污点表示默认情况下master节点将不会调度运行Pod，即不运行工作负载, 对于使用二进制手动部署的集群设置和移除这个污点的命令如下:\n\n\t$ kubectl taint nodes <node-name> node-role.kubernetes.io/master=:NoSchedule\n\t$ kubectl taint nodes <node-name> node-role.kubernetes.io/master:NoSchedule-\n> kubeadm初始化的Kubernetes集群，master节点也被打上了一个node-role.kubernetes.io/master=的label，标识这个节点的角色为master。给Node设置Label和设置污点是两个不同的操作。设置Label和移除Label的操作命令如下\n\n设置Label\n\n\t$ kubectl label node node1 node-role.kubernetes.io/master=\n移除Label\n\n\t$ kubectl label node node1 node-role.kubernetes.io/master-\n\n\n## Namespace\n> 大多数对象的名称必须符合 RFC 1035 （域名）中规定的命名规范 ，这意味着它们可能只包含字母、数字、横杠（－）和点号，但命名空间（和另外几个）不允许包含点号\n\n### 隔离性\n> 名字的隔离只是 通过svc名称(DNS) 访问的隔离，通过svc的IP和Pod的IP再加上端口号(Port) 照样可以访问不同命名空间下的服务.\n\n### 设置默认命名空间\n> 默认Kubeclt获取default命名空间下的资源，可以通过设置K8s上下文配置文件如kube.config 使得某个命名空间变为默认namespace，获取pod时候不需要在加上 -n 参数\n\n### 创建命名空间\n> namespace不提供网络隔离, 如果命名空间 foo 中的某个 pod 知道命名空间 bar 中 pod 的 IP 地址，那它就可以将流量（例如 HTTP 请求）发送到另一个 pod\n第一种： commands方式\n\n\t$ kubectl create namespace custom-namespace\n\t$ kubectl create ns custom-namespace\n\n第二种： Yaml方式， 之所以选择使用 YAML 文件，只是为了强化Kubemetes中的所有内容都是一 个 API 对象这一概念\n\n\t$ touch custom-namespace.yaml\n\tapiVersion: v1\n\tkind: Namespace\n\tmetadata:\n\t  name: custom-namespace\n\t$ kubectl create -f custom-namespace.yaml\n\n### 划分方式\n\n\t* 按环境划分: dev(开发), test(测试)\n\t* 按团队划分\n\t* 自定义多级划分\n\n### 标记命名空间\n\n\t$ kubectl label namespace default istio-injection=enabled --overwrite         // enabled\n\t$ kubectl label namespace default istio-injection=disabled --overwrite        // disabled\n\t$ kubectl label namespace default istio-injection= --overwrite                // cancel set\n\tnamespace/default labeled\n\n### 查看标记 istio-injection=enabled 标签的命名空间\n\n\t$ kubectl get namespace -L istio-injection\n\tNAME              STATUS   AGE   ISTIO-INJECTION\n\tdefault           Active   85m   enabled\n\tistio-system      Active   25m   disabled\n\tkube-node-lease   Active   85m\n\tkube-public       Active   85m\n\tkube-system       Active   85m\n\t[root@hci-node01 istio-1.5.2]#\n\n### 删除namespace\n删除当前命名空间中的所有资源，可以删除ReplicationCcontroller和pod,以及我们创建的所有service\n第一个 all 指定正在删除所有资源类型, --all 选项指定将删除所有资源实例, 而不是按名称指定它们\n使用 all 关键字删除所有内容并不是真的完全删除所有内容。 一些资源比如Secret会被保留下来， 并且需要被明确指定删除\n\n\t$ kubectl delete all --all\t\t// 命令也会删除名为 kubernetes 的Service, 但它应该会在几分钟后自动重新创建\n可以简单地删除整个命名空间（ pod 将会伴随命名空间 自动删除〉\n\n\t$ kubectl delete ns custom-namespace\n强制删除NAMESPACE\n\n\t$ kubectl delete namespace NAMESPACENAME --force --grace-period=0\n进入kube-system下得etcd pod 删除需要删除的NAMESPACE\n\n\t$ kubectl get po -n kube-system\n\tNAME                                 READY   STATUS    RESTARTS   AGE\n\tetcd-hci-node01                      1/1     Running   5          16d\n\t......\n\t\n\t$ kubectl exec -it etcd-hci-node01 sh -n kube-system\n\t$ etcdctl del /registry/namespaces/NAMESPACENAME\n\n## POD\n\n### 查看pod解释\n\n\t$ kubectl explain pod\n\tKIND:     Pod\n\tVERSION:  v1\n\t\n\tDESCRIPTION:\n\t\tPod is a collection of containers that can run on a host. This resource is\n\t\tcreated by clients and scheduled onto hosts.\n\t\n\tFIELDS:\n\tapiVersion   <string>\n\t\tAPIVersion defines the versioned schema of this representation of an\n\t\tobject. Servers should convert recognized schemas to the latest internal\n\t\tvalue, and may reject unrecognized values. More info:\n\t\thttps://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\t\n\tkind <string>\n\t\tKind is a string value representing the REST resource this object\n\t\trepresents. Servers may infer this from the endpoint the client submits\n\t\trequests to. Cannot be updated. In CamelCase. More info:\n\t\thttps://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\t\n\tmetadata     <Object>\n\t\tStandard object's metadata. More info:\n\t\thttps://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\t\n\tspec <Object>\n\t\tSpecification of the desired behavior of the pod. More info:\n\t\thttps://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status\n\t\n\tstatus       <Object>\n\t\tMost recently observed status of the pod. This data may not be up to date.\n\t\tPopulated by the system. Read-only. More info:\n\t\thttps://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status\n\n深入理解POD属性\n\n\t$ kubectl explain pod.apiVersion\n\t$ kubectl explain pod.kind\n\t$ kubectl explain pod.spec\npods 的缩写是 po, service 的缩写是 SVC, replicationcontroller 的缩写 rc\n\n\t$ kubectl get pods -n kube-system\n> 我们提到过每个 pod 都有自己的 IP 地址，但是这个地址是集群 内部的，不能从集群外部访问。\n> 要让 pod 能够从外部访问 ， 需要通过服务对象公开它， 要创建一个特殊的 LoadBalancer 类型的服务。\n> 因为如果你创建一个常规服务（ 一个 Cluster IP 服务）， 比如 pod ，它也 只能从集群内部访问。\n> 通过创建 LoadBalanc er 类型 的服务，将创建一个外部的负载均衡 ，可以通过 负载均衡的公共 IP 访问 pod \n\n### 创建POD\n通过上传 JSON 或 YAML 描述文件到 Kubemetes API 服务器来创建 pod.\nkubectl create -f 命令用于从YAML或JSON文件创建任何资源（不只是 pod).\n\t$ kubectl create -f kubia-manual.yaml\n\t$ kubectl create -f kubia-gpu.yaml -n custom-namespace\t//船舰pod到custom-namespace命名空间下\n\n\t$ kubectl describe pod/kubia\n\t......\n\tEvents:\n\tType    Reason     Age    From               Message\n\t----    ------     ----   ----               -------\n\tNormal  Scheduled  5m12s  default-scheduler  Successfully assigned default/kubia-liveness to server02\n\tNormal  Pulling    5m8s   kubelet, server02  Pulling image \"luksa/kubia-unhealthy\"\n\n### pod标签labels\n\n\t$ kubectl get po --show-labels\n查看pod标签的key值为creation_method 和 env 的信息\n\n\t$ kubectl get po -L creation_method,env\n\tNAME                           READY   STATUS    RESTARTS   AGE   CREATION_METHOD   ENV\n\tkubia                          1/1     Running   0          16h\n\tkubia-manual-v2                1/1     Running   0          34m   manual            pod\nPOD添加标签\n\n\t$ kubectl label po kubia  creation_method=manual\n\tNAME                           READY   STATUS    RESTARTS   AGE   CREATION_METHOD   ENV\n\tkubia                          1/1     Running   0          16h   manual\n\tkubia-manual-v2                1/1     Running   0          43m   manual            pod\n更改现有标签, 在更改现有标签时， 需要使用--overwrite选项\n\n\t$ kubectl label po kubia-manual-v2 env=debug --overwrite\n使用标签列出POD\n\n\t$ kubectl get po -1 creation_method=manual\n\t$ kubectl get po -l env\n同样列出没有env标签的pod\n确保使用单引号来圈引 !env, 这样bash shell才不会解释感叹号（译者注：感叹号在bash中有特殊含义， 表示事件指示器)\n\n\t$ kubectl get po -l '!env'\n\tcreation_method!=manual 选择带有creation_method标签， 并且值不等于manual的pod\n\tenv in (prod, devel)选择带有env标签且值为prod或devel的pod\n\tenv notin (prod, devel)选择带有env标签， 但其 值不是prod或devel的pod\n\tapp=pc,rel=beta 选择pc微服务的beta版本pod\n\n\n## pod 注解\n\n\t$ kubectl annotate pod kubia-gpu mycompany.com/someannotion=\"foo bar\"\n\t$ kubectl describe pod/kubia-gpu\n\t......\n\tAnnotations:  mycompany.com/someannotion: foo bar\n\t......\n\n### 查看该 pod 的完整描述文件：\n\t$ kubectl get po kubia-manual -o yaml\t// 获取yaml格式信息\n\t$ kubect1 get po kubia-manual -o json\t// 获取json格式信息\n\n\n### 执行pod容器\n直接执行:\n\n\t$ kubectl exec fortioclient-f8d65c6bb-5k4td -c captured date -n twopods\n进入容器执行, 当pod中只有一个容器时可以不加-c参数指定某个容器\n\n\t$ kubectl exec fortioclient-f8d65c6bb-5k4td -c captured -i -t /bin/sh -n twopods\n\n### 容器进程, 网络等\n查看进程command完整信息\n\n\t$ ps auxwww\n\t$ pa -ef\n查看网络\n\n\t$ netstat -ntlp\n\n### 查看Pod, svc日志\n\n\t$ kubectl logs pod/istiod-774777b79-ddfk4 -n istio-system\n\t$ kubectl logs -f pod/<pod_name> #类似tail -f的方式查看(tail -f 实时查看日志文件 tail -f 日志文件log)\n\t$ kubectl logs svc/istiod -n istio-system\n\t如果该pod中有其他容器， 可以通过如下命令获取其日志：\n\t$ kubectl logs kubia-manual -c kubia\n\n查看容器重启后前一个容器为什么重启的日志信息\n\t$ kubectl logs mypod --previous\n\n### 部署应用程序\n\n\t$ kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml\n\n### 重启Pod\n\n\t$ kubectl get pod {podname} -n {namespace} -o yaml | kubectl replace --force -f -\n\n### 删除Pod\n\n\t$ kubectl delete pod PODNAME -n custom-namespace\t\t// 删除指定命名空间下的POD\n\t$ kubectl delete po -l creation_method=manual\t\t\t// 通过标签选择器来删除\n\t$ kubectl delete po --all -n custom-namespace\t\t\t// 删除当前命名空间中的所有 pod\n\t$ kubectl delete all --all -n custom-namespace\t\t\t// 删除所有pod和svc，系统带的kubernetes服务会过一会重启\n可使用kubectl中的强制删除命令删除POD\n\n\t$ kubectl delete pod PODNAME --force --grace-period=0\n直接从ETCD中删除源数据\n删除default namespace下的pod名为pod-to-be-deleted-0\n\n\t$ ETCDCTL_API=3 etcdctl del /registry/pods/default/pod-to-be-deleted-0\n\n## livenessProbe 存活探针, readinessProbe\nKubemetes 可以通过存活探针 (liveness probe) 检查容器是否还在运行.\nKubemetes 可以通过readinessProbe探针 检查容器是否准备完毕可以挂到负载均衡上供外部访问.\nlivenessProbe与readinessProbe探针用法完全一样, 都有三种，下面介绍这三种健康检查方式.\n\n可以为 pod 中的每个容器单独指定存活探针。 如果探测失败， Kubemetes 将定期执行探针并重新启动容器\n\n * 第一种健康检查方式: 执行命令检查存活探针是否存活\n\n\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\t  name: web-demo\n\t  namespace: dev\n\tspec:\n\t  selector:\n\t    matchLabels:\n\t      app: web-demo\n\t  replicas: 1\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: web-demo\n\t    spec:\n\t      selector:\n\t        matchLabels:\n\t          app: web-demo\n\t      replicas: 1\n\t      template:\n\t        metadata:\n\t          labels:\n\t            app: web-demo\n\t        spec:\n\t          containers:\n\t          - name: web-demo\n\t            image: hub.mooc.com/kubernetes/web:v1\n\t            ports:\n\t            - containerPort: 8080\n\t            livenessProbe:\t\t\t\t// 检查应用是否存活的探针, 和容器一个级别\n\t              exec:\t\t\t\t\t\t// 第一种健康检查方式, 通过执行命令\n\t                command:\n\t                - /bin/sh\n\t                - -c\n\t                - ps -ef|grep java|grep -v grep\n\t              initialDelaySeconds: 10\t\t// 容器起来后过10s开始检查\n\t              periodSeconds: 10\t\t\t\t// 每隔10s检查一次\n\t              failureThreshold: 2\t\t\t// 连续健康检查失败2次放弃检查, 重启容器\n\t              successThreshold: 1\t\t\t// 检查一次满足条件就认为健康检查通过\n\t              timeoutSeconds: 5\t\t\t\t// 每次健康检查delay时间是5s, 超时也认为健康检查失败, 重启容器\n\t            readinessProbe:\t\t\t\t// readinessProbe与livenessProbe用法完全一样.\n\t              exec:\t\t\t\t\t\t// 第一种检查方式, 通过执行命令\n\t                command:\n\t                - /bin/sh\n\t                - -c\n\t                - ps -ef|grep java|grep -v grep\n\t              initialDelaySeconds: 10\t\t// 容器起来后过10s开始检查\n\t              periodSeconds: 10\t\t\t\t// 每隔10s检查一次\n\t              failureThreshold: 2\t\t\t// 连续健康检查失败2次放弃检查, 重启容器\n\t              successThreshold: 1\t\t\t// 检查一次满足条件就认为健康检查通过\n\t              timeoutSeconds: 5\t\t\t\t// 每次健康检查delay时间是5s, 超时也认为健康检查失败, 重启容器\n\n * 第二种健康检查方式: 执行网络请求检查存活探针是否存活\n\n\n\t$ touch kubia-liveness-probe.yaml\n\tapiVersion: v1\n\tkind: Pod\n\tmetadata:\n\t  name: kubia-liveness\n\tspec:\n\t  containers:\n\t  - image: luksa/kubia-unhealthy\n\t    name: kubia\n\t    livenessProbe:\t\t// 一个 HTTP GET 存活探针\n\t      httpGet:\t\t\t// 第二种健康检查方式, 通过httpGet\n\t        path: /\t\t\t// 应用要访问的路径\n\t        port: 8080\t\t// 容器本身启动的端口\n\t        scheme: HTTP\n\t      initialDelaySeconds: 15\t\t// 容器起来后过10s开始检查\n\t      periodSeconds: 5\n\n\t$ kubectl get pods\n\tNAME                           READY   STATUS    RESTARTS   AGE\n\tkubia-liveness                 1/1     Running   1          13m\n查看该pod描述\n\n\t$ kubectl describe pod/kubia-liveness\n\t......\n\tLast State:     Terminated\n\t  Reason:       Error\n\t  Exit Code:    137\n\t  Started:      Wed, 13 May 2020 15:49:36 +0800\n\t  Finished:     Wed, 13 May 2020 15:51:25 +0800\n\tReady:          True\n\tRestart Count:  1\n\tLiveness:       http-get http://:8080/ delay=0s timeout=1s period=10s #success=1 #failure=3\n\t......\n数字137是两个 数字的总和：128+x, 其中x是终止进程的信号编号.\n在这个例子中，x等于9, 这是SIGKILL的信号编号，意味着这个进程被强行终止.\n当容器被强行终止时，会创建一个全新的容器—-而不是重启原来的容器.\ndelay=Os部分显示在容器启动后立即开始探测.\ntimeout仅设置为1秒，因此容器必须在1秒内进行响应， 不然这次探测记作失败.\n每10秒探测一次容器(period=lOs), 并在探测连续三次失败(#failure=3)后重启容器.\n定义探 针时可以自定义这些附加参数。例如，要设 置初始延迟，请将initialDelaySeconds属性添加到存活探针的配置中.\n\n\t    livenessProbe:\t\t// 一个 HTTP GET 存活探针\n\t      httpGet:\n\t        path: /\n\t        port: 8080\n\t      initialDelaySeconds: 15\t// Kubernetes会在第—次探测前等待15秒 \n\n\t$ kubectl describe pod/kubia-liveness\n\t......\n\tLiveness:       http-get http://:8080/ delay=15s timeout=1s period=10s #success=1 #failure=3\n\n * 第三种健康检查方式: 通过TCP检查端口是否处于监听状态\n\t    livenessProbe:\t\t// 一个 HTTP GET 存活探针\n\t      tcpSocket:\n\t        port: 8080\n\t      initialDelaySeconds: 20\t// Kubernetes会在第—次探测前等待15秒 \n\t      periodSeconds: 5\n\n> 如果没有设置初始延迟，探针将在启动时立即开始探测容器， 这通常会导致探测失败， 因为应用程序还没准备好开始接收请求.\n> 务必记得设置一个初始延迟未说明应用程序的启动时间.\n> 对于在生产中运行的pod, 一定要定义一个存活探针。没有探针的话，Kubemetes无法知道你的应用是否还活着。只要进程还在运行， Kubemetes会认为容器是健康的\n> Kubernetes会在你的容器崩溃或其存活探针失败时， 通过重启容器来保持运行。 这项任务由承载pod的节点上的Kubelet 执行 一— 在主服务器上运行的Kubernetes Control Plane组件不会参与此过程.\n> 但如果节点本身崩溃， 那么Control Plane 必须为所有随节点停止运行的pod创建替代品。 它不 会为你直接创建的pod执行此操作 。 这些pod只被Kubelet 管理.\n\n### 查看 readinessProbe, healthProbe\n\t\n\t$ kubectl edit po -n istio-system istio-ingressgateway-6489d9556d-wjr58\n\t$ kubectl edit deployment -n istio-system istio-ingressgateway\n\t$ kubectl logs po/istio-ingressgateway-6489d9556d-wjr58 -n istio-system\n\t$ kubectl get po -A\n\n### affinity\n匹配Node标签, Pod部署到哪台机器上.\n\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\t  name: web-demo\n\t  namespace: dev\n\tspec:\n\t  selector:\n\t    matchLabels:\n\t      app: web-demo\n\t  replicas: 1\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: web-demo\n\t    spec:\n\t      selector:\n\t        matchLabels:\n\t          app: web-demo\n\t      replicas: 1\n\t      template:\n\t        metadata:\n\t          labels:\n\t            app: web-demo\n\t        spec:\n\t          containers:\n\t          - name: web-demo\n\t            image: hub.mooc.com/kubernetes/web:v1\n\t            ports:\n\t            - containerPort: 8080\n\t          affinity:\n\t            nodeAffinity:\t\t// node亲和性, 要部署到哪台机器，不要部署到哪台机器\n\t              requiredDuringSchedulingIgnoredDuringExecution:\t// 必须满足下面条件才会执行调度\n\t                nodeSelectorTerms:\t\t// 数组形式, 下面可以定义多个Terms, 它们之间是或的关系\n\t                - matchExpressions:\t\t// 数组形式, 如果定义多个matchExpressions它们之间是与的关系\n\t                  - key: beta.kubernetes.io/arch\t// 节点的label含有的key名字, 这里的是由K8s根据机器自动生成的\n\t                    operator: In\n\t                    values:\t\t\t\t// 前提是Node机器有amd64标签K8s才会把容器部署到次Node机器\n\t                    - amd64\t\t\t\t// 通过kubectl get nodes NodeName -o yaml进行查看\n\t              preferredDuringSchedulingIgnoredDuringExecution:\t// 最好是怎样调度\n\t              - weight: 1\t\t\t\t// 权重\n\t                perference:\n\t                  matchExpressions:\n\t                  - key: disktype\t\t// 通过kubectl get nodes --show-labels查看\n\t                    operator: NotIn\n\t                    values:\n\t                    - ssd\n\t            podAffinity:\t\t// Pod亲和性, 想和哪些Pod部署到一台机器, 不想和哪些Pod部署在一台机器\n\t              requiredDuringSchedulingIgnoredDuringExecution:\n\t              - labelSelector:\n\t                  matchExpressions:\n\t                  - key: app\n\t                    operator: In\t\t// 要跟app=web-demo的Pod运行在同一个节点上\n\t                    values:\n\t                    - web-demo-node\n\t                topologyKey: kubernetes.io/hostname\t\t// 节点的label名字\n\t              preferredDuringSchedulingIgnoredDuringExecution:\n\t              - weight: 100\n\t                podAffinityTerm:\n\t                  labelSelector:\n\t                    matchExpressions:\n\t                    - key: app\n\t                      operator: In\n\t                      values:\n\t                      - web-demo-node\n\t                  topologyKey: kubernetes.io/hostname\n\t            podAntiAffinity:\t\t// Pod反亲和性, 不想和哪些Pod部署到一台机器, 用法和podAffinity用法完全一样\n\t            pod反亲和性用的很多的是上面的replicas: 的值 >=2 时候会把容器副本分别部署到不同机器\n\n### Pod启动停止控制\nPod容器启动时候和停止前所做的事\n\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\t  name: web-demo\n\t  namespace: dev\n\tspec:\n\t  selector:\n\t    matchLabels:\n\t      app: web-demo\n\t  replicas: 1\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: web-demo\n\t    spec:\n\t      selector:\n\t        matchLabels:\n\t          app: web-demo\n\t      replicas: 1\n\t      template:\n\t        metadata:\n\t          labels:\n\t            app: web-demo\n\t        spec:\n\t          containers:\n\t          - name: web-demo\n\t            image: hub.mooc.com/kubernetes/web:v1\n\t            ports:\n\t            - containerPort: 8080\n\t            volumeMounts:\n\t            - name: shared-volume\n\t              mounthPath: /shared-web\n\t            lifecycle:\t\t\t\tPod里容器启动前和停止前要做的事\n\t              postStart:\n\t                exec:\n\t                  command: [\"/bin/sh\", \"-c\", \"echo web starting ... >> /var/log/messages\"]\n\t              preStop:\n\t                exec:\n\t                  command: [\"/bin/sh\", \"-c\", \"echo web stopping ... >> /var/log/messages && sleep 3\"]\n\n\n## ReplicationController\n一个ReplicationController有三个主要部分\n • label selector ( 标签选择器）， 用于确定ReplicationController作用域中有哪些pod\n • replica count (副本个数）， 指定应运行的pod 数量\n • pod template (pod模板）， 用于创建新的pod 副本\n使用 ReplicationController 的好处\n •确保一 个 pod (或多个 pod副本）持续运行， 方法是在现有pod 丢失时启动一个新 pod。\n • 集群节点发生故障时， 它将为故障节 点 上运 行的所有 pod (即受ReplicationController 控制的节点上的那些 pod) 创建替代副本。\n • 它能轻松实现 pod的水平伸缩 手动和自动都可以\n\n### 由RC创建POD\nkubia-rc.yaml, 内容如下:\n\n\tapiVersion: v1\n\tkind: ReplicationController\t\t// 这里的配置定义了ReplicationController(RC)\n\tmetadata:\n\t  name: kubia\t\t// ReplicationController 的名字\n\tspec:\n\t  replicas: 3\t\t// pod 实例的目标数目\n\t  selector:\t\t\t// selector也可以不写，replica 直接根据下面的template模板里的lables标签选择创建POD\n\t    app: kubia\t\t// pod 选择器决定了 RC 的操作对象\n\t  template:\t\t\t// 从此以下都是创建新 pod 所用的 pod 模板, 与单独创建的pod定义yaml文件内容几乎相同\n\t    metadata:\n\t      labels:\n\t        app: kubia\n\t    spec:\n\t      containers:\n\t      - name: kubia\n\t        image: luksa/kubia\n\t        ports:\n\t        - containerPort: 8080\n创建ReplicationController并由其创建pod\n\n\t$ kubectl create -f kubia-rc.yaml\n\t$ kubectl get po -o wide\n\tNAME          READY   STATUS    RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES\n\tkubia-6wnj5   1/1     Running   0          56s   10.44.0.3   server02   <none>           <none>\n\tkubia-788p8   1/1     Running   0          56s   10.44.0.2   server02   <none>           <none>\n\tkubia-c9kn6   1/1     Running   0          56s   10.44.0.1   server02   <none>           <none>\n\n\t$ kubectl delete po kubia-6wnj5\n\tNAME          READY   STATUS              RESTARTS   AGE\n\tkubia-6ntgt   0/1     ContainerCreating   0          12s\n\tkubia-6wnj5   1/1     Terminating         0          3m3s\n\tkubia-788p8   1/1     Running             0          3m3s\n\tkubia-c9kn6   1/1     Running             0          3m3s\n上面重新列出pod会显示四个， 因为你删除的pod己终止， 并且己创建一个新的pod\n虽然ReplicationController会立即收到删除pod的通知 (API 服务器允许客户端监听资源和资源列表的更改），但这不是它创建替代pod的原因。\n该通知会触发控制器检查实际的pod数量并采取适当的措施.\n\n\t$ kubectl get po -o wide\n\tNAME          READY   STATUS    RESTARTS   AGE     IP          NODE       NOMINATED NODE   READINESS GATES\n\tkubia-6ntgt   1/1     Running   0          53s     10.44.0.4   server02   <none>           <none>\n\tkubia-788p8   1/1     Running   0          3m44s   10.44.0.2   server02   <none>           <none>\n\tkubia-c9kn6   1/1     Running   0          3m44s   10.44.0.1   server02   <none>           <none>\n\n### 获取有关 ReplicationController 的信息\n\n\t$ kubectl get rc -o wide\n\t$ kubectl get rc -o wide -n default\t\t// RC是针对某个namespace下做的副本pod控制\n\tNAME    DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES        SELECTOR\n\tkubia   3         3         3       17m   kubia        luksa/kubia   app=kubia\n\t获取RC的详细信息\n\t$ kubectl describe rc kubia\n\n如果你更改了 一个 pod 的标签，使它不再 与 ReplicationController 的标签选择器相匹配 ， 那么该 pod 就变得和其他手动创建的 pod 一样了\n更改 pod 的标签时， ReplicationController 发现一个 pod 丢失了 ， 并启动一个新的pod替换它.\n\n给其中一个 pod 添加了 type=special 标签，再次列出所有 pod 会显示和以前一样的三个 pod 。 因为从 ReplicationCon位oiler 角度而言， 没发生任何更改.\n\n\t$ kubectl label pod/kubia-6ntgt type=special\n\t$ kubectl get pod --show-labels\n\tNAME          READY   STATUS    RESTARTS   AGE   LABELS\n\tkubia-6ntgt   1/1     Running   0          27m   app=kubia,type=special\n\tkubia-788p8   1/1     Running   0          30m   app=kubia\n\tkubia-c9kn6   1/1     Running   0          30m   app=kubia\n\n更改app标签该 pod 不再与 RC 的标签选择器相匹配\n\n\t$ kubectl label pod/kubia-6ntgt app=foo --overwrite\n\t$ kubectl get pod --show-labels\n\tNAME          READY   STATUS              RESTARTS   AGE   LABELS\n\tkubia-6ntgt   1/1     Running             0          30m   app=foo,type=special\n\tkubia-788p8   1/1     Running             0          33m   app=kubia\n\tkubia-c9kn6   1/1     Running             0          33m   app=kubia\n\tkubia-dqshz   0/1     ContainerCreating   0          4s    app=kubia\n使用 -L app 选项在列 中显示 app 标签\n\n\t$ kubectl get pod -L app\n\tNAME          READY   STATUS    RESTARTS   AGE     APP\n\tkubia-6ntgt   1/1     Running   0          32m     foo\n\tkubia-788p8   1/1     Running   0          35m     kubia\n\tkubia-c9kn6   1/1     Running   0          35m     kubia\n\tkubia-dqshz   1/1     Running   0          2m17s   kubia\n可能有一个 bug 导致你的 pod 在特定时间或特定事件后开始出问题。\n如果你知道某个 pod 发生了故障， 就可以将它从 Replication-Controller 的管理范围中移除， 让控制器将它替换为新 pod, 接着这个 pod 就任你处置了。 完成后删除该pod 即可。\n\n### 编辑RC的YAML配置\n用默认文本编辑器中打开ReplicationController的YAML配置，会在/tmp目录生成一个临时yaml文件，退出后/tmp目录下的yaml文件也会删掉\n如果你想使用nano编辑Kubernetes资源，请执行以下命令（或将其放入 ~/.bashrc或等效文件中）\nexport KUBE_EDITOR=\"/usr/bin/nano\"\n\n\t$ kubectl edit rc kubia\n\t......\n\t spec:\n\t   replicas: 3\n\t   selector:\n\t     app: kubia1\t\t\t\t RC selector 修改，需要配合下面的label一起修改\n\t   template:\n\t     metadata:\n\t       creationTimestamp: null\n\t       labels:\n\t         app: kubia1\t\t\t Pod label 修改，需要配合上面的 RC selector 一起修改\n\t     spec:\n\t       containers:\n\t       - image: luksa/kubia\n\t         imagePullPolicy: Always\n\t         name: kubia\n\t         ports:\n\t         - containerPort: 8080\n\t           protocol: TCP\n\t......\n\n\t$ kubectl get pod\n\tNAME          READY   STATUS              RESTARTS   AGE   APP\n\tkubia-279wl   0/1     ContainerCreating   0          2s    kubia1\n\tkubia-6ntgt   1/1     Running             0          44m   foo\n\tkubia-788p8   1/1     Running             0          47m   kubia\n\tkubia-c9kn6   1/1     Running             0          47m   kubia\n\tkubia-dqshz   1/1     Running             0          14m   kubia\n\tkubia-m6vml   0/1     Pending             0          2s    kubia1\n\tkubia-xxjqr   0/1     ContainerCreating   0          2s    kubia1\n\n### RC 扩容\n扩展/缩容 RC管理的pod为5个\n第一种，commands方式:\n\n\t$ kubectl scale rc kubia --replicas=5\n\n第二种， edit rc yaml文件\n\n\t$ kubectl edit rc kubia\n\t......\n\tspec:\n\t  replicas: 5\n\t......\n\n### 删除RC\n当使用 kubectl delete 删除 ReplicationController 时， 可以通过给命令增加 --cascade= false 选项来保持 pod 的运行.\n\n\t$ kubectl delete rc kubia --cascade=false\n已经删除了 ReplicationController, 所以这些 pod 独立了， 它们不再被管理。但是你始终可以使用适当的标签选择器创建新的 ReplicationController, 并再次将它们管理起来\n\n\n## ReplicaSet\n> 最 初， ReplicationController 是用于复制和在异常时重新调度节点的唯 一Kubemetes 组件， 后来又引入了 一个名为 ReplicaSet 的类似资源 。 它是新一代的ReplicationController, 并且将其完全替换掉 (ReplicationController 最终将被弃用）。\n> 也就是说从现在起， 你应该始终创建 ReplicaSet 而不是 ReplicationController。 它们几乎完全相同， 所以你不会碰到任何麻烦\n> ReplicaSet 的行为与ReplicationController 完全相同， 但pod 选择器的表达能力更强\n> ReplicationController 都无法仅基千标签名的存在来匹配 pod, 而ReplicaSet 则可以。 例如， ReplicaSet 可匹配所有包含名为 env 的标签的 pod, 无论ReplicaSet 的实际值是什么（可以理解为 env=*)\n\nkubia-replicaset.yaml\n\n\tapiVersion: apps/v1\n\tkind: ReplicaSet\n\tmetadata:\n\t  name: kubia\n\tspec:\n\t  replicas: 3\n\t  selector:\n\t    matchLabels:\n\t      app: kubia\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: kubia\n\t    spec:\n\t      containers:\n\t      - name: kubia\n\t        image: luksa/kubia\n\t        ports:\n\t        - containerPort: 8080\n检查replicaset:\n\n\t$ kubectl get rs\n\n### matchExpressions选择器\n创建个yaml文件\nkubia-replicaset-matchexpressions.yaml\n\n\t selector:\n\t   matchExpressions:\n\t     - key: app\n\t       operator: In\n\t       values:\n\t         - kubia\n每个表达式都必须 包含一个key, 一个operator (运算符），并且可能还有一个values的列表（取决于 运算符）.\n• In : Label的值 必须与其中 一个指定的values 匹配。\n• Notln : Label的值与任何指定的values 不匹配。\n• Exists : pod 必须包含一个指定名称的标签（值不重要）。使用此运算符时，\n不应指定 values字段。\n• DoesNotExist : pod不得包含有指定名称的标签。values属性不得指定\n如果同时指定matchLabels和matchExpressions, 则所有标签都必须匹配，并且所有表达式必须计算为true以使该pod与选择器匹配.\n\n### 查看 replicaset 和 deployment 的详细信息\n\n\t$ kubectl describe deployment details-v1\n\t$ kubectl describe rs details-v1-6fc55d65c9\n\n### 删除ReplicaSet\n删除ReplicaSet会删除所有的pod,这种情况下是需要列出pod来确认.\n\n\t$ kubectl delete rs kubia\n\n## DaemonSet\n如果节点下线， DaemonSet不会在其他地方重新创建pod。 但是， 当将一个新节点添加到集群中时， DaemonSet会立刻部署一个新的pod实例。\n如果有人无意中删除了 一个 pod ， 那么它也会重新创建 一个新的 pod。\n与 ReplicaSet一样，DaemonSet 从配置的 pod 模板创建 pod.\n\n> 如果节点可以被设置为不可调度的 ， 防止 pod 被部署到节点上. DaemonSet 甚至会将 pod 部署到这些节点上，因为无法调度的属性只会被调度器使用，而 DaemonSet 管理的 pod 则完全绕过调度器. 这是预期的，因为DaemonSet的目的是运行系统服务，即使是在不可调度的节点上，系统服务通常也需要运行.\n\n给node节点打上label\n\n\t$ kubectl label node server02 disk=ssd\n\nssd-monitor-daemonset.yaml\n\n\tapiVersion: apps/v1\t\t\t// DaemooSet在apps的API组 中，版本是v1\n\tkind: DaemonSet\n\tmetadata:\n\t  name: ssd-monitor\n\tspec:\n\t  selector:\n\t    matchLabels:\n\t      app: ssd-monitor\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: ssd-monitor\n\t    spec:\n\t      nodeSelector:\t\t\t// pod模板包含 会选择有disk=ssd标签的节点 一个节点选择器\n\t        disk: ssd\n\t      containers:\n\t      - name: main\n\t        image: luksa/ssd-monitor\n\n\t$ kubectl create -f ssd-monitor-daemonset.yaml\n\n### 查看DaemonSet\n\n\t$ kubectl get ds\n\tNAME          DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE     CONTAINERS   IMAGES              SELECTOR\n\tssd-monitor   1         1         1       1            1           disk=ssd        3m29s   main         luksa/ssd-monitor   app=ssd-monitor\n如果你有多个节点并且其他的节点也加上了同样的标签，将会看到 DaemonSet 在每个节点上都启动 pod.\n给其中一个节点修改标签disk=hdd, 假设它的硬盘换成磁盘而不是SSD, 那个节点上的pod会如预期中被终止.\n如果还有其他的 pod在运行， 删除 DaemonSet 也会一起删除这些 pod。\n\n### 删除ds\n删除ds会删除由ds控制schedule到每个节点的pod\n\n\t$ kubectl delete ds ssd-monitor\n\n## Job资源\nKubemetes 通过 Job 资源提供了对此的支持，它允许你运行一种 pod, 该 pod 在内部进程成功结束时， 不重启容器。\n一旦任务完成， pod 就被认为处于完成状态.\n由Job管理的pod会一直被重新安排，直到它们成功完成任务.\n\nexporter.yaml\n\n\tapiVersion: batch/v1\n\tkind: Job\n\tmetadata:\n\t  name: batch-job\n\tspec:\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: batch-job\n\t    spec:\n\t      restartPolicy: OnFailure\t\t// 默认为Always,Job pod不能使用默认策略， 因为它们不是要无限期地运行\n\t      containers:\n\t      - name: main\n\t        image: luksa/batch-job\t\t// 运行luksa/batch-job镜像，该镜像调用 一个运行120秒的进程，然后退出\n需要明确地将重启策略 restartPolicy 设置为 OnFailure 或 Never。 此设置防止容器在完成任务时重新启动\n\n\t$ kubectl create -f exporter.yaml\n\n\t$ kubectl get pod\n\tNAME                READY   STATUS    RESTARTS   AGE\n\tbatch-job-lhnfg     1/1     Running   0          113s\n\t\n\t$ kubectl get jobs\n\tNAME        COMPLETIONS   DURATION   AGE\n\tbatch-job   0/1           111s       111s\n\n等待两三分钟后\n\n\t$ kubectl get pod\n\tNAME                READY   STATUS      RESTARTS   AGE\n\tbatch-job-lhnfg     0/1     Completed   0          3m21s\n\n\t$ kubectl get job\n\tNAME        COMPLETIONS   DURATION   AGE\n\tbatch-job   1/1           2m41s      3m27s\n完成后pod未被删除的原因是允许你查阅其日志\n\n\t$ kubectl logs po/batch-job-lhnfg\n\tThu May 14 05:04:38 UTC 2020 Batch job starting\n\tThu May 14 05:06:38 UTC 2020 Finished succesfully\npod 可以被直接删除， 或者在删除创建它的Job时被删除\n作业可以配置为创建多个pod实例，并以并行或串行方式运行它们\n在Job配置中设置 completions和parallelism属性来完成的\n如果你需要 一个Job运行多次，则可以将comple巨ons设为你希望作业的pod运行多少次\n\n\tapiVersion: batch/v1\n\tkind: Job\n\tmetadata:\n\t  name: multi-completion-batch-job\n\tspec:\n\t  completions: 5\t// job将一个接一个地运行五个pod\n\t  parallelism: 2\t// 最多两个pod可以并行运行\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: batch-job\n\t    spec:\n\t      restartPolicy: OnFailure\n\t      containers:\n\t      - name: main\n\t        image: luksa/batch-job\n它最初创建一个pod, 当pod的容器运行完成时，它创建第二个pod, 以此类推，直到五个pod成功完成。\n如果其中 一个pod发生故障，工作会创建一个新的pod, 所以Job总共可以创建五个以上的pod.\n\n\t$ kubectl create -f multi-completion-batch-job.yaml\n\tNAME                               READY   STATUS              RESTARTS   AGE\n\tmulti-completion-batch-job-8kzd5   0/1     ContainerCreating   0          4s\n\tmulti-completion-batch-job-9rnxs   0/1     ContainerCreating   0          4s\n只要其中 一个pod完成任务，工作将运行下 一个pod, 直到五个pod都成功完成任务.\n\n\tkubectl get po\n\tNAME                               READY   STATUS    RESTARTS   AGE\n\tmulti-completion-batch-job-8kzd5   1/1     Running   0          2m8s\n\tmulti-completion-batch-job-9rnxs   1/1     Running   0          2m8s\n\t\n\t$ kubectl get job\n\tNAME                         COMPLETIONS   DURATION   AGE\n\tmulti-completion-batch-job   0/5           2m13s      2m13s\nPOD虽然创建，但是POD里的进程任务还没有完成，因此job显示任然是0/5没有一个pod任务完成\n再等待一会时间\n\n\t$ kubectl get po\n\tNAME                               READY   STATUS      RESTARTS   AGE\n\tmulti-completion-batch-job-8kzd5   0/1     Completed   0          4m18s\n\tmulti-completion-batch-job-9rnxs   0/1     Completed   0          4m18s\n\tmulti-completion-batch-job-blntb   1/1     Running     0          107s\n\tmulti-completion-batch-job-qhsr5   1/1     Running     0          92s\n\tssd-monitor-jbhpd                  1/1     Running     0          176m\n\n\t$ kubectl get job\n\tNAME                         COMPLETIONS   DURATION   AGE\n\tmulti-completion-batch-job   2/5           4m16s      4m16s\n如上显示已经有2个POD任务完成，POD退出.\n甚至可以在 Job 运行时更改 Job 的 parallelism 属性, command如下，实验环境没有成功使用\n\n\t$ kubectl scale job multi-completion-batch-job --replicas 3\n\n> 通过在 pod 配置中设置 activeDeadlineSeconds 属性，可以限制 pod的时间。如果 pod 运行时间超过此时间， 系统将尝试终止 pod, 并将 Job 标记为失败。\n> 通过指定 Job manifest 中的 spec.backoff巨m辽字段， 可以配置 Job在被标记为失败之前可以重试的次数。 如果你没有明确指定它， 则默认为6\n\n### 删除job\n删除job时，由job创建的pod也被直接删除\n\n\t $ kubectl delete job multi-completion-batch-job\n\n## CornJob 资源\n> 批处理任务需要在特定的时间运行，或者在指定的时间间隔内重复运行,在 Linux 和类 UNIX 操作系统中， 这些任务通常被称为 cron 任务。 Kubemetes 也支持这种任务\n> Kubemetes 中的 cron 任务通过创建 CronJob 资源进行配置, 运行任务的时间表以知名的 cron 格式指定\n时间表从左到右包含以下五个条目\n• 分钟\n• 小时\n• 每月中的第几天\n• 月\n• 星期几\n\n创建资源文件(kube API 对象文件)cronjob.yaml\n\n\tapiVersion: batch/v1beta1\n\tkind: CronJob\n\tmetadata:\n\t  name: batch-job-every-fifteen-minutes\n\tspec:\n\t  schedule: \"0,15,30,55 * * * *\"\n\t  startingDeadlineSeconds: 15\t// pod最迟必须在预定时间后15秒开始运行， 如果因为任何原因到该启动时间15s后仍不启动，任务将不会运行，并将显示为Failed\n\t  jobTemplate:\n\t    spec:\n\t      template:\n\t        metadata:\n\t          labels:\n\t            app: periodic-batch-job\n\t        spec:\n\t          restartPolicy: OnFailure\n\t          containers:\n\t          - name: main\n\t            image: luksa/batch-job\n\n> 希望每 15 分钟运行一 次任务因此 schedule 字段的值应该是\"0, 15, 30, 45****\" 这意味着每小时的 0 、 15 、 30和 45 分钟（第一个星号），每月的每一天（第二个星号），每月（第三个星号）和每周的每一天（第四个星号）。\n> 相反，如果你希望每隔 30 分钟运行一 次，但仅在每月的第一天运行，则应将计划设置为 \"0,30 * 1 * *\", 并且如果你希望它每个星期天的 3AM 运行，将它设置为 \"0 3 * * 0\" (最后一个零代表星期天）。\n\n### 查看cronjob\n\t$ kubectl get cronjob -o wide\n\tNAME                              SCHEDULE             SUSPEND   ACTIVE   LAST SCHEDULE   AGE    CONTAINERS   IMAGES            SELECTOR\n\tbatch-job-every-fifteen-minutes   0,15,30,55 * * * *   False     0        18m             112m   main         luksa/batch-job   <none>\n\n### cronjob运行状态\n\t$ kubectl get po\n\tNAME                                               READY   STATUS      RESTARTS   AGE\n\tbatch-job-every-fifteen-minutes-1589439300-4v8wd   0/1     Completed   0          36m\n\tbatch-job-every-fifteen-minutes-1589439600-99pns   0/1     Completed   0          31m\n\tbatch-job-every-fifteen-minutes-1589440500-vs5vm   0/1     Completed   0          16m\n\tbatch-job-every-fifteen-minutes-1589441400-52rzb   1/1     Running     0          112s\n\n\t$ kubectl get job\n\tNAME                                         COMPLETIONS   DURATION   AGE\n\tbatch-job-every-fifteen-minutes-1589439300   1/1           2m24s      36m\n\tbatch-job-every-fifteen-minutes-1589439600   1/1           2m24s      31m\n\tbatch-job-every-fifteen-minutes-1589440500   1/1           2m22s      16m\n\tbatch-job-every-fifteen-minutes-1589441400   0/1           116s       116s\n\n再过一点时间查看\n\n\t$ kubectl get po\n\tNAME                                               READY   STATUS      RESTARTS   AGE\n\tbatch-job-every-fifteen-minutes-1589439600-99pns   0/1     Completed   0          32m\n\tbatch-job-every-fifteen-minutes-1589440500-vs5vm   0/1     Completed   0          17m\n\tbatch-job-every-fifteen-minutes-1589441400-52rzb   0/1     Completed   0          2m34s\n\n\t$ kubectl get job\n\tNAME                                         COMPLETIONS   DURATION   AGE\n\tbatch-job-every-fifteen-minutes-1589439600   1/1           2m24s      32m\n\tbatch-job-every-fifteen-minutes-1589440500   1/1           2m22s      17m\n\tbatch-job-every-fifteen-minutes-1589441400   1/1           2m20s      2m37s\n\n总结: CornJob过指定的时间执行一次POD，执行完退出，会保留三个POD和Job记录.\n\n### 删除cronjob\n运行中的 Job 将不会被终止，不会删除 Job 或 它们的 Pod。为了清理那些 Job 和 Pod，需要列出该 Cron Job 创建的Job，然后删除它们.\n\n\t$ batch-job-every-fifteen-minutes\n\tcronjob.batch \"batch-job-every-fifteen-minutes\" deleted\n\n## secret\n\n\t$ kubectl get secret -n default\n\tNAME                  TYPE                                  DATA   AGE\n\tdefault-token-gtcjx   kubernetes.io/service-account-token   3      32d\n\n\t$ kubectl get pods -o wide\n\tNAME                               READY   STATUS    RESTARTS   AGE     IP           NODE         NOMINATED NODE   READINESS GATES\n\twordpress-7bfc545758-vtfvm         1/1     Running   5          10d     10.36.0.10   hci-node04   <none>           <none>\n\twordpress-mysql-764fc64f97-sjnjk   1/1     Running   0          10d     10.36.0.8    hci-node04   <none>           <none>\n\n\t$ kubectl get po/wordpress-7bfc545758-vtfvm -o yaml\n\t......\n\tspec:\n\t  containers:\n\t  - env:\n\t    volumeMounts:\n\t    - mountPath: /var/www/html\n\t      name: wordpress-persistent-storage\n\t    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\n\t      name: default-token-gtcjx\n\t      readOnly: true\n\t......\n\t  volumes:\n\t  - name: wordpress-persistent-storage\n\t    persistentVolumeClaim:\n\t      claimName: wp-pv-claim\n\t  - name: default-token-gtcjx\n\t    secret:\n\t      defaultMode: 420\t\t// 访问权限\n\t      secretName: default-token-gtcjx\n\t......\n进入wordpress-7bfc545758-vtfvm所在机器的容器里查看/var/run/secrets/kubernetes.io/serviceaccount路径文件\n\n\t$ docker exec -it daec0458a397 /bin/sh\n\t# ls /var/run/secrets/kubernetes.io/serviceaccount\n\t  ca.crt  namespace  token\n\n### 创建自己的Secret\nserviceAccount 用来跟Apiserver通信，用来授权, 可以创建自己的Secret\n编写Secret配置文件 secret.yaml\n\n\tapiVersion: v1\n\tkind: Secret\n\tmetadata:\n\t  name: dbpass\n\ttype: Opaque\t\t// 不透明，浑浊的.\n\tdata:\n\t  username: aW1vb2M=\t\t// base64加密的用户名\n\t  passwd: aW1vb2MxMjM=\t\t// base64加密的密码\n把字符串生成base64很简单，命令如下\n\n\t$ echo -n imooc | base64\t// -n 表示换行\n\taW1vb2M=\n编写Pod资源配置文件 pod-secret.yaml\n\n\tapiVersion: v1\n\tkind: Pod\n\tmetadata:\n\t  name: pod-secret\n\tspec:\n\t  containers:\n\t  - name: springbook-web\n\t    image: hub.mooc.com/kubernetes/springboot-web:v1\n\t    ports:\n\t    - containerPort: 8080\n\t    volumeMounts:\n\t    - name: db-secret\n\t      mountPath: /db-secret\n\t      readOnly: true\n\t  volumes:\n\t  - name: db-secret\n\t    projected:\n\t      sources:\t\t\t// secret 来源\n\t      - secret:\n\t        name: dbpass\t// secret 名字\n生成Pod并进入查看\n\n\t$ / # cd /db-secret/\n\t$ ls\n\t  passwd username\n\t$ cat -n username\t\t// 查看容器里存放的是base64解码过的数据\n\t  immoc\n\t$ cat -n passwd\n\t  imooc123\n\n可以通过修改secret.yaml文件修改secret账号密码等再$ kubectl apply -f secret.yaml来更改密码.\n\n## Configmap\n> configmap常用来存储不需要加密的数据, 比如应用的启动参数，一些参数的配置等\n * 第一种向k8s添加很多key value的键值对属性值，就可以用configmap\n\n\n\t$ touch game.properties\n\t$ vim game.properties\n\t  enemies=aliens\n\t  lives=3\n\t  enemies.cheat=true\n\t  secret.code.allowed=true\n\t  ......\n配置到K8S里\n\n\t$ kubectl create configmap web-game --from-file game.properties\n\t$ kubectl get cm\n\n使用configmap, Pod-game.yaml\n\n\tapiVersion: v1\n\tkind: Pod\n\tmetadata:\n\t  name: pod-game\n\tspec:\n\t  containers:\n\t  - name: web\n\t    image: hub.mooc.com/kubernetes/springboot-web:v1\n\t    ports:\n\t    - containerPort: 8080\n\t    volumeMounts:\n\t    - name: game\n\t      mountPath: /etc/config/game\n\t      readOnly: true\n\t  volumes:\n\t  - name: game\n\t    configMap:\n\t      name: web-game\n生成Pod并进入查看\n\n\t$ cd /etc/config/game\n\t$ ls\n\t  game.properties\n\t$ cat game.properties\n\t  enemies=aliens\n\t  lives=3\n\t  enemies.cheat=true\n\t  secret.code.allowed=true\n\t  ......\n\n可以通过kubectl edit 修改configMap账号密码等\n\n\t$ kubectl edit cm web-game -o yaml\n\t  enemies.cheat=false\t//等等操作\n\n * 第二种配置文件方式创建configMap\nconfigmap.yaml\n\n\n\tapeVersion: v1\n\tkind: Configmap\n\tmetadata:\n\t  name: configs\n\tdata:\n\t  Java_OPTS: -Xms1024m\n\t  LOG_LEVEL: DEBUG\n\n\t$ kubectl create -f configmap.yaml\n编写资源配置文件pod-env.yaml\n\n\tapiVersion: v1\n\tkind: Pod\n\tmetadata:\n\t  name: pod-env\n\tspec:\n\t  containers:\n\t  - name: web\n\t    image: hub.mooc.com/kubernetes/springboot-web:v1\n\t    ports:\n\t    - containerPort: 8080\n\t    env:\n\t      - name: LOG_LEVEL_CONFIG\n\t        valueFrom:\n\t          configMapKeyRef:\n\t            name: configs\t\t// 指定configMap名字\n\t            key: LOG_LEVEL\t\t// configs下面的LOG_LEVEL\n进入容器查看环境变量\n\n\t$ env | grep LOG\n\t  LOG_LEVEL_CONFIG=DEBUG\n之后次容器就可以通过环境变量获取值\n\n * 第三种 通过命令行方式传进参数\n也是先跟第二种一样创建configMap资源\n\n\n\t$ kubectl create -f configmap.yaml\n编写资源配置文件pod-cmd.yaml\n\n\tapiVersion: v1\n\tkind: Pod\n\tmetadata:\n\t  name: pod-cmd\n\tspec:\n\t  containers:\n\t  - name: web\n\t    image: hub.mooc.com/kubernetes/springboot-web:v1\n\t    command: [\"/bin/sh\", \"-c\", \"java -jar /springboot-web.jar -DJAVA_OPTS=$(JAVA_OPTS)\"]\n\t    ports:\n\t    - containerPort: 8080\n\t    env:\n\t      - name: Java_OPTS\n\t        valueFrom:\n\t          configMapKeyRef:\n\t            name: configs\t\t// 指定configMap名字\n\t            key: Java_OPTS\t\t// configs下面的LOG_LEVEL\n进入容器查看进程\n\n\t$ ps -ef\n\t  java -jar /springboot-web.jar -DJAVA_OPTS=-Xms1024m\n\n## downwardAPI\ndownwardAPI主要作用是在程序中取得Pod对象本身的一些相关信息\npod-downwardapi.yaml\n\n\tapiVersion: v1\n\tkind: Pod\n\tmetadata:\n\t  name: pod-downwardapi\n\t  labels:\n\t    app： downwardapi\n\t    type: webapp\n\tspec:\n\t  containers:\n\t  - name: web\n\t    image: hub.mooc.com/kubernetes/springboot-web:v1\n\t    ports:\n\t    - containerPort: 8080\n\t    volumeMounts:\n\t      - name: podinfo\n\t        mountPath: /etc/podinfo\n\t  volumes:\n\t    - name: podinfo\n\t      projected:\n\t        sources:\n\t        - downwardAPI:\n\t          items:\n\t            - path: \"labels\"\n\t              fieldRef:\n\t                fieldPath: metadata.labels\n\t            - path: \"name\"\n\t              fieldRef:\n\t                fieldPath: metadata.name\n\t            - path: \"namespace\"\n\t              fieldRef:\n\t                fieldPath: metadata.namespace\n\t            - path: \"mem-request\"\n\t              resourceFieldRef:\n\t                containerName: web\n\t                resource: limits.memory\n进入容器查看文件信息\n\n\t$ cd /etc/podinfo\n\t$ ls -l\n\t  labels mem-request name namespace\n\t$ cat -n labels\n\t  app=\"downwardapi\"\n\t  type=\"webapp\"\n\t$ cat -n namespace\n\t  default\n\t$ cat -n name\n\t  pod-downwardapi\n\n\n\n\n\n\n\n\n\n\n","slug":"micro_service/03_kubernetes_ns_pod","published":1,"date":"2020-08-12T16:05:47.352Z","updated":"2020-08-10T16:36:21.398Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmg50049hohx4arxfxcb","content":"<h2 id=\"nodes\"><a href=\"#nodes\" class=\"headerlink\" title=\"nodes\"></a>nodes</h2><pre><code>$ kubectl get nodes -o wide\nNAME         STATUS   ROLES    AGE   VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION           CONTAINER-RUNTIME\nhci-node01   Ready    master   5d    v1.18.1   10.67.108.211   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1062.el7.x86_64   docker://19.3.8\nhci-node02   Ready    &lt;none&gt;   5d    v1.18.1   10.67.109.142   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1062.el7.x86_64   docker://19.3.8\nhci-node03   Ready    &lt;none&gt;   5d    v1.18.1   10.67.109.147   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1062.el7.x86_64   docker://19.3.8\nhci-node04   Ready    &lt;none&gt;   5d    v1.18.1   10.67.109.144   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1062.el7.x86_64   docker://19.3.8\n$ kubectl describe node hci-node02\n输出显示了节点的状态、 CPU 和内存数据、系统信息、运行容器的节点等\n\n查看某台机器的资源\n$ kubectl describe node hci-node01</code></pre><h3 id=\"创建别名和补全\"><a href=\"#创建别名和补全\" class=\"headerlink\" title=\"创建别名和补全\"></a>创建别名和补全</h3><p>kubectl 会被经常使用。很快你就会发现每次不得不打全命令是非常痛苦的。<br>将下面的代码添加到 ~/.bashrc 或类似的文件中 ：</p>\n<pre><code>alias k=kubectl</code></pre><p>为kuebctl配置 tab 补全<br>需要先安装一个叫作 bashcompletio口的包来启用 bash 中的 tab 命令补全， 然后可以运行接下来的命令（也需要加到 ~/.bashrc 或类似的文件中）</p>\n<pre><code>$ source &lt;{kubectl completion bash)\n$ kubectl desc&lt;TAB&gt; nod&lt;TAB&gt; hci&lt;TAB&gt;</code></pre><p>但是需要注意的是， tab 命令行补全只在使用完整的 kubectl 命令时会起作用,(当使用别名 k 时不会起作用). 需要改变 kubectl completion 的输出来修复：</p>\n<pre><code>$ source &lt;(kubectl completion bash | sed s/kubectl/k/g)</code></pre><h3 id=\"node-标签\"><a href=\"#node-标签\" class=\"headerlink\" title=\"node 标签\"></a>node 标签</h3><pre><code>$ kubectl get nodes\n$ kubectl label node server02 gpu=false\n$ kubectl label node server02 gpu=true --overwrite    //修改node标签\n$ kubectl get node -L gpu        // 列出所有node，并添加GPU一列进行展示\n$ kubectl get node -l gpu        // 只列出含标签的key为gpu的node\n$ kubectl get node -l gpu=false    // 只列出含gpu=false的node</code></pre><p>将POD调度到指定的node上: kubia-gpu.yaml</p>\n<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\nname: kubia-gpu        // 指定生成的POD名字\nspec:\nnodeSelector:        // node选择器,选择含标签gpu=true的node机器\n    gpu: &quot;true&quot;        \ncontainers:\n- image: luksa/kubia    // 要拉取的 image 名字\n    name: kubia            // 生成的 container 名字\n\n$ kubectl create -f kubia-gpu.yaml</code></pre><p>如果没有标签为gpu=true的合适node， 通过 $ kubectl describe pod/kubia-nogpu 查看Message， 会报 0/2 nodes are available: 2 node(s) didn’t match node selector.信息</p>\n<pre><code>$ kubectl describe pod/kubia-gpu\n......\nNode-Selectors:  gpu=true\n......</code></pre><h3 id=\"taint污点\"><a href=\"#taint污点\" class=\"headerlink\" title=\"taint污点\"></a>taint污点</h3><p>给Node添加污点可以让配置tolerations的Pod部署上来，而不让平常的Pod部署.<br>配置tolerations的Pod可以部署到添加污点的机器也可以部署到其它平常机器</p>\n<pre><code>$ kubectl taint nodes NodeName gpu=true:NoSchedule\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-demo\n  namespace: dev\nspec:\n  selector:\n    matchLabels:\n      app: web-demo\n  replicas: 3            // 副本数3来测试能部署到哪些机器\n  template:\n    metadata:\n      labels:\n        app: web-demo\n    spec:\n      selector:\n        matchLabels:\n          app: web-demo\n      replicas: 1\n      template:\n        metadata:\n          labels:\n            app: web-demo\n        spec:\n          containers:\n          - name: web-demo\n            image: hub.mooc.com/kubernetes/web:v1\n            ports:\n            - containerPort: 8080\n          tolerations:        // 可以部署到有设置taint的机器，也可以部署到其它机器\n          - key: &quot;gpu&quot;\n            operator: &quot;Equal&quot;\n            value: &quot;true&quot;\n            effect: &quot;NoSchedule&quot;</code></pre><blockquote>\n<p>典型的使用kubeadm部署和初始化的Kubernetes集群，master节点被设置了一个node-role.kubernetes.io/master:NoSchedule的污点，可以使用kubectl describe node <node-name>命令查看<br>这个污点表示默认情况下master节点将不会调度运行Pod，即不运行工作负载, 对于使用二进制手动部署的集群设置和移除这个污点的命令如下:</p>\n</blockquote>\n<pre><code>$ kubectl taint nodes &lt;node-name&gt; node-role.kubernetes.io/master=:NoSchedule\n$ kubectl taint nodes &lt;node-name&gt; node-role.kubernetes.io/master:NoSchedule-</code></pre><blockquote>\n<p>kubeadm初始化的Kubernetes集群，master节点也被打上了一个node-role.kubernetes.io/master=的label，标识这个节点的角色为master。给Node设置Label和设置污点是两个不同的操作。设置Label和移除Label的操作命令如下</p>\n</blockquote>\n<p>设置Label</p>\n<pre><code>$ kubectl label node node1 node-role.kubernetes.io/master=</code></pre><p>移除Label</p>\n<pre><code>$ kubectl label node node1 node-role.kubernetes.io/master-</code></pre><h2 id=\"Namespace\"><a href=\"#Namespace\" class=\"headerlink\" title=\"Namespace\"></a>Namespace</h2><blockquote>\n<p>大多数对象的名称必须符合 RFC 1035 （域名）中规定的命名规范 ，这意味着它们可能只包含字母、数字、横杠（－）和点号，但命名空间（和另外几个）不允许包含点号</p>\n</blockquote>\n<h3 id=\"隔离性\"><a href=\"#隔离性\" class=\"headerlink\" title=\"隔离性\"></a>隔离性</h3><blockquote>\n<p>名字的隔离只是 通过svc名称(DNS) 访问的隔离，通过svc的IP和Pod的IP再加上端口号(Port) 照样可以访问不同命名空间下的服务.</p>\n</blockquote>\n<h3 id=\"设置默认命名空间\"><a href=\"#设置默认命名空间\" class=\"headerlink\" title=\"设置默认命名空间\"></a>设置默认命名空间</h3><blockquote>\n<p>默认Kubeclt获取default命名空间下的资源，可以通过设置K8s上下文配置文件如kube.config 使得某个命名空间变为默认namespace，获取pod时候不需要在加上 -n 参数</p>\n</blockquote>\n<h3 id=\"创建命名空间\"><a href=\"#创建命名空间\" class=\"headerlink\" title=\"创建命名空间\"></a>创建命名空间</h3><blockquote>\n<p>namespace不提供网络隔离, 如果命名空间 foo 中的某个 pod 知道命名空间 bar 中 pod 的 IP 地址，那它就可以将流量（例如 HTTP 请求）发送到另一个 pod<br>第一种： commands方式</p>\n</blockquote>\n<pre><code>$ kubectl create namespace custom-namespace\n$ kubectl create ns custom-namespace</code></pre><p>第二种： Yaml方式， 之所以选择使用 YAML 文件，只是为了强化Kubemetes中的所有内容都是一 个 API 对象这一概念</p>\n<pre><code>$ touch custom-namespace.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: custom-namespace\n$ kubectl create -f custom-namespace.yaml</code></pre><h3 id=\"划分方式\"><a href=\"#划分方式\" class=\"headerlink\" title=\"划分方式\"></a>划分方式</h3><pre><code>* 按环境划分: dev(开发), test(测试)\n* 按团队划分\n* 自定义多级划分</code></pre><h3 id=\"标记命名空间\"><a href=\"#标记命名空间\" class=\"headerlink\" title=\"标记命名空间\"></a>标记命名空间</h3><pre><code>$ kubectl label namespace default istio-injection=enabled --overwrite         // enabled\n$ kubectl label namespace default istio-injection=disabled --overwrite        // disabled\n$ kubectl label namespace default istio-injection= --overwrite                // cancel set\nnamespace/default labeled</code></pre><h3 id=\"查看标记-istio-injection-enabled-标签的命名空间\"><a href=\"#查看标记-istio-injection-enabled-标签的命名空间\" class=\"headerlink\" title=\"查看标记 istio-injection=enabled 标签的命名空间\"></a>查看标记 istio-injection=enabled 标签的命名空间</h3><pre><code>$ kubectl get namespace -L istio-injection\nNAME              STATUS   AGE   ISTIO-INJECTION\ndefault           Active   85m   enabled\nistio-system      Active   25m   disabled\nkube-node-lease   Active   85m\nkube-public       Active   85m\nkube-system       Active   85m\n[root@hci-node01 istio-1.5.2]#</code></pre><h3 id=\"删除namespace\"><a href=\"#删除namespace\" class=\"headerlink\" title=\"删除namespace\"></a>删除namespace</h3><p>删除当前命名空间中的所有资源，可以删除ReplicationCcontroller和pod,以及我们创建的所有service<br>第一个 all 指定正在删除所有资源类型, –all 选项指定将删除所有资源实例, 而不是按名称指定它们<br>使用 all 关键字删除所有内容并不是真的完全删除所有内容。 一些资源比如Secret会被保留下来， 并且需要被明确指定删除</p>\n<pre><code>$ kubectl delete all --all        // 命令也会删除名为 kubernetes 的Service, 但它应该会在几分钟后自动重新创建</code></pre><p>可以简单地删除整个命名空间（ pod 将会伴随命名空间 自动删除〉</p>\n<pre><code>$ kubectl delete ns custom-namespace</code></pre><p>强制删除NAMESPACE</p>\n<pre><code>$ kubectl delete namespace NAMESPACENAME --force --grace-period=0</code></pre><p>进入kube-system下得etcd pod 删除需要删除的NAMESPACE</p>\n<pre><code>$ kubectl get po -n kube-system\nNAME                                 READY   STATUS    RESTARTS   AGE\netcd-hci-node01                      1/1     Running   5          16d\n......\n\n$ kubectl exec -it etcd-hci-node01 sh -n kube-system\n$ etcdctl del /registry/namespaces/NAMESPACENAME</code></pre><h2 id=\"POD\"><a href=\"#POD\" class=\"headerlink\" title=\"POD\"></a>POD</h2><h3 id=\"查看pod解释\"><a href=\"#查看pod解释\" class=\"headerlink\" title=\"查看pod解释\"></a>查看pod解释</h3><pre><code>$ kubectl explain pod\nKIND:     Pod\nVERSION:  v1\n\nDESCRIPTION:\n    Pod is a collection of containers that can run on a host. This resource is\n    created by clients and scheduled onto hosts.\n\nFIELDS:\napiVersion   &lt;string&gt;\n    APIVersion defines the versioned schema of this representation of an\n    object. Servers should convert recognized schemas to the latest internal\n    value, and may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\nkind &lt;string&gt;\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\nmetadata     &lt;Object&gt;\n    Standard object&apos;s metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\nspec &lt;Object&gt;\n    Specification of the desired behavior of the pod. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status\n\nstatus       &lt;Object&gt;\n    Most recently observed status of the pod. This data may not be up to date.\n    Populated by the system. Read-only. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status</code></pre><p>深入理解POD属性</p>\n<pre><code>$ kubectl explain pod.apiVersion\n$ kubectl explain pod.kind\n$ kubectl explain pod.spec</code></pre><p>pods 的缩写是 po, service 的缩写是 SVC, replicationcontroller 的缩写 rc</p>\n<pre><code>$ kubectl get pods -n kube-system</code></pre><blockquote>\n<p>我们提到过每个 pod 都有自己的 IP 地址，但是这个地址是集群 内部的，不能从集群外部访问。<br>要让 pod 能够从外部访问 ， 需要通过服务对象公开它， 要创建一个特殊的 LoadBalancer 类型的服务。<br>因为如果你创建一个常规服务（ 一个 Cluster IP 服务）， 比如 pod ，它也 只能从集群内部访问。<br>通过创建 LoadBalanc er 类型 的服务，将创建一个外部的负载均衡 ，可以通过 负载均衡的公共 IP 访问 pod </p>\n</blockquote>\n<h3 id=\"创建POD\"><a href=\"#创建POD\" class=\"headerlink\" title=\"创建POD\"></a>创建POD</h3><p>通过上传 JSON 或 YAML 描述文件到 Kubemetes API 服务器来创建 pod.<br>kubectl create -f 命令用于从YAML或JSON文件创建任何资源（不只是 pod).<br>    $ kubectl create -f kubia-manual.yaml<br>    $ kubectl create -f kubia-gpu.yaml -n custom-namespace    //船舰pod到custom-namespace命名空间下</p>\n<pre><code>$ kubectl describe pod/kubia\n......\nEvents:\nType    Reason     Age    From               Message\n----    ------     ----   ----               -------\nNormal  Scheduled  5m12s  default-scheduler  Successfully assigned default/kubia-liveness to server02\nNormal  Pulling    5m8s   kubelet, server02  Pulling image &quot;luksa/kubia-unhealthy&quot;</code></pre><h3 id=\"pod标签labels\"><a href=\"#pod标签labels\" class=\"headerlink\" title=\"pod标签labels\"></a>pod标签labels</h3><pre><code>$ kubectl get po --show-labels</code></pre><p>查看pod标签的key值为creation_method 和 env 的信息</p>\n<pre><code>$ kubectl get po -L creation_method,env\nNAME                           READY   STATUS    RESTARTS   AGE   CREATION_METHOD   ENV\nkubia                          1/1     Running   0          16h\nkubia-manual-v2                1/1     Running   0          34m   manual            pod</code></pre><p>POD添加标签</p>\n<pre><code>$ kubectl label po kubia  creation_method=manual\nNAME                           READY   STATUS    RESTARTS   AGE   CREATION_METHOD   ENV\nkubia                          1/1     Running   0          16h   manual\nkubia-manual-v2                1/1     Running   0          43m   manual            pod</code></pre><p>更改现有标签, 在更改现有标签时， 需要使用–overwrite选项</p>\n<pre><code>$ kubectl label po kubia-manual-v2 env=debug --overwrite</code></pre><p>使用标签列出POD</p>\n<pre><code>$ kubectl get po -1 creation_method=manual\n$ kubectl get po -l env</code></pre><p>同样列出没有env标签的pod<br>确保使用单引号来圈引 !env, 这样bash shell才不会解释感叹号（译者注：感叹号在bash中有特殊含义， 表示事件指示器)</p>\n<pre><code>$ kubectl get po -l &apos;!env&apos;\ncreation_method!=manual 选择带有creation_method标签， 并且值不等于manual的pod\nenv in (prod, devel)选择带有env标签且值为prod或devel的pod\nenv notin (prod, devel)选择带有env标签， 但其 值不是prod或devel的pod\napp=pc,rel=beta 选择pc微服务的beta版本pod</code></pre><h2 id=\"pod-注解\"><a href=\"#pod-注解\" class=\"headerlink\" title=\"pod 注解\"></a>pod 注解</h2><pre><code>$ kubectl annotate pod kubia-gpu mycompany.com/someannotion=&quot;foo bar&quot;\n$ kubectl describe pod/kubia-gpu\n......\nAnnotations:  mycompany.com/someannotion: foo bar\n......</code></pre><h3 id=\"查看该-pod-的完整描述文件：\"><a href=\"#查看该-pod-的完整描述文件：\" class=\"headerlink\" title=\"查看该 pod 的完整描述文件：\"></a>查看该 pod 的完整描述文件：</h3><pre><code>$ kubectl get po kubia-manual -o yaml    // 获取yaml格式信息\n$ kubect1 get po kubia-manual -o json    // 获取json格式信息</code></pre><h3 id=\"执行pod容器\"><a href=\"#执行pod容器\" class=\"headerlink\" title=\"执行pod容器\"></a>执行pod容器</h3><p>直接执行:</p>\n<pre><code>$ kubectl exec fortioclient-f8d65c6bb-5k4td -c captured date -n twopods</code></pre><p>进入容器执行, 当pod中只有一个容器时可以不加-c参数指定某个容器</p>\n<pre><code>$ kubectl exec fortioclient-f8d65c6bb-5k4td -c captured -i -t /bin/sh -n twopods</code></pre><h3 id=\"容器进程-网络等\"><a href=\"#容器进程-网络等\" class=\"headerlink\" title=\"容器进程, 网络等\"></a>容器进程, 网络等</h3><p>查看进程command完整信息</p>\n<pre><code>$ ps auxwww\n$ pa -ef</code></pre><p>查看网络</p>\n<pre><code>$ netstat -ntlp</code></pre><h3 id=\"查看Pod-svc日志\"><a href=\"#查看Pod-svc日志\" class=\"headerlink\" title=\"查看Pod, svc日志\"></a>查看Pod, svc日志</h3><pre><code>$ kubectl logs pod/istiod-774777b79-ddfk4 -n istio-system\n$ kubectl logs -f pod/&lt;pod_name&gt; #类似tail -f的方式查看(tail -f 实时查看日志文件 tail -f 日志文件log)\n$ kubectl logs svc/istiod -n istio-system\n如果该pod中有其他容器， 可以通过如下命令获取其日志：\n$ kubectl logs kubia-manual -c kubia</code></pre><p>查看容器重启后前一个容器为什么重启的日志信息<br>    $ kubectl logs mypod –previous</p>\n<h3 id=\"部署应用程序\"><a href=\"#部署应用程序\" class=\"headerlink\" title=\"部署应用程序\"></a>部署应用程序</h3><pre><code>$ kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml</code></pre><h3 id=\"重启Pod\"><a href=\"#重启Pod\" class=\"headerlink\" title=\"重启Pod\"></a>重启Pod</h3><pre><code>$ kubectl get pod {podname} -n {namespace} -o yaml | kubectl replace --force -f -</code></pre><h3 id=\"删除Pod\"><a href=\"#删除Pod\" class=\"headerlink\" title=\"删除Pod\"></a>删除Pod</h3><pre><code>$ kubectl delete pod PODNAME -n custom-namespace        // 删除指定命名空间下的POD\n$ kubectl delete po -l creation_method=manual            // 通过标签选择器来删除\n$ kubectl delete po --all -n custom-namespace            // 删除当前命名空间中的所有 pod\n$ kubectl delete all --all -n custom-namespace            // 删除所有pod和svc，系统带的kubernetes服务会过一会重启</code></pre><p>可使用kubectl中的强制删除命令删除POD</p>\n<pre><code>$ kubectl delete pod PODNAME --force --grace-period=0</code></pre><p>直接从ETCD中删除源数据<br>删除default namespace下的pod名为pod-to-be-deleted-0</p>\n<pre><code>$ ETCDCTL_API=3 etcdctl del /registry/pods/default/pod-to-be-deleted-0</code></pre><h2 id=\"livenessProbe-存活探针-readinessProbe\"><a href=\"#livenessProbe-存活探针-readinessProbe\" class=\"headerlink\" title=\"livenessProbe 存活探针, readinessProbe\"></a>livenessProbe 存活探针, readinessProbe</h2><p>Kubemetes 可以通过存活探针 (liveness probe) 检查容器是否还在运行.<br>Kubemetes 可以通过readinessProbe探针 检查容器是否准备完毕可以挂到负载均衡上供外部访问.<br>livenessProbe与readinessProbe探针用法完全一样, 都有三种，下面介绍这三种健康检查方式.</p>\n<p>可以为 pod 中的每个容器单独指定存活探针。 如果探测失败， Kubemetes 将定期执行探针并重新启动容器</p>\n<ul>\n<li>第一种健康检查方式: 执行命令检查存活探针是否存活</li>\n</ul>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-demo\n  namespace: dev\nspec:\n  selector:\n    matchLabels:\n      app: web-demo\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: web-demo\n    spec:\n      selector:\n        matchLabels:\n          app: web-demo\n      replicas: 1\n      template:\n        metadata:\n          labels:\n            app: web-demo\n        spec:\n          containers:\n          - name: web-demo\n            image: hub.mooc.com/kubernetes/web:v1\n            ports:\n            - containerPort: 8080\n            livenessProbe:                // 检查应用是否存活的探针, 和容器一个级别\n              exec:                        // 第一种健康检查方式, 通过执行命令\n                command:\n                - /bin/sh\n                - -c\n                - ps -ef|grep java|grep -v grep\n              initialDelaySeconds: 10        // 容器起来后过10s开始检查\n              periodSeconds: 10                // 每隔10s检查一次\n              failureThreshold: 2            // 连续健康检查失败2次放弃检查, 重启容器\n              successThreshold: 1            // 检查一次满足条件就认为健康检查通过\n              timeoutSeconds: 5                // 每次健康检查delay时间是5s, 超时也认为健康检查失败, 重启容器\n            readinessProbe:                // readinessProbe与livenessProbe用法完全一样.\n              exec:                        // 第一种检查方式, 通过执行命令\n                command:\n                - /bin/sh\n                - -c\n                - ps -ef|grep java|grep -v grep\n              initialDelaySeconds: 10        // 容器起来后过10s开始检查\n              periodSeconds: 10                // 每隔10s检查一次\n              failureThreshold: 2            // 连续健康检查失败2次放弃检查, 重启容器\n              successThreshold: 1            // 检查一次满足条件就认为健康检查通过\n              timeoutSeconds: 5                // 每次健康检查delay时间是5s, 超时也认为健康检查失败, 重启容器</code></pre><ul>\n<li>第二种健康检查方式: 执行网络请求检查存活探针是否存活</li>\n</ul>\n<pre><code>$ touch kubia-liveness-probe.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: kubia-liveness\nspec:\n  containers:\n  - image: luksa/kubia-unhealthy\n    name: kubia\n    livenessProbe:        // 一个 HTTP GET 存活探针\n      httpGet:            // 第二种健康检查方式, 通过httpGet\n        path: /            // 应用要访问的路径\n        port: 8080        // 容器本身启动的端口\n        scheme: HTTP\n      initialDelaySeconds: 15        // 容器起来后过10s开始检查\n      periodSeconds: 5\n\n$ kubectl get pods\nNAME                           READY   STATUS    RESTARTS   AGE\nkubia-liveness                 1/1     Running   1          13m</code></pre><p>查看该pod描述</p>\n<pre><code>$ kubectl describe pod/kubia-liveness\n......\nLast State:     Terminated\n  Reason:       Error\n  Exit Code:    137\n  Started:      Wed, 13 May 2020 15:49:36 +0800\n  Finished:     Wed, 13 May 2020 15:51:25 +0800\nReady:          True\nRestart Count:  1\nLiveness:       http-get http://:8080/ delay=0s timeout=1s period=10s #success=1 #failure=3\n......</code></pre><p>数字137是两个 数字的总和：128+x, 其中x是终止进程的信号编号.<br>在这个例子中，x等于9, 这是SIGKILL的信号编号，意味着这个进程被强行终止.<br>当容器被强行终止时，会创建一个全新的容器—-而不是重启原来的容器.<br>delay=Os部分显示在容器启动后立即开始探测.<br>timeout仅设置为1秒，因此容器必须在1秒内进行响应， 不然这次探测记作失败.<br>每10秒探测一次容器(period=lOs), 并在探测连续三次失败(#failure=3)后重启容器.<br>定义探 针时可以自定义这些附加参数。例如，要设 置初始延迟，请将initialDelaySeconds属性添加到存活探针的配置中.</p>\n<pre><code>    livenessProbe:        // 一个 HTTP GET 存活探针\n      httpGet:\n        path: /\n        port: 8080\n      initialDelaySeconds: 15    // Kubernetes会在第—次探测前等待15秒 \n\n$ kubectl describe pod/kubia-liveness\n......\nLiveness:       http-get http://:8080/ delay=15s timeout=1s period=10s #success=1 #failure=3</code></pre><ul>\n<li>第三种健康检查方式: 通过TCP检查端口是否处于监听状态<pre><code>livenessProbe:        // 一个 HTTP GET 存活探针\n  tcpSocket:\n    port: 8080\n  initialDelaySeconds: 20    // Kubernetes会在第—次探测前等待15秒 \n  periodSeconds: 5</code></pre></li>\n</ul>\n<blockquote>\n<p>如果没有设置初始延迟，探针将在启动时立即开始探测容器， 这通常会导致探测失败， 因为应用程序还没准备好开始接收请求.<br>务必记得设置一个初始延迟未说明应用程序的启动时间.<br>对于在生产中运行的pod, 一定要定义一个存活探针。没有探针的话，Kubemetes无法知道你的应用是否还活着。只要进程还在运行， Kubemetes会认为容器是健康的<br>Kubernetes会在你的容器崩溃或其存活探针失败时， 通过重启容器来保持运行。 这项任务由承载pod的节点上的Kubelet 执行 一— 在主服务器上运行的Kubernetes Control Plane组件不会参与此过程.<br>但如果节点本身崩溃， 那么Control Plane 必须为所有随节点停止运行的pod创建替代品。 它不 会为你直接创建的pod执行此操作 。 这些pod只被Kubelet 管理.</p>\n</blockquote>\n<h3 id=\"查看-readinessProbe-healthProbe\"><a href=\"#查看-readinessProbe-healthProbe\" class=\"headerlink\" title=\"查看 readinessProbe, healthProbe\"></a>查看 readinessProbe, healthProbe</h3><pre><code>$ kubectl edit po -n istio-system istio-ingressgateway-6489d9556d-wjr58\n$ kubectl edit deployment -n istio-system istio-ingressgateway\n$ kubectl logs po/istio-ingressgateway-6489d9556d-wjr58 -n istio-system\n$ kubectl get po -A</code></pre><h3 id=\"affinity\"><a href=\"#affinity\" class=\"headerlink\" title=\"affinity\"></a>affinity</h3><p>匹配Node标签, Pod部署到哪台机器上.</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-demo\n  namespace: dev\nspec:\n  selector:\n    matchLabels:\n      app: web-demo\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: web-demo\n    spec:\n      selector:\n        matchLabels:\n          app: web-demo\n      replicas: 1\n      template:\n        metadata:\n          labels:\n            app: web-demo\n        spec:\n          containers:\n          - name: web-demo\n            image: hub.mooc.com/kubernetes/web:v1\n            ports:\n            - containerPort: 8080\n          affinity:\n            nodeAffinity:        // node亲和性, 要部署到哪台机器，不要部署到哪台机器\n              requiredDuringSchedulingIgnoredDuringExecution:    // 必须满足下面条件才会执行调度\n                nodeSelectorTerms:        // 数组形式, 下面可以定义多个Terms, 它们之间是或的关系\n                - matchExpressions:        // 数组形式, 如果定义多个matchExpressions它们之间是与的关系\n                  - key: beta.kubernetes.io/arch    // 节点的label含有的key名字, 这里的是由K8s根据机器自动生成的\n                    operator: In\n                    values:                // 前提是Node机器有amd64标签K8s才会把容器部署到次Node机器\n                    - amd64                // 通过kubectl get nodes NodeName -o yaml进行查看\n              preferredDuringSchedulingIgnoredDuringExecution:    // 最好是怎样调度\n              - weight: 1                // 权重\n                perference:\n                  matchExpressions:\n                  - key: disktype        // 通过kubectl get nodes --show-labels查看\n                    operator: NotIn\n                    values:\n                    - ssd\n            podAffinity:        // Pod亲和性, 想和哪些Pod部署到一台机器, 不想和哪些Pod部署在一台机器\n              requiredDuringSchedulingIgnoredDuringExecution:\n              - labelSelector:\n                  matchExpressions:\n                  - key: app\n                    operator: In        // 要跟app=web-demo的Pod运行在同一个节点上\n                    values:\n                    - web-demo-node\n                topologyKey: kubernetes.io/hostname        // 节点的label名字\n              preferredDuringSchedulingIgnoredDuringExecution:\n              - weight: 100\n                podAffinityTerm:\n                  labelSelector:\n                    matchExpressions:\n                    - key: app\n                      operator: In\n                      values:\n                      - web-demo-node\n                  topologyKey: kubernetes.io/hostname\n            podAntiAffinity:        // Pod反亲和性, 不想和哪些Pod部署到一台机器, 用法和podAffinity用法完全一样\n            pod反亲和性用的很多的是上面的replicas: 的值 &gt;=2 时候会把容器副本分别部署到不同机器</code></pre><h3 id=\"Pod启动停止控制\"><a href=\"#Pod启动停止控制\" class=\"headerlink\" title=\"Pod启动停止控制\"></a>Pod启动停止控制</h3><p>Pod容器启动时候和停止前所做的事</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-demo\n  namespace: dev\nspec:\n  selector:\n    matchLabels:\n      app: web-demo\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: web-demo\n    spec:\n      selector:\n        matchLabels:\n          app: web-demo\n      replicas: 1\n      template:\n        metadata:\n          labels:\n            app: web-demo\n        spec:\n          containers:\n          - name: web-demo\n            image: hub.mooc.com/kubernetes/web:v1\n            ports:\n            - containerPort: 8080\n            volumeMounts:\n            - name: shared-volume\n              mounthPath: /shared-web\n            lifecycle:                Pod里容器启动前和停止前要做的事\n              postStart:\n                exec:\n                  command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo web starting ... &gt;&gt; /var/log/messages&quot;]\n              preStop:\n                exec:\n                  command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo web stopping ... &gt;&gt; /var/log/messages &amp;&amp; sleep 3&quot;]</code></pre><h2 id=\"ReplicationController\"><a href=\"#ReplicationController\" class=\"headerlink\" title=\"ReplicationController\"></a>ReplicationController</h2><p>一个ReplicationController有三个主要部分<br> • label selector ( 标签选择器）， 用于确定ReplicationController作用域中有哪些pod<br> • replica count (副本个数）， 指定应运行的pod 数量<br> • pod template (pod模板）， 用于创建新的pod 副本<br>使用 ReplicationController 的好处<br> •确保一 个 pod (或多个 pod副本）持续运行， 方法是在现有pod 丢失时启动一个新 pod。<br> • 集群节点发生故障时， 它将为故障节 点 上运 行的所有 pod (即受ReplicationController 控制的节点上的那些 pod) 创建替代副本。<br> • 它能轻松实现 pod的水平伸缩 手动和自动都可以</p>\n<h3 id=\"由RC创建POD\"><a href=\"#由RC创建POD\" class=\"headerlink\" title=\"由RC创建POD\"></a>由RC创建POD</h3><p>kubia-rc.yaml, 内容如下:</p>\n<pre><code>apiVersion: v1\nkind: ReplicationController        // 这里的配置定义了ReplicationController(RC)\nmetadata:\n  name: kubia        // ReplicationController 的名字\nspec:\n  replicas: 3        // pod 实例的目标数目\n  selector:            // selector也可以不写，replica 直接根据下面的template模板里的lables标签选择创建POD\n    app: kubia        // pod 选择器决定了 RC 的操作对象\n  template:            // 从此以下都是创建新 pod 所用的 pod 模板, 与单独创建的pod定义yaml文件内容几乎相同\n    metadata:\n      labels:\n        app: kubia\n    spec:\n      containers:\n      - name: kubia\n        image: luksa/kubia\n        ports:\n        - containerPort: 8080</code></pre><p>创建ReplicationController并由其创建pod</p>\n<pre><code>$ kubectl create -f kubia-rc.yaml\n$ kubectl get po -o wide\nNAME          READY   STATUS    RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES\nkubia-6wnj5   1/1     Running   0          56s   10.44.0.3   server02   &lt;none&gt;           &lt;none&gt;\nkubia-788p8   1/1     Running   0          56s   10.44.0.2   server02   &lt;none&gt;           &lt;none&gt;\nkubia-c9kn6   1/1     Running   0          56s   10.44.0.1   server02   &lt;none&gt;           &lt;none&gt;\n\n$ kubectl delete po kubia-6wnj5\nNAME          READY   STATUS              RESTARTS   AGE\nkubia-6ntgt   0/1     ContainerCreating   0          12s\nkubia-6wnj5   1/1     Terminating         0          3m3s\nkubia-788p8   1/1     Running             0          3m3s\nkubia-c9kn6   1/1     Running             0          3m3s</code></pre><p>上面重新列出pod会显示四个， 因为你删除的pod己终止， 并且己创建一个新的pod<br>虽然ReplicationController会立即收到删除pod的通知 (API 服务器允许客户端监听资源和资源列表的更改），但这不是它创建替代pod的原因。<br>该通知会触发控制器检查实际的pod数量并采取适当的措施.</p>\n<pre><code>$ kubectl get po -o wide\nNAME          READY   STATUS    RESTARTS   AGE     IP          NODE       NOMINATED NODE   READINESS GATES\nkubia-6ntgt   1/1     Running   0          53s     10.44.0.4   server02   &lt;none&gt;           &lt;none&gt;\nkubia-788p8   1/1     Running   0          3m44s   10.44.0.2   server02   &lt;none&gt;           &lt;none&gt;\nkubia-c9kn6   1/1     Running   0          3m44s   10.44.0.1   server02   &lt;none&gt;           &lt;none&gt;</code></pre><h3 id=\"获取有关-ReplicationController-的信息\"><a href=\"#获取有关-ReplicationController-的信息\" class=\"headerlink\" title=\"获取有关 ReplicationController 的信息\"></a>获取有关 ReplicationController 的信息</h3><pre><code>$ kubectl get rc -o wide\n$ kubectl get rc -o wide -n default        // RC是针对某个namespace下做的副本pod控制\nNAME    DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES        SELECTOR\nkubia   3         3         3       17m   kubia        luksa/kubia   app=kubia\n获取RC的详细信息\n$ kubectl describe rc kubia</code></pre><p>如果你更改了 一个 pod 的标签，使它不再 与 ReplicationController 的标签选择器相匹配 ， 那么该 pod 就变得和其他手动创建的 pod 一样了<br>更改 pod 的标签时， ReplicationController 发现一个 pod 丢失了 ， 并启动一个新的pod替换它.</p>\n<p>给其中一个 pod 添加了 type=special 标签，再次列出所有 pod 会显示和以前一样的三个 pod 。 因为从 ReplicationCon位oiler 角度而言， 没发生任何更改.</p>\n<pre><code>$ kubectl label pod/kubia-6ntgt type=special\n$ kubectl get pod --show-labels\nNAME          READY   STATUS    RESTARTS   AGE   LABELS\nkubia-6ntgt   1/1     Running   0          27m   app=kubia,type=special\nkubia-788p8   1/1     Running   0          30m   app=kubia\nkubia-c9kn6   1/1     Running   0          30m   app=kubia</code></pre><p>更改app标签该 pod 不再与 RC 的标签选择器相匹配</p>\n<pre><code>$ kubectl label pod/kubia-6ntgt app=foo --overwrite\n$ kubectl get pod --show-labels\nNAME          READY   STATUS              RESTARTS   AGE   LABELS\nkubia-6ntgt   1/1     Running             0          30m   app=foo,type=special\nkubia-788p8   1/1     Running             0          33m   app=kubia\nkubia-c9kn6   1/1     Running             0          33m   app=kubia\nkubia-dqshz   0/1     ContainerCreating   0          4s    app=kubia</code></pre><p>使用 -L app 选项在列 中显示 app 标签</p>\n<pre><code>$ kubectl get pod -L app\nNAME          READY   STATUS    RESTARTS   AGE     APP\nkubia-6ntgt   1/1     Running   0          32m     foo\nkubia-788p8   1/1     Running   0          35m     kubia\nkubia-c9kn6   1/1     Running   0          35m     kubia\nkubia-dqshz   1/1     Running   0          2m17s   kubia</code></pre><p>可能有一个 bug 导致你的 pod 在特定时间或特定事件后开始出问题。<br>如果你知道某个 pod 发生了故障， 就可以将它从 Replication-Controller 的管理范围中移除， 让控制器将它替换为新 pod, 接着这个 pod 就任你处置了。 完成后删除该pod 即可。</p>\n<h3 id=\"编辑RC的YAML配置\"><a href=\"#编辑RC的YAML配置\" class=\"headerlink\" title=\"编辑RC的YAML配置\"></a>编辑RC的YAML配置</h3><p>用默认文本编辑器中打开ReplicationController的YAML配置，会在/tmp目录生成一个临时yaml文件，退出后/tmp目录下的yaml文件也会删掉<br>如果你想使用nano编辑Kubernetes资源，请执行以下命令（或将其放入 ~/.bashrc或等效文件中）<br>export KUBE_EDITOR=”/usr/bin/nano”</p>\n<pre><code>$ kubectl edit rc kubia\n......\n spec:\n   replicas: 3\n   selector:\n     app: kubia1                 RC selector 修改，需要配合下面的label一起修改\n   template:\n     metadata:\n       creationTimestamp: null\n       labels:\n         app: kubia1             Pod label 修改，需要配合上面的 RC selector 一起修改\n     spec:\n       containers:\n       - image: luksa/kubia\n         imagePullPolicy: Always\n         name: kubia\n         ports:\n         - containerPort: 8080\n           protocol: TCP\n......\n\n$ kubectl get pod\nNAME          READY   STATUS              RESTARTS   AGE   APP\nkubia-279wl   0/1     ContainerCreating   0          2s    kubia1\nkubia-6ntgt   1/1     Running             0          44m   foo\nkubia-788p8   1/1     Running             0          47m   kubia\nkubia-c9kn6   1/1     Running             0          47m   kubia\nkubia-dqshz   1/1     Running             0          14m   kubia\nkubia-m6vml   0/1     Pending             0          2s    kubia1\nkubia-xxjqr   0/1     ContainerCreating   0          2s    kubia1</code></pre><h3 id=\"RC-扩容\"><a href=\"#RC-扩容\" class=\"headerlink\" title=\"RC 扩容\"></a>RC 扩容</h3><p>扩展/缩容 RC管理的pod为5个<br>第一种，commands方式:</p>\n<pre><code>$ kubectl scale rc kubia --replicas=5</code></pre><p>第二种， edit rc yaml文件</p>\n<pre><code>$ kubectl edit rc kubia\n......\nspec:\n  replicas: 5\n......</code></pre><h3 id=\"删除RC\"><a href=\"#删除RC\" class=\"headerlink\" title=\"删除RC\"></a>删除RC</h3><p>当使用 kubectl delete 删除 ReplicationController 时， 可以通过给命令增加 –cascade= false 选项来保持 pod 的运行.</p>\n<pre><code>$ kubectl delete rc kubia --cascade=false</code></pre><p>已经删除了 ReplicationController, 所以这些 pod 独立了， 它们不再被管理。但是你始终可以使用适当的标签选择器创建新的 ReplicationController, 并再次将它们管理起来</p>\n<h2 id=\"ReplicaSet\"><a href=\"#ReplicaSet\" class=\"headerlink\" title=\"ReplicaSet\"></a>ReplicaSet</h2><blockquote>\n<p>最 初， ReplicationController 是用于复制和在异常时重新调度节点的唯 一Kubemetes 组件， 后来又引入了 一个名为 ReplicaSet 的类似资源 。 它是新一代的ReplicationController, 并且将其完全替换掉 (ReplicationController 最终将被弃用）。<br>也就是说从现在起， 你应该始终创建 ReplicaSet 而不是 ReplicationController。 它们几乎完全相同， 所以你不会碰到任何麻烦<br>ReplicaSet 的行为与ReplicationController 完全相同， 但pod 选择器的表达能力更强<br>ReplicationController 都无法仅基千标签名的存在来匹配 pod, 而ReplicaSet 则可以。 例如， ReplicaSet 可匹配所有包含名为 env 的标签的 pod, 无论ReplicaSet 的实际值是什么（可以理解为 env=*)</p>\n</blockquote>\n<p>kubia-replicaset.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: kubia\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: kubia\n  template:\n    metadata:\n      labels:\n        app: kubia\n    spec:\n      containers:\n      - name: kubia\n        image: luksa/kubia\n        ports:\n        - containerPort: 8080</code></pre><p>检查replicaset:</p>\n<pre><code>$ kubectl get rs</code></pre><h3 id=\"matchExpressions选择器\"><a href=\"#matchExpressions选择器\" class=\"headerlink\" title=\"matchExpressions选择器\"></a>matchExpressions选择器</h3><p>创建个yaml文件<br>kubia-replicaset-matchexpressions.yaml</p>\n<pre><code>selector:\n  matchExpressions:\n    - key: app\n      operator: In\n      values:\n        - kubia</code></pre><p>每个表达式都必须 包含一个key, 一个operator (运算符），并且可能还有一个values的列表（取决于 运算符）.<br>• In : Label的值 必须与其中 一个指定的values 匹配。<br>• Notln : Label的值与任何指定的values 不匹配。<br>• Exists : pod 必须包含一个指定名称的标签（值不重要）。使用此运算符时，<br>不应指定 values字段。<br>• DoesNotExist : pod不得包含有指定名称的标签。values属性不得指定<br>如果同时指定matchLabels和matchExpressions, 则所有标签都必须匹配，并且所有表达式必须计算为true以使该pod与选择器匹配.</p>\n<h3 id=\"查看-replicaset-和-deployment-的详细信息\"><a href=\"#查看-replicaset-和-deployment-的详细信息\" class=\"headerlink\" title=\"查看 replicaset 和 deployment 的详细信息\"></a>查看 replicaset 和 deployment 的详细信息</h3><pre><code>$ kubectl describe deployment details-v1\n$ kubectl describe rs details-v1-6fc55d65c9</code></pre><h3 id=\"删除ReplicaSet\"><a href=\"#删除ReplicaSet\" class=\"headerlink\" title=\"删除ReplicaSet\"></a>删除ReplicaSet</h3><p>删除ReplicaSet会删除所有的pod,这种情况下是需要列出pod来确认.</p>\n<pre><code>$ kubectl delete rs kubia</code></pre><h2 id=\"DaemonSet\"><a href=\"#DaemonSet\" class=\"headerlink\" title=\"DaemonSet\"></a>DaemonSet</h2><p>如果节点下线， DaemonSet不会在其他地方重新创建pod。 但是， 当将一个新节点添加到集群中时， DaemonSet会立刻部署一个新的pod实例。<br>如果有人无意中删除了 一个 pod ， 那么它也会重新创建 一个新的 pod。<br>与 ReplicaSet一样，DaemonSet 从配置的 pod 模板创建 pod.</p>\n<blockquote>\n<p>如果节点可以被设置为不可调度的 ， 防止 pod 被部署到节点上. DaemonSet 甚至会将 pod 部署到这些节点上，因为无法调度的属性只会被调度器使用，而 DaemonSet 管理的 pod 则完全绕过调度器. 这是预期的，因为DaemonSet的目的是运行系统服务，即使是在不可调度的节点上，系统服务通常也需要运行.</p>\n</blockquote>\n<p>给node节点打上label</p>\n<pre><code>$ kubectl label node server02 disk=ssd</code></pre><p>ssd-monitor-daemonset.yaml</p>\n<pre><code>apiVersion: apps/v1            // DaemooSet在apps的API组 中，版本是v1\nkind: DaemonSet\nmetadata:\n  name: ssd-monitor\nspec:\n  selector:\n    matchLabels:\n      app: ssd-monitor\n  template:\n    metadata:\n      labels:\n        app: ssd-monitor\n    spec:\n      nodeSelector:            // pod模板包含 会选择有disk=ssd标签的节点 一个节点选择器\n        disk: ssd\n      containers:\n      - name: main\n        image: luksa/ssd-monitor\n\n$ kubectl create -f ssd-monitor-daemonset.yaml</code></pre><h3 id=\"查看DaemonSet\"><a href=\"#查看DaemonSet\" class=\"headerlink\" title=\"查看DaemonSet\"></a>查看DaemonSet</h3><pre><code>$ kubectl get ds\nNAME          DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE     CONTAINERS   IMAGES              SELECTOR\nssd-monitor   1         1         1       1            1           disk=ssd        3m29s   main         luksa/ssd-monitor   app=ssd-monitor</code></pre><p>如果你有多个节点并且其他的节点也加上了同样的标签，将会看到 DaemonSet 在每个节点上都启动 pod.<br>给其中一个节点修改标签disk=hdd, 假设它的硬盘换成磁盘而不是SSD, 那个节点上的pod会如预期中被终止.<br>如果还有其他的 pod在运行， 删除 DaemonSet 也会一起删除这些 pod。</p>\n<h3 id=\"删除ds\"><a href=\"#删除ds\" class=\"headerlink\" title=\"删除ds\"></a>删除ds</h3><p>删除ds会删除由ds控制schedule到每个节点的pod</p>\n<pre><code>$ kubectl delete ds ssd-monitor</code></pre><h2 id=\"Job资源\"><a href=\"#Job资源\" class=\"headerlink\" title=\"Job资源\"></a>Job资源</h2><p>Kubemetes 通过 Job 资源提供了对此的支持，它允许你运行一种 pod, 该 pod 在内部进程成功结束时， 不重启容器。<br>一旦任务完成， pod 就被认为处于完成状态.<br>由Job管理的pod会一直被重新安排，直到它们成功完成任务.</p>\n<p>exporter.yaml</p>\n<pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: batch-job\nspec:\n  template:\n    metadata:\n      labels:\n        app: batch-job\n    spec:\n      restartPolicy: OnFailure        // 默认为Always,Job pod不能使用默认策略， 因为它们不是要无限期地运行\n      containers:\n      - name: main\n        image: luksa/batch-job        // 运行luksa/batch-job镜像，该镜像调用 一个运行120秒的进程，然后退出</code></pre><p>需要明确地将重启策略 restartPolicy 设置为 OnFailure 或 Never。 此设置防止容器在完成任务时重新启动</p>\n<pre><code>$ kubectl create -f exporter.yaml\n\n$ kubectl get pod\nNAME                READY   STATUS    RESTARTS   AGE\nbatch-job-lhnfg     1/1     Running   0          113s\n\n$ kubectl get jobs\nNAME        COMPLETIONS   DURATION   AGE\nbatch-job   0/1           111s       111s</code></pre><p>等待两三分钟后</p>\n<pre><code>$ kubectl get pod\nNAME                READY   STATUS      RESTARTS   AGE\nbatch-job-lhnfg     0/1     Completed   0          3m21s\n\n$ kubectl get job\nNAME        COMPLETIONS   DURATION   AGE\nbatch-job   1/1           2m41s      3m27s</code></pre><p>完成后pod未被删除的原因是允许你查阅其日志</p>\n<pre><code>$ kubectl logs po/batch-job-lhnfg\nThu May 14 05:04:38 UTC 2020 Batch job starting\nThu May 14 05:06:38 UTC 2020 Finished succesfully</code></pre><p>pod 可以被直接删除， 或者在删除创建它的Job时被删除<br>作业可以配置为创建多个pod实例，并以并行或串行方式运行它们<br>在Job配置中设置 completions和parallelism属性来完成的<br>如果你需要 一个Job运行多次，则可以将comple巨ons设为你希望作业的pod运行多少次</p>\n<pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: multi-completion-batch-job\nspec:\n  completions: 5    // job将一个接一个地运行五个pod\n  parallelism: 2    // 最多两个pod可以并行运行\n  template:\n    metadata:\n      labels:\n        app: batch-job\n    spec:\n      restartPolicy: OnFailure\n      containers:\n      - name: main\n        image: luksa/batch-job</code></pre><p>它最初创建一个pod, 当pod的容器运行完成时，它创建第二个pod, 以此类推，直到五个pod成功完成。<br>如果其中 一个pod发生故障，工作会创建一个新的pod, 所以Job总共可以创建五个以上的pod.</p>\n<pre><code>$ kubectl create -f multi-completion-batch-job.yaml\nNAME                               READY   STATUS              RESTARTS   AGE\nmulti-completion-batch-job-8kzd5   0/1     ContainerCreating   0          4s\nmulti-completion-batch-job-9rnxs   0/1     ContainerCreating   0          4s</code></pre><p>只要其中 一个pod完成任务，工作将运行下 一个pod, 直到五个pod都成功完成任务.</p>\n<pre><code>kubectl get po\nNAME                               READY   STATUS    RESTARTS   AGE\nmulti-completion-batch-job-8kzd5   1/1     Running   0          2m8s\nmulti-completion-batch-job-9rnxs   1/1     Running   0          2m8s\n\n$ kubectl get job\nNAME                         COMPLETIONS   DURATION   AGE\nmulti-completion-batch-job   0/5           2m13s      2m13s</code></pre><p>POD虽然创建，但是POD里的进程任务还没有完成，因此job显示任然是0/5没有一个pod任务完成<br>再等待一会时间</p>\n<pre><code>$ kubectl get po\nNAME                               READY   STATUS      RESTARTS   AGE\nmulti-completion-batch-job-8kzd5   0/1     Completed   0          4m18s\nmulti-completion-batch-job-9rnxs   0/1     Completed   0          4m18s\nmulti-completion-batch-job-blntb   1/1     Running     0          107s\nmulti-completion-batch-job-qhsr5   1/1     Running     0          92s\nssd-monitor-jbhpd                  1/1     Running     0          176m\n\n$ kubectl get job\nNAME                         COMPLETIONS   DURATION   AGE\nmulti-completion-batch-job   2/5           4m16s      4m16s</code></pre><p>如上显示已经有2个POD任务完成，POD退出.<br>甚至可以在 Job 运行时更改 Job 的 parallelism 属性, command如下，实验环境没有成功使用</p>\n<pre><code>$ kubectl scale job multi-completion-batch-job --replicas 3</code></pre><blockquote>\n<p>通过在 pod 配置中设置 activeDeadlineSeconds 属性，可以限制 pod的时间。如果 pod 运行时间超过此时间， 系统将尝试终止 pod, 并将 Job 标记为失败。<br>通过指定 Job manifest 中的 spec.backoff巨m辽字段， 可以配置 Job在被标记为失败之前可以重试的次数。 如果你没有明确指定它， 则默认为6</p>\n</blockquote>\n<h3 id=\"删除job\"><a href=\"#删除job\" class=\"headerlink\" title=\"删除job\"></a>删除job</h3><p>删除job时，由job创建的pod也被直接删除</p>\n<pre><code>$ kubectl delete job multi-completion-batch-job</code></pre><h2 id=\"CornJob-资源\"><a href=\"#CornJob-资源\" class=\"headerlink\" title=\"CornJob 资源\"></a>CornJob 资源</h2><blockquote>\n<p>批处理任务需要在特定的时间运行，或者在指定的时间间隔内重复运行,在 Linux 和类 UNIX 操作系统中， 这些任务通常被称为 cron 任务。 Kubemetes 也支持这种任务<br>Kubemetes 中的 cron 任务通过创建 CronJob 资源进行配置, 运行任务的时间表以知名的 cron 格式指定<br>时间表从左到右包含以下五个条目<br>• 分钟<br>• 小时<br>• 每月中的第几天<br>• 月<br>• 星期几</p>\n</blockquote>\n<p>创建资源文件(kube API 对象文件)cronjob.yaml</p>\n<pre><code>apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: batch-job-every-fifteen-minutes\nspec:\n  schedule: &quot;0,15,30,55 * * * *&quot;\n  startingDeadlineSeconds: 15    // pod最迟必须在预定时间后15秒开始运行， 如果因为任何原因到该启动时间15s后仍不启动，任务将不会运行，并将显示为Failed\n  jobTemplate:\n    spec:\n      template:\n        metadata:\n          labels:\n            app: periodic-batch-job\n        spec:\n          restartPolicy: OnFailure\n          containers:\n          - name: main\n            image: luksa/batch-job</code></pre><blockquote>\n<p>希望每 15 分钟运行一 次任务因此 schedule 字段的值应该是”0, 15, 30, 45****” 这意味着每小时的 0 、 15 、 30和 45 分钟（第一个星号），每月的每一天（第二个星号），每月（第三个星号）和每周的每一天（第四个星号）。<br>相反，如果你希望每隔 30 分钟运行一 次，但仅在每月的第一天运行，则应将计划设置为 “0,30 * 1 * *”, 并且如果你希望它每个星期天的 3AM 运行，将它设置为 “0 3 * * 0” (最后一个零代表星期天）。</p>\n</blockquote>\n<h3 id=\"查看cronjob\"><a href=\"#查看cronjob\" class=\"headerlink\" title=\"查看cronjob\"></a>查看cronjob</h3><pre><code>$ kubectl get cronjob -o wide\nNAME                              SCHEDULE             SUSPEND   ACTIVE   LAST SCHEDULE   AGE    CONTAINERS   IMAGES            SELECTOR\nbatch-job-every-fifteen-minutes   0,15,30,55 * * * *   False     0        18m             112m   main         luksa/batch-job   &lt;none&gt;</code></pre><h3 id=\"cronjob运行状态\"><a href=\"#cronjob运行状态\" class=\"headerlink\" title=\"cronjob运行状态\"></a>cronjob运行状态</h3><pre><code>$ kubectl get po\nNAME                                               READY   STATUS      RESTARTS   AGE\nbatch-job-every-fifteen-minutes-1589439300-4v8wd   0/1     Completed   0          36m\nbatch-job-every-fifteen-minutes-1589439600-99pns   0/1     Completed   0          31m\nbatch-job-every-fifteen-minutes-1589440500-vs5vm   0/1     Completed   0          16m\nbatch-job-every-fifteen-minutes-1589441400-52rzb   1/1     Running     0          112s\n\n$ kubectl get job\nNAME                                         COMPLETIONS   DURATION   AGE\nbatch-job-every-fifteen-minutes-1589439300   1/1           2m24s      36m\nbatch-job-every-fifteen-minutes-1589439600   1/1           2m24s      31m\nbatch-job-every-fifteen-minutes-1589440500   1/1           2m22s      16m\nbatch-job-every-fifteen-minutes-1589441400   0/1           116s       116s</code></pre><p>再过一点时间查看</p>\n<pre><code>$ kubectl get po\nNAME                                               READY   STATUS      RESTARTS   AGE\nbatch-job-every-fifteen-minutes-1589439600-99pns   0/1     Completed   0          32m\nbatch-job-every-fifteen-minutes-1589440500-vs5vm   0/1     Completed   0          17m\nbatch-job-every-fifteen-minutes-1589441400-52rzb   0/1     Completed   0          2m34s\n\n$ kubectl get job\nNAME                                         COMPLETIONS   DURATION   AGE\nbatch-job-every-fifteen-minutes-1589439600   1/1           2m24s      32m\nbatch-job-every-fifteen-minutes-1589440500   1/1           2m22s      17m\nbatch-job-every-fifteen-minutes-1589441400   1/1           2m20s      2m37s</code></pre><p>总结: CornJob过指定的时间执行一次POD，执行完退出，会保留三个POD和Job记录.</p>\n<h3 id=\"删除cronjob\"><a href=\"#删除cronjob\" class=\"headerlink\" title=\"删除cronjob\"></a>删除cronjob</h3><p>运行中的 Job 将不会被终止，不会删除 Job 或 它们的 Pod。为了清理那些 Job 和 Pod，需要列出该 Cron Job 创建的Job，然后删除它们.</p>\n<pre><code>$ batch-job-every-fifteen-minutes\ncronjob.batch &quot;batch-job-every-fifteen-minutes&quot; deleted</code></pre><h2 id=\"secret\"><a href=\"#secret\" class=\"headerlink\" title=\"secret\"></a>secret</h2><pre><code>$ kubectl get secret -n default\nNAME                  TYPE                                  DATA   AGE\ndefault-token-gtcjx   kubernetes.io/service-account-token   3      32d\n\n$ kubectl get pods -o wide\nNAME                               READY   STATUS    RESTARTS   AGE     IP           NODE         NOMINATED NODE   READINESS GATES\nwordpress-7bfc545758-vtfvm         1/1     Running   5          10d     10.36.0.10   hci-node04   &lt;none&gt;           &lt;none&gt;\nwordpress-mysql-764fc64f97-sjnjk   1/1     Running   0          10d     10.36.0.8    hci-node04   &lt;none&gt;           &lt;none&gt;\n\n$ kubectl get po/wordpress-7bfc545758-vtfvm -o yaml\n......\nspec:\n  containers:\n  - env:\n    volumeMounts:\n    - mountPath: /var/www/html\n      name: wordpress-persistent-storage\n    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\n      name: default-token-gtcjx\n      readOnly: true\n......\n  volumes:\n  - name: wordpress-persistent-storage\n    persistentVolumeClaim:\n      claimName: wp-pv-claim\n  - name: default-token-gtcjx\n    secret:\n      defaultMode: 420        // 访问权限\n      secretName: default-token-gtcjx\n......</code></pre><p>进入wordpress-7bfc545758-vtfvm所在机器的容器里查看/var/run/secrets/kubernetes.io/serviceaccount路径文件</p>\n<pre><code>$ docker exec -it daec0458a397 /bin/sh\n# ls /var/run/secrets/kubernetes.io/serviceaccount\n  ca.crt  namespace  token</code></pre><h3 id=\"创建自己的Secret\"><a href=\"#创建自己的Secret\" class=\"headerlink\" title=\"创建自己的Secret\"></a>创建自己的Secret</h3><p>serviceAccount 用来跟Apiserver通信，用来授权, 可以创建自己的Secret<br>编写Secret配置文件 secret.yaml</p>\n<pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: dbpass\ntype: Opaque        // 不透明，浑浊的.\ndata:\n  username: aW1vb2M=        // base64加密的用户名\n  passwd: aW1vb2MxMjM=        // base64加密的密码</code></pre><p>把字符串生成base64很简单，命令如下</p>\n<pre><code>$ echo -n imooc | base64    // -n 表示换行\naW1vb2M=</code></pre><p>编写Pod资源配置文件 pod-secret.yaml</p>\n<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-secret\nspec:\n  containers:\n  - name: springbook-web\n    image: hub.mooc.com/kubernetes/springboot-web:v1\n    ports:\n    - containerPort: 8080\n    volumeMounts:\n    - name: db-secret\n      mountPath: /db-secret\n      readOnly: true\n  volumes:\n  - name: db-secret\n    projected:\n      sources:            // secret 来源\n      - secret:\n        name: dbpass    // secret 名字</code></pre><p>生成Pod并进入查看</p>\n<pre><code>$ / # cd /db-secret/\n$ ls\n  passwd username\n$ cat -n username        // 查看容器里存放的是base64解码过的数据\n  immoc\n$ cat -n passwd\n  imooc123</code></pre><p>可以通过修改secret.yaml文件修改secret账号密码等再$ kubectl apply -f secret.yaml来更改密码.</p>\n<h2 id=\"Configmap\"><a href=\"#Configmap\" class=\"headerlink\" title=\"Configmap\"></a>Configmap</h2><blockquote>\n<p>configmap常用来存储不需要加密的数据, 比如应用的启动参数，一些参数的配置等</p>\n</blockquote>\n<ul>\n<li>第一种向k8s添加很多key value的键值对属性值，就可以用configmap</li>\n</ul>\n<pre><code>$ touch game.properties\n$ vim game.properties\n  enemies=aliens\n  lives=3\n  enemies.cheat=true\n  secret.code.allowed=true\n  ......</code></pre><p>配置到K8S里</p>\n<pre><code>$ kubectl create configmap web-game --from-file game.properties\n$ kubectl get cm</code></pre><p>使用configmap, Pod-game.yaml</p>\n<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-game\nspec:\n  containers:\n  - name: web\n    image: hub.mooc.com/kubernetes/springboot-web:v1\n    ports:\n    - containerPort: 8080\n    volumeMounts:\n    - name: game\n      mountPath: /etc/config/game\n      readOnly: true\n  volumes:\n  - name: game\n    configMap:\n      name: web-game</code></pre><p>生成Pod并进入查看</p>\n<pre><code>$ cd /etc/config/game\n$ ls\n  game.properties\n$ cat game.properties\n  enemies=aliens\n  lives=3\n  enemies.cheat=true\n  secret.code.allowed=true\n  ......</code></pre><p>可以通过kubectl edit 修改configMap账号密码等</p>\n<pre><code>$ kubectl edit cm web-game -o yaml\n  enemies.cheat=false    //等等操作</code></pre><ul>\n<li>第二种配置文件方式创建configMap<br>configmap.yaml</li>\n</ul>\n<pre><code>apeVersion: v1\nkind: Configmap\nmetadata:\n  name: configs\ndata:\n  Java_OPTS: -Xms1024m\n  LOG_LEVEL: DEBUG\n\n$ kubectl create -f configmap.yaml</code></pre><p>编写资源配置文件pod-env.yaml</p>\n<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-env\nspec:\n  containers:\n  - name: web\n    image: hub.mooc.com/kubernetes/springboot-web:v1\n    ports:\n    - containerPort: 8080\n    env:\n      - name: LOG_LEVEL_CONFIG\n        valueFrom:\n          configMapKeyRef:\n            name: configs        // 指定configMap名字\n            key: LOG_LEVEL        // configs下面的LOG_LEVEL</code></pre><p>进入容器查看环境变量</p>\n<pre><code>$ env | grep LOG\n  LOG_LEVEL_CONFIG=DEBUG</code></pre><p>之后次容器就可以通过环境变量获取值</p>\n<ul>\n<li>第三种 通过命令行方式传进参数<br>也是先跟第二种一样创建configMap资源</li>\n</ul>\n<pre><code>$ kubectl create -f configmap.yaml</code></pre><p>编写资源配置文件pod-cmd.yaml</p>\n<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-cmd\nspec:\n  containers:\n  - name: web\n    image: hub.mooc.com/kubernetes/springboot-web:v1\n    command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;java -jar /springboot-web.jar -DJAVA_OPTS=$(JAVA_OPTS)&quot;]\n    ports:\n    - containerPort: 8080\n    env:\n      - name: Java_OPTS\n        valueFrom:\n          configMapKeyRef:\n            name: configs        // 指定configMap名字\n            key: Java_OPTS        // configs下面的LOG_LEVEL</code></pre><p>进入容器查看进程</p>\n<pre><code>$ ps -ef\n  java -jar /springboot-web.jar -DJAVA_OPTS=-Xms1024m</code></pre><h2 id=\"downwardAPI\"><a href=\"#downwardAPI\" class=\"headerlink\" title=\"downwardAPI\"></a>downwardAPI</h2><p>downwardAPI主要作用是在程序中取得Pod对象本身的一些相关信息<br>pod-downwardapi.yaml</p>\n<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-downwardapi\n  labels:\n    app： downwardapi\n    type: webapp\nspec:\n  containers:\n  - name: web\n    image: hub.mooc.com/kubernetes/springboot-web:v1\n    ports:\n    - containerPort: 8080\n    volumeMounts:\n      - name: podinfo\n        mountPath: /etc/podinfo\n  volumes:\n    - name: podinfo\n      projected:\n        sources:\n        - downwardAPI:\n          items:\n            - path: &quot;labels&quot;\n              fieldRef:\n                fieldPath: metadata.labels\n            - path: &quot;name&quot;\n              fieldRef:\n                fieldPath: metadata.name\n            - path: &quot;namespace&quot;\n              fieldRef:\n                fieldPath: metadata.namespace\n            - path: &quot;mem-request&quot;\n              resourceFieldRef:\n                containerName: web\n                resource: limits.memory</code></pre><p>进入容器查看文件信息</p>\n<pre><code>$ cd /etc/podinfo\n$ ls -l\n  labels mem-request name namespace\n$ cat -n labels\n  app=&quot;downwardapi&quot;\n  type=&quot;webapp&quot;\n$ cat -n namespace\n  default\n$ cat -n name\n  pod-downwardapi</code></pre>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"nodes\"><a href=\"#nodes\" class=\"headerlink\" title=\"nodes\"></a>nodes</h2><pre><code>$ kubectl get nodes -o wide\nNAME         STATUS   ROLES    AGE   VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION           CONTAINER-RUNTIME\nhci-node01   Ready    master   5d    v1.18.1   10.67.108.211   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1062.el7.x86_64   docker://19.3.8\nhci-node02   Ready    &lt;none&gt;   5d    v1.18.1   10.67.109.142   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1062.el7.x86_64   docker://19.3.8\nhci-node03   Ready    &lt;none&gt;   5d    v1.18.1   10.67.109.147   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1062.el7.x86_64   docker://19.3.8\nhci-node04   Ready    &lt;none&gt;   5d    v1.18.1   10.67.109.144   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1062.el7.x86_64   docker://19.3.8\n$ kubectl describe node hci-node02\n输出显示了节点的状态、 CPU 和内存数据、系统信息、运行容器的节点等\n\n查看某台机器的资源\n$ kubectl describe node hci-node01</code></pre><h3 id=\"创建别名和补全\"><a href=\"#创建别名和补全\" class=\"headerlink\" title=\"创建别名和补全\"></a>创建别名和补全</h3><p>kubectl 会被经常使用。很快你就会发现每次不得不打全命令是非常痛苦的。<br>将下面的代码添加到 ~/.bashrc 或类似的文件中 ：</p>\n<pre><code>alias k=kubectl</code></pre><p>为kuebctl配置 tab 补全<br>需要先安装一个叫作 bashcompletio口的包来启用 bash 中的 tab 命令补全， 然后可以运行接下来的命令（也需要加到 ~/.bashrc 或类似的文件中）</p>\n<pre><code>$ source &lt;{kubectl completion bash)\n$ kubectl desc&lt;TAB&gt; nod&lt;TAB&gt; hci&lt;TAB&gt;</code></pre><p>但是需要注意的是， tab 命令行补全只在使用完整的 kubectl 命令时会起作用,(当使用别名 k 时不会起作用). 需要改变 kubectl completion 的输出来修复：</p>\n<pre><code>$ source &lt;(kubectl completion bash | sed s/kubectl/k/g)</code></pre><h3 id=\"node-标签\"><a href=\"#node-标签\" class=\"headerlink\" title=\"node 标签\"></a>node 标签</h3><pre><code>$ kubectl get nodes\n$ kubectl label node server02 gpu=false\n$ kubectl label node server02 gpu=true --overwrite    //修改node标签\n$ kubectl get node -L gpu        // 列出所有node，并添加GPU一列进行展示\n$ kubectl get node -l gpu        // 只列出含标签的key为gpu的node\n$ kubectl get node -l gpu=false    // 只列出含gpu=false的node</code></pre><p>将POD调度到指定的node上: kubia-gpu.yaml</p>\n<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\nname: kubia-gpu        // 指定生成的POD名字\nspec:\nnodeSelector:        // node选择器,选择含标签gpu=true的node机器\n    gpu: &quot;true&quot;        \ncontainers:\n- image: luksa/kubia    // 要拉取的 image 名字\n    name: kubia            // 生成的 container 名字\n\n$ kubectl create -f kubia-gpu.yaml</code></pre><p>如果没有标签为gpu=true的合适node， 通过 $ kubectl describe pod/kubia-nogpu 查看Message， 会报 0/2 nodes are available: 2 node(s) didn’t match node selector.信息</p>\n<pre><code>$ kubectl describe pod/kubia-gpu\n......\nNode-Selectors:  gpu=true\n......</code></pre><h3 id=\"taint污点\"><a href=\"#taint污点\" class=\"headerlink\" title=\"taint污点\"></a>taint污点</h3><p>给Node添加污点可以让配置tolerations的Pod部署上来，而不让平常的Pod部署.<br>配置tolerations的Pod可以部署到添加污点的机器也可以部署到其它平常机器</p>\n<pre><code>$ kubectl taint nodes NodeName gpu=true:NoSchedule\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-demo\n  namespace: dev\nspec:\n  selector:\n    matchLabels:\n      app: web-demo\n  replicas: 3            // 副本数3来测试能部署到哪些机器\n  template:\n    metadata:\n      labels:\n        app: web-demo\n    spec:\n      selector:\n        matchLabels:\n          app: web-demo\n      replicas: 1\n      template:\n        metadata:\n          labels:\n            app: web-demo\n        spec:\n          containers:\n          - name: web-demo\n            image: hub.mooc.com/kubernetes/web:v1\n            ports:\n            - containerPort: 8080\n          tolerations:        // 可以部署到有设置taint的机器，也可以部署到其它机器\n          - key: &quot;gpu&quot;\n            operator: &quot;Equal&quot;\n            value: &quot;true&quot;\n            effect: &quot;NoSchedule&quot;</code></pre><blockquote>\n<p>典型的使用kubeadm部署和初始化的Kubernetes集群，master节点被设置了一个node-role.kubernetes.io/master:NoSchedule的污点，可以使用kubectl describe node <node-name>命令查看<br>这个污点表示默认情况下master节点将不会调度运行Pod，即不运行工作负载, 对于使用二进制手动部署的集群设置和移除这个污点的命令如下:</p>\n</blockquote>\n<pre><code>$ kubectl taint nodes &lt;node-name&gt; node-role.kubernetes.io/master=:NoSchedule\n$ kubectl taint nodes &lt;node-name&gt; node-role.kubernetes.io/master:NoSchedule-</code></pre><blockquote>\n<p>kubeadm初始化的Kubernetes集群，master节点也被打上了一个node-role.kubernetes.io/master=的label，标识这个节点的角色为master。给Node设置Label和设置污点是两个不同的操作。设置Label和移除Label的操作命令如下</p>\n</blockquote>\n<p>设置Label</p>\n<pre><code>$ kubectl label node node1 node-role.kubernetes.io/master=</code></pre><p>移除Label</p>\n<pre><code>$ kubectl label node node1 node-role.kubernetes.io/master-</code></pre><h2 id=\"Namespace\"><a href=\"#Namespace\" class=\"headerlink\" title=\"Namespace\"></a>Namespace</h2><blockquote>\n<p>大多数对象的名称必须符合 RFC 1035 （域名）中规定的命名规范 ，这意味着它们可能只包含字母、数字、横杠（－）和点号，但命名空间（和另外几个）不允许包含点号</p>\n</blockquote>\n<h3 id=\"隔离性\"><a href=\"#隔离性\" class=\"headerlink\" title=\"隔离性\"></a>隔离性</h3><blockquote>\n<p>名字的隔离只是 通过svc名称(DNS) 访问的隔离，通过svc的IP和Pod的IP再加上端口号(Port) 照样可以访问不同命名空间下的服务.</p>\n</blockquote>\n<h3 id=\"设置默认命名空间\"><a href=\"#设置默认命名空间\" class=\"headerlink\" title=\"设置默认命名空间\"></a>设置默认命名空间</h3><blockquote>\n<p>默认Kubeclt获取default命名空间下的资源，可以通过设置K8s上下文配置文件如kube.config 使得某个命名空间变为默认namespace，获取pod时候不需要在加上 -n 参数</p>\n</blockquote>\n<h3 id=\"创建命名空间\"><a href=\"#创建命名空间\" class=\"headerlink\" title=\"创建命名空间\"></a>创建命名空间</h3><blockquote>\n<p>namespace不提供网络隔离, 如果命名空间 foo 中的某个 pod 知道命名空间 bar 中 pod 的 IP 地址，那它就可以将流量（例如 HTTP 请求）发送到另一个 pod<br>第一种： commands方式</p>\n</blockquote>\n<pre><code>$ kubectl create namespace custom-namespace\n$ kubectl create ns custom-namespace</code></pre><p>第二种： Yaml方式， 之所以选择使用 YAML 文件，只是为了强化Kubemetes中的所有内容都是一 个 API 对象这一概念</p>\n<pre><code>$ touch custom-namespace.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: custom-namespace\n$ kubectl create -f custom-namespace.yaml</code></pre><h3 id=\"划分方式\"><a href=\"#划分方式\" class=\"headerlink\" title=\"划分方式\"></a>划分方式</h3><pre><code>* 按环境划分: dev(开发), test(测试)\n* 按团队划分\n* 自定义多级划分</code></pre><h3 id=\"标记命名空间\"><a href=\"#标记命名空间\" class=\"headerlink\" title=\"标记命名空间\"></a>标记命名空间</h3><pre><code>$ kubectl label namespace default istio-injection=enabled --overwrite         // enabled\n$ kubectl label namespace default istio-injection=disabled --overwrite        // disabled\n$ kubectl label namespace default istio-injection= --overwrite                // cancel set\nnamespace/default labeled</code></pre><h3 id=\"查看标记-istio-injection-enabled-标签的命名空间\"><a href=\"#查看标记-istio-injection-enabled-标签的命名空间\" class=\"headerlink\" title=\"查看标记 istio-injection=enabled 标签的命名空间\"></a>查看标记 istio-injection=enabled 标签的命名空间</h3><pre><code>$ kubectl get namespace -L istio-injection\nNAME              STATUS   AGE   ISTIO-INJECTION\ndefault           Active   85m   enabled\nistio-system      Active   25m   disabled\nkube-node-lease   Active   85m\nkube-public       Active   85m\nkube-system       Active   85m\n[root@hci-node01 istio-1.5.2]#</code></pre><h3 id=\"删除namespace\"><a href=\"#删除namespace\" class=\"headerlink\" title=\"删除namespace\"></a>删除namespace</h3><p>删除当前命名空间中的所有资源，可以删除ReplicationCcontroller和pod,以及我们创建的所有service<br>第一个 all 指定正在删除所有资源类型, –all 选项指定将删除所有资源实例, 而不是按名称指定它们<br>使用 all 关键字删除所有内容并不是真的完全删除所有内容。 一些资源比如Secret会被保留下来， 并且需要被明确指定删除</p>\n<pre><code>$ kubectl delete all --all        // 命令也会删除名为 kubernetes 的Service, 但它应该会在几分钟后自动重新创建</code></pre><p>可以简单地删除整个命名空间（ pod 将会伴随命名空间 自动删除〉</p>\n<pre><code>$ kubectl delete ns custom-namespace</code></pre><p>强制删除NAMESPACE</p>\n<pre><code>$ kubectl delete namespace NAMESPACENAME --force --grace-period=0</code></pre><p>进入kube-system下得etcd pod 删除需要删除的NAMESPACE</p>\n<pre><code>$ kubectl get po -n kube-system\nNAME                                 READY   STATUS    RESTARTS   AGE\netcd-hci-node01                      1/1     Running   5          16d\n......\n\n$ kubectl exec -it etcd-hci-node01 sh -n kube-system\n$ etcdctl del /registry/namespaces/NAMESPACENAME</code></pre><h2 id=\"POD\"><a href=\"#POD\" class=\"headerlink\" title=\"POD\"></a>POD</h2><h3 id=\"查看pod解释\"><a href=\"#查看pod解释\" class=\"headerlink\" title=\"查看pod解释\"></a>查看pod解释</h3><pre><code>$ kubectl explain pod\nKIND:     Pod\nVERSION:  v1\n\nDESCRIPTION:\n    Pod is a collection of containers that can run on a host. This resource is\n    created by clients and scheduled onto hosts.\n\nFIELDS:\napiVersion   &lt;string&gt;\n    APIVersion defines the versioned schema of this representation of an\n    object. Servers should convert recognized schemas to the latest internal\n    value, and may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\nkind &lt;string&gt;\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\nmetadata     &lt;Object&gt;\n    Standard object&apos;s metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\nspec &lt;Object&gt;\n    Specification of the desired behavior of the pod. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status\n\nstatus       &lt;Object&gt;\n    Most recently observed status of the pod. This data may not be up to date.\n    Populated by the system. Read-only. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status</code></pre><p>深入理解POD属性</p>\n<pre><code>$ kubectl explain pod.apiVersion\n$ kubectl explain pod.kind\n$ kubectl explain pod.spec</code></pre><p>pods 的缩写是 po, service 的缩写是 SVC, replicationcontroller 的缩写 rc</p>\n<pre><code>$ kubectl get pods -n kube-system</code></pre><blockquote>\n<p>我们提到过每个 pod 都有自己的 IP 地址，但是这个地址是集群 内部的，不能从集群外部访问。<br>要让 pod 能够从外部访问 ， 需要通过服务对象公开它， 要创建一个特殊的 LoadBalancer 类型的服务。<br>因为如果你创建一个常规服务（ 一个 Cluster IP 服务）， 比如 pod ，它也 只能从集群内部访问。<br>通过创建 LoadBalanc er 类型 的服务，将创建一个外部的负载均衡 ，可以通过 负载均衡的公共 IP 访问 pod </p>\n</blockquote>\n<h3 id=\"创建POD\"><a href=\"#创建POD\" class=\"headerlink\" title=\"创建POD\"></a>创建POD</h3><p>通过上传 JSON 或 YAML 描述文件到 Kubemetes API 服务器来创建 pod.<br>kubectl create -f 命令用于从YAML或JSON文件创建任何资源（不只是 pod).<br>    $ kubectl create -f kubia-manual.yaml<br>    $ kubectl create -f kubia-gpu.yaml -n custom-namespace    //船舰pod到custom-namespace命名空间下</p>\n<pre><code>$ kubectl describe pod/kubia\n......\nEvents:\nType    Reason     Age    From               Message\n----    ------     ----   ----               -------\nNormal  Scheduled  5m12s  default-scheduler  Successfully assigned default/kubia-liveness to server02\nNormal  Pulling    5m8s   kubelet, server02  Pulling image &quot;luksa/kubia-unhealthy&quot;</code></pre><h3 id=\"pod标签labels\"><a href=\"#pod标签labels\" class=\"headerlink\" title=\"pod标签labels\"></a>pod标签labels</h3><pre><code>$ kubectl get po --show-labels</code></pre><p>查看pod标签的key值为creation_method 和 env 的信息</p>\n<pre><code>$ kubectl get po -L creation_method,env\nNAME                           READY   STATUS    RESTARTS   AGE   CREATION_METHOD   ENV\nkubia                          1/1     Running   0          16h\nkubia-manual-v2                1/1     Running   0          34m   manual            pod</code></pre><p>POD添加标签</p>\n<pre><code>$ kubectl label po kubia  creation_method=manual\nNAME                           READY   STATUS    RESTARTS   AGE   CREATION_METHOD   ENV\nkubia                          1/1     Running   0          16h   manual\nkubia-manual-v2                1/1     Running   0          43m   manual            pod</code></pre><p>更改现有标签, 在更改现有标签时， 需要使用–overwrite选项</p>\n<pre><code>$ kubectl label po kubia-manual-v2 env=debug --overwrite</code></pre><p>使用标签列出POD</p>\n<pre><code>$ kubectl get po -1 creation_method=manual\n$ kubectl get po -l env</code></pre><p>同样列出没有env标签的pod<br>确保使用单引号来圈引 !env, 这样bash shell才不会解释感叹号（译者注：感叹号在bash中有特殊含义， 表示事件指示器)</p>\n<pre><code>$ kubectl get po -l &apos;!env&apos;\ncreation_method!=manual 选择带有creation_method标签， 并且值不等于manual的pod\nenv in (prod, devel)选择带有env标签且值为prod或devel的pod\nenv notin (prod, devel)选择带有env标签， 但其 值不是prod或devel的pod\napp=pc,rel=beta 选择pc微服务的beta版本pod</code></pre><h2 id=\"pod-注解\"><a href=\"#pod-注解\" class=\"headerlink\" title=\"pod 注解\"></a>pod 注解</h2><pre><code>$ kubectl annotate pod kubia-gpu mycompany.com/someannotion=&quot;foo bar&quot;\n$ kubectl describe pod/kubia-gpu\n......\nAnnotations:  mycompany.com/someannotion: foo bar\n......</code></pre><h3 id=\"查看该-pod-的完整描述文件：\"><a href=\"#查看该-pod-的完整描述文件：\" class=\"headerlink\" title=\"查看该 pod 的完整描述文件：\"></a>查看该 pod 的完整描述文件：</h3><pre><code>$ kubectl get po kubia-manual -o yaml    // 获取yaml格式信息\n$ kubect1 get po kubia-manual -o json    // 获取json格式信息</code></pre><h3 id=\"执行pod容器\"><a href=\"#执行pod容器\" class=\"headerlink\" title=\"执行pod容器\"></a>执行pod容器</h3><p>直接执行:</p>\n<pre><code>$ kubectl exec fortioclient-f8d65c6bb-5k4td -c captured date -n twopods</code></pre><p>进入容器执行, 当pod中只有一个容器时可以不加-c参数指定某个容器</p>\n<pre><code>$ kubectl exec fortioclient-f8d65c6bb-5k4td -c captured -i -t /bin/sh -n twopods</code></pre><h3 id=\"容器进程-网络等\"><a href=\"#容器进程-网络等\" class=\"headerlink\" title=\"容器进程, 网络等\"></a>容器进程, 网络等</h3><p>查看进程command完整信息</p>\n<pre><code>$ ps auxwww\n$ pa -ef</code></pre><p>查看网络</p>\n<pre><code>$ netstat -ntlp</code></pre><h3 id=\"查看Pod-svc日志\"><a href=\"#查看Pod-svc日志\" class=\"headerlink\" title=\"查看Pod, svc日志\"></a>查看Pod, svc日志</h3><pre><code>$ kubectl logs pod/istiod-774777b79-ddfk4 -n istio-system\n$ kubectl logs -f pod/&lt;pod_name&gt; #类似tail -f的方式查看(tail -f 实时查看日志文件 tail -f 日志文件log)\n$ kubectl logs svc/istiod -n istio-system\n如果该pod中有其他容器， 可以通过如下命令获取其日志：\n$ kubectl logs kubia-manual -c kubia</code></pre><p>查看容器重启后前一个容器为什么重启的日志信息<br>    $ kubectl logs mypod –previous</p>\n<h3 id=\"部署应用程序\"><a href=\"#部署应用程序\" class=\"headerlink\" title=\"部署应用程序\"></a>部署应用程序</h3><pre><code>$ kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml</code></pre><h3 id=\"重启Pod\"><a href=\"#重启Pod\" class=\"headerlink\" title=\"重启Pod\"></a>重启Pod</h3><pre><code>$ kubectl get pod {podname} -n {namespace} -o yaml | kubectl replace --force -f -</code></pre><h3 id=\"删除Pod\"><a href=\"#删除Pod\" class=\"headerlink\" title=\"删除Pod\"></a>删除Pod</h3><pre><code>$ kubectl delete pod PODNAME -n custom-namespace        // 删除指定命名空间下的POD\n$ kubectl delete po -l creation_method=manual            // 通过标签选择器来删除\n$ kubectl delete po --all -n custom-namespace            // 删除当前命名空间中的所有 pod\n$ kubectl delete all --all -n custom-namespace            // 删除所有pod和svc，系统带的kubernetes服务会过一会重启</code></pre><p>可使用kubectl中的强制删除命令删除POD</p>\n<pre><code>$ kubectl delete pod PODNAME --force --grace-period=0</code></pre><p>直接从ETCD中删除源数据<br>删除default namespace下的pod名为pod-to-be-deleted-0</p>\n<pre><code>$ ETCDCTL_API=3 etcdctl del /registry/pods/default/pod-to-be-deleted-0</code></pre><h2 id=\"livenessProbe-存活探针-readinessProbe\"><a href=\"#livenessProbe-存活探针-readinessProbe\" class=\"headerlink\" title=\"livenessProbe 存活探针, readinessProbe\"></a>livenessProbe 存活探针, readinessProbe</h2><p>Kubemetes 可以通过存活探针 (liveness probe) 检查容器是否还在运行.<br>Kubemetes 可以通过readinessProbe探针 检查容器是否准备完毕可以挂到负载均衡上供外部访问.<br>livenessProbe与readinessProbe探针用法完全一样, 都有三种，下面介绍这三种健康检查方式.</p>\n<p>可以为 pod 中的每个容器单独指定存活探针。 如果探测失败， Kubemetes 将定期执行探针并重新启动容器</p>\n<ul>\n<li>第一种健康检查方式: 执行命令检查存活探针是否存活</li>\n</ul>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-demo\n  namespace: dev\nspec:\n  selector:\n    matchLabels:\n      app: web-demo\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: web-demo\n    spec:\n      selector:\n        matchLabels:\n          app: web-demo\n      replicas: 1\n      template:\n        metadata:\n          labels:\n            app: web-demo\n        spec:\n          containers:\n          - name: web-demo\n            image: hub.mooc.com/kubernetes/web:v1\n            ports:\n            - containerPort: 8080\n            livenessProbe:                // 检查应用是否存活的探针, 和容器一个级别\n              exec:                        // 第一种健康检查方式, 通过执行命令\n                command:\n                - /bin/sh\n                - -c\n                - ps -ef|grep java|grep -v grep\n              initialDelaySeconds: 10        // 容器起来后过10s开始检查\n              periodSeconds: 10                // 每隔10s检查一次\n              failureThreshold: 2            // 连续健康检查失败2次放弃检查, 重启容器\n              successThreshold: 1            // 检查一次满足条件就认为健康检查通过\n              timeoutSeconds: 5                // 每次健康检查delay时间是5s, 超时也认为健康检查失败, 重启容器\n            readinessProbe:                // readinessProbe与livenessProbe用法完全一样.\n              exec:                        // 第一种检查方式, 通过执行命令\n                command:\n                - /bin/sh\n                - -c\n                - ps -ef|grep java|grep -v grep\n              initialDelaySeconds: 10        // 容器起来后过10s开始检查\n              periodSeconds: 10                // 每隔10s检查一次\n              failureThreshold: 2            // 连续健康检查失败2次放弃检查, 重启容器\n              successThreshold: 1            // 检查一次满足条件就认为健康检查通过\n              timeoutSeconds: 5                // 每次健康检查delay时间是5s, 超时也认为健康检查失败, 重启容器</code></pre><ul>\n<li>第二种健康检查方式: 执行网络请求检查存活探针是否存活</li>\n</ul>\n<pre><code>$ touch kubia-liveness-probe.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: kubia-liveness\nspec:\n  containers:\n  - image: luksa/kubia-unhealthy\n    name: kubia\n    livenessProbe:        // 一个 HTTP GET 存活探针\n      httpGet:            // 第二种健康检查方式, 通过httpGet\n        path: /            // 应用要访问的路径\n        port: 8080        // 容器本身启动的端口\n        scheme: HTTP\n      initialDelaySeconds: 15        // 容器起来后过10s开始检查\n      periodSeconds: 5\n\n$ kubectl get pods\nNAME                           READY   STATUS    RESTARTS   AGE\nkubia-liveness                 1/1     Running   1          13m</code></pre><p>查看该pod描述</p>\n<pre><code>$ kubectl describe pod/kubia-liveness\n......\nLast State:     Terminated\n  Reason:       Error\n  Exit Code:    137\n  Started:      Wed, 13 May 2020 15:49:36 +0800\n  Finished:     Wed, 13 May 2020 15:51:25 +0800\nReady:          True\nRestart Count:  1\nLiveness:       http-get http://:8080/ delay=0s timeout=1s period=10s #success=1 #failure=3\n......</code></pre><p>数字137是两个 数字的总和：128+x, 其中x是终止进程的信号编号.<br>在这个例子中，x等于9, 这是SIGKILL的信号编号，意味着这个进程被强行终止.<br>当容器被强行终止时，会创建一个全新的容器—-而不是重启原来的容器.<br>delay=Os部分显示在容器启动后立即开始探测.<br>timeout仅设置为1秒，因此容器必须在1秒内进行响应， 不然这次探测记作失败.<br>每10秒探测一次容器(period=lOs), 并在探测连续三次失败(#failure=3)后重启容器.<br>定义探 针时可以自定义这些附加参数。例如，要设 置初始延迟，请将initialDelaySeconds属性添加到存活探针的配置中.</p>\n<pre><code>    livenessProbe:        // 一个 HTTP GET 存活探针\n      httpGet:\n        path: /\n        port: 8080\n      initialDelaySeconds: 15    // Kubernetes会在第—次探测前等待15秒 \n\n$ kubectl describe pod/kubia-liveness\n......\nLiveness:       http-get http://:8080/ delay=15s timeout=1s period=10s #success=1 #failure=3</code></pre><ul>\n<li>第三种健康检查方式: 通过TCP检查端口是否处于监听状态<pre><code>livenessProbe:        // 一个 HTTP GET 存活探针\n  tcpSocket:\n    port: 8080\n  initialDelaySeconds: 20    // Kubernetes会在第—次探测前等待15秒 \n  periodSeconds: 5</code></pre></li>\n</ul>\n<blockquote>\n<p>如果没有设置初始延迟，探针将在启动时立即开始探测容器， 这通常会导致探测失败， 因为应用程序还没准备好开始接收请求.<br>务必记得设置一个初始延迟未说明应用程序的启动时间.<br>对于在生产中运行的pod, 一定要定义一个存活探针。没有探针的话，Kubemetes无法知道你的应用是否还活着。只要进程还在运行， Kubemetes会认为容器是健康的<br>Kubernetes会在你的容器崩溃或其存活探针失败时， 通过重启容器来保持运行。 这项任务由承载pod的节点上的Kubelet 执行 一— 在主服务器上运行的Kubernetes Control Plane组件不会参与此过程.<br>但如果节点本身崩溃， 那么Control Plane 必须为所有随节点停止运行的pod创建替代品。 它不 会为你直接创建的pod执行此操作 。 这些pod只被Kubelet 管理.</p>\n</blockquote>\n<h3 id=\"查看-readinessProbe-healthProbe\"><a href=\"#查看-readinessProbe-healthProbe\" class=\"headerlink\" title=\"查看 readinessProbe, healthProbe\"></a>查看 readinessProbe, healthProbe</h3><pre><code>$ kubectl edit po -n istio-system istio-ingressgateway-6489d9556d-wjr58\n$ kubectl edit deployment -n istio-system istio-ingressgateway\n$ kubectl logs po/istio-ingressgateway-6489d9556d-wjr58 -n istio-system\n$ kubectl get po -A</code></pre><h3 id=\"affinity\"><a href=\"#affinity\" class=\"headerlink\" title=\"affinity\"></a>affinity</h3><p>匹配Node标签, Pod部署到哪台机器上.</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-demo\n  namespace: dev\nspec:\n  selector:\n    matchLabels:\n      app: web-demo\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: web-demo\n    spec:\n      selector:\n        matchLabels:\n          app: web-demo\n      replicas: 1\n      template:\n        metadata:\n          labels:\n            app: web-demo\n        spec:\n          containers:\n          - name: web-demo\n            image: hub.mooc.com/kubernetes/web:v1\n            ports:\n            - containerPort: 8080\n          affinity:\n            nodeAffinity:        // node亲和性, 要部署到哪台机器，不要部署到哪台机器\n              requiredDuringSchedulingIgnoredDuringExecution:    // 必须满足下面条件才会执行调度\n                nodeSelectorTerms:        // 数组形式, 下面可以定义多个Terms, 它们之间是或的关系\n                - matchExpressions:        // 数组形式, 如果定义多个matchExpressions它们之间是与的关系\n                  - key: beta.kubernetes.io/arch    // 节点的label含有的key名字, 这里的是由K8s根据机器自动生成的\n                    operator: In\n                    values:                // 前提是Node机器有amd64标签K8s才会把容器部署到次Node机器\n                    - amd64                // 通过kubectl get nodes NodeName -o yaml进行查看\n              preferredDuringSchedulingIgnoredDuringExecution:    // 最好是怎样调度\n              - weight: 1                // 权重\n                perference:\n                  matchExpressions:\n                  - key: disktype        // 通过kubectl get nodes --show-labels查看\n                    operator: NotIn\n                    values:\n                    - ssd\n            podAffinity:        // Pod亲和性, 想和哪些Pod部署到一台机器, 不想和哪些Pod部署在一台机器\n              requiredDuringSchedulingIgnoredDuringExecution:\n              - labelSelector:\n                  matchExpressions:\n                  - key: app\n                    operator: In        // 要跟app=web-demo的Pod运行在同一个节点上\n                    values:\n                    - web-demo-node\n                topologyKey: kubernetes.io/hostname        // 节点的label名字\n              preferredDuringSchedulingIgnoredDuringExecution:\n              - weight: 100\n                podAffinityTerm:\n                  labelSelector:\n                    matchExpressions:\n                    - key: app\n                      operator: In\n                      values:\n                      - web-demo-node\n                  topologyKey: kubernetes.io/hostname\n            podAntiAffinity:        // Pod反亲和性, 不想和哪些Pod部署到一台机器, 用法和podAffinity用法完全一样\n            pod反亲和性用的很多的是上面的replicas: 的值 &gt;=2 时候会把容器副本分别部署到不同机器</code></pre><h3 id=\"Pod启动停止控制\"><a href=\"#Pod启动停止控制\" class=\"headerlink\" title=\"Pod启动停止控制\"></a>Pod启动停止控制</h3><p>Pod容器启动时候和停止前所做的事</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-demo\n  namespace: dev\nspec:\n  selector:\n    matchLabels:\n      app: web-demo\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: web-demo\n    spec:\n      selector:\n        matchLabels:\n          app: web-demo\n      replicas: 1\n      template:\n        metadata:\n          labels:\n            app: web-demo\n        spec:\n          containers:\n          - name: web-demo\n            image: hub.mooc.com/kubernetes/web:v1\n            ports:\n            - containerPort: 8080\n            volumeMounts:\n            - name: shared-volume\n              mounthPath: /shared-web\n            lifecycle:                Pod里容器启动前和停止前要做的事\n              postStart:\n                exec:\n                  command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo web starting ... &gt;&gt; /var/log/messages&quot;]\n              preStop:\n                exec:\n                  command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo web stopping ... &gt;&gt; /var/log/messages &amp;&amp; sleep 3&quot;]</code></pre><h2 id=\"ReplicationController\"><a href=\"#ReplicationController\" class=\"headerlink\" title=\"ReplicationController\"></a>ReplicationController</h2><p>一个ReplicationController有三个主要部分<br> • label selector ( 标签选择器）， 用于确定ReplicationController作用域中有哪些pod<br> • replica count (副本个数）， 指定应运行的pod 数量<br> • pod template (pod模板）， 用于创建新的pod 副本<br>使用 ReplicationController 的好处<br> •确保一 个 pod (或多个 pod副本）持续运行， 方法是在现有pod 丢失时启动一个新 pod。<br> • 集群节点发生故障时， 它将为故障节 点 上运 行的所有 pod (即受ReplicationController 控制的节点上的那些 pod) 创建替代副本。<br> • 它能轻松实现 pod的水平伸缩 手动和自动都可以</p>\n<h3 id=\"由RC创建POD\"><a href=\"#由RC创建POD\" class=\"headerlink\" title=\"由RC创建POD\"></a>由RC创建POD</h3><p>kubia-rc.yaml, 内容如下:</p>\n<pre><code>apiVersion: v1\nkind: ReplicationController        // 这里的配置定义了ReplicationController(RC)\nmetadata:\n  name: kubia        // ReplicationController 的名字\nspec:\n  replicas: 3        // pod 实例的目标数目\n  selector:            // selector也可以不写，replica 直接根据下面的template模板里的lables标签选择创建POD\n    app: kubia        // pod 选择器决定了 RC 的操作对象\n  template:            // 从此以下都是创建新 pod 所用的 pod 模板, 与单独创建的pod定义yaml文件内容几乎相同\n    metadata:\n      labels:\n        app: kubia\n    spec:\n      containers:\n      - name: kubia\n        image: luksa/kubia\n        ports:\n        - containerPort: 8080</code></pre><p>创建ReplicationController并由其创建pod</p>\n<pre><code>$ kubectl create -f kubia-rc.yaml\n$ kubectl get po -o wide\nNAME          READY   STATUS    RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES\nkubia-6wnj5   1/1     Running   0          56s   10.44.0.3   server02   &lt;none&gt;           &lt;none&gt;\nkubia-788p8   1/1     Running   0          56s   10.44.0.2   server02   &lt;none&gt;           &lt;none&gt;\nkubia-c9kn6   1/1     Running   0          56s   10.44.0.1   server02   &lt;none&gt;           &lt;none&gt;\n\n$ kubectl delete po kubia-6wnj5\nNAME          READY   STATUS              RESTARTS   AGE\nkubia-6ntgt   0/1     ContainerCreating   0          12s\nkubia-6wnj5   1/1     Terminating         0          3m3s\nkubia-788p8   1/1     Running             0          3m3s\nkubia-c9kn6   1/1     Running             0          3m3s</code></pre><p>上面重新列出pod会显示四个， 因为你删除的pod己终止， 并且己创建一个新的pod<br>虽然ReplicationController会立即收到删除pod的通知 (API 服务器允许客户端监听资源和资源列表的更改），但这不是它创建替代pod的原因。<br>该通知会触发控制器检查实际的pod数量并采取适当的措施.</p>\n<pre><code>$ kubectl get po -o wide\nNAME          READY   STATUS    RESTARTS   AGE     IP          NODE       NOMINATED NODE   READINESS GATES\nkubia-6ntgt   1/1     Running   0          53s     10.44.0.4   server02   &lt;none&gt;           &lt;none&gt;\nkubia-788p8   1/1     Running   0          3m44s   10.44.0.2   server02   &lt;none&gt;           &lt;none&gt;\nkubia-c9kn6   1/1     Running   0          3m44s   10.44.0.1   server02   &lt;none&gt;           &lt;none&gt;</code></pre><h3 id=\"获取有关-ReplicationController-的信息\"><a href=\"#获取有关-ReplicationController-的信息\" class=\"headerlink\" title=\"获取有关 ReplicationController 的信息\"></a>获取有关 ReplicationController 的信息</h3><pre><code>$ kubectl get rc -o wide\n$ kubectl get rc -o wide -n default        // RC是针对某个namespace下做的副本pod控制\nNAME    DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES        SELECTOR\nkubia   3         3         3       17m   kubia        luksa/kubia   app=kubia\n获取RC的详细信息\n$ kubectl describe rc kubia</code></pre><p>如果你更改了 一个 pod 的标签，使它不再 与 ReplicationController 的标签选择器相匹配 ， 那么该 pod 就变得和其他手动创建的 pod 一样了<br>更改 pod 的标签时， ReplicationController 发现一个 pod 丢失了 ， 并启动一个新的pod替换它.</p>\n<p>给其中一个 pod 添加了 type=special 标签，再次列出所有 pod 会显示和以前一样的三个 pod 。 因为从 ReplicationCon位oiler 角度而言， 没发生任何更改.</p>\n<pre><code>$ kubectl label pod/kubia-6ntgt type=special\n$ kubectl get pod --show-labels\nNAME          READY   STATUS    RESTARTS   AGE   LABELS\nkubia-6ntgt   1/1     Running   0          27m   app=kubia,type=special\nkubia-788p8   1/1     Running   0          30m   app=kubia\nkubia-c9kn6   1/1     Running   0          30m   app=kubia</code></pre><p>更改app标签该 pod 不再与 RC 的标签选择器相匹配</p>\n<pre><code>$ kubectl label pod/kubia-6ntgt app=foo --overwrite\n$ kubectl get pod --show-labels\nNAME          READY   STATUS              RESTARTS   AGE   LABELS\nkubia-6ntgt   1/1     Running             0          30m   app=foo,type=special\nkubia-788p8   1/1     Running             0          33m   app=kubia\nkubia-c9kn6   1/1     Running             0          33m   app=kubia\nkubia-dqshz   0/1     ContainerCreating   0          4s    app=kubia</code></pre><p>使用 -L app 选项在列 中显示 app 标签</p>\n<pre><code>$ kubectl get pod -L app\nNAME          READY   STATUS    RESTARTS   AGE     APP\nkubia-6ntgt   1/1     Running   0          32m     foo\nkubia-788p8   1/1     Running   0          35m     kubia\nkubia-c9kn6   1/1     Running   0          35m     kubia\nkubia-dqshz   1/1     Running   0          2m17s   kubia</code></pre><p>可能有一个 bug 导致你的 pod 在特定时间或特定事件后开始出问题。<br>如果你知道某个 pod 发生了故障， 就可以将它从 Replication-Controller 的管理范围中移除， 让控制器将它替换为新 pod, 接着这个 pod 就任你处置了。 完成后删除该pod 即可。</p>\n<h3 id=\"编辑RC的YAML配置\"><a href=\"#编辑RC的YAML配置\" class=\"headerlink\" title=\"编辑RC的YAML配置\"></a>编辑RC的YAML配置</h3><p>用默认文本编辑器中打开ReplicationController的YAML配置，会在/tmp目录生成一个临时yaml文件，退出后/tmp目录下的yaml文件也会删掉<br>如果你想使用nano编辑Kubernetes资源，请执行以下命令（或将其放入 ~/.bashrc或等效文件中）<br>export KUBE_EDITOR=”/usr/bin/nano”</p>\n<pre><code>$ kubectl edit rc kubia\n......\n spec:\n   replicas: 3\n   selector:\n     app: kubia1                 RC selector 修改，需要配合下面的label一起修改\n   template:\n     metadata:\n       creationTimestamp: null\n       labels:\n         app: kubia1             Pod label 修改，需要配合上面的 RC selector 一起修改\n     spec:\n       containers:\n       - image: luksa/kubia\n         imagePullPolicy: Always\n         name: kubia\n         ports:\n         - containerPort: 8080\n           protocol: TCP\n......\n\n$ kubectl get pod\nNAME          READY   STATUS              RESTARTS   AGE   APP\nkubia-279wl   0/1     ContainerCreating   0          2s    kubia1\nkubia-6ntgt   1/1     Running             0          44m   foo\nkubia-788p8   1/1     Running             0          47m   kubia\nkubia-c9kn6   1/1     Running             0          47m   kubia\nkubia-dqshz   1/1     Running             0          14m   kubia\nkubia-m6vml   0/1     Pending             0          2s    kubia1\nkubia-xxjqr   0/1     ContainerCreating   0          2s    kubia1</code></pre><h3 id=\"RC-扩容\"><a href=\"#RC-扩容\" class=\"headerlink\" title=\"RC 扩容\"></a>RC 扩容</h3><p>扩展/缩容 RC管理的pod为5个<br>第一种，commands方式:</p>\n<pre><code>$ kubectl scale rc kubia --replicas=5</code></pre><p>第二种， edit rc yaml文件</p>\n<pre><code>$ kubectl edit rc kubia\n......\nspec:\n  replicas: 5\n......</code></pre><h3 id=\"删除RC\"><a href=\"#删除RC\" class=\"headerlink\" title=\"删除RC\"></a>删除RC</h3><p>当使用 kubectl delete 删除 ReplicationController 时， 可以通过给命令增加 –cascade= false 选项来保持 pod 的运行.</p>\n<pre><code>$ kubectl delete rc kubia --cascade=false</code></pre><p>已经删除了 ReplicationController, 所以这些 pod 独立了， 它们不再被管理。但是你始终可以使用适当的标签选择器创建新的 ReplicationController, 并再次将它们管理起来</p>\n<h2 id=\"ReplicaSet\"><a href=\"#ReplicaSet\" class=\"headerlink\" title=\"ReplicaSet\"></a>ReplicaSet</h2><blockquote>\n<p>最 初， ReplicationController 是用于复制和在异常时重新调度节点的唯 一Kubemetes 组件， 后来又引入了 一个名为 ReplicaSet 的类似资源 。 它是新一代的ReplicationController, 并且将其完全替换掉 (ReplicationController 最终将被弃用）。<br>也就是说从现在起， 你应该始终创建 ReplicaSet 而不是 ReplicationController。 它们几乎完全相同， 所以你不会碰到任何麻烦<br>ReplicaSet 的行为与ReplicationController 完全相同， 但pod 选择器的表达能力更强<br>ReplicationController 都无法仅基千标签名的存在来匹配 pod, 而ReplicaSet 则可以。 例如， ReplicaSet 可匹配所有包含名为 env 的标签的 pod, 无论ReplicaSet 的实际值是什么（可以理解为 env=*)</p>\n</blockquote>\n<p>kubia-replicaset.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: kubia\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: kubia\n  template:\n    metadata:\n      labels:\n        app: kubia\n    spec:\n      containers:\n      - name: kubia\n        image: luksa/kubia\n        ports:\n        - containerPort: 8080</code></pre><p>检查replicaset:</p>\n<pre><code>$ kubectl get rs</code></pre><h3 id=\"matchExpressions选择器\"><a href=\"#matchExpressions选择器\" class=\"headerlink\" title=\"matchExpressions选择器\"></a>matchExpressions选择器</h3><p>创建个yaml文件<br>kubia-replicaset-matchexpressions.yaml</p>\n<pre><code>selector:\n  matchExpressions:\n    - key: app\n      operator: In\n      values:\n        - kubia</code></pre><p>每个表达式都必须 包含一个key, 一个operator (运算符），并且可能还有一个values的列表（取决于 运算符）.<br>• In : Label的值 必须与其中 一个指定的values 匹配。<br>• Notln : Label的值与任何指定的values 不匹配。<br>• Exists : pod 必须包含一个指定名称的标签（值不重要）。使用此运算符时，<br>不应指定 values字段。<br>• DoesNotExist : pod不得包含有指定名称的标签。values属性不得指定<br>如果同时指定matchLabels和matchExpressions, 则所有标签都必须匹配，并且所有表达式必须计算为true以使该pod与选择器匹配.</p>\n<h3 id=\"查看-replicaset-和-deployment-的详细信息\"><a href=\"#查看-replicaset-和-deployment-的详细信息\" class=\"headerlink\" title=\"查看 replicaset 和 deployment 的详细信息\"></a>查看 replicaset 和 deployment 的详细信息</h3><pre><code>$ kubectl describe deployment details-v1\n$ kubectl describe rs details-v1-6fc55d65c9</code></pre><h3 id=\"删除ReplicaSet\"><a href=\"#删除ReplicaSet\" class=\"headerlink\" title=\"删除ReplicaSet\"></a>删除ReplicaSet</h3><p>删除ReplicaSet会删除所有的pod,这种情况下是需要列出pod来确认.</p>\n<pre><code>$ kubectl delete rs kubia</code></pre><h2 id=\"DaemonSet\"><a href=\"#DaemonSet\" class=\"headerlink\" title=\"DaemonSet\"></a>DaemonSet</h2><p>如果节点下线， DaemonSet不会在其他地方重新创建pod。 但是， 当将一个新节点添加到集群中时， DaemonSet会立刻部署一个新的pod实例。<br>如果有人无意中删除了 一个 pod ， 那么它也会重新创建 一个新的 pod。<br>与 ReplicaSet一样，DaemonSet 从配置的 pod 模板创建 pod.</p>\n<blockquote>\n<p>如果节点可以被设置为不可调度的 ， 防止 pod 被部署到节点上. DaemonSet 甚至会将 pod 部署到这些节点上，因为无法调度的属性只会被调度器使用，而 DaemonSet 管理的 pod 则完全绕过调度器. 这是预期的，因为DaemonSet的目的是运行系统服务，即使是在不可调度的节点上，系统服务通常也需要运行.</p>\n</blockquote>\n<p>给node节点打上label</p>\n<pre><code>$ kubectl label node server02 disk=ssd</code></pre><p>ssd-monitor-daemonset.yaml</p>\n<pre><code>apiVersion: apps/v1            // DaemooSet在apps的API组 中，版本是v1\nkind: DaemonSet\nmetadata:\n  name: ssd-monitor\nspec:\n  selector:\n    matchLabels:\n      app: ssd-monitor\n  template:\n    metadata:\n      labels:\n        app: ssd-monitor\n    spec:\n      nodeSelector:            // pod模板包含 会选择有disk=ssd标签的节点 一个节点选择器\n        disk: ssd\n      containers:\n      - name: main\n        image: luksa/ssd-monitor\n\n$ kubectl create -f ssd-monitor-daemonset.yaml</code></pre><h3 id=\"查看DaemonSet\"><a href=\"#查看DaemonSet\" class=\"headerlink\" title=\"查看DaemonSet\"></a>查看DaemonSet</h3><pre><code>$ kubectl get ds\nNAME          DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE     CONTAINERS   IMAGES              SELECTOR\nssd-monitor   1         1         1       1            1           disk=ssd        3m29s   main         luksa/ssd-monitor   app=ssd-monitor</code></pre><p>如果你有多个节点并且其他的节点也加上了同样的标签，将会看到 DaemonSet 在每个节点上都启动 pod.<br>给其中一个节点修改标签disk=hdd, 假设它的硬盘换成磁盘而不是SSD, 那个节点上的pod会如预期中被终止.<br>如果还有其他的 pod在运行， 删除 DaemonSet 也会一起删除这些 pod。</p>\n<h3 id=\"删除ds\"><a href=\"#删除ds\" class=\"headerlink\" title=\"删除ds\"></a>删除ds</h3><p>删除ds会删除由ds控制schedule到每个节点的pod</p>\n<pre><code>$ kubectl delete ds ssd-monitor</code></pre><h2 id=\"Job资源\"><a href=\"#Job资源\" class=\"headerlink\" title=\"Job资源\"></a>Job资源</h2><p>Kubemetes 通过 Job 资源提供了对此的支持，它允许你运行一种 pod, 该 pod 在内部进程成功结束时， 不重启容器。<br>一旦任务完成， pod 就被认为处于完成状态.<br>由Job管理的pod会一直被重新安排，直到它们成功完成任务.</p>\n<p>exporter.yaml</p>\n<pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: batch-job\nspec:\n  template:\n    metadata:\n      labels:\n        app: batch-job\n    spec:\n      restartPolicy: OnFailure        // 默认为Always,Job pod不能使用默认策略， 因为它们不是要无限期地运行\n      containers:\n      - name: main\n        image: luksa/batch-job        // 运行luksa/batch-job镜像，该镜像调用 一个运行120秒的进程，然后退出</code></pre><p>需要明确地将重启策略 restartPolicy 设置为 OnFailure 或 Never。 此设置防止容器在完成任务时重新启动</p>\n<pre><code>$ kubectl create -f exporter.yaml\n\n$ kubectl get pod\nNAME                READY   STATUS    RESTARTS   AGE\nbatch-job-lhnfg     1/1     Running   0          113s\n\n$ kubectl get jobs\nNAME        COMPLETIONS   DURATION   AGE\nbatch-job   0/1           111s       111s</code></pre><p>等待两三分钟后</p>\n<pre><code>$ kubectl get pod\nNAME                READY   STATUS      RESTARTS   AGE\nbatch-job-lhnfg     0/1     Completed   0          3m21s\n\n$ kubectl get job\nNAME        COMPLETIONS   DURATION   AGE\nbatch-job   1/1           2m41s      3m27s</code></pre><p>完成后pod未被删除的原因是允许你查阅其日志</p>\n<pre><code>$ kubectl logs po/batch-job-lhnfg\nThu May 14 05:04:38 UTC 2020 Batch job starting\nThu May 14 05:06:38 UTC 2020 Finished succesfully</code></pre><p>pod 可以被直接删除， 或者在删除创建它的Job时被删除<br>作业可以配置为创建多个pod实例，并以并行或串行方式运行它们<br>在Job配置中设置 completions和parallelism属性来完成的<br>如果你需要 一个Job运行多次，则可以将comple巨ons设为你希望作业的pod运行多少次</p>\n<pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: multi-completion-batch-job\nspec:\n  completions: 5    // job将一个接一个地运行五个pod\n  parallelism: 2    // 最多两个pod可以并行运行\n  template:\n    metadata:\n      labels:\n        app: batch-job\n    spec:\n      restartPolicy: OnFailure\n      containers:\n      - name: main\n        image: luksa/batch-job</code></pre><p>它最初创建一个pod, 当pod的容器运行完成时，它创建第二个pod, 以此类推，直到五个pod成功完成。<br>如果其中 一个pod发生故障，工作会创建一个新的pod, 所以Job总共可以创建五个以上的pod.</p>\n<pre><code>$ kubectl create -f multi-completion-batch-job.yaml\nNAME                               READY   STATUS              RESTARTS   AGE\nmulti-completion-batch-job-8kzd5   0/1     ContainerCreating   0          4s\nmulti-completion-batch-job-9rnxs   0/1     ContainerCreating   0          4s</code></pre><p>只要其中 一个pod完成任务，工作将运行下 一个pod, 直到五个pod都成功完成任务.</p>\n<pre><code>kubectl get po\nNAME                               READY   STATUS    RESTARTS   AGE\nmulti-completion-batch-job-8kzd5   1/1     Running   0          2m8s\nmulti-completion-batch-job-9rnxs   1/1     Running   0          2m8s\n\n$ kubectl get job\nNAME                         COMPLETIONS   DURATION   AGE\nmulti-completion-batch-job   0/5           2m13s      2m13s</code></pre><p>POD虽然创建，但是POD里的进程任务还没有完成，因此job显示任然是0/5没有一个pod任务完成<br>再等待一会时间</p>\n<pre><code>$ kubectl get po\nNAME                               READY   STATUS      RESTARTS   AGE\nmulti-completion-batch-job-8kzd5   0/1     Completed   0          4m18s\nmulti-completion-batch-job-9rnxs   0/1     Completed   0          4m18s\nmulti-completion-batch-job-blntb   1/1     Running     0          107s\nmulti-completion-batch-job-qhsr5   1/1     Running     0          92s\nssd-monitor-jbhpd                  1/1     Running     0          176m\n\n$ kubectl get job\nNAME                         COMPLETIONS   DURATION   AGE\nmulti-completion-batch-job   2/5           4m16s      4m16s</code></pre><p>如上显示已经有2个POD任务完成，POD退出.<br>甚至可以在 Job 运行时更改 Job 的 parallelism 属性, command如下，实验环境没有成功使用</p>\n<pre><code>$ kubectl scale job multi-completion-batch-job --replicas 3</code></pre><blockquote>\n<p>通过在 pod 配置中设置 activeDeadlineSeconds 属性，可以限制 pod的时间。如果 pod 运行时间超过此时间， 系统将尝试终止 pod, 并将 Job 标记为失败。<br>通过指定 Job manifest 中的 spec.backoff巨m辽字段， 可以配置 Job在被标记为失败之前可以重试的次数。 如果你没有明确指定它， 则默认为6</p>\n</blockquote>\n<h3 id=\"删除job\"><a href=\"#删除job\" class=\"headerlink\" title=\"删除job\"></a>删除job</h3><p>删除job时，由job创建的pod也被直接删除</p>\n<pre><code>$ kubectl delete job multi-completion-batch-job</code></pre><h2 id=\"CornJob-资源\"><a href=\"#CornJob-资源\" class=\"headerlink\" title=\"CornJob 资源\"></a>CornJob 资源</h2><blockquote>\n<p>批处理任务需要在特定的时间运行，或者在指定的时间间隔内重复运行,在 Linux 和类 UNIX 操作系统中， 这些任务通常被称为 cron 任务。 Kubemetes 也支持这种任务<br>Kubemetes 中的 cron 任务通过创建 CronJob 资源进行配置, 运行任务的时间表以知名的 cron 格式指定<br>时间表从左到右包含以下五个条目<br>• 分钟<br>• 小时<br>• 每月中的第几天<br>• 月<br>• 星期几</p>\n</blockquote>\n<p>创建资源文件(kube API 对象文件)cronjob.yaml</p>\n<pre><code>apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: batch-job-every-fifteen-minutes\nspec:\n  schedule: &quot;0,15,30,55 * * * *&quot;\n  startingDeadlineSeconds: 15    // pod最迟必须在预定时间后15秒开始运行， 如果因为任何原因到该启动时间15s后仍不启动，任务将不会运行，并将显示为Failed\n  jobTemplate:\n    spec:\n      template:\n        metadata:\n          labels:\n            app: periodic-batch-job\n        spec:\n          restartPolicy: OnFailure\n          containers:\n          - name: main\n            image: luksa/batch-job</code></pre><blockquote>\n<p>希望每 15 分钟运行一 次任务因此 schedule 字段的值应该是”0, 15, 30, 45****” 这意味着每小时的 0 、 15 、 30和 45 分钟（第一个星号），每月的每一天（第二个星号），每月（第三个星号）和每周的每一天（第四个星号）。<br>相反，如果你希望每隔 30 分钟运行一 次，但仅在每月的第一天运行，则应将计划设置为 “0,30 * 1 * *”, 并且如果你希望它每个星期天的 3AM 运行，将它设置为 “0 3 * * 0” (最后一个零代表星期天）。</p>\n</blockquote>\n<h3 id=\"查看cronjob\"><a href=\"#查看cronjob\" class=\"headerlink\" title=\"查看cronjob\"></a>查看cronjob</h3><pre><code>$ kubectl get cronjob -o wide\nNAME                              SCHEDULE             SUSPEND   ACTIVE   LAST SCHEDULE   AGE    CONTAINERS   IMAGES            SELECTOR\nbatch-job-every-fifteen-minutes   0,15,30,55 * * * *   False     0        18m             112m   main         luksa/batch-job   &lt;none&gt;</code></pre><h3 id=\"cronjob运行状态\"><a href=\"#cronjob运行状态\" class=\"headerlink\" title=\"cronjob运行状态\"></a>cronjob运行状态</h3><pre><code>$ kubectl get po\nNAME                                               READY   STATUS      RESTARTS   AGE\nbatch-job-every-fifteen-minutes-1589439300-4v8wd   0/1     Completed   0          36m\nbatch-job-every-fifteen-minutes-1589439600-99pns   0/1     Completed   0          31m\nbatch-job-every-fifteen-minutes-1589440500-vs5vm   0/1     Completed   0          16m\nbatch-job-every-fifteen-minutes-1589441400-52rzb   1/1     Running     0          112s\n\n$ kubectl get job\nNAME                                         COMPLETIONS   DURATION   AGE\nbatch-job-every-fifteen-minutes-1589439300   1/1           2m24s      36m\nbatch-job-every-fifteen-minutes-1589439600   1/1           2m24s      31m\nbatch-job-every-fifteen-minutes-1589440500   1/1           2m22s      16m\nbatch-job-every-fifteen-minutes-1589441400   0/1           116s       116s</code></pre><p>再过一点时间查看</p>\n<pre><code>$ kubectl get po\nNAME                                               READY   STATUS      RESTARTS   AGE\nbatch-job-every-fifteen-minutes-1589439600-99pns   0/1     Completed   0          32m\nbatch-job-every-fifteen-minutes-1589440500-vs5vm   0/1     Completed   0          17m\nbatch-job-every-fifteen-minutes-1589441400-52rzb   0/1     Completed   0          2m34s\n\n$ kubectl get job\nNAME                                         COMPLETIONS   DURATION   AGE\nbatch-job-every-fifteen-minutes-1589439600   1/1           2m24s      32m\nbatch-job-every-fifteen-minutes-1589440500   1/1           2m22s      17m\nbatch-job-every-fifteen-minutes-1589441400   1/1           2m20s      2m37s</code></pre><p>总结: CornJob过指定的时间执行一次POD，执行完退出，会保留三个POD和Job记录.</p>\n<h3 id=\"删除cronjob\"><a href=\"#删除cronjob\" class=\"headerlink\" title=\"删除cronjob\"></a>删除cronjob</h3><p>运行中的 Job 将不会被终止，不会删除 Job 或 它们的 Pod。为了清理那些 Job 和 Pod，需要列出该 Cron Job 创建的Job，然后删除它们.</p>\n<pre><code>$ batch-job-every-fifteen-minutes\ncronjob.batch &quot;batch-job-every-fifteen-minutes&quot; deleted</code></pre><h2 id=\"secret\"><a href=\"#secret\" class=\"headerlink\" title=\"secret\"></a>secret</h2><pre><code>$ kubectl get secret -n default\nNAME                  TYPE                                  DATA   AGE\ndefault-token-gtcjx   kubernetes.io/service-account-token   3      32d\n\n$ kubectl get pods -o wide\nNAME                               READY   STATUS    RESTARTS   AGE     IP           NODE         NOMINATED NODE   READINESS GATES\nwordpress-7bfc545758-vtfvm         1/1     Running   5          10d     10.36.0.10   hci-node04   &lt;none&gt;           &lt;none&gt;\nwordpress-mysql-764fc64f97-sjnjk   1/1     Running   0          10d     10.36.0.8    hci-node04   &lt;none&gt;           &lt;none&gt;\n\n$ kubectl get po/wordpress-7bfc545758-vtfvm -o yaml\n......\nspec:\n  containers:\n  - env:\n    volumeMounts:\n    - mountPath: /var/www/html\n      name: wordpress-persistent-storage\n    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\n      name: default-token-gtcjx\n      readOnly: true\n......\n  volumes:\n  - name: wordpress-persistent-storage\n    persistentVolumeClaim:\n      claimName: wp-pv-claim\n  - name: default-token-gtcjx\n    secret:\n      defaultMode: 420        // 访问权限\n      secretName: default-token-gtcjx\n......</code></pre><p>进入wordpress-7bfc545758-vtfvm所在机器的容器里查看/var/run/secrets/kubernetes.io/serviceaccount路径文件</p>\n<pre><code>$ docker exec -it daec0458a397 /bin/sh\n# ls /var/run/secrets/kubernetes.io/serviceaccount\n  ca.crt  namespace  token</code></pre><h3 id=\"创建自己的Secret\"><a href=\"#创建自己的Secret\" class=\"headerlink\" title=\"创建自己的Secret\"></a>创建自己的Secret</h3><p>serviceAccount 用来跟Apiserver通信，用来授权, 可以创建自己的Secret<br>编写Secret配置文件 secret.yaml</p>\n<pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: dbpass\ntype: Opaque        // 不透明，浑浊的.\ndata:\n  username: aW1vb2M=        // base64加密的用户名\n  passwd: aW1vb2MxMjM=        // base64加密的密码</code></pre><p>把字符串生成base64很简单，命令如下</p>\n<pre><code>$ echo -n imooc | base64    // -n 表示换行\naW1vb2M=</code></pre><p>编写Pod资源配置文件 pod-secret.yaml</p>\n<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-secret\nspec:\n  containers:\n  - name: springbook-web\n    image: hub.mooc.com/kubernetes/springboot-web:v1\n    ports:\n    - containerPort: 8080\n    volumeMounts:\n    - name: db-secret\n      mountPath: /db-secret\n      readOnly: true\n  volumes:\n  - name: db-secret\n    projected:\n      sources:            // secret 来源\n      - secret:\n        name: dbpass    // secret 名字</code></pre><p>生成Pod并进入查看</p>\n<pre><code>$ / # cd /db-secret/\n$ ls\n  passwd username\n$ cat -n username        // 查看容器里存放的是base64解码过的数据\n  immoc\n$ cat -n passwd\n  imooc123</code></pre><p>可以通过修改secret.yaml文件修改secret账号密码等再$ kubectl apply -f secret.yaml来更改密码.</p>\n<h2 id=\"Configmap\"><a href=\"#Configmap\" class=\"headerlink\" title=\"Configmap\"></a>Configmap</h2><blockquote>\n<p>configmap常用来存储不需要加密的数据, 比如应用的启动参数，一些参数的配置等</p>\n</blockquote>\n<ul>\n<li>第一种向k8s添加很多key value的键值对属性值，就可以用configmap</li>\n</ul>\n<pre><code>$ touch game.properties\n$ vim game.properties\n  enemies=aliens\n  lives=3\n  enemies.cheat=true\n  secret.code.allowed=true\n  ......</code></pre><p>配置到K8S里</p>\n<pre><code>$ kubectl create configmap web-game --from-file game.properties\n$ kubectl get cm</code></pre><p>使用configmap, Pod-game.yaml</p>\n<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-game\nspec:\n  containers:\n  - name: web\n    image: hub.mooc.com/kubernetes/springboot-web:v1\n    ports:\n    - containerPort: 8080\n    volumeMounts:\n    - name: game\n      mountPath: /etc/config/game\n      readOnly: true\n  volumes:\n  - name: game\n    configMap:\n      name: web-game</code></pre><p>生成Pod并进入查看</p>\n<pre><code>$ cd /etc/config/game\n$ ls\n  game.properties\n$ cat game.properties\n  enemies=aliens\n  lives=3\n  enemies.cheat=true\n  secret.code.allowed=true\n  ......</code></pre><p>可以通过kubectl edit 修改configMap账号密码等</p>\n<pre><code>$ kubectl edit cm web-game -o yaml\n  enemies.cheat=false    //等等操作</code></pre><ul>\n<li>第二种配置文件方式创建configMap<br>configmap.yaml</li>\n</ul>\n<pre><code>apeVersion: v1\nkind: Configmap\nmetadata:\n  name: configs\ndata:\n  Java_OPTS: -Xms1024m\n  LOG_LEVEL: DEBUG\n\n$ kubectl create -f configmap.yaml</code></pre><p>编写资源配置文件pod-env.yaml</p>\n<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-env\nspec:\n  containers:\n  - name: web\n    image: hub.mooc.com/kubernetes/springboot-web:v1\n    ports:\n    - containerPort: 8080\n    env:\n      - name: LOG_LEVEL_CONFIG\n        valueFrom:\n          configMapKeyRef:\n            name: configs        // 指定configMap名字\n            key: LOG_LEVEL        // configs下面的LOG_LEVEL</code></pre><p>进入容器查看环境变量</p>\n<pre><code>$ env | grep LOG\n  LOG_LEVEL_CONFIG=DEBUG</code></pre><p>之后次容器就可以通过环境变量获取值</p>\n<ul>\n<li>第三种 通过命令行方式传进参数<br>也是先跟第二种一样创建configMap资源</li>\n</ul>\n<pre><code>$ kubectl create -f configmap.yaml</code></pre><p>编写资源配置文件pod-cmd.yaml</p>\n<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-cmd\nspec:\n  containers:\n  - name: web\n    image: hub.mooc.com/kubernetes/springboot-web:v1\n    command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;java -jar /springboot-web.jar -DJAVA_OPTS=$(JAVA_OPTS)&quot;]\n    ports:\n    - containerPort: 8080\n    env:\n      - name: Java_OPTS\n        valueFrom:\n          configMapKeyRef:\n            name: configs        // 指定configMap名字\n            key: Java_OPTS        // configs下面的LOG_LEVEL</code></pre><p>进入容器查看进程</p>\n<pre><code>$ ps -ef\n  java -jar /springboot-web.jar -DJAVA_OPTS=-Xms1024m</code></pre><h2 id=\"downwardAPI\"><a href=\"#downwardAPI\" class=\"headerlink\" title=\"downwardAPI\"></a>downwardAPI</h2><p>downwardAPI主要作用是在程序中取得Pod对象本身的一些相关信息<br>pod-downwardapi.yaml</p>\n<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-downwardapi\n  labels:\n    app： downwardapi\n    type: webapp\nspec:\n  containers:\n  - name: web\n    image: hub.mooc.com/kubernetes/springboot-web:v1\n    ports:\n    - containerPort: 8080\n    volumeMounts:\n      - name: podinfo\n        mountPath: /etc/podinfo\n  volumes:\n    - name: podinfo\n      projected:\n        sources:\n        - downwardAPI:\n          items:\n            - path: &quot;labels&quot;\n              fieldRef:\n                fieldPath: metadata.labels\n            - path: &quot;name&quot;\n              fieldRef:\n                fieldPath: metadata.name\n            - path: &quot;namespace&quot;\n              fieldRef:\n                fieldPath: metadata.namespace\n            - path: &quot;mem-request&quot;\n              resourceFieldRef:\n                containerName: web\n                resource: limits.memory</code></pre><p>进入容器查看文件信息</p>\n<pre><code>$ cd /etc/podinfo\n$ ls -l\n  labels mem-request name namespace\n$ cat -n labels\n  app=&quot;downwardapi&quot;\n  type=&quot;webapp&quot;\n$ cat -n namespace\n  default\n$ cat -n name\n  pod-downwardapi</code></pre>"},{"title":"05 Kubernetes volumes","_content":"\n## volumes\n> 我们可能希望新的容器可以在之前容器结束的位置继续运行，比如在物理机上重启进程。 可能不需要（或者不想要）整个文件系统被持久化， 但又希望能保存实际数据的目录\n> 在 pod 启动时创建卷， 并在删除 pod 时销毁卷. 在容器重新启动期间， 卷的内容将保持不变， 在重新启动容器之后， 新容器可以识别前一个容器写入卷的所有文件。 另外，如果一个 pod 包含多个容器， 那这个卷可以同时被所有的容器使用\n\nKubernetes 的卷是 pod 的一个组成部分， 因此像容器一样在 pod 的规范中就定义了。 \n它们不是独立的 Kubernetes 对象， 也不能单独创建或删除。 \npod 中的所有容器都可以使用卷， 但必须先将它挂载在每个需要访问它的容器中。 在每个容器中， 都可以在其文件系统的任意位置挂载卷\n卷类型\n * emptyDir 用于存储临时数据的简单空目录\n * gitRepo 通过检出Git仓库的内容来初始化的卷\n * hostPath 用于将目录从工作节点的文件系统挂载到pod中\n * configMap、secret、downwardAPI 用于将 Kubemetes 部分资源和集群信息公开给 pod 的特殊类型的卷 \n ......\n\nfortune-pod.yaml\n\n\tapiVersion: v1\n\tkind: Pod\n\tmetadata:\n\t  name: fortune\n\tspec:\n\t  containers:\n\t  - image: luksa/fortune\n\t    name: html-generator\n\t    volumeMounts:\n\t    - name: html\n\t      mountPath: /var/htdocs\n\t  - image: nginx:alpine\n\t    name: web-server\n\t    volumeMounts:\n\t    - name: html\n\t      mountPath: /usr/share/nginx/html\n\t      readOnly: true\n\t    ports:\n\t    - containerPort: 80\n\t      protocol: TCP\n\t  volumes:\n\t  - name: html\n\t    emptyDir: {}\n作为卷来使用的 emptyDir 是在承载 pod 的工作节点的实际磁盘上创建的，因此其性能取决于节点的磁盘类型。\n也可以通知 Kubemetes 在 tmfs 文件系统(存在内存而非硬盘)上创建 emptyDir. 因此，将 emptyDir 的 medium 设置为Memory\n\n\t  volumes:\n\t  - name: html\n\t    emptyDir\n\t      medium: Memory\n创建pod\n\n\t$ kubectl create -f fortune-pod.yaml\n\n\t$ kuberctl port-forward fortune 8080:80\n\tForwarding from 127.0.0.1:8080 -> 80\n\tForwarding from [::1]:8080 -> 80\n\tHandling connection for 8080\n\t......\n查看 pod 描述\n\n\t$ kubectl describe po/fortune\n\t......\n\tContainers:\n\thtml-generator:\n\t......\n\t  Mounts:\n\t    /var/htdocs from html (rw)\n\t    /var/run/secrets/kubernetes.io/serviceaccount from default-token-b79jt (ro)\n\t......\n\tVolumes:\n\t  html:\n\t    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)\n\t    Medium:     Memory\n\t    SizeLimit:  <unset>\n\t  default-token-b79jt:\n\t    Type:        Secret (a volume populated by a Secret)\n\t    SecretName:  default-token-b79jt\n\t    Optional:    false\n\t......\n\n测试访问两种方式:\n\n * 第一种浏览器访问:\n浏览器输入 [http://127.0.0.1:8080](http://127.0.0.1:8080) 或 [http://localhost:8080](http://localhost:8080)\n即可看到每过10s按F5刷新一次HTML页面内容都不一样\n\n * 第二种 curl 或 wget 访问\n不去掉公司的proxy访问命令里加上 noproxy\n\n\n\t$ curl http://127.0.0.1:8080 --noproxy \"*\"\t// \"*\" 对所有路径的访问都不经过配置的proxy\n也可以去掉公司的proxy, 需要先执行 $ export http_proxy= 把公司的proxy去掉\n再执行如下命令即可访问\n\n\n\t$ curl -s http://127.0.0.1:8080\n\t$ curl -s http://localhost:8080\n\t$ wget http://127.0.0.1:8080\n\n开启两个终端进入这两个container，每过10s分别运行如下各自container里的cat html命令，发现HTML内容不断变化但两个容器的html内容一样\n如果打开浏览器，发现浏览器输出跟这两个container里相应路径下html的内容都是一样同步变化的\n\n\t$ kubectl exec po/fortune -c web-server -it -- sh\n\t$ cat /usr/share/nginx/html/index.html\n\n\t$ kubectl exec po/fortune -c html-generator -it -- sh\n\t$ cat /var/htdocs/index.html\n\n\n## gitRepo 卷\n> gitRepo 容器就像 emptyDir 卷一样， 基本上是一个专用目录， 专门用于包含卷的容器并单独使用。 当 pod 被删除时， 卷及其内容被删除。 然而， 其他类型的卷并不创建新目录， 而是将现有的外部目录挂载到 pod 的容器文件系统中.\n> 使用对应私有 Git repo 的 gitRepo 卷， 其实不可行。 Kubemetes 开发入员的共识是保待 gitRepo 卷的简单性， 而不添加任何通过 SSH 协议克隆私有存储库的支待， 因为这需要向 gitRepo 卷添加额外的配置选项。如果想要将私有的 Git repo 克隆到容器中， 则应该使用 gitsync sidecar 或类似的方法， 而不是使用 gitRepo 卷.\n\n## hostPath 卷\n> hostPath 卷指向节点文件系统上的特定文件或目录,在同一个节点上运行并在其 hostPath 卷中使用相同路径的 pod 可以看到相同的文件.\n> 持久性存储, 因为gitRepo 和 emptyDir 卷的内容都会在 pod 被删除时被删除， 而 hostPath 卷的内容则 不会被删除.\n> 如果删除了一个pod, 并且下一个 pod 使用了指向主机上相同路径的hostPath 卷， 则新 pod 将会发现上一个 pod 留下的数据， 但前提是必须将其调度到与第一个 pod 相同的节点上.\n> 不应该使用hostPath 卷作为存储数据库数据的目录. 因为卷的内容存储在特定节点的文件系统中, 当数据库 pod 被重新安排在另一个节点时， 会找不到数据, 这会使 pod 对预定规划的节点很敏感\n> 请记住仅当需要在节点上读取或写入系统文件时才使用 hos七Path, 切勿使用它们来持久化跨 pod的数据.\n\n\t$ kubectl get pods -n kube-system\n\tNAME                                  READY   STATUS    RESTARTS   AGE\n\t......\n\tkube-apiserver-master-node            1/1     Running   5          2d20h\n\t......\n\n\t$ kubectl describe po/kube-apiserver-master-node -n kube-system\n\t......\n\tContainers:\n\t  kube-apiserver:\n\t  ......\n\t  Mounts:\n\t    /etc/kubernetes/pki from k8s-certs (ro)\n\t    /etc/pki from etc-pki (ro)\n\t    /etc/ssl/certs from ca-certs (ro)\n\t......\n\tVolumes:\n\t  ca-certs:\n\t    Type:          HostPath (bare host directory volume)\n\t    Path:          /etc/ssl/certs\n\t    HostPathType:  DirectoryOrCreate\n\t  etc-pki:\n\t    Type:          HostPath (bare host directory volume)\n\t    Path:          /etc/pki\n\t    HostPathType:  DirectoryOrCreate\n\t  k8s-certs:\n\t    Type:          HostPath (bare host directory volume)\n\t    Path:          /etc/kubernetes/pki\n\t    HostPathType:  DirectoryOrCreate\nPod使用三个HostPath卷来访问宿主主机的/etc/ssl/certs, /etc/pki, /etc/kubernetes/pki三个目录.\n\n\n## PV & PVC & storageclass(sc)\n> 在 Kubemetes 集群中为了使应用能够正常请求存储资源， 同时避免处理基础设施细节， 引入了两个新的资源， 分别是待久卷和持久卷声明. 这名字可能有点误导，因为正如在前面看到的， 甚至常规的 Kubemetes 卷 也可以用来存储持久性数据\n> 在 pod 中使用 PersistentVolume (持久卷， 简称 PV) 要比使用常规的 pod 卷复杂一些\n> 研发人员无须向他们的 pod 中添加特定技术的卷， 而是由集群管理员设置底层存储， 然后通过 Kubernetes API 服务器创建持久卷并注册。 在创建持久卷时， 管理员可以指定其大小和所支持的访问模式.\n> 当集群用户需要在其 pod 中使用持久化存储时， 他们首先创建持久卷声明(PersistentVolumeClaim, 简称 PVC) 清单， 指定所需要的最低容量要求和访问模式，然后用户将待久卷声明清单提交给 Kubernetes API 服务器， Kubernetes 将找到可匹配的待久卷并将其绑定到持久卷声明\n> 持久卷声明可以当作 pod 中的一个卷来使用， 其他用户不能使用相同的持久卷，除非先通过删除持久卷声明绑定来释放.\n![](PV_PVC.PNG)\n\n\t$ kubectl get pv\n\n\t$ kubectl get pvc -n default\n\tNAME             STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS      AGE\n\tmysql-pv-claim   Bound    pvc-522c119b-a968-4a86-ae6c-521b64b775ee   20Gi       RWO            rook-ceph-block   5d2h\n\twp-pv-claim      Bound    pvc-4b83da7a-4552-4806-9f68-af96d4a56d96   20Gi       RWO            rook-ceph-block   5d2h\n\n\t$ kubectl get sc\t// storageclass的简写(sc)\n\n\n\n## Additional:\n## CephFS example\n\n创建CephFS\n\n\tapiVersion: ceph.rook.io/v1\n\tkind: CephFilesystem\n\tmetadata:\n\t  name: myfs\n\t  namespace: rook-ceph\n\tspec:\n\t  metadataPool:\n\t    replicated:\n\t      size: 3\n\t  dataPools:\n\t    - replicated:\n\t        size: 3\n\t  preservePoolsOnDelete: true\n\t  metadataServer:\n\t    activeCount: 1\n\t    activeStandby: true\n\n创建sc(StorageClass), sc是不需要提前创建好PV, 而是根据PVC需求动态创建PV.\n\n\tapiVersion: storage.k8s.io/v1\n\tkind: StorageClass\n\tmetadata:\n\t  name: rook-cephfs\n\t# Change \"rook-ceph\" provisioner prefix to match the operator namespace if needed\n\tprovisioner: rook-ceph.cephfs.csi.ceph.com\n\t  parameters:\n\t  # clusterID is the namespace where operator is deployed.\n\t  clusterID: rook-ceph\n\t  \n\t  # CephFS filesystem name into which the volume shall be created\n\t  fsName: myfs\n\t  \n\t  # Ceph pool into which the volume shall be created\n\t  # Required for provisionVolume: \"true\"\n\t  pool: myfs-data0\n\t  \n\t  # Root path of an existing CephFS volume\n\t  # Required for provisionVolume: \"false\"\n\t  # rootPath: /absolute/path\n\t  \n\t  # The secrets contain Ceph admin credentials. These are generated automatically by the operator\n\t  # in the same namespace as the cluster.\n\t  csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner\n\t  csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph\n\t  csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node\n\t  csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph\n\t  \n\treclaimPolicy: Delete\n\n\n创建PVC和deployment\n> PV 是K8S全局资源\n> PVC 是指定在某个Namespace下的K8S资源, 如果PVC访问属性为ReadWriteMany， 多个不同Pod挂载此相同的PVC到容器指定目录, 该目录将共享文件\n> 多个不同Pod挂载不同的PVC到容器指定目录，则文件不能共享\n\n\tapiVersion: v1\n\tkind: PersistentVolumeClaim\n\tmetadata:\n\t  name: my-pvc\n\t  namespace: kube-system\n\tspec:\n\t  accessModes:\t\t\t\t// PV 具有的访问部署属性， PVC绑定后也应具有的访问部署属性(可读,可写,多机部署)\n\t  - ReadWriteMany\n\t  resources:\n\t    requests:\n\t      storage: 1Gi\n\t  storageClassName: rook-cephfs\n\t---\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\t  name: my-test\n\t  namespace: kube-system\n\t  labels:\n\t    app: my-test\n\t    kubernetes.io/cluster-service: \"true\"\n\tspec:\n\t  replicas: 2\n\t  selector:\n\t    matchLabels:\n\t      app: my-test\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: my-test\n\t        kubernetes.io/cluster-service: \"true\"\n\t    spec:\n\t      containers:\n\t      - name: my-test\n\t        image: registry:2\n\t        imagePullPolicy: IfNotPresent\n\t        resources:\n\t          limits:\n\t            cpu: 100m\n\t            memory: 100Mi\n\t        volumeMounts:\n\t        - name: my-volume\n\t          mountPath: /var/lib/myVolume\n\t      volumes:\n\t      - name: my-volume\n\t         persistentVolumeClaim:\n\t           claimName: my-pvc\t\t\t// 绑定上面的PVC\n\t           readOnly: false\n\t       affinity:\n\t         podAffinity:\n\t           requiredDuringSchedulingIgnoredDuringExecution:\n\t               - labelSelector:\n\t                   matchExpressions:\n\t                   - key: app\n\t                     operator: In\n\t                     values:\n\t                     - helm\n\t                 topologyKey: kubernetes.io/hostname\n\n\n\n\n\n","source":"_posts/micro_service/05_kubernetes_volume.md","raw":"---\ntitle: 05 Kubernetes volumes\ntags: kubernetes\ncategories:\n- microService\n- kubernetes\n---\n\n## volumes\n> 我们可能希望新的容器可以在之前容器结束的位置继续运行，比如在物理机上重启进程。 可能不需要（或者不想要）整个文件系统被持久化， 但又希望能保存实际数据的目录\n> 在 pod 启动时创建卷， 并在删除 pod 时销毁卷. 在容器重新启动期间， 卷的内容将保持不变， 在重新启动容器之后， 新容器可以识别前一个容器写入卷的所有文件。 另外，如果一个 pod 包含多个容器， 那这个卷可以同时被所有的容器使用\n\nKubernetes 的卷是 pod 的一个组成部分， 因此像容器一样在 pod 的规范中就定义了。 \n它们不是独立的 Kubernetes 对象， 也不能单独创建或删除。 \npod 中的所有容器都可以使用卷， 但必须先将它挂载在每个需要访问它的容器中。 在每个容器中， 都可以在其文件系统的任意位置挂载卷\n卷类型\n * emptyDir 用于存储临时数据的简单空目录\n * gitRepo 通过检出Git仓库的内容来初始化的卷\n * hostPath 用于将目录从工作节点的文件系统挂载到pod中\n * configMap、secret、downwardAPI 用于将 Kubemetes 部分资源和集群信息公开给 pod 的特殊类型的卷 \n ......\n\nfortune-pod.yaml\n\n\tapiVersion: v1\n\tkind: Pod\n\tmetadata:\n\t  name: fortune\n\tspec:\n\t  containers:\n\t  - image: luksa/fortune\n\t    name: html-generator\n\t    volumeMounts:\n\t    - name: html\n\t      mountPath: /var/htdocs\n\t  - image: nginx:alpine\n\t    name: web-server\n\t    volumeMounts:\n\t    - name: html\n\t      mountPath: /usr/share/nginx/html\n\t      readOnly: true\n\t    ports:\n\t    - containerPort: 80\n\t      protocol: TCP\n\t  volumes:\n\t  - name: html\n\t    emptyDir: {}\n作为卷来使用的 emptyDir 是在承载 pod 的工作节点的实际磁盘上创建的，因此其性能取决于节点的磁盘类型。\n也可以通知 Kubemetes 在 tmfs 文件系统(存在内存而非硬盘)上创建 emptyDir. 因此，将 emptyDir 的 medium 设置为Memory\n\n\t  volumes:\n\t  - name: html\n\t    emptyDir\n\t      medium: Memory\n创建pod\n\n\t$ kubectl create -f fortune-pod.yaml\n\n\t$ kuberctl port-forward fortune 8080:80\n\tForwarding from 127.0.0.1:8080 -> 80\n\tForwarding from [::1]:8080 -> 80\n\tHandling connection for 8080\n\t......\n查看 pod 描述\n\n\t$ kubectl describe po/fortune\n\t......\n\tContainers:\n\thtml-generator:\n\t......\n\t  Mounts:\n\t    /var/htdocs from html (rw)\n\t    /var/run/secrets/kubernetes.io/serviceaccount from default-token-b79jt (ro)\n\t......\n\tVolumes:\n\t  html:\n\t    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)\n\t    Medium:     Memory\n\t    SizeLimit:  <unset>\n\t  default-token-b79jt:\n\t    Type:        Secret (a volume populated by a Secret)\n\t    SecretName:  default-token-b79jt\n\t    Optional:    false\n\t......\n\n测试访问两种方式:\n\n * 第一种浏览器访问:\n浏览器输入 [http://127.0.0.1:8080](http://127.0.0.1:8080) 或 [http://localhost:8080](http://localhost:8080)\n即可看到每过10s按F5刷新一次HTML页面内容都不一样\n\n * 第二种 curl 或 wget 访问\n不去掉公司的proxy访问命令里加上 noproxy\n\n\n\t$ curl http://127.0.0.1:8080 --noproxy \"*\"\t// \"*\" 对所有路径的访问都不经过配置的proxy\n也可以去掉公司的proxy, 需要先执行 $ export http_proxy= 把公司的proxy去掉\n再执行如下命令即可访问\n\n\n\t$ curl -s http://127.0.0.1:8080\n\t$ curl -s http://localhost:8080\n\t$ wget http://127.0.0.1:8080\n\n开启两个终端进入这两个container，每过10s分别运行如下各自container里的cat html命令，发现HTML内容不断变化但两个容器的html内容一样\n如果打开浏览器，发现浏览器输出跟这两个container里相应路径下html的内容都是一样同步变化的\n\n\t$ kubectl exec po/fortune -c web-server -it -- sh\n\t$ cat /usr/share/nginx/html/index.html\n\n\t$ kubectl exec po/fortune -c html-generator -it -- sh\n\t$ cat /var/htdocs/index.html\n\n\n## gitRepo 卷\n> gitRepo 容器就像 emptyDir 卷一样， 基本上是一个专用目录， 专门用于包含卷的容器并单独使用。 当 pod 被删除时， 卷及其内容被删除。 然而， 其他类型的卷并不创建新目录， 而是将现有的外部目录挂载到 pod 的容器文件系统中.\n> 使用对应私有 Git repo 的 gitRepo 卷， 其实不可行。 Kubemetes 开发入员的共识是保待 gitRepo 卷的简单性， 而不添加任何通过 SSH 协议克隆私有存储库的支待， 因为这需要向 gitRepo 卷添加额外的配置选项。如果想要将私有的 Git repo 克隆到容器中， 则应该使用 gitsync sidecar 或类似的方法， 而不是使用 gitRepo 卷.\n\n## hostPath 卷\n> hostPath 卷指向节点文件系统上的特定文件或目录,在同一个节点上运行并在其 hostPath 卷中使用相同路径的 pod 可以看到相同的文件.\n> 持久性存储, 因为gitRepo 和 emptyDir 卷的内容都会在 pod 被删除时被删除， 而 hostPath 卷的内容则 不会被删除.\n> 如果删除了一个pod, 并且下一个 pod 使用了指向主机上相同路径的hostPath 卷， 则新 pod 将会发现上一个 pod 留下的数据， 但前提是必须将其调度到与第一个 pod 相同的节点上.\n> 不应该使用hostPath 卷作为存储数据库数据的目录. 因为卷的内容存储在特定节点的文件系统中, 当数据库 pod 被重新安排在另一个节点时， 会找不到数据, 这会使 pod 对预定规划的节点很敏感\n> 请记住仅当需要在节点上读取或写入系统文件时才使用 hos七Path, 切勿使用它们来持久化跨 pod的数据.\n\n\t$ kubectl get pods -n kube-system\n\tNAME                                  READY   STATUS    RESTARTS   AGE\n\t......\n\tkube-apiserver-master-node            1/1     Running   5          2d20h\n\t......\n\n\t$ kubectl describe po/kube-apiserver-master-node -n kube-system\n\t......\n\tContainers:\n\t  kube-apiserver:\n\t  ......\n\t  Mounts:\n\t    /etc/kubernetes/pki from k8s-certs (ro)\n\t    /etc/pki from etc-pki (ro)\n\t    /etc/ssl/certs from ca-certs (ro)\n\t......\n\tVolumes:\n\t  ca-certs:\n\t    Type:          HostPath (bare host directory volume)\n\t    Path:          /etc/ssl/certs\n\t    HostPathType:  DirectoryOrCreate\n\t  etc-pki:\n\t    Type:          HostPath (bare host directory volume)\n\t    Path:          /etc/pki\n\t    HostPathType:  DirectoryOrCreate\n\t  k8s-certs:\n\t    Type:          HostPath (bare host directory volume)\n\t    Path:          /etc/kubernetes/pki\n\t    HostPathType:  DirectoryOrCreate\nPod使用三个HostPath卷来访问宿主主机的/etc/ssl/certs, /etc/pki, /etc/kubernetes/pki三个目录.\n\n\n## PV & PVC & storageclass(sc)\n> 在 Kubemetes 集群中为了使应用能够正常请求存储资源， 同时避免处理基础设施细节， 引入了两个新的资源， 分别是待久卷和持久卷声明. 这名字可能有点误导，因为正如在前面看到的， 甚至常规的 Kubemetes 卷 也可以用来存储持久性数据\n> 在 pod 中使用 PersistentVolume (持久卷， 简称 PV) 要比使用常规的 pod 卷复杂一些\n> 研发人员无须向他们的 pod 中添加特定技术的卷， 而是由集群管理员设置底层存储， 然后通过 Kubernetes API 服务器创建持久卷并注册。 在创建持久卷时， 管理员可以指定其大小和所支持的访问模式.\n> 当集群用户需要在其 pod 中使用持久化存储时， 他们首先创建持久卷声明(PersistentVolumeClaim, 简称 PVC) 清单， 指定所需要的最低容量要求和访问模式，然后用户将待久卷声明清单提交给 Kubernetes API 服务器， Kubernetes 将找到可匹配的待久卷并将其绑定到持久卷声明\n> 持久卷声明可以当作 pod 中的一个卷来使用， 其他用户不能使用相同的持久卷，除非先通过删除持久卷声明绑定来释放.\n![](PV_PVC.PNG)\n\n\t$ kubectl get pv\n\n\t$ kubectl get pvc -n default\n\tNAME             STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS      AGE\n\tmysql-pv-claim   Bound    pvc-522c119b-a968-4a86-ae6c-521b64b775ee   20Gi       RWO            rook-ceph-block   5d2h\n\twp-pv-claim      Bound    pvc-4b83da7a-4552-4806-9f68-af96d4a56d96   20Gi       RWO            rook-ceph-block   5d2h\n\n\t$ kubectl get sc\t// storageclass的简写(sc)\n\n\n\n## Additional:\n## CephFS example\n\n创建CephFS\n\n\tapiVersion: ceph.rook.io/v1\n\tkind: CephFilesystem\n\tmetadata:\n\t  name: myfs\n\t  namespace: rook-ceph\n\tspec:\n\t  metadataPool:\n\t    replicated:\n\t      size: 3\n\t  dataPools:\n\t    - replicated:\n\t        size: 3\n\t  preservePoolsOnDelete: true\n\t  metadataServer:\n\t    activeCount: 1\n\t    activeStandby: true\n\n创建sc(StorageClass), sc是不需要提前创建好PV, 而是根据PVC需求动态创建PV.\n\n\tapiVersion: storage.k8s.io/v1\n\tkind: StorageClass\n\tmetadata:\n\t  name: rook-cephfs\n\t# Change \"rook-ceph\" provisioner prefix to match the operator namespace if needed\n\tprovisioner: rook-ceph.cephfs.csi.ceph.com\n\t  parameters:\n\t  # clusterID is the namespace where operator is deployed.\n\t  clusterID: rook-ceph\n\t  \n\t  # CephFS filesystem name into which the volume shall be created\n\t  fsName: myfs\n\t  \n\t  # Ceph pool into which the volume shall be created\n\t  # Required for provisionVolume: \"true\"\n\t  pool: myfs-data0\n\t  \n\t  # Root path of an existing CephFS volume\n\t  # Required for provisionVolume: \"false\"\n\t  # rootPath: /absolute/path\n\t  \n\t  # The secrets contain Ceph admin credentials. These are generated automatically by the operator\n\t  # in the same namespace as the cluster.\n\t  csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner\n\t  csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph\n\t  csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node\n\t  csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph\n\t  \n\treclaimPolicy: Delete\n\n\n创建PVC和deployment\n> PV 是K8S全局资源\n> PVC 是指定在某个Namespace下的K8S资源, 如果PVC访问属性为ReadWriteMany， 多个不同Pod挂载此相同的PVC到容器指定目录, 该目录将共享文件\n> 多个不同Pod挂载不同的PVC到容器指定目录，则文件不能共享\n\n\tapiVersion: v1\n\tkind: PersistentVolumeClaim\n\tmetadata:\n\t  name: my-pvc\n\t  namespace: kube-system\n\tspec:\n\t  accessModes:\t\t\t\t// PV 具有的访问部署属性， PVC绑定后也应具有的访问部署属性(可读,可写,多机部署)\n\t  - ReadWriteMany\n\t  resources:\n\t    requests:\n\t      storage: 1Gi\n\t  storageClassName: rook-cephfs\n\t---\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\t  name: my-test\n\t  namespace: kube-system\n\t  labels:\n\t    app: my-test\n\t    kubernetes.io/cluster-service: \"true\"\n\tspec:\n\t  replicas: 2\n\t  selector:\n\t    matchLabels:\n\t      app: my-test\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: my-test\n\t        kubernetes.io/cluster-service: \"true\"\n\t    spec:\n\t      containers:\n\t      - name: my-test\n\t        image: registry:2\n\t        imagePullPolicy: IfNotPresent\n\t        resources:\n\t          limits:\n\t            cpu: 100m\n\t            memory: 100Mi\n\t        volumeMounts:\n\t        - name: my-volume\n\t          mountPath: /var/lib/myVolume\n\t      volumes:\n\t      - name: my-volume\n\t         persistentVolumeClaim:\n\t           claimName: my-pvc\t\t\t// 绑定上面的PVC\n\t           readOnly: false\n\t       affinity:\n\t         podAffinity:\n\t           requiredDuringSchedulingIgnoredDuringExecution:\n\t               - labelSelector:\n\t                   matchExpressions:\n\t                   - key: app\n\t                     operator: In\n\t                     values:\n\t                     - helm\n\t                 topologyKey: kubernetes.io/hostname\n\n\n\n\n\n","slug":"micro_service/05_kubernetes_volume","published":1,"date":"2020-08-12T16:05:47.398Z","updated":"2020-08-10T16:36:30.335Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmg6004bhohx08xqbea4","content":"<h2 id=\"volumes\"><a href=\"#volumes\" class=\"headerlink\" title=\"volumes\"></a>volumes</h2><blockquote>\n<p>我们可能希望新的容器可以在之前容器结束的位置继续运行，比如在物理机上重启进程。 可能不需要（或者不想要）整个文件系统被持久化， 但又希望能保存实际数据的目录<br>在 pod 启动时创建卷， 并在删除 pod 时销毁卷. 在容器重新启动期间， 卷的内容将保持不变， 在重新启动容器之后， 新容器可以识别前一个容器写入卷的所有文件。 另外，如果一个 pod 包含多个容器， 那这个卷可以同时被所有的容器使用</p>\n</blockquote>\n<p>Kubernetes 的卷是 pod 的一个组成部分， 因此像容器一样在 pod 的规范中就定义了。<br>它们不是独立的 Kubernetes 对象， 也不能单独创建或删除。<br>pod 中的所有容器都可以使用卷， 但必须先将它挂载在每个需要访问它的容器中。 在每个容器中， 都可以在其文件系统的任意位置挂载卷<br>卷类型</p>\n<ul>\n<li>emptyDir 用于存储临时数据的简单空目录</li>\n<li>gitRepo 通过检出Git仓库的内容来初始化的卷</li>\n<li>hostPath 用于将目录从工作节点的文件系统挂载到pod中</li>\n<li>configMap、secret、downwardAPI 用于将 Kubemetes 部分资源和集群信息公开给 pod 的特殊类型的卷<br>……</li>\n</ul>\n<p>fortune-pod.yaml</p>\n<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: fortune\nspec:\n  containers:\n  - image: luksa/fortune\n    name: html-generator\n    volumeMounts:\n    - name: html\n      mountPath: /var/htdocs\n  - image: nginx:alpine\n    name: web-server\n    volumeMounts:\n    - name: html\n      mountPath: /usr/share/nginx/html\n      readOnly: true\n    ports:\n    - containerPort: 80\n      protocol: TCP\n  volumes:\n  - name: html\n    emptyDir: {}</code></pre><p>作为卷来使用的 emptyDir 是在承载 pod 的工作节点的实际磁盘上创建的，因此其性能取决于节点的磁盘类型。<br>也可以通知 Kubemetes 在 tmfs 文件系统(存在内存而非硬盘)上创建 emptyDir. 因此，将 emptyDir 的 medium 设置为Memory</p>\n<pre><code>volumes:\n- name: html\n  emptyDir\n    medium: Memory</code></pre><p>创建pod</p>\n<pre><code>$ kubectl create -f fortune-pod.yaml\n\n$ kuberctl port-forward fortune 8080:80\nForwarding from 127.0.0.1:8080 -&gt; 80\nForwarding from [::1]:8080 -&gt; 80\nHandling connection for 8080\n......</code></pre><p>查看 pod 描述</p>\n<pre><code>$ kubectl describe po/fortune\n......\nContainers:\nhtml-generator:\n......\n  Mounts:\n    /var/htdocs from html (rw)\n    /var/run/secrets/kubernetes.io/serviceaccount from default-token-b79jt (ro)\n......\nVolumes:\n  html:\n    Type:       EmptyDir (a temporary directory that shares a pod&apos;s lifetime)\n    Medium:     Memory\n    SizeLimit:  &lt;unset&gt;\n  default-token-b79jt:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-b79jt\n    Optional:    false\n......</code></pre><p>测试访问两种方式:</p>\n<ul>\n<li><p>第一种浏览器访问:<br>浏览器输入 <a href=\"http://127.0.0.1:8080\" target=\"_blank\" rel=\"noopener\">http://127.0.0.1:8080</a> 或 <a href=\"http://localhost:8080\" target=\"_blank\" rel=\"noopener\">http://localhost:8080</a><br>即可看到每过10s按F5刷新一次HTML页面内容都不一样</p>\n</li>\n<li><p>第二种 curl 或 wget 访问<br>不去掉公司的proxy访问命令里加上 noproxy</p>\n</li>\n</ul>\n<pre><code>$ curl http://127.0.0.1:8080 --noproxy &quot;*&quot;    // &quot;*&quot; 对所有路径的访问都不经过配置的proxy</code></pre><p>也可以去掉公司的proxy, 需要先执行 $ export http_proxy= 把公司的proxy去掉<br>再执行如下命令即可访问</p>\n<pre><code>$ curl -s http://127.0.0.1:8080\n$ curl -s http://localhost:8080\n$ wget http://127.0.0.1:8080</code></pre><p>开启两个终端进入这两个container，每过10s分别运行如下各自container里的cat html命令，发现HTML内容不断变化但两个容器的html内容一样<br>如果打开浏览器，发现浏览器输出跟这两个container里相应路径下html的内容都是一样同步变化的</p>\n<pre><code>$ kubectl exec po/fortune -c web-server -it -- sh\n$ cat /usr/share/nginx/html/index.html\n\n$ kubectl exec po/fortune -c html-generator -it -- sh\n$ cat /var/htdocs/index.html</code></pre><h2 id=\"gitRepo-卷\"><a href=\"#gitRepo-卷\" class=\"headerlink\" title=\"gitRepo 卷\"></a>gitRepo 卷</h2><blockquote>\n<p>gitRepo 容器就像 emptyDir 卷一样， 基本上是一个专用目录， 专门用于包含卷的容器并单独使用。 当 pod 被删除时， 卷及其内容被删除。 然而， 其他类型的卷并不创建新目录， 而是将现有的外部目录挂载到 pod 的容器文件系统中.<br>使用对应私有 Git repo 的 gitRepo 卷， 其实不可行。 Kubemetes 开发入员的共识是保待 gitRepo 卷的简单性， 而不添加任何通过 SSH 协议克隆私有存储库的支待， 因为这需要向 gitRepo 卷添加额外的配置选项。如果想要将私有的 Git repo 克隆到容器中， 则应该使用 gitsync sidecar 或类似的方法， 而不是使用 gitRepo 卷.</p>\n</blockquote>\n<h2 id=\"hostPath-卷\"><a href=\"#hostPath-卷\" class=\"headerlink\" title=\"hostPath 卷\"></a>hostPath 卷</h2><blockquote>\n<p>hostPath 卷指向节点文件系统上的特定文件或目录,在同一个节点上运行并在其 hostPath 卷中使用相同路径的 pod 可以看到相同的文件.<br>持久性存储, 因为gitRepo 和 emptyDir 卷的内容都会在 pod 被删除时被删除， 而 hostPath 卷的内容则 不会被删除.<br>如果删除了一个pod, 并且下一个 pod 使用了指向主机上相同路径的hostPath 卷， 则新 pod 将会发现上一个 pod 留下的数据， 但前提是必须将其调度到与第一个 pod 相同的节点上.<br>不应该使用hostPath 卷作为存储数据库数据的目录. 因为卷的内容存储在特定节点的文件系统中, 当数据库 pod 被重新安排在另一个节点时， 会找不到数据, 这会使 pod 对预定规划的节点很敏感<br>请记住仅当需要在节点上读取或写入系统文件时才使用 hos七Path, 切勿使用它们来持久化跨 pod的数据.</p>\n</blockquote>\n<pre><code>$ kubectl get pods -n kube-system\nNAME                                  READY   STATUS    RESTARTS   AGE\n......\nkube-apiserver-master-node            1/1     Running   5          2d20h\n......\n\n$ kubectl describe po/kube-apiserver-master-node -n kube-system\n......\nContainers:\n  kube-apiserver:\n  ......\n  Mounts:\n    /etc/kubernetes/pki from k8s-certs (ro)\n    /etc/pki from etc-pki (ro)\n    /etc/ssl/certs from ca-certs (ro)\n......\nVolumes:\n  ca-certs:\n    Type:          HostPath (bare host directory volume)\n    Path:          /etc/ssl/certs\n    HostPathType:  DirectoryOrCreate\n  etc-pki:\n    Type:          HostPath (bare host directory volume)\n    Path:          /etc/pki\n    HostPathType:  DirectoryOrCreate\n  k8s-certs:\n    Type:          HostPath (bare host directory volume)\n    Path:          /etc/kubernetes/pki\n    HostPathType:  DirectoryOrCreate</code></pre><p>Pod使用三个HostPath卷来访问宿主主机的/etc/ssl/certs, /etc/pki, /etc/kubernetes/pki三个目录.</p>\n<h2 id=\"PV-amp-PVC-amp-storageclass-sc\"><a href=\"#PV-amp-PVC-amp-storageclass-sc\" class=\"headerlink\" title=\"PV &amp; PVC &amp; storageclass(sc)\"></a>PV &amp; PVC &amp; storageclass(sc)</h2><blockquote>\n<p>在 Kubemetes 集群中为了使应用能够正常请求存储资源， 同时避免处理基础设施细节， 引入了两个新的资源， 分别是待久卷和持久卷声明. 这名字可能有点误导，因为正如在前面看到的， 甚至常规的 Kubemetes 卷 也可以用来存储持久性数据<br>在 pod 中使用 PersistentVolume (持久卷， 简称 PV) 要比使用常规的 pod 卷复杂一些<br>研发人员无须向他们的 pod 中添加特定技术的卷， 而是由集群管理员设置底层存储， 然后通过 Kubernetes API 服务器创建持久卷并注册。 在创建持久卷时， 管理员可以指定其大小和所支持的访问模式.<br>当集群用户需要在其 pod 中使用持久化存储时， 他们首先创建持久卷声明(PersistentVolumeClaim, 简称 PVC) 清单， 指定所需要的最低容量要求和访问模式，然后用户将待久卷声明清单提交给 Kubernetes API 服务器， Kubernetes 将找到可匹配的待久卷并将其绑定到持久卷声明<br>持久卷声明可以当作 pod 中的一个卷来使用， 其他用户不能使用相同的持久卷，除非先通过删除持久卷声明绑定来释放.<br><img src=\"PV_PVC.PNG\" alt=\"\"></p>\n</blockquote>\n<pre><code>$ kubectl get pv\n\n$ kubectl get pvc -n default\nNAME             STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS      AGE\nmysql-pv-claim   Bound    pvc-522c119b-a968-4a86-ae6c-521b64b775ee   20Gi       RWO            rook-ceph-block   5d2h\nwp-pv-claim      Bound    pvc-4b83da7a-4552-4806-9f68-af96d4a56d96   20Gi       RWO            rook-ceph-block   5d2h\n\n$ kubectl get sc    // storageclass的简写(sc)</code></pre><h2 id=\"Additional\"><a href=\"#Additional\" class=\"headerlink\" title=\"Additional:\"></a>Additional:</h2><h2 id=\"CephFS-example\"><a href=\"#CephFS-example\" class=\"headerlink\" title=\"CephFS example\"></a>CephFS example</h2><p>创建CephFS</p>\n<pre><code>apiVersion: ceph.rook.io/v1\nkind: CephFilesystem\nmetadata:\n  name: myfs\n  namespace: rook-ceph\nspec:\n  metadataPool:\n    replicated:\n      size: 3\n  dataPools:\n    - replicated:\n        size: 3\n  preservePoolsOnDelete: true\n  metadataServer:\n    activeCount: 1\n    activeStandby: true</code></pre><p>创建sc(StorageClass), sc是不需要提前创建好PV, 而是根据PVC需求动态创建PV.</p>\n<pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: rook-cephfs\n# Change &quot;rook-ceph&quot; provisioner prefix to match the operator namespace if needed\nprovisioner: rook-ceph.cephfs.csi.ceph.com\n  parameters:\n  # clusterID is the namespace where operator is deployed.\n  clusterID: rook-ceph\n\n  # CephFS filesystem name into which the volume shall be created\n  fsName: myfs\n\n  # Ceph pool into which the volume shall be created\n  # Required for provisionVolume: &quot;true&quot;\n  pool: myfs-data0\n\n  # Root path of an existing CephFS volume\n  # Required for provisionVolume: &quot;false&quot;\n  # rootPath: /absolute/path\n\n  # The secrets contain Ceph admin credentials. These are generated automatically by the operator\n  # in the same namespace as the cluster.\n  csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner\n  csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph\n  csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node\n  csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph\n\nreclaimPolicy: Delete</code></pre><p>创建PVC和deployment</p>\n<blockquote>\n<p>PV 是K8S全局资源<br>PVC 是指定在某个Namespace下的K8S资源, 如果PVC访问属性为ReadWriteMany， 多个不同Pod挂载此相同的PVC到容器指定目录, 该目录将共享文件<br>多个不同Pod挂载不同的PVC到容器指定目录，则文件不能共享</p>\n</blockquote>\n<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: my-pvc\n  namespace: kube-system\nspec:\n  accessModes:                // PV 具有的访问部署属性， PVC绑定后也应具有的访问部署属性(可读,可写,多机部署)\n  - ReadWriteMany\n  resources:\n    requests:\n      storage: 1Gi\n  storageClassName: rook-cephfs\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-test\n  namespace: kube-system\n  labels:\n    app: my-test\n    kubernetes.io/cluster-service: &quot;true&quot;\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: my-test\n  template:\n    metadata:\n      labels:\n        app: my-test\n        kubernetes.io/cluster-service: &quot;true&quot;\n    spec:\n      containers:\n      - name: my-test\n        image: registry:2\n        imagePullPolicy: IfNotPresent\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n        volumeMounts:\n        - name: my-volume\n          mountPath: /var/lib/myVolume\n      volumes:\n      - name: my-volume\n         persistentVolumeClaim:\n           claimName: my-pvc            // 绑定上面的PVC\n           readOnly: false\n       affinity:\n         podAffinity:\n           requiredDuringSchedulingIgnoredDuringExecution:\n               - labelSelector:\n                   matchExpressions:\n                   - key: app\n                     operator: In\n                     values:\n                     - helm\n                 topologyKey: kubernetes.io/hostname</code></pre>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"volumes\"><a href=\"#volumes\" class=\"headerlink\" title=\"volumes\"></a>volumes</h2><blockquote>\n<p>我们可能希望新的容器可以在之前容器结束的位置继续运行，比如在物理机上重启进程。 可能不需要（或者不想要）整个文件系统被持久化， 但又希望能保存实际数据的目录<br>在 pod 启动时创建卷， 并在删除 pod 时销毁卷. 在容器重新启动期间， 卷的内容将保持不变， 在重新启动容器之后， 新容器可以识别前一个容器写入卷的所有文件。 另外，如果一个 pod 包含多个容器， 那这个卷可以同时被所有的容器使用</p>\n</blockquote>\n<p>Kubernetes 的卷是 pod 的一个组成部分， 因此像容器一样在 pod 的规范中就定义了。<br>它们不是独立的 Kubernetes 对象， 也不能单独创建或删除。<br>pod 中的所有容器都可以使用卷， 但必须先将它挂载在每个需要访问它的容器中。 在每个容器中， 都可以在其文件系统的任意位置挂载卷<br>卷类型</p>\n<ul>\n<li>emptyDir 用于存储临时数据的简单空目录</li>\n<li>gitRepo 通过检出Git仓库的内容来初始化的卷</li>\n<li>hostPath 用于将目录从工作节点的文件系统挂载到pod中</li>\n<li>configMap、secret、downwardAPI 用于将 Kubemetes 部分资源和集群信息公开给 pod 的特殊类型的卷<br>……</li>\n</ul>\n<p>fortune-pod.yaml</p>\n<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: fortune\nspec:\n  containers:\n  - image: luksa/fortune\n    name: html-generator\n    volumeMounts:\n    - name: html\n      mountPath: /var/htdocs\n  - image: nginx:alpine\n    name: web-server\n    volumeMounts:\n    - name: html\n      mountPath: /usr/share/nginx/html\n      readOnly: true\n    ports:\n    - containerPort: 80\n      protocol: TCP\n  volumes:\n  - name: html\n    emptyDir: {}</code></pre><p>作为卷来使用的 emptyDir 是在承载 pod 的工作节点的实际磁盘上创建的，因此其性能取决于节点的磁盘类型。<br>也可以通知 Kubemetes 在 tmfs 文件系统(存在内存而非硬盘)上创建 emptyDir. 因此，将 emptyDir 的 medium 设置为Memory</p>\n<pre><code>volumes:\n- name: html\n  emptyDir\n    medium: Memory</code></pre><p>创建pod</p>\n<pre><code>$ kubectl create -f fortune-pod.yaml\n\n$ kuberctl port-forward fortune 8080:80\nForwarding from 127.0.0.1:8080 -&gt; 80\nForwarding from [::1]:8080 -&gt; 80\nHandling connection for 8080\n......</code></pre><p>查看 pod 描述</p>\n<pre><code>$ kubectl describe po/fortune\n......\nContainers:\nhtml-generator:\n......\n  Mounts:\n    /var/htdocs from html (rw)\n    /var/run/secrets/kubernetes.io/serviceaccount from default-token-b79jt (ro)\n......\nVolumes:\n  html:\n    Type:       EmptyDir (a temporary directory that shares a pod&apos;s lifetime)\n    Medium:     Memory\n    SizeLimit:  &lt;unset&gt;\n  default-token-b79jt:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-b79jt\n    Optional:    false\n......</code></pre><p>测试访问两种方式:</p>\n<ul>\n<li><p>第一种浏览器访问:<br>浏览器输入 <a href=\"http://127.0.0.1:8080\" target=\"_blank\" rel=\"noopener\">http://127.0.0.1:8080</a> 或 <a href=\"http://localhost:8080\" target=\"_blank\" rel=\"noopener\">http://localhost:8080</a><br>即可看到每过10s按F5刷新一次HTML页面内容都不一样</p>\n</li>\n<li><p>第二种 curl 或 wget 访问<br>不去掉公司的proxy访问命令里加上 noproxy</p>\n</li>\n</ul>\n<pre><code>$ curl http://127.0.0.1:8080 --noproxy &quot;*&quot;    // &quot;*&quot; 对所有路径的访问都不经过配置的proxy</code></pre><p>也可以去掉公司的proxy, 需要先执行 $ export http_proxy= 把公司的proxy去掉<br>再执行如下命令即可访问</p>\n<pre><code>$ curl -s http://127.0.0.1:8080\n$ curl -s http://localhost:8080\n$ wget http://127.0.0.1:8080</code></pre><p>开启两个终端进入这两个container，每过10s分别运行如下各自container里的cat html命令，发现HTML内容不断变化但两个容器的html内容一样<br>如果打开浏览器，发现浏览器输出跟这两个container里相应路径下html的内容都是一样同步变化的</p>\n<pre><code>$ kubectl exec po/fortune -c web-server -it -- sh\n$ cat /usr/share/nginx/html/index.html\n\n$ kubectl exec po/fortune -c html-generator -it -- sh\n$ cat /var/htdocs/index.html</code></pre><h2 id=\"gitRepo-卷\"><a href=\"#gitRepo-卷\" class=\"headerlink\" title=\"gitRepo 卷\"></a>gitRepo 卷</h2><blockquote>\n<p>gitRepo 容器就像 emptyDir 卷一样， 基本上是一个专用目录， 专门用于包含卷的容器并单独使用。 当 pod 被删除时， 卷及其内容被删除。 然而， 其他类型的卷并不创建新目录， 而是将现有的外部目录挂载到 pod 的容器文件系统中.<br>使用对应私有 Git repo 的 gitRepo 卷， 其实不可行。 Kubemetes 开发入员的共识是保待 gitRepo 卷的简单性， 而不添加任何通过 SSH 协议克隆私有存储库的支待， 因为这需要向 gitRepo 卷添加额外的配置选项。如果想要将私有的 Git repo 克隆到容器中， 则应该使用 gitsync sidecar 或类似的方法， 而不是使用 gitRepo 卷.</p>\n</blockquote>\n<h2 id=\"hostPath-卷\"><a href=\"#hostPath-卷\" class=\"headerlink\" title=\"hostPath 卷\"></a>hostPath 卷</h2><blockquote>\n<p>hostPath 卷指向节点文件系统上的特定文件或目录,在同一个节点上运行并在其 hostPath 卷中使用相同路径的 pod 可以看到相同的文件.<br>持久性存储, 因为gitRepo 和 emptyDir 卷的内容都会在 pod 被删除时被删除， 而 hostPath 卷的内容则 不会被删除.<br>如果删除了一个pod, 并且下一个 pod 使用了指向主机上相同路径的hostPath 卷， 则新 pod 将会发现上一个 pod 留下的数据， 但前提是必须将其调度到与第一个 pod 相同的节点上.<br>不应该使用hostPath 卷作为存储数据库数据的目录. 因为卷的内容存储在特定节点的文件系统中, 当数据库 pod 被重新安排在另一个节点时， 会找不到数据, 这会使 pod 对预定规划的节点很敏感<br>请记住仅当需要在节点上读取或写入系统文件时才使用 hos七Path, 切勿使用它们来持久化跨 pod的数据.</p>\n</blockquote>\n<pre><code>$ kubectl get pods -n kube-system\nNAME                                  READY   STATUS    RESTARTS   AGE\n......\nkube-apiserver-master-node            1/1     Running   5          2d20h\n......\n\n$ kubectl describe po/kube-apiserver-master-node -n kube-system\n......\nContainers:\n  kube-apiserver:\n  ......\n  Mounts:\n    /etc/kubernetes/pki from k8s-certs (ro)\n    /etc/pki from etc-pki (ro)\n    /etc/ssl/certs from ca-certs (ro)\n......\nVolumes:\n  ca-certs:\n    Type:          HostPath (bare host directory volume)\n    Path:          /etc/ssl/certs\n    HostPathType:  DirectoryOrCreate\n  etc-pki:\n    Type:          HostPath (bare host directory volume)\n    Path:          /etc/pki\n    HostPathType:  DirectoryOrCreate\n  k8s-certs:\n    Type:          HostPath (bare host directory volume)\n    Path:          /etc/kubernetes/pki\n    HostPathType:  DirectoryOrCreate</code></pre><p>Pod使用三个HostPath卷来访问宿主主机的/etc/ssl/certs, /etc/pki, /etc/kubernetes/pki三个目录.</p>\n<h2 id=\"PV-amp-PVC-amp-storageclass-sc\"><a href=\"#PV-amp-PVC-amp-storageclass-sc\" class=\"headerlink\" title=\"PV &amp; PVC &amp; storageclass(sc)\"></a>PV &amp; PVC &amp; storageclass(sc)</h2><blockquote>\n<p>在 Kubemetes 集群中为了使应用能够正常请求存储资源， 同时避免处理基础设施细节， 引入了两个新的资源， 分别是待久卷和持久卷声明. 这名字可能有点误导，因为正如在前面看到的， 甚至常规的 Kubemetes 卷 也可以用来存储持久性数据<br>在 pod 中使用 PersistentVolume (持久卷， 简称 PV) 要比使用常规的 pod 卷复杂一些<br>研发人员无须向他们的 pod 中添加特定技术的卷， 而是由集群管理员设置底层存储， 然后通过 Kubernetes API 服务器创建持久卷并注册。 在创建持久卷时， 管理员可以指定其大小和所支持的访问模式.<br>当集群用户需要在其 pod 中使用持久化存储时， 他们首先创建持久卷声明(PersistentVolumeClaim, 简称 PVC) 清单， 指定所需要的最低容量要求和访问模式，然后用户将待久卷声明清单提交给 Kubernetes API 服务器， Kubernetes 将找到可匹配的待久卷并将其绑定到持久卷声明<br>持久卷声明可以当作 pod 中的一个卷来使用， 其他用户不能使用相同的持久卷，除非先通过删除持久卷声明绑定来释放.<br><img src=\"PV_PVC.PNG\" alt=\"\"></p>\n</blockquote>\n<pre><code>$ kubectl get pv\n\n$ kubectl get pvc -n default\nNAME             STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS      AGE\nmysql-pv-claim   Bound    pvc-522c119b-a968-4a86-ae6c-521b64b775ee   20Gi       RWO            rook-ceph-block   5d2h\nwp-pv-claim      Bound    pvc-4b83da7a-4552-4806-9f68-af96d4a56d96   20Gi       RWO            rook-ceph-block   5d2h\n\n$ kubectl get sc    // storageclass的简写(sc)</code></pre><h2 id=\"Additional\"><a href=\"#Additional\" class=\"headerlink\" title=\"Additional:\"></a>Additional:</h2><h2 id=\"CephFS-example\"><a href=\"#CephFS-example\" class=\"headerlink\" title=\"CephFS example\"></a>CephFS example</h2><p>创建CephFS</p>\n<pre><code>apiVersion: ceph.rook.io/v1\nkind: CephFilesystem\nmetadata:\n  name: myfs\n  namespace: rook-ceph\nspec:\n  metadataPool:\n    replicated:\n      size: 3\n  dataPools:\n    - replicated:\n        size: 3\n  preservePoolsOnDelete: true\n  metadataServer:\n    activeCount: 1\n    activeStandby: true</code></pre><p>创建sc(StorageClass), sc是不需要提前创建好PV, 而是根据PVC需求动态创建PV.</p>\n<pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: rook-cephfs\n# Change &quot;rook-ceph&quot; provisioner prefix to match the operator namespace if needed\nprovisioner: rook-ceph.cephfs.csi.ceph.com\n  parameters:\n  # clusterID is the namespace where operator is deployed.\n  clusterID: rook-ceph\n\n  # CephFS filesystem name into which the volume shall be created\n  fsName: myfs\n\n  # Ceph pool into which the volume shall be created\n  # Required for provisionVolume: &quot;true&quot;\n  pool: myfs-data0\n\n  # Root path of an existing CephFS volume\n  # Required for provisionVolume: &quot;false&quot;\n  # rootPath: /absolute/path\n\n  # The secrets contain Ceph admin credentials. These are generated automatically by the operator\n  # in the same namespace as the cluster.\n  csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner\n  csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph\n  csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node\n  csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph\n\nreclaimPolicy: Delete</code></pre><p>创建PVC和deployment</p>\n<blockquote>\n<p>PV 是K8S全局资源<br>PVC 是指定在某个Namespace下的K8S资源, 如果PVC访问属性为ReadWriteMany， 多个不同Pod挂载此相同的PVC到容器指定目录, 该目录将共享文件<br>多个不同Pod挂载不同的PVC到容器指定目录，则文件不能共享</p>\n</blockquote>\n<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: my-pvc\n  namespace: kube-system\nspec:\n  accessModes:                // PV 具有的访问部署属性， PVC绑定后也应具有的访问部署属性(可读,可写,多机部署)\n  - ReadWriteMany\n  resources:\n    requests:\n      storage: 1Gi\n  storageClassName: rook-cephfs\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-test\n  namespace: kube-system\n  labels:\n    app: my-test\n    kubernetes.io/cluster-service: &quot;true&quot;\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: my-test\n  template:\n    metadata:\n      labels:\n        app: my-test\n        kubernetes.io/cluster-service: &quot;true&quot;\n    spec:\n      containers:\n      - name: my-test\n        image: registry:2\n        imagePullPolicy: IfNotPresent\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n        volumeMounts:\n        - name: my-volume\n          mountPath: /var/lib/myVolume\n      volumes:\n      - name: my-volume\n         persistentVolumeClaim:\n           claimName: my-pvc            // 绑定上面的PVC\n           readOnly: false\n       affinity:\n         podAffinity:\n           requiredDuringSchedulingIgnoredDuringExecution:\n               - labelSelector:\n                   matchExpressions:\n                   - key: app\n                     operator: In\n                     values:\n                     - helm\n                 topologyKey: kubernetes.io/hostname</code></pre>"},{"title":"06 Kubernetes deployment","top":6,"_content":"\n## deployment\nDeployment 是一种更高阶资源， 用千部署应用程序并以声明的方式升级应用, 而不是通过 ReplicationController 或 ReplicaSet 进行部署， 它们都被认为是更底层的概念.\n当创建一个 Deployment 时， ReplicaSet 资源也会随之创建.\n在使用 Deployment 时， 实际的 pod是由 Deployment 的 Replicaset 创建和管理的， 而不是由 Deployment 直接创建和管理的.\n> 创建Deployment与创建ReplicationController并没有任何区别。Deployment也是由标签选择器、期望副数和pod模板组成的。此外，它还包含另 一 个字段，指定一 个部署策略，该策略定义在修改Deployment资源时应该如何执行更新\nDeployment可以同时管理多个版本的 pod, 所以在命名时不需要指定应用的版本号\nkubia-svc-loadbalancer.yaml\n\n\tapiVersion: v1\n\tkind: Service\n\tmetadata:\n\t  name: kubia-loadbalancer\n\tspec:\n\t  type: LoadBalancer\n\t  ports:\n\t  - port: 80\n\t    targetPort: 8080\n\t  selector:\n\t    app: kubia\nkubia-deployment-v1.yaml\n\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\t  name: kubia\n\tspec:\n\t  replicas: 3\n\t  selector:\n\t    matchLabels:\n\t      app: kubia\n\t  template:\n\t    metadata:\n\t      name: kubia\n\t      labels:\n\t        app: kubia\n\t    spec:\n\t      containers:\n\t      - image: luksa/kubia:v1\n\t        name: nodejs\n创建deployment\n\n\t$ kubectl create -f kubia-deployment-v1.yaml --record\n查看deployment过程\n\n\t$ kubectl rollout status deployment kubia\n\tWaiting for deployment \"kubia\" rollout to finish: 1 out of 3 new replicas have been updated...\n\tWaiting for deployment \"kubia\" rollout to finish: 1 out of 3 new replicas have been updated...\n\tWaiting for deployment \"kubia\" rollout to finish: 2 out of 3 new replicas have been updated...\n\tWaiting for deployment \"kubia\" rollout to finish: 2 out of 3 new replicas have been updated...\n\tWaiting for deployment \"kubia\" rollout to finish: 2 out of 3 new replicas have been updated...\n\tWaiting for deployment \"kubia\" rollout to finish: 2 out of 3 new replicas have been updated...\n\tWaiting for deployment \"kubia\" rollout to finish: 1 old replicas are pending termination...\n\tWaiting for deployment \"kubia\" rollout to finish: 1 old replicas are pending termination...\n\tWaiting for deployment \"kubia\" rollout to finish: 1 old replicas are pending termination...\n\tdeployment \"kubia\" successfully rolled out\n当使用 ReplicationController 创建 pod 时， 它们的名称是由 Controller 的名称加上一个运行时生成的随机字符串.\n由 Deployment 创建的三个 pod 名称中均包含一个额外的数字, 这个数字实际上对应 Deployment 和 ReplicaSet 中的 pod 模板的哈希值\n\n\t$ kubectl get po\n\tkubia-59d857b444-2nrr7   1/1     Running   0          5m15s\n\tkubia-59d857b444-f9pnx   1/1     Running   0          5m15s\n\tkubia-59d857b444-wzgnj   1/1     Running   0          5m15s\n\n\t$ kubectl get replicasets\n\tNAME               DESIRED   CURRENT   READY   AGE\n\tkubia-59d857b444   3         3         3       8m48s\n\n\t$ kubectl get svc\n\tNAME                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\n\tkubernetes           ClusterIP      10.96.0.1       <none>        443/TCP        4d22h\n\tkubia-loadbalancer   LoadBalancer   10.100.58.157   <pending>     80:31170/TCP   3s\n查看master node 的IP为10.239.140.186\n\n\t$ curl 10.239.140.186:31170\n\tThis is v1 running in pod kubia-59d857b444-wzgnj\n查看deployment详细信息\n\n\t$ kubectl describe deployment kubia\n\tName:                   kubia\n\tNamespace:              default\n\tCreationTimestamp:      Mon, 18 May 2020 15:04:12 +0800\n\tLabels:                 <none>\n\tAnnotations:            deployment.kubernetes.io/revision: 1\n\t                        kubernetes.io/change-cause: kubectl create --filename=kubia-deployment-v1.yaml --record=true\n\tSelector:               app=kubia\n\tReplicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable\n\tStrategyType:           RollingUpdate\n\tMinReadySeconds:        0\n\tRollingUpdateStrategy:  25% max unavailable, 25% max surge\n\tPod Template:\n\t  Labels:  app=kubia\n\t  Containers:\n\t   nodejs:\n\t    Image:        luksa/kubia:v1\n\t    Port:         <none>\n\t    Host Port:    <none>\n\t    Environment:  <none>\n\t    Mounts:       <none>\n\t  Volumes:        <none>\n\tConditions:\n\t  Type           Status  Reason\n\t  ----           ------  ------\n\t  Available      True    MinimumReplicasAvailable\n\t  Progressing    True    NewReplicaSetAvailable\n\tOldReplicaSets:  <none>\n\tNewReplicaSet:   kubia-59d857b444 (3/3 replicas created)\n\tEvents:\n\t  Type    Reason             Age    From                   Message\n\t  ----    ------             ----   ----                   -------\n\t  Normal  ScalingReplicaSet  7m12s  deployment-controller  Scaled up replica set kubia-59d857b444 to 3\n略微减慢滚动升级的速度， 以便观察升级过程确实是以滚动的方式执行的。 可以通过在Deployment上设置minReadySeconds属性来实现\nminReadySeconds的主要功能是避免部署出错版本的应用， 而不只是单纯地减慢部署的速度.\nminReadySeconds属性指定新创建的pod至少要成功运行多久之后，才能将其视为可用.\n通常情况下需要 将minReadySeconds设置为更高的值， 以确保pod在它们真正开始接收实际流量之后可以持续保持就绪状态.\n\n如kubectl patch命令将其设置为10秒\n\n\t$ kubectl patch deployment kubia -p '{\"spec\": {\"minreadyseconds\": 10}}'\n## 重新部署几种方式\n重建(recreate)，滚动(rollingUpdate)，蓝绿，金丝雀\n\n### recreate\n停止Pod并重新创建Pod\n\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\t  name: web-recreate\n\t  namespace: dev\n\tspec:\n\t  strategy:\n\t    type: Recreate\t\t// 停止Pod并重新创建Pod\n\t  selector:\n\t    matchLabels:\n\t      app: web-recreate\n\t  replicas: 2\n\t  template:\n\t......\n\tapiVersion: extensions/v1beta1\n\tkind: Ingress\n\tmetadata:\n\t  name: web-recreate\n\t  namespace: dev\n\tspec:\n\t  rules:\n\t  - host: web-recreate.mooc.com  //配置下/etc/hosts 文件 \"IP web-recreate.mooc.com\"\n\t    http:\n\t      paths:\n\t      - path: /\n\t        backend:\n\t          serviceName: web-recreate\n\t          servicePort: 80\n\n\n### 滚动更新deployment\n滚动更新过程svc的IP等不会变，只是改变pod版本，修改pod的镜像就可以了\n> 实际上， 如何达到新的系统状态的过程是由 Deployment 的升级策略决定的，默认策略是执行滚动更新（策略名为 RollingUpdate)。 另 一种策略为 Recreate, 它会一次性删除所有旧版本的 pod, 然后创建新的 pod, 整个行为类似千修改ReplicationController 的 pod 模板， 然后删除所有的 pod\n使用kubectl set image命令来更改任何包含容器资源的镜像(ReplicationController、ReplicaSet、 Deployment等）\n\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\t  name: web-rollingupdate\n\t  namespace: dev\n\tspec:\n\t  strategy:\n\t    rollingUpdate:\t\t\t// 滚动更新, 不设置的话都会设成跟下面一样的默认值, $kubectl get deployment Name -o yaml查看\n\t      maxSurge: 25%\t\t\t// 可以最大超出实力数的百分比，4个replicas，就是每次最多多启动1个实例\n\t      maxUnavailable: 25%\t// 不可用实力百分比，4个replicas，就是每次必须有3个实例可用\n\t    type: RollingUpdate\n\t  selector:\n\t    matchLabels:\n\t      app: web-rollingupdate\n\t  replicas: 2\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: web-bluegreen\n\t        version: v1.0\n\t    spec:\n\t......\n\n\t$ kubectl set image deployment kubia nodejs=luksa/kubia:v2\n\tdeployment.apps/kubia image updated\n创建rs，然后新的rs会创建一个pod，然后原来的rs删除一个pod，新的rs再创建一个pod，依次完成设定的3个pod都完成更新.\n通过命令定时查看输出:\n\n\t$ while sleep 0.2; do curl \"http://web-rollingupdate.mooc.com/hello?name=michael\"; echo \"\"; done\n查看Pod:\n\n\t$ kubectl get po\n\tNAME                     READY   STATUS              RESTARTS   AGE\n\tfortune                  2/2     Running             0          3d\n\tkubia-59d857b444-6nq74   1/1     Running             0          72s\n\tkubia-59d857b444-jbln7   1/1     Terminating         0          72s\n\tkubia-59d857b444-lr2zw   1/1     Running             0          72s\n\tkubia-7d5c456ffc-69gg5   0/1     ContainerCreating   0          2s\n\tkubia-7d5c456ffc-vmz74   1/1     Running             0          14s\n\n滚动更新后旧的 ReplicaSet 仍然会被保留\n\n\t$ kubectl get rs\n\tNAME               DESIRED   CURRENT   READY   AGE\n\tkubia-59d857b444   3         3         3       9m27s\n\tkubia-7d5c456ffc   1         1         0       3s\n再等待一会再查看rs\n\n\t$ kubectl get rs\n\tNAME               DESIRED   CURRENT   READY   AGE\n\tkubia-59d857b444   0         0         0       10m\n\tkubia-7d5c456ffc   3         3         3       72s\n\nDeployment可以非常容易地回滚到先前部署的版本，它可以让Kubernetes 取消最后一次部署的 Deployment\n\n\t$ kubectl set image deployment kubia nodejs=luksa/kubia:v2\n\t$ kubectl get rs\n\tNAME               DESIRED   CURRENT   READY   AGE\n\tkubia-59d857b444   0         0         0       3h3m\n\tkubia-79b84b44f4   3         3         3       96s\n\tkubia-7d5c456ffc   0         0         0       174m\nundo 命令也可以在滚动升级过程中运行，并直接停止滚动升级。 在升级过程中已创建的 pod 会被删除并被老版本的 pod 替代\n\n\t$ kubectl rollout undo deployment kubia\n\tdeployment.apps/kubia rolled back\n\t$ kubectl get rs\n\tNAME               DESIRED   CURRENT   READY   AGE\n\tkubia-59d857b444   0         0         0       3h7m\n\tkubia-79b84b44f4   0         0         0       5m19s\n\tkubia-7d5c456ffc   3         3         3       177m\n\nkubectl rollout history 来显示升级的版本\n\n\t$ kubectl rollout history deployment kubia\n\tdeployment.apps/kubia\n\tREVISION  CHANGE-CAUSE\n\t1         kubectl create --filename=kubia-deployment-v1.yaml --record=true\n\t2         kubectl create --filename=kubia-deployment-v1.yaml --record=true\n\t3         kubectl create --filename=kubia-deployment-v1.yaml --record=true\n\n### 回滚到一个特定的 Deployment 版本\n\n\t$ kubectl rollout undo deployment kubia --to-revision=l\n\tdeployment.apps/kubia rolled back\n> 旧版本的 ReplicaSet 过多会导致 ReplicaSet 列表过于混乱，可以通过指定Deployment 的 re visionHistoryLimit 属性来限制历史版本数量。默认值是 2\n\n\t$ kubectl rollout history deployment kubia\n\tdeployment.apps/kubia\n\tREVISION  CHANGE-CAUSE\n\t2         kubectl create --filename=kubia-deployment-v1.yaml --record=true\n\t3         kubectl create --filename=kubia-deployment-v1.yaml --record=true\n\t4         kubectl create --filename=kubia-deployment-v1.yaml --record=true\n\n### 滚动升级速率\n在 Deployment 的滚动升级期间，有两个属性会决定一次替换多少个pod: maxSurge 和 maxUnavailable。可以通过 Deployment 的 strategy 字 段下rollingUpdate 的子属性来配置.\n\n\tspec:\n\t  strategy:\n\t    rollingUpdate:\n\t      maxSurge· 1\n\t      maxUnavailable: 0\n\t    type: RollingUpdate\n\n> * maxSurge: 决定了 Deployment 配置中期望的副本数之外，最多允许超出的 pod 实例的数量。默认值为 25%，所以 pod 实例最多可以比期望数量多25%. 这个值也可以不是百分数而是绝对值(例如，可以允许最多多出一个成两个pod).\n> * maxUnavailable: 决定了在滚动升级期间 ，相对于期望副本数能够允许有多少 pod 实例处于不可用状态。默认值也是25%, 所以可用 pod 实例的数量不能低于期望副本数的75%. 与 maxSurge 一样，也可以指定绝对值而不是百分比.\n\n### 暂停滚动升级\n\n\t$ kubectl set image deployment kubia nodejs=luksa/kubia:v4\n\tdeployment \"kubia\" image updated\n\t$ kubectl rollout pause deployment kubia\n\tdeployment \"kubia\" paused\n\n### 恢复滚动升级\n如果部署被暂停， 那么在恢复部署之前， 撤销命令不会撤销它\n\n\t$ kubectl rollout resume deployment kubia\n\tdeployment \"kubia\" resumed\n\n### readinessProbe\nkubia-deployment-v3-with-readinesscheck.yaml\n\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\t  name: kubia\n\tspec:\n\t  replicas: 3\t\t\t\t\t// POD副本个数为3\n\t  minReadySeconds: 10\t\t\t// 设置minReadySeconds 值为10s,指定新创建的pod至少要成功运行多久之后，才能将其视为可用.\n\t  progressDeadlineSeconds: 120\t// 设置升级失败超时时间，超过则自动停止升级，如下describe deployment 可查看到\"Progressing False...\"信息，需要手动undo来取消升级\n\t  strategy:\n\t    rollingUpdate:\n\t      maxSurge: 1\n\t      maxUnavailable: 0\t\t\t// 设置maxUnavailable的 中值为0来确保升级过程 pod被挨个替换\n\t    type: RollingUpdate\n\t  selector:\n\t    matchLabels:\n\t      app: kubia\n\t  template:\n\t    metadata:\n\t      name: kubia\n\t      labels:\n\t        app: kubia\n\t    spec:\n\t      containers:\n\t      - image: luksa/kubia:v3\t// 修改image\n\t        name: nodejs\n\t        readinessProbe:\n\t          periodSeconds: 1\t\t// 定义一个就绪探针，并且每隔—秒钟执行一次\n\t          httpGet:\t\t\t\t// 就绪探针会执行发送HTTP GET请求到容器\n\t            path: /\n\t            port: 8080\n直接使用kubectl apply来升级Deployment\napply命令可以用YAML 文件中声明的字段来更新Deployment。不仅更新镜像，而且还添加了就绪探针， 以及在 YAML 中添加或修改的其他声明。 \n如果新的 YAML也包含rep巨 cas字段， 当它与现有Deployment中的数量不一致时， 那么apply 操作也会对Deployment进行扩容.\n\n\t$ kubectl apply -f kubia-deployment-v3-with-readinesscheck.yaml\n\tdeployment \"kubia\" configured\n\n\n### 取消滚动升级\n默认情况下， 在10分钟内不能完成滚动升级的话， 将被视为失败。 如果运行kubectl describe deployment命令， 将会显示一条ProgressDeadlineExceeded的记录.\n判定Deployment滚动升级失败的超时时间， 可以通过设定Deployment spec中的progressDeadlineSeconds来指定.\n如果达到了progressDeadlineSeconds指定的时间， 则滚动升级过程会自动取消.\n\n\t$ kubectl describe deployment kubia\n\tConditions:\n\t  Type           Status  Reason\n\t  ----           ------  ------\n\t  Available      True    MinimumReplicasAvailable\n\t  Progressing    True    ReplicaSetUpdated\n\t......\n过了3，4分钟后再次执行\n\n\t$ kubectl describe deployment kubia\n\tName:                   kubia\n\t......\n\tConditions:\n\t  Type           Status  Reason\n\t  ----           ------  ------\n\t  Available      True    MinimumReplicasAvailable\n\t  Progressing    False   ProgressDeadlineExceeded\n\tOldReplicaSets:  kubia-59d857b444 (3/3 replicas created)\n\tNewReplicaSet:   kubia-7d6c89d47b (1/1 replicas created)\n\t......\n\n因为滚动升级过程不再继续， 所以只能通过rollout undo命令来取消滚动升级, 其实就是回滚上一个版本.\n\n\t$ kubectl rollout undo deployment kubia\n\tdeployment.apps/kubia rolled back\n\n### 蓝绿部署\n可以通过修改Service下的不同version值，选择应用不同版本的Pod来提供服务.\n新版本运行起来一段时间没问题后才可以删除旧版本.\n一般保持有两个版本的应用也就是Pod保持运行状态, 只有下个版本部署一段时间没问题后，第一个版本的可以删除.\n\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\t  name: web-rollingupdate\n\t  namespace: dev\n\tspec:\n\t  strategy:\n\t    rollingUpdate:\t\t\t// 滚动更新, 不设置的话都会设成跟下面一样的默认值, $kubectl get deployment Name -o yaml查看\n\t      maxSurge: 25%\t\t\t// 可以最大超出实力数的百分比，4个replicas，就是每次最多多启动1个实例\n\t      maxUnavailable: 25%\t// 不可用实力百分比，4个replicas，就是每次必须有3个实例可用\n\t    type: RollingUpdate\n\t  selector:\n\t    matchLabels:\n\t      app: web-rollingupdate\n\t  replicas: 2\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: web-bluegreen\n\t        version: v2.0\t\t// 蓝绿部署，与下面的version一致，部署不同版本的应用\n\t    spec:\n\t......\n\t---\n\tapiVersion: v1\n\tkind: Service\n\tmetadata:\n\t  name: web-bluegreen\n\t  namespace: dev\n\tspec:\n\t  ports:\n\t  - ports: 80\n\t    protocol: TCP\n\t    targetPort: 8080\n\t  selector:\n\t    app: web-bluegreen\n\t    version: v2.0\t\t\t// 与上面的version一致，部署不同版本应用, 下次部署单独抽离Service，选择不同版本version就可以了\n\t  type: ClusterIP\n\t---\n\t......\n\n### 金丝雀发布\n> 在蓝绿部署的基础之上，去掉version, 修改selector就是金丝雀部署.\n> 一个新的 pod 会被创建， 与此同时所有旧的 pod 还在运行。 一旦新的 pod 成功运行， 服务的一部分请求将被切换到新的 pod。 这样相当于 运行了一个金丝雀版本。金丝雀发布是一种可以将应用程序的出错版本和其影响到的用户的风险化为最小的技术.\n> 与其直接向每个用户发布新版本， 不如用新版本替换 一个或一小部分的 pod。通过 这种方式， 在升级的初期只有少数用户会访问新版本。 验证新版本是否正常工作之后， 可以将剩余的 pod 继续升级或者回滚到上一个的版本\n\n### 删除deployment\n删除deployment会连带删除创建的replicaset和由replicaset创建的pod\n\n\t$ kubectl delete deployment kubia\n\tdeployment.apps \"kubia\" deleted\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/micro_service/06_kubernetes_deployment.md","raw":"---\ntitle: 06 Kubernetes deployment\ntags: kubernetes\ncategories:\n- microService\n- kubernetes\ntop: 6\n---\n\n## deployment\nDeployment 是一种更高阶资源， 用千部署应用程序并以声明的方式升级应用, 而不是通过 ReplicationController 或 ReplicaSet 进行部署， 它们都被认为是更底层的概念.\n当创建一个 Deployment 时， ReplicaSet 资源也会随之创建.\n在使用 Deployment 时， 实际的 pod是由 Deployment 的 Replicaset 创建和管理的， 而不是由 Deployment 直接创建和管理的.\n> 创建Deployment与创建ReplicationController并没有任何区别。Deployment也是由标签选择器、期望副数和pod模板组成的。此外，它还包含另 一 个字段，指定一 个部署策略，该策略定义在修改Deployment资源时应该如何执行更新\nDeployment可以同时管理多个版本的 pod, 所以在命名时不需要指定应用的版本号\nkubia-svc-loadbalancer.yaml\n\n\tapiVersion: v1\n\tkind: Service\n\tmetadata:\n\t  name: kubia-loadbalancer\n\tspec:\n\t  type: LoadBalancer\n\t  ports:\n\t  - port: 80\n\t    targetPort: 8080\n\t  selector:\n\t    app: kubia\nkubia-deployment-v1.yaml\n\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\t  name: kubia\n\tspec:\n\t  replicas: 3\n\t  selector:\n\t    matchLabels:\n\t      app: kubia\n\t  template:\n\t    metadata:\n\t      name: kubia\n\t      labels:\n\t        app: kubia\n\t    spec:\n\t      containers:\n\t      - image: luksa/kubia:v1\n\t        name: nodejs\n创建deployment\n\n\t$ kubectl create -f kubia-deployment-v1.yaml --record\n查看deployment过程\n\n\t$ kubectl rollout status deployment kubia\n\tWaiting for deployment \"kubia\" rollout to finish: 1 out of 3 new replicas have been updated...\n\tWaiting for deployment \"kubia\" rollout to finish: 1 out of 3 new replicas have been updated...\n\tWaiting for deployment \"kubia\" rollout to finish: 2 out of 3 new replicas have been updated...\n\tWaiting for deployment \"kubia\" rollout to finish: 2 out of 3 new replicas have been updated...\n\tWaiting for deployment \"kubia\" rollout to finish: 2 out of 3 new replicas have been updated...\n\tWaiting for deployment \"kubia\" rollout to finish: 2 out of 3 new replicas have been updated...\n\tWaiting for deployment \"kubia\" rollout to finish: 1 old replicas are pending termination...\n\tWaiting for deployment \"kubia\" rollout to finish: 1 old replicas are pending termination...\n\tWaiting for deployment \"kubia\" rollout to finish: 1 old replicas are pending termination...\n\tdeployment \"kubia\" successfully rolled out\n当使用 ReplicationController 创建 pod 时， 它们的名称是由 Controller 的名称加上一个运行时生成的随机字符串.\n由 Deployment 创建的三个 pod 名称中均包含一个额外的数字, 这个数字实际上对应 Deployment 和 ReplicaSet 中的 pod 模板的哈希值\n\n\t$ kubectl get po\n\tkubia-59d857b444-2nrr7   1/1     Running   0          5m15s\n\tkubia-59d857b444-f9pnx   1/1     Running   0          5m15s\n\tkubia-59d857b444-wzgnj   1/1     Running   0          5m15s\n\n\t$ kubectl get replicasets\n\tNAME               DESIRED   CURRENT   READY   AGE\n\tkubia-59d857b444   3         3         3       8m48s\n\n\t$ kubectl get svc\n\tNAME                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\n\tkubernetes           ClusterIP      10.96.0.1       <none>        443/TCP        4d22h\n\tkubia-loadbalancer   LoadBalancer   10.100.58.157   <pending>     80:31170/TCP   3s\n查看master node 的IP为10.239.140.186\n\n\t$ curl 10.239.140.186:31170\n\tThis is v1 running in pod kubia-59d857b444-wzgnj\n查看deployment详细信息\n\n\t$ kubectl describe deployment kubia\n\tName:                   kubia\n\tNamespace:              default\n\tCreationTimestamp:      Mon, 18 May 2020 15:04:12 +0800\n\tLabels:                 <none>\n\tAnnotations:            deployment.kubernetes.io/revision: 1\n\t                        kubernetes.io/change-cause: kubectl create --filename=kubia-deployment-v1.yaml --record=true\n\tSelector:               app=kubia\n\tReplicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable\n\tStrategyType:           RollingUpdate\n\tMinReadySeconds:        0\n\tRollingUpdateStrategy:  25% max unavailable, 25% max surge\n\tPod Template:\n\t  Labels:  app=kubia\n\t  Containers:\n\t   nodejs:\n\t    Image:        luksa/kubia:v1\n\t    Port:         <none>\n\t    Host Port:    <none>\n\t    Environment:  <none>\n\t    Mounts:       <none>\n\t  Volumes:        <none>\n\tConditions:\n\t  Type           Status  Reason\n\t  ----           ------  ------\n\t  Available      True    MinimumReplicasAvailable\n\t  Progressing    True    NewReplicaSetAvailable\n\tOldReplicaSets:  <none>\n\tNewReplicaSet:   kubia-59d857b444 (3/3 replicas created)\n\tEvents:\n\t  Type    Reason             Age    From                   Message\n\t  ----    ------             ----   ----                   -------\n\t  Normal  ScalingReplicaSet  7m12s  deployment-controller  Scaled up replica set kubia-59d857b444 to 3\n略微减慢滚动升级的速度， 以便观察升级过程确实是以滚动的方式执行的。 可以通过在Deployment上设置minReadySeconds属性来实现\nminReadySeconds的主要功能是避免部署出错版本的应用， 而不只是单纯地减慢部署的速度.\nminReadySeconds属性指定新创建的pod至少要成功运行多久之后，才能将其视为可用.\n通常情况下需要 将minReadySeconds设置为更高的值， 以确保pod在它们真正开始接收实际流量之后可以持续保持就绪状态.\n\n如kubectl patch命令将其设置为10秒\n\n\t$ kubectl patch deployment kubia -p '{\"spec\": {\"minreadyseconds\": 10}}'\n## 重新部署几种方式\n重建(recreate)，滚动(rollingUpdate)，蓝绿，金丝雀\n\n### recreate\n停止Pod并重新创建Pod\n\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\t  name: web-recreate\n\t  namespace: dev\n\tspec:\n\t  strategy:\n\t    type: Recreate\t\t// 停止Pod并重新创建Pod\n\t  selector:\n\t    matchLabels:\n\t      app: web-recreate\n\t  replicas: 2\n\t  template:\n\t......\n\tapiVersion: extensions/v1beta1\n\tkind: Ingress\n\tmetadata:\n\t  name: web-recreate\n\t  namespace: dev\n\tspec:\n\t  rules:\n\t  - host: web-recreate.mooc.com  //配置下/etc/hosts 文件 \"IP web-recreate.mooc.com\"\n\t    http:\n\t      paths:\n\t      - path: /\n\t        backend:\n\t          serviceName: web-recreate\n\t          servicePort: 80\n\n\n### 滚动更新deployment\n滚动更新过程svc的IP等不会变，只是改变pod版本，修改pod的镜像就可以了\n> 实际上， 如何达到新的系统状态的过程是由 Deployment 的升级策略决定的，默认策略是执行滚动更新（策略名为 RollingUpdate)。 另 一种策略为 Recreate, 它会一次性删除所有旧版本的 pod, 然后创建新的 pod, 整个行为类似千修改ReplicationController 的 pod 模板， 然后删除所有的 pod\n使用kubectl set image命令来更改任何包含容器资源的镜像(ReplicationController、ReplicaSet、 Deployment等）\n\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\t  name: web-rollingupdate\n\t  namespace: dev\n\tspec:\n\t  strategy:\n\t    rollingUpdate:\t\t\t// 滚动更新, 不设置的话都会设成跟下面一样的默认值, $kubectl get deployment Name -o yaml查看\n\t      maxSurge: 25%\t\t\t// 可以最大超出实力数的百分比，4个replicas，就是每次最多多启动1个实例\n\t      maxUnavailable: 25%\t// 不可用实力百分比，4个replicas，就是每次必须有3个实例可用\n\t    type: RollingUpdate\n\t  selector:\n\t    matchLabels:\n\t      app: web-rollingupdate\n\t  replicas: 2\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: web-bluegreen\n\t        version: v1.0\n\t    spec:\n\t......\n\n\t$ kubectl set image deployment kubia nodejs=luksa/kubia:v2\n\tdeployment.apps/kubia image updated\n创建rs，然后新的rs会创建一个pod，然后原来的rs删除一个pod，新的rs再创建一个pod，依次完成设定的3个pod都完成更新.\n通过命令定时查看输出:\n\n\t$ while sleep 0.2; do curl \"http://web-rollingupdate.mooc.com/hello?name=michael\"; echo \"\"; done\n查看Pod:\n\n\t$ kubectl get po\n\tNAME                     READY   STATUS              RESTARTS   AGE\n\tfortune                  2/2     Running             0          3d\n\tkubia-59d857b444-6nq74   1/1     Running             0          72s\n\tkubia-59d857b444-jbln7   1/1     Terminating         0          72s\n\tkubia-59d857b444-lr2zw   1/1     Running             0          72s\n\tkubia-7d5c456ffc-69gg5   0/1     ContainerCreating   0          2s\n\tkubia-7d5c456ffc-vmz74   1/1     Running             0          14s\n\n滚动更新后旧的 ReplicaSet 仍然会被保留\n\n\t$ kubectl get rs\n\tNAME               DESIRED   CURRENT   READY   AGE\n\tkubia-59d857b444   3         3         3       9m27s\n\tkubia-7d5c456ffc   1         1         0       3s\n再等待一会再查看rs\n\n\t$ kubectl get rs\n\tNAME               DESIRED   CURRENT   READY   AGE\n\tkubia-59d857b444   0         0         0       10m\n\tkubia-7d5c456ffc   3         3         3       72s\n\nDeployment可以非常容易地回滚到先前部署的版本，它可以让Kubernetes 取消最后一次部署的 Deployment\n\n\t$ kubectl set image deployment kubia nodejs=luksa/kubia:v2\n\t$ kubectl get rs\n\tNAME               DESIRED   CURRENT   READY   AGE\n\tkubia-59d857b444   0         0         0       3h3m\n\tkubia-79b84b44f4   3         3         3       96s\n\tkubia-7d5c456ffc   0         0         0       174m\nundo 命令也可以在滚动升级过程中运行，并直接停止滚动升级。 在升级过程中已创建的 pod 会被删除并被老版本的 pod 替代\n\n\t$ kubectl rollout undo deployment kubia\n\tdeployment.apps/kubia rolled back\n\t$ kubectl get rs\n\tNAME               DESIRED   CURRENT   READY   AGE\n\tkubia-59d857b444   0         0         0       3h7m\n\tkubia-79b84b44f4   0         0         0       5m19s\n\tkubia-7d5c456ffc   3         3         3       177m\n\nkubectl rollout history 来显示升级的版本\n\n\t$ kubectl rollout history deployment kubia\n\tdeployment.apps/kubia\n\tREVISION  CHANGE-CAUSE\n\t1         kubectl create --filename=kubia-deployment-v1.yaml --record=true\n\t2         kubectl create --filename=kubia-deployment-v1.yaml --record=true\n\t3         kubectl create --filename=kubia-deployment-v1.yaml --record=true\n\n### 回滚到一个特定的 Deployment 版本\n\n\t$ kubectl rollout undo deployment kubia --to-revision=l\n\tdeployment.apps/kubia rolled back\n> 旧版本的 ReplicaSet 过多会导致 ReplicaSet 列表过于混乱，可以通过指定Deployment 的 re visionHistoryLimit 属性来限制历史版本数量。默认值是 2\n\n\t$ kubectl rollout history deployment kubia\n\tdeployment.apps/kubia\n\tREVISION  CHANGE-CAUSE\n\t2         kubectl create --filename=kubia-deployment-v1.yaml --record=true\n\t3         kubectl create --filename=kubia-deployment-v1.yaml --record=true\n\t4         kubectl create --filename=kubia-deployment-v1.yaml --record=true\n\n### 滚动升级速率\n在 Deployment 的滚动升级期间，有两个属性会决定一次替换多少个pod: maxSurge 和 maxUnavailable。可以通过 Deployment 的 strategy 字 段下rollingUpdate 的子属性来配置.\n\n\tspec:\n\t  strategy:\n\t    rollingUpdate:\n\t      maxSurge· 1\n\t      maxUnavailable: 0\n\t    type: RollingUpdate\n\n> * maxSurge: 决定了 Deployment 配置中期望的副本数之外，最多允许超出的 pod 实例的数量。默认值为 25%，所以 pod 实例最多可以比期望数量多25%. 这个值也可以不是百分数而是绝对值(例如，可以允许最多多出一个成两个pod).\n> * maxUnavailable: 决定了在滚动升级期间 ，相对于期望副本数能够允许有多少 pod 实例处于不可用状态。默认值也是25%, 所以可用 pod 实例的数量不能低于期望副本数的75%. 与 maxSurge 一样，也可以指定绝对值而不是百分比.\n\n### 暂停滚动升级\n\n\t$ kubectl set image deployment kubia nodejs=luksa/kubia:v4\n\tdeployment \"kubia\" image updated\n\t$ kubectl rollout pause deployment kubia\n\tdeployment \"kubia\" paused\n\n### 恢复滚动升级\n如果部署被暂停， 那么在恢复部署之前， 撤销命令不会撤销它\n\n\t$ kubectl rollout resume deployment kubia\n\tdeployment \"kubia\" resumed\n\n### readinessProbe\nkubia-deployment-v3-with-readinesscheck.yaml\n\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\t  name: kubia\n\tspec:\n\t  replicas: 3\t\t\t\t\t// POD副本个数为3\n\t  minReadySeconds: 10\t\t\t// 设置minReadySeconds 值为10s,指定新创建的pod至少要成功运行多久之后，才能将其视为可用.\n\t  progressDeadlineSeconds: 120\t// 设置升级失败超时时间，超过则自动停止升级，如下describe deployment 可查看到\"Progressing False...\"信息，需要手动undo来取消升级\n\t  strategy:\n\t    rollingUpdate:\n\t      maxSurge: 1\n\t      maxUnavailable: 0\t\t\t// 设置maxUnavailable的 中值为0来确保升级过程 pod被挨个替换\n\t    type: RollingUpdate\n\t  selector:\n\t    matchLabels:\n\t      app: kubia\n\t  template:\n\t    metadata:\n\t      name: kubia\n\t      labels:\n\t        app: kubia\n\t    spec:\n\t      containers:\n\t      - image: luksa/kubia:v3\t// 修改image\n\t        name: nodejs\n\t        readinessProbe:\n\t          periodSeconds: 1\t\t// 定义一个就绪探针，并且每隔—秒钟执行一次\n\t          httpGet:\t\t\t\t// 就绪探针会执行发送HTTP GET请求到容器\n\t            path: /\n\t            port: 8080\n直接使用kubectl apply来升级Deployment\napply命令可以用YAML 文件中声明的字段来更新Deployment。不仅更新镜像，而且还添加了就绪探针， 以及在 YAML 中添加或修改的其他声明。 \n如果新的 YAML也包含rep巨 cas字段， 当它与现有Deployment中的数量不一致时， 那么apply 操作也会对Deployment进行扩容.\n\n\t$ kubectl apply -f kubia-deployment-v3-with-readinesscheck.yaml\n\tdeployment \"kubia\" configured\n\n\n### 取消滚动升级\n默认情况下， 在10分钟内不能完成滚动升级的话， 将被视为失败。 如果运行kubectl describe deployment命令， 将会显示一条ProgressDeadlineExceeded的记录.\n判定Deployment滚动升级失败的超时时间， 可以通过设定Deployment spec中的progressDeadlineSeconds来指定.\n如果达到了progressDeadlineSeconds指定的时间， 则滚动升级过程会自动取消.\n\n\t$ kubectl describe deployment kubia\n\tConditions:\n\t  Type           Status  Reason\n\t  ----           ------  ------\n\t  Available      True    MinimumReplicasAvailable\n\t  Progressing    True    ReplicaSetUpdated\n\t......\n过了3，4分钟后再次执行\n\n\t$ kubectl describe deployment kubia\n\tName:                   kubia\n\t......\n\tConditions:\n\t  Type           Status  Reason\n\t  ----           ------  ------\n\t  Available      True    MinimumReplicasAvailable\n\t  Progressing    False   ProgressDeadlineExceeded\n\tOldReplicaSets:  kubia-59d857b444 (3/3 replicas created)\n\tNewReplicaSet:   kubia-7d6c89d47b (1/1 replicas created)\n\t......\n\n因为滚动升级过程不再继续， 所以只能通过rollout undo命令来取消滚动升级, 其实就是回滚上一个版本.\n\n\t$ kubectl rollout undo deployment kubia\n\tdeployment.apps/kubia rolled back\n\n### 蓝绿部署\n可以通过修改Service下的不同version值，选择应用不同版本的Pod来提供服务.\n新版本运行起来一段时间没问题后才可以删除旧版本.\n一般保持有两个版本的应用也就是Pod保持运行状态, 只有下个版本部署一段时间没问题后，第一个版本的可以删除.\n\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\t  name: web-rollingupdate\n\t  namespace: dev\n\tspec:\n\t  strategy:\n\t    rollingUpdate:\t\t\t// 滚动更新, 不设置的话都会设成跟下面一样的默认值, $kubectl get deployment Name -o yaml查看\n\t      maxSurge: 25%\t\t\t// 可以最大超出实力数的百分比，4个replicas，就是每次最多多启动1个实例\n\t      maxUnavailable: 25%\t// 不可用实力百分比，4个replicas，就是每次必须有3个实例可用\n\t    type: RollingUpdate\n\t  selector:\n\t    matchLabels:\n\t      app: web-rollingupdate\n\t  replicas: 2\n\t  template:\n\t    metadata:\n\t      labels:\n\t        app: web-bluegreen\n\t        version: v2.0\t\t// 蓝绿部署，与下面的version一致，部署不同版本的应用\n\t    spec:\n\t......\n\t---\n\tapiVersion: v1\n\tkind: Service\n\tmetadata:\n\t  name: web-bluegreen\n\t  namespace: dev\n\tspec:\n\t  ports:\n\t  - ports: 80\n\t    protocol: TCP\n\t    targetPort: 8080\n\t  selector:\n\t    app: web-bluegreen\n\t    version: v2.0\t\t\t// 与上面的version一致，部署不同版本应用, 下次部署单独抽离Service，选择不同版本version就可以了\n\t  type: ClusterIP\n\t---\n\t......\n\n### 金丝雀发布\n> 在蓝绿部署的基础之上，去掉version, 修改selector就是金丝雀部署.\n> 一个新的 pod 会被创建， 与此同时所有旧的 pod 还在运行。 一旦新的 pod 成功运行， 服务的一部分请求将被切换到新的 pod。 这样相当于 运行了一个金丝雀版本。金丝雀发布是一种可以将应用程序的出错版本和其影响到的用户的风险化为最小的技术.\n> 与其直接向每个用户发布新版本， 不如用新版本替换 一个或一小部分的 pod。通过 这种方式， 在升级的初期只有少数用户会访问新版本。 验证新版本是否正常工作之后， 可以将剩余的 pod 继续升级或者回滚到上一个的版本\n\n### 删除deployment\n删除deployment会连带删除创建的replicaset和由replicaset创建的pod\n\n\t$ kubectl delete deployment kubia\n\tdeployment.apps \"kubia\" deleted\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"micro_service/06_kubernetes_deployment","published":1,"date":"2020-08-12T16:05:47.411Z","updated":"2020-08-10T16:36:34.335Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmg7004ghohx49b3enuo","content":"<h2 id=\"deployment\"><a href=\"#deployment\" class=\"headerlink\" title=\"deployment\"></a>deployment</h2><p>Deployment 是一种更高阶资源， 用千部署应用程序并以声明的方式升级应用, 而不是通过 ReplicationController 或 ReplicaSet 进行部署， 它们都被认为是更底层的概念.<br>当创建一个 Deployment 时， ReplicaSet 资源也会随之创建.<br>在使用 Deployment 时， 实际的 pod是由 Deployment 的 Replicaset 创建和管理的， 而不是由 Deployment 直接创建和管理的.</p>\n<blockquote>\n<p>创建Deployment与创建ReplicationController并没有任何区别。Deployment也是由标签选择器、期望副数和pod模板组成的。此外，它还包含另 一 个字段，指定一 个部署策略，该策略定义在修改Deployment资源时应该如何执行更新<br>Deployment可以同时管理多个版本的 pod, 所以在命名时不需要指定应用的版本号<br>kubia-svc-loadbalancer.yaml</p>\n</blockquote>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: kubia-loadbalancer\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 80\n    targetPort: 8080\n  selector:\n    app: kubia</code></pre><p>kubia-deployment-v1.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kubia\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: kubia\n  template:\n    metadata:\n      name: kubia\n      labels:\n        app: kubia\n    spec:\n      containers:\n      - image: luksa/kubia:v1\n        name: nodejs</code></pre><p>创建deployment</p>\n<pre><code>$ kubectl create -f kubia-deployment-v1.yaml --record</code></pre><p>查看deployment过程</p>\n<pre><code>$ kubectl rollout status deployment kubia\nWaiting for deployment &quot;kubia&quot; rollout to finish: 1 out of 3 new replicas have been updated...\nWaiting for deployment &quot;kubia&quot; rollout to finish: 1 out of 3 new replicas have been updated...\nWaiting for deployment &quot;kubia&quot; rollout to finish: 2 out of 3 new replicas have been updated...\nWaiting for deployment &quot;kubia&quot; rollout to finish: 2 out of 3 new replicas have been updated...\nWaiting for deployment &quot;kubia&quot; rollout to finish: 2 out of 3 new replicas have been updated...\nWaiting for deployment &quot;kubia&quot; rollout to finish: 2 out of 3 new replicas have been updated...\nWaiting for deployment &quot;kubia&quot; rollout to finish: 1 old replicas are pending termination...\nWaiting for deployment &quot;kubia&quot; rollout to finish: 1 old replicas are pending termination...\nWaiting for deployment &quot;kubia&quot; rollout to finish: 1 old replicas are pending termination...\ndeployment &quot;kubia&quot; successfully rolled out</code></pre><p>当使用 ReplicationController 创建 pod 时， 它们的名称是由 Controller 的名称加上一个运行时生成的随机字符串.<br>由 Deployment 创建的三个 pod 名称中均包含一个额外的数字, 这个数字实际上对应 Deployment 和 ReplicaSet 中的 pod 模板的哈希值</p>\n<pre><code>$ kubectl get po\nkubia-59d857b444-2nrr7   1/1     Running   0          5m15s\nkubia-59d857b444-f9pnx   1/1     Running   0          5m15s\nkubia-59d857b444-wzgnj   1/1     Running   0          5m15s\n\n$ kubectl get replicasets\nNAME               DESIRED   CURRENT   READY   AGE\nkubia-59d857b444   3         3         3       8m48s\n\n$ kubectl get svc\nNAME                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\nkubernetes           ClusterIP      10.96.0.1       &lt;none&gt;        443/TCP        4d22h\nkubia-loadbalancer   LoadBalancer   10.100.58.157   &lt;pending&gt;     80:31170/TCP   3s</code></pre><p>查看master node 的IP为10.239.140.186</p>\n<pre><code>$ curl 10.239.140.186:31170\nThis is v1 running in pod kubia-59d857b444-wzgnj</code></pre><p>查看deployment详细信息</p>\n<pre><code>$ kubectl describe deployment kubia\nName:                   kubia\nNamespace:              default\nCreationTimestamp:      Mon, 18 May 2020 15:04:12 +0800\nLabels:                 &lt;none&gt;\nAnnotations:            deployment.kubernetes.io/revision: 1\n                        kubernetes.io/change-cause: kubectl create --filename=kubia-deployment-v1.yaml --record=true\nSelector:               app=kubia\nReplicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable\nStrategyType:           RollingUpdate\nMinReadySeconds:        0\nRollingUpdateStrategy:  25% max unavailable, 25% max surge\nPod Template:\n  Labels:  app=kubia\n  Containers:\n   nodejs:\n    Image:        luksa/kubia:v1\n    Port:         &lt;none&gt;\n    Host Port:    &lt;none&gt;\n    Environment:  &lt;none&gt;\n    Mounts:       &lt;none&gt;\n  Volumes:        &lt;none&gt;\nConditions:\n  Type           Status  Reason\n  ----           ------  ------\n  Available      True    MinimumReplicasAvailable\n  Progressing    True    NewReplicaSetAvailable\nOldReplicaSets:  &lt;none&gt;\nNewReplicaSet:   kubia-59d857b444 (3/3 replicas created)\nEvents:\n  Type    Reason             Age    From                   Message\n  ----    ------             ----   ----                   -------\n  Normal  ScalingReplicaSet  7m12s  deployment-controller  Scaled up replica set kubia-59d857b444 to 3</code></pre><p>略微减慢滚动升级的速度， 以便观察升级过程确实是以滚动的方式执行的。 可以通过在Deployment上设置minReadySeconds属性来实现<br>minReadySeconds的主要功能是避免部署出错版本的应用， 而不只是单纯地减慢部署的速度.<br>minReadySeconds属性指定新创建的pod至少要成功运行多久之后，才能将其视为可用.<br>通常情况下需要 将minReadySeconds设置为更高的值， 以确保pod在它们真正开始接收实际流量之后可以持续保持就绪状态.</p>\n<p>如kubectl patch命令将其设置为10秒</p>\n<pre><code>$ kubectl patch deployment kubia -p &apos;{&quot;spec&quot;: {&quot;minreadyseconds&quot;: 10}}&apos;</code></pre><h2 id=\"重新部署几种方式\"><a href=\"#重新部署几种方式\" class=\"headerlink\" title=\"重新部署几种方式\"></a>重新部署几种方式</h2><p>重建(recreate)，滚动(rollingUpdate)，蓝绿，金丝雀</p>\n<h3 id=\"recreate\"><a href=\"#recreate\" class=\"headerlink\" title=\"recreate\"></a>recreate</h3><p>停止Pod并重新创建Pod</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-recreate\n  namespace: dev\nspec:\n  strategy:\n    type: Recreate        // 停止Pod并重新创建Pod\n  selector:\n    matchLabels:\n      app: web-recreate\n  replicas: 2\n  template:\n......\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: web-recreate\n  namespace: dev\nspec:\n  rules:\n  - host: web-recreate.mooc.com  //配置下/etc/hosts 文件 &quot;IP web-recreate.mooc.com&quot;\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: web-recreate\n          servicePort: 80</code></pre><h3 id=\"滚动更新deployment\"><a href=\"#滚动更新deployment\" class=\"headerlink\" title=\"滚动更新deployment\"></a>滚动更新deployment</h3><p>滚动更新过程svc的IP等不会变，只是改变pod版本，修改pod的镜像就可以了</p>\n<blockquote>\n<p>实际上， 如何达到新的系统状态的过程是由 Deployment 的升级策略决定的，默认策略是执行滚动更新（策略名为 RollingUpdate)。 另 一种策略为 Recreate, 它会一次性删除所有旧版本的 pod, 然后创建新的 pod, 整个行为类似千修改ReplicationController 的 pod 模板， 然后删除所有的 pod<br>使用kubectl set image命令来更改任何包含容器资源的镜像(ReplicationController、ReplicaSet、 Deployment等）</p>\n</blockquote>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-rollingupdate\n  namespace: dev\nspec:\n  strategy:\n    rollingUpdate:            // 滚动更新, 不设置的话都会设成跟下面一样的默认值, $kubectl get deployment Name -o yaml查看\n      maxSurge: 25%            // 可以最大超出实力数的百分比，4个replicas，就是每次最多多启动1个实例\n      maxUnavailable: 25%    // 不可用实力百分比，4个replicas，就是每次必须有3个实例可用\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app: web-rollingupdate\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: web-bluegreen\n        version: v1.0\n    spec:\n......\n\n$ kubectl set image deployment kubia nodejs=luksa/kubia:v2\ndeployment.apps/kubia image updated</code></pre><p>创建rs，然后新的rs会创建一个pod，然后原来的rs删除一个pod，新的rs再创建一个pod，依次完成设定的3个pod都完成更新.<br>通过命令定时查看输出:</p>\n<pre><code>$ while sleep 0.2; do curl &quot;http://web-rollingupdate.mooc.com/hello?name=michael&quot;; echo &quot;&quot;; done</code></pre><p>查看Pod:</p>\n<pre><code>$ kubectl get po\nNAME                     READY   STATUS              RESTARTS   AGE\nfortune                  2/2     Running             0          3d\nkubia-59d857b444-6nq74   1/1     Running             0          72s\nkubia-59d857b444-jbln7   1/1     Terminating         0          72s\nkubia-59d857b444-lr2zw   1/1     Running             0          72s\nkubia-7d5c456ffc-69gg5   0/1     ContainerCreating   0          2s\nkubia-7d5c456ffc-vmz74   1/1     Running             0          14s</code></pre><p>滚动更新后旧的 ReplicaSet 仍然会被保留</p>\n<pre><code>$ kubectl get rs\nNAME               DESIRED   CURRENT   READY   AGE\nkubia-59d857b444   3         3         3       9m27s\nkubia-7d5c456ffc   1         1         0       3s</code></pre><p>再等待一会再查看rs</p>\n<pre><code>$ kubectl get rs\nNAME               DESIRED   CURRENT   READY   AGE\nkubia-59d857b444   0         0         0       10m\nkubia-7d5c456ffc   3         3         3       72s</code></pre><p>Deployment可以非常容易地回滚到先前部署的版本，它可以让Kubernetes 取消最后一次部署的 Deployment</p>\n<pre><code>$ kubectl set image deployment kubia nodejs=luksa/kubia:v2\n$ kubectl get rs\nNAME               DESIRED   CURRENT   READY   AGE\nkubia-59d857b444   0         0         0       3h3m\nkubia-79b84b44f4   3         3         3       96s\nkubia-7d5c456ffc   0         0         0       174m</code></pre><p>undo 命令也可以在滚动升级过程中运行，并直接停止滚动升级。 在升级过程中已创建的 pod 会被删除并被老版本的 pod 替代</p>\n<pre><code>$ kubectl rollout undo deployment kubia\ndeployment.apps/kubia rolled back\n$ kubectl get rs\nNAME               DESIRED   CURRENT   READY   AGE\nkubia-59d857b444   0         0         0       3h7m\nkubia-79b84b44f4   0         0         0       5m19s\nkubia-7d5c456ffc   3         3         3       177m</code></pre><p>kubectl rollout history 来显示升级的版本</p>\n<pre><code>$ kubectl rollout history deployment kubia\ndeployment.apps/kubia\nREVISION  CHANGE-CAUSE\n1         kubectl create --filename=kubia-deployment-v1.yaml --record=true\n2         kubectl create --filename=kubia-deployment-v1.yaml --record=true\n3         kubectl create --filename=kubia-deployment-v1.yaml --record=true</code></pre><h3 id=\"回滚到一个特定的-Deployment-版本\"><a href=\"#回滚到一个特定的-Deployment-版本\" class=\"headerlink\" title=\"回滚到一个特定的 Deployment 版本\"></a>回滚到一个特定的 Deployment 版本</h3><pre><code>$ kubectl rollout undo deployment kubia --to-revision=l\ndeployment.apps/kubia rolled back</code></pre><blockquote>\n<p>旧版本的 ReplicaSet 过多会导致 ReplicaSet 列表过于混乱，可以通过指定Deployment 的 re visionHistoryLimit 属性来限制历史版本数量。默认值是 2</p>\n</blockquote>\n<pre><code>$ kubectl rollout history deployment kubia\ndeployment.apps/kubia\nREVISION  CHANGE-CAUSE\n2         kubectl create --filename=kubia-deployment-v1.yaml --record=true\n3         kubectl create --filename=kubia-deployment-v1.yaml --record=true\n4         kubectl create --filename=kubia-deployment-v1.yaml --record=true</code></pre><h3 id=\"滚动升级速率\"><a href=\"#滚动升级速率\" class=\"headerlink\" title=\"滚动升级速率\"></a>滚动升级速率</h3><p>在 Deployment 的滚动升级期间，有两个属性会决定一次替换多少个pod: maxSurge 和 maxUnavailable。可以通过 Deployment 的 strategy 字 段下rollingUpdate 的子属性来配置.</p>\n<pre><code>spec:\n  strategy:\n    rollingUpdate:\n      maxSurge· 1\n      maxUnavailable: 0\n    type: RollingUpdate</code></pre><blockquote>\n<ul>\n<li>maxSurge: 决定了 Deployment 配置中期望的副本数之外，最多允许超出的 pod 实例的数量。默认值为 25%，所以 pod 实例最多可以比期望数量多25%. 这个值也可以不是百分数而是绝对值(例如，可以允许最多多出一个成两个pod).</li>\n<li>maxUnavailable: 决定了在滚动升级期间 ，相对于期望副本数能够允许有多少 pod 实例处于不可用状态。默认值也是25%, 所以可用 pod 实例的数量不能低于期望副本数的75%. 与 maxSurge 一样，也可以指定绝对值而不是百分比.</li>\n</ul>\n</blockquote>\n<h3 id=\"暂停滚动升级\"><a href=\"#暂停滚动升级\" class=\"headerlink\" title=\"暂停滚动升级\"></a>暂停滚动升级</h3><pre><code>$ kubectl set image deployment kubia nodejs=luksa/kubia:v4\ndeployment &quot;kubia&quot; image updated\n$ kubectl rollout pause deployment kubia\ndeployment &quot;kubia&quot; paused</code></pre><h3 id=\"恢复滚动升级\"><a href=\"#恢复滚动升级\" class=\"headerlink\" title=\"恢复滚动升级\"></a>恢复滚动升级</h3><p>如果部署被暂停， 那么在恢复部署之前， 撤销命令不会撤销它</p>\n<pre><code>$ kubectl rollout resume deployment kubia\ndeployment &quot;kubia&quot; resumed</code></pre><h3 id=\"readinessProbe\"><a href=\"#readinessProbe\" class=\"headerlink\" title=\"readinessProbe\"></a>readinessProbe</h3><p>kubia-deployment-v3-with-readinesscheck.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kubia\nspec:\n  replicas: 3                    // POD副本个数为3\n  minReadySeconds: 10            // 设置minReadySeconds 值为10s,指定新创建的pod至少要成功运行多久之后，才能将其视为可用.\n  progressDeadlineSeconds: 120    // 设置升级失败超时时间，超过则自动停止升级，如下describe deployment 可查看到&quot;Progressing False...&quot;信息，需要手动undo来取消升级\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0            // 设置maxUnavailable的 中值为0来确保升级过程 pod被挨个替换\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app: kubia\n  template:\n    metadata:\n      name: kubia\n      labels:\n        app: kubia\n    spec:\n      containers:\n      - image: luksa/kubia:v3    // 修改image\n        name: nodejs\n        readinessProbe:\n          periodSeconds: 1        // 定义一个就绪探针，并且每隔—秒钟执行一次\n          httpGet:                // 就绪探针会执行发送HTTP GET请求到容器\n            path: /\n            port: 8080</code></pre><p>直接使用kubectl apply来升级Deployment<br>apply命令可以用YAML 文件中声明的字段来更新Deployment。不仅更新镜像，而且还添加了就绪探针， 以及在 YAML 中添加或修改的其他声明。<br>如果新的 YAML也包含rep巨 cas字段， 当它与现有Deployment中的数量不一致时， 那么apply 操作也会对Deployment进行扩容.</p>\n<pre><code>$ kubectl apply -f kubia-deployment-v3-with-readinesscheck.yaml\ndeployment &quot;kubia&quot; configured</code></pre><h3 id=\"取消滚动升级\"><a href=\"#取消滚动升级\" class=\"headerlink\" title=\"取消滚动升级\"></a>取消滚动升级</h3><p>默认情况下， 在10分钟内不能完成滚动升级的话， 将被视为失败。 如果运行kubectl describe deployment命令， 将会显示一条ProgressDeadlineExceeded的记录.<br>判定Deployment滚动升级失败的超时时间， 可以通过设定Deployment spec中的progressDeadlineSeconds来指定.<br>如果达到了progressDeadlineSeconds指定的时间， 则滚动升级过程会自动取消.</p>\n<pre><code>$ kubectl describe deployment kubia\nConditions:\n  Type           Status  Reason\n  ----           ------  ------\n  Available      True    MinimumReplicasAvailable\n  Progressing    True    ReplicaSetUpdated\n......</code></pre><p>过了3，4分钟后再次执行</p>\n<pre><code>$ kubectl describe deployment kubia\nName:                   kubia\n......\nConditions:\n  Type           Status  Reason\n  ----           ------  ------\n  Available      True    MinimumReplicasAvailable\n  Progressing    False   ProgressDeadlineExceeded\nOldReplicaSets:  kubia-59d857b444 (3/3 replicas created)\nNewReplicaSet:   kubia-7d6c89d47b (1/1 replicas created)\n......</code></pre><p>因为滚动升级过程不再继续， 所以只能通过rollout undo命令来取消滚动升级, 其实就是回滚上一个版本.</p>\n<pre><code>$ kubectl rollout undo deployment kubia\ndeployment.apps/kubia rolled back</code></pre><h3 id=\"蓝绿部署\"><a href=\"#蓝绿部署\" class=\"headerlink\" title=\"蓝绿部署\"></a>蓝绿部署</h3><p>可以通过修改Service下的不同version值，选择应用不同版本的Pod来提供服务.<br>新版本运行起来一段时间没问题后才可以删除旧版本.<br>一般保持有两个版本的应用也就是Pod保持运行状态, 只有下个版本部署一段时间没问题后，第一个版本的可以删除.</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-rollingupdate\n  namespace: dev\nspec:\n  strategy:\n    rollingUpdate:            // 滚动更新, 不设置的话都会设成跟下面一样的默认值, $kubectl get deployment Name -o yaml查看\n      maxSurge: 25%            // 可以最大超出实力数的百分比，4个replicas，就是每次最多多启动1个实例\n      maxUnavailable: 25%    // 不可用实力百分比，4个replicas，就是每次必须有3个实例可用\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app: web-rollingupdate\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: web-bluegreen\n        version: v2.0        // 蓝绿部署，与下面的version一致，部署不同版本的应用\n    spec:\n......\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: web-bluegreen\n  namespace: dev\nspec:\n  ports:\n  - ports: 80\n    protocol: TCP\n    targetPort: 8080\n  selector:\n    app: web-bluegreen\n    version: v2.0            // 与上面的version一致，部署不同版本应用, 下次部署单独抽离Service，选择不同版本version就可以了\n  type: ClusterIP\n---\n......</code></pre><h3 id=\"金丝雀发布\"><a href=\"#金丝雀发布\" class=\"headerlink\" title=\"金丝雀发布\"></a>金丝雀发布</h3><blockquote>\n<p>在蓝绿部署的基础之上，去掉version, 修改selector就是金丝雀部署.<br>一个新的 pod 会被创建， 与此同时所有旧的 pod 还在运行。 一旦新的 pod 成功运行， 服务的一部分请求将被切换到新的 pod。 这样相当于 运行了一个金丝雀版本。金丝雀发布是一种可以将应用程序的出错版本和其影响到的用户的风险化为最小的技术.<br>与其直接向每个用户发布新版本， 不如用新版本替换 一个或一小部分的 pod。通过 这种方式， 在升级的初期只有少数用户会访问新版本。 验证新版本是否正常工作之后， 可以将剩余的 pod 继续升级或者回滚到上一个的版本</p>\n</blockquote>\n<h3 id=\"删除deployment\"><a href=\"#删除deployment\" class=\"headerlink\" title=\"删除deployment\"></a>删除deployment</h3><p>删除deployment会连带删除创建的replicaset和由replicaset创建的pod</p>\n<pre><code>$ kubectl delete deployment kubia\ndeployment.apps &quot;kubia&quot; deleted</code></pre>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"deployment\"><a href=\"#deployment\" class=\"headerlink\" title=\"deployment\"></a>deployment</h2><p>Deployment 是一种更高阶资源， 用千部署应用程序并以声明的方式升级应用, 而不是通过 ReplicationController 或 ReplicaSet 进行部署， 它们都被认为是更底层的概念.<br>当创建一个 Deployment 时， ReplicaSet 资源也会随之创建.<br>在使用 Deployment 时， 实际的 pod是由 Deployment 的 Replicaset 创建和管理的， 而不是由 Deployment 直接创建和管理的.</p>\n<blockquote>\n<p>创建Deployment与创建ReplicationController并没有任何区别。Deployment也是由标签选择器、期望副数和pod模板组成的。此外，它还包含另 一 个字段，指定一 个部署策略，该策略定义在修改Deployment资源时应该如何执行更新<br>Deployment可以同时管理多个版本的 pod, 所以在命名时不需要指定应用的版本号<br>kubia-svc-loadbalancer.yaml</p>\n</blockquote>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: kubia-loadbalancer\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 80\n    targetPort: 8080\n  selector:\n    app: kubia</code></pre><p>kubia-deployment-v1.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kubia\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: kubia\n  template:\n    metadata:\n      name: kubia\n      labels:\n        app: kubia\n    spec:\n      containers:\n      - image: luksa/kubia:v1\n        name: nodejs</code></pre><p>创建deployment</p>\n<pre><code>$ kubectl create -f kubia-deployment-v1.yaml --record</code></pre><p>查看deployment过程</p>\n<pre><code>$ kubectl rollout status deployment kubia\nWaiting for deployment &quot;kubia&quot; rollout to finish: 1 out of 3 new replicas have been updated...\nWaiting for deployment &quot;kubia&quot; rollout to finish: 1 out of 3 new replicas have been updated...\nWaiting for deployment &quot;kubia&quot; rollout to finish: 2 out of 3 new replicas have been updated...\nWaiting for deployment &quot;kubia&quot; rollout to finish: 2 out of 3 new replicas have been updated...\nWaiting for deployment &quot;kubia&quot; rollout to finish: 2 out of 3 new replicas have been updated...\nWaiting for deployment &quot;kubia&quot; rollout to finish: 2 out of 3 new replicas have been updated...\nWaiting for deployment &quot;kubia&quot; rollout to finish: 1 old replicas are pending termination...\nWaiting for deployment &quot;kubia&quot; rollout to finish: 1 old replicas are pending termination...\nWaiting for deployment &quot;kubia&quot; rollout to finish: 1 old replicas are pending termination...\ndeployment &quot;kubia&quot; successfully rolled out</code></pre><p>当使用 ReplicationController 创建 pod 时， 它们的名称是由 Controller 的名称加上一个运行时生成的随机字符串.<br>由 Deployment 创建的三个 pod 名称中均包含一个额外的数字, 这个数字实际上对应 Deployment 和 ReplicaSet 中的 pod 模板的哈希值</p>\n<pre><code>$ kubectl get po\nkubia-59d857b444-2nrr7   1/1     Running   0          5m15s\nkubia-59d857b444-f9pnx   1/1     Running   0          5m15s\nkubia-59d857b444-wzgnj   1/1     Running   0          5m15s\n\n$ kubectl get replicasets\nNAME               DESIRED   CURRENT   READY   AGE\nkubia-59d857b444   3         3         3       8m48s\n\n$ kubectl get svc\nNAME                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\nkubernetes           ClusterIP      10.96.0.1       &lt;none&gt;        443/TCP        4d22h\nkubia-loadbalancer   LoadBalancer   10.100.58.157   &lt;pending&gt;     80:31170/TCP   3s</code></pre><p>查看master node 的IP为10.239.140.186</p>\n<pre><code>$ curl 10.239.140.186:31170\nThis is v1 running in pod kubia-59d857b444-wzgnj</code></pre><p>查看deployment详细信息</p>\n<pre><code>$ kubectl describe deployment kubia\nName:                   kubia\nNamespace:              default\nCreationTimestamp:      Mon, 18 May 2020 15:04:12 +0800\nLabels:                 &lt;none&gt;\nAnnotations:            deployment.kubernetes.io/revision: 1\n                        kubernetes.io/change-cause: kubectl create --filename=kubia-deployment-v1.yaml --record=true\nSelector:               app=kubia\nReplicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable\nStrategyType:           RollingUpdate\nMinReadySeconds:        0\nRollingUpdateStrategy:  25% max unavailable, 25% max surge\nPod Template:\n  Labels:  app=kubia\n  Containers:\n   nodejs:\n    Image:        luksa/kubia:v1\n    Port:         &lt;none&gt;\n    Host Port:    &lt;none&gt;\n    Environment:  &lt;none&gt;\n    Mounts:       &lt;none&gt;\n  Volumes:        &lt;none&gt;\nConditions:\n  Type           Status  Reason\n  ----           ------  ------\n  Available      True    MinimumReplicasAvailable\n  Progressing    True    NewReplicaSetAvailable\nOldReplicaSets:  &lt;none&gt;\nNewReplicaSet:   kubia-59d857b444 (3/3 replicas created)\nEvents:\n  Type    Reason             Age    From                   Message\n  ----    ------             ----   ----                   -------\n  Normal  ScalingReplicaSet  7m12s  deployment-controller  Scaled up replica set kubia-59d857b444 to 3</code></pre><p>略微减慢滚动升级的速度， 以便观察升级过程确实是以滚动的方式执行的。 可以通过在Deployment上设置minReadySeconds属性来实现<br>minReadySeconds的主要功能是避免部署出错版本的应用， 而不只是单纯地减慢部署的速度.<br>minReadySeconds属性指定新创建的pod至少要成功运行多久之后，才能将其视为可用.<br>通常情况下需要 将minReadySeconds设置为更高的值， 以确保pod在它们真正开始接收实际流量之后可以持续保持就绪状态.</p>\n<p>如kubectl patch命令将其设置为10秒</p>\n<pre><code>$ kubectl patch deployment kubia -p &apos;{&quot;spec&quot;: {&quot;minreadyseconds&quot;: 10}}&apos;</code></pre><h2 id=\"重新部署几种方式\"><a href=\"#重新部署几种方式\" class=\"headerlink\" title=\"重新部署几种方式\"></a>重新部署几种方式</h2><p>重建(recreate)，滚动(rollingUpdate)，蓝绿，金丝雀</p>\n<h3 id=\"recreate\"><a href=\"#recreate\" class=\"headerlink\" title=\"recreate\"></a>recreate</h3><p>停止Pod并重新创建Pod</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-recreate\n  namespace: dev\nspec:\n  strategy:\n    type: Recreate        // 停止Pod并重新创建Pod\n  selector:\n    matchLabels:\n      app: web-recreate\n  replicas: 2\n  template:\n......\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: web-recreate\n  namespace: dev\nspec:\n  rules:\n  - host: web-recreate.mooc.com  //配置下/etc/hosts 文件 &quot;IP web-recreate.mooc.com&quot;\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: web-recreate\n          servicePort: 80</code></pre><h3 id=\"滚动更新deployment\"><a href=\"#滚动更新deployment\" class=\"headerlink\" title=\"滚动更新deployment\"></a>滚动更新deployment</h3><p>滚动更新过程svc的IP等不会变，只是改变pod版本，修改pod的镜像就可以了</p>\n<blockquote>\n<p>实际上， 如何达到新的系统状态的过程是由 Deployment 的升级策略决定的，默认策略是执行滚动更新（策略名为 RollingUpdate)。 另 一种策略为 Recreate, 它会一次性删除所有旧版本的 pod, 然后创建新的 pod, 整个行为类似千修改ReplicationController 的 pod 模板， 然后删除所有的 pod<br>使用kubectl set image命令来更改任何包含容器资源的镜像(ReplicationController、ReplicaSet、 Deployment等）</p>\n</blockquote>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-rollingupdate\n  namespace: dev\nspec:\n  strategy:\n    rollingUpdate:            // 滚动更新, 不设置的话都会设成跟下面一样的默认值, $kubectl get deployment Name -o yaml查看\n      maxSurge: 25%            // 可以最大超出实力数的百分比，4个replicas，就是每次最多多启动1个实例\n      maxUnavailable: 25%    // 不可用实力百分比，4个replicas，就是每次必须有3个实例可用\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app: web-rollingupdate\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: web-bluegreen\n        version: v1.0\n    spec:\n......\n\n$ kubectl set image deployment kubia nodejs=luksa/kubia:v2\ndeployment.apps/kubia image updated</code></pre><p>创建rs，然后新的rs会创建一个pod，然后原来的rs删除一个pod，新的rs再创建一个pod，依次完成设定的3个pod都完成更新.<br>通过命令定时查看输出:</p>\n<pre><code>$ while sleep 0.2; do curl &quot;http://web-rollingupdate.mooc.com/hello?name=michael&quot;; echo &quot;&quot;; done</code></pre><p>查看Pod:</p>\n<pre><code>$ kubectl get po\nNAME                     READY   STATUS              RESTARTS   AGE\nfortune                  2/2     Running             0          3d\nkubia-59d857b444-6nq74   1/1     Running             0          72s\nkubia-59d857b444-jbln7   1/1     Terminating         0          72s\nkubia-59d857b444-lr2zw   1/1     Running             0          72s\nkubia-7d5c456ffc-69gg5   0/1     ContainerCreating   0          2s\nkubia-7d5c456ffc-vmz74   1/1     Running             0          14s</code></pre><p>滚动更新后旧的 ReplicaSet 仍然会被保留</p>\n<pre><code>$ kubectl get rs\nNAME               DESIRED   CURRENT   READY   AGE\nkubia-59d857b444   3         3         3       9m27s\nkubia-7d5c456ffc   1         1         0       3s</code></pre><p>再等待一会再查看rs</p>\n<pre><code>$ kubectl get rs\nNAME               DESIRED   CURRENT   READY   AGE\nkubia-59d857b444   0         0         0       10m\nkubia-7d5c456ffc   3         3         3       72s</code></pre><p>Deployment可以非常容易地回滚到先前部署的版本，它可以让Kubernetes 取消最后一次部署的 Deployment</p>\n<pre><code>$ kubectl set image deployment kubia nodejs=luksa/kubia:v2\n$ kubectl get rs\nNAME               DESIRED   CURRENT   READY   AGE\nkubia-59d857b444   0         0         0       3h3m\nkubia-79b84b44f4   3         3         3       96s\nkubia-7d5c456ffc   0         0         0       174m</code></pre><p>undo 命令也可以在滚动升级过程中运行，并直接停止滚动升级。 在升级过程中已创建的 pod 会被删除并被老版本的 pod 替代</p>\n<pre><code>$ kubectl rollout undo deployment kubia\ndeployment.apps/kubia rolled back\n$ kubectl get rs\nNAME               DESIRED   CURRENT   READY   AGE\nkubia-59d857b444   0         0         0       3h7m\nkubia-79b84b44f4   0         0         0       5m19s\nkubia-7d5c456ffc   3         3         3       177m</code></pre><p>kubectl rollout history 来显示升级的版本</p>\n<pre><code>$ kubectl rollout history deployment kubia\ndeployment.apps/kubia\nREVISION  CHANGE-CAUSE\n1         kubectl create --filename=kubia-deployment-v1.yaml --record=true\n2         kubectl create --filename=kubia-deployment-v1.yaml --record=true\n3         kubectl create --filename=kubia-deployment-v1.yaml --record=true</code></pre><h3 id=\"回滚到一个特定的-Deployment-版本\"><a href=\"#回滚到一个特定的-Deployment-版本\" class=\"headerlink\" title=\"回滚到一个特定的 Deployment 版本\"></a>回滚到一个特定的 Deployment 版本</h3><pre><code>$ kubectl rollout undo deployment kubia --to-revision=l\ndeployment.apps/kubia rolled back</code></pre><blockquote>\n<p>旧版本的 ReplicaSet 过多会导致 ReplicaSet 列表过于混乱，可以通过指定Deployment 的 re visionHistoryLimit 属性来限制历史版本数量。默认值是 2</p>\n</blockquote>\n<pre><code>$ kubectl rollout history deployment kubia\ndeployment.apps/kubia\nREVISION  CHANGE-CAUSE\n2         kubectl create --filename=kubia-deployment-v1.yaml --record=true\n3         kubectl create --filename=kubia-deployment-v1.yaml --record=true\n4         kubectl create --filename=kubia-deployment-v1.yaml --record=true</code></pre><h3 id=\"滚动升级速率\"><a href=\"#滚动升级速率\" class=\"headerlink\" title=\"滚动升级速率\"></a>滚动升级速率</h3><p>在 Deployment 的滚动升级期间，有两个属性会决定一次替换多少个pod: maxSurge 和 maxUnavailable。可以通过 Deployment 的 strategy 字 段下rollingUpdate 的子属性来配置.</p>\n<pre><code>spec:\n  strategy:\n    rollingUpdate:\n      maxSurge· 1\n      maxUnavailable: 0\n    type: RollingUpdate</code></pre><blockquote>\n<ul>\n<li>maxSurge: 决定了 Deployment 配置中期望的副本数之外，最多允许超出的 pod 实例的数量。默认值为 25%，所以 pod 实例最多可以比期望数量多25%. 这个值也可以不是百分数而是绝对值(例如，可以允许最多多出一个成两个pod).</li>\n<li>maxUnavailable: 决定了在滚动升级期间 ，相对于期望副本数能够允许有多少 pod 实例处于不可用状态。默认值也是25%, 所以可用 pod 实例的数量不能低于期望副本数的75%. 与 maxSurge 一样，也可以指定绝对值而不是百分比.</li>\n</ul>\n</blockquote>\n<h3 id=\"暂停滚动升级\"><a href=\"#暂停滚动升级\" class=\"headerlink\" title=\"暂停滚动升级\"></a>暂停滚动升级</h3><pre><code>$ kubectl set image deployment kubia nodejs=luksa/kubia:v4\ndeployment &quot;kubia&quot; image updated\n$ kubectl rollout pause deployment kubia\ndeployment &quot;kubia&quot; paused</code></pre><h3 id=\"恢复滚动升级\"><a href=\"#恢复滚动升级\" class=\"headerlink\" title=\"恢复滚动升级\"></a>恢复滚动升级</h3><p>如果部署被暂停， 那么在恢复部署之前， 撤销命令不会撤销它</p>\n<pre><code>$ kubectl rollout resume deployment kubia\ndeployment &quot;kubia&quot; resumed</code></pre><h3 id=\"readinessProbe\"><a href=\"#readinessProbe\" class=\"headerlink\" title=\"readinessProbe\"></a>readinessProbe</h3><p>kubia-deployment-v3-with-readinesscheck.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kubia\nspec:\n  replicas: 3                    // POD副本个数为3\n  minReadySeconds: 10            // 设置minReadySeconds 值为10s,指定新创建的pod至少要成功运行多久之后，才能将其视为可用.\n  progressDeadlineSeconds: 120    // 设置升级失败超时时间，超过则自动停止升级，如下describe deployment 可查看到&quot;Progressing False...&quot;信息，需要手动undo来取消升级\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0            // 设置maxUnavailable的 中值为0来确保升级过程 pod被挨个替换\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app: kubia\n  template:\n    metadata:\n      name: kubia\n      labels:\n        app: kubia\n    spec:\n      containers:\n      - image: luksa/kubia:v3    // 修改image\n        name: nodejs\n        readinessProbe:\n          periodSeconds: 1        // 定义一个就绪探针，并且每隔—秒钟执行一次\n          httpGet:                // 就绪探针会执行发送HTTP GET请求到容器\n            path: /\n            port: 8080</code></pre><p>直接使用kubectl apply来升级Deployment<br>apply命令可以用YAML 文件中声明的字段来更新Deployment。不仅更新镜像，而且还添加了就绪探针， 以及在 YAML 中添加或修改的其他声明。<br>如果新的 YAML也包含rep巨 cas字段， 当它与现有Deployment中的数量不一致时， 那么apply 操作也会对Deployment进行扩容.</p>\n<pre><code>$ kubectl apply -f kubia-deployment-v3-with-readinesscheck.yaml\ndeployment &quot;kubia&quot; configured</code></pre><h3 id=\"取消滚动升级\"><a href=\"#取消滚动升级\" class=\"headerlink\" title=\"取消滚动升级\"></a>取消滚动升级</h3><p>默认情况下， 在10分钟内不能完成滚动升级的话， 将被视为失败。 如果运行kubectl describe deployment命令， 将会显示一条ProgressDeadlineExceeded的记录.<br>判定Deployment滚动升级失败的超时时间， 可以通过设定Deployment spec中的progressDeadlineSeconds来指定.<br>如果达到了progressDeadlineSeconds指定的时间， 则滚动升级过程会自动取消.</p>\n<pre><code>$ kubectl describe deployment kubia\nConditions:\n  Type           Status  Reason\n  ----           ------  ------\n  Available      True    MinimumReplicasAvailable\n  Progressing    True    ReplicaSetUpdated\n......</code></pre><p>过了3，4分钟后再次执行</p>\n<pre><code>$ kubectl describe deployment kubia\nName:                   kubia\n......\nConditions:\n  Type           Status  Reason\n  ----           ------  ------\n  Available      True    MinimumReplicasAvailable\n  Progressing    False   ProgressDeadlineExceeded\nOldReplicaSets:  kubia-59d857b444 (3/3 replicas created)\nNewReplicaSet:   kubia-7d6c89d47b (1/1 replicas created)\n......</code></pre><p>因为滚动升级过程不再继续， 所以只能通过rollout undo命令来取消滚动升级, 其实就是回滚上一个版本.</p>\n<pre><code>$ kubectl rollout undo deployment kubia\ndeployment.apps/kubia rolled back</code></pre><h3 id=\"蓝绿部署\"><a href=\"#蓝绿部署\" class=\"headerlink\" title=\"蓝绿部署\"></a>蓝绿部署</h3><p>可以通过修改Service下的不同version值，选择应用不同版本的Pod来提供服务.<br>新版本运行起来一段时间没问题后才可以删除旧版本.<br>一般保持有两个版本的应用也就是Pod保持运行状态, 只有下个版本部署一段时间没问题后，第一个版本的可以删除.</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-rollingupdate\n  namespace: dev\nspec:\n  strategy:\n    rollingUpdate:            // 滚动更新, 不设置的话都会设成跟下面一样的默认值, $kubectl get deployment Name -o yaml查看\n      maxSurge: 25%            // 可以最大超出实力数的百分比，4个replicas，就是每次最多多启动1个实例\n      maxUnavailable: 25%    // 不可用实力百分比，4个replicas，就是每次必须有3个实例可用\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app: web-rollingupdate\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: web-bluegreen\n        version: v2.0        // 蓝绿部署，与下面的version一致，部署不同版本的应用\n    spec:\n......\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: web-bluegreen\n  namespace: dev\nspec:\n  ports:\n  - ports: 80\n    protocol: TCP\n    targetPort: 8080\n  selector:\n    app: web-bluegreen\n    version: v2.0            // 与上面的version一致，部署不同版本应用, 下次部署单独抽离Service，选择不同版本version就可以了\n  type: ClusterIP\n---\n......</code></pre><h3 id=\"金丝雀发布\"><a href=\"#金丝雀发布\" class=\"headerlink\" title=\"金丝雀发布\"></a>金丝雀发布</h3><blockquote>\n<p>在蓝绿部署的基础之上，去掉version, 修改selector就是金丝雀部署.<br>一个新的 pod 会被创建， 与此同时所有旧的 pod 还在运行。 一旦新的 pod 成功运行， 服务的一部分请求将被切换到新的 pod。 这样相当于 运行了一个金丝雀版本。金丝雀发布是一种可以将应用程序的出错版本和其影响到的用户的风险化为最小的技术.<br>与其直接向每个用户发布新版本， 不如用新版本替换 一个或一小部分的 pod。通过 这种方式， 在升级的初期只有少数用户会访问新版本。 验证新版本是否正常工作之后， 可以将剩余的 pod 继续升级或者回滚到上一个的版本</p>\n</blockquote>\n<h3 id=\"删除deployment\"><a href=\"#删除deployment\" class=\"headerlink\" title=\"删除deployment\"></a>删除deployment</h3><p>删除deployment会连带删除创建的replicaset和由replicaset创建的pod</p>\n<pre><code>$ kubectl delete deployment kubia\ndeployment.apps &quot;kubia&quot; deleted</code></pre>"},{"title":"07 Kubernetes Etcd","top":7,"_content":"\n## Etcd\nhttps://github.com/coreos/etcd\n> Etcd 是 CoreOS 团队（同时发起了 CoreoS 、 Rocket 等热门项目）发起的一个开源分布式键值仓库项目，可以用于分布式系统中的配置信息管理和服务发现（ service discovery），目前已经被广泛应用到大量开源项目中，包括 Kubernetes 、 CloudFoundry 、 CoreOS Fleet 和Salesforce 等\n> Etcd 是 CoreOS 团队于 2013 年 6 月发起的开源项目，它的目标是构建一个高可用的分布式键值（ key-value ）仓库，遵循 Apache v2许可，基于 Go 语言实现\n> 分布式系统中最基本的问题之一就是实现信息的共识，在此基础上才能实现对服务配置信息的管理、服务的发现、更新、同步,Etcd 专门为集群环境设计，采用了更为简洁的 Raft 共识算法＠，同样可以实现数据强一.致性，并支持集群节点状态管理和服务自动发现等.\n * 简单：支持 RESTfulAPI 和 gRPCAPI;\n * 安全： 基于 TLS 方式实现安全连接访问 ；\n * 快速： 支持每秒一万次的并发写操作，超时控制在毫秒量级 ；\n * 可靠： 支持分布式结构 ， 基于 Raft 算法实现一致性 \n![](etcd_3.PNG)\n默认etcd在k8s集群中的 3 or 5 or 7 台node上部署.\n\n## 下载安装\n\n###  二进制文件方式下载\n\n\t$ curl -L https://github.com/coreos/etcd/releases/download/v3.3.1/etcd-v3.3.1-linux-amd64.tar.gz\n\t$ tar xzvf etcd-v3.3.llinux-amd64.tar.gz\n\t$ cd etcd-v3.3.llinux-amd64.tar.gz | ls\n\t其中 etcd 是服务主文件， etcdctl 是提供给用户的命令客户端, 其他都是文档文件.\n\t$ sudo cp etcd* /usr/local/bin/\nEtcd 安装到此完成\n\n\t$ etcd --version\n直接执行 Etcd 命令，将启动一个服务节点，监昕在本地的 2379 （客户端请求端口）和 2380 （其他节点连接端口 ） \n\n\t$ etcd\n可以通过 REST API 直接查看集群健康状态：\n\n\t$ curl -L http://127.0.0.1:2379/health\n\t{”health”: ”true”}\n也可以使用自带的 etcdctl 命令进行查看（实际上是封装了阻STAPI 调用）：\n\n\t$ etcdctl cluster-health\n通过 etcdctl 设置和获取键值, 设置键值对 testkey：\"hello world\"\n\n\t$ etcdctl put testkey \"hello world111\"\n也可以直接通过 HTTP 访问本地 2379 端口的方式来进行操作，例如查看 test key 的值：\n\n\t$ curl -L -X PUT http://localhost:2379/v2/keys/testkey -d value=\"hello world\"\n\n### Docker 镜像方式下载\n镜像名称为 quay.io/coreos/etcd:v3.3.1，可以通过下面的命令启动 etcd 服务监听到本地的 2379 和 2380 端口\n\n\t$ docker run -p 2379:2379 -p 2380:2380 -v /etc/ssl/certs/:/etc/ssl/certs/ quay.io/coreos/etcd:v3.3.1\n\n\n## Etcd 集群管理\n启动各个节点上的 etcd 服务, 指向主节点etcd存储\n\n### 时钟同步\n对于分布式集群来说，各个节点上的同步时钟十分重要， Etcd 集群需要各个节点时钟差异不超过 ls ，否则可能会导致 Raft 协议的异常.\n\n### 节点恢复\n> Etcd 集群中的节点会通过数据目录来存放修改信息和集群配置 。\n> 一般来说，当某个节点出现故障时候，本地数据已经过期甚至格式破坏. 如果只是简单地重启进程，容易造成数据的不一致。 这个时候，保险的做法是先通过命令（例如 etcdctlmember rm [member ］）来删除该节点，然后清空数据目录，再重新作为空节点加入.\n> Etcd 提供了－ strict-reconf ig-check 选项，确保当集群状态不稳定时候（例如启动节点数还不够达到 quorum ）拒绝对配置状态的修改\n\n### 重启集群\n> 极端情况下，集群中大部分节点都出现问题，需要重启整个集群.\n> 这个时候，最保险的办法是找到一个数据记录完整且比较新的节点，先以它为唯一节点创建新的集群，然后将其他节点一个一个地添加进来，添加过程中注意保证集群的稳定性.\n\n\n### K8s证书访问etcd server\n\nEnter etcd pod:\n\n\t$ kubectl exec etcd-hci-node01 -n kube-system -i -t – sh\nGet all key:\n\n\t$ ETCDCTL_API=3 etcdctl --endpoints 127.0.0.1:2379 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt --key /etc/kubernetes/pki/etcd/server.key get / --prefix --keys-only\nCheck the value of the key:\n\n\t$ ETCDCTL_API=3 etcdctl --endpoints 127.0.0.1:2379 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt --key /etc/kubernetes/pki/etcd/server.key get /registry/statefulsets/kafka/kafka -w=json\n向etcd数据库添加key,value\n\n\t$ ETCDCTL_API=3 etcdctl --endpoints 127.0.0.1:2379 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt --key /etc/kubernetes/pki/etcd/server.key put testkey \"hello world111\"\n获取添加的key, value值\n\n\t$ ETCDCTL_API=3 etcdctl --endpoints 127.0.0.1:2379 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt --key /etc/kubernetes/pki/etcd/server.key get testkey\n\n\n\n\n\n\n\n\n\n","source":"_posts/micro_service/07_kubernetes_Etcd.md","raw":"---\ntitle: 07 Kubernetes Etcd\ntags: kubernetes\ncategories:\n- microService\n- kubernetes\ntop: 7\n---\n\n## Etcd\nhttps://github.com/coreos/etcd\n> Etcd 是 CoreOS 团队（同时发起了 CoreoS 、 Rocket 等热门项目）发起的一个开源分布式键值仓库项目，可以用于分布式系统中的配置信息管理和服务发现（ service discovery），目前已经被广泛应用到大量开源项目中，包括 Kubernetes 、 CloudFoundry 、 CoreOS Fleet 和Salesforce 等\n> Etcd 是 CoreOS 团队于 2013 年 6 月发起的开源项目，它的目标是构建一个高可用的分布式键值（ key-value ）仓库，遵循 Apache v2许可，基于 Go 语言实现\n> 分布式系统中最基本的问题之一就是实现信息的共识，在此基础上才能实现对服务配置信息的管理、服务的发现、更新、同步,Etcd 专门为集群环境设计，采用了更为简洁的 Raft 共识算法＠，同样可以实现数据强一.致性，并支持集群节点状态管理和服务自动发现等.\n * 简单：支持 RESTfulAPI 和 gRPCAPI;\n * 安全： 基于 TLS 方式实现安全连接访问 ；\n * 快速： 支持每秒一万次的并发写操作，超时控制在毫秒量级 ；\n * 可靠： 支持分布式结构 ， 基于 Raft 算法实现一致性 \n![](etcd_3.PNG)\n默认etcd在k8s集群中的 3 or 5 or 7 台node上部署.\n\n## 下载安装\n\n###  二进制文件方式下载\n\n\t$ curl -L https://github.com/coreos/etcd/releases/download/v3.3.1/etcd-v3.3.1-linux-amd64.tar.gz\n\t$ tar xzvf etcd-v3.3.llinux-amd64.tar.gz\n\t$ cd etcd-v3.3.llinux-amd64.tar.gz | ls\n\t其中 etcd 是服务主文件， etcdctl 是提供给用户的命令客户端, 其他都是文档文件.\n\t$ sudo cp etcd* /usr/local/bin/\nEtcd 安装到此完成\n\n\t$ etcd --version\n直接执行 Etcd 命令，将启动一个服务节点，监昕在本地的 2379 （客户端请求端口）和 2380 （其他节点连接端口 ） \n\n\t$ etcd\n可以通过 REST API 直接查看集群健康状态：\n\n\t$ curl -L http://127.0.0.1:2379/health\n\t{”health”: ”true”}\n也可以使用自带的 etcdctl 命令进行查看（实际上是封装了阻STAPI 调用）：\n\n\t$ etcdctl cluster-health\n通过 etcdctl 设置和获取键值, 设置键值对 testkey：\"hello world\"\n\n\t$ etcdctl put testkey \"hello world111\"\n也可以直接通过 HTTP 访问本地 2379 端口的方式来进行操作，例如查看 test key 的值：\n\n\t$ curl -L -X PUT http://localhost:2379/v2/keys/testkey -d value=\"hello world\"\n\n### Docker 镜像方式下载\n镜像名称为 quay.io/coreos/etcd:v3.3.1，可以通过下面的命令启动 etcd 服务监听到本地的 2379 和 2380 端口\n\n\t$ docker run -p 2379:2379 -p 2380:2380 -v /etc/ssl/certs/:/etc/ssl/certs/ quay.io/coreos/etcd:v3.3.1\n\n\n## Etcd 集群管理\n启动各个节点上的 etcd 服务, 指向主节点etcd存储\n\n### 时钟同步\n对于分布式集群来说，各个节点上的同步时钟十分重要， Etcd 集群需要各个节点时钟差异不超过 ls ，否则可能会导致 Raft 协议的异常.\n\n### 节点恢复\n> Etcd 集群中的节点会通过数据目录来存放修改信息和集群配置 。\n> 一般来说，当某个节点出现故障时候，本地数据已经过期甚至格式破坏. 如果只是简单地重启进程，容易造成数据的不一致。 这个时候，保险的做法是先通过命令（例如 etcdctlmember rm [member ］）来删除该节点，然后清空数据目录，再重新作为空节点加入.\n> Etcd 提供了－ strict-reconf ig-check 选项，确保当集群状态不稳定时候（例如启动节点数还不够达到 quorum ）拒绝对配置状态的修改\n\n### 重启集群\n> 极端情况下，集群中大部分节点都出现问题，需要重启整个集群.\n> 这个时候，最保险的办法是找到一个数据记录完整且比较新的节点，先以它为唯一节点创建新的集群，然后将其他节点一个一个地添加进来，添加过程中注意保证集群的稳定性.\n\n\n### K8s证书访问etcd server\n\nEnter etcd pod:\n\n\t$ kubectl exec etcd-hci-node01 -n kube-system -i -t – sh\nGet all key:\n\n\t$ ETCDCTL_API=3 etcdctl --endpoints 127.0.0.1:2379 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt --key /etc/kubernetes/pki/etcd/server.key get / --prefix --keys-only\nCheck the value of the key:\n\n\t$ ETCDCTL_API=3 etcdctl --endpoints 127.0.0.1:2379 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt --key /etc/kubernetes/pki/etcd/server.key get /registry/statefulsets/kafka/kafka -w=json\n向etcd数据库添加key,value\n\n\t$ ETCDCTL_API=3 etcdctl --endpoints 127.0.0.1:2379 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt --key /etc/kubernetes/pki/etcd/server.key put testkey \"hello world111\"\n获取添加的key, value值\n\n\t$ ETCDCTL_API=3 etcdctl --endpoints 127.0.0.1:2379 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt --key /etc/kubernetes/pki/etcd/server.key get testkey\n\n\n\n\n\n\n\n\n\n","slug":"micro_service/07_kubernetes_Etcd","published":1,"date":"2020-08-12T16:05:47.451Z","updated":"2020-08-10T16:36:38.266Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmg8004jhohx3ejy4up6","content":"<h2 id=\"Etcd\"><a href=\"#Etcd\" class=\"headerlink\" title=\"Etcd\"></a>Etcd</h2><p><a href=\"https://github.com/coreos/etcd\" target=\"_blank\" rel=\"noopener\">https://github.com/coreos/etcd</a></p>\n<blockquote>\n<p>Etcd 是 CoreOS 团队（同时发起了 CoreoS 、 Rocket 等热门项目）发起的一个开源分布式键值仓库项目，可以用于分布式系统中的配置信息管理和服务发现（ service discovery），目前已经被广泛应用到大量开源项目中，包括 Kubernetes 、 CloudFoundry 、 CoreOS Fleet 和Salesforce 等<br>Etcd 是 CoreOS 团队于 2013 年 6 月发起的开源项目，它的目标是构建一个高可用的分布式键值（ key-value ）仓库，遵循 Apache v2许可，基于 Go 语言实现<br>分布式系统中最基本的问题之一就是实现信息的共识，在此基础上才能实现对服务配置信息的管理、服务的发现、更新、同步,Etcd 专门为集群环境设计，采用了更为简洁的 Raft 共识算法＠，同样可以实现数据强一.致性，并支持集群节点状态管理和服务自动发现等.</p>\n</blockquote>\n<ul>\n<li>简单：支持 RESTfulAPI 和 gRPCAPI;</li>\n<li>安全： 基于 TLS 方式实现安全连接访问 ；</li>\n<li>快速： 支持每秒一万次的并发写操作，超时控制在毫秒量级 ；</li>\n<li>可靠： 支持分布式结构 ， 基于 Raft 算法实现一致性<br><img src=\"etcd_3.PNG\" alt=\"\"><br>默认etcd在k8s集群中的 3 or 5 or 7 台node上部署.</li>\n</ul>\n<h2 id=\"下载安装\"><a href=\"#下载安装\" class=\"headerlink\" title=\"下载安装\"></a>下载安装</h2><h3 id=\"二进制文件方式下载\"><a href=\"#二进制文件方式下载\" class=\"headerlink\" title=\"二进制文件方式下载\"></a>二进制文件方式下载</h3><pre><code>$ curl -L https://github.com/coreos/etcd/releases/download/v3.3.1/etcd-v3.3.1-linux-amd64.tar.gz\n$ tar xzvf etcd-v3.3.llinux-amd64.tar.gz\n$ cd etcd-v3.3.llinux-amd64.tar.gz | ls\n其中 etcd 是服务主文件， etcdctl 是提供给用户的命令客户端, 其他都是文档文件.\n$ sudo cp etcd* /usr/local/bin/</code></pre><p>Etcd 安装到此完成</p>\n<pre><code>$ etcd --version</code></pre><p>直接执行 Etcd 命令，将启动一个服务节点，监昕在本地的 2379 （客户端请求端口）和 2380 （其他节点连接端口 ） </p>\n<pre><code>$ etcd</code></pre><p>可以通过 REST API 直接查看集群健康状态：</p>\n<pre><code>$ curl -L http://127.0.0.1:2379/health\n{”health”: ”true”}</code></pre><p>也可以使用自带的 etcdctl 命令进行查看（实际上是封装了阻STAPI 调用）：</p>\n<pre><code>$ etcdctl cluster-health</code></pre><p>通过 etcdctl 设置和获取键值, 设置键值对 testkey：”hello world”</p>\n<pre><code>$ etcdctl put testkey &quot;hello world111&quot;</code></pre><p>也可以直接通过 HTTP 访问本地 2379 端口的方式来进行操作，例如查看 test key 的值：</p>\n<pre><code>$ curl -L -X PUT http://localhost:2379/v2/keys/testkey -d value=&quot;hello world&quot;</code></pre><h3 id=\"Docker-镜像方式下载\"><a href=\"#Docker-镜像方式下载\" class=\"headerlink\" title=\"Docker 镜像方式下载\"></a>Docker 镜像方式下载</h3><p>镜像名称为 quay.io/coreos/etcd:v3.3.1，可以通过下面的命令启动 etcd 服务监听到本地的 2379 和 2380 端口</p>\n<pre><code>$ docker run -p 2379:2379 -p 2380:2380 -v /etc/ssl/certs/:/etc/ssl/certs/ quay.io/coreos/etcd:v3.3.1</code></pre><h2 id=\"Etcd-集群管理\"><a href=\"#Etcd-集群管理\" class=\"headerlink\" title=\"Etcd 集群管理\"></a>Etcd 集群管理</h2><p>启动各个节点上的 etcd 服务, 指向主节点etcd存储</p>\n<h3 id=\"时钟同步\"><a href=\"#时钟同步\" class=\"headerlink\" title=\"时钟同步\"></a>时钟同步</h3><p>对于分布式集群来说，各个节点上的同步时钟十分重要， Etcd 集群需要各个节点时钟差异不超过 ls ，否则可能会导致 Raft 协议的异常.</p>\n<h3 id=\"节点恢复\"><a href=\"#节点恢复\" class=\"headerlink\" title=\"节点恢复\"></a>节点恢复</h3><blockquote>\n<p>Etcd 集群中的节点会通过数据目录来存放修改信息和集群配置 。<br>一般来说，当某个节点出现故障时候，本地数据已经过期甚至格式破坏. 如果只是简单地重启进程，容易造成数据的不一致。 这个时候，保险的做法是先通过命令（例如 etcdctlmember rm [member ］）来删除该节点，然后清空数据目录，再重新作为空节点加入.<br>Etcd 提供了－ strict-reconf ig-check 选项，确保当集群状态不稳定时候（例如启动节点数还不够达到 quorum ）拒绝对配置状态的修改</p>\n</blockquote>\n<h3 id=\"重启集群\"><a href=\"#重启集群\" class=\"headerlink\" title=\"重启集群\"></a>重启集群</h3><blockquote>\n<p>极端情况下，集群中大部分节点都出现问题，需要重启整个集群.<br>这个时候，最保险的办法是找到一个数据记录完整且比较新的节点，先以它为唯一节点创建新的集群，然后将其他节点一个一个地添加进来，添加过程中注意保证集群的稳定性.</p>\n</blockquote>\n<h3 id=\"K8s证书访问etcd-server\"><a href=\"#K8s证书访问etcd-server\" class=\"headerlink\" title=\"K8s证书访问etcd server\"></a>K8s证书访问etcd server</h3><p>Enter etcd pod:</p>\n<pre><code>$ kubectl exec etcd-hci-node01 -n kube-system -i -t – sh</code></pre><p>Get all key:</p>\n<pre><code>$ ETCDCTL_API=3 etcdctl --endpoints 127.0.0.1:2379 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt --key /etc/kubernetes/pki/etcd/server.key get / --prefix --keys-only</code></pre><p>Check the value of the key:</p>\n<pre><code>$ ETCDCTL_API=3 etcdctl --endpoints 127.0.0.1:2379 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt --key /etc/kubernetes/pki/etcd/server.key get /registry/statefulsets/kafka/kafka -w=json</code></pre><p>向etcd数据库添加key,value</p>\n<pre><code>$ ETCDCTL_API=3 etcdctl --endpoints 127.0.0.1:2379 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt --key /etc/kubernetes/pki/etcd/server.key put testkey &quot;hello world111&quot;</code></pre><p>获取添加的key, value值</p>\n<pre><code>$ ETCDCTL_API=3 etcdctl --endpoints 127.0.0.1:2379 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt --key /etc/kubernetes/pki/etcd/server.key get testkey</code></pre>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Etcd\"><a href=\"#Etcd\" class=\"headerlink\" title=\"Etcd\"></a>Etcd</h2><p><a href=\"https://github.com/coreos/etcd\" target=\"_blank\" rel=\"noopener\">https://github.com/coreos/etcd</a></p>\n<blockquote>\n<p>Etcd 是 CoreOS 团队（同时发起了 CoreoS 、 Rocket 等热门项目）发起的一个开源分布式键值仓库项目，可以用于分布式系统中的配置信息管理和服务发现（ service discovery），目前已经被广泛应用到大量开源项目中，包括 Kubernetes 、 CloudFoundry 、 CoreOS Fleet 和Salesforce 等<br>Etcd 是 CoreOS 团队于 2013 年 6 月发起的开源项目，它的目标是构建一个高可用的分布式键值（ key-value ）仓库，遵循 Apache v2许可，基于 Go 语言实现<br>分布式系统中最基本的问题之一就是实现信息的共识，在此基础上才能实现对服务配置信息的管理、服务的发现、更新、同步,Etcd 专门为集群环境设计，采用了更为简洁的 Raft 共识算法＠，同样可以实现数据强一.致性，并支持集群节点状态管理和服务自动发现等.</p>\n</blockquote>\n<ul>\n<li>简单：支持 RESTfulAPI 和 gRPCAPI;</li>\n<li>安全： 基于 TLS 方式实现安全连接访问 ；</li>\n<li>快速： 支持每秒一万次的并发写操作，超时控制在毫秒量级 ；</li>\n<li>可靠： 支持分布式结构 ， 基于 Raft 算法实现一致性<br><img src=\"etcd_3.PNG\" alt=\"\"><br>默认etcd在k8s集群中的 3 or 5 or 7 台node上部署.</li>\n</ul>\n<h2 id=\"下载安装\"><a href=\"#下载安装\" class=\"headerlink\" title=\"下载安装\"></a>下载安装</h2><h3 id=\"二进制文件方式下载\"><a href=\"#二进制文件方式下载\" class=\"headerlink\" title=\"二进制文件方式下载\"></a>二进制文件方式下载</h3><pre><code>$ curl -L https://github.com/coreos/etcd/releases/download/v3.3.1/etcd-v3.3.1-linux-amd64.tar.gz\n$ tar xzvf etcd-v3.3.llinux-amd64.tar.gz\n$ cd etcd-v3.3.llinux-amd64.tar.gz | ls\n其中 etcd 是服务主文件， etcdctl 是提供给用户的命令客户端, 其他都是文档文件.\n$ sudo cp etcd* /usr/local/bin/</code></pre><p>Etcd 安装到此完成</p>\n<pre><code>$ etcd --version</code></pre><p>直接执行 Etcd 命令，将启动一个服务节点，监昕在本地的 2379 （客户端请求端口）和 2380 （其他节点连接端口 ） </p>\n<pre><code>$ etcd</code></pre><p>可以通过 REST API 直接查看集群健康状态：</p>\n<pre><code>$ curl -L http://127.0.0.1:2379/health\n{”health”: ”true”}</code></pre><p>也可以使用自带的 etcdctl 命令进行查看（实际上是封装了阻STAPI 调用）：</p>\n<pre><code>$ etcdctl cluster-health</code></pre><p>通过 etcdctl 设置和获取键值, 设置键值对 testkey：”hello world”</p>\n<pre><code>$ etcdctl put testkey &quot;hello world111&quot;</code></pre><p>也可以直接通过 HTTP 访问本地 2379 端口的方式来进行操作，例如查看 test key 的值：</p>\n<pre><code>$ curl -L -X PUT http://localhost:2379/v2/keys/testkey -d value=&quot;hello world&quot;</code></pre><h3 id=\"Docker-镜像方式下载\"><a href=\"#Docker-镜像方式下载\" class=\"headerlink\" title=\"Docker 镜像方式下载\"></a>Docker 镜像方式下载</h3><p>镜像名称为 quay.io/coreos/etcd:v3.3.1，可以通过下面的命令启动 etcd 服务监听到本地的 2379 和 2380 端口</p>\n<pre><code>$ docker run -p 2379:2379 -p 2380:2380 -v /etc/ssl/certs/:/etc/ssl/certs/ quay.io/coreos/etcd:v3.3.1</code></pre><h2 id=\"Etcd-集群管理\"><a href=\"#Etcd-集群管理\" class=\"headerlink\" title=\"Etcd 集群管理\"></a>Etcd 集群管理</h2><p>启动各个节点上的 etcd 服务, 指向主节点etcd存储</p>\n<h3 id=\"时钟同步\"><a href=\"#时钟同步\" class=\"headerlink\" title=\"时钟同步\"></a>时钟同步</h3><p>对于分布式集群来说，各个节点上的同步时钟十分重要， Etcd 集群需要各个节点时钟差异不超过 ls ，否则可能会导致 Raft 协议的异常.</p>\n<h3 id=\"节点恢复\"><a href=\"#节点恢复\" class=\"headerlink\" title=\"节点恢复\"></a>节点恢复</h3><blockquote>\n<p>Etcd 集群中的节点会通过数据目录来存放修改信息和集群配置 。<br>一般来说，当某个节点出现故障时候，本地数据已经过期甚至格式破坏. 如果只是简单地重启进程，容易造成数据的不一致。 这个时候，保险的做法是先通过命令（例如 etcdctlmember rm [member ］）来删除该节点，然后清空数据目录，再重新作为空节点加入.<br>Etcd 提供了－ strict-reconf ig-check 选项，确保当集群状态不稳定时候（例如启动节点数还不够达到 quorum ）拒绝对配置状态的修改</p>\n</blockquote>\n<h3 id=\"重启集群\"><a href=\"#重启集群\" class=\"headerlink\" title=\"重启集群\"></a>重启集群</h3><blockquote>\n<p>极端情况下，集群中大部分节点都出现问题，需要重启整个集群.<br>这个时候，最保险的办法是找到一个数据记录完整且比较新的节点，先以它为唯一节点创建新的集群，然后将其他节点一个一个地添加进来，添加过程中注意保证集群的稳定性.</p>\n</blockquote>\n<h3 id=\"K8s证书访问etcd-server\"><a href=\"#K8s证书访问etcd-server\" class=\"headerlink\" title=\"K8s证书访问etcd server\"></a>K8s证书访问etcd server</h3><p>Enter etcd pod:</p>\n<pre><code>$ kubectl exec etcd-hci-node01 -n kube-system -i -t – sh</code></pre><p>Get all key:</p>\n<pre><code>$ ETCDCTL_API=3 etcdctl --endpoints 127.0.0.1:2379 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt --key /etc/kubernetes/pki/etcd/server.key get / --prefix --keys-only</code></pre><p>Check the value of the key:</p>\n<pre><code>$ ETCDCTL_API=3 etcdctl --endpoints 127.0.0.1:2379 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt --key /etc/kubernetes/pki/etcd/server.key get /registry/statefulsets/kafka/kafka -w=json</code></pre><p>向etcd数据库添加key,value</p>\n<pre><code>$ ETCDCTL_API=3 etcdctl --endpoints 127.0.0.1:2379 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt --key /etc/kubernetes/pki/etcd/server.key put testkey &quot;hello world111&quot;</code></pre><p>获取添加的key, value值</p>\n<pre><code>$ ETCDCTL_API=3 etcdctl --endpoints 127.0.0.1:2379 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt --key /etc/kubernetes/pki/etcd/server.key get testkey</code></pre>"},{"title":"08 Kubernetes samples and problems","top":8,"_content":"\n## 01samples\nReference link:\nhttps://kubernetes.io/docs/tutorials/stateless-application/expose-external-ip-address/\n\n1. 填写yaml文件\n\t$ touch test.yaml\n添加如下内容\n\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\tlabels:\n\t\tapp.kubernetes.io/name: load-balancer-example\n\tname: hello-world\n\tspec:\n\treplicas: 5\n\tselector:\n\t\tmatchLabels:\n\t\tapp.kubernetes.io/name: load-balancer-example\n\ttemplate:\n\t\tmetadata:\n\t\tlabels:\n\t\t\tapp.kubernetes.io/name: load-balancer-example\n\t\tspec:\n\t\tcontainers:\n\t\t- image: gcr.io/google-samples/node-hello:1.0\n\t\t\tname: hello-world\n\t\t\tports:\n\t\t\t- containerPort: 8080\n\n2. 执行yaml生成POD\n\n\t$ kubectl apply -f test.yaml\n\n3. Display information about the Deployment:\n\n\t$ kubectl get deployments hello-world\n\t$ kubectl describe deployments hello-world\n\n4. Display information about your ReplicaSet objects:\n\n\t$ kubectl get replicasets\n\t$ kubectl describe replicasets\n\n5. Create a Service object that exposes the deployment:\n\n\t$ kubectl expose deployment hello-world --type=LoadBalancer --name=my-service\n\n6. Display information about the Service:\n\n\t$ kubectl get services my-service\n\tNAME         TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\n\tmy-service   LoadBalancer   10.103.40.210   <pending>     8080:30972/TCP   16m\n\n7. Display detailed information about the Service:\n\n\t$ kubectl describe services my-service\n\tName:                     my-service\n\tNamespace:                default\n\tLabels:                   app.kubernetes.io/name=load-balancer-example\n\tAnnotations:              <none>\n\tSelector:                 app.kubernetes.io/name=load-balancer-example\n\tType:                     LoadBalancer\n\tIP:                       10.103.40.210\n\tPort:                     <unset>  8080/TCP\n\tTargetPort:               8080/TCP\n\tNodePort:                 <unset>  30972/TCP\n\tEndpoints:                10.44.0.2:8080,10.44.0.3:8080,10.44.0.4:8080 + 2 more...\n\tSession Affinity:         None\n\tExternal Traffic Policy:  Cluster\n\tEvents:                   <none>\n\n8. 通过 NODE-IP + NodePort 访问\n如自己cubic中的开发机IP是10.239.140.186\n * 第一种访问方式:\n\n\t$ curl http://10.239.140.186:30972\n\tHello Kubernetes!\n * 第二种访问方式:\n\t浏览器输入http://10.239.140.186:30972 也能正常显示 Hello Kubernetes!\n\n但是公司lab实验室的开发机同样用上面方式部署之后，无法通过 NODE-IP + NodePort 访问， 问题估计跟网络有关\n\n\n","source":"_posts/micro_service/08_kubernetes_samples_problems.md","raw":"---\ntitle: 08 Kubernetes samples and problems\ntags: kubernetes\ncategories:\n- microService\n- kubernetes\ntop: 8\n---\n\n## 01samples\nReference link:\nhttps://kubernetes.io/docs/tutorials/stateless-application/expose-external-ip-address/\n\n1. 填写yaml文件\n\t$ touch test.yaml\n添加如下内容\n\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\tlabels:\n\t\tapp.kubernetes.io/name: load-balancer-example\n\tname: hello-world\n\tspec:\n\treplicas: 5\n\tselector:\n\t\tmatchLabels:\n\t\tapp.kubernetes.io/name: load-balancer-example\n\ttemplate:\n\t\tmetadata:\n\t\tlabels:\n\t\t\tapp.kubernetes.io/name: load-balancer-example\n\t\tspec:\n\t\tcontainers:\n\t\t- image: gcr.io/google-samples/node-hello:1.0\n\t\t\tname: hello-world\n\t\t\tports:\n\t\t\t- containerPort: 8080\n\n2. 执行yaml生成POD\n\n\t$ kubectl apply -f test.yaml\n\n3. Display information about the Deployment:\n\n\t$ kubectl get deployments hello-world\n\t$ kubectl describe deployments hello-world\n\n4. Display information about your ReplicaSet objects:\n\n\t$ kubectl get replicasets\n\t$ kubectl describe replicasets\n\n5. Create a Service object that exposes the deployment:\n\n\t$ kubectl expose deployment hello-world --type=LoadBalancer --name=my-service\n\n6. Display information about the Service:\n\n\t$ kubectl get services my-service\n\tNAME         TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\n\tmy-service   LoadBalancer   10.103.40.210   <pending>     8080:30972/TCP   16m\n\n7. Display detailed information about the Service:\n\n\t$ kubectl describe services my-service\n\tName:                     my-service\n\tNamespace:                default\n\tLabels:                   app.kubernetes.io/name=load-balancer-example\n\tAnnotations:              <none>\n\tSelector:                 app.kubernetes.io/name=load-balancer-example\n\tType:                     LoadBalancer\n\tIP:                       10.103.40.210\n\tPort:                     <unset>  8080/TCP\n\tTargetPort:               8080/TCP\n\tNodePort:                 <unset>  30972/TCP\n\tEndpoints:                10.44.0.2:8080,10.44.0.3:8080,10.44.0.4:8080 + 2 more...\n\tSession Affinity:         None\n\tExternal Traffic Policy:  Cluster\n\tEvents:                   <none>\n\n8. 通过 NODE-IP + NodePort 访问\n如自己cubic中的开发机IP是10.239.140.186\n * 第一种访问方式:\n\n\t$ curl http://10.239.140.186:30972\n\tHello Kubernetes!\n * 第二种访问方式:\n\t浏览器输入http://10.239.140.186:30972 也能正常显示 Hello Kubernetes!\n\n但是公司lab实验室的开发机同样用上面方式部署之后，无法通过 NODE-IP + NodePort 访问， 问题估计跟网络有关\n\n\n","slug":"micro_service/08_kubernetes_samples_problems","published":1,"date":"2020-08-12T16:05:47.468Z","updated":"2020-08-10T16:36:42.349Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmga004ohohxht6n42go","content":"<h2 id=\"01samples\"><a href=\"#01samples\" class=\"headerlink\" title=\"01samples\"></a>01samples</h2><p>Reference link:<br><a href=\"https://kubernetes.io/docs/tutorials/stateless-application/expose-external-ip-address/\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/docs/tutorials/stateless-application/expose-external-ip-address/</a></p>\n<ol>\n<li><p>填写yaml文件<br> $ touch test.yaml<br>添加如下内容</p>\n<p> apiVersion: apps/v1<br> kind: Deployment<br> metadata:<br> labels:</p>\n<pre><code>app.kubernetes.io/name: load-balancer-example</code></pre><p> name: hello-world<br> spec:<br> replicas: 5<br> selector:</p>\n<pre><code>matchLabels:\napp.kubernetes.io/name: load-balancer-example</code></pre><p> template:</p>\n<pre><code>metadata:\nlabels:\n    app.kubernetes.io/name: load-balancer-example\nspec:\ncontainers:\n- image: gcr.io/google-samples/node-hello:1.0\n    name: hello-world\n    ports:\n    - containerPort: 8080</code></pre></li>\n<li><p>执行yaml生成POD</p>\n<p> $ kubectl apply -f test.yaml</p>\n</li>\n<li><p>Display information about the Deployment:</p>\n<p> $ kubectl get deployments hello-world<br> $ kubectl describe deployments hello-world</p>\n</li>\n<li><p>Display information about your ReplicaSet objects:</p>\n<p> $ kubectl get replicasets<br> $ kubectl describe replicasets</p>\n</li>\n<li><p>Create a Service object that exposes the deployment:</p>\n<p> $ kubectl expose deployment hello-world –type=LoadBalancer –name=my-service</p>\n</li>\n<li><p>Display information about the Service:</p>\n<p> $ kubectl get services my-service<br> NAME         TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE<br> my-service   LoadBalancer   10.103.40.210   <pending>     8080:30972/TCP   16m</p>\n</li>\n<li><p>Display detailed information about the Service:</p>\n<p> $ kubectl describe services my-service<br> Name:                     my-service<br> Namespace:                default<br> Labels:                   app.kubernetes.io/name=load-balancer-example<br> Annotations:              <none><br> Selector:                 app.kubernetes.io/name=load-balancer-example<br> Type:                     LoadBalancer<br> IP:                       10.103.40.210<br> Port:                     <unset>  8080/TCP<br> TargetPort:               8080/TCP<br> NodePort:                 <unset>  30972/TCP<br> Endpoints:                10.44.0.2:8080,10.44.0.3:8080,10.44.0.4:8080 + 2 more…<br> Session Affinity:         None<br> External Traffic Policy:  Cluster<br> Events:                   <none></p>\n</li>\n<li><p>通过 NODE-IP + NodePort 访问<br>如自己cubic中的开发机IP是10.239.140.186</p>\n<ul>\n<li><p>第一种访问方式:</p>\n<p>$ curl <a href=\"http://10.239.140.186:30972\" target=\"_blank\" rel=\"noopener\">http://10.239.140.186:30972</a><br>Hello Kubernetes!</p>\n</li>\n<li><p>第二种访问方式:<br>浏览器输入<a href=\"http://10.239.140.186:30972\" target=\"_blank\" rel=\"noopener\">http://10.239.140.186:30972</a> 也能正常显示 Hello Kubernetes!</p>\n</li>\n</ul>\n</li>\n</ol>\n<p>但是公司lab实验室的开发机同样用上面方式部署之后，无法通过 NODE-IP + NodePort 访问， 问题估计跟网络有关</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"01samples\"><a href=\"#01samples\" class=\"headerlink\" title=\"01samples\"></a>01samples</h2><p>Reference link:<br><a href=\"https://kubernetes.io/docs/tutorials/stateless-application/expose-external-ip-address/\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/docs/tutorials/stateless-application/expose-external-ip-address/</a></p>\n<ol>\n<li><p>填写yaml文件<br> $ touch test.yaml<br>添加如下内容</p>\n<p> apiVersion: apps/v1<br> kind: Deployment<br> metadata:<br> labels:</p>\n<pre><code>app.kubernetes.io/name: load-balancer-example</code></pre><p> name: hello-world<br> spec:<br> replicas: 5<br> selector:</p>\n<pre><code>matchLabels:\napp.kubernetes.io/name: load-balancer-example</code></pre><p> template:</p>\n<pre><code>metadata:\nlabels:\n    app.kubernetes.io/name: load-balancer-example\nspec:\ncontainers:\n- image: gcr.io/google-samples/node-hello:1.0\n    name: hello-world\n    ports:\n    - containerPort: 8080</code></pre></li>\n<li><p>执行yaml生成POD</p>\n<p> $ kubectl apply -f test.yaml</p>\n</li>\n<li><p>Display information about the Deployment:</p>\n<p> $ kubectl get deployments hello-world<br> $ kubectl describe deployments hello-world</p>\n</li>\n<li><p>Display information about your ReplicaSet objects:</p>\n<p> $ kubectl get replicasets<br> $ kubectl describe replicasets</p>\n</li>\n<li><p>Create a Service object that exposes the deployment:</p>\n<p> $ kubectl expose deployment hello-world –type=LoadBalancer –name=my-service</p>\n</li>\n<li><p>Display information about the Service:</p>\n<p> $ kubectl get services my-service<br> NAME         TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE<br> my-service   LoadBalancer   10.103.40.210   <pending>     8080:30972/TCP   16m</p>\n</li>\n<li><p>Display detailed information about the Service:</p>\n<p> $ kubectl describe services my-service<br> Name:                     my-service<br> Namespace:                default<br> Labels:                   app.kubernetes.io/name=load-balancer-example<br> Annotations:              <none><br> Selector:                 app.kubernetes.io/name=load-balancer-example<br> Type:                     LoadBalancer<br> IP:                       10.103.40.210<br> Port:                     <unset>  8080/TCP<br> TargetPort:               8080/TCP<br> NodePort:                 <unset>  30972/TCP<br> Endpoints:                10.44.0.2:8080,10.44.0.3:8080,10.44.0.4:8080 + 2 more…<br> Session Affinity:         None<br> External Traffic Policy:  Cluster<br> Events:                   <none></p>\n</li>\n<li><p>通过 NODE-IP + NodePort 访问<br>如自己cubic中的开发机IP是10.239.140.186</p>\n<ul>\n<li><p>第一种访问方式:</p>\n<p>$ curl <a href=\"http://10.239.140.186:30972\" target=\"_blank\" rel=\"noopener\">http://10.239.140.186:30972</a><br>Hello Kubernetes!</p>\n</li>\n<li><p>第二种访问方式:<br>浏览器输入<a href=\"http://10.239.140.186:30972\" target=\"_blank\" rel=\"noopener\">http://10.239.140.186:30972</a> 也能正常显示 Hello Kubernetes!</p>\n</li>\n</ul>\n</li>\n</ol>\n<p>但是公司lab实验室的开发机同样用上面方式部署之后，无法通过 NODE-IP + NodePort 访问， 问题估计跟网络有关</p>\n"},{"title":"08 Kubernetes Certificates","top":9,"_content":"\n## K8s Certificates\n\n !()[k8s_certificates.PNG]\n\n## 证书颁发\n\n1. 自签证书, 多用在内部服务之间, K8s, etcd就是使用自签证书.\n\n2. 权威机构: GeoTrust RSA CA 2018, GTS CA 101, Intel Internal Issuing CA 5A\n例如赛门铁克, 分不同档次, 中档3000元左右, 如www.ctnrs.com, 也有针对所有域名的 *.ctnrs.com, 不过更贵\n\n根证书: 每个浏览器都内置了各个信任的权威机构, 是权威机构颁发的证书浏览https访问路径上的锁显示安全, 否则显示不可信任的网站\n\n自签证书和权威机构都会颁发两个证书:\n-- 1. crt： 数字证书;\n-- 2. key： 私钥;\n将这两证书配置到web服务器就可以了\n\n不管是自签还是权威机构都有CA, 会颁发多个证书出来, \n\n## simulate CA\n![](CA_simulate.PNG)\n\n## 使用cfssl或openssl生成自签证书\nhttps://kubernetes.io/zh/docs/concepts/cluster-administration/certificates/\n\ncfssl 在 k8s 中比较流行, 使用json文件传入来生成证书, 要比 openssl 更直观也简单点.\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/micro_service/09_kubernetes_certificate.md","raw":"---\ntitle: 08 Kubernetes Certificates\ntags:\n- kubernetes\ncategories:\n- microService\n- kubernetes\ntop: 9\n---\n\n## K8s Certificates\n\n !()[k8s_certificates.PNG]\n\n## 证书颁发\n\n1. 自签证书, 多用在内部服务之间, K8s, etcd就是使用自签证书.\n\n2. 权威机构: GeoTrust RSA CA 2018, GTS CA 101, Intel Internal Issuing CA 5A\n例如赛门铁克, 分不同档次, 中档3000元左右, 如www.ctnrs.com, 也有针对所有域名的 *.ctnrs.com, 不过更贵\n\n根证书: 每个浏览器都内置了各个信任的权威机构, 是权威机构颁发的证书浏览https访问路径上的锁显示安全, 否则显示不可信任的网站\n\n自签证书和权威机构都会颁发两个证书:\n-- 1. crt： 数字证书;\n-- 2. key： 私钥;\n将这两证书配置到web服务器就可以了\n\n不管是自签还是权威机构都有CA, 会颁发多个证书出来, \n\n## simulate CA\n![](CA_simulate.PNG)\n\n## 使用cfssl或openssl生成自签证书\nhttps://kubernetes.io/zh/docs/concepts/cluster-administration/certificates/\n\ncfssl 在 k8s 中比较流行, 使用json文件传入来生成证书, 要比 openssl 更直观也简单点.\n\n\n\n\n\n\n\n\n\n\n\n","slug":"micro_service/09_kubernetes_certificate","published":1,"date":"2020-08-12T16:05:47.483Z","updated":"2020-08-10T16:36:48.889Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmgc004rhohx0qqt3l4o","content":"<h2 id=\"K8s-Certificates\"><a href=\"#K8s-Certificates\" class=\"headerlink\" title=\"K8s Certificates\"></a>K8s Certificates</h2><p> !()[k8s_certificates.PNG]</p>\n<h2 id=\"证书颁发\"><a href=\"#证书颁发\" class=\"headerlink\" title=\"证书颁发\"></a>证书颁发</h2><ol>\n<li><p>自签证书, 多用在内部服务之间, K8s, etcd就是使用自签证书.</p>\n</li>\n<li><p>权威机构: GeoTrust RSA CA 2018, GTS CA 101, Intel Internal Issuing CA 5A<br>例如赛门铁克, 分不同档次, 中档3000元左右, 如<a href=\"http://www.ctnrs.com\" target=\"_blank\" rel=\"noopener\">www.ctnrs.com</a>, 也有针对所有域名的 *.ctnrs.com, 不过更贵</p>\n</li>\n</ol>\n<p>根证书: 每个浏览器都内置了各个信任的权威机构, 是权威机构颁发的证书浏览https访问路径上的锁显示安全, 否则显示不可信任的网站</p>\n<p>自签证书和权威机构都会颁发两个证书:<br>– 1. crt： 数字证书;<br>– 2. key： 私钥;<br>将这两证书配置到web服务器就可以了</p>\n<p>不管是自签还是权威机构都有CA, 会颁发多个证书出来, </p>\n<h2 id=\"simulate-CA\"><a href=\"#simulate-CA\" class=\"headerlink\" title=\"simulate CA\"></a>simulate CA</h2><p><img src=\"CA_simulate.PNG\" alt=\"\"></p>\n<h2 id=\"使用cfssl或openssl生成自签证书\"><a href=\"#使用cfssl或openssl生成自签证书\" class=\"headerlink\" title=\"使用cfssl或openssl生成自签证书\"></a>使用cfssl或openssl生成自签证书</h2><p><a href=\"https://kubernetes.io/zh/docs/concepts/cluster-administration/certificates/\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/zh/docs/concepts/cluster-administration/certificates/</a></p>\n<p>cfssl 在 k8s 中比较流行, 使用json文件传入来生成证书, 要比 openssl 更直观也简单点.</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"K8s-Certificates\"><a href=\"#K8s-Certificates\" class=\"headerlink\" title=\"K8s Certificates\"></a>K8s Certificates</h2><p> !()[k8s_certificates.PNG]</p>\n<h2 id=\"证书颁发\"><a href=\"#证书颁发\" class=\"headerlink\" title=\"证书颁发\"></a>证书颁发</h2><ol>\n<li><p>自签证书, 多用在内部服务之间, K8s, etcd就是使用自签证书.</p>\n</li>\n<li><p>权威机构: GeoTrust RSA CA 2018, GTS CA 101, Intel Internal Issuing CA 5A<br>例如赛门铁克, 分不同档次, 中档3000元左右, 如<a href=\"http://www.ctnrs.com\" target=\"_blank\" rel=\"noopener\">www.ctnrs.com</a>, 也有针对所有域名的 *.ctnrs.com, 不过更贵</p>\n</li>\n</ol>\n<p>根证书: 每个浏览器都内置了各个信任的权威机构, 是权威机构颁发的证书浏览https访问路径上的锁显示安全, 否则显示不可信任的网站</p>\n<p>自签证书和权威机构都会颁发两个证书:<br>– 1. crt： 数字证书;<br>– 2. key： 私钥;<br>将这两证书配置到web服务器就可以了</p>\n<p>不管是自签还是权威机构都有CA, 会颁发多个证书出来, </p>\n<h2 id=\"simulate-CA\"><a href=\"#simulate-CA\" class=\"headerlink\" title=\"simulate CA\"></a>simulate CA</h2><p><img src=\"CA_simulate.PNG\" alt=\"\"></p>\n<h2 id=\"使用cfssl或openssl生成自签证书\"><a href=\"#使用cfssl或openssl生成自签证书\" class=\"headerlink\" title=\"使用cfssl或openssl生成自签证书\"></a>使用cfssl或openssl生成自签证书</h2><p><a href=\"https://kubernetes.io/zh/docs/concepts/cluster-administration/certificates/\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/zh/docs/concepts/cluster-administration/certificates/</a></p>\n<p>cfssl 在 k8s 中比较流行, 使用json文件传入来生成证书, 要比 openssl 更直观也简单点.</p>\n"},{"title":"Istio_K8s_SpringCloud","_content":"\nSpringCloud、Istio比较\n> https://blog.csdn.net/qq_33873431/article/details/89524554\n\nSpring Cloud Netflix vs. Kubernetes＆Istio\n> https://my.oschina.net/xiaominmin/blog/1859677\n> https://my.oschina.net/xiaominmin?tab=newest&catalogId=5894416\n\n史上最简单的spark系列教程\n> https://blog.csdn.net/youbitch1/article/details/89925790\nSpark教程视频:\n> https://www.bilibili.com/video/BV1JE411R7Xp?p=55\n> https://www.bilibili.com/video/BV11J41147iP?p=1\n> https://www.bilibili.com/video/BV11J41147iP?p=1\n\n\n\nIstio B站学习视频和对应的Gihub文档\n> https://www.bilibili.com/video/BV1vt411H755/?spm_id_from=333.788.videocard.0\n> https://github.com/Kung-Fu-Master/Document\n\nIstio中文社区:\n> * [中文社区](https://istio.cn/)\n> * [Istio 1.5发布](https://istio.cn/t/topic/270)\n\n\n","source":"_posts/micro_service/Istio_K8s_SpringCloud.md","raw":"---\ntitle: Istio_K8s_SpringCloud\ntags: kubernetes\ncategories:\n- microService\n- istio\n---\n\nSpringCloud、Istio比较\n> https://blog.csdn.net/qq_33873431/article/details/89524554\n\nSpring Cloud Netflix vs. Kubernetes＆Istio\n> https://my.oschina.net/xiaominmin/blog/1859677\n> https://my.oschina.net/xiaominmin?tab=newest&catalogId=5894416\n\n史上最简单的spark系列教程\n> https://blog.csdn.net/youbitch1/article/details/89925790\nSpark教程视频:\n> https://www.bilibili.com/video/BV1JE411R7Xp?p=55\n> https://www.bilibili.com/video/BV11J41147iP?p=1\n> https://www.bilibili.com/video/BV11J41147iP?p=1\n\n\n\nIstio B站学习视频和对应的Gihub文档\n> https://www.bilibili.com/video/BV1vt411H755/?spm_id_from=333.788.videocard.0\n> https://github.com/Kung-Fu-Master/Document\n\nIstio中文社区:\n> * [中文社区](https://istio.cn/)\n> * [Istio 1.5发布](https://istio.cn/t/topic/270)\n\n\n","slug":"micro_service/Istio_K8s_SpringCloud","published":1,"date":"2020-08-12T16:05:47.523Z","updated":"2020-08-10T16:37:50.898Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmgd004vhohxbs4h3mfi","content":"<p>SpringCloud、Istio比较</p>\n<blockquote>\n<p><a href=\"https://blog.csdn.net/qq_33873431/article/details/89524554\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_33873431/article/details/89524554</a></p>\n</blockquote>\n<p>Spring Cloud Netflix vs. Kubernetes＆Istio</p>\n<blockquote>\n<p><a href=\"https://my.oschina.net/xiaominmin/blog/1859677\" target=\"_blank\" rel=\"noopener\">https://my.oschina.net/xiaominmin/blog/1859677</a><br><a href=\"https://my.oschina.net/xiaominmin?tab=newest&amp;catalogId=5894416\" target=\"_blank\" rel=\"noopener\">https://my.oschina.net/xiaominmin?tab=newest&amp;catalogId=5894416</a></p>\n</blockquote>\n<p>史上最简单的spark系列教程</p>\n<blockquote>\n<p><a href=\"https://blog.csdn.net/youbitch1/article/details/89925790\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/youbitch1/article/details/89925790</a><br>Spark教程视频:<br><a href=\"https://www.bilibili.com/video/BV1JE411R7Xp?p=55\" target=\"_blank\" rel=\"noopener\">https://www.bilibili.com/video/BV1JE411R7Xp?p=55</a><br><a href=\"https://www.bilibili.com/video/BV11J41147iP?p=1\" target=\"_blank\" rel=\"noopener\">https://www.bilibili.com/video/BV11J41147iP?p=1</a><br><a href=\"https://www.bilibili.com/video/BV11J41147iP?p=1\" target=\"_blank\" rel=\"noopener\">https://www.bilibili.com/video/BV11J41147iP?p=1</a></p>\n</blockquote>\n<p>Istio B站学习视频和对应的Gihub文档</p>\n<blockquote>\n<p><a href=\"https://www.bilibili.com/video/BV1vt411H755/?spm_id_from=333.788.videocard.0\" target=\"_blank\" rel=\"noopener\">https://www.bilibili.com/video/BV1vt411H755/?spm_id_from=333.788.videocard.0</a><br><a href=\"https://github.com/Kung-Fu-Master/Document\" target=\"_blank\" rel=\"noopener\">https://github.com/Kung-Fu-Master/Document</a></p>\n</blockquote>\n<p>Istio中文社区:</p>\n<blockquote>\n<ul>\n<li><a href=\"https://istio.cn/\" target=\"_blank\" rel=\"noopener\">中文社区</a></li>\n<li><a href=\"https://istio.cn/t/topic/270\" target=\"_blank\" rel=\"noopener\">Istio 1.5发布</a></li>\n</ul>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<p>SpringCloud、Istio比较</p>\n<blockquote>\n<p><a href=\"https://blog.csdn.net/qq_33873431/article/details/89524554\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_33873431/article/details/89524554</a></p>\n</blockquote>\n<p>Spring Cloud Netflix vs. Kubernetes＆Istio</p>\n<blockquote>\n<p><a href=\"https://my.oschina.net/xiaominmin/blog/1859677\" target=\"_blank\" rel=\"noopener\">https://my.oschina.net/xiaominmin/blog/1859677</a><br><a href=\"https://my.oschina.net/xiaominmin?tab=newest&amp;catalogId=5894416\" target=\"_blank\" rel=\"noopener\">https://my.oschina.net/xiaominmin?tab=newest&amp;catalogId=5894416</a></p>\n</blockquote>\n<p>史上最简单的spark系列教程</p>\n<blockquote>\n<p><a href=\"https://blog.csdn.net/youbitch1/article/details/89925790\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/youbitch1/article/details/89925790</a><br>Spark教程视频:<br><a href=\"https://www.bilibili.com/video/BV1JE411R7Xp?p=55\" target=\"_blank\" rel=\"noopener\">https://www.bilibili.com/video/BV1JE411R7Xp?p=55</a><br><a href=\"https://www.bilibili.com/video/BV11J41147iP?p=1\" target=\"_blank\" rel=\"noopener\">https://www.bilibili.com/video/BV11J41147iP?p=1</a><br><a href=\"https://www.bilibili.com/video/BV11J41147iP?p=1\" target=\"_blank\" rel=\"noopener\">https://www.bilibili.com/video/BV11J41147iP?p=1</a></p>\n</blockquote>\n<p>Istio B站学习视频和对应的Gihub文档</p>\n<blockquote>\n<p><a href=\"https://www.bilibili.com/video/BV1vt411H755/?spm_id_from=333.788.videocard.0\" target=\"_blank\" rel=\"noopener\">https://www.bilibili.com/video/BV1vt411H755/?spm_id_from=333.788.videocard.0</a><br><a href=\"https://github.com/Kung-Fu-Master/Document\" target=\"_blank\" rel=\"noopener\">https://github.com/Kung-Fu-Master/Document</a></p>\n</blockquote>\n<p>Istio中文社区:</p>\n<blockquote>\n<ul>\n<li><a href=\"https://istio.cn/\" target=\"_blank\" rel=\"noopener\">中文社区</a></li>\n<li><a href=\"https://istio.cn/t/topic/270\" target=\"_blank\" rel=\"noopener\">Istio 1.5发布</a></li>\n</ul>\n</blockquote>\n"},{"title":"Resources","top":9,"_content":"\n## Resources\n查看某台机器的资源\n\n\t$ kubectl describe node hci-node01\n\n### memory, CPU\nrequests, limits关键字.\n当没有哪个Node节点满足requests的资源时候，container会一直处于pending状态, 而不会受limits资源影响.\n如Node只有10GB内存，一个container request memory配置7GB内存大小，那么其余container只能分配剩余的3GB内存大小.\n配置K8s的container文件\n\n\tapiVersion: v1\n\t......\n\tspec:\n\t  containers:\n\t  - name: web-demo\n\t    image: hub.**\n\t    ports:\n\t    - containerPort: 8080\n\t    resources:\n\t      requests:\n\t        memory: 100Mi\t\t// Ki: KB大小, Mi: MB大小, Gi: GB大小\n\t        cpu: 100m\t\t\t// 如机器有12个内核, 而1个cpu内核=1000m, 100m为0.1个cpu内核, milli core, 千分之一core\n\t      limits:\n\t        memory: 1000Mi\n\t        cpu: 200m\n\n登陆container运行的机器，查看容器设置参数\n\n\t$ docker inspect containerID\n\t......\n\t\"CpuShares\" 102,\t\t// 100m转为为0.1内核，再用0.1 * 1024 = 102，当很多个容器运行在某台机器上发生CPU资源抢占时候用该值作为权重进行分配\n\t\"Memory\": 1048576000,\t// 对应K8s资源文件的limits->memory值：1000MB大小\n\t......\n\t\"CPUPeriod\": 100000,\t// docker 默认值, 单位是ns, 转化为毫秒是100\n\t\"CpuQuota\": 20000,\t\t// 0.2 core * 100000 = 20000, 与上面一起使用，表示100ms内最多分配给容器的cpu量是0.2个core\n当容器里进程所用内存超过requests值时, 占用资源最多的进程会被kill掉, 但是容器不会退出重启.\n而CPU超出limits值时进程不会退出，因为CPU是可压缩资源，而内存不是.\n\n\t$ docker stats ContainerID\t\t\t// 查看container CPU和内存使用情况\n\n进入容器通过以下command命令模拟多个后台进程占用CPU\n\n\t$ dd if=/dev/zero of=/dev/null &\t//\n\t$ killall dd\t\t\t\t\t\t// 删除所有dd命令\n一般情况都是设置requests == limits\n\n\n### LimitRange\n在一个namespace下对Pod和container申请的CPU和memory资源进行限制\n\n\tapiVersion: v1\n\tkind: LimitRange\n\tmetadata:\n\t  name: test-limits\n\tspec: \n\t  limits:\n\t  - max:\n\t      cpu: 4000m\n\t      memory: 2Gi\n\t    min:\n\t      cpu: 100m\n\t      memory: 100Mi\n\t    maxLimitRequestRatio:\n\t      cpu: 3\t\t\t\t// 对POD显示，运行起来后占用机器cpu资源数是在limits.cpu最大以内且不能超过requests.cpu的3倍.\n\t      memory: 2\n\t    type: Pod\t\t\t\t// 上面限制类型为Pod\n\t  - default:\n\t      cpu: 300m\t\t\t\t// 默认Container 0.3个内核\n\t      memory: 200Mi\n\t    defaultRequest:\n\t      cpu: 200m\n\t      memory: 100Mi\n\t    max:\n\t      cpu: 2000m\n\t      memory: 1Gi\n\t    min:\n\t      cpu: 100m\n\t      memory: 100Mi\n\t    maxLimitRequestRatio:\n\t      cpu: 5\n\t      memory: 4\n\t    type: Container\t\t\t// 上面显示类型为Container\n运行如下命令查看limits限制\n\n\t$ kubectl describe limits -n namespaces\n> 当新建deployment或RS或Pod时，会根据LimitRange限制检测新建的Pod或Container是否满足条件，否则创建失败, 可以通过kubectl get ** -o yaml查看事件message.\n\n### ResourceQuota\n对每个namespace能够使用的资源进行限制.\n\n\tapiVersion: v1\n\tkind: ResourceQuota\n\tmetadata:\n\t  name: resource-quota\n\tspec:\n\t  hard:\n\t    pods: 4\n\t    requests.cpu: 2000m\n\t    requests.memory: 4Gi\n\t    limits.cpu: 4000m\n\t    limits.memory: 8Gi\n\t    configmaps: 10\n\t    persistentvolumeclaims: 4\n\t    replicationcontrollers: 20\n\t    secrets: 10\n\t    services: 10\n查看quota类型资源\n\n\t$ kubectl get quota -n NS\n\t$ kubectl describe quota *** -n NS\t\t// 查看硬件资源是否使用饱和\n\n\n### Eviction-Pod驱逐\n常见驱逐策略配置\n * 在1m30s时间内可利用内存持续小于1.5GB时进行驱逐\n\n\n\t--eviction-soft=memory.available<1.5Gi\n\t--eviction-soft-grace-period=memory.available=1m30s\n * 当可利用内存小于100MB或磁盘小于1GB或剩余的节点小于5%立即执行驱逐策略\n\n\n\t--eviction-hard=memory.available<100Mi,nodefs.available<1Gi,nodefs.inodesFree<5%\n\n驱逐策略:\n磁盘紧缺时候:\n * 删除死掉的Pod和容器\n * 删除没用的image\n * 按优先级和资源占用情况驱逐Pod\n\n\n内存紧缺时候:\n * 驱逐不可靠的Pod(没有设置requests和limits资源的pod都是不可靠的Pod)\n * 驱逐基本可靠的pod(实际使用资源大于requests资源是基本可靠,超出的越多优先删除，否则删除占用内存最多的Pod)\n * 驱逐可靠的Pod(requests资源==limits资源的Pod为可靠的Pod, 如果都一样驱逐策略跟上面驱逐基本可靠Pod一致)\n\n\n### label\nkey=value 贴标签(Node, Deployment, Service, Pod)\n\n\t#deploy\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\t  name: web-demo\n\t  namespace: dev\n\tspec:\n\t  selector:\n\t    matchLabels:\t\t\t\t// 选择含有指定标签的Pod,必须跟下面一致，或者不写只配置下面Pod的label也可以\n\t      app: web-demo\n\t    matchExpressions:\n\t      - {key: group, operator: In, values: [dev, test]}\t\t// Key in values的Pod都会被选中\n\t  replicas: 1\n\t  template:\t\t\t\t\t\t// 设置Pod模板\n\t    metadata:\n\t      labels:\t\t\t\t\t// 设置Pod标签\n\t        app: web-demo\n\t        group: dev\n\t    spec:\n\t      containers:\n\t      - name: web-demo\n\t        image: hub**\n\t        ports:\n\t        - containerPort: 8080\n\t      nodeSelector:\t\t\t\t// 选择含有某个标签的Node机器部署Pod\n\t        disktype: ssd\n\t---\n\t# service\n\tapiVersion: v1\n\tkind: Service\n\tmetadata:\n\t  name: web-demo\n\t  namespace: dev\n\tspec:\n\t  ports:\n\t  - port: 80\n\t    protocol: TCP\n\t    targetPort: 8080\n\t  selector:\n\t    app: web-demo\n\t  type: ClusterIP\n查询Pod\n\n\t$ kubectl get pods -l \"group in (dev, test)\" -n NS\n\t$ kubectl get pods -l \"group notin (dev)\" -n NS\n\t$ kubectl get pods  -l group=dev,group=test -n NS\n\n\n\n\n\n\n\n\n","source":"_posts/micro_service/Resources.md","raw":"---\ntitle: Resources\ntags: kubernetes\ncategories:\n- microService\n- kubernetes\ntop: 9\n---\n\n## Resources\n查看某台机器的资源\n\n\t$ kubectl describe node hci-node01\n\n### memory, CPU\nrequests, limits关键字.\n当没有哪个Node节点满足requests的资源时候，container会一直处于pending状态, 而不会受limits资源影响.\n如Node只有10GB内存，一个container request memory配置7GB内存大小，那么其余container只能分配剩余的3GB内存大小.\n配置K8s的container文件\n\n\tapiVersion: v1\n\t......\n\tspec:\n\t  containers:\n\t  - name: web-demo\n\t    image: hub.**\n\t    ports:\n\t    - containerPort: 8080\n\t    resources:\n\t      requests:\n\t        memory: 100Mi\t\t// Ki: KB大小, Mi: MB大小, Gi: GB大小\n\t        cpu: 100m\t\t\t// 如机器有12个内核, 而1个cpu内核=1000m, 100m为0.1个cpu内核, milli core, 千分之一core\n\t      limits:\n\t        memory: 1000Mi\n\t        cpu: 200m\n\n登陆container运行的机器，查看容器设置参数\n\n\t$ docker inspect containerID\n\t......\n\t\"CpuShares\" 102,\t\t// 100m转为为0.1内核，再用0.1 * 1024 = 102，当很多个容器运行在某台机器上发生CPU资源抢占时候用该值作为权重进行分配\n\t\"Memory\": 1048576000,\t// 对应K8s资源文件的limits->memory值：1000MB大小\n\t......\n\t\"CPUPeriod\": 100000,\t// docker 默认值, 单位是ns, 转化为毫秒是100\n\t\"CpuQuota\": 20000,\t\t// 0.2 core * 100000 = 20000, 与上面一起使用，表示100ms内最多分配给容器的cpu量是0.2个core\n当容器里进程所用内存超过requests值时, 占用资源最多的进程会被kill掉, 但是容器不会退出重启.\n而CPU超出limits值时进程不会退出，因为CPU是可压缩资源，而内存不是.\n\n\t$ docker stats ContainerID\t\t\t// 查看container CPU和内存使用情况\n\n进入容器通过以下command命令模拟多个后台进程占用CPU\n\n\t$ dd if=/dev/zero of=/dev/null &\t//\n\t$ killall dd\t\t\t\t\t\t// 删除所有dd命令\n一般情况都是设置requests == limits\n\n\n### LimitRange\n在一个namespace下对Pod和container申请的CPU和memory资源进行限制\n\n\tapiVersion: v1\n\tkind: LimitRange\n\tmetadata:\n\t  name: test-limits\n\tspec: \n\t  limits:\n\t  - max:\n\t      cpu: 4000m\n\t      memory: 2Gi\n\t    min:\n\t      cpu: 100m\n\t      memory: 100Mi\n\t    maxLimitRequestRatio:\n\t      cpu: 3\t\t\t\t// 对POD显示，运行起来后占用机器cpu资源数是在limits.cpu最大以内且不能超过requests.cpu的3倍.\n\t      memory: 2\n\t    type: Pod\t\t\t\t// 上面限制类型为Pod\n\t  - default:\n\t      cpu: 300m\t\t\t\t// 默认Container 0.3个内核\n\t      memory: 200Mi\n\t    defaultRequest:\n\t      cpu: 200m\n\t      memory: 100Mi\n\t    max:\n\t      cpu: 2000m\n\t      memory: 1Gi\n\t    min:\n\t      cpu: 100m\n\t      memory: 100Mi\n\t    maxLimitRequestRatio:\n\t      cpu: 5\n\t      memory: 4\n\t    type: Container\t\t\t// 上面显示类型为Container\n运行如下命令查看limits限制\n\n\t$ kubectl describe limits -n namespaces\n> 当新建deployment或RS或Pod时，会根据LimitRange限制检测新建的Pod或Container是否满足条件，否则创建失败, 可以通过kubectl get ** -o yaml查看事件message.\n\n### ResourceQuota\n对每个namespace能够使用的资源进行限制.\n\n\tapiVersion: v1\n\tkind: ResourceQuota\n\tmetadata:\n\t  name: resource-quota\n\tspec:\n\t  hard:\n\t    pods: 4\n\t    requests.cpu: 2000m\n\t    requests.memory: 4Gi\n\t    limits.cpu: 4000m\n\t    limits.memory: 8Gi\n\t    configmaps: 10\n\t    persistentvolumeclaims: 4\n\t    replicationcontrollers: 20\n\t    secrets: 10\n\t    services: 10\n查看quota类型资源\n\n\t$ kubectl get quota -n NS\n\t$ kubectl describe quota *** -n NS\t\t// 查看硬件资源是否使用饱和\n\n\n### Eviction-Pod驱逐\n常见驱逐策略配置\n * 在1m30s时间内可利用内存持续小于1.5GB时进行驱逐\n\n\n\t--eviction-soft=memory.available<1.5Gi\n\t--eviction-soft-grace-period=memory.available=1m30s\n * 当可利用内存小于100MB或磁盘小于1GB或剩余的节点小于5%立即执行驱逐策略\n\n\n\t--eviction-hard=memory.available<100Mi,nodefs.available<1Gi,nodefs.inodesFree<5%\n\n驱逐策略:\n磁盘紧缺时候:\n * 删除死掉的Pod和容器\n * 删除没用的image\n * 按优先级和资源占用情况驱逐Pod\n\n\n内存紧缺时候:\n * 驱逐不可靠的Pod(没有设置requests和limits资源的pod都是不可靠的Pod)\n * 驱逐基本可靠的pod(实际使用资源大于requests资源是基本可靠,超出的越多优先删除，否则删除占用内存最多的Pod)\n * 驱逐可靠的Pod(requests资源==limits资源的Pod为可靠的Pod, 如果都一样驱逐策略跟上面驱逐基本可靠Pod一致)\n\n\n### label\nkey=value 贴标签(Node, Deployment, Service, Pod)\n\n\t#deploy\n\tapiVersion: apps/v1\n\tkind: Deployment\n\tmetadata:\n\t  name: web-demo\n\t  namespace: dev\n\tspec:\n\t  selector:\n\t    matchLabels:\t\t\t\t// 选择含有指定标签的Pod,必须跟下面一致，或者不写只配置下面Pod的label也可以\n\t      app: web-demo\n\t    matchExpressions:\n\t      - {key: group, operator: In, values: [dev, test]}\t\t// Key in values的Pod都会被选中\n\t  replicas: 1\n\t  template:\t\t\t\t\t\t// 设置Pod模板\n\t    metadata:\n\t      labels:\t\t\t\t\t// 设置Pod标签\n\t        app: web-demo\n\t        group: dev\n\t    spec:\n\t      containers:\n\t      - name: web-demo\n\t        image: hub**\n\t        ports:\n\t        - containerPort: 8080\n\t      nodeSelector:\t\t\t\t// 选择含有某个标签的Node机器部署Pod\n\t        disktype: ssd\n\t---\n\t# service\n\tapiVersion: v1\n\tkind: Service\n\tmetadata:\n\t  name: web-demo\n\t  namespace: dev\n\tspec:\n\t  ports:\n\t  - port: 80\n\t    protocol: TCP\n\t    targetPort: 8080\n\t  selector:\n\t    app: web-demo\n\t  type: ClusterIP\n查询Pod\n\n\t$ kubectl get pods -l \"group in (dev, test)\" -n NS\n\t$ kubectl get pods -l \"group notin (dev)\" -n NS\n\t$ kubectl get pods  -l group=dev,group=test -n NS\n\n\n\n\n\n\n\n\n","slug":"micro_service/Resources","published":1,"date":"2020-08-12T16:05:47.526Z","updated":"2020-08-10T16:38:06.957Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmge004yhohx0tw701dz","content":"<h2 id=\"Resources\"><a href=\"#Resources\" class=\"headerlink\" title=\"Resources\"></a>Resources</h2><p>查看某台机器的资源</p>\n<pre><code>$ kubectl describe node hci-node01</code></pre><h3 id=\"memory-CPU\"><a href=\"#memory-CPU\" class=\"headerlink\" title=\"memory, CPU\"></a>memory, CPU</h3><p>requests, limits关键字.<br>当没有哪个Node节点满足requests的资源时候，container会一直处于pending状态, 而不会受limits资源影响.<br>如Node只有10GB内存，一个container request memory配置7GB内存大小，那么其余container只能分配剩余的3GB内存大小.<br>配置K8s的container文件</p>\n<pre><code>apiVersion: v1\n......\nspec:\n  containers:\n  - name: web-demo\n    image: hub.**\n    ports:\n    - containerPort: 8080\n    resources:\n      requests:\n        memory: 100Mi        // Ki: KB大小, Mi: MB大小, Gi: GB大小\n        cpu: 100m            // 如机器有12个内核, 而1个cpu内核=1000m, 100m为0.1个cpu内核, milli core, 千分之一core\n      limits:\n        memory: 1000Mi\n        cpu: 200m</code></pre><p>登陆container运行的机器，查看容器设置参数</p>\n<pre><code>$ docker inspect containerID\n......\n&quot;CpuShares&quot; 102,        // 100m转为为0.1内核，再用0.1 * 1024 = 102，当很多个容器运行在某台机器上发生CPU资源抢占时候用该值作为权重进行分配\n&quot;Memory&quot;: 1048576000,    // 对应K8s资源文件的limits-&gt;memory值：1000MB大小\n......\n&quot;CPUPeriod&quot;: 100000,    // docker 默认值, 单位是ns, 转化为毫秒是100\n&quot;CpuQuota&quot;: 20000,        // 0.2 core * 100000 = 20000, 与上面一起使用，表示100ms内最多分配给容器的cpu量是0.2个core</code></pre><p>当容器里进程所用内存超过requests值时, 占用资源最多的进程会被kill掉, 但是容器不会退出重启.<br>而CPU超出limits值时进程不会退出，因为CPU是可压缩资源，而内存不是.</p>\n<pre><code>$ docker stats ContainerID            // 查看container CPU和内存使用情况</code></pre><p>进入容器通过以下command命令模拟多个后台进程占用CPU</p>\n<pre><code>$ dd if=/dev/zero of=/dev/null &amp;    //\n$ killall dd                        // 删除所有dd命令</code></pre><p>一般情况都是设置requests == limits</p>\n<h3 id=\"LimitRange\"><a href=\"#LimitRange\" class=\"headerlink\" title=\"LimitRange\"></a>LimitRange</h3><p>在一个namespace下对Pod和container申请的CPU和memory资源进行限制</p>\n<pre><code>apiVersion: v1\nkind: LimitRange\nmetadata:\n  name: test-limits\nspec: \n  limits:\n  - max:\n      cpu: 4000m\n      memory: 2Gi\n    min:\n      cpu: 100m\n      memory: 100Mi\n    maxLimitRequestRatio:\n      cpu: 3                // 对POD显示，运行起来后占用机器cpu资源数是在limits.cpu最大以内且不能超过requests.cpu的3倍.\n      memory: 2\n    type: Pod                // 上面限制类型为Pod\n  - default:\n      cpu: 300m                // 默认Container 0.3个内核\n      memory: 200Mi\n    defaultRequest:\n      cpu: 200m\n      memory: 100Mi\n    max:\n      cpu: 2000m\n      memory: 1Gi\n    min:\n      cpu: 100m\n      memory: 100Mi\n    maxLimitRequestRatio:\n      cpu: 5\n      memory: 4\n    type: Container            // 上面显示类型为Container</code></pre><p>运行如下命令查看limits限制</p>\n<pre><code>$ kubectl describe limits -n namespaces</code></pre><blockquote>\n<p>当新建deployment或RS或Pod时，会根据LimitRange限制检测新建的Pod或Container是否满足条件，否则创建失败, 可以通过kubectl get ** -o yaml查看事件message.</p>\n</blockquote>\n<h3 id=\"ResourceQuota\"><a href=\"#ResourceQuota\" class=\"headerlink\" title=\"ResourceQuota\"></a>ResourceQuota</h3><p>对每个namespace能够使用的资源进行限制.</p>\n<pre><code>apiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: resource-quota\nspec:\n  hard:\n    pods: 4\n    requests.cpu: 2000m\n    requests.memory: 4Gi\n    limits.cpu: 4000m\n    limits.memory: 8Gi\n    configmaps: 10\n    persistentvolumeclaims: 4\n    replicationcontrollers: 20\n    secrets: 10\n    services: 10</code></pre><p>查看quota类型资源</p>\n<pre><code>$ kubectl get quota -n NS\n$ kubectl describe quota *** -n NS        // 查看硬件资源是否使用饱和</code></pre><h3 id=\"Eviction-Pod驱逐\"><a href=\"#Eviction-Pod驱逐\" class=\"headerlink\" title=\"Eviction-Pod驱逐\"></a>Eviction-Pod驱逐</h3><p>常见驱逐策略配置</p>\n<ul>\n<li>在1m30s时间内可利用内存持续小于1.5GB时进行驱逐</li>\n</ul>\n<pre><code>--eviction-soft=memory.available&lt;1.5Gi\n--eviction-soft-grace-period=memory.available=1m30s</code></pre><ul>\n<li>当可利用内存小于100MB或磁盘小于1GB或剩余的节点小于5%立即执行驱逐策略</li>\n</ul>\n<pre><code>--eviction-hard=memory.available&lt;100Mi,nodefs.available&lt;1Gi,nodefs.inodesFree&lt;5%</code></pre><p>驱逐策略:<br>磁盘紧缺时候:</p>\n<ul>\n<li>删除死掉的Pod和容器</li>\n<li>删除没用的image</li>\n<li>按优先级和资源占用情况驱逐Pod</li>\n</ul>\n<p>内存紧缺时候:</p>\n<ul>\n<li>驱逐不可靠的Pod(没有设置requests和limits资源的pod都是不可靠的Pod)</li>\n<li>驱逐基本可靠的pod(实际使用资源大于requests资源是基本可靠,超出的越多优先删除，否则删除占用内存最多的Pod)</li>\n<li>驱逐可靠的Pod(requests资源==limits资源的Pod为可靠的Pod, 如果都一样驱逐策略跟上面驱逐基本可靠Pod一致)</li>\n</ul>\n<h3 id=\"label\"><a href=\"#label\" class=\"headerlink\" title=\"label\"></a>label</h3><p>key=value 贴标签(Node, Deployment, Service, Pod)</p>\n<pre><code>#deploy\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-demo\n  namespace: dev\nspec:\n  selector:\n    matchLabels:                // 选择含有指定标签的Pod,必须跟下面一致，或者不写只配置下面Pod的label也可以\n      app: web-demo\n    matchExpressions:\n      - {key: group, operator: In, values: [dev, test]}        // Key in values的Pod都会被选中\n  replicas: 1\n  template:                        // 设置Pod模板\n    metadata:\n      labels:                    // 设置Pod标签\n        app: web-demo\n        group: dev\n    spec:\n      containers:\n      - name: web-demo\n        image: hub**\n        ports:\n        - containerPort: 8080\n      nodeSelector:                // 选择含有某个标签的Node机器部署Pod\n        disktype: ssd\n---\n# service\napiVersion: v1\nkind: Service\nmetadata:\n  name: web-demo\n  namespace: dev\nspec:\n  ports:\n  - port: 80\n    protocol: TCP\n    targetPort: 8080\n  selector:\n    app: web-demo\n  type: ClusterIP</code></pre><p>查询Pod</p>\n<pre><code>$ kubectl get pods -l &quot;group in (dev, test)&quot; -n NS\n$ kubectl get pods -l &quot;group notin (dev)&quot; -n NS\n$ kubectl get pods  -l group=dev,group=test -n NS</code></pre>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Resources\"><a href=\"#Resources\" class=\"headerlink\" title=\"Resources\"></a>Resources</h2><p>查看某台机器的资源</p>\n<pre><code>$ kubectl describe node hci-node01</code></pre><h3 id=\"memory-CPU\"><a href=\"#memory-CPU\" class=\"headerlink\" title=\"memory, CPU\"></a>memory, CPU</h3><p>requests, limits关键字.<br>当没有哪个Node节点满足requests的资源时候，container会一直处于pending状态, 而不会受limits资源影响.<br>如Node只有10GB内存，一个container request memory配置7GB内存大小，那么其余container只能分配剩余的3GB内存大小.<br>配置K8s的container文件</p>\n<pre><code>apiVersion: v1\n......\nspec:\n  containers:\n  - name: web-demo\n    image: hub.**\n    ports:\n    - containerPort: 8080\n    resources:\n      requests:\n        memory: 100Mi        // Ki: KB大小, Mi: MB大小, Gi: GB大小\n        cpu: 100m            // 如机器有12个内核, 而1个cpu内核=1000m, 100m为0.1个cpu内核, milli core, 千分之一core\n      limits:\n        memory: 1000Mi\n        cpu: 200m</code></pre><p>登陆container运行的机器，查看容器设置参数</p>\n<pre><code>$ docker inspect containerID\n......\n&quot;CpuShares&quot; 102,        // 100m转为为0.1内核，再用0.1 * 1024 = 102，当很多个容器运行在某台机器上发生CPU资源抢占时候用该值作为权重进行分配\n&quot;Memory&quot;: 1048576000,    // 对应K8s资源文件的limits-&gt;memory值：1000MB大小\n......\n&quot;CPUPeriod&quot;: 100000,    // docker 默认值, 单位是ns, 转化为毫秒是100\n&quot;CpuQuota&quot;: 20000,        // 0.2 core * 100000 = 20000, 与上面一起使用，表示100ms内最多分配给容器的cpu量是0.2个core</code></pre><p>当容器里进程所用内存超过requests值时, 占用资源最多的进程会被kill掉, 但是容器不会退出重启.<br>而CPU超出limits值时进程不会退出，因为CPU是可压缩资源，而内存不是.</p>\n<pre><code>$ docker stats ContainerID            // 查看container CPU和内存使用情况</code></pre><p>进入容器通过以下command命令模拟多个后台进程占用CPU</p>\n<pre><code>$ dd if=/dev/zero of=/dev/null &amp;    //\n$ killall dd                        // 删除所有dd命令</code></pre><p>一般情况都是设置requests == limits</p>\n<h3 id=\"LimitRange\"><a href=\"#LimitRange\" class=\"headerlink\" title=\"LimitRange\"></a>LimitRange</h3><p>在一个namespace下对Pod和container申请的CPU和memory资源进行限制</p>\n<pre><code>apiVersion: v1\nkind: LimitRange\nmetadata:\n  name: test-limits\nspec: \n  limits:\n  - max:\n      cpu: 4000m\n      memory: 2Gi\n    min:\n      cpu: 100m\n      memory: 100Mi\n    maxLimitRequestRatio:\n      cpu: 3                // 对POD显示，运行起来后占用机器cpu资源数是在limits.cpu最大以内且不能超过requests.cpu的3倍.\n      memory: 2\n    type: Pod                // 上面限制类型为Pod\n  - default:\n      cpu: 300m                // 默认Container 0.3个内核\n      memory: 200Mi\n    defaultRequest:\n      cpu: 200m\n      memory: 100Mi\n    max:\n      cpu: 2000m\n      memory: 1Gi\n    min:\n      cpu: 100m\n      memory: 100Mi\n    maxLimitRequestRatio:\n      cpu: 5\n      memory: 4\n    type: Container            // 上面显示类型为Container</code></pre><p>运行如下命令查看limits限制</p>\n<pre><code>$ kubectl describe limits -n namespaces</code></pre><blockquote>\n<p>当新建deployment或RS或Pod时，会根据LimitRange限制检测新建的Pod或Container是否满足条件，否则创建失败, 可以通过kubectl get ** -o yaml查看事件message.</p>\n</blockquote>\n<h3 id=\"ResourceQuota\"><a href=\"#ResourceQuota\" class=\"headerlink\" title=\"ResourceQuota\"></a>ResourceQuota</h3><p>对每个namespace能够使用的资源进行限制.</p>\n<pre><code>apiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: resource-quota\nspec:\n  hard:\n    pods: 4\n    requests.cpu: 2000m\n    requests.memory: 4Gi\n    limits.cpu: 4000m\n    limits.memory: 8Gi\n    configmaps: 10\n    persistentvolumeclaims: 4\n    replicationcontrollers: 20\n    secrets: 10\n    services: 10</code></pre><p>查看quota类型资源</p>\n<pre><code>$ kubectl get quota -n NS\n$ kubectl describe quota *** -n NS        // 查看硬件资源是否使用饱和</code></pre><h3 id=\"Eviction-Pod驱逐\"><a href=\"#Eviction-Pod驱逐\" class=\"headerlink\" title=\"Eviction-Pod驱逐\"></a>Eviction-Pod驱逐</h3><p>常见驱逐策略配置</p>\n<ul>\n<li>在1m30s时间内可利用内存持续小于1.5GB时进行驱逐</li>\n</ul>\n<pre><code>--eviction-soft=memory.available&lt;1.5Gi\n--eviction-soft-grace-period=memory.available=1m30s</code></pre><ul>\n<li>当可利用内存小于100MB或磁盘小于1GB或剩余的节点小于5%立即执行驱逐策略</li>\n</ul>\n<pre><code>--eviction-hard=memory.available&lt;100Mi,nodefs.available&lt;1Gi,nodefs.inodesFree&lt;5%</code></pre><p>驱逐策略:<br>磁盘紧缺时候:</p>\n<ul>\n<li>删除死掉的Pod和容器</li>\n<li>删除没用的image</li>\n<li>按优先级和资源占用情况驱逐Pod</li>\n</ul>\n<p>内存紧缺时候:</p>\n<ul>\n<li>驱逐不可靠的Pod(没有设置requests和limits资源的pod都是不可靠的Pod)</li>\n<li>驱逐基本可靠的pod(实际使用资源大于requests资源是基本可靠,超出的越多优先删除，否则删除占用内存最多的Pod)</li>\n<li>驱逐可靠的Pod(requests资源==limits资源的Pod为可靠的Pod, 如果都一样驱逐策略跟上面驱逐基本可靠Pod一致)</li>\n</ul>\n<h3 id=\"label\"><a href=\"#label\" class=\"headerlink\" title=\"label\"></a>label</h3><p>key=value 贴标签(Node, Deployment, Service, Pod)</p>\n<pre><code>#deploy\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-demo\n  namespace: dev\nspec:\n  selector:\n    matchLabels:                // 选择含有指定标签的Pod,必须跟下面一致，或者不写只配置下面Pod的label也可以\n      app: web-demo\n    matchExpressions:\n      - {key: group, operator: In, values: [dev, test]}        // Key in values的Pod都会被选中\n  replicas: 1\n  template:                        // 设置Pod模板\n    metadata:\n      labels:                    // 设置Pod标签\n        app: web-demo\n        group: dev\n    spec:\n      containers:\n      - name: web-demo\n        image: hub**\n        ports:\n        - containerPort: 8080\n      nodeSelector:                // 选择含有某个标签的Node机器部署Pod\n        disktype: ssd\n---\n# service\napiVersion: v1\nkind: Service\nmetadata:\n  name: web-demo\n  namespace: dev\nspec:\n  ports:\n  - port: 80\n    protocol: TCP\n    targetPort: 8080\n  selector:\n    app: web-demo\n  type: ClusterIP</code></pre><p>查询Pod</p>\n<pre><code>$ kubectl get pods -l &quot;group in (dev, test)&quot; -n NS\n$ kubectl get pods -l &quot;group notin (dev)&quot; -n NS\n$ kubectl get pods  -l group=dev,group=test -n NS</code></pre>"},{"title":"Istio 01 conception","_content":"\n## Istio架构组件简介\n> 官网: https://istio.io/\n> 官网中文: https://istio.io/zh/\n> Github: https://github.com/istio/istio\n> 中文社区: https://istio.cn/\n\n### 简介\n> Istio 是一个由谷歌、IBM 与 Lyft 共同开发的开源项目，旨在提供一种统一化的微服务连接、安全保障、管理与监控方式。具体来说，Istio 是一个开源服务网格平台，它确保微服务在处理故障时以指定的方式相互连接。\n\n### 架构\n> Istio 服务网格逻辑上分为数据平面和控制平面。\n> * 数据平面由一组以 sidecar 方式部署的智能代理（Envoy）组成。这些代理可以调节和控制微服务及 Mixer 之间所有的网络通信。\n> * 控制平面负责管理和配置代理来路由流量。此外控制平面配置 Mixer 以实施策略和收集遥测数据。\n![](istio_arch.jpeg)\n\n### Envoy\n![](envoy_xds.png)\n\n\tListeners: 设置监听IP:Port, 到达sidecar的请求都会到这里来.\n\tRoutes: 根据route, 如: - match: {prefix:”/”} route: {cluster: service_envoy}选择 Cluster.\n\tClusters: 找到相应的Cluster name: service_envoy, 定义了一些轮询规则等.\n\tEndpoints: 指定路由转发到哪里, IP:Port\nEnvoy是经过CNCF(Cloud Native Computing Foundation,云原生计算基金会(是一个开源软件基金会，它致力于云原生（Cloud Native）技术的普及和可持续发展。)非常成功毕业的sidecar软件.\n从CNCF毕业的软件还有Prometheus, Kubernetes.\n\n> Istio 使用 Envoy 代理的扩展版本，Envoy 是以 C++ 开发的高性能代理，用于调解服务网格中所有服务的所有入站和出站流量。Envoy 的许多内置功能被 istio 发扬光大，例如：\n> Envoy 被部署为 sidecar，和对应服务在同一个 Kubernetes pod 中。这允许 Istio 将大量关于流量行为的信号作为属性提取出来，而这些属性又可以在 Mixer 中用于执行策略决策，并发送给监控系统，以提供整个网格行为的信息。\n> Sidecar 代理模型还可以将 Istio 的功能添加到现有部署中，而无需重新构建或重写代码。可以阅读更多来了解为什么我们在设计目标中选择这种方式。\n> * 动态服务发现\n> * 负载均衡\n> * TLS 终止\n> * HTTP/2 & gRPC 代理\n> * 熔断器\n> * 健康检查、基于百分比流量拆分的灰度发布\n> * 故障注入\n> * 丰富的度量指标\n\n### Mixer\n> Mixer 是一个独立于平台的组件，负责在服务网格上执行访问控制和使用策略，并从 Envoy 代理和其他服务收集遥测数据。代理提取请求级属性，发送到 Mixer 进行评估。有关属性提取和策略评估的更多信息，请参见 Mixer 配置。\n> Mixer 中包括一个灵活的插件模型，使其能够接入到各种主机环境和基础设施后端，从这些细节中抽象出 Envoy 代理和 Istio 管理的服务。\n\n### Pilot\n> 控制面中负责流量管理的组件为Pilot\n\n### 流量管理\nIstio 维护了一个内部服务注册表 (service registry)，它包含在服务网格中运行的一组服务及其相应的服务 endpoints。Istio 使用服务注册表生成 Envoy 配置。\nIstio 不提供服务发现，尽管大多数服务都是通过 Pilot adapter 自动加入到服务注册表里的，而且这反映了底层平台（Kubernetes、Consul、plain DNS）的已发现的服务。还有就是，可以使用 ServiceEntry 配置手动进行注册。\n\n\n### Envoy\n> Istio 选择了开源的Envoy作为它的网络代理，envoy是2016年用c++的高性能的代理组件，用于管理所有服务的入口和出口流量.\n> envoy内置了很多功能，像服务发现，负载均衡，多种协议的支持，断路器，流量分割，健康检查，模拟一些故障，还有监控指标等等.\n> envoy会以sidecar的形式部署在每一个POD中负责完成Istio的核心功能，如果把Istio比作公司，envoy就是这个公司的一些员工，所有的具体工作都是由envoy干的\n\n### Pilot\n![](Pilot_Architecture.png)\n> 控制面中负责流量管理的组件为Pilot\n> Pilot 和 Envoy组件有了Istio就可以运转起来了，其它组件可以不需要.\n> Pilot 好比是envoy的直接领导，顶头上司，告诉并协助envoy怎样工作，因为envoy跑在一个容器里的.\n * Pilot告诉envoy集群都有哪些服务，envoy就可以做服务发现了.\n * Pilot根据用户配置的流量管理和服务信息转换成envoy能够识别的格式，然后分发给envoy，告诉envoy哪些POD需要多少流量，envoy就能做A/B测试，蓝绿部署.\n * Pilot告诉envoy多长时间算超时，应该重试几次.\n> Pilot 为 Envoy sidecar 提供服务发现功能，为智能路由（例如 A/B 测试、金丝雀部署等）和弹性（超时、重试、熔断器等）提供流量管理功能。它将控制流量行为的高级路由规则转换为特定于 Envoy 的配置，并在运行时将它们传播到 sidecar。\n> Pilot 将平台特定的服务发现机制抽象化并将其合成为符合 Envoy 数据平面 API 的任何 sidecar 都可以使用的标准格式。这种松散耦合使得 Istio 能够在多种环境下运行（例如，Kubernetes、Consul、Nomad），同时保持用于流量管理的相同操作界面。\n * Platform Adapter: 平台适配器。针对多种集群管理平台实现的控制器，得到API server的DNS服务注册信息（即service名与podIP的对应表）、入口资源以及存储流量管理规则的第三方资源\n * Abstract Model：维护了envoy中对service的规范表示。接收上层获取的service信息转化为规范模型\n * Envoy API：下发服务发现、流量规则到envoy上\n * Rules API：由运维人员管理。可通过API配置高级管理规则\n\n\n\n### Mixer (独立组件)\n两大功能: 策略，遥测\n> 策略: 为整个集群执行访问控制, 哪些用户可以访问哪些服务，还有一些策略的管理，像对一些服务的访问速度的限制等，比如服务A最多接受100QPS，超过的就会被直接扔掉\n> 遥测: 数据的收集和汇报，从envoy(proxy)收集数据，收集的是服务之间流转的数据, 收集的数据会汇报给其它对象，每个汇报的对象都有Adapter(适配器)转换汇报的数据为自己认识的格式，如Prometheus.\n可以不用Mixer也可以把Istio跑起来\n\n### Galley\n> 最初负责验证配置，Istio1.1之后升级为Istio整个平面的配置管理中心，校验各种配置是否正确\n\n### Citadel\n> 安全相关的，为用户到服务，服务到服务之间提供安全的通信，可以让http服务无感知的升级成为https服务，还有服务的访问授权等.\n\n\n## Istio 解决的问题\n> * 原来的单个应用拆分成多个微服务, 它们之间相互调用才能完成微服务，组件(服务模块)越多，出错概率越大，就会非常难以排查.\n> * 用户请求出现问题: 1.错误， 2.慢响应\n>  - 请求错误，得知道哪个步骤出错了，微服务之间哪些能调用成功哪些失败.\n>  - 请求响应太慢, 各个链路调用，耗时是多少，哪些并发执行哪些串行.\n> * 设置timeout\n> * 设置重试机制\n> * 某些节点异常(如load高)\n\n\n\n\n### A/B测试\n * A/B测试的基本思想是什么?\n> A/B测试的基本思想包括：提供两个方案并行测试。不同方案之间只存在一个变量，排除其他干扰因素。以某种标准判定结果优劣，筛出最优方案。其中第二点，即单变量，需要重点关注。因为某种方案的优劣，不光与方案本身有关，也可能与方案所适配的环境密不可分。\n> 所谓A/B测试，简单说来就是针对想调研的问题提供两种不同的备选解决方案（比如两个下单页面），然后让一部分用户使用方案A，另一部分用户使用方案B像LinkedIn的升级迭代一样，最终通过数据观察对比确定最优方案。\n\n * A/B测试案例\n> 在互联网产品开发过程中，我们经常面临多种方案的抉择。有些选择轻而易举，例如面向大众的偏理性产品，主色调定位蓝色最权威稳重而广为接受（比如百度、Facebook）；强调安全的服务，绿色是常规之选。但有些时候，备选方案模棱两可，甚至区别看起来无关紧要，例如某个按钮是用橙色还是红色，摆放的位置偏左还是偏右。面对这种情况，传统解决方式要么是根据设计师的审美来定，要么是一群人共同表决，要么由某个领导拍板决定。无论哪种方式，都不免受到个人主观因素的制约，未必代表的了广大用户在实际使用场景中的认知。“不识庐山真面目，只缘身在此山中。”通常解决此类情况，最合理的办法之一，就是进行A/B测试（A/B Testing）。所谓A/B测试，简单说来就是针对想调研的问题提供两种不同的备选解决方案（比如两个下单页面），然后让一部分用户使用方案A，另一部分用户使用方案B，最终通过数据观察对比确定最优方案。在现实生活中，达尔文《物种起源》中提到的物竞天择原理，本质上就是在谈同一物种的不同变体经过外部环境测试后存留延续下的最优结果，也算是一种A/B测试。\n\n * 团队使用A/B测试有什么好处？\n> 在数据面前任何妄加揣测的评断都可能是不准确的。通过A/B测试，产品团队能够获悉哪些对激发用户活跃度有所帮助，哪些又徒劳无功（有时候后者显得更为重要，因为它能终结一场无意义的争吵，或是缩减许多不必要的消耗）。一次测试或许能带来良好的改善效果，但也绝非意味着提升空间已然消失。微软公司的测试经验表明，在他们做的所有测试中，有三分之一被验证为成功有效，剩下的三分之二平平无奇或压根就是失败的。谷歌在2009年做了12000多次测试，但其中只有10％带来了业务变化。产品不息，测试不止。永远不要满足于当下的结果，因为世界上总有更好的解决方案\n\n\n\n\n","source":"_posts/micro_service/istio_01_conception.md","raw":"---\ntitle: Istio 01 conception\ntags: istio\ncategories:\n- microService\n- istio\n---\n\n## Istio架构组件简介\n> 官网: https://istio.io/\n> 官网中文: https://istio.io/zh/\n> Github: https://github.com/istio/istio\n> 中文社区: https://istio.cn/\n\n### 简介\n> Istio 是一个由谷歌、IBM 与 Lyft 共同开发的开源项目，旨在提供一种统一化的微服务连接、安全保障、管理与监控方式。具体来说，Istio 是一个开源服务网格平台，它确保微服务在处理故障时以指定的方式相互连接。\n\n### 架构\n> Istio 服务网格逻辑上分为数据平面和控制平面。\n> * 数据平面由一组以 sidecar 方式部署的智能代理（Envoy）组成。这些代理可以调节和控制微服务及 Mixer 之间所有的网络通信。\n> * 控制平面负责管理和配置代理来路由流量。此外控制平面配置 Mixer 以实施策略和收集遥测数据。\n![](istio_arch.jpeg)\n\n### Envoy\n![](envoy_xds.png)\n\n\tListeners: 设置监听IP:Port, 到达sidecar的请求都会到这里来.\n\tRoutes: 根据route, 如: - match: {prefix:”/”} route: {cluster: service_envoy}选择 Cluster.\n\tClusters: 找到相应的Cluster name: service_envoy, 定义了一些轮询规则等.\n\tEndpoints: 指定路由转发到哪里, IP:Port\nEnvoy是经过CNCF(Cloud Native Computing Foundation,云原生计算基金会(是一个开源软件基金会，它致力于云原生（Cloud Native）技术的普及和可持续发展。)非常成功毕业的sidecar软件.\n从CNCF毕业的软件还有Prometheus, Kubernetes.\n\n> Istio 使用 Envoy 代理的扩展版本，Envoy 是以 C++ 开发的高性能代理，用于调解服务网格中所有服务的所有入站和出站流量。Envoy 的许多内置功能被 istio 发扬光大，例如：\n> Envoy 被部署为 sidecar，和对应服务在同一个 Kubernetes pod 中。这允许 Istio 将大量关于流量行为的信号作为属性提取出来，而这些属性又可以在 Mixer 中用于执行策略决策，并发送给监控系统，以提供整个网格行为的信息。\n> Sidecar 代理模型还可以将 Istio 的功能添加到现有部署中，而无需重新构建或重写代码。可以阅读更多来了解为什么我们在设计目标中选择这种方式。\n> * 动态服务发现\n> * 负载均衡\n> * TLS 终止\n> * HTTP/2 & gRPC 代理\n> * 熔断器\n> * 健康检查、基于百分比流量拆分的灰度发布\n> * 故障注入\n> * 丰富的度量指标\n\n### Mixer\n> Mixer 是一个独立于平台的组件，负责在服务网格上执行访问控制和使用策略，并从 Envoy 代理和其他服务收集遥测数据。代理提取请求级属性，发送到 Mixer 进行评估。有关属性提取和策略评估的更多信息，请参见 Mixer 配置。\n> Mixer 中包括一个灵活的插件模型，使其能够接入到各种主机环境和基础设施后端，从这些细节中抽象出 Envoy 代理和 Istio 管理的服务。\n\n### Pilot\n> 控制面中负责流量管理的组件为Pilot\n\n### 流量管理\nIstio 维护了一个内部服务注册表 (service registry)，它包含在服务网格中运行的一组服务及其相应的服务 endpoints。Istio 使用服务注册表生成 Envoy 配置。\nIstio 不提供服务发现，尽管大多数服务都是通过 Pilot adapter 自动加入到服务注册表里的，而且这反映了底层平台（Kubernetes、Consul、plain DNS）的已发现的服务。还有就是，可以使用 ServiceEntry 配置手动进行注册。\n\n\n### Envoy\n> Istio 选择了开源的Envoy作为它的网络代理，envoy是2016年用c++的高性能的代理组件，用于管理所有服务的入口和出口流量.\n> envoy内置了很多功能，像服务发现，负载均衡，多种协议的支持，断路器，流量分割，健康检查，模拟一些故障，还有监控指标等等.\n> envoy会以sidecar的形式部署在每一个POD中负责完成Istio的核心功能，如果把Istio比作公司，envoy就是这个公司的一些员工，所有的具体工作都是由envoy干的\n\n### Pilot\n![](Pilot_Architecture.png)\n> 控制面中负责流量管理的组件为Pilot\n> Pilot 和 Envoy组件有了Istio就可以运转起来了，其它组件可以不需要.\n> Pilot 好比是envoy的直接领导，顶头上司，告诉并协助envoy怎样工作，因为envoy跑在一个容器里的.\n * Pilot告诉envoy集群都有哪些服务，envoy就可以做服务发现了.\n * Pilot根据用户配置的流量管理和服务信息转换成envoy能够识别的格式，然后分发给envoy，告诉envoy哪些POD需要多少流量，envoy就能做A/B测试，蓝绿部署.\n * Pilot告诉envoy多长时间算超时，应该重试几次.\n> Pilot 为 Envoy sidecar 提供服务发现功能，为智能路由（例如 A/B 测试、金丝雀部署等）和弹性（超时、重试、熔断器等）提供流量管理功能。它将控制流量行为的高级路由规则转换为特定于 Envoy 的配置，并在运行时将它们传播到 sidecar。\n> Pilot 将平台特定的服务发现机制抽象化并将其合成为符合 Envoy 数据平面 API 的任何 sidecar 都可以使用的标准格式。这种松散耦合使得 Istio 能够在多种环境下运行（例如，Kubernetes、Consul、Nomad），同时保持用于流量管理的相同操作界面。\n * Platform Adapter: 平台适配器。针对多种集群管理平台实现的控制器，得到API server的DNS服务注册信息（即service名与podIP的对应表）、入口资源以及存储流量管理规则的第三方资源\n * Abstract Model：维护了envoy中对service的规范表示。接收上层获取的service信息转化为规范模型\n * Envoy API：下发服务发现、流量规则到envoy上\n * Rules API：由运维人员管理。可通过API配置高级管理规则\n\n\n\n### Mixer (独立组件)\n两大功能: 策略，遥测\n> 策略: 为整个集群执行访问控制, 哪些用户可以访问哪些服务，还有一些策略的管理，像对一些服务的访问速度的限制等，比如服务A最多接受100QPS，超过的就会被直接扔掉\n> 遥测: 数据的收集和汇报，从envoy(proxy)收集数据，收集的是服务之间流转的数据, 收集的数据会汇报给其它对象，每个汇报的对象都有Adapter(适配器)转换汇报的数据为自己认识的格式，如Prometheus.\n可以不用Mixer也可以把Istio跑起来\n\n### Galley\n> 最初负责验证配置，Istio1.1之后升级为Istio整个平面的配置管理中心，校验各种配置是否正确\n\n### Citadel\n> 安全相关的，为用户到服务，服务到服务之间提供安全的通信，可以让http服务无感知的升级成为https服务，还有服务的访问授权等.\n\n\n## Istio 解决的问题\n> * 原来的单个应用拆分成多个微服务, 它们之间相互调用才能完成微服务，组件(服务模块)越多，出错概率越大，就会非常难以排查.\n> * 用户请求出现问题: 1.错误， 2.慢响应\n>  - 请求错误，得知道哪个步骤出错了，微服务之间哪些能调用成功哪些失败.\n>  - 请求响应太慢, 各个链路调用，耗时是多少，哪些并发执行哪些串行.\n> * 设置timeout\n> * 设置重试机制\n> * 某些节点异常(如load高)\n\n\n\n\n### A/B测试\n * A/B测试的基本思想是什么?\n> A/B测试的基本思想包括：提供两个方案并行测试。不同方案之间只存在一个变量，排除其他干扰因素。以某种标准判定结果优劣，筛出最优方案。其中第二点，即单变量，需要重点关注。因为某种方案的优劣，不光与方案本身有关，也可能与方案所适配的环境密不可分。\n> 所谓A/B测试，简单说来就是针对想调研的问题提供两种不同的备选解决方案（比如两个下单页面），然后让一部分用户使用方案A，另一部分用户使用方案B像LinkedIn的升级迭代一样，最终通过数据观察对比确定最优方案。\n\n * A/B测试案例\n> 在互联网产品开发过程中，我们经常面临多种方案的抉择。有些选择轻而易举，例如面向大众的偏理性产品，主色调定位蓝色最权威稳重而广为接受（比如百度、Facebook）；强调安全的服务，绿色是常规之选。但有些时候，备选方案模棱两可，甚至区别看起来无关紧要，例如某个按钮是用橙色还是红色，摆放的位置偏左还是偏右。面对这种情况，传统解决方式要么是根据设计师的审美来定，要么是一群人共同表决，要么由某个领导拍板决定。无论哪种方式，都不免受到个人主观因素的制约，未必代表的了广大用户在实际使用场景中的认知。“不识庐山真面目，只缘身在此山中。”通常解决此类情况，最合理的办法之一，就是进行A/B测试（A/B Testing）。所谓A/B测试，简单说来就是针对想调研的问题提供两种不同的备选解决方案（比如两个下单页面），然后让一部分用户使用方案A，另一部分用户使用方案B，最终通过数据观察对比确定最优方案。在现实生活中，达尔文《物种起源》中提到的物竞天择原理，本质上就是在谈同一物种的不同变体经过外部环境测试后存留延续下的最优结果，也算是一种A/B测试。\n\n * 团队使用A/B测试有什么好处？\n> 在数据面前任何妄加揣测的评断都可能是不准确的。通过A/B测试，产品团队能够获悉哪些对激发用户活跃度有所帮助，哪些又徒劳无功（有时候后者显得更为重要，因为它能终结一场无意义的争吵，或是缩减许多不必要的消耗）。一次测试或许能带来良好的改善效果，但也绝非意味着提升空间已然消失。微软公司的测试经验表明，在他们做的所有测试中，有三分之一被验证为成功有效，剩下的三分之二平平无奇或压根就是失败的。谷歌在2009年做了12000多次测试，但其中只有10％带来了业务变化。产品不息，测试不止。永远不要满足于当下的结果，因为世界上总有更好的解决方案\n\n\n\n\n","slug":"micro_service/istio_01_conception","published":1,"date":"2020-08-12T16:05:47.496Z","updated":"2020-08-10T16:37:16.328Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmgh0052hohxg0rtci2f","content":"<h2 id=\"Istio架构组件简介\"><a href=\"#Istio架构组件简介\" class=\"headerlink\" title=\"Istio架构组件简介\"></a>Istio架构组件简介</h2><blockquote>\n<p>官网: <a href=\"https://istio.io/\" target=\"_blank\" rel=\"noopener\">https://istio.io/</a><br>官网中文: <a href=\"https://istio.io/zh/\" target=\"_blank\" rel=\"noopener\">https://istio.io/zh/</a><br>Github: <a href=\"https://github.com/istio/istio\" target=\"_blank\" rel=\"noopener\">https://github.com/istio/istio</a><br>中文社区: <a href=\"https://istio.cn/\" target=\"_blank\" rel=\"noopener\">https://istio.cn/</a></p>\n</blockquote>\n<h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><blockquote>\n<p>Istio 是一个由谷歌、IBM 与 Lyft 共同开发的开源项目，旨在提供一种统一化的微服务连接、安全保障、管理与监控方式。具体来说，Istio 是一个开源服务网格平台，它确保微服务在处理故障时以指定的方式相互连接。</p>\n</blockquote>\n<h3 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h3><blockquote>\n<p>Istio 服务网格逻辑上分为数据平面和控制平面。</p>\n<ul>\n<li>数据平面由一组以 sidecar 方式部署的智能代理（Envoy）组成。这些代理可以调节和控制微服务及 Mixer 之间所有的网络通信。</li>\n<li>控制平面负责管理和配置代理来路由流量。此外控制平面配置 Mixer 以实施策略和收集遥测数据。<br><img src=\"istio_arch.jpeg\" alt=\"\"></li>\n</ul>\n</blockquote>\n<h3 id=\"Envoy\"><a href=\"#Envoy\" class=\"headerlink\" title=\"Envoy\"></a>Envoy</h3><p><img src=\"envoy_xds.png\" alt=\"\"></p>\n<pre><code>Listeners: 设置监听IP:Port, 到达sidecar的请求都会到这里来.\nRoutes: 根据route, 如: - match: {prefix:”/”} route: {cluster: service_envoy}选择 Cluster.\nClusters: 找到相应的Cluster name: service_envoy, 定义了一些轮询规则等.\nEndpoints: 指定路由转发到哪里, IP:Port</code></pre><p>Envoy是经过CNCF(Cloud Native Computing Foundation,云原生计算基金会(是一个开源软件基金会，它致力于云原生（Cloud Native）技术的普及和可持续发展。)非常成功毕业的sidecar软件.<br>从CNCF毕业的软件还有Prometheus, Kubernetes.</p>\n<blockquote>\n<p>Istio 使用 Envoy 代理的扩展版本，Envoy 是以 C++ 开发的高性能代理，用于调解服务网格中所有服务的所有入站和出站流量。Envoy 的许多内置功能被 istio 发扬光大，例如：<br>Envoy 被部署为 sidecar，和对应服务在同一个 Kubernetes pod 中。这允许 Istio 将大量关于流量行为的信号作为属性提取出来，而这些属性又可以在 Mixer 中用于执行策略决策，并发送给监控系统，以提供整个网格行为的信息。<br>Sidecar 代理模型还可以将 Istio 的功能添加到现有部署中，而无需重新构建或重写代码。可以阅读更多来了解为什么我们在设计目标中选择这种方式。</p>\n<ul>\n<li>动态服务发现</li>\n<li>负载均衡</li>\n<li>TLS 终止</li>\n<li>HTTP/2 &amp; gRPC 代理</li>\n<li>熔断器</li>\n<li>健康检查、基于百分比流量拆分的灰度发布</li>\n<li>故障注入</li>\n<li>丰富的度量指标</li>\n</ul>\n</blockquote>\n<h3 id=\"Mixer\"><a href=\"#Mixer\" class=\"headerlink\" title=\"Mixer\"></a>Mixer</h3><blockquote>\n<p>Mixer 是一个独立于平台的组件，负责在服务网格上执行访问控制和使用策略，并从 Envoy 代理和其他服务收集遥测数据。代理提取请求级属性，发送到 Mixer 进行评估。有关属性提取和策略评估的更多信息，请参见 Mixer 配置。<br>Mixer 中包括一个灵活的插件模型，使其能够接入到各种主机环境和基础设施后端，从这些细节中抽象出 Envoy 代理和 Istio 管理的服务。</p>\n</blockquote>\n<h3 id=\"Pilot\"><a href=\"#Pilot\" class=\"headerlink\" title=\"Pilot\"></a>Pilot</h3><blockquote>\n<p>控制面中负责流量管理的组件为Pilot</p>\n</blockquote>\n<h3 id=\"流量管理\"><a href=\"#流量管理\" class=\"headerlink\" title=\"流量管理\"></a>流量管理</h3><p>Istio 维护了一个内部服务注册表 (service registry)，它包含在服务网格中运行的一组服务及其相应的服务 endpoints。Istio 使用服务注册表生成 Envoy 配置。<br>Istio 不提供服务发现，尽管大多数服务都是通过 Pilot adapter 自动加入到服务注册表里的，而且这反映了底层平台（Kubernetes、Consul、plain DNS）的已发现的服务。还有就是，可以使用 ServiceEntry 配置手动进行注册。</p>\n<h3 id=\"Envoy-1\"><a href=\"#Envoy-1\" class=\"headerlink\" title=\"Envoy\"></a>Envoy</h3><blockquote>\n<p>Istio 选择了开源的Envoy作为它的网络代理，envoy是2016年用c++的高性能的代理组件，用于管理所有服务的入口和出口流量.<br>envoy内置了很多功能，像服务发现，负载均衡，多种协议的支持，断路器，流量分割，健康检查，模拟一些故障，还有监控指标等等.<br>envoy会以sidecar的形式部署在每一个POD中负责完成Istio的核心功能，如果把Istio比作公司，envoy就是这个公司的一些员工，所有的具体工作都是由envoy干的</p>\n</blockquote>\n<h3 id=\"Pilot-1\"><a href=\"#Pilot-1\" class=\"headerlink\" title=\"Pilot\"></a>Pilot</h3><p><img src=\"Pilot_Architecture.png\" alt=\"\"></p>\n<blockquote>\n<p>控制面中负责流量管理的组件为Pilot<br>Pilot 和 Envoy组件有了Istio就可以运转起来了，其它组件可以不需要.<br>Pilot 好比是envoy的直接领导，顶头上司，告诉并协助envoy怎样工作，因为envoy跑在一个容器里的.</p>\n</blockquote>\n<ul>\n<li>Pilot告诉envoy集群都有哪些服务，envoy就可以做服务发现了.</li>\n<li>Pilot根据用户配置的流量管理和服务信息转换成envoy能够识别的格式，然后分发给envoy，告诉envoy哪些POD需要多少流量，envoy就能做A/B测试，蓝绿部署.</li>\n<li>Pilot告诉envoy多长时间算超时，应该重试几次.<blockquote>\n<p>Pilot 为 Envoy sidecar 提供服务发现功能，为智能路由（例如 A/B 测试、金丝雀部署等）和弹性（超时、重试、熔断器等）提供流量管理功能。它将控制流量行为的高级路由规则转换为特定于 Envoy 的配置，并在运行时将它们传播到 sidecar。<br>Pilot 将平台特定的服务发现机制抽象化并将其合成为符合 Envoy 数据平面 API 的任何 sidecar 都可以使用的标准格式。这种松散耦合使得 Istio 能够在多种环境下运行（例如，Kubernetes、Consul、Nomad），同时保持用于流量管理的相同操作界面。</p>\n</blockquote>\n</li>\n<li>Platform Adapter: 平台适配器。针对多种集群管理平台实现的控制器，得到API server的DNS服务注册信息（即service名与podIP的对应表）、入口资源以及存储流量管理规则的第三方资源</li>\n<li>Abstract Model：维护了envoy中对service的规范表示。接收上层获取的service信息转化为规范模型</li>\n<li>Envoy API：下发服务发现、流量规则到envoy上</li>\n<li>Rules API：由运维人员管理。可通过API配置高级管理规则</li>\n</ul>\n<h3 id=\"Mixer-独立组件\"><a href=\"#Mixer-独立组件\" class=\"headerlink\" title=\"Mixer (独立组件)\"></a>Mixer (独立组件)</h3><p>两大功能: 策略，遥测</p>\n<blockquote>\n<p>策略: 为整个集群执行访问控制, 哪些用户可以访问哪些服务，还有一些策略的管理，像对一些服务的访问速度的限制等，比如服务A最多接受100QPS，超过的就会被直接扔掉<br>遥测: 数据的收集和汇报，从envoy(proxy)收集数据，收集的是服务之间流转的数据, 收集的数据会汇报给其它对象，每个汇报的对象都有Adapter(适配器)转换汇报的数据为自己认识的格式，如Prometheus.<br>可以不用Mixer也可以把Istio跑起来</p>\n</blockquote>\n<h3 id=\"Galley\"><a href=\"#Galley\" class=\"headerlink\" title=\"Galley\"></a>Galley</h3><blockquote>\n<p>最初负责验证配置，Istio1.1之后升级为Istio整个平面的配置管理中心，校验各种配置是否正确</p>\n</blockquote>\n<h3 id=\"Citadel\"><a href=\"#Citadel\" class=\"headerlink\" title=\"Citadel\"></a>Citadel</h3><blockquote>\n<p>安全相关的，为用户到服务，服务到服务之间提供安全的通信，可以让http服务无感知的升级成为https服务，还有服务的访问授权等.</p>\n</blockquote>\n<h2 id=\"Istio-解决的问题\"><a href=\"#Istio-解决的问题\" class=\"headerlink\" title=\"Istio 解决的问题\"></a>Istio 解决的问题</h2><blockquote>\n<ul>\n<li>原来的单个应用拆分成多个微服务, 它们之间相互调用才能完成微服务，组件(服务模块)越多，出错概率越大，就会非常难以排查.</li>\n<li>用户请求出现问题: 1.错误， 2.慢响应<ul>\n<li>请求错误，得知道哪个步骤出错了，微服务之间哪些能调用成功哪些失败.</li>\n<li>请求响应太慢, 各个链路调用，耗时是多少，哪些并发执行哪些串行.</li>\n</ul>\n</li>\n<li>设置timeout</li>\n<li>设置重试机制</li>\n<li>某些节点异常(如load高)</li>\n</ul>\n</blockquote>\n<h3 id=\"A-B测试\"><a href=\"#A-B测试\" class=\"headerlink\" title=\"A/B测试\"></a>A/B测试</h3><ul>\n<li><p>A/B测试的基本思想是什么?</p>\n<blockquote>\n<p>A/B测试的基本思想包括：提供两个方案并行测试。不同方案之间只存在一个变量，排除其他干扰因素。以某种标准判定结果优劣，筛出最优方案。其中第二点，即单变量，需要重点关注。因为某种方案的优劣，不光与方案本身有关，也可能与方案所适配的环境密不可分。<br>所谓A/B测试，简单说来就是针对想调研的问题提供两种不同的备选解决方案（比如两个下单页面），然后让一部分用户使用方案A，另一部分用户使用方案B像LinkedIn的升级迭代一样，最终通过数据观察对比确定最优方案。</p>\n</blockquote>\n</li>\n<li><p>A/B测试案例</p>\n<blockquote>\n<p>在互联网产品开发过程中，我们经常面临多种方案的抉择。有些选择轻而易举，例如面向大众的偏理性产品，主色调定位蓝色最权威稳重而广为接受（比如百度、Facebook）；强调安全的服务，绿色是常规之选。但有些时候，备选方案模棱两可，甚至区别看起来无关紧要，例如某个按钮是用橙色还是红色，摆放的位置偏左还是偏右。面对这种情况，传统解决方式要么是根据设计师的审美来定，要么是一群人共同表决，要么由某个领导拍板决定。无论哪种方式，都不免受到个人主观因素的制约，未必代表的了广大用户在实际使用场景中的认知。“不识庐山真面目，只缘身在此山中。”通常解决此类情况，最合理的办法之一，就是进行A/B测试（A/B Testing）。所谓A/B测试，简单说来就是针对想调研的问题提供两种不同的备选解决方案（比如两个下单页面），然后让一部分用户使用方案A，另一部分用户使用方案B，最终通过数据观察对比确定最优方案。在现实生活中，达尔文《物种起源》中提到的物竞天择原理，本质上就是在谈同一物种的不同变体经过外部环境测试后存留延续下的最优结果，也算是一种A/B测试。</p>\n</blockquote>\n</li>\n<li><p>团队使用A/B测试有什么好处？</p>\n<blockquote>\n<p>在数据面前任何妄加揣测的评断都可能是不准确的。通过A/B测试，产品团队能够获悉哪些对激发用户活跃度有所帮助，哪些又徒劳无功（有时候后者显得更为重要，因为它能终结一场无意义的争吵，或是缩减许多不必要的消耗）。一次测试或许能带来良好的改善效果，但也绝非意味着提升空间已然消失。微软公司的测试经验表明，在他们做的所有测试中，有三分之一被验证为成功有效，剩下的三分之二平平无奇或压根就是失败的。谷歌在2009年做了12000多次测试，但其中只有10％带来了业务变化。产品不息，测试不止。永远不要满足于当下的结果，因为世界上总有更好的解决方案</p>\n</blockquote>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Istio架构组件简介\"><a href=\"#Istio架构组件简介\" class=\"headerlink\" title=\"Istio架构组件简介\"></a>Istio架构组件简介</h2><blockquote>\n<p>官网: <a href=\"https://istio.io/\" target=\"_blank\" rel=\"noopener\">https://istio.io/</a><br>官网中文: <a href=\"https://istio.io/zh/\" target=\"_blank\" rel=\"noopener\">https://istio.io/zh/</a><br>Github: <a href=\"https://github.com/istio/istio\" target=\"_blank\" rel=\"noopener\">https://github.com/istio/istio</a><br>中文社区: <a href=\"https://istio.cn/\" target=\"_blank\" rel=\"noopener\">https://istio.cn/</a></p>\n</blockquote>\n<h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><blockquote>\n<p>Istio 是一个由谷歌、IBM 与 Lyft 共同开发的开源项目，旨在提供一种统一化的微服务连接、安全保障、管理与监控方式。具体来说，Istio 是一个开源服务网格平台，它确保微服务在处理故障时以指定的方式相互连接。</p>\n</blockquote>\n<h3 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h3><blockquote>\n<p>Istio 服务网格逻辑上分为数据平面和控制平面。</p>\n<ul>\n<li>数据平面由一组以 sidecar 方式部署的智能代理（Envoy）组成。这些代理可以调节和控制微服务及 Mixer 之间所有的网络通信。</li>\n<li>控制平面负责管理和配置代理来路由流量。此外控制平面配置 Mixer 以实施策略和收集遥测数据。<br><img src=\"istio_arch.jpeg\" alt=\"\"></li>\n</ul>\n</blockquote>\n<h3 id=\"Envoy\"><a href=\"#Envoy\" class=\"headerlink\" title=\"Envoy\"></a>Envoy</h3><p><img src=\"envoy_xds.png\" alt=\"\"></p>\n<pre><code>Listeners: 设置监听IP:Port, 到达sidecar的请求都会到这里来.\nRoutes: 根据route, 如: - match: {prefix:”/”} route: {cluster: service_envoy}选择 Cluster.\nClusters: 找到相应的Cluster name: service_envoy, 定义了一些轮询规则等.\nEndpoints: 指定路由转发到哪里, IP:Port</code></pre><p>Envoy是经过CNCF(Cloud Native Computing Foundation,云原生计算基金会(是一个开源软件基金会，它致力于云原生（Cloud Native）技术的普及和可持续发展。)非常成功毕业的sidecar软件.<br>从CNCF毕业的软件还有Prometheus, Kubernetes.</p>\n<blockquote>\n<p>Istio 使用 Envoy 代理的扩展版本，Envoy 是以 C++ 开发的高性能代理，用于调解服务网格中所有服务的所有入站和出站流量。Envoy 的许多内置功能被 istio 发扬光大，例如：<br>Envoy 被部署为 sidecar，和对应服务在同一个 Kubernetes pod 中。这允许 Istio 将大量关于流量行为的信号作为属性提取出来，而这些属性又可以在 Mixer 中用于执行策略决策，并发送给监控系统，以提供整个网格行为的信息。<br>Sidecar 代理模型还可以将 Istio 的功能添加到现有部署中，而无需重新构建或重写代码。可以阅读更多来了解为什么我们在设计目标中选择这种方式。</p>\n<ul>\n<li>动态服务发现</li>\n<li>负载均衡</li>\n<li>TLS 终止</li>\n<li>HTTP/2 &amp; gRPC 代理</li>\n<li>熔断器</li>\n<li>健康检查、基于百分比流量拆分的灰度发布</li>\n<li>故障注入</li>\n<li>丰富的度量指标</li>\n</ul>\n</blockquote>\n<h3 id=\"Mixer\"><a href=\"#Mixer\" class=\"headerlink\" title=\"Mixer\"></a>Mixer</h3><blockquote>\n<p>Mixer 是一个独立于平台的组件，负责在服务网格上执行访问控制和使用策略，并从 Envoy 代理和其他服务收集遥测数据。代理提取请求级属性，发送到 Mixer 进行评估。有关属性提取和策略评估的更多信息，请参见 Mixer 配置。<br>Mixer 中包括一个灵活的插件模型，使其能够接入到各种主机环境和基础设施后端，从这些细节中抽象出 Envoy 代理和 Istio 管理的服务。</p>\n</blockquote>\n<h3 id=\"Pilot\"><a href=\"#Pilot\" class=\"headerlink\" title=\"Pilot\"></a>Pilot</h3><blockquote>\n<p>控制面中负责流量管理的组件为Pilot</p>\n</blockquote>\n<h3 id=\"流量管理\"><a href=\"#流量管理\" class=\"headerlink\" title=\"流量管理\"></a>流量管理</h3><p>Istio 维护了一个内部服务注册表 (service registry)，它包含在服务网格中运行的一组服务及其相应的服务 endpoints。Istio 使用服务注册表生成 Envoy 配置。<br>Istio 不提供服务发现，尽管大多数服务都是通过 Pilot adapter 自动加入到服务注册表里的，而且这反映了底层平台（Kubernetes、Consul、plain DNS）的已发现的服务。还有就是，可以使用 ServiceEntry 配置手动进行注册。</p>\n<h3 id=\"Envoy-1\"><a href=\"#Envoy-1\" class=\"headerlink\" title=\"Envoy\"></a>Envoy</h3><blockquote>\n<p>Istio 选择了开源的Envoy作为它的网络代理，envoy是2016年用c++的高性能的代理组件，用于管理所有服务的入口和出口流量.<br>envoy内置了很多功能，像服务发现，负载均衡，多种协议的支持，断路器，流量分割，健康检查，模拟一些故障，还有监控指标等等.<br>envoy会以sidecar的形式部署在每一个POD中负责完成Istio的核心功能，如果把Istio比作公司，envoy就是这个公司的一些员工，所有的具体工作都是由envoy干的</p>\n</blockquote>\n<h3 id=\"Pilot-1\"><a href=\"#Pilot-1\" class=\"headerlink\" title=\"Pilot\"></a>Pilot</h3><p><img src=\"Pilot_Architecture.png\" alt=\"\"></p>\n<blockquote>\n<p>控制面中负责流量管理的组件为Pilot<br>Pilot 和 Envoy组件有了Istio就可以运转起来了，其它组件可以不需要.<br>Pilot 好比是envoy的直接领导，顶头上司，告诉并协助envoy怎样工作，因为envoy跑在一个容器里的.</p>\n</blockquote>\n<ul>\n<li>Pilot告诉envoy集群都有哪些服务，envoy就可以做服务发现了.</li>\n<li>Pilot根据用户配置的流量管理和服务信息转换成envoy能够识别的格式，然后分发给envoy，告诉envoy哪些POD需要多少流量，envoy就能做A/B测试，蓝绿部署.</li>\n<li>Pilot告诉envoy多长时间算超时，应该重试几次.<blockquote>\n<p>Pilot 为 Envoy sidecar 提供服务发现功能，为智能路由（例如 A/B 测试、金丝雀部署等）和弹性（超时、重试、熔断器等）提供流量管理功能。它将控制流量行为的高级路由规则转换为特定于 Envoy 的配置，并在运行时将它们传播到 sidecar。<br>Pilot 将平台特定的服务发现机制抽象化并将其合成为符合 Envoy 数据平面 API 的任何 sidecar 都可以使用的标准格式。这种松散耦合使得 Istio 能够在多种环境下运行（例如，Kubernetes、Consul、Nomad），同时保持用于流量管理的相同操作界面。</p>\n</blockquote>\n</li>\n<li>Platform Adapter: 平台适配器。针对多种集群管理平台实现的控制器，得到API server的DNS服务注册信息（即service名与podIP的对应表）、入口资源以及存储流量管理规则的第三方资源</li>\n<li>Abstract Model：维护了envoy中对service的规范表示。接收上层获取的service信息转化为规范模型</li>\n<li>Envoy API：下发服务发现、流量规则到envoy上</li>\n<li>Rules API：由运维人员管理。可通过API配置高级管理规则</li>\n</ul>\n<h3 id=\"Mixer-独立组件\"><a href=\"#Mixer-独立组件\" class=\"headerlink\" title=\"Mixer (独立组件)\"></a>Mixer (独立组件)</h3><p>两大功能: 策略，遥测</p>\n<blockquote>\n<p>策略: 为整个集群执行访问控制, 哪些用户可以访问哪些服务，还有一些策略的管理，像对一些服务的访问速度的限制等，比如服务A最多接受100QPS，超过的就会被直接扔掉<br>遥测: 数据的收集和汇报，从envoy(proxy)收集数据，收集的是服务之间流转的数据, 收集的数据会汇报给其它对象，每个汇报的对象都有Adapter(适配器)转换汇报的数据为自己认识的格式，如Prometheus.<br>可以不用Mixer也可以把Istio跑起来</p>\n</blockquote>\n<h3 id=\"Galley\"><a href=\"#Galley\" class=\"headerlink\" title=\"Galley\"></a>Galley</h3><blockquote>\n<p>最初负责验证配置，Istio1.1之后升级为Istio整个平面的配置管理中心，校验各种配置是否正确</p>\n</blockquote>\n<h3 id=\"Citadel\"><a href=\"#Citadel\" class=\"headerlink\" title=\"Citadel\"></a>Citadel</h3><blockquote>\n<p>安全相关的，为用户到服务，服务到服务之间提供安全的通信，可以让http服务无感知的升级成为https服务，还有服务的访问授权等.</p>\n</blockquote>\n<h2 id=\"Istio-解决的问题\"><a href=\"#Istio-解决的问题\" class=\"headerlink\" title=\"Istio 解决的问题\"></a>Istio 解决的问题</h2><blockquote>\n<ul>\n<li>原来的单个应用拆分成多个微服务, 它们之间相互调用才能完成微服务，组件(服务模块)越多，出错概率越大，就会非常难以排查.</li>\n<li>用户请求出现问题: 1.错误， 2.慢响应<ul>\n<li>请求错误，得知道哪个步骤出错了，微服务之间哪些能调用成功哪些失败.</li>\n<li>请求响应太慢, 各个链路调用，耗时是多少，哪些并发执行哪些串行.</li>\n</ul>\n</li>\n<li>设置timeout</li>\n<li>设置重试机制</li>\n<li>某些节点异常(如load高)</li>\n</ul>\n</blockquote>\n<h3 id=\"A-B测试\"><a href=\"#A-B测试\" class=\"headerlink\" title=\"A/B测试\"></a>A/B测试</h3><ul>\n<li><p>A/B测试的基本思想是什么?</p>\n<blockquote>\n<p>A/B测试的基本思想包括：提供两个方案并行测试。不同方案之间只存在一个变量，排除其他干扰因素。以某种标准判定结果优劣，筛出最优方案。其中第二点，即单变量，需要重点关注。因为某种方案的优劣，不光与方案本身有关，也可能与方案所适配的环境密不可分。<br>所谓A/B测试，简单说来就是针对想调研的问题提供两种不同的备选解决方案（比如两个下单页面），然后让一部分用户使用方案A，另一部分用户使用方案B像LinkedIn的升级迭代一样，最终通过数据观察对比确定最优方案。</p>\n</blockquote>\n</li>\n<li><p>A/B测试案例</p>\n<blockquote>\n<p>在互联网产品开发过程中，我们经常面临多种方案的抉择。有些选择轻而易举，例如面向大众的偏理性产品，主色调定位蓝色最权威稳重而广为接受（比如百度、Facebook）；强调安全的服务，绿色是常规之选。但有些时候，备选方案模棱两可，甚至区别看起来无关紧要，例如某个按钮是用橙色还是红色，摆放的位置偏左还是偏右。面对这种情况，传统解决方式要么是根据设计师的审美来定，要么是一群人共同表决，要么由某个领导拍板决定。无论哪种方式，都不免受到个人主观因素的制约，未必代表的了广大用户在实际使用场景中的认知。“不识庐山真面目，只缘身在此山中。”通常解决此类情况，最合理的办法之一，就是进行A/B测试（A/B Testing）。所谓A/B测试，简单说来就是针对想调研的问题提供两种不同的备选解决方案（比如两个下单页面），然后让一部分用户使用方案A，另一部分用户使用方案B，最终通过数据观察对比确定最优方案。在现实生活中，达尔文《物种起源》中提到的物竞天择原理，本质上就是在谈同一物种的不同变体经过外部环境测试后存留延续下的最优结果，也算是一种A/B测试。</p>\n</blockquote>\n</li>\n<li><p>团队使用A/B测试有什么好处？</p>\n<blockquote>\n<p>在数据面前任何妄加揣测的评断都可能是不准确的。通过A/B测试，产品团队能够获悉哪些对激发用户活跃度有所帮助，哪些又徒劳无功（有时候后者显得更为重要，因为它能终结一场无意义的争吵，或是缩减许多不必要的消耗）。一次测试或许能带来良好的改善效果，但也绝非意味着提升空间已然消失。微软公司的测试经验表明，在他们做的所有测试中，有三分之一被验证为成功有效，剩下的三分之二平平无奇或压根就是失败的。谷歌在2009年做了12000多次测试，但其中只有10％带来了业务变化。产品不息，测试不止。永远不要满足于当下的结果，因为世界上总有更好的解决方案</p>\n</blockquote>\n</li>\n</ul>\n"},{"title":"Istio 02 Installation on Kubernetes","_content":"\n## **Download the specific version of Istio**\n\n\t$ curl -L https://istio.io/downloadIstio | ISTIO_VERSION=1.6.4 sh -\n\t$ cd istio/bin/\n\t$ ./istioctl -h\n\t  Istio configuration command line utility for service operators to\n\t  debug and diagnose their Istio mesh.\n\t  \n\t  Usage:\n\t    istioctl [command]\n\t  \n\t  Available Commands:\n\t    analyze         Analyze Istio configuration and print validation messages\n\t    authz           (authz is experimental. Use `istioctl experimental authz`)\n\t    convert-ingress Convert Ingress configuration into Istio VirtualService configuration\n\t    dashboard       Access to Istio web UIs\n\t    deregister      De-registers a service instance\n\t    experimental    Experimental commands that may be modified or deprecated\n\t    help            Help about any command\n\t    install         Applies an Istio manifest, installing or reconfiguring Istio on a cluster.\n\t    kube-inject     Inject Envoy sidecar into Kubernetes pod resources\n\t    manifest        Commands related to Istio manifests\n\t    operator        Commands related to Istio operator controller.\n\t    profile         Commands related to Istio configuration profiles\n\t    proxy-config    Retrieve information about proxy configuration from Envoy [kube only]\n\t    proxy-status    Retrieves the synchronization status of each Envoy in the mesh [kube only]\n\t    register        Registers a service instance (e.g. VM) joining the mesh\n\t    upgrade         Upgrade Istio control plane in-place\n\t    validate        Validate Istio policy and rules (NOTE: validate is deprecated and will be removed in 1.6. Use 'istioctl analyze' to validate configuration.)\n\t    verify-install  Verifies Istio Installation Status or performs pre-check for the cluster before Istio installation\n\t    version         Prints out build version information\n\t  \n\t  Flags:\n\t        --context string          The name of the kubeconfig context to use\n\t    -h, --help                    help for istioctl\n\t    -i, --istioNamespace string   Istio system namespace (default \"istio-system\")\n\t    -c, --kubeconfig string       Kubernetes configuration file\n\t    -n, --namespace string        Config namespace\n\t  \n\t  Additional help topics:\n\t    istioctl options         Displays istioctl global options\n\t  \n\t  Use \"istioctl [command] --help\" for more information about a command.\n\n## **istio目录介绍**\n\n\t$ll istio-*\n\t  bin/ ,***, manifests/, samples/, tools/\nbin/目录存放istioctl客户端工具.  \nmanifests/目录存放istio安装表单.  \nsamples/目录存放一些使用样例.  \ntools/目录下的istioctl.bash文件是能在输入$ istioctl m 时候自动补全命令,如 $istioctl manfest.  , 需要先执行$ source istioctl.bash才能生效，新版本istio好像不用设置也能有自动补全功能.  \n\n## **Istioctl工具介绍**\nofficial website: https://istio.io/latest/docs/ops/diagnostic-tools/proxy-cmd/\n\n**Istioctl 与 Kubectl关系**\n从一开始istioctl和kubectl工具有一定的融合部分，如apply, delete等共同功能, 随着istioctl版本提升启用了一些与kubectl重合的功能并完善开发了自己的一套功能.\n\n\t// 查看pilot和envoy配置策略等的同步情况, pilot是否完全将配置信息同步到envoy\n\t$ ./istioctl proxy-status\n\t// 查询属于某个pod的envoy规则等\n\t$ ./istioctl proxy-config <clusters|listeners|routes|endpoints|bootstrap> <pod-name[.namespace]>\n\n\t// 检测安装是否成功\n\t$ ./istioctl verify-install\n\t  ......\n\t  Checked 25 custom resource definitions\t// 可以看到Istio 1.6.4只有25个crd\n\t  Checked 3 Istio Deployments\n\t  Istio is installed successfully\n\n## istioctl command\n\n### istioctl profile\n查看profile list\n\n\t$ istioctl profile list\n输出profile\n\n\t$ istioctl profile dump demo > demo.yaml\n\tvim demo.yaml\n\n\n## **Istioctl analyze**\n\n\t$ istioctl analyze -n book-info\n\t  √ No Validation issues found when analyzing namespace: book-info\n\n## **Istio upgrade and rollback**\nistio1.6 提供了简单的升级命令方式，直接通过命令 $ istioctl upgrade 就可以更新Istio control plane in-place\n且提供了金丝雀发布方式，更新和回滚过程可以看到有两个istiod在istio-system命名空间下.\n\n\n\n\n","source":"_posts/micro_service/istio_02_installation.md","raw":"---\ntitle: Istio 02 Installation on Kubernetes\ntags: istio\ncategories:\n- microService\n- istio\n---\n\n## **Download the specific version of Istio**\n\n\t$ curl -L https://istio.io/downloadIstio | ISTIO_VERSION=1.6.4 sh -\n\t$ cd istio/bin/\n\t$ ./istioctl -h\n\t  Istio configuration command line utility for service operators to\n\t  debug and diagnose their Istio mesh.\n\t  \n\t  Usage:\n\t    istioctl [command]\n\t  \n\t  Available Commands:\n\t    analyze         Analyze Istio configuration and print validation messages\n\t    authz           (authz is experimental. Use `istioctl experimental authz`)\n\t    convert-ingress Convert Ingress configuration into Istio VirtualService configuration\n\t    dashboard       Access to Istio web UIs\n\t    deregister      De-registers a service instance\n\t    experimental    Experimental commands that may be modified or deprecated\n\t    help            Help about any command\n\t    install         Applies an Istio manifest, installing or reconfiguring Istio on a cluster.\n\t    kube-inject     Inject Envoy sidecar into Kubernetes pod resources\n\t    manifest        Commands related to Istio manifests\n\t    operator        Commands related to Istio operator controller.\n\t    profile         Commands related to Istio configuration profiles\n\t    proxy-config    Retrieve information about proxy configuration from Envoy [kube only]\n\t    proxy-status    Retrieves the synchronization status of each Envoy in the mesh [kube only]\n\t    register        Registers a service instance (e.g. VM) joining the mesh\n\t    upgrade         Upgrade Istio control plane in-place\n\t    validate        Validate Istio policy and rules (NOTE: validate is deprecated and will be removed in 1.6. Use 'istioctl analyze' to validate configuration.)\n\t    verify-install  Verifies Istio Installation Status or performs pre-check for the cluster before Istio installation\n\t    version         Prints out build version information\n\t  \n\t  Flags:\n\t        --context string          The name of the kubeconfig context to use\n\t    -h, --help                    help for istioctl\n\t    -i, --istioNamespace string   Istio system namespace (default \"istio-system\")\n\t    -c, --kubeconfig string       Kubernetes configuration file\n\t    -n, --namespace string        Config namespace\n\t  \n\t  Additional help topics:\n\t    istioctl options         Displays istioctl global options\n\t  \n\t  Use \"istioctl [command] --help\" for more information about a command.\n\n## **istio目录介绍**\n\n\t$ll istio-*\n\t  bin/ ,***, manifests/, samples/, tools/\nbin/目录存放istioctl客户端工具.  \nmanifests/目录存放istio安装表单.  \nsamples/目录存放一些使用样例.  \ntools/目录下的istioctl.bash文件是能在输入$ istioctl m 时候自动补全命令,如 $istioctl manfest.  , 需要先执行$ source istioctl.bash才能生效，新版本istio好像不用设置也能有自动补全功能.  \n\n## **Istioctl工具介绍**\nofficial website: https://istio.io/latest/docs/ops/diagnostic-tools/proxy-cmd/\n\n**Istioctl 与 Kubectl关系**\n从一开始istioctl和kubectl工具有一定的融合部分，如apply, delete等共同功能, 随着istioctl版本提升启用了一些与kubectl重合的功能并完善开发了自己的一套功能.\n\n\t// 查看pilot和envoy配置策略等的同步情况, pilot是否完全将配置信息同步到envoy\n\t$ ./istioctl proxy-status\n\t// 查询属于某个pod的envoy规则等\n\t$ ./istioctl proxy-config <clusters|listeners|routes|endpoints|bootstrap> <pod-name[.namespace]>\n\n\t// 检测安装是否成功\n\t$ ./istioctl verify-install\n\t  ......\n\t  Checked 25 custom resource definitions\t// 可以看到Istio 1.6.4只有25个crd\n\t  Checked 3 Istio Deployments\n\t  Istio is installed successfully\n\n## istioctl command\n\n### istioctl profile\n查看profile list\n\n\t$ istioctl profile list\n输出profile\n\n\t$ istioctl profile dump demo > demo.yaml\n\tvim demo.yaml\n\n\n## **Istioctl analyze**\n\n\t$ istioctl analyze -n book-info\n\t  √ No Validation issues found when analyzing namespace: book-info\n\n## **Istio upgrade and rollback**\nistio1.6 提供了简单的升级命令方式，直接通过命令 $ istioctl upgrade 就可以更新Istio control plane in-place\n且提供了金丝雀发布方式，更新和回滚过程可以看到有两个istiod在istio-system命名空间下.\n\n\n\n\n","slug":"micro_service/istio_02_installation","published":1,"date":"2020-08-12T16:05:47.507Z","updated":"2020-08-17T13:01:06.628Z","_id":"ckdt3hmgi0055hohx4dvudg48","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"Download-the-specific-version-of-Istio\"><a href=\"#Download-the-specific-version-of-Istio\" class=\"headerlink\" title=\"Download the specific version of Istio\"></a><strong>Download the specific version of Istio</strong></h2><pre><code>$ curl -L https://istio.io/downloadIstio | ISTIO_VERSION=1.6.4 sh -\n$ cd istio/bin/\n$ ./istioctl -h\n  Istio configuration command line utility for service operators to\n  debug and diagnose their Istio mesh.\n\n  Usage:\n    istioctl [command]\n\n  Available Commands:\n    analyze         Analyze Istio configuration and print validation messages\n    authz           (authz is experimental. Use `istioctl experimental authz`)\n    convert-ingress Convert Ingress configuration into Istio VirtualService configuration\n    dashboard       Access to Istio web UIs\n    deregister      De-registers a service instance\n    experimental    Experimental commands that may be modified or deprecated\n    help            Help about any command\n    install         Applies an Istio manifest, installing or reconfiguring Istio on a cluster.\n    kube-inject     Inject Envoy sidecar into Kubernetes pod resources\n    manifest        Commands related to Istio manifests\n    operator        Commands related to Istio operator controller.\n    profile         Commands related to Istio configuration profiles\n    proxy-config    Retrieve information about proxy configuration from Envoy [kube only]\n    proxy-status    Retrieves the synchronization status of each Envoy in the mesh [kube only]\n    register        Registers a service instance (e.g. VM) joining the mesh\n    upgrade         Upgrade Istio control plane in-place\n    validate        Validate Istio policy and rules (NOTE: validate is deprecated and will be removed in 1.6. Use &apos;istioctl analyze&apos; to validate configuration.)\n    verify-install  Verifies Istio Installation Status or performs pre-check for the cluster before Istio installation\n    version         Prints out build version information\n\n  Flags:\n        --context string          The name of the kubeconfig context to use\n    -h, --help                    help for istioctl\n    -i, --istioNamespace string   Istio system namespace (default &quot;istio-system&quot;)\n    -c, --kubeconfig string       Kubernetes configuration file\n    -n, --namespace string        Config namespace\n\n  Additional help topics:\n    istioctl options         Displays istioctl global options\n\n  Use &quot;istioctl [command] --help&quot; for more information about a command.</code></pre><h2 id=\"istio目录介绍\"><a href=\"#istio目录介绍\" class=\"headerlink\" title=\"istio目录介绍\"></a><strong>istio目录介绍</strong></h2><pre><code>$ll istio-*\n  bin/ ,***, manifests/, samples/, tools/</code></pre><p>bin/目录存放istioctl客户端工具.<br>manifests/目录存放istio安装表单.<br>samples/目录存放一些使用样例.<br>tools/目录下的istioctl.bash文件是能在输入$ istioctl m 时候自动补全命令,如 $istioctl manfest.  , 需要先执行$ source istioctl.bash才能生效，新版本istio好像不用设置也能有自动补全功能.  </p>\n<h2 id=\"Istioctl工具介绍\"><a href=\"#Istioctl工具介绍\" class=\"headerlink\" title=\"Istioctl工具介绍\"></a><strong>Istioctl工具介绍</strong></h2><p>official website: <a href=\"https://istio.io/latest/docs/ops/diagnostic-tools/proxy-cmd/\" target=\"_blank\" rel=\"noopener\">https://istio.io/latest/docs/ops/diagnostic-tools/proxy-cmd/</a></p>\n<p><strong>Istioctl 与 Kubectl关系</strong><br>从一开始istioctl和kubectl工具有一定的融合部分，如apply, delete等共同功能, 随着istioctl版本提升启用了一些与kubectl重合的功能并完善开发了自己的一套功能.</p>\n<pre><code>// 查看pilot和envoy配置策略等的同步情况, pilot是否完全将配置信息同步到envoy\n$ ./istioctl proxy-status\n// 查询属于某个pod的envoy规则等\n$ ./istioctl proxy-config &lt;clusters|listeners|routes|endpoints|bootstrap&gt; &lt;pod-name[.namespace]&gt;\n\n// 检测安装是否成功\n$ ./istioctl verify-install\n  ......\n  Checked 25 custom resource definitions    // 可以看到Istio 1.6.4只有25个crd\n  Checked 3 Istio Deployments\n  Istio is installed successfully</code></pre><h2 id=\"istioctl-command\"><a href=\"#istioctl-command\" class=\"headerlink\" title=\"istioctl command\"></a>istioctl command</h2><h3 id=\"istioctl-profile\"><a href=\"#istioctl-profile\" class=\"headerlink\" title=\"istioctl profile\"></a>istioctl profile</h3><p>查看profile list</p>\n<pre><code>$ istioctl profile list</code></pre><p>输出profile</p>\n<pre><code>$ istioctl profile dump demo &gt; demo.yaml\nvim demo.yaml</code></pre><h2 id=\"Istioctl-analyze\"><a href=\"#Istioctl-analyze\" class=\"headerlink\" title=\"Istioctl analyze\"></a><strong>Istioctl analyze</strong></h2><pre><code>$ istioctl analyze -n book-info\n  √ No Validation issues found when analyzing namespace: book-info</code></pre><h2 id=\"Istio-upgrade-and-rollback\"><a href=\"#Istio-upgrade-and-rollback\" class=\"headerlink\" title=\"Istio upgrade and rollback\"></a><strong>Istio upgrade and rollback</strong></h2><p>istio1.6 提供了简单的升级命令方式，直接通过命令 $ istioctl upgrade 就可以更新Istio control plane in-place<br>且提供了金丝雀发布方式，更新和回滚过程可以看到有两个istiod在istio-system命名空间下.</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Download-the-specific-version-of-Istio\"><a href=\"#Download-the-specific-version-of-Istio\" class=\"headerlink\" title=\"Download the specific version of Istio\"></a><strong>Download the specific version of Istio</strong></h2><pre><code>$ curl -L https://istio.io/downloadIstio | ISTIO_VERSION=1.6.4 sh -\n$ cd istio/bin/\n$ ./istioctl -h\n  Istio configuration command line utility for service operators to\n  debug and diagnose their Istio mesh.\n\n  Usage:\n    istioctl [command]\n\n  Available Commands:\n    analyze         Analyze Istio configuration and print validation messages\n    authz           (authz is experimental. Use `istioctl experimental authz`)\n    convert-ingress Convert Ingress configuration into Istio VirtualService configuration\n    dashboard       Access to Istio web UIs\n    deregister      De-registers a service instance\n    experimental    Experimental commands that may be modified or deprecated\n    help            Help about any command\n    install         Applies an Istio manifest, installing or reconfiguring Istio on a cluster.\n    kube-inject     Inject Envoy sidecar into Kubernetes pod resources\n    manifest        Commands related to Istio manifests\n    operator        Commands related to Istio operator controller.\n    profile         Commands related to Istio configuration profiles\n    proxy-config    Retrieve information about proxy configuration from Envoy [kube only]\n    proxy-status    Retrieves the synchronization status of each Envoy in the mesh [kube only]\n    register        Registers a service instance (e.g. VM) joining the mesh\n    upgrade         Upgrade Istio control plane in-place\n    validate        Validate Istio policy and rules (NOTE: validate is deprecated and will be removed in 1.6. Use &apos;istioctl analyze&apos; to validate configuration.)\n    verify-install  Verifies Istio Installation Status or performs pre-check for the cluster before Istio installation\n    version         Prints out build version information\n\n  Flags:\n        --context string          The name of the kubeconfig context to use\n    -h, --help                    help for istioctl\n    -i, --istioNamespace string   Istio system namespace (default &quot;istio-system&quot;)\n    -c, --kubeconfig string       Kubernetes configuration file\n    -n, --namespace string        Config namespace\n\n  Additional help topics:\n    istioctl options         Displays istioctl global options\n\n  Use &quot;istioctl [command] --help&quot; for more information about a command.</code></pre><h2 id=\"istio目录介绍\"><a href=\"#istio目录介绍\" class=\"headerlink\" title=\"istio目录介绍\"></a><strong>istio目录介绍</strong></h2><pre><code>$ll istio-*\n  bin/ ,***, manifests/, samples/, tools/</code></pre><p>bin/目录存放istioctl客户端工具.<br>manifests/目录存放istio安装表单.<br>samples/目录存放一些使用样例.<br>tools/目录下的istioctl.bash文件是能在输入$ istioctl m 时候自动补全命令,如 $istioctl manfest.  , 需要先执行$ source istioctl.bash才能生效，新版本istio好像不用设置也能有自动补全功能.  </p>\n<h2 id=\"Istioctl工具介绍\"><a href=\"#Istioctl工具介绍\" class=\"headerlink\" title=\"Istioctl工具介绍\"></a><strong>Istioctl工具介绍</strong></h2><p>official website: <a href=\"https://istio.io/latest/docs/ops/diagnostic-tools/proxy-cmd/\" target=\"_blank\" rel=\"noopener\">https://istio.io/latest/docs/ops/diagnostic-tools/proxy-cmd/</a></p>\n<p><strong>Istioctl 与 Kubectl关系</strong><br>从一开始istioctl和kubectl工具有一定的融合部分，如apply, delete等共同功能, 随着istioctl版本提升启用了一些与kubectl重合的功能并完善开发了自己的一套功能.</p>\n<pre><code>// 查看pilot和envoy配置策略等的同步情况, pilot是否完全将配置信息同步到envoy\n$ ./istioctl proxy-status\n// 查询属于某个pod的envoy规则等\n$ ./istioctl proxy-config &lt;clusters|listeners|routes|endpoints|bootstrap&gt; &lt;pod-name[.namespace]&gt;\n\n// 检测安装是否成功\n$ ./istioctl verify-install\n  ......\n  Checked 25 custom resource definitions    // 可以看到Istio 1.6.4只有25个crd\n  Checked 3 Istio Deployments\n  Istio is installed successfully</code></pre><h2 id=\"istioctl-command\"><a href=\"#istioctl-command\" class=\"headerlink\" title=\"istioctl command\"></a>istioctl command</h2><h3 id=\"istioctl-profile\"><a href=\"#istioctl-profile\" class=\"headerlink\" title=\"istioctl profile\"></a>istioctl profile</h3><p>查看profile list</p>\n<pre><code>$ istioctl profile list</code></pre><p>输出profile</p>\n<pre><code>$ istioctl profile dump demo &gt; demo.yaml\nvim demo.yaml</code></pre><h2 id=\"Istioctl-analyze\"><a href=\"#Istioctl-analyze\" class=\"headerlink\" title=\"Istioctl analyze\"></a><strong>Istioctl analyze</strong></h2><pre><code>$ istioctl analyze -n book-info\n  √ No Validation issues found when analyzing namespace: book-info</code></pre><h2 id=\"Istio-upgrade-and-rollback\"><a href=\"#Istio-upgrade-and-rollback\" class=\"headerlink\" title=\"Istio upgrade and rollback\"></a><strong>Istio upgrade and rollback</strong></h2><p>istio1.6 提供了简单的升级命令方式，直接通过命令 $ istioctl upgrade 就可以更新Istio control plane in-place<br>且提供了金丝雀发布方式，更新和回滚过程可以看到有两个istiod在istio-system命名空间下.</p>\n"},{"title":"1.services analysis","_content":"![](architecture.png)\n# API Gateway\n\n# Zookeeper 服务的注册和发现\n\n# 服务API\n * REST\n * Thrift\n * Dubbo - 基于kv的存储来进行服务的发布和订阅\n\n## REST API\n![](REST_FUL_API.png)  \n * REST，即Representational State Transfer的缩写,中文是\"表现层状态转化\"。\n\t通俗来讲就是：资源在网络中以某种表现形式进行状态转移。(再通俗来说，就是通过HTTP请求服务器上的某资源，使该资源copy了一份到服务请求方那去了(get动作)。\n\tRepresentational：某种表现形式，比如用JSON，XML，JPEG等；HTTP请求的头信息中用Accept和Content-Type字段指定，这两个字段才是对\"表现形式\"的描述。\n\tState Transfer：状态变化。通过HTTP动词（GET,POST,DELETE,DETC）实现。\n\t互联网通信协议HTTP协议，是一个无状态协议。**这意味着，所有的状态都保存在服务器端。\n\t**因此，如果客户端想要操作服务器，必须通过某种手段，让服务器端发生\"状态转化\"（State Transfer）。\n\tHTTP协议里面，四个表示操作方式的动词：GET、POST、PUT、DELETE。\n\t它们分别对应四种基本操作：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源。\n\n * REST是由谁提出来的:\n\tRoy Thomes Fielding在他2000年的博士论文中提出REST架构模式，他是HTTP协议(v1.0和v1.1)的主要设计者、Apache服务器作者之一、Apache基金会第一任主席。\n\t\n * 什么是REST ful API\n\t基于REST构建的API就是Restful风格。\n\n * 为什么产生了这种架构模式\n\t传统的那种JSP前后端耦合在一起的网页模式我们称之为“上古时期”网页，这种模式弊端很多。\n\t近年来，随着移动技术的发展，各种移动端设备层出不穷，RESTful可以通过一套统一的接口为 Web，iOS和Android提供服务。\n\t另外对于广大平台来说，比如新浪微博开放平台，微信公共平台等，它们不需要有显式的前端，只需要一套提供服务的接口，于是RESTful更是它们最好的选择。\n\n * 如何设计规范的REST ful API接口\n  - [RESETful API 设计规范](https://godruoyi.com/posts/the-resetful-api-design-specification)\n  -  [RESTful API 最佳实践](http://www.ruanyifeng.com/blog/2018/10/restful-api-best-practices.html)\n\n## 单点登陆系统 慕课网有免费课程\n\t访问单点登陆系统，校验拿到的token或者称为tickets(票据)是不是正确的, 然后使用这个东西去换取用户的具体信息, 再存储到当前的服务里面\n\n\n\n","source":"_posts/micro_service/services_analysis.md","raw":"---\ntitle: 1.services analysis\ntags: kubernetes\ncategories:\n- microService\n- REST-API\n---\n![](architecture.png)\n# API Gateway\n\n# Zookeeper 服务的注册和发现\n\n# 服务API\n * REST\n * Thrift\n * Dubbo - 基于kv的存储来进行服务的发布和订阅\n\n## REST API\n![](REST_FUL_API.png)  \n * REST，即Representational State Transfer的缩写,中文是\"表现层状态转化\"。\n\t通俗来讲就是：资源在网络中以某种表现形式进行状态转移。(再通俗来说，就是通过HTTP请求服务器上的某资源，使该资源copy了一份到服务请求方那去了(get动作)。\n\tRepresentational：某种表现形式，比如用JSON，XML，JPEG等；HTTP请求的头信息中用Accept和Content-Type字段指定，这两个字段才是对\"表现形式\"的描述。\n\tState Transfer：状态变化。通过HTTP动词（GET,POST,DELETE,DETC）实现。\n\t互联网通信协议HTTP协议，是一个无状态协议。**这意味着，所有的状态都保存在服务器端。\n\t**因此，如果客户端想要操作服务器，必须通过某种手段，让服务器端发生\"状态转化\"（State Transfer）。\n\tHTTP协议里面，四个表示操作方式的动词：GET、POST、PUT、DELETE。\n\t它们分别对应四种基本操作：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源。\n\n * REST是由谁提出来的:\n\tRoy Thomes Fielding在他2000年的博士论文中提出REST架构模式，他是HTTP协议(v1.0和v1.1)的主要设计者、Apache服务器作者之一、Apache基金会第一任主席。\n\t\n * 什么是REST ful API\n\t基于REST构建的API就是Restful风格。\n\n * 为什么产生了这种架构模式\n\t传统的那种JSP前后端耦合在一起的网页模式我们称之为“上古时期”网页，这种模式弊端很多。\n\t近年来，随着移动技术的发展，各种移动端设备层出不穷，RESTful可以通过一套统一的接口为 Web，iOS和Android提供服务。\n\t另外对于广大平台来说，比如新浪微博开放平台，微信公共平台等，它们不需要有显式的前端，只需要一套提供服务的接口，于是RESTful更是它们最好的选择。\n\n * 如何设计规范的REST ful API接口\n  - [RESETful API 设计规范](https://godruoyi.com/posts/the-resetful-api-design-specification)\n  -  [RESTful API 最佳实践](http://www.ruanyifeng.com/blog/2018/10/restful-api-best-practices.html)\n\n## 单点登陆系统 慕课网有免费课程\n\t访问单点登陆系统，校验拿到的token或者称为tickets(票据)是不是正确的, 然后使用这个东西去换取用户的具体信息, 再存储到当前的服务里面\n\n\n\n","slug":"micro_service/services_analysis","published":1,"date":"2020-08-12T16:05:47.537Z","updated":"2020-08-10T16:38:45.924Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmgk005dhohxfn4tdl18","content":"<p><img src=\"architecture.png\" alt=\"\"></p>\n<h1 id=\"API-Gateway\"><a href=\"#API-Gateway\" class=\"headerlink\" title=\"API Gateway\"></a>API Gateway</h1><h1 id=\"Zookeeper-服务的注册和发现\"><a href=\"#Zookeeper-服务的注册和发现\" class=\"headerlink\" title=\"Zookeeper 服务的注册和发现\"></a>Zookeeper 服务的注册和发现</h1><h1 id=\"服务API\"><a href=\"#服务API\" class=\"headerlink\" title=\"服务API\"></a>服务API</h1><ul>\n<li>REST</li>\n<li>Thrift</li>\n<li>Dubbo - 基于kv的存储来进行服务的发布和订阅</li>\n</ul>\n<h2 id=\"REST-API\"><a href=\"#REST-API\" class=\"headerlink\" title=\"REST API\"></a>REST API</h2><p><img src=\"REST_FUL_API.png\" alt=\"\">  </p>\n<ul>\n<li><p>REST，即Representational State Transfer的缩写,中文是”表现层状态转化”。<br> 通俗来讲就是：资源在网络中以某种表现形式进行状态转移。(再通俗来说，就是通过HTTP请求服务器上的某资源，使该资源copy了一份到服务请求方那去了(get动作)。<br> Representational：某种表现形式，比如用JSON，XML，JPEG等；HTTP请求的头信息中用Accept和Content-Type字段指定，这两个字段才是对”表现形式”的描述。<br> State Transfer：状态变化。通过HTTP动词（GET,POST,DELETE,DETC）实现。<br> 互联网通信协议HTTP协议，是一个无状态协议。*<em>这意味着，所有的状态都保存在服务器端。<br> *</em>因此，如果客户端想要操作服务器，必须通过某种手段，让服务器端发生”状态转化”（State Transfer）。<br> HTTP协议里面，四个表示操作方式的动词：GET、POST、PUT、DELETE。<br> 它们分别对应四种基本操作：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源。</p>\n</li>\n<li><p>REST是由谁提出来的:<br> Roy Thomes Fielding在他2000年的博士论文中提出REST架构模式，他是HTTP协议(v1.0和v1.1)的主要设计者、Apache服务器作者之一、Apache基金会第一任主席。</p>\n</li>\n<li><p>什么是REST ful API<br> 基于REST构建的API就是Restful风格。</p>\n</li>\n<li><p>为什么产生了这种架构模式<br> 传统的那种JSP前后端耦合在一起的网页模式我们称之为“上古时期”网页，这种模式弊端很多。<br> 近年来，随着移动技术的发展，各种移动端设备层出不穷，RESTful可以通过一套统一的接口为 Web，iOS和Android提供服务。<br> 另外对于广大平台来说，比如新浪微博开放平台，微信公共平台等，它们不需要有显式的前端，只需要一套提供服务的接口，于是RESTful更是它们最好的选择。</p>\n</li>\n<li><p>如何设计规范的REST ful API接口</p>\n<ul>\n<li><a href=\"https://godruoyi.com/posts/the-resetful-api-design-specification\" target=\"_blank\" rel=\"noopener\">RESETful API 设计规范</a></li>\n<li><a href=\"http://www.ruanyifeng.com/blog/2018/10/restful-api-best-practices.html\" target=\"_blank\" rel=\"noopener\">RESTful API 最佳实践</a></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"单点登陆系统-慕课网有免费课程\"><a href=\"#单点登陆系统-慕课网有免费课程\" class=\"headerlink\" title=\"单点登陆系统 慕课网有免费课程\"></a>单点登陆系统 慕课网有免费课程</h2><pre><code>访问单点登陆系统，校验拿到的token或者称为tickets(票据)是不是正确的, 然后使用这个东西去换取用户的具体信息, 再存储到当前的服务里面</code></pre>","site":{"data":{}},"excerpt":"","more":"<p><img src=\"architecture.png\" alt=\"\"></p>\n<h1 id=\"API-Gateway\"><a href=\"#API-Gateway\" class=\"headerlink\" title=\"API Gateway\"></a>API Gateway</h1><h1 id=\"Zookeeper-服务的注册和发现\"><a href=\"#Zookeeper-服务的注册和发现\" class=\"headerlink\" title=\"Zookeeper 服务的注册和发现\"></a>Zookeeper 服务的注册和发现</h1><h1 id=\"服务API\"><a href=\"#服务API\" class=\"headerlink\" title=\"服务API\"></a>服务API</h1><ul>\n<li>REST</li>\n<li>Thrift</li>\n<li>Dubbo - 基于kv的存储来进行服务的发布和订阅</li>\n</ul>\n<h2 id=\"REST-API\"><a href=\"#REST-API\" class=\"headerlink\" title=\"REST API\"></a>REST API</h2><p><img src=\"REST_FUL_API.png\" alt=\"\">  </p>\n<ul>\n<li><p>REST，即Representational State Transfer的缩写,中文是”表现层状态转化”。<br> 通俗来讲就是：资源在网络中以某种表现形式进行状态转移。(再通俗来说，就是通过HTTP请求服务器上的某资源，使该资源copy了一份到服务请求方那去了(get动作)。<br> Representational：某种表现形式，比如用JSON，XML，JPEG等；HTTP请求的头信息中用Accept和Content-Type字段指定，这两个字段才是对”表现形式”的描述。<br> State Transfer：状态变化。通过HTTP动词（GET,POST,DELETE,DETC）实现。<br> 互联网通信协议HTTP协议，是一个无状态协议。*<em>这意味着，所有的状态都保存在服务器端。<br> *</em>因此，如果客户端想要操作服务器，必须通过某种手段，让服务器端发生”状态转化”（State Transfer）。<br> HTTP协议里面，四个表示操作方式的动词：GET、POST、PUT、DELETE。<br> 它们分别对应四种基本操作：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源。</p>\n</li>\n<li><p>REST是由谁提出来的:<br> Roy Thomes Fielding在他2000年的博士论文中提出REST架构模式，他是HTTP协议(v1.0和v1.1)的主要设计者、Apache服务器作者之一、Apache基金会第一任主席。</p>\n</li>\n<li><p>什么是REST ful API<br> 基于REST构建的API就是Restful风格。</p>\n</li>\n<li><p>为什么产生了这种架构模式<br> 传统的那种JSP前后端耦合在一起的网页模式我们称之为“上古时期”网页，这种模式弊端很多。<br> 近年来，随着移动技术的发展，各种移动端设备层出不穷，RESTful可以通过一套统一的接口为 Web，iOS和Android提供服务。<br> 另外对于广大平台来说，比如新浪微博开放平台，微信公共平台等，它们不需要有显式的前端，只需要一套提供服务的接口，于是RESTful更是它们最好的选择。</p>\n</li>\n<li><p>如何设计规范的REST ful API接口</p>\n<ul>\n<li><a href=\"https://godruoyi.com/posts/the-resetful-api-design-specification\" target=\"_blank\" rel=\"noopener\">RESETful API 设计规范</a></li>\n<li><a href=\"http://www.ruanyifeng.com/blog/2018/10/restful-api-best-practices.html\" target=\"_blank\" rel=\"noopener\">RESTful API 最佳实践</a></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"单点登陆系统-慕课网有免费课程\"><a href=\"#单点登陆系统-慕课网有免费课程\" class=\"headerlink\" title=\"单点登陆系统 慕课网有免费课程\"></a>单点登陆系统 慕课网有免费课程</h2><pre><code>访问单点登陆系统，校验拿到的token或者称为tickets(票据)是不是正确的, 然后使用这个东西去换取用户的具体信息, 再存储到当前的服务里面</code></pre>"},{"title":"1.webstorm自动提示设置","_content":"\n### 1. 设置 Webstorm js 语法支持到 es6（或根据需要选择）\n![](1.png)\n\n### 2. 下载 node 语法库\n![](2.png)\n![](3.png)\n![](4.png)\n\n### 3. 不要过滤node_modules文件夹！\n![](5.png)\n\n## 效果\n设置后，不仅没有语法波浪线，在输入的时候已经有代码候选补全，并且按ctrl点击还能跳转查看源码\n![](6.png)\n标签组件名也能补全了\n![](7.png)\n标签也不会出现语法背景黄色，并且还支持自定义属性参数的补全\n![](8.png)","source":"_posts/nodejs/1.webstorm自动提示设置.md","raw":"---\ntitle: 1.webstorm自动提示设置\ntags:\ncategories:\n- nodejs\n---\n\n### 1. 设置 Webstorm js 语法支持到 es6（或根据需要选择）\n![](1.png)\n\n### 2. 下载 node 语法库\n![](2.png)\n![](3.png)\n![](4.png)\n\n### 3. 不要过滤node_modules文件夹！\n![](5.png)\n\n## 效果\n设置后，不仅没有语法波浪线，在输入的时候已经有代码候选补全，并且按ctrl点击还能跳转查看源码\n![](6.png)\n标签组件名也能补全了\n![](7.png)\n标签也不会出现语法背景黄色，并且还支持自定义属性参数的补全\n![](8.png)","slug":"nodejs/1.webstorm自动提示设置","published":1,"date":"2020-08-12T16:05:47.761Z","updated":"2020-03-05T05:27:52.711Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmgl005hhohxeud05w4h","content":"<h3 id=\"1-设置-Webstorm-js-语法支持到-es6（或根据需要选择）\"><a href=\"#1-设置-Webstorm-js-语法支持到-es6（或根据需要选择）\" class=\"headerlink\" title=\"1. 设置 Webstorm js 语法支持到 es6（或根据需要选择）\"></a>1. 设置 Webstorm js 语法支持到 es6（或根据需要选择）</h3><p><img src=\"1.png\" alt=\"\"></p>\n<h3 id=\"2-下载-node-语法库\"><a href=\"#2-下载-node-语法库\" class=\"headerlink\" title=\"2. 下载 node 语法库\"></a>2. 下载 node 语法库</h3><p><img src=\"2.png\" alt=\"\"><br><img src=\"3.png\" alt=\"\"><br><img src=\"4.png\" alt=\"\"></p>\n<h3 id=\"3-不要过滤node-modules文件夹！\"><a href=\"#3-不要过滤node-modules文件夹！\" class=\"headerlink\" title=\"3. 不要过滤node_modules文件夹！\"></a>3. 不要过滤node_modules文件夹！</h3><p><img src=\"5.png\" alt=\"\"></p>\n<h2 id=\"效果\"><a href=\"#效果\" class=\"headerlink\" title=\"效果\"></a>效果</h2><p>设置后，不仅没有语法波浪线，在输入的时候已经有代码候选补全，并且按ctrl点击还能跳转查看源码<br><img src=\"6.png\" alt=\"\"><br>标签组件名也能补全了<br><img src=\"7.png\" alt=\"\"><br>标签也不会出现语法背景黄色，并且还支持自定义属性参数的补全<br><img src=\"8.png\" alt=\"\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"1-设置-Webstorm-js-语法支持到-es6（或根据需要选择）\"><a href=\"#1-设置-Webstorm-js-语法支持到-es6（或根据需要选择）\" class=\"headerlink\" title=\"1. 设置 Webstorm js 语法支持到 es6（或根据需要选择）\"></a>1. 设置 Webstorm js 语法支持到 es6（或根据需要选择）</h3><p><img src=\"1.png\" alt=\"\"></p>\n<h3 id=\"2-下载-node-语法库\"><a href=\"#2-下载-node-语法库\" class=\"headerlink\" title=\"2. 下载 node 语法库\"></a>2. 下载 node 语法库</h3><p><img src=\"2.png\" alt=\"\"><br><img src=\"3.png\" alt=\"\"><br><img src=\"4.png\" alt=\"\"></p>\n<h3 id=\"3-不要过滤node-modules文件夹！\"><a href=\"#3-不要过滤node-modules文件夹！\" class=\"headerlink\" title=\"3. 不要过滤node_modules文件夹！\"></a>3. 不要过滤node_modules文件夹！</h3><p><img src=\"5.png\" alt=\"\"></p>\n<h2 id=\"效果\"><a href=\"#效果\" class=\"headerlink\" title=\"效果\"></a>效果</h2><p>设置后，不仅没有语法波浪线，在输入的时候已经有代码候选补全，并且按ctrl点击还能跳转查看源码<br><img src=\"6.png\" alt=\"\"><br>标签组件名也能补全了<br><img src=\"7.png\" alt=\"\"><br>标签也不会出现语法背景黄色，并且还支持自定义属性参数的补全<br><img src=\"8.png\" alt=\"\"></p>\n"},{"title":"2.Linux Node.js 安装","_content":"<!-- date: 2020-01-06 13:50:12    //可以添加到上面-->\n\n## Linux安装:\ncurl: https://curl.haxx.se/download.html\n\t curl-7.69.1.tar.gz\n\t ./configure --prefix=/usr/local/curl\n\t make -j12\n\t make install\n\t ln -s /usr/local/curl/bin/curl /usr/bin\n\t vim ~/.bashrc 添加 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/curl/lib\n\t source ~/.bashrc\n\t curl --version \t\t// 查看curl版本和支持的协议如http, https\n","source":"_posts/nodejs/2.Linux_Node.js_安装.md","raw":"---\ntitle: 2.Linux Node.js 安装\ntags:\ncategories:\n- nodejs\n---\n<!-- date: 2020-01-06 13:50:12    //可以添加到上面-->\n\n## Linux安装:\ncurl: https://curl.haxx.se/download.html\n\t curl-7.69.1.tar.gz\n\t ./configure --prefix=/usr/local/curl\n\t make -j12\n\t make install\n\t ln -s /usr/local/curl/bin/curl /usr/bin\n\t vim ~/.bashrc 添加 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/curl/lib\n\t source ~/.bashrc\n\t curl --version \t\t// 查看curl版本和支持的协议如http, https\n","slug":"nodejs/2.Linux_Node.js_安装","published":1,"date":"2020-08-12T16:05:47.773Z","updated":"2020-04-07T12:44:34.099Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmgn005lhohx09jm3mx8","content":"<!-- date: 2020-01-06 13:50:12    //可以添加到上面-->\n\n<h2 id=\"Linux安装\"><a href=\"#Linux安装\" class=\"headerlink\" title=\"Linux安装:\"></a>Linux安装:</h2><p>curl: <a href=\"https://curl.haxx.se/download.html\" target=\"_blank\" rel=\"noopener\">https://curl.haxx.se/download.html</a><br>     curl-7.69.1.tar.gz<br>     ./configure –prefix=/usr/local/curl<br>     make -j12<br>     make install<br>     ln -s /usr/local/curl/bin/curl /usr/bin<br>     vim ~/.bashrc 添加 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/curl/lib<br>     source ~/.bashrc<br>     curl –version         // 查看curl版本和支持的协议如http, https</p>\n","site":{"data":{}},"excerpt":"","more":"<!-- date: 2020-01-06 13:50:12    //可以添加到上面-->\n\n<h2 id=\"Linux安装\"><a href=\"#Linux安装\" class=\"headerlink\" title=\"Linux安装:\"></a>Linux安装:</h2><p>curl: <a href=\"https://curl.haxx.se/download.html\" target=\"_blank\" rel=\"noopener\">https://curl.haxx.se/download.html</a><br>     curl-7.69.1.tar.gz<br>     ./configure –prefix=/usr/local/curl<br>     make -j12<br>     make install<br>     ln -s /usr/local/curl/bin/curl /usr/bin<br>     vim ~/.bashrc 添加 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/curl/lib<br>     source ~/.bashrc<br>     curl –version         // 查看curl版本和支持的协议如http, https</p>\n"},{"title":"2.Windows10 Node.js 安装","_content":"<!-- date: 2020-01-06 13:50:12    //可以添加到上面-->\n\n### 1. 下载node安装包(LTS版本) https://nodejs.org/en/  \n    运行msi文件默认下一步即可\n\n### 2. cd C:\\Program Files\\nodejs\n    mkdir node_cache\n\tmkdir node_global\n\n### 3. <font color='red'>管理员</font>方式打开cmd\n```\n\tnpm -v\n\tnpm config list\n\tnpm config set proxy http://child-prc.intel.com:913\n\tnpm config set https-proxy http://child-prc.intel.com:913\n\tnpm config set prefix \"C:\\Program Files\\nodejs\\node_global\"\n\tnpm config set cache \"C:\\Program Files\\nodejs\\node_cache\"\n\t\n\tnpm install npm -g    //将npm安装一份到刚迁移的新目录(方便后续统一管理)。\n\t```\n\n### 4. 配置环境变量(注意结合自己的node安装位置)\n\t• 新建NODE_PATH环境变量，值为 C:\\Program Files\\nodejs\\node_global\\node_modules\n\t• 在path环境变量中加入 C:\\Program Files\\nodejs\\node_global\n\tNODE_PATH环境变量是指向新的模块安装位置(node默认使用该环境变量，建立就行)  \n\tpath中加入的是node模块的启动方式目录  \n![](NODE_PATH.png)\n\t可以把安装nodejs时候自动配置的PATH变量C:\\Users\\yazhanma\\AppData\\Roaming\\npm删掉\n![](PATH_nodejs_intall.png)\n### 5. 到此node安装完毕，介绍下node的模块安装方式(关闭cmd命令行并重新以管理员身份打开,让更新的环境变量生效)。\n\t• #npm install 模块名 –g\n\t如 #npm install -g hexo-cli， 稍等一会\n\t会在如下路径找到hexo\n\tC:\\Program Files\\nodejs\\node_global\n\tC:\\Program Files\\nodejs\\node_global\\node_modules\n\t\nAppendix:  \n设置git代理  \n    1. #git config --global http.proxy http://127.0.0.1:1080  \n    2. #git config --global https.proxy https://127.0.0.1:1080  \n\n如果所用网络不需要代理，则要把npm代理和git代理去掉  \n1、去掉npm代理\n\t#npm config delete proxy\n\t#npm config delete https-proxy\n\n2、去掉git代理\n\t#git config --global --unset http.proxy\n\t#git config --global --unset https.proxy\n\n### FAQ(Frequently asked question)\n遇到设置完D:\\nodejs\\node_global环境变量后CMD窗口打开输入 hexo 可用, 但是powershell打开无法运行hexo(D:\\nodejs\\node_global\\hexo)\n提示原因是安全security问题，禁止运行脚本, 修改方法:\npowershell窗口打开运行如下命令:\n\n\t1. $ Set-ExecutionPolicy -Scope CurrentUser\n\t2. 再输入remotesigned 即可\n\n\n\n\n\n","source":"_posts/nodejs/2.Windows10_Node.js_安装.md","raw":"---\ntitle: 2.Windows10 Node.js 安装\ntags:\ncategories:\n- nodejs\n---\n<!-- date: 2020-01-06 13:50:12    //可以添加到上面-->\n\n### 1. 下载node安装包(LTS版本) https://nodejs.org/en/  \n    运行msi文件默认下一步即可\n\n### 2. cd C:\\Program Files\\nodejs\n    mkdir node_cache\n\tmkdir node_global\n\n### 3. <font color='red'>管理员</font>方式打开cmd\n```\n\tnpm -v\n\tnpm config list\n\tnpm config set proxy http://child-prc.intel.com:913\n\tnpm config set https-proxy http://child-prc.intel.com:913\n\tnpm config set prefix \"C:\\Program Files\\nodejs\\node_global\"\n\tnpm config set cache \"C:\\Program Files\\nodejs\\node_cache\"\n\t\n\tnpm install npm -g    //将npm安装一份到刚迁移的新目录(方便后续统一管理)。\n\t```\n\n### 4. 配置环境变量(注意结合自己的node安装位置)\n\t• 新建NODE_PATH环境变量，值为 C:\\Program Files\\nodejs\\node_global\\node_modules\n\t• 在path环境变量中加入 C:\\Program Files\\nodejs\\node_global\n\tNODE_PATH环境变量是指向新的模块安装位置(node默认使用该环境变量，建立就行)  \n\tpath中加入的是node模块的启动方式目录  \n![](NODE_PATH.png)\n\t可以把安装nodejs时候自动配置的PATH变量C:\\Users\\yazhanma\\AppData\\Roaming\\npm删掉\n![](PATH_nodejs_intall.png)\n### 5. 到此node安装完毕，介绍下node的模块安装方式(关闭cmd命令行并重新以管理员身份打开,让更新的环境变量生效)。\n\t• #npm install 模块名 –g\n\t如 #npm install -g hexo-cli， 稍等一会\n\t会在如下路径找到hexo\n\tC:\\Program Files\\nodejs\\node_global\n\tC:\\Program Files\\nodejs\\node_global\\node_modules\n\t\nAppendix:  \n设置git代理  \n    1. #git config --global http.proxy http://127.0.0.1:1080  \n    2. #git config --global https.proxy https://127.0.0.1:1080  \n\n如果所用网络不需要代理，则要把npm代理和git代理去掉  \n1、去掉npm代理\n\t#npm config delete proxy\n\t#npm config delete https-proxy\n\n2、去掉git代理\n\t#git config --global --unset http.proxy\n\t#git config --global --unset https.proxy\n\n### FAQ(Frequently asked question)\n遇到设置完D:\\nodejs\\node_global环境变量后CMD窗口打开输入 hexo 可用, 但是powershell打开无法运行hexo(D:\\nodejs\\node_global\\hexo)\n提示原因是安全security问题，禁止运行脚本, 修改方法:\npowershell窗口打开运行如下命令:\n\n\t1. $ Set-ExecutionPolicy -Scope CurrentUser\n\t2. 再输入remotesigned 即可\n\n\n\n\n\n","slug":"nodejs/2.Windows10_Node.js_安装","published":1,"date":"2020-08-12T16:05:47.788Z","updated":"2020-07-20T15:21:53.896Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmgo005phohx8kle7b4v","content":"<!-- date: 2020-01-06 13:50:12    //可以添加到上面-->\n\n<h3 id=\"1-下载node安装包-LTS版本-https-nodejs-org-en\"><a href=\"#1-下载node安装包-LTS版本-https-nodejs-org-en\" class=\"headerlink\" title=\"1. 下载node安装包(LTS版本) https://nodejs.org/en/\"></a>1. 下载node安装包(LTS版本) <a href=\"https://nodejs.org/en/\" target=\"_blank\" rel=\"noopener\">https://nodejs.org/en/</a></h3><pre><code>运行msi文件默认下一步即可</code></pre><h3 id=\"2-cd-C-Program-Files-nodejs\"><a href=\"#2-cd-C-Program-Files-nodejs\" class=\"headerlink\" title=\"2. cd C:\\Program Files\\nodejs\"></a>2. cd C:\\Program Files\\nodejs</h3><pre><code>mkdir node_cache\nmkdir node_global</code></pre><h3 id=\"3-管理员方式打开cmd\"><a href=\"#3-管理员方式打开cmd\" class=\"headerlink\" title=\"3. 管理员方式打开cmd\"></a>3. <font color='red'>管理员</font>方式打开cmd</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm -v</span><br><span class=\"line\">npm config list</span><br><span class=\"line\">npm config set proxy http:&#x2F;&#x2F;child-prc.intel.com:913</span><br><span class=\"line\">npm config set https-proxy http:&#x2F;&#x2F;child-prc.intel.com:913</span><br><span class=\"line\">npm config set prefix &quot;C:\\Program Files\\nodejs\\node_global&quot;</span><br><span class=\"line\">npm config set cache &quot;C:\\Program Files\\nodejs\\node_cache&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">npm install npm -g    &#x2F;&#x2F;将npm安装一份到刚迁移的新目录(方便后续统一管理)。</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"4-配置环境变量-注意结合自己的node安装位置\"><a href=\"#4-配置环境变量-注意结合自己的node安装位置\" class=\"headerlink\" title=\"4. 配置环境变量(注意结合自己的node安装位置)\"></a>4. 配置环境变量(注意结合自己的node安装位置)</h3><pre><code>• 新建NODE_PATH环境变量，值为 C:\\Program Files\\nodejs\\node_global\\node_modules\n• 在path环境变量中加入 C:\\Program Files\\nodejs\\node_global\nNODE_PATH环境变量是指向新的模块安装位置(node默认使用该环境变量，建立就行)  \npath中加入的是node模块的启动方式目录  </code></pre><p><img src=\"NODE_PATH.png\" alt=\"\"><br>    可以把安装nodejs时候自动配置的PATH变量C:\\Users\\yazhanma\\AppData\\Roaming\\npm删掉<br><img src=\"PATH_nodejs_intall.png\" alt=\"\"></p>\n<h3 id=\"5-到此node安装完毕，介绍下node的模块安装方式-关闭cmd命令行并重新以管理员身份打开-让更新的环境变量生效-。\"><a href=\"#5-到此node安装完毕，介绍下node的模块安装方式-关闭cmd命令行并重新以管理员身份打开-让更新的环境变量生效-。\" class=\"headerlink\" title=\"5. 到此node安装完毕，介绍下node的模块安装方式(关闭cmd命令行并重新以管理员身份打开,让更新的环境变量生效)。\"></a>5. 到此node安装完毕，介绍下node的模块安装方式(关闭cmd命令行并重新以管理员身份打开,让更新的环境变量生效)。</h3><pre><code>• #npm install 模块名 –g\n如 #npm install -g hexo-cli， 稍等一会\n会在如下路径找到hexo\nC:\\Program Files\\nodejs\\node_global\nC:\\Program Files\\nodejs\\node_global\\node_modules</code></pre><p>Appendix:<br>设置git代理<br>    1. #git config –global http.proxy <a href=\"http://127.0.0.1:1080\" target=\"_blank\" rel=\"noopener\">http://127.0.0.1:1080</a><br>    2. #git config –global https.proxy <a href=\"https://127.0.0.1:1080\" target=\"_blank\" rel=\"noopener\">https://127.0.0.1:1080</a>  </p>\n<p>如果所用网络不需要代理，则要把npm代理和git代理去掉<br>1、去掉npm代理<br>    #npm config delete proxy<br>    #npm config delete https-proxy</p>\n<p>2、去掉git代理<br>    #git config –global –unset http.proxy<br>    #git config –global –unset https.proxy</p>\n<h3 id=\"FAQ-Frequently-asked-question\"><a href=\"#FAQ-Frequently-asked-question\" class=\"headerlink\" title=\"FAQ(Frequently asked question)\"></a>FAQ(Frequently asked question)</h3><p>遇到设置完D:\\nodejs\\node_global环境变量后CMD窗口打开输入 hexo 可用, 但是powershell打开无法运行hexo(D:\\nodejs\\node_global\\hexo)<br>提示原因是安全security问题，禁止运行脚本, 修改方法:<br>powershell窗口打开运行如下命令:</p>\n<pre><code>1. $ Set-ExecutionPolicy -Scope CurrentUser\n2. 再输入remotesigned 即可</code></pre>","site":{"data":{}},"excerpt":"","more":"<!-- date: 2020-01-06 13:50:12    //可以添加到上面-->\n\n<h3 id=\"1-下载node安装包-LTS版本-https-nodejs-org-en\"><a href=\"#1-下载node安装包-LTS版本-https-nodejs-org-en\" class=\"headerlink\" title=\"1. 下载node安装包(LTS版本) https://nodejs.org/en/\"></a>1. 下载node安装包(LTS版本) <a href=\"https://nodejs.org/en/\" target=\"_blank\" rel=\"noopener\">https://nodejs.org/en/</a></h3><pre><code>运行msi文件默认下一步即可</code></pre><h3 id=\"2-cd-C-Program-Files-nodejs\"><a href=\"#2-cd-C-Program-Files-nodejs\" class=\"headerlink\" title=\"2. cd C:\\Program Files\\nodejs\"></a>2. cd C:\\Program Files\\nodejs</h3><pre><code>mkdir node_cache\nmkdir node_global</code></pre><h3 id=\"3-管理员方式打开cmd\"><a href=\"#3-管理员方式打开cmd\" class=\"headerlink\" title=\"3. 管理员方式打开cmd\"></a>3. <font color='red'>管理员</font>方式打开cmd</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm -v</span><br><span class=\"line\">npm config list</span><br><span class=\"line\">npm config set proxy http:&#x2F;&#x2F;child-prc.intel.com:913</span><br><span class=\"line\">npm config set https-proxy http:&#x2F;&#x2F;child-prc.intel.com:913</span><br><span class=\"line\">npm config set prefix &quot;C:\\Program Files\\nodejs\\node_global&quot;</span><br><span class=\"line\">npm config set cache &quot;C:\\Program Files\\nodejs\\node_cache&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">npm install npm -g    &#x2F;&#x2F;将npm安装一份到刚迁移的新目录(方便后续统一管理)。</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"4-配置环境变量-注意结合自己的node安装位置\"><a href=\"#4-配置环境变量-注意结合自己的node安装位置\" class=\"headerlink\" title=\"4. 配置环境变量(注意结合自己的node安装位置)\"></a>4. 配置环境变量(注意结合自己的node安装位置)</h3><pre><code>• 新建NODE_PATH环境变量，值为 C:\\Program Files\\nodejs\\node_global\\node_modules\n• 在path环境变量中加入 C:\\Program Files\\nodejs\\node_global\nNODE_PATH环境变量是指向新的模块安装位置(node默认使用该环境变量，建立就行)  \npath中加入的是node模块的启动方式目录  </code></pre><p><img src=\"NODE_PATH.png\" alt=\"\"><br>    可以把安装nodejs时候自动配置的PATH变量C:\\Users\\yazhanma\\AppData\\Roaming\\npm删掉<br><img src=\"PATH_nodejs_intall.png\" alt=\"\"></p>\n<h3 id=\"5-到此node安装完毕，介绍下node的模块安装方式-关闭cmd命令行并重新以管理员身份打开-让更新的环境变量生效-。\"><a href=\"#5-到此node安装完毕，介绍下node的模块安装方式-关闭cmd命令行并重新以管理员身份打开-让更新的环境变量生效-。\" class=\"headerlink\" title=\"5. 到此node安装完毕，介绍下node的模块安装方式(关闭cmd命令行并重新以管理员身份打开,让更新的环境变量生效)。\"></a>5. 到此node安装完毕，介绍下node的模块安装方式(关闭cmd命令行并重新以管理员身份打开,让更新的环境变量生效)。</h3><pre><code>• #npm install 模块名 –g\n如 #npm install -g hexo-cli， 稍等一会\n会在如下路径找到hexo\nC:\\Program Files\\nodejs\\node_global\nC:\\Program Files\\nodejs\\node_global\\node_modules</code></pre><p>Appendix:<br>设置git代理<br>    1. #git config –global http.proxy <a href=\"http://127.0.0.1:1080\" target=\"_blank\" rel=\"noopener\">http://127.0.0.1:1080</a><br>    2. #git config –global https.proxy <a href=\"https://127.0.0.1:1080\" target=\"_blank\" rel=\"noopener\">https://127.0.0.1:1080</a>  </p>\n<p>如果所用网络不需要代理，则要把npm代理和git代理去掉<br>1、去掉npm代理<br>    #npm config delete proxy<br>    #npm config delete https-proxy</p>\n<p>2、去掉git代理<br>    #git config –global –unset http.proxy<br>    #git config –global –unset https.proxy</p>\n<h3 id=\"FAQ-Frequently-asked-question\"><a href=\"#FAQ-Frequently-asked-question\" class=\"headerlink\" title=\"FAQ(Frequently asked question)\"></a>FAQ(Frequently asked question)</h3><p>遇到设置完D:\\nodejs\\node_global环境变量后CMD窗口打开输入 hexo 可用, 但是powershell打开无法运行hexo(D:\\nodejs\\node_global\\hexo)<br>提示原因是安全security问题，禁止运行脚本, 修改方法:<br>powershell窗口打开运行如下命令:</p>\n<pre><code>1. $ Set-ExecutionPolicy -Scope CurrentUser\n2. 再输入remotesigned 即可</code></pre>"},{"title":"3.匿名函数,自执行函数","_content":"\n### 1.1 函数声明\njavascript具有“函数声明提升”的特性，即执行代码之前，先读取函数声明，意味着函数声明可以放在调用它的语句之后。如下代码可以正常执行：\n```\nsum(1, 2);\nfunction sum(x, y) {\n    alert(x+y);\n}\n```\n\n### 1.2 函数表达式\n函数表达式在使用前必须先赋值\n函数表达式中，创建的函数叫做匿名函数，因为function关键字后面没有标识符。\n```\nvar ss = function(x, y) {\n    alert(x+y);\n}\nss(1, 2);\n```\n\n### 2 匿名函数的调用方式\n匿名函数，顾名思义就是没有名字的函数\n上面的函数表达式中的创建，即创建一个匿名函数，并将匿名函数赋值给变量ss，用ss来进行函数的调用，\n调用的方式就是在变量ss后面加上一对括号()，如果有参数传入的话就是ss(1,2)，这就是匿名函数的一种调用方式。\n再看一下以下例子：\n\t1）将匿名函数用()括起来；\n\t2）然后在后面加一对小括号(包含参数列表)\n\t紧随其后的另一个圆括号会立即调用这个函数。\n```\n(function(x, y){return x+y;})(2, 3)  // 定义并立即调用了一个匿名函数\n\n如a = function(){}()，\"a=\"这个告诉了编译器这是一个函数表达式，而不是函数声明，因为函数表达式后面可以跟()\n\n因此下面两段代码是等价的。\nvar aa = function(x) {\n    alert(x);\n}(5); // 5\n(function(x){alert(x);})(5);\n```\n\n### 3 自执行函数\n我们创建了一个匿名的函数，并立即执行它，由于外部无法引用它内部的变量，因此在执行完后很快就会被释放，关键是这种机制不会污染全局对象。\n自执行函数，即定义和调用合为一体。\n自执行函数的一些表达方式：\n```\n// 下面2个括号()都会立即执行  \n(function () { /* code */ } ()); // 推荐使用这个  \n(function () { /* code */ })(); // 但是这个也是可以用的\n```\n\n\n\n","source":"_posts/nodejs/3.JSP匿名函数,自执行函数.md","raw":"---\ntitle: 3.匿名函数,自执行函数\ntags:\ncategories:\n- nodejs\n---\n\n### 1.1 函数声明\njavascript具有“函数声明提升”的特性，即执行代码之前，先读取函数声明，意味着函数声明可以放在调用它的语句之后。如下代码可以正常执行：\n```\nsum(1, 2);\nfunction sum(x, y) {\n    alert(x+y);\n}\n```\n\n### 1.2 函数表达式\n函数表达式在使用前必须先赋值\n函数表达式中，创建的函数叫做匿名函数，因为function关键字后面没有标识符。\n```\nvar ss = function(x, y) {\n    alert(x+y);\n}\nss(1, 2);\n```\n\n### 2 匿名函数的调用方式\n匿名函数，顾名思义就是没有名字的函数\n上面的函数表达式中的创建，即创建一个匿名函数，并将匿名函数赋值给变量ss，用ss来进行函数的调用，\n调用的方式就是在变量ss后面加上一对括号()，如果有参数传入的话就是ss(1,2)，这就是匿名函数的一种调用方式。\n再看一下以下例子：\n\t1）将匿名函数用()括起来；\n\t2）然后在后面加一对小括号(包含参数列表)\n\t紧随其后的另一个圆括号会立即调用这个函数。\n```\n(function(x, y){return x+y;})(2, 3)  // 定义并立即调用了一个匿名函数\n\n如a = function(){}()，\"a=\"这个告诉了编译器这是一个函数表达式，而不是函数声明，因为函数表达式后面可以跟()\n\n因此下面两段代码是等价的。\nvar aa = function(x) {\n    alert(x);\n}(5); // 5\n(function(x){alert(x);})(5);\n```\n\n### 3 自执行函数\n我们创建了一个匿名的函数，并立即执行它，由于外部无法引用它内部的变量，因此在执行完后很快就会被释放，关键是这种机制不会污染全局对象。\n自执行函数，即定义和调用合为一体。\n自执行函数的一些表达方式：\n```\n// 下面2个括号()都会立即执行  \n(function () { /* code */ } ()); // 推荐使用这个  \n(function () { /* code */ })(); // 但是这个也是可以用的\n```\n\n\n\n","slug":"nodejs/3.JSP匿名函数,自执行函数","published":1,"date":"2020-08-12T16:05:47.794Z","updated":"2020-08-12T11:33:54.154Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmgp005thohx1bdybopp","content":"<h3 id=\"1-1-函数声明\"><a href=\"#1-1-函数声明\" class=\"headerlink\" title=\"1.1 函数声明\"></a>1.1 函数声明</h3><p>javascript具有“函数声明提升”的特性，即执行代码之前，先读取函数声明，意味着函数声明可以放在调用它的语句之后。如下代码可以正常执行：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sum(1, 2);</span><br><span class=\"line\">function sum(x, y) &#123;</span><br><span class=\"line\">    alert(x+y);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"1-2-函数表达式\"><a href=\"#1-2-函数表达式\" class=\"headerlink\" title=\"1.2 函数表达式\"></a>1.2 函数表达式</h3><p>函数表达式在使用前必须先赋值<br>函数表达式中，创建的函数叫做匿名函数，因为function关键字后面没有标识符。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var ss &#x3D; function(x, y) &#123;</span><br><span class=\"line\">    alert(x+y);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">ss(1, 2);</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2-匿名函数的调用方式\"><a href=\"#2-匿名函数的调用方式\" class=\"headerlink\" title=\"2 匿名函数的调用方式\"></a>2 匿名函数的调用方式</h3><p>匿名函数，顾名思义就是没有名字的函数<br>上面的函数表达式中的创建，即创建一个匿名函数，并将匿名函数赋值给变量ss，用ss来进行函数的调用，<br>调用的方式就是在变量ss后面加上一对括号()，如果有参数传入的话就是ss(1,2)，这就是匿名函数的一种调用方式。<br>再看一下以下例子：<br>    1）将匿名函数用()括起来；<br>    2）然后在后面加一对小括号(包含参数列表)<br>    紧随其后的另一个圆括号会立即调用这个函数。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(function(x, y)&#123;return x+y;&#125;)(2, 3)  &#x2F;&#x2F; 定义并立即调用了一个匿名函数</span><br><span class=\"line\"></span><br><span class=\"line\">如a &#x3D; function()&#123;&#125;()，&quot;a&#x3D;&quot;这个告诉了编译器这是一个函数表达式，而不是函数声明，因为函数表达式后面可以跟()</span><br><span class=\"line\"></span><br><span class=\"line\">因此下面两段代码是等价的。</span><br><span class=\"line\">var aa &#x3D; function(x) &#123;</span><br><span class=\"line\">    alert(x);</span><br><span class=\"line\">&#125;(5); &#x2F;&#x2F; 5</span><br><span class=\"line\">(function(x)&#123;alert(x);&#125;)(5);</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"3-自执行函数\"><a href=\"#3-自执行函数\" class=\"headerlink\" title=\"3 自执行函数\"></a>3 自执行函数</h3><p>我们创建了一个匿名的函数，并立即执行它，由于外部无法引用它内部的变量，因此在执行完后很快就会被释放，关键是这种机制不会污染全局对象。<br>自执行函数，即定义和调用合为一体。<br>自执行函数的一些表达方式：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#x2F;&#x2F; 下面2个括号()都会立即执行  </span><br><span class=\"line\">(function () &#123; &#x2F;* code *&#x2F; &#125; ()); &#x2F;&#x2F; 推荐使用这个  </span><br><span class=\"line\">(function () &#123; &#x2F;* code *&#x2F; &#125;)(); &#x2F;&#x2F; 但是这个也是可以用的</span><br></pre></td></tr></table></figure>\n\n\n\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"1-1-函数声明\"><a href=\"#1-1-函数声明\" class=\"headerlink\" title=\"1.1 函数声明\"></a>1.1 函数声明</h3><p>javascript具有“函数声明提升”的特性，即执行代码之前，先读取函数声明，意味着函数声明可以放在调用它的语句之后。如下代码可以正常执行：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sum(1, 2);</span><br><span class=\"line\">function sum(x, y) &#123;</span><br><span class=\"line\">    alert(x+y);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"1-2-函数表达式\"><a href=\"#1-2-函数表达式\" class=\"headerlink\" title=\"1.2 函数表达式\"></a>1.2 函数表达式</h3><p>函数表达式在使用前必须先赋值<br>函数表达式中，创建的函数叫做匿名函数，因为function关键字后面没有标识符。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var ss &#x3D; function(x, y) &#123;</span><br><span class=\"line\">    alert(x+y);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">ss(1, 2);</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2-匿名函数的调用方式\"><a href=\"#2-匿名函数的调用方式\" class=\"headerlink\" title=\"2 匿名函数的调用方式\"></a>2 匿名函数的调用方式</h3><p>匿名函数，顾名思义就是没有名字的函数<br>上面的函数表达式中的创建，即创建一个匿名函数，并将匿名函数赋值给变量ss，用ss来进行函数的调用，<br>调用的方式就是在变量ss后面加上一对括号()，如果有参数传入的话就是ss(1,2)，这就是匿名函数的一种调用方式。<br>再看一下以下例子：<br>    1）将匿名函数用()括起来；<br>    2）然后在后面加一对小括号(包含参数列表)<br>    紧随其后的另一个圆括号会立即调用这个函数。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(function(x, y)&#123;return x+y;&#125;)(2, 3)  &#x2F;&#x2F; 定义并立即调用了一个匿名函数</span><br><span class=\"line\"></span><br><span class=\"line\">如a &#x3D; function()&#123;&#125;()，&quot;a&#x3D;&quot;这个告诉了编译器这是一个函数表达式，而不是函数声明，因为函数表达式后面可以跟()</span><br><span class=\"line\"></span><br><span class=\"line\">因此下面两段代码是等价的。</span><br><span class=\"line\">var aa &#x3D; function(x) &#123;</span><br><span class=\"line\">    alert(x);</span><br><span class=\"line\">&#125;(5); &#x2F;&#x2F; 5</span><br><span class=\"line\">(function(x)&#123;alert(x);&#125;)(5);</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"3-自执行函数\"><a href=\"#3-自执行函数\" class=\"headerlink\" title=\"3 自执行函数\"></a>3 自执行函数</h3><p>我们创建了一个匿名的函数，并立即执行它，由于外部无法引用它内部的变量，因此在执行完后很快就会被释放，关键是这种机制不会污染全局对象。<br>自执行函数，即定义和调用合为一体。<br>自执行函数的一些表达方式：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#x2F;&#x2F; 下面2个括号()都会立即执行  </span><br><span class=\"line\">(function () &#123; &#x2F;* code *&#x2F; &#125; ()); &#x2F;&#x2F; 推荐使用这个  </span><br><span class=\"line\">(function () &#123; &#x2F;* code *&#x2F; &#125;)(); &#x2F;&#x2F; 但是这个也是可以用的</span><br></pre></td></tr></table></figure>\n\n\n\n"},{"title":"Express简介","_content":"\n### Express 是一个自身功能极简，完全由路由和中间件构成的一个web开发框架\n中间件: 就是匹配路由之前和匹配路由之后做的一系列操作.\n中间件是一个函数，可以访问请求对象，响应对象，和web应用中处理请求响应循环流程中的中间件，一般被命名为next的变量\n\n\n中间件功能包括:\n * 执行任何代码\n * 修改请求和响应对象\n * 终结请求，响应循环\n * 调用堆栈中的下一个中间件\n \n如果get，post回调函数中，没有next参数，那么就匹配第一个路由，就不会往下匹配. 如果往下匹配必须写next.\n\nExpress 应用可使用如下几种中间件:\n * 1. 应用级中间件\n * 2. 内置中间件\n * 3. 路由级中间件\n * 4. 错误处理中间件\n * 5. 第三方中间件\n\n### 例子:\n```\nvar express=require('express'); // 引入\nvar app=new express();\t\t\t// 实例化\n/* 1. 应用级中间件app.use(), 匹配所有路由,就是在匹配其它路由之前都需要执行的操作，多用在权限判断, 没登陆之前是否可登陆 或 是否有权限访问某些网页\n* 下面中间件: 表示匹配任何路由, 如再匹配其它路由之前打印下时间\n*/\napp.use(function(req, res, next){\n\tconsole.log(new Date());\n\t// next();\t\t// 缺少next, 匹配到此路由并打印出时间后浏览器头部观察到转圈圈不再往下匹配.\n\tif(req.session != Null){\n\t\tnext();\n\t}else\n\t{\n\t\tres.redir(\"/login\");\n\t}\n})\n\n/* 2. 内置中间件，托管静态页面, 匹配路由之前, 看public下面有没有匹配的文件, 如果有则返回，没有就继续向下匹配*/\n// 项目部分目录结构: project_name/public/css/style.css\n// 第一种访问方式: http://127.0.0.1:3000/css/style.css\napp.use(express.static('public'));\n// 第二种访问方式: http://127.0.0.1:3000/static/css/style.css\napp.use(\"/static\", express.static('public'));\n\n/* 3. 路由中间件app.get(): 匹配某个路由 */\napp.get(\"/\", function(req, res, next){\n\tconsole.log(\"您好express\");\n\tnext();\t\t\t\t\t\t// 缺少next(), 浏览器会一直转圈圈卡着等待服务器继续返回.\n});\napp.get(\"/\", function(req, res){\n\tres.send(\"您好express\");\t// 匹配到此路由后, res.send()后不需要再next, 浏览器会结束响应.\n});\n\n/* 1. 应用级中间件app.use()*/\napp.use(\"/news\", function(req, res, next){\n\tconsole.log(\"应用级中间件匹配news\");\n\tnext();\n})\napp.get(\"/news\", function(req, res){\n\tres.send(\"news\");\n});\n\n/* 4. 错误处理中间件, 如果上面路由都没有匹配到，404*/\napp.use(function(req, res){\n\tres.status(404).send(\"这是404，路由没有匹配到\");\n})\n\n/* 5. 第三方中间件就是官方或者其他人好的中间件，访问https://npmjs.com搜索下载 */ \n/* \n* 不用中间件获取post提交数据: req.on(); 用中间件body-parser获取post提交的数据.\n* 一: 安装: npm install body-parser --save\n* 二: 引用: var bodyParser = require('body-parser');\n* 三：设置中间件\n*\t// parse application/x-www-form-urlencoded\n*\tapp.use(bodyParser.urlencoded({extended: false}))\n*\t//parse application/json\n*\tapp.use(bodyParser.json())\n* 四: req.body 获取post提交的数据\n*/\n\n// 二：引入body-parser中间件\nvar bodyParser = require('body-parser');\n// parse application/x-www-form-urlencoded\n// 三：配置body-parser中间件\napp.use(bodyParser.urlencoded({extended: false}))\n//parse application/json\napp.use(bodyParser.json())\n\n// ejs, 1.安装(package.json)，2.如下配置 ejs引擎\n// 默认ejs加载的是views下面的视图, 如login.ejs\napp.set('view engine', 'ejs');\napp.get('/login', function(req, res){\n\tres.render('login');\n})\n/*\tlogin.ejs文件路径: project_name/views/login.ejs, 内容含有如下表单\n* <form action=\"doLogin\" method=\"post\">\n*\t用户名: <input type=\"text\" name=\"username\"/><br/>\n*\t密  码: <input type=\"password\" name=\"password\"><br/>\n*\t<input type=\"submit\" value=\"登陆\"/>\n* </form>\n*/\n// 四：使用req.body 获取post提交的数据 \napp.post(\"/doLogin\", function(req, res){\n\tconsole.log(req.body);\n})\n```","source":"_posts/nodejs/Express简介.md","raw":"---\ntitle: Express简介\ntags:\ncategories:\n- nodejs\n---\n\n### Express 是一个自身功能极简，完全由路由和中间件构成的一个web开发框架\n中间件: 就是匹配路由之前和匹配路由之后做的一系列操作.\n中间件是一个函数，可以访问请求对象，响应对象，和web应用中处理请求响应循环流程中的中间件，一般被命名为next的变量\n\n\n中间件功能包括:\n * 执行任何代码\n * 修改请求和响应对象\n * 终结请求，响应循环\n * 调用堆栈中的下一个中间件\n \n如果get，post回调函数中，没有next参数，那么就匹配第一个路由，就不会往下匹配. 如果往下匹配必须写next.\n\nExpress 应用可使用如下几种中间件:\n * 1. 应用级中间件\n * 2. 内置中间件\n * 3. 路由级中间件\n * 4. 错误处理中间件\n * 5. 第三方中间件\n\n### 例子:\n```\nvar express=require('express'); // 引入\nvar app=new express();\t\t\t// 实例化\n/* 1. 应用级中间件app.use(), 匹配所有路由,就是在匹配其它路由之前都需要执行的操作，多用在权限判断, 没登陆之前是否可登陆 或 是否有权限访问某些网页\n* 下面中间件: 表示匹配任何路由, 如再匹配其它路由之前打印下时间\n*/\napp.use(function(req, res, next){\n\tconsole.log(new Date());\n\t// next();\t\t// 缺少next, 匹配到此路由并打印出时间后浏览器头部观察到转圈圈不再往下匹配.\n\tif(req.session != Null){\n\t\tnext();\n\t}else\n\t{\n\t\tres.redir(\"/login\");\n\t}\n})\n\n/* 2. 内置中间件，托管静态页面, 匹配路由之前, 看public下面有没有匹配的文件, 如果有则返回，没有就继续向下匹配*/\n// 项目部分目录结构: project_name/public/css/style.css\n// 第一种访问方式: http://127.0.0.1:3000/css/style.css\napp.use(express.static('public'));\n// 第二种访问方式: http://127.0.0.1:3000/static/css/style.css\napp.use(\"/static\", express.static('public'));\n\n/* 3. 路由中间件app.get(): 匹配某个路由 */\napp.get(\"/\", function(req, res, next){\n\tconsole.log(\"您好express\");\n\tnext();\t\t\t\t\t\t// 缺少next(), 浏览器会一直转圈圈卡着等待服务器继续返回.\n});\napp.get(\"/\", function(req, res){\n\tres.send(\"您好express\");\t// 匹配到此路由后, res.send()后不需要再next, 浏览器会结束响应.\n});\n\n/* 1. 应用级中间件app.use()*/\napp.use(\"/news\", function(req, res, next){\n\tconsole.log(\"应用级中间件匹配news\");\n\tnext();\n})\napp.get(\"/news\", function(req, res){\n\tres.send(\"news\");\n});\n\n/* 4. 错误处理中间件, 如果上面路由都没有匹配到，404*/\napp.use(function(req, res){\n\tres.status(404).send(\"这是404，路由没有匹配到\");\n})\n\n/* 5. 第三方中间件就是官方或者其他人好的中间件，访问https://npmjs.com搜索下载 */ \n/* \n* 不用中间件获取post提交数据: req.on(); 用中间件body-parser获取post提交的数据.\n* 一: 安装: npm install body-parser --save\n* 二: 引用: var bodyParser = require('body-parser');\n* 三：设置中间件\n*\t// parse application/x-www-form-urlencoded\n*\tapp.use(bodyParser.urlencoded({extended: false}))\n*\t//parse application/json\n*\tapp.use(bodyParser.json())\n* 四: req.body 获取post提交的数据\n*/\n\n// 二：引入body-parser中间件\nvar bodyParser = require('body-parser');\n// parse application/x-www-form-urlencoded\n// 三：配置body-parser中间件\napp.use(bodyParser.urlencoded({extended: false}))\n//parse application/json\napp.use(bodyParser.json())\n\n// ejs, 1.安装(package.json)，2.如下配置 ejs引擎\n// 默认ejs加载的是views下面的视图, 如login.ejs\napp.set('view engine', 'ejs');\napp.get('/login', function(req, res){\n\tres.render('login');\n})\n/*\tlogin.ejs文件路径: project_name/views/login.ejs, 内容含有如下表单\n* <form action=\"doLogin\" method=\"post\">\n*\t用户名: <input type=\"text\" name=\"username\"/><br/>\n*\t密  码: <input type=\"password\" name=\"password\"><br/>\n*\t<input type=\"submit\" value=\"登陆\"/>\n* </form>\n*/\n// 四：使用req.body 获取post提交的数据 \napp.post(\"/doLogin\", function(req, res){\n\tconsole.log(req.body);\n})\n```","slug":"nodejs/Express简介","published":1,"date":"2020-08-12T16:05:47.818Z","updated":"2020-04-12T17:24:03.802Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmgq005whohxf6ikf9zt","content":"<h3 id=\"Express-是一个自身功能极简，完全由路由和中间件构成的一个web开发框架\"><a href=\"#Express-是一个自身功能极简，完全由路由和中间件构成的一个web开发框架\" class=\"headerlink\" title=\"Express 是一个自身功能极简，完全由路由和中间件构成的一个web开发框架\"></a>Express 是一个自身功能极简，完全由路由和中间件构成的一个web开发框架</h3><p>中间件: 就是匹配路由之前和匹配路由之后做的一系列操作.<br>中间件是一个函数，可以访问请求对象，响应对象，和web应用中处理请求响应循环流程中的中间件，一般被命名为next的变量</p>\n<p>中间件功能包括:</p>\n<ul>\n<li>执行任何代码</li>\n<li>修改请求和响应对象</li>\n<li>终结请求，响应循环</li>\n<li>调用堆栈中的下一个中间件</li>\n</ul>\n<p>如果get，post回调函数中，没有next参数，那么就匹配第一个路由，就不会往下匹配. 如果往下匹配必须写next.</p>\n<p>Express 应用可使用如下几种中间件:</p>\n<ul>\n<li><ol>\n<li>应用级中间件</li>\n</ol>\n</li>\n<li><ol start=\"2\">\n<li>内置中间件</li>\n</ol>\n</li>\n<li><ol start=\"3\">\n<li>路由级中间件</li>\n</ol>\n</li>\n<li><ol start=\"4\">\n<li>错误处理中间件</li>\n</ol>\n</li>\n<li><ol start=\"5\">\n<li>第三方中间件</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子:\"></a>例子:</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var express&#x3D;require(&#39;express&#39;); &#x2F;&#x2F; 引入</span><br><span class=\"line\">var app&#x3D;new express();\t\t\t&#x2F;&#x2F; 实例化</span><br><span class=\"line\">&#x2F;* 1. 应用级中间件app.use(), 匹配所有路由,就是在匹配其它路由之前都需要执行的操作，多用在权限判断, 没登陆之前是否可登陆 或 是否有权限访问某些网页</span><br><span class=\"line\">* 下面中间件: 表示匹配任何路由, 如再匹配其它路由之前打印下时间</span><br><span class=\"line\">*&#x2F;</span><br><span class=\"line\">app.use(function(req, res, next)&#123;</span><br><span class=\"line\">\tconsole.log(new Date());</span><br><span class=\"line\">\t&#x2F;&#x2F; next();\t\t&#x2F;&#x2F; 缺少next, 匹配到此路由并打印出时间后浏览器头部观察到转圈圈不再往下匹配.</span><br><span class=\"line\">\tif(req.session !&#x3D; Null)&#123;</span><br><span class=\"line\">\t\tnext();</span><br><span class=\"line\">\t&#125;else</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tres.redir(&quot;&#x2F;login&quot;);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;* 2. 内置中间件，托管静态页面, 匹配路由之前, 看public下面有没有匹配的文件, 如果有则返回，没有就继续向下匹配*&#x2F;</span><br><span class=\"line\">&#x2F;&#x2F; 项目部分目录结构: project_name&#x2F;public&#x2F;css&#x2F;style.css</span><br><span class=\"line\">&#x2F;&#x2F; 第一种访问方式: http:&#x2F;&#x2F;127.0.0.1:3000&#x2F;css&#x2F;style.css</span><br><span class=\"line\">app.use(express.static(&#39;public&#39;));</span><br><span class=\"line\">&#x2F;&#x2F; 第二种访问方式: http:&#x2F;&#x2F;127.0.0.1:3000&#x2F;static&#x2F;css&#x2F;style.css</span><br><span class=\"line\">app.use(&quot;&#x2F;static&quot;, express.static(&#39;public&#39;));</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;* 3. 路由中间件app.get(): 匹配某个路由 *&#x2F;</span><br><span class=\"line\">app.get(&quot;&#x2F;&quot;, function(req, res, next)&#123;</span><br><span class=\"line\">\tconsole.log(&quot;您好express&quot;);</span><br><span class=\"line\">\tnext();\t\t\t\t\t\t&#x2F;&#x2F; 缺少next(), 浏览器会一直转圈圈卡着等待服务器继续返回.</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\">app.get(&quot;&#x2F;&quot;, function(req, res)&#123;</span><br><span class=\"line\">\tres.send(&quot;您好express&quot;);\t&#x2F;&#x2F; 匹配到此路由后, res.send()后不需要再next, 浏览器会结束响应.</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;* 1. 应用级中间件app.use()*&#x2F;</span><br><span class=\"line\">app.use(&quot;&#x2F;news&quot;, function(req, res, next)&#123;</span><br><span class=\"line\">\tconsole.log(&quot;应用级中间件匹配news&quot;);</span><br><span class=\"line\">\tnext();</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\">app.get(&quot;&#x2F;news&quot;, function(req, res)&#123;</span><br><span class=\"line\">\tres.send(&quot;news&quot;);</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;* 4. 错误处理中间件, 如果上面路由都没有匹配到，404*&#x2F;</span><br><span class=\"line\">app.use(function(req, res)&#123;</span><br><span class=\"line\">\tres.status(404).send(&quot;这是404，路由没有匹配到&quot;);</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;* 5. 第三方中间件就是官方或者其他人好的中间件，访问https:&#x2F;&#x2F;npmjs.com搜索下载 *&#x2F; </span><br><span class=\"line\">&#x2F;* </span><br><span class=\"line\">* 不用中间件获取post提交数据: req.on(); 用中间件body-parser获取post提交的数据.</span><br><span class=\"line\">* 一: 安装: npm install body-parser --save</span><br><span class=\"line\">* 二: 引用: var bodyParser &#x3D; require(&#39;body-parser&#39;);</span><br><span class=\"line\">* 三：设置中间件</span><br><span class=\"line\">*\t&#x2F;&#x2F; parse application&#x2F;x-www-form-urlencoded</span><br><span class=\"line\">*\tapp.use(bodyParser.urlencoded(&#123;extended: false&#125;))</span><br><span class=\"line\">*\t&#x2F;&#x2F;parse application&#x2F;json</span><br><span class=\"line\">*\tapp.use(bodyParser.json())</span><br><span class=\"line\">* 四: req.body 获取post提交的数据</span><br><span class=\"line\">*&#x2F;</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;&#x2F; 二：引入body-parser中间件</span><br><span class=\"line\">var bodyParser &#x3D; require(&#39;body-parser&#39;);</span><br><span class=\"line\">&#x2F;&#x2F; parse application&#x2F;x-www-form-urlencoded</span><br><span class=\"line\">&#x2F;&#x2F; 三：配置body-parser中间件</span><br><span class=\"line\">app.use(bodyParser.urlencoded(&#123;extended: false&#125;))</span><br><span class=\"line\">&#x2F;&#x2F;parse application&#x2F;json</span><br><span class=\"line\">app.use(bodyParser.json())</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;&#x2F; ejs, 1.安装(package.json)，2.如下配置 ejs引擎</span><br><span class=\"line\">&#x2F;&#x2F; 默认ejs加载的是views下面的视图, 如login.ejs</span><br><span class=\"line\">app.set(&#39;view engine&#39;, &#39;ejs&#39;);</span><br><span class=\"line\">app.get(&#39;&#x2F;login&#39;, function(req, res)&#123;</span><br><span class=\"line\">\tres.render(&#39;login&#39;);</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\">&#x2F;*\tlogin.ejs文件路径: project_name&#x2F;views&#x2F;login.ejs, 内容含有如下表单</span><br><span class=\"line\">* &lt;form action&#x3D;&quot;doLogin&quot; method&#x3D;&quot;post&quot;&gt;</span><br><span class=\"line\">*\t用户名: &lt;input type&#x3D;&quot;text&quot; name&#x3D;&quot;username&quot;&#x2F;&gt;&lt;br&#x2F;&gt;</span><br><span class=\"line\">*\t密  码: &lt;input type&#x3D;&quot;password&quot; name&#x3D;&quot;password&quot;&gt;&lt;br&#x2F;&gt;</span><br><span class=\"line\">*\t&lt;input type&#x3D;&quot;submit&quot; value&#x3D;&quot;登陆&quot;&#x2F;&gt;</span><br><span class=\"line\">* &lt;&#x2F;form&gt;</span><br><span class=\"line\">*&#x2F;</span><br><span class=\"line\">&#x2F;&#x2F; 四：使用req.body 获取post提交的数据 </span><br><span class=\"line\">app.post(&quot;&#x2F;doLogin&quot;, function(req, res)&#123;</span><br><span class=\"line\">\tconsole.log(req.body);</span><br><span class=\"line\">&#125;)</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Express-是一个自身功能极简，完全由路由和中间件构成的一个web开发框架\"><a href=\"#Express-是一个自身功能极简，完全由路由和中间件构成的一个web开发框架\" class=\"headerlink\" title=\"Express 是一个自身功能极简，完全由路由和中间件构成的一个web开发框架\"></a>Express 是一个自身功能极简，完全由路由和中间件构成的一个web开发框架</h3><p>中间件: 就是匹配路由之前和匹配路由之后做的一系列操作.<br>中间件是一个函数，可以访问请求对象，响应对象，和web应用中处理请求响应循环流程中的中间件，一般被命名为next的变量</p>\n<p>中间件功能包括:</p>\n<ul>\n<li>执行任何代码</li>\n<li>修改请求和响应对象</li>\n<li>终结请求，响应循环</li>\n<li>调用堆栈中的下一个中间件</li>\n</ul>\n<p>如果get，post回调函数中，没有next参数，那么就匹配第一个路由，就不会往下匹配. 如果往下匹配必须写next.</p>\n<p>Express 应用可使用如下几种中间件:</p>\n<ul>\n<li><ol>\n<li>应用级中间件</li>\n</ol>\n</li>\n<li><ol start=\"2\">\n<li>内置中间件</li>\n</ol>\n</li>\n<li><ol start=\"3\">\n<li>路由级中间件</li>\n</ol>\n</li>\n<li><ol start=\"4\">\n<li>错误处理中间件</li>\n</ol>\n</li>\n<li><ol start=\"5\">\n<li>第三方中间件</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子:\"></a>例子:</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var express&#x3D;require(&#39;express&#39;); &#x2F;&#x2F; 引入</span><br><span class=\"line\">var app&#x3D;new express();\t\t\t&#x2F;&#x2F; 实例化</span><br><span class=\"line\">&#x2F;* 1. 应用级中间件app.use(), 匹配所有路由,就是在匹配其它路由之前都需要执行的操作，多用在权限判断, 没登陆之前是否可登陆 或 是否有权限访问某些网页</span><br><span class=\"line\">* 下面中间件: 表示匹配任何路由, 如再匹配其它路由之前打印下时间</span><br><span class=\"line\">*&#x2F;</span><br><span class=\"line\">app.use(function(req, res, next)&#123;</span><br><span class=\"line\">\tconsole.log(new Date());</span><br><span class=\"line\">\t&#x2F;&#x2F; next();\t\t&#x2F;&#x2F; 缺少next, 匹配到此路由并打印出时间后浏览器头部观察到转圈圈不再往下匹配.</span><br><span class=\"line\">\tif(req.session !&#x3D; Null)&#123;</span><br><span class=\"line\">\t\tnext();</span><br><span class=\"line\">\t&#125;else</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tres.redir(&quot;&#x2F;login&quot;);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;* 2. 内置中间件，托管静态页面, 匹配路由之前, 看public下面有没有匹配的文件, 如果有则返回，没有就继续向下匹配*&#x2F;</span><br><span class=\"line\">&#x2F;&#x2F; 项目部分目录结构: project_name&#x2F;public&#x2F;css&#x2F;style.css</span><br><span class=\"line\">&#x2F;&#x2F; 第一种访问方式: http:&#x2F;&#x2F;127.0.0.1:3000&#x2F;css&#x2F;style.css</span><br><span class=\"line\">app.use(express.static(&#39;public&#39;));</span><br><span class=\"line\">&#x2F;&#x2F; 第二种访问方式: http:&#x2F;&#x2F;127.0.0.1:3000&#x2F;static&#x2F;css&#x2F;style.css</span><br><span class=\"line\">app.use(&quot;&#x2F;static&quot;, express.static(&#39;public&#39;));</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;* 3. 路由中间件app.get(): 匹配某个路由 *&#x2F;</span><br><span class=\"line\">app.get(&quot;&#x2F;&quot;, function(req, res, next)&#123;</span><br><span class=\"line\">\tconsole.log(&quot;您好express&quot;);</span><br><span class=\"line\">\tnext();\t\t\t\t\t\t&#x2F;&#x2F; 缺少next(), 浏览器会一直转圈圈卡着等待服务器继续返回.</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\">app.get(&quot;&#x2F;&quot;, function(req, res)&#123;</span><br><span class=\"line\">\tres.send(&quot;您好express&quot;);\t&#x2F;&#x2F; 匹配到此路由后, res.send()后不需要再next, 浏览器会结束响应.</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;* 1. 应用级中间件app.use()*&#x2F;</span><br><span class=\"line\">app.use(&quot;&#x2F;news&quot;, function(req, res, next)&#123;</span><br><span class=\"line\">\tconsole.log(&quot;应用级中间件匹配news&quot;);</span><br><span class=\"line\">\tnext();</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\">app.get(&quot;&#x2F;news&quot;, function(req, res)&#123;</span><br><span class=\"line\">\tres.send(&quot;news&quot;);</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;* 4. 错误处理中间件, 如果上面路由都没有匹配到，404*&#x2F;</span><br><span class=\"line\">app.use(function(req, res)&#123;</span><br><span class=\"line\">\tres.status(404).send(&quot;这是404，路由没有匹配到&quot;);</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;* 5. 第三方中间件就是官方或者其他人好的中间件，访问https:&#x2F;&#x2F;npmjs.com搜索下载 *&#x2F; </span><br><span class=\"line\">&#x2F;* </span><br><span class=\"line\">* 不用中间件获取post提交数据: req.on(); 用中间件body-parser获取post提交的数据.</span><br><span class=\"line\">* 一: 安装: npm install body-parser --save</span><br><span class=\"line\">* 二: 引用: var bodyParser &#x3D; require(&#39;body-parser&#39;);</span><br><span class=\"line\">* 三：设置中间件</span><br><span class=\"line\">*\t&#x2F;&#x2F; parse application&#x2F;x-www-form-urlencoded</span><br><span class=\"line\">*\tapp.use(bodyParser.urlencoded(&#123;extended: false&#125;))</span><br><span class=\"line\">*\t&#x2F;&#x2F;parse application&#x2F;json</span><br><span class=\"line\">*\tapp.use(bodyParser.json())</span><br><span class=\"line\">* 四: req.body 获取post提交的数据</span><br><span class=\"line\">*&#x2F;</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;&#x2F; 二：引入body-parser中间件</span><br><span class=\"line\">var bodyParser &#x3D; require(&#39;body-parser&#39;);</span><br><span class=\"line\">&#x2F;&#x2F; parse application&#x2F;x-www-form-urlencoded</span><br><span class=\"line\">&#x2F;&#x2F; 三：配置body-parser中间件</span><br><span class=\"line\">app.use(bodyParser.urlencoded(&#123;extended: false&#125;))</span><br><span class=\"line\">&#x2F;&#x2F;parse application&#x2F;json</span><br><span class=\"line\">app.use(bodyParser.json())</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;&#x2F; ejs, 1.安装(package.json)，2.如下配置 ejs引擎</span><br><span class=\"line\">&#x2F;&#x2F; 默认ejs加载的是views下面的视图, 如login.ejs</span><br><span class=\"line\">app.set(&#39;view engine&#39;, &#39;ejs&#39;);</span><br><span class=\"line\">app.get(&#39;&#x2F;login&#39;, function(req, res)&#123;</span><br><span class=\"line\">\tres.render(&#39;login&#39;);</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\">&#x2F;*\tlogin.ejs文件路径: project_name&#x2F;views&#x2F;login.ejs, 内容含有如下表单</span><br><span class=\"line\">* &lt;form action&#x3D;&quot;doLogin&quot; method&#x3D;&quot;post&quot;&gt;</span><br><span class=\"line\">*\t用户名: &lt;input type&#x3D;&quot;text&quot; name&#x3D;&quot;username&quot;&#x2F;&gt;&lt;br&#x2F;&gt;</span><br><span class=\"line\">*\t密  码: &lt;input type&#x3D;&quot;password&quot; name&#x3D;&quot;password&quot;&gt;&lt;br&#x2F;&gt;</span><br><span class=\"line\">*\t&lt;input type&#x3D;&quot;submit&quot; value&#x3D;&quot;登陆&quot;&#x2F;&gt;</span><br><span class=\"line\">* &lt;&#x2F;form&gt;</span><br><span class=\"line\">*&#x2F;</span><br><span class=\"line\">&#x2F;&#x2F; 四：使用req.body 获取post提交的数据 </span><br><span class=\"line\">app.post(&quot;&#x2F;doLogin&quot;, function(req, res)&#123;</span><br><span class=\"line\">\tconsole.log(req.body);</span><br><span class=\"line\">&#125;)</span><br></pre></td></tr></table></figure>"},{"title":"NodeJs简介","_content":"\n### bilibili网址:[https://www.bilibili.com/video/BV1FJ411Q7fi](https://www.bilibili.com/video/BV1FJ411Q7fi)\n\n## node.js 网站\n\n> 1. [node.js官方网站](https://nodejs.org/)\n> 2. [node.js中文网](http://nodejs.cn/)\n> 3. [node.js 中文社区](https://cnodejs.org/)\n\n## NodeJs简介\n * 开发工具: WebStorm, VScode.\n * Node.js是一个javascript运行环境，它让JavaScript可以开发后端程序.\n * Nodejs是基于V8 JS引擎，V8 JS引擎是Google发布的开源JavaScript引擎,本身就是用于Chrome浏览器的JS解析部分.\n * Ryan Dahl把V8 JS引擎搬到了服务器上，用来做服务器的软件.\n * 基于 node.js 可以开发控制台程序（命令行程序、CLI程序）、桌面应用程序（GUI）（借助 node-webkit、electron 等框架实现）、Web 应用程序（网站）\n\n npm 官网: [https://www.npmjs.com/](https://www.npmjs.com/)\n\n * NodeJs语法完全是JS语法，打破了过去JavaScript只能在浏览器中运行的局面，前后端编程环境统一.\n\n * node.js 全栈开发技术栈: MEAN - MongoDB Express Angular Node.js\n\n### node.js 有哪些特点？\n\n> 1. 事件驱动(当事件被触发时，执行传递过去的回调函数)\n> 2. 非阻塞 I/O 模型（当执行I/O操作时，不会阻塞线程）磁盘I/O(文件I/O)，网络I/O(当向网络发送一些数据或接受一些数据也称为I/O)\n> 3. 单线程(V8引擎只有堆deep和一个调用栈stack, 之所以单线程又是非阻塞, 原因是在NodeJs底层开辟一个异步操作来做如写文件等,JS代码依然是单线程, Nodejs底层帮我们把文件写完后，把回调函数放到队列里, NodeJs主线程执行完栈里面函数后，发现队列里有回调函数，就取出来到栈里再执行)\n\t在线动画演示：http://latentflip.com/loupe\n> 4. 拥有世界最大的开源库生态系统 —— npm。\n\n### NodeJs超强的高并发能力\n\tJava、PHP、.net 等服务器端语言中，会为每个客户端创建一个新线程，每个线程需要耗费约2MB内存\n\t理论上，一个8GB内存的服务器可以同时连接的最大用户数为4000个左右，如果要实现进一步的高并发就需要增加服务器的数量，硬件成本就会上升.\n\tNode.js不为每个客户的连接创建一个新的线程，而仅仅使用一个线程，当用户连接就触发一个内部事件，通过非阻塞I/O、事件驱动机制\n\t让Node.js程序宏观上也是并行的. 使用Node.js, 一个8GB内存的服务器，可以同时处理超过4万用户的连接.\n\t总结: 同样的服务器配置，Node.js的并发量将近是传统的后端语言的10倍.\n\n### 实现高性能服务器\n\tV8 JavaScript并不局限于在浏览器中运行，Node.js将其用在了服务器中.\n\t该引擎使用C++语言开发的一种高性能JavaScript引擎，引擎内部使用一种全新的编译技术, 解析并执行JavaScript脚本语言\n\t意味着用JavaScript编写的语言可以有与低端c语言非常相近的执行效率,所以NodeJs是可以实现高性能服务器.\n\n\n#### 非阻塞\n```\nvar fs = require('fs');\nconsole.log('1');\nfs.readFile('my.json', function(err, data){\n\tconsole.log('2');\n})\nconsole.log('3');\n输出：\n1\n3\n2\n```\n\n#### 回调函数\n```\nvar fs=require('fs');\nfunction getmsg(callback){\n\tfs.readFile('my.json', function(err, data){\n\t\tcallback(data);\n\t})\n})\n\ngetmsg(function(data_result){\n\tconsole.log(data_result.toString());\n})\n\n```\n\n\n\n\n","source":"_posts/nodejs/NodeJs简介.md","raw":"---\ntitle: NodeJs简介\ntags:\ncategories:\n- nodejs\n---\n\n### bilibili网址:[https://www.bilibili.com/video/BV1FJ411Q7fi](https://www.bilibili.com/video/BV1FJ411Q7fi)\n\n## node.js 网站\n\n> 1. [node.js官方网站](https://nodejs.org/)\n> 2. [node.js中文网](http://nodejs.cn/)\n> 3. [node.js 中文社区](https://cnodejs.org/)\n\n## NodeJs简介\n * 开发工具: WebStorm, VScode.\n * Node.js是一个javascript运行环境，它让JavaScript可以开发后端程序.\n * Nodejs是基于V8 JS引擎，V8 JS引擎是Google发布的开源JavaScript引擎,本身就是用于Chrome浏览器的JS解析部分.\n * Ryan Dahl把V8 JS引擎搬到了服务器上，用来做服务器的软件.\n * 基于 node.js 可以开发控制台程序（命令行程序、CLI程序）、桌面应用程序（GUI）（借助 node-webkit、electron 等框架实现）、Web 应用程序（网站）\n\n npm 官网: [https://www.npmjs.com/](https://www.npmjs.com/)\n\n * NodeJs语法完全是JS语法，打破了过去JavaScript只能在浏览器中运行的局面，前后端编程环境统一.\n\n * node.js 全栈开发技术栈: MEAN - MongoDB Express Angular Node.js\n\n### node.js 有哪些特点？\n\n> 1. 事件驱动(当事件被触发时，执行传递过去的回调函数)\n> 2. 非阻塞 I/O 模型（当执行I/O操作时，不会阻塞线程）磁盘I/O(文件I/O)，网络I/O(当向网络发送一些数据或接受一些数据也称为I/O)\n> 3. 单线程(V8引擎只有堆deep和一个调用栈stack, 之所以单线程又是非阻塞, 原因是在NodeJs底层开辟一个异步操作来做如写文件等,JS代码依然是单线程, Nodejs底层帮我们把文件写完后，把回调函数放到队列里, NodeJs主线程执行完栈里面函数后，发现队列里有回调函数，就取出来到栈里再执行)\n\t在线动画演示：http://latentflip.com/loupe\n> 4. 拥有世界最大的开源库生态系统 —— npm。\n\n### NodeJs超强的高并发能力\n\tJava、PHP、.net 等服务器端语言中，会为每个客户端创建一个新线程，每个线程需要耗费约2MB内存\n\t理论上，一个8GB内存的服务器可以同时连接的最大用户数为4000个左右，如果要实现进一步的高并发就需要增加服务器的数量，硬件成本就会上升.\n\tNode.js不为每个客户的连接创建一个新的线程，而仅仅使用一个线程，当用户连接就触发一个内部事件，通过非阻塞I/O、事件驱动机制\n\t让Node.js程序宏观上也是并行的. 使用Node.js, 一个8GB内存的服务器，可以同时处理超过4万用户的连接.\n\t总结: 同样的服务器配置，Node.js的并发量将近是传统的后端语言的10倍.\n\n### 实现高性能服务器\n\tV8 JavaScript并不局限于在浏览器中运行，Node.js将其用在了服务器中.\n\t该引擎使用C++语言开发的一种高性能JavaScript引擎，引擎内部使用一种全新的编译技术, 解析并执行JavaScript脚本语言\n\t意味着用JavaScript编写的语言可以有与低端c语言非常相近的执行效率,所以NodeJs是可以实现高性能服务器.\n\n\n#### 非阻塞\n```\nvar fs = require('fs');\nconsole.log('1');\nfs.readFile('my.json', function(err, data){\n\tconsole.log('2');\n})\nconsole.log('3');\n输出：\n1\n3\n2\n```\n\n#### 回调函数\n```\nvar fs=require('fs');\nfunction getmsg(callback){\n\tfs.readFile('my.json', function(err, data){\n\t\tcallback(data);\n\t})\n})\n\ngetmsg(function(data_result){\n\tconsole.log(data_result.toString());\n})\n\n```\n\n\n\n\n","slug":"nodejs/NodeJs简介","published":1,"date":"2020-08-12T16:05:47.832Z","updated":"2020-04-12T18:13:10.629Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmgr005zhohxaokzg9dk","content":"<h3 id=\"bilibili网址-https-www-bilibili-com-video-BV1FJ411Q7fi\"><a href=\"#bilibili网址-https-www-bilibili-com-video-BV1FJ411Q7fi\" class=\"headerlink\" title=\"bilibili网址:https://www.bilibili.com/video/BV1FJ411Q7fi\"></a>bilibili网址:<a href=\"https://www.bilibili.com/video/BV1FJ411Q7fi\" target=\"_blank\" rel=\"noopener\">https://www.bilibili.com/video/BV1FJ411Q7fi</a></h3><h2 id=\"node-js-网站\"><a href=\"#node-js-网站\" class=\"headerlink\" title=\"node.js 网站\"></a>node.js 网站</h2><blockquote>\n<ol>\n<li><a href=\"https://nodejs.org/\" target=\"_blank\" rel=\"noopener\">node.js官方网站</a></li>\n<li><a href=\"http://nodejs.cn/\" target=\"_blank\" rel=\"noopener\">node.js中文网</a></li>\n<li><a href=\"https://cnodejs.org/\" target=\"_blank\" rel=\"noopener\">node.js 中文社区</a></li>\n</ol>\n</blockquote>\n<h2 id=\"NodeJs简介\"><a href=\"#NodeJs简介\" class=\"headerlink\" title=\"NodeJs简介\"></a>NodeJs简介</h2><ul>\n<li><p>开发工具: WebStorm, VScode.</p>\n</li>\n<li><p>Node.js是一个javascript运行环境，它让JavaScript可以开发后端程序.</p>\n</li>\n<li><p>Nodejs是基于V8 JS引擎，V8 JS引擎是Google发布的开源JavaScript引擎,本身就是用于Chrome浏览器的JS解析部分.</p>\n</li>\n<li><p>Ryan Dahl把V8 JS引擎搬到了服务器上，用来做服务器的软件.</p>\n</li>\n<li><p>基于 node.js 可以开发控制台程序（命令行程序、CLI程序）、桌面应用程序（GUI）（借助 node-webkit、electron 等框架实现）、Web 应用程序（网站）</p>\n<p>npm 官网: <a href=\"https://www.npmjs.com/\" target=\"_blank\" rel=\"noopener\">https://www.npmjs.com/</a></p>\n</li>\n<li><p>NodeJs语法完全是JS语法，打破了过去JavaScript只能在浏览器中运行的局面，前后端编程环境统一.</p>\n</li>\n<li><p>node.js 全栈开发技术栈: MEAN - MongoDB Express Angular Node.js</p>\n</li>\n</ul>\n<h3 id=\"node-js-有哪些特点？\"><a href=\"#node-js-有哪些特点？\" class=\"headerlink\" title=\"node.js 有哪些特点？\"></a>node.js 有哪些特点？</h3><blockquote>\n<ol>\n<li>事件驱动(当事件被触发时，执行传递过去的回调函数)</li>\n<li>非阻塞 I/O 模型（当执行I/O操作时，不会阻塞线程）磁盘I/O(文件I/O)，网络I/O(当向网络发送一些数据或接受一些数据也称为I/O)</li>\n<li>单线程(V8引擎只有堆deep和一个调用栈stack, 之所以单线程又是非阻塞, 原因是在NodeJs底层开辟一个异步操作来做如写文件等,JS代码依然是单线程, Nodejs底层帮我们把文件写完后，把回调函数放到队列里, NodeJs主线程执行完栈里面函数后，发现队列里有回调函数，就取出来到栈里再执行)<br> 在线动画演示：<a href=\"http://latentflip.com/loupe\" target=\"_blank\" rel=\"noopener\">http://latentflip.com/loupe</a></li>\n<li>拥有世界最大的开源库生态系统 —— npm。</li>\n</ol>\n</blockquote>\n<h3 id=\"NodeJs超强的高并发能力\"><a href=\"#NodeJs超强的高并发能力\" class=\"headerlink\" title=\"NodeJs超强的高并发能力\"></a>NodeJs超强的高并发能力</h3><pre><code>Java、PHP、.net 等服务器端语言中，会为每个客户端创建一个新线程，每个线程需要耗费约2MB内存\n理论上，一个8GB内存的服务器可以同时连接的最大用户数为4000个左右，如果要实现进一步的高并发就需要增加服务器的数量，硬件成本就会上升.\nNode.js不为每个客户的连接创建一个新的线程，而仅仅使用一个线程，当用户连接就触发一个内部事件，通过非阻塞I/O、事件驱动机制\n让Node.js程序宏观上也是并行的. 使用Node.js, 一个8GB内存的服务器，可以同时处理超过4万用户的连接.\n总结: 同样的服务器配置，Node.js的并发量将近是传统的后端语言的10倍.</code></pre><h3 id=\"实现高性能服务器\"><a href=\"#实现高性能服务器\" class=\"headerlink\" title=\"实现高性能服务器\"></a>实现高性能服务器</h3><pre><code>V8 JavaScript并不局限于在浏览器中运行，Node.js将其用在了服务器中.\n该引擎使用C++语言开发的一种高性能JavaScript引擎，引擎内部使用一种全新的编译技术, 解析并执行JavaScript脚本语言\n意味着用JavaScript编写的语言可以有与低端c语言非常相近的执行效率,所以NodeJs是可以实现高性能服务器.</code></pre><h4 id=\"非阻塞\"><a href=\"#非阻塞\" class=\"headerlink\" title=\"非阻塞\"></a>非阻塞</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var fs &#x3D; require(&#39;fs&#39;);</span><br><span class=\"line\">console.log(&#39;1&#39;);</span><br><span class=\"line\">fs.readFile(&#39;my.json&#39;, function(err, data)&#123;</span><br><span class=\"line\">\tconsole.log(&#39;2&#39;);</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\">console.log(&#39;3&#39;);</span><br><span class=\"line\">输出：</span><br><span class=\"line\">1</span><br><span class=\"line\">3</span><br><span class=\"line\">2</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"回调函数\"><a href=\"#回调函数\" class=\"headerlink\" title=\"回调函数\"></a>回调函数</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var fs&#x3D;require(&#39;fs&#39;);</span><br><span class=\"line\">function getmsg(callback)&#123;</span><br><span class=\"line\">\tfs.readFile(&#39;my.json&#39;, function(err, data)&#123;</span><br><span class=\"line\">\t\tcallback(data);</span><br><span class=\"line\">\t&#125;)</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">getmsg(function(data_result)&#123;</span><br><span class=\"line\">\tconsole.log(data_result.toString());</span><br><span class=\"line\">&#125;)</span><br></pre></td></tr></table></figure>\n\n\n\n\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"bilibili网址-https-www-bilibili-com-video-BV1FJ411Q7fi\"><a href=\"#bilibili网址-https-www-bilibili-com-video-BV1FJ411Q7fi\" class=\"headerlink\" title=\"bilibili网址:https://www.bilibili.com/video/BV1FJ411Q7fi\"></a>bilibili网址:<a href=\"https://www.bilibili.com/video/BV1FJ411Q7fi\" target=\"_blank\" rel=\"noopener\">https://www.bilibili.com/video/BV1FJ411Q7fi</a></h3><h2 id=\"node-js-网站\"><a href=\"#node-js-网站\" class=\"headerlink\" title=\"node.js 网站\"></a>node.js 网站</h2><blockquote>\n<ol>\n<li><a href=\"https://nodejs.org/\" target=\"_blank\" rel=\"noopener\">node.js官方网站</a></li>\n<li><a href=\"http://nodejs.cn/\" target=\"_blank\" rel=\"noopener\">node.js中文网</a></li>\n<li><a href=\"https://cnodejs.org/\" target=\"_blank\" rel=\"noopener\">node.js 中文社区</a></li>\n</ol>\n</blockquote>\n<h2 id=\"NodeJs简介\"><a href=\"#NodeJs简介\" class=\"headerlink\" title=\"NodeJs简介\"></a>NodeJs简介</h2><ul>\n<li><p>开发工具: WebStorm, VScode.</p>\n</li>\n<li><p>Node.js是一个javascript运行环境，它让JavaScript可以开发后端程序.</p>\n</li>\n<li><p>Nodejs是基于V8 JS引擎，V8 JS引擎是Google发布的开源JavaScript引擎,本身就是用于Chrome浏览器的JS解析部分.</p>\n</li>\n<li><p>Ryan Dahl把V8 JS引擎搬到了服务器上，用来做服务器的软件.</p>\n</li>\n<li><p>基于 node.js 可以开发控制台程序（命令行程序、CLI程序）、桌面应用程序（GUI）（借助 node-webkit、electron 等框架实现）、Web 应用程序（网站）</p>\n<p>npm 官网: <a href=\"https://www.npmjs.com/\" target=\"_blank\" rel=\"noopener\">https://www.npmjs.com/</a></p>\n</li>\n<li><p>NodeJs语法完全是JS语法，打破了过去JavaScript只能在浏览器中运行的局面，前后端编程环境统一.</p>\n</li>\n<li><p>node.js 全栈开发技术栈: MEAN - MongoDB Express Angular Node.js</p>\n</li>\n</ul>\n<h3 id=\"node-js-有哪些特点？\"><a href=\"#node-js-有哪些特点？\" class=\"headerlink\" title=\"node.js 有哪些特点？\"></a>node.js 有哪些特点？</h3><blockquote>\n<ol>\n<li>事件驱动(当事件被触发时，执行传递过去的回调函数)</li>\n<li>非阻塞 I/O 模型（当执行I/O操作时，不会阻塞线程）磁盘I/O(文件I/O)，网络I/O(当向网络发送一些数据或接受一些数据也称为I/O)</li>\n<li>单线程(V8引擎只有堆deep和一个调用栈stack, 之所以单线程又是非阻塞, 原因是在NodeJs底层开辟一个异步操作来做如写文件等,JS代码依然是单线程, Nodejs底层帮我们把文件写完后，把回调函数放到队列里, NodeJs主线程执行完栈里面函数后，发现队列里有回调函数，就取出来到栈里再执行)<br> 在线动画演示：<a href=\"http://latentflip.com/loupe\" target=\"_blank\" rel=\"noopener\">http://latentflip.com/loupe</a></li>\n<li>拥有世界最大的开源库生态系统 —— npm。</li>\n</ol>\n</blockquote>\n<h3 id=\"NodeJs超强的高并发能力\"><a href=\"#NodeJs超强的高并发能力\" class=\"headerlink\" title=\"NodeJs超强的高并发能力\"></a>NodeJs超强的高并发能力</h3><pre><code>Java、PHP、.net 等服务器端语言中，会为每个客户端创建一个新线程，每个线程需要耗费约2MB内存\n理论上，一个8GB内存的服务器可以同时连接的最大用户数为4000个左右，如果要实现进一步的高并发就需要增加服务器的数量，硬件成本就会上升.\nNode.js不为每个客户的连接创建一个新的线程，而仅仅使用一个线程，当用户连接就触发一个内部事件，通过非阻塞I/O、事件驱动机制\n让Node.js程序宏观上也是并行的. 使用Node.js, 一个8GB内存的服务器，可以同时处理超过4万用户的连接.\n总结: 同样的服务器配置，Node.js的并发量将近是传统的后端语言的10倍.</code></pre><h3 id=\"实现高性能服务器\"><a href=\"#实现高性能服务器\" class=\"headerlink\" title=\"实现高性能服务器\"></a>实现高性能服务器</h3><pre><code>V8 JavaScript并不局限于在浏览器中运行，Node.js将其用在了服务器中.\n该引擎使用C++语言开发的一种高性能JavaScript引擎，引擎内部使用一种全新的编译技术, 解析并执行JavaScript脚本语言\n意味着用JavaScript编写的语言可以有与低端c语言非常相近的执行效率,所以NodeJs是可以实现高性能服务器.</code></pre><h4 id=\"非阻塞\"><a href=\"#非阻塞\" class=\"headerlink\" title=\"非阻塞\"></a>非阻塞</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var fs &#x3D; require(&#39;fs&#39;);</span><br><span class=\"line\">console.log(&#39;1&#39;);</span><br><span class=\"line\">fs.readFile(&#39;my.json&#39;, function(err, data)&#123;</span><br><span class=\"line\">\tconsole.log(&#39;2&#39;);</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\">console.log(&#39;3&#39;);</span><br><span class=\"line\">输出：</span><br><span class=\"line\">1</span><br><span class=\"line\">3</span><br><span class=\"line\">2</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"回调函数\"><a href=\"#回调函数\" class=\"headerlink\" title=\"回调函数\"></a>回调函数</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var fs&#x3D;require(&#39;fs&#39;);</span><br><span class=\"line\">function getmsg(callback)&#123;</span><br><span class=\"line\">\tfs.readFile(&#39;my.json&#39;, function(err, data)&#123;</span><br><span class=\"line\">\t\tcallback(data);</span><br><span class=\"line\">\t&#125;)</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">getmsg(function(data_result)&#123;</span><br><span class=\"line\">\tconsole.log(data_result.toString());</span><br><span class=\"line\">&#125;)</span><br></pre></td></tr></table></figure>\n\n\n\n\n"},{"title":"4.node_modules","_content":"\n### 设置淘宝镜像\n\t$npm install -g cnpm --registry=https://registry.npm.taobao.org\n\t之后就可以用$cnpm install 来安装包\n![](taobao_mirror.PNG)\n\n### 先执行如下命令create package.json\npackage.json和package-lock.json可以在把项目发送给别人后便于别人查看和下载node_modules\n当接到新的NodeJS平台项目后，直接cd到项目目录然后$npm install就可以安装项目所需的所有node modules\n\t$cd 项目目录\n\t$npm init\t\t// create package.json文件\n\t\tinit过程中默认回车就可以了\n\t\tPress ^C at any time to quit.\n\t\tpackage name: (workspace)\t//默认入口项目名\n\t\tversion: (1.0.0)\n\t\tdescription:\n\t\tentry point: (index.js)\n\t\ttest command:\n\t\tgit repository:\n\t\tkeywords:\n\t\tauthor:\n\t\tlicense: (ISC)\n\t\tAbout to write to F:\n\t$npm install 包\t// 会自动创建package-lock.json文件\n\t\n\n### supervisor\n这个包用来启动如app.js等服务文件，当源码里有代码改变时，supervisor会自动重启服务，浏览器直接刷新就可看到更改\n\tnpm -g install supervisor\n\t$supervisor app.js\n\n\n\n","source":"_posts/nodejs/4.node_modules.md","raw":"---\ntitle: 4.node_modules\ntags:\ncategories:\n- nodejs\n---\n\n### 设置淘宝镜像\n\t$npm install -g cnpm --registry=https://registry.npm.taobao.org\n\t之后就可以用$cnpm install 来安装包\n![](taobao_mirror.PNG)\n\n### 先执行如下命令create package.json\npackage.json和package-lock.json可以在把项目发送给别人后便于别人查看和下载node_modules\n当接到新的NodeJS平台项目后，直接cd到项目目录然后$npm install就可以安装项目所需的所有node modules\n\t$cd 项目目录\n\t$npm init\t\t// create package.json文件\n\t\tinit过程中默认回车就可以了\n\t\tPress ^C at any time to quit.\n\t\tpackage name: (workspace)\t//默认入口项目名\n\t\tversion: (1.0.0)\n\t\tdescription:\n\t\tentry point: (index.js)\n\t\ttest command:\n\t\tgit repository:\n\t\tkeywords:\n\t\tauthor:\n\t\tlicense: (ISC)\n\t\tAbout to write to F:\n\t$npm install 包\t// 会自动创建package-lock.json文件\n\t\n\n### supervisor\n这个包用来启动如app.js等服务文件，当源码里有代码改变时，supervisor会自动重启服务，浏览器直接刷新就可看到更改\n\tnpm -g install supervisor\n\t$supervisor app.js\n\n\n\n","slug":"nodejs/4.node_modules","published":1,"date":"2020-08-12T16:05:47.807Z","updated":"2020-08-12T11:35:12.832Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmgs0062hohx5y1t6596","content":"<h3 id=\"设置淘宝镜像\"><a href=\"#设置淘宝镜像\" class=\"headerlink\" title=\"设置淘宝镜像\"></a>设置淘宝镜像</h3><pre><code>$npm install -g cnpm --registry=https://registry.npm.taobao.org\n之后就可以用$cnpm install 来安装包</code></pre><p><img src=\"taobao_mirror.PNG\" alt=\"\"></p>\n<h3 id=\"先执行如下命令create-package-json\"><a href=\"#先执行如下命令create-package-json\" class=\"headerlink\" title=\"先执行如下命令create package.json\"></a>先执行如下命令create package.json</h3><p>package.json和package-lock.json可以在把项目发送给别人后便于别人查看和下载node_modules<br>当接到新的NodeJS平台项目后，直接cd到项目目录然后$npm install就可以安装项目所需的所有node modules<br>    $cd 项目目录<br>    $npm init        // create package.json文件<br>        init过程中默认回车就可以了<br>        Press ^C at any time to quit.<br>        package name: (workspace)    //默认入口项目名<br>        version: (1.0.0)<br>        description:<br>        entry point: (index.js)<br>        test command:<br>        git repository:<br>        keywords:<br>        author:<br>        license: (ISC)<br>        About to write to F:<br>    $npm install 包    // 会自动创建package-lock.json文件</p>\n<h3 id=\"supervisor\"><a href=\"#supervisor\" class=\"headerlink\" title=\"supervisor\"></a>supervisor</h3><p>这个包用来启动如app.js等服务文件，当源码里有代码改变时，supervisor会自动重启服务，浏览器直接刷新就可看到更改<br>    npm -g install supervisor<br>    $supervisor app.js</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"设置淘宝镜像\"><a href=\"#设置淘宝镜像\" class=\"headerlink\" title=\"设置淘宝镜像\"></a>设置淘宝镜像</h3><pre><code>$npm install -g cnpm --registry=https://registry.npm.taobao.org\n之后就可以用$cnpm install 来安装包</code></pre><p><img src=\"taobao_mirror.PNG\" alt=\"\"></p>\n<h3 id=\"先执行如下命令create-package-json\"><a href=\"#先执行如下命令create-package-json\" class=\"headerlink\" title=\"先执行如下命令create package.json\"></a>先执行如下命令create package.json</h3><p>package.json和package-lock.json可以在把项目发送给别人后便于别人查看和下载node_modules<br>当接到新的NodeJS平台项目后，直接cd到项目目录然后$npm install就可以安装项目所需的所有node modules<br>    $cd 项目目录<br>    $npm init        // create package.json文件<br>        init过程中默认回车就可以了<br>        Press ^C at any time to quit.<br>        package name: (workspace)    //默认入口项目名<br>        version: (1.0.0)<br>        description:<br>        entry point: (index.js)<br>        test command:<br>        git repository:<br>        keywords:<br>        author:<br>        license: (ISC)<br>        About to write to F:<br>    $npm install 包    // 会自动创建package-lock.json文件</p>\n<h3 id=\"supervisor\"><a href=\"#supervisor\" class=\"headerlink\" title=\"supervisor\"></a>supervisor</h3><p>这个包用来启动如app.js等服务文件，当源码里有代码改变时，supervisor会自动重启服务，浏览器直接刷新就可看到更改<br>    npm -g install supervisor<br>    $supervisor app.js</p>\n"},{"title":"浏览器工作原理","_content":"\n## 浏览器的组成\n- 人机交互部分（UI）\n- 网络请求部分（Socket）\n- JavaScript引擎部分（解析执行JavaScript）\n- 渲染引擎部分（渲染HTML、CSS等）\n- 数据存储部分（cookie、HTML5中的本地存储LocalStorage、SessionStorage）\n\nsqlite\n\n\n## 主流渲染引擎\n\n### 介绍\n1. 渲染引擎 又叫 排版引擎 或 浏览器内核。\n\n2. 主流的 渲染引擎 有\n  - **Chrome浏览器**: Blink引擎（WebKit的一个分支）。\n  - **Safari浏览器**: WebKit引擎，windows版本2008年3月18日推出正式版，但苹果已于2012年7月25日停止开发Windows版的Safari。\n  - **FireFox浏览器**: Gecko引擎。\n  - **Opera浏览器**: Blink引擎(早期版使用Presto引擎）。\n  - **Internet Explorer浏览器**: Trident引擎。\n  - **Microsoft Edge浏览器**: EdgeHTML引擎（Trident的一个分支）。\n\n\n### 工作原理\n1. 解析HTML构建Dom树（Document Object Model，文档对象模型），DOM 是W3C组织推荐的处理可扩展置标语言的标准编程接口。\n\n2. 构建*渲染树*，*渲染树*并不等同于*Dom树*，因为像`head标签 或 display: none`这样的元素就没有必要放到*渲染树*中了，但是它们在*Dom树*中。\n\n3. 对*渲染树*进行布局，定位坐标和大小、确定是否换行、确定position、overflow、z-index等等，这个过程叫`\"layout\" 或 \"reflow\"`。\n\n4. 绘制*渲染树*，调用操作系统底层API进行绘图操作。\n\n\n\n### 渲染引擎工作原理示意图\n\n**渲染引擎工作原理示意图**\n\n![渲染引擎工作原理](flow.png)\n\n\n**WebKit工作原理（Chrome、Safari、Opera）**\n\n![Blink渲染引擎工作原理](webkitflow.png)\n\n\n**Gecko工作原理（FireFox）**\n\n![Gecko渲染引擎工作原理](gecko.jpg)\n\n\n\n### 浏览器的 reflow 或 layout 过程\n\nhttps://www.youtube.com/watch?v=ZTnIxIA5KGw\n\n\n\n\n\n### 打开 Chrome 的 Rendering 功能\n\n第一步：\n\n![第一步](chrome_rendering1.png)\n\n第二步：\n\n![第二步](chrome_rendering2.png)\n\n\n\n\n\n## 浏览器访问网站过程\n\n> 1. 在浏览器地址栏中输入网址。\n\n![淘宝网址](taobao_url.png)\n\n> 2. 浏览器通过用户在地址栏中输入的URL构建HTTP请求报文。\n\n```http\nGET / HTTP/1.1\nHost: www.taobao.com\nConnection: keep-alive\nUpgrade-Insecure-Requests: 1\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\nAccept-Encoding: gzip, deflate, sdch, br\nAccept-Language: zh-CN,zh;q=0.8,en;q=0.6\nCookie: l=Ag0NWp9E8X4hgaGEtIBhOmKxnSOH6kG8; isg=AkZGLTL-Yr9tHDZbgd5bsn4Rlzwg5IphaK-1BzBvMmlEM-ZNmDfacSyDfdgF; thw=cn\n```\n\n> 3. 浏览器发起DNS解析请求，将域名转换为IP地址。\n\n![淘宝网址](taobao_ip.png)\n\n> 4. 浏览器将请求报文发送给服务器。\n\n> 5. 服务器接收请求报文，并解析。\n\n> 6. 服务器处理用户请求，并将处理结果封装成HTTP响应报文。\n\n```http\nHTTP/1.1 200 OK\nServer: Tengine\nDate: Thu, 13 Apr 2017 02:24:25 GMT\nContent-Type: text/html; charset=utf-8\nTransfer-Encoding: chunked\nConnection: keep-alive\nVary: Accept-Encoding\nVary: Ali-Detector-Type, X-CIP-PT\nCache-Control: max-age=0, s-maxage=300\nVia: cache8.l2cm10-1[172,200-0,C], cache13.l2cm10-1[122,0], cache3.cn206[0,200-0,H], cache6.cn206[0,0]\nAge: 293\nX-Cache: HIT TCP_MEM_HIT dirn:-2:-2\nX-Swift-SaveTime: Thu, 13 Apr 2017 02:19:32 GMT\nX-Swift-CacheTime: 300\nTiming-Allow-Origin: *\nEagleId: 9903e7e514920502659594264e\nStrict-Transport-Security: max-age=31536000\nContent-Encoding: gzip\n\n<!DOCTYPE html>\n<html lang=\"zh-CN\">\n<head>\n<meta charset=\"utf-8\" />\n<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" />\n<meta name=\"renderer\" content=\"webkit\" />\n<title>淘宝网 - 淘！我喜欢</title>\n<meta name=\"spm-id\" content=\"a21bo\" />\n<meta name=\"description\" content=\"淘宝网 - 亚洲较大的网上交易平台，提供各类服饰、美容、家居、数码、话费/点卡充值… 数亿优质商品，同时提供担保交易(先收货后付款)等安全交易保障服务，并由商家提供退货承诺、破损补寄等消费者保障服务，让你安心享受网上购物乐趣！\" />\n<meta name=\"aplus-xplug\" content=\"NONE\">\n<meta name=\"keyword\" content=\"淘宝,掏宝,网上购物,C2C,在线交易,交易市场,网上交易,交易市场,网上买,网上卖,购物网站,团购,网上贸易,安全购物,电子商务,放心买,供应,买卖信息,网店,一口价,拍卖,网上开店,网络购物,打折,免费开店,网购,频道,店铺\" />\n</head>\n<body>\n......\n</body>\n</html>\n```\n\n> 7. 服务器将HTTP响应报文发送给浏览器。\n\n> 8. 浏览器接收服务器响应的HTTP报文，并解析。\n\n> 9. 浏览器解析 HTML 页面并展示，在解析HTML页面时遇到新的资源需要再次发起请求。\n\n> 10. 最终浏览器展示出了页面\n\n\n\n\n\n\n## HTTP请求报文和响应报文格式\n\n![http请求报文和响应报文](HTTPMsgStructure2.png)\n\n\n\n\n## DNS 解析过程\n\n![DNS解析过程](DNS.gif)\n\n\n### windows 下 hosts 文件位置\n\nC:\\Windows\\System32\\drivers\\etc\\hosts\n\n\n\n\n\n## DOM 解析\n\n参考代码:\n\n```html\n<html>\n  <body>\n    <p>Hello World</p>\n    <div> <img src=\"example.png\" alt=\"example\"/></div>\n  </body>\n</html>\n```\n\n![Dom 解析工作原理](dom.png)\n\n\n\n## Webkit CSS 解析\n\n![CSS 解析工作原理](css_parser.png)\n\n\n\n## How Browsers work - 浏览器是如何工作的\n\n[How Browsers work](http://taligarsiel.com/Projects/howbrowserswork1.htm#The_browsers_we_will_talk_about)\nhttps://www.html5rocks.com/zh/tutorials/internals/howbrowserswork/\n\n\n\n\n","source":"_posts/nodejs/浏览器工作原理.md","raw":"---\ntitle: 浏览器工作原理\ntags:\ncategories:\n- nodejs\n---\n\n## 浏览器的组成\n- 人机交互部分（UI）\n- 网络请求部分（Socket）\n- JavaScript引擎部分（解析执行JavaScript）\n- 渲染引擎部分（渲染HTML、CSS等）\n- 数据存储部分（cookie、HTML5中的本地存储LocalStorage、SessionStorage）\n\nsqlite\n\n\n## 主流渲染引擎\n\n### 介绍\n1. 渲染引擎 又叫 排版引擎 或 浏览器内核。\n\n2. 主流的 渲染引擎 有\n  - **Chrome浏览器**: Blink引擎（WebKit的一个分支）。\n  - **Safari浏览器**: WebKit引擎，windows版本2008年3月18日推出正式版，但苹果已于2012年7月25日停止开发Windows版的Safari。\n  - **FireFox浏览器**: Gecko引擎。\n  - **Opera浏览器**: Blink引擎(早期版使用Presto引擎）。\n  - **Internet Explorer浏览器**: Trident引擎。\n  - **Microsoft Edge浏览器**: EdgeHTML引擎（Trident的一个分支）。\n\n\n### 工作原理\n1. 解析HTML构建Dom树（Document Object Model，文档对象模型），DOM 是W3C组织推荐的处理可扩展置标语言的标准编程接口。\n\n2. 构建*渲染树*，*渲染树*并不等同于*Dom树*，因为像`head标签 或 display: none`这样的元素就没有必要放到*渲染树*中了，但是它们在*Dom树*中。\n\n3. 对*渲染树*进行布局，定位坐标和大小、确定是否换行、确定position、overflow、z-index等等，这个过程叫`\"layout\" 或 \"reflow\"`。\n\n4. 绘制*渲染树*，调用操作系统底层API进行绘图操作。\n\n\n\n### 渲染引擎工作原理示意图\n\n**渲染引擎工作原理示意图**\n\n![渲染引擎工作原理](flow.png)\n\n\n**WebKit工作原理（Chrome、Safari、Opera）**\n\n![Blink渲染引擎工作原理](webkitflow.png)\n\n\n**Gecko工作原理（FireFox）**\n\n![Gecko渲染引擎工作原理](gecko.jpg)\n\n\n\n### 浏览器的 reflow 或 layout 过程\n\nhttps://www.youtube.com/watch?v=ZTnIxIA5KGw\n\n\n\n\n\n### 打开 Chrome 的 Rendering 功能\n\n第一步：\n\n![第一步](chrome_rendering1.png)\n\n第二步：\n\n![第二步](chrome_rendering2.png)\n\n\n\n\n\n## 浏览器访问网站过程\n\n> 1. 在浏览器地址栏中输入网址。\n\n![淘宝网址](taobao_url.png)\n\n> 2. 浏览器通过用户在地址栏中输入的URL构建HTTP请求报文。\n\n```http\nGET / HTTP/1.1\nHost: www.taobao.com\nConnection: keep-alive\nUpgrade-Insecure-Requests: 1\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\nAccept-Encoding: gzip, deflate, sdch, br\nAccept-Language: zh-CN,zh;q=0.8,en;q=0.6\nCookie: l=Ag0NWp9E8X4hgaGEtIBhOmKxnSOH6kG8; isg=AkZGLTL-Yr9tHDZbgd5bsn4Rlzwg5IphaK-1BzBvMmlEM-ZNmDfacSyDfdgF; thw=cn\n```\n\n> 3. 浏览器发起DNS解析请求，将域名转换为IP地址。\n\n![淘宝网址](taobao_ip.png)\n\n> 4. 浏览器将请求报文发送给服务器。\n\n> 5. 服务器接收请求报文，并解析。\n\n> 6. 服务器处理用户请求，并将处理结果封装成HTTP响应报文。\n\n```http\nHTTP/1.1 200 OK\nServer: Tengine\nDate: Thu, 13 Apr 2017 02:24:25 GMT\nContent-Type: text/html; charset=utf-8\nTransfer-Encoding: chunked\nConnection: keep-alive\nVary: Accept-Encoding\nVary: Ali-Detector-Type, X-CIP-PT\nCache-Control: max-age=0, s-maxage=300\nVia: cache8.l2cm10-1[172,200-0,C], cache13.l2cm10-1[122,0], cache3.cn206[0,200-0,H], cache6.cn206[0,0]\nAge: 293\nX-Cache: HIT TCP_MEM_HIT dirn:-2:-2\nX-Swift-SaveTime: Thu, 13 Apr 2017 02:19:32 GMT\nX-Swift-CacheTime: 300\nTiming-Allow-Origin: *\nEagleId: 9903e7e514920502659594264e\nStrict-Transport-Security: max-age=31536000\nContent-Encoding: gzip\n\n<!DOCTYPE html>\n<html lang=\"zh-CN\">\n<head>\n<meta charset=\"utf-8\" />\n<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" />\n<meta name=\"renderer\" content=\"webkit\" />\n<title>淘宝网 - 淘！我喜欢</title>\n<meta name=\"spm-id\" content=\"a21bo\" />\n<meta name=\"description\" content=\"淘宝网 - 亚洲较大的网上交易平台，提供各类服饰、美容、家居、数码、话费/点卡充值… 数亿优质商品，同时提供担保交易(先收货后付款)等安全交易保障服务，并由商家提供退货承诺、破损补寄等消费者保障服务，让你安心享受网上购物乐趣！\" />\n<meta name=\"aplus-xplug\" content=\"NONE\">\n<meta name=\"keyword\" content=\"淘宝,掏宝,网上购物,C2C,在线交易,交易市场,网上交易,交易市场,网上买,网上卖,购物网站,团购,网上贸易,安全购物,电子商务,放心买,供应,买卖信息,网店,一口价,拍卖,网上开店,网络购物,打折,免费开店,网购,频道,店铺\" />\n</head>\n<body>\n......\n</body>\n</html>\n```\n\n> 7. 服务器将HTTP响应报文发送给浏览器。\n\n> 8. 浏览器接收服务器响应的HTTP报文，并解析。\n\n> 9. 浏览器解析 HTML 页面并展示，在解析HTML页面时遇到新的资源需要再次发起请求。\n\n> 10. 最终浏览器展示出了页面\n\n\n\n\n\n\n## HTTP请求报文和响应报文格式\n\n![http请求报文和响应报文](HTTPMsgStructure2.png)\n\n\n\n\n## DNS 解析过程\n\n![DNS解析过程](DNS.gif)\n\n\n### windows 下 hosts 文件位置\n\nC:\\Windows\\System32\\drivers\\etc\\hosts\n\n\n\n\n\n## DOM 解析\n\n参考代码:\n\n```html\n<html>\n  <body>\n    <p>Hello World</p>\n    <div> <img src=\"example.png\" alt=\"example\"/></div>\n  </body>\n</html>\n```\n\n![Dom 解析工作原理](dom.png)\n\n\n\n## Webkit CSS 解析\n\n![CSS 解析工作原理](css_parser.png)\n\n\n\n## How Browsers work - 浏览器是如何工作的\n\n[How Browsers work](http://taligarsiel.com/Projects/howbrowserswork1.htm#The_browsers_we_will_talk_about)\nhttps://www.html5rocks.com/zh/tutorials/internals/howbrowserswork/\n\n\n\n\n","slug":"nodejs/浏览器工作原理","published":1,"date":"2020-08-12T16:05:47.845Z","updated":"2020-04-12T17:28:20.398Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmgt0064hohx2ce45l3g","content":"<h2 id=\"浏览器的组成\"><a href=\"#浏览器的组成\" class=\"headerlink\" title=\"浏览器的组成\"></a>浏览器的组成</h2><ul>\n<li>人机交互部分（UI）</li>\n<li>网络请求部分（Socket）</li>\n<li>JavaScript引擎部分（解析执行JavaScript）</li>\n<li>渲染引擎部分（渲染HTML、CSS等）</li>\n<li>数据存储部分（cookie、HTML5中的本地存储LocalStorage、SessionStorage）</li>\n</ul>\n<p>sqlite</p>\n<h2 id=\"主流渲染引擎\"><a href=\"#主流渲染引擎\" class=\"headerlink\" title=\"主流渲染引擎\"></a>主流渲染引擎</h2><h3 id=\"介绍\"><a href=\"#介绍\" class=\"headerlink\" title=\"介绍\"></a>介绍</h3><ol>\n<li><p>渲染引擎 又叫 排版引擎 或 浏览器内核。</p>\n</li>\n<li><p>主流的 渲染引擎 有</p>\n<ul>\n<li><strong>Chrome浏览器</strong>: Blink引擎（WebKit的一个分支）。</li>\n<li><strong>Safari浏览器</strong>: WebKit引擎，windows版本2008年3月18日推出正式版，但苹果已于2012年7月25日停止开发Windows版的Safari。</li>\n<li><strong>FireFox浏览器</strong>: Gecko引擎。</li>\n<li><strong>Opera浏览器</strong>: Blink引擎(早期版使用Presto引擎）。</li>\n<li><strong>Internet Explorer浏览器</strong>: Trident引擎。</li>\n<li><strong>Microsoft Edge浏览器</strong>: EdgeHTML引擎（Trident的一个分支）。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"工作原理\"><a href=\"#工作原理\" class=\"headerlink\" title=\"工作原理\"></a>工作原理</h3><ol>\n<li><p>解析HTML构建Dom树（Document Object Model，文档对象模型），DOM 是W3C组织推荐的处理可扩展置标语言的标准编程接口。</p>\n</li>\n<li><p>构建<em>渲染树</em>，<em>渲染树</em>并不等同于<em>Dom树</em>，因为像<code>head标签 或 display: none</code>这样的元素就没有必要放到<em>渲染树</em>中了，但是它们在<em>Dom树</em>中。</p>\n</li>\n<li><p>对<em>渲染树</em>进行布局，定位坐标和大小、确定是否换行、确定position、overflow、z-index等等，这个过程叫<code>&quot;layout&quot; 或 &quot;reflow&quot;</code>。</p>\n</li>\n<li><p>绘制<em>渲染树</em>，调用操作系统底层API进行绘图操作。</p>\n</li>\n</ol>\n<h3 id=\"渲染引擎工作原理示意图\"><a href=\"#渲染引擎工作原理示意图\" class=\"headerlink\" title=\"渲染引擎工作原理示意图\"></a>渲染引擎工作原理示意图</h3><p><strong>渲染引擎工作原理示意图</strong></p>\n<p><img src=\"flow.png\" alt=\"渲染引擎工作原理\"></p>\n<p><strong>WebKit工作原理（Chrome、Safari、Opera）</strong></p>\n<p><img src=\"webkitflow.png\" alt=\"Blink渲染引擎工作原理\"></p>\n<p><strong>Gecko工作原理（FireFox）</strong></p>\n<p><img src=\"gecko.jpg\" alt=\"Gecko渲染引擎工作原理\"></p>\n<h3 id=\"浏览器的-reflow-或-layout-过程\"><a href=\"#浏览器的-reflow-或-layout-过程\" class=\"headerlink\" title=\"浏览器的 reflow 或 layout 过程\"></a>浏览器的 reflow 或 layout 过程</h3><p><a href=\"https://www.youtube.com/watch?v=ZTnIxIA5KGw\" target=\"_blank\" rel=\"noopener\">https://www.youtube.com/watch?v=ZTnIxIA5KGw</a></p>\n<h3 id=\"打开-Chrome-的-Rendering-功能\"><a href=\"#打开-Chrome-的-Rendering-功能\" class=\"headerlink\" title=\"打开 Chrome 的 Rendering 功能\"></a>打开 Chrome 的 Rendering 功能</h3><p>第一步：</p>\n<p><img src=\"chrome_rendering1.png\" alt=\"第一步\"></p>\n<p>第二步：</p>\n<p><img src=\"chrome_rendering2.png\" alt=\"第二步\"></p>\n<h2 id=\"浏览器访问网站过程\"><a href=\"#浏览器访问网站过程\" class=\"headerlink\" title=\"浏览器访问网站过程\"></a>浏览器访问网站过程</h2><blockquote>\n<ol>\n<li>在浏览器地址栏中输入网址。</li>\n</ol>\n</blockquote>\n<p><img src=\"taobao_url.png\" alt=\"淘宝网址\"></p>\n<blockquote>\n<ol start=\"2\">\n<li>浏览器通过用户在地址栏中输入的URL构建HTTP请求报文。</li>\n</ol>\n</blockquote>\n<figure class=\"highlight http\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">GET</span> <span class=\"string\">/</span> HTTP/1.1</span><br><span class=\"line\"><span class=\"attribute\">Host</span>: www.taobao.com</span><br><span class=\"line\"><span class=\"attribute\">Connection</span>: keep-alive</span><br><span class=\"line\"><span class=\"attribute\">Upgrade-Insecure-Requests</span>: 1</span><br><span class=\"line\"><span class=\"attribute\">User-Agent</span>: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36</span><br><span class=\"line\"><span class=\"attribute\">Accept</span>: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8</span><br><span class=\"line\"><span class=\"attribute\">Accept-Encoding</span>: gzip, deflate, sdch, br</span><br><span class=\"line\"><span class=\"attribute\">Accept-Language</span>: zh-CN,zh;q=0.8,en;q=0.6</span><br><span class=\"line\"><span class=\"attribute\">Cookie</span>: l=Ag0NWp9E8X4hgaGEtIBhOmKxnSOH6kG8; isg=AkZGLTL-Yr9tHDZbgd5bsn4Rlzwg5IphaK-1BzBvMmlEM-ZNmDfacSyDfdgF; thw=cn</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<ol start=\"3\">\n<li>浏览器发起DNS解析请求，将域名转换为IP地址。</li>\n</ol>\n</blockquote>\n<p><img src=\"taobao_ip.png\" alt=\"淘宝网址\"></p>\n<blockquote>\n<ol start=\"4\">\n<li>浏览器将请求报文发送给服务器。</li>\n</ol>\n</blockquote>\n<blockquote>\n<ol start=\"5\">\n<li>服务器接收请求报文，并解析。</li>\n</ol>\n</blockquote>\n<blockquote>\n<ol start=\"6\">\n<li>服务器处理用户请求，并将处理结果封装成HTTP响应报文。</li>\n</ol>\n</blockquote>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">HTTP/1.1 <span class=\"number\">200</span> OK</span><br><span class=\"line\"><span class=\"attribute\">Server</span>: Tengine</span><br><span class=\"line\"><span class=\"attribute\">Date</span>: Thu, 13 Apr 2017 02:24:25 GMT</span><br><span class=\"line\"><span class=\"attribute\">Content-Type</span>: text/html; charset=utf-8</span><br><span class=\"line\"><span class=\"attribute\">Transfer-Encoding</span>: chunked</span><br><span class=\"line\"><span class=\"attribute\">Connection</span>: keep-alive</span><br><span class=\"line\"><span class=\"attribute\">Vary</span>: Accept-Encoding</span><br><span class=\"line\"><span class=\"attribute\">Vary</span>: Ali-Detector-Type, X-CIP-PT</span><br><span class=\"line\"><span class=\"attribute\">Cache-Control</span>: max-age=0, s-maxage=300</span><br><span class=\"line\"><span class=\"attribute\">Via</span>: cache8.l2cm10-1[172,200-0,C], cache13.l2cm10-1[122,0], cache3.cn206[0,200-0,H], cache6.cn206[0,0]</span><br><span class=\"line\"><span class=\"attribute\">Age</span>: 293</span><br><span class=\"line\"><span class=\"attribute\">X-Cache</span>: HIT TCP_MEM_HIT dirn:-2:-2</span><br><span class=\"line\"><span class=\"attribute\">X-Swift-SaveTime</span>: Thu, 13 Apr 2017 02:19:32 GMT</span><br><span class=\"line\"><span class=\"attribute\">X-Swift-CacheTime</span>: 300</span><br><span class=\"line\"><span class=\"attribute\">Timing-Allow-Origin</span>: *</span><br><span class=\"line\"><span class=\"attribute\">EagleId</span>: 9903e7e514920502659594264e</span><br><span class=\"line\"><span class=\"attribute\">Strict-Transport-Security</span>: max-age=31536000</span><br><span class=\"line\"><span class=\"attribute\">Content-Encoding</span>: gzip</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;!DOCTYPE html&gt;</span><br><span class=\"line\">&lt;html lang=\"zh-CN\"&gt;</span><br><span class=\"line\">&lt;head&gt;</span><br><span class=\"line\">&lt;meta charset=\"utf-8\" /&gt;</span><br><span class=\"line\">&lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" /&gt;</span><br><span class=\"line\">&lt;meta name=\"renderer\" content=\"webkit\" /&gt;</span><br><span class=\"line\">&lt;title&gt;淘宝网 - 淘！我喜欢&lt;/title&gt;</span><br><span class=\"line\">&lt;meta name=\"spm-id\" content=\"a21bo\" /&gt;</span><br><span class=\"line\">&lt;meta name=\"description\" content=\"淘宝网 - 亚洲较大的网上交易平台，提供各类服饰、美容、家居、数码、话费/点卡充值… 数亿优质商品，同时提供担保交易(先收货后付款)等安全交易保障服务，并由商家提供退货承诺、破损补寄等消费者保障服务，让你安心享受网上购物乐趣！\" /&gt;</span><br><span class=\"line\">&lt;meta name=\"aplus-xplug\" content=\"NONE\"&gt;</span><br><span class=\"line\">&lt;meta name=\"keyword\" content=\"淘宝,掏宝,网上购物,C2C,在线交易,交易市场,网上交易,交易市场,网上买,网上卖,购物网站,团购,网上贸易,安全购物,电子商务,放心买,供应,买卖信息,网店,一口价,拍卖,网上开店,网络购物,打折,免费开店,网购,频道,店铺\" /&gt;</span><br><span class=\"line\">&lt;/head&gt;</span><br><span class=\"line\">&lt;body&gt;</span><br><span class=\"line\">......</span><br><span class=\"line\">&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<ol start=\"7\">\n<li>服务器将HTTP响应报文发送给浏览器。</li>\n</ol>\n</blockquote>\n<blockquote>\n<ol start=\"8\">\n<li>浏览器接收服务器响应的HTTP报文，并解析。</li>\n</ol>\n</blockquote>\n<blockquote>\n<ol start=\"9\">\n<li>浏览器解析 HTML 页面并展示，在解析HTML页面时遇到新的资源需要再次发起请求。</li>\n</ol>\n</blockquote>\n<blockquote>\n<ol start=\"10\">\n<li>最终浏览器展示出了页面</li>\n</ol>\n</blockquote>\n<h2 id=\"HTTP请求报文和响应报文格式\"><a href=\"#HTTP请求报文和响应报文格式\" class=\"headerlink\" title=\"HTTP请求报文和响应报文格式\"></a>HTTP请求报文和响应报文格式</h2><p><img src=\"HTTPMsgStructure2.png\" alt=\"http请求报文和响应报文\"></p>\n<h2 id=\"DNS-解析过程\"><a href=\"#DNS-解析过程\" class=\"headerlink\" title=\"DNS 解析过程\"></a>DNS 解析过程</h2><p><img src=\"DNS.gif\" alt=\"DNS解析过程\"></p>\n<h3 id=\"windows-下-hosts-文件位置\"><a href=\"#windows-下-hosts-文件位置\" class=\"headerlink\" title=\"windows 下 hosts 文件位置\"></a>windows 下 hosts 文件位置</h3><p>C:\\Windows\\System32\\drivers\\etc\\hosts</p>\n<h2 id=\"DOM-解析\"><a href=\"#DOM-解析\" class=\"headerlink\" title=\"DOM 解析\"></a>DOM 解析</h2><p>参考代码:</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span>Hello World<span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">div</span>&gt;</span> <span class=\"tag\">&lt;<span class=\"name\">img</span> <span class=\"attr\">src</span>=<span class=\"string\">\"example.png\"</span> <span class=\"attr\">alt</span>=<span class=\"string\">\"example\"</span>/&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">html</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<p><img src=\"dom.png\" alt=\"Dom 解析工作原理\"></p>\n<h2 id=\"Webkit-CSS-解析\"><a href=\"#Webkit-CSS-解析\" class=\"headerlink\" title=\"Webkit CSS 解析\"></a>Webkit CSS 解析</h2><p><img src=\"css_parser.png\" alt=\"CSS 解析工作原理\"></p>\n<h2 id=\"How-Browsers-work-浏览器是如何工作的\"><a href=\"#How-Browsers-work-浏览器是如何工作的\" class=\"headerlink\" title=\"How Browsers work - 浏览器是如何工作的\"></a>How Browsers work - 浏览器是如何工作的</h2><p><a href=\"http://taligarsiel.com/Projects/howbrowserswork1.htm#The_browsers_we_will_talk_about\" target=\"_blank\" rel=\"noopener\">How Browsers work</a><br><a href=\"https://www.html5rocks.com/zh/tutorials/internals/howbrowserswork/\" target=\"_blank\" rel=\"noopener\">https://www.html5rocks.com/zh/tutorials/internals/howbrowserswork/</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"浏览器的组成\"><a href=\"#浏览器的组成\" class=\"headerlink\" title=\"浏览器的组成\"></a>浏览器的组成</h2><ul>\n<li>人机交互部分（UI）</li>\n<li>网络请求部分（Socket）</li>\n<li>JavaScript引擎部分（解析执行JavaScript）</li>\n<li>渲染引擎部分（渲染HTML、CSS等）</li>\n<li>数据存储部分（cookie、HTML5中的本地存储LocalStorage、SessionStorage）</li>\n</ul>\n<p>sqlite</p>\n<h2 id=\"主流渲染引擎\"><a href=\"#主流渲染引擎\" class=\"headerlink\" title=\"主流渲染引擎\"></a>主流渲染引擎</h2><h3 id=\"介绍\"><a href=\"#介绍\" class=\"headerlink\" title=\"介绍\"></a>介绍</h3><ol>\n<li><p>渲染引擎 又叫 排版引擎 或 浏览器内核。</p>\n</li>\n<li><p>主流的 渲染引擎 有</p>\n<ul>\n<li><strong>Chrome浏览器</strong>: Blink引擎（WebKit的一个分支）。</li>\n<li><strong>Safari浏览器</strong>: WebKit引擎，windows版本2008年3月18日推出正式版，但苹果已于2012年7月25日停止开发Windows版的Safari。</li>\n<li><strong>FireFox浏览器</strong>: Gecko引擎。</li>\n<li><strong>Opera浏览器</strong>: Blink引擎(早期版使用Presto引擎）。</li>\n<li><strong>Internet Explorer浏览器</strong>: Trident引擎。</li>\n<li><strong>Microsoft Edge浏览器</strong>: EdgeHTML引擎（Trident的一个分支）。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"工作原理\"><a href=\"#工作原理\" class=\"headerlink\" title=\"工作原理\"></a>工作原理</h3><ol>\n<li><p>解析HTML构建Dom树（Document Object Model，文档对象模型），DOM 是W3C组织推荐的处理可扩展置标语言的标准编程接口。</p>\n</li>\n<li><p>构建<em>渲染树</em>，<em>渲染树</em>并不等同于<em>Dom树</em>，因为像<code>head标签 或 display: none</code>这样的元素就没有必要放到<em>渲染树</em>中了，但是它们在<em>Dom树</em>中。</p>\n</li>\n<li><p>对<em>渲染树</em>进行布局，定位坐标和大小、确定是否换行、确定position、overflow、z-index等等，这个过程叫<code>&quot;layout&quot; 或 &quot;reflow&quot;</code>。</p>\n</li>\n<li><p>绘制<em>渲染树</em>，调用操作系统底层API进行绘图操作。</p>\n</li>\n</ol>\n<h3 id=\"渲染引擎工作原理示意图\"><a href=\"#渲染引擎工作原理示意图\" class=\"headerlink\" title=\"渲染引擎工作原理示意图\"></a>渲染引擎工作原理示意图</h3><p><strong>渲染引擎工作原理示意图</strong></p>\n<p><img src=\"flow.png\" alt=\"渲染引擎工作原理\"></p>\n<p><strong>WebKit工作原理（Chrome、Safari、Opera）</strong></p>\n<p><img src=\"webkitflow.png\" alt=\"Blink渲染引擎工作原理\"></p>\n<p><strong>Gecko工作原理（FireFox）</strong></p>\n<p><img src=\"gecko.jpg\" alt=\"Gecko渲染引擎工作原理\"></p>\n<h3 id=\"浏览器的-reflow-或-layout-过程\"><a href=\"#浏览器的-reflow-或-layout-过程\" class=\"headerlink\" title=\"浏览器的 reflow 或 layout 过程\"></a>浏览器的 reflow 或 layout 过程</h3><p><a href=\"https://www.youtube.com/watch?v=ZTnIxIA5KGw\" target=\"_blank\" rel=\"noopener\">https://www.youtube.com/watch?v=ZTnIxIA5KGw</a></p>\n<h3 id=\"打开-Chrome-的-Rendering-功能\"><a href=\"#打开-Chrome-的-Rendering-功能\" class=\"headerlink\" title=\"打开 Chrome 的 Rendering 功能\"></a>打开 Chrome 的 Rendering 功能</h3><p>第一步：</p>\n<p><img src=\"chrome_rendering1.png\" alt=\"第一步\"></p>\n<p>第二步：</p>\n<p><img src=\"chrome_rendering2.png\" alt=\"第二步\"></p>\n<h2 id=\"浏览器访问网站过程\"><a href=\"#浏览器访问网站过程\" class=\"headerlink\" title=\"浏览器访问网站过程\"></a>浏览器访问网站过程</h2><blockquote>\n<ol>\n<li>在浏览器地址栏中输入网址。</li>\n</ol>\n</blockquote>\n<p><img src=\"taobao_url.png\" alt=\"淘宝网址\"></p>\n<blockquote>\n<ol start=\"2\">\n<li>浏览器通过用户在地址栏中输入的URL构建HTTP请求报文。</li>\n</ol>\n</blockquote>\n<figure class=\"highlight http\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">GET</span> <span class=\"string\">/</span> HTTP/1.1</span><br><span class=\"line\"><span class=\"attribute\">Host</span>: www.taobao.com</span><br><span class=\"line\"><span class=\"attribute\">Connection</span>: keep-alive</span><br><span class=\"line\"><span class=\"attribute\">Upgrade-Insecure-Requests</span>: 1</span><br><span class=\"line\"><span class=\"attribute\">User-Agent</span>: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36</span><br><span class=\"line\"><span class=\"attribute\">Accept</span>: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8</span><br><span class=\"line\"><span class=\"attribute\">Accept-Encoding</span>: gzip, deflate, sdch, br</span><br><span class=\"line\"><span class=\"attribute\">Accept-Language</span>: zh-CN,zh;q=0.8,en;q=0.6</span><br><span class=\"line\"><span class=\"attribute\">Cookie</span>: l=Ag0NWp9E8X4hgaGEtIBhOmKxnSOH6kG8; isg=AkZGLTL-Yr9tHDZbgd5bsn4Rlzwg5IphaK-1BzBvMmlEM-ZNmDfacSyDfdgF; thw=cn</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<ol start=\"3\">\n<li>浏览器发起DNS解析请求，将域名转换为IP地址。</li>\n</ol>\n</blockquote>\n<p><img src=\"taobao_ip.png\" alt=\"淘宝网址\"></p>\n<blockquote>\n<ol start=\"4\">\n<li>浏览器将请求报文发送给服务器。</li>\n</ol>\n</blockquote>\n<blockquote>\n<ol start=\"5\">\n<li>服务器接收请求报文，并解析。</li>\n</ol>\n</blockquote>\n<blockquote>\n<ol start=\"6\">\n<li>服务器处理用户请求，并将处理结果封装成HTTP响应报文。</li>\n</ol>\n</blockquote>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">HTTP/1.1 <span class=\"number\">200</span> OK</span><br><span class=\"line\"><span class=\"attribute\">Server</span>: Tengine</span><br><span class=\"line\"><span class=\"attribute\">Date</span>: Thu, 13 Apr 2017 02:24:25 GMT</span><br><span class=\"line\"><span class=\"attribute\">Content-Type</span>: text/html; charset=utf-8</span><br><span class=\"line\"><span class=\"attribute\">Transfer-Encoding</span>: chunked</span><br><span class=\"line\"><span class=\"attribute\">Connection</span>: keep-alive</span><br><span class=\"line\"><span class=\"attribute\">Vary</span>: Accept-Encoding</span><br><span class=\"line\"><span class=\"attribute\">Vary</span>: Ali-Detector-Type, X-CIP-PT</span><br><span class=\"line\"><span class=\"attribute\">Cache-Control</span>: max-age=0, s-maxage=300</span><br><span class=\"line\"><span class=\"attribute\">Via</span>: cache8.l2cm10-1[172,200-0,C], cache13.l2cm10-1[122,0], cache3.cn206[0,200-0,H], cache6.cn206[0,0]</span><br><span class=\"line\"><span class=\"attribute\">Age</span>: 293</span><br><span class=\"line\"><span class=\"attribute\">X-Cache</span>: HIT TCP_MEM_HIT dirn:-2:-2</span><br><span class=\"line\"><span class=\"attribute\">X-Swift-SaveTime</span>: Thu, 13 Apr 2017 02:19:32 GMT</span><br><span class=\"line\"><span class=\"attribute\">X-Swift-CacheTime</span>: 300</span><br><span class=\"line\"><span class=\"attribute\">Timing-Allow-Origin</span>: *</span><br><span class=\"line\"><span class=\"attribute\">EagleId</span>: 9903e7e514920502659594264e</span><br><span class=\"line\"><span class=\"attribute\">Strict-Transport-Security</span>: max-age=31536000</span><br><span class=\"line\"><span class=\"attribute\">Content-Encoding</span>: gzip</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;!DOCTYPE html&gt;</span><br><span class=\"line\">&lt;html lang=\"zh-CN\"&gt;</span><br><span class=\"line\">&lt;head&gt;</span><br><span class=\"line\">&lt;meta charset=\"utf-8\" /&gt;</span><br><span class=\"line\">&lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" /&gt;</span><br><span class=\"line\">&lt;meta name=\"renderer\" content=\"webkit\" /&gt;</span><br><span class=\"line\">&lt;title&gt;淘宝网 - 淘！我喜欢&lt;/title&gt;</span><br><span class=\"line\">&lt;meta name=\"spm-id\" content=\"a21bo\" /&gt;</span><br><span class=\"line\">&lt;meta name=\"description\" content=\"淘宝网 - 亚洲较大的网上交易平台，提供各类服饰、美容、家居、数码、话费/点卡充值… 数亿优质商品，同时提供担保交易(先收货后付款)等安全交易保障服务，并由商家提供退货承诺、破损补寄等消费者保障服务，让你安心享受网上购物乐趣！\" /&gt;</span><br><span class=\"line\">&lt;meta name=\"aplus-xplug\" content=\"NONE\"&gt;</span><br><span class=\"line\">&lt;meta name=\"keyword\" content=\"淘宝,掏宝,网上购物,C2C,在线交易,交易市场,网上交易,交易市场,网上买,网上卖,购物网站,团购,网上贸易,安全购物,电子商务,放心买,供应,买卖信息,网店,一口价,拍卖,网上开店,网络购物,打折,免费开店,网购,频道,店铺\" /&gt;</span><br><span class=\"line\">&lt;/head&gt;</span><br><span class=\"line\">&lt;body&gt;</span><br><span class=\"line\">......</span><br><span class=\"line\">&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<ol start=\"7\">\n<li>服务器将HTTP响应报文发送给浏览器。</li>\n</ol>\n</blockquote>\n<blockquote>\n<ol start=\"8\">\n<li>浏览器接收服务器响应的HTTP报文，并解析。</li>\n</ol>\n</blockquote>\n<blockquote>\n<ol start=\"9\">\n<li>浏览器解析 HTML 页面并展示，在解析HTML页面时遇到新的资源需要再次发起请求。</li>\n</ol>\n</blockquote>\n<blockquote>\n<ol start=\"10\">\n<li>最终浏览器展示出了页面</li>\n</ol>\n</blockquote>\n<h2 id=\"HTTP请求报文和响应报文格式\"><a href=\"#HTTP请求报文和响应报文格式\" class=\"headerlink\" title=\"HTTP请求报文和响应报文格式\"></a>HTTP请求报文和响应报文格式</h2><p><img src=\"HTTPMsgStructure2.png\" alt=\"http请求报文和响应报文\"></p>\n<h2 id=\"DNS-解析过程\"><a href=\"#DNS-解析过程\" class=\"headerlink\" title=\"DNS 解析过程\"></a>DNS 解析过程</h2><p><img src=\"DNS.gif\" alt=\"DNS解析过程\"></p>\n<h3 id=\"windows-下-hosts-文件位置\"><a href=\"#windows-下-hosts-文件位置\" class=\"headerlink\" title=\"windows 下 hosts 文件位置\"></a>windows 下 hosts 文件位置</h3><p>C:\\Windows\\System32\\drivers\\etc\\hosts</p>\n<h2 id=\"DOM-解析\"><a href=\"#DOM-解析\" class=\"headerlink\" title=\"DOM 解析\"></a>DOM 解析</h2><p>参考代码:</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span>Hello World<span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">div</span>&gt;</span> <span class=\"tag\">&lt;<span class=\"name\">img</span> <span class=\"attr\">src</span>=<span class=\"string\">\"example.png\"</span> <span class=\"attr\">alt</span>=<span class=\"string\">\"example\"</span>/&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">html</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<p><img src=\"dom.png\" alt=\"Dom 解析工作原理\"></p>\n<h2 id=\"Webkit-CSS-解析\"><a href=\"#Webkit-CSS-解析\" class=\"headerlink\" title=\"Webkit CSS 解析\"></a>Webkit CSS 解析</h2><p><img src=\"css_parser.png\" alt=\"CSS 解析工作原理\"></p>\n<h2 id=\"How-Browsers-work-浏览器是如何工作的\"><a href=\"#How-Browsers-work-浏览器是如何工作的\" class=\"headerlink\" title=\"How Browsers work - 浏览器是如何工作的\"></a>How Browsers work - 浏览器是如何工作的</h2><p><a href=\"http://taligarsiel.com/Projects/howbrowserswork1.htm#The_browsers_we_will_talk_about\" target=\"_blank\" rel=\"noopener\">How Browsers work</a><br><a href=\"https://www.html5rocks.com/zh/tutorials/internals/howbrowserswork/\" target=\"_blank\" rel=\"noopener\">https://www.html5rocks.com/zh/tutorials/internals/howbrowserswork/</a></p>\n"},{"title":"Ceph Storage Conception 01","_content":"\n## Ceph\n官网: https://ceph.io/get/\ngithub: https://github.com/ceph/ceph\n中文文档: http://docs.ceph.org.cn/\n\n * 软件定义存储 -SDS\nSDS是减少存储基础设施的TCO(总体成本)所需要的。除了降低存储成本外， SDS还可以提供灵活性、可伸缩性和可靠\n性。 Ceph是一种真正的SDS;它运行在没有厂商锁定的普通硬件上。 与传统的存储系统(硬件与软件结合在一起)不同，\n在SDS中，您可以从任何制造商中自由选择硬件，也可以根据自己的需要自由设计异构硬件解决方案。 Ceph在此硬件\n之上的软件定义存储提供了您需要的所有， 并将负责所有事情，从软件层提供了所有企业存储特性。\n\n * 云存储\n目前已经和开源云架构 OpenStack 结合起来，成为 Openstack后端存储的标配，并且又同时支持用于 kubernetes 动态存储.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/storage/ceph_conception_01.md","raw":"---\ntitle: Ceph Storage Conception 01\ntags: storage\ncategories:\n- storage\n---\n\n## Ceph\n官网: https://ceph.io/get/\ngithub: https://github.com/ceph/ceph\n中文文档: http://docs.ceph.org.cn/\n\n * 软件定义存储 -SDS\nSDS是减少存储基础设施的TCO(总体成本)所需要的。除了降低存储成本外， SDS还可以提供灵活性、可伸缩性和可靠\n性。 Ceph是一种真正的SDS;它运行在没有厂商锁定的普通硬件上。 与传统的存储系统(硬件与软件结合在一起)不同，\n在SDS中，您可以从任何制造商中自由选择硬件，也可以根据自己的需要自由设计异构硬件解决方案。 Ceph在此硬件\n之上的软件定义存储提供了您需要的所有， 并将负责所有事情，从软件层提供了所有企业存储特性。\n\n * 云存储\n目前已经和开源云架构 OpenStack 结合起来，成为 Openstack后端存储的标配，并且又同时支持用于 kubernetes 动态存储.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"storage/ceph_conception_01","published":1,"date":"2020-08-12T16:05:48.421Z","updated":"2020-08-03T12:20:35.856Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmgv0067hohx9pwk942x","content":"<h2 id=\"Ceph\"><a href=\"#Ceph\" class=\"headerlink\" title=\"Ceph\"></a>Ceph</h2><p>官网: <a href=\"https://ceph.io/get/\" target=\"_blank\" rel=\"noopener\">https://ceph.io/get/</a><br>github: <a href=\"https://github.com/ceph/ceph\" target=\"_blank\" rel=\"noopener\">https://github.com/ceph/ceph</a><br>中文文档: <a href=\"http://docs.ceph.org.cn/\" target=\"_blank\" rel=\"noopener\">http://docs.ceph.org.cn/</a></p>\n<ul>\n<li><p>软件定义存储 -SDS<br>SDS是减少存储基础设施的TCO(总体成本)所需要的。除了降低存储成本外， SDS还可以提供灵活性、可伸缩性和可靠<br>性。 Ceph是一种真正的SDS;它运行在没有厂商锁定的普通硬件上。 与传统的存储系统(硬件与软件结合在一起)不同，<br>在SDS中，您可以从任何制造商中自由选择硬件，也可以根据自己的需要自由设计异构硬件解决方案。 Ceph在此硬件<br>之上的软件定义存储提供了您需要的所有， 并将负责所有事情，从软件层提供了所有企业存储特性。</p>\n</li>\n<li><p>云存储<br>目前已经和开源云架构 OpenStack 结合起来，成为 Openstack后端存储的标配，并且又同时支持用于 kubernetes 动态存储.</p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Ceph\"><a href=\"#Ceph\" class=\"headerlink\" title=\"Ceph\"></a>Ceph</h2><p>官网: <a href=\"https://ceph.io/get/\" target=\"_blank\" rel=\"noopener\">https://ceph.io/get/</a><br>github: <a href=\"https://github.com/ceph/ceph\" target=\"_blank\" rel=\"noopener\">https://github.com/ceph/ceph</a><br>中文文档: <a href=\"http://docs.ceph.org.cn/\" target=\"_blank\" rel=\"noopener\">http://docs.ceph.org.cn/</a></p>\n<ul>\n<li><p>软件定义存储 -SDS<br>SDS是减少存储基础设施的TCO(总体成本)所需要的。除了降低存储成本外， SDS还可以提供灵活性、可伸缩性和可靠<br>性。 Ceph是一种真正的SDS;它运行在没有厂商锁定的普通硬件上。 与传统的存储系统(硬件与软件结合在一起)不同，<br>在SDS中，您可以从任何制造商中自由选择硬件，也可以根据自己的需要自由设计异构硬件解决方案。 Ceph在此硬件<br>之上的软件定义存储提供了您需要的所有， 并将负责所有事情，从软件层提供了所有企业存储特性。</p>\n</li>\n<li><p>云存储<br>目前已经和开源云架构 OpenStack 结合起来，成为 Openstack后端存储的标配，并且又同时支持用于 kubernetes 动态存储.</p>\n</li>\n</ul>\n"},{"title":"Ceph Storage Deployment on Kubernetes","_content":"\nThis document describes the steps to enable Ceph cluster in Kubernetes(k8s)  \n\n## **Prerequisites**\n1. A running Kubernetes environmen.  \n\n\n## **Setup steps**\n1. The first step is to deploy the Rook operator. Check that you are using the example yaml files that correspond to your release of Rook.  \n\n\n\t$ git clone --single-branch --branch release-1.3 https://github.com/rook/rook.git\n\t$ cd cluster/examples/kubernetes/ceph\n\t$ kubectl create -f common.yaml\n\t$ kubectl create -f operator.yaml\n\t\n\tVerify the rook-ceph-operator is in the Running state before proceeding\n\t$ kubectl -n rook-ceph get pod\n2. Now that the Rook operator is running we can create the Ceph cluster. For the cluster to survive reboots, make sure you set the dataDirHostPath property that is valid for your hosts.  \n\n\n\t$ kubectl create -f cluster.yaml\n3. Use kubectl to list pods in the rook-ceph namespace. You should be able to see the following pods once they are all running. The number of osd pods will depend on the number of nodes in the cluster and the number of devices configured. If you did not modify the cluster.yaml above, it is expected that one OSD will be created per node. The CSI, rook-ceph-agent, and rook-discover pods are also optional depending on your settings.  \n\n\n\t$ kubectl -n rook-ceph get pod\n\t  NAME                                                 READY   STATUS      RESTARTS   AGE\n\t  csi-cephfsplugin-provisioner-d77bb49c6-n5tgs         5/5     Running     0          140s\n\t  csi-cephfsplugin-provisioner-d77bb49c6-v9rvn         5/5     Running     0          140s\n\t  csi-cephfsplugin-rthrp                               3/3     Running     0          140s\n\t  csi-rbdplugin-hbsm7                                  3/3     Running     0          140s\n\t  csi-rbdplugin-provisioner-5b5cd64fd-nvk6c            6/6     Running     0          140s\n\t  csi-rbdplugin-provisioner-5b5cd64fd-q7bxl            6/6     Running     0          140s\n\t  rook-ceph-agent-4zkg8                                1/1     Running     0          140s\n\t  rook-ceph-crashcollector-minikube-5b57b7c5d4-hfldl   1/1     Running     0          105s\n\t  rook-ceph-mgr-a-64cd7cdf54-j8b5p                     1/1     Running     0          77s\n\t  rook-ceph-mon-a-694bb7987d-fp9w7                     1/1     Running     0          105s\n\t  rook-ceph-mon-b-856fdd5cb9-5h2qk                     1/1     Running     0          94s\n\t  rook-ceph-mon-c-57545897fc-j576h                     1/1     Running     0          85s\n\t  rook-ceph-operator-85f5b946bd-s8grz                  1/1     Running     0          92m\n\t  rook-ceph-osd-0-6bb747b6c5-lnvb6                     1/1     Running     0          23s\n\t  rook-ceph-osd-1-7f67f9646d-44p7v                     1/1     Running     0          24s\n\t  rook-ceph-osd-2-6cd4b776ff-v4d68                     1/1     Running     0          25s\n\t  rook-ceph-osd-prepare-node1-vx2rz                    0/2     Completed   0          60s\n\t  rook-ceph-osd-prepare-node2-ab3fd                    0/2     Completed   0          60s\n\t  rook-ceph-osd-prepare-node3-w4xyz                    0/2     Completed   0          60s\n\t  rook-discover-dhkb8                                  1/1     Running     0          140s\n4. To verify that the cluster is in a healthy state, connect to the Rook toolbox and run the ceph status command.  \n\n* All mons should be in quorum  \n* A mgr should be active  \n* At least one OSD should be active  \n* If the health is not HEALTH_OK, the warnings or errors should be investigated.  \n\nRunning the Toolbox in Kubernetes:  \n\n\t$ kubectl create -f toolbox.yaml\nWait for the toolbox pod to download its container and get to the running state:\n\n\t$ kubectl -n rook-ceph get pod -l \"app=rook-ceph-tools\"\nOnce the rook-ceph-tools pod is running, you can connect to it with:\n\n\t$ kubectl -n rook-ceph exec -it $(kubectl -n rook-ceph get pod -l \"app=rook-ceph-tools\" -o jsonpath='{.items[0].metadata.name}') bash\nExample:\n\n\t$ ceph status\n\t  cluster:\n\t    id:     a0452c76-30d9-4c1a-a948-5d8405f19a7c\n\t    health: HEALTH_OK\n\t\n\t  services:\n\t    mon: 3 daemons, quorum a,b,c (age 3m)\n\t    mgr: a(active, since 2m)\n\t    osd: 3 osds: 3 up (since 1m), 3 in (since 1m)\n\t...\n\nWhen you are done with the toolbox, you can remove the deployment, but if you want continue to doing other test experiments below, please keep the toolbox:\n\n\t$ kubectl -n rook-ceph delete deployment rook-ceph-tools\n\n## **Object Store**\n### 1. Create an Object Store\n\n\t$ cd cluster/examples/kubernetes/ceph\n\t// Create the object store\n\t$ kubectl create -f object.yaml\n\t// To confirm the object store is configured, wait for the rgw pod to start\n\t$ kubectl -n rook-ceph get pod -l app=rook-ceph-rgw\n### 2. Define a storage class that will allow object clients to create a bucket.\n\n\t// Define the storage class that will allow object clients to create a bucket\n\t$ kubectl create -f storageclass-bucket-delete.yaml\n### 3.1 Create a Bucket\nAn Object Bucket Claim (OBC) is custom resource which requests a bucket (new or existing) and is described by a Custom Resource Definition (CRD).\n\n\t// Create an Object Bucket Claim (OBC) \n\t$ kubectl create -f object-bucket-claim-delete.yaml\nWhen the OBC is created, the Rook-Ceph bucket provisioner will create a new bucket.A `secret` and `ConfigMap` are created with the same name as the OBC and in the same namespace. The secret contains credentials used by the application pod to access the bucket. The ConfigMap contains bucket endpoint information and is also consumed by the pod. \n\n\t// Check the created bucket name, \"ceph-bkt-5124df41-7939-4aa6-b989-2bff0aa38deb\" as shown below.\n\t$ kubectl describe obc ceph-delete-bucket\n\t  ......\n\t  Spec:\n\t    Object Bucket Name:    obc-default-ceph-delete-bucket\n\t    Bucket Name:           ceph-bkt-5124df41-7939-4aa6-b989-2bff0aa38deb\n\t    Generate Bucket Name:  ceph-bkt\n\t    Storage Class Name:    rook-ceph-delete-bucket\n\t  Status:\n\t    Phase:  Bound\t\t// [Notice]: The Status must be Bound, if `Pending`, please wait or delete and recreate the obc.\n\t  Events:   <none>\nAn Object Bucket (OB) is a custom resource automatically generated when a bucket is provisioned. It is a global resource, typically not visible to non-admin users, and contains information specific to the bucket. It is described by an OB CRD.\n\n\t// Check the OB\n\t$ kubectl get ob\n\t  NAME                             AGE\n\t  obc-default-ceph-delete-bucket   5m16s\n### 3.2 Create another Bucket\nChange the ObjectBucketClaim metadata.name and create another bucket.\n\n\t$ vim object-bucket-claim-delete.yaml\n\t  apiVersion: objectbucket.io/v1alpha1\n\t  kind: ObjectBucketClaim\n\t  metadata:\n\t    name: ceph-bucket-new\t\t# Change bucket name\n\t  spec:\n\t    generateBucketName: ceph-bkt\n\t    storageClassName: rook-ceph-bucket\n\t$ kubectl create -f object-bucket-claim-delete.yaml\n**Client Connections**\nThe following commands extract key pieces of information from the secret and configmap:\n\n\t// config-map, secret, OBC will part of default if no specific name space mentioned\n\t$ export AWS_HOST=$(kubectl -n default get cm ceph-delete-bucket -o yaml | grep BUCKET_HOST | awk '{print $2}' | awk 'NR==1')\n\t$ export AWS_ACCESS_KEY_ID=$(kubectl -n default get secret ceph-delete-bucket -o yaml | grep AWS_ACCESS_KEY_ID | awk '{print $2}' | awk 'NR==1'| base64 --decode)\n\t$ export AWS_SECRET_ACCESS_KEY=$(kubectl -n default get secret ceph-delete-bucket -o yaml | grep AWS_SECRET_ACCESS_KEY | awk '{print $2}' | awk 'NR==1'| base64 --decode)\n\n### 4. Consume the Object Storage\n**Enter into the toolbox**\n\n\tkubectl exec $(kubectl get po -l app=rook-ceph-tools -n rook-ceph -o jsonpath='{.items[0].metadata.name}') -it -n rook-ceph -- bash\nConnected to the Rook toolbox Pod and then set the four environment variables for use by your client(ie. inside the toolbox).\n\n\t$ export AWS_HOST=<host>\n\t$ export AWS_ENDPOINT=<endpoint>\n\t$ export AWS_ACCESS_KEY_ID=<accessKey>\n\t$ export AWS_SECRET_ACCESS_KEY=<secretKey>\nEndpoint: The endpoint where the rgw service is listening. Run ```kubectl -n rook-ceph get svc rook-ceph-rgw-my-store```, then combine the clusterIP and the port.\n\n**Install s3cmd**\n\n\t$ echo proxy=http://Proxy-Name:913 >> /etc/yum.conf\n\t$ yum --assumeyes install s3cmd\n**PUT or GET an object**\nUpload a file to the newly created bucket\n\n\t$ echo \"Hello Rook\" > /tmp/rookObj\n\t$ s3cmd put /tmp/rookObj --no-ssl --host=${AWS_HOST} --host-bucket=  s3://<-Your-Bucket-Name-> // As follow.\n\t// $ s3cmd put /tmp/rookObj --no-ssl --host=${AWS_HOST} --host-bucket=  s3://ceph-bkt-5124df41-7939-4aa6-b989-2bff0aa38deb\n\t  upload: '/tmp/rookObj' -> 's3://ceph-bkt-5124df41-7939-4aa6-b989-2bff0aa38deb/rookObj'  [1 of 1]\n\t   11 of 11   100% in    0s   190.11 B/s  done\nDownload and verify the file from the bucket\n\n\t$ s3cmd get s3://<-Your-Bucket-Name->/rookObj /tmp/rookObj-download --no-ssl --host=${AWS_HOST} --host-bucket=\n\t  download: 's3://ceph-bkt-5124df41-7939-4aa6-b989-2bff0aa38deb/rookObj' -> '/tmp/rookObj-download'  [1 of 1]\n\t   11 of 11   100% in    0s   254.34 B/s  done\n\t$ cat /tmp/rookObj-download\nList the buckets\n\n\t$ s3cmd ls --no-ssl --host=${AWS_HOST} --host-bucket=\n\n## Teardown\n1. First you will need to clean up the resources created on top of the Rook cluster.  \n\n\n\t$ kubectl delete -n rook-ceph cephblockpool replicapool\n\t$ kubectl delete storageclass rook-ceph-block\n\t$ kubectl delete -f csi/cephfs/kube-registry.yaml\n\t$ kubectl delete storageclass csi-cephfs\n2. Delete the CephCluster CRD\n\n\n\t$ kubectl -n rook-ceph delete cephcluster rook-ceph\n3. Delete the Operator and related Resources\n\n\n\t$ kubectl delete -f operator.yaml\n\t$ kubectl delete -f common.yaml\n4. /var/lib/rook: Path on each host in the cluster where configuration is cached by the ceph mons and osds. so need to clean the files in the path.\n\n\n\t$ rm -rf /var/lib/rook/\nAdditional: If there are ceph related files in the \"/var/lib/kubelet/plugins/\" and \"/var/lib/kubelet/plugins_registry/\" path, delete them.\n\n\t$ rm -rf /var/lib/kubelet/plugins/*\n\t$ rm -rf /var/lib/kubelet/plugins_registry/*\n5. Delete the data on hosts\n\n\n\t#!/usr/bin/env bash\n\tDISK=\"/dev/sdb\"\n\t# Zap the disk to a fresh, usable state (zap-all is important, b/c MBR has to be clean)\n\t# You will have to run this step for all disks.\n\tsgdisk --zap-all $DISK\n\tdd if=/dev/zero of=\"$DISK\" bs=1M count=100 oflag=direct,dsync\n\t\n\t# These steps only have to be run once on each node\n\t# If rook sets up osds using ceph-volume, teardown leaves some devices mapped that lock the disks.\n\tls /dev/mapper/ceph-* | xargs -I% -- dmsetup remove %\n\t# ceph-volume setup can leave ceph-<UUID> directories in /dev (unnecessary clutter)\n\trm -rf /dev/ceph-*\n## FAQ\nIf the cluster resource still exists even though you have executed the delete command earlier, see the command below remove the finalizer.\n\n\t$ kubectl -n rook-ceph patch crd cephclusters.ceph.rook.io --type merge -p '{\"metadata\":{\"finalizers\": [null]}}'\n\n\n","source":"_posts/storage/ceph_deployment_02.md","raw":"---\ntitle: Ceph Storage Deployment on Kubernetes\ntags: storage\ncategories:\n- storage\n---\n\nThis document describes the steps to enable Ceph cluster in Kubernetes(k8s)  \n\n## **Prerequisites**\n1. A running Kubernetes environmen.  \n\n\n## **Setup steps**\n1. The first step is to deploy the Rook operator. Check that you are using the example yaml files that correspond to your release of Rook.  \n\n\n\t$ git clone --single-branch --branch release-1.3 https://github.com/rook/rook.git\n\t$ cd cluster/examples/kubernetes/ceph\n\t$ kubectl create -f common.yaml\n\t$ kubectl create -f operator.yaml\n\t\n\tVerify the rook-ceph-operator is in the Running state before proceeding\n\t$ kubectl -n rook-ceph get pod\n2. Now that the Rook operator is running we can create the Ceph cluster. For the cluster to survive reboots, make sure you set the dataDirHostPath property that is valid for your hosts.  \n\n\n\t$ kubectl create -f cluster.yaml\n3. Use kubectl to list pods in the rook-ceph namespace. You should be able to see the following pods once they are all running. The number of osd pods will depend on the number of nodes in the cluster and the number of devices configured. If you did not modify the cluster.yaml above, it is expected that one OSD will be created per node. The CSI, rook-ceph-agent, and rook-discover pods are also optional depending on your settings.  \n\n\n\t$ kubectl -n rook-ceph get pod\n\t  NAME                                                 READY   STATUS      RESTARTS   AGE\n\t  csi-cephfsplugin-provisioner-d77bb49c6-n5tgs         5/5     Running     0          140s\n\t  csi-cephfsplugin-provisioner-d77bb49c6-v9rvn         5/5     Running     0          140s\n\t  csi-cephfsplugin-rthrp                               3/3     Running     0          140s\n\t  csi-rbdplugin-hbsm7                                  3/3     Running     0          140s\n\t  csi-rbdplugin-provisioner-5b5cd64fd-nvk6c            6/6     Running     0          140s\n\t  csi-rbdplugin-provisioner-5b5cd64fd-q7bxl            6/6     Running     0          140s\n\t  rook-ceph-agent-4zkg8                                1/1     Running     0          140s\n\t  rook-ceph-crashcollector-minikube-5b57b7c5d4-hfldl   1/1     Running     0          105s\n\t  rook-ceph-mgr-a-64cd7cdf54-j8b5p                     1/1     Running     0          77s\n\t  rook-ceph-mon-a-694bb7987d-fp9w7                     1/1     Running     0          105s\n\t  rook-ceph-mon-b-856fdd5cb9-5h2qk                     1/1     Running     0          94s\n\t  rook-ceph-mon-c-57545897fc-j576h                     1/1     Running     0          85s\n\t  rook-ceph-operator-85f5b946bd-s8grz                  1/1     Running     0          92m\n\t  rook-ceph-osd-0-6bb747b6c5-lnvb6                     1/1     Running     0          23s\n\t  rook-ceph-osd-1-7f67f9646d-44p7v                     1/1     Running     0          24s\n\t  rook-ceph-osd-2-6cd4b776ff-v4d68                     1/1     Running     0          25s\n\t  rook-ceph-osd-prepare-node1-vx2rz                    0/2     Completed   0          60s\n\t  rook-ceph-osd-prepare-node2-ab3fd                    0/2     Completed   0          60s\n\t  rook-ceph-osd-prepare-node3-w4xyz                    0/2     Completed   0          60s\n\t  rook-discover-dhkb8                                  1/1     Running     0          140s\n4. To verify that the cluster is in a healthy state, connect to the Rook toolbox and run the ceph status command.  \n\n* All mons should be in quorum  \n* A mgr should be active  \n* At least one OSD should be active  \n* If the health is not HEALTH_OK, the warnings or errors should be investigated.  \n\nRunning the Toolbox in Kubernetes:  \n\n\t$ kubectl create -f toolbox.yaml\nWait for the toolbox pod to download its container and get to the running state:\n\n\t$ kubectl -n rook-ceph get pod -l \"app=rook-ceph-tools\"\nOnce the rook-ceph-tools pod is running, you can connect to it with:\n\n\t$ kubectl -n rook-ceph exec -it $(kubectl -n rook-ceph get pod -l \"app=rook-ceph-tools\" -o jsonpath='{.items[0].metadata.name}') bash\nExample:\n\n\t$ ceph status\n\t  cluster:\n\t    id:     a0452c76-30d9-4c1a-a948-5d8405f19a7c\n\t    health: HEALTH_OK\n\t\n\t  services:\n\t    mon: 3 daemons, quorum a,b,c (age 3m)\n\t    mgr: a(active, since 2m)\n\t    osd: 3 osds: 3 up (since 1m), 3 in (since 1m)\n\t...\n\nWhen you are done with the toolbox, you can remove the deployment, but if you want continue to doing other test experiments below, please keep the toolbox:\n\n\t$ kubectl -n rook-ceph delete deployment rook-ceph-tools\n\n## **Object Store**\n### 1. Create an Object Store\n\n\t$ cd cluster/examples/kubernetes/ceph\n\t// Create the object store\n\t$ kubectl create -f object.yaml\n\t// To confirm the object store is configured, wait for the rgw pod to start\n\t$ kubectl -n rook-ceph get pod -l app=rook-ceph-rgw\n### 2. Define a storage class that will allow object clients to create a bucket.\n\n\t// Define the storage class that will allow object clients to create a bucket\n\t$ kubectl create -f storageclass-bucket-delete.yaml\n### 3.1 Create a Bucket\nAn Object Bucket Claim (OBC) is custom resource which requests a bucket (new or existing) and is described by a Custom Resource Definition (CRD).\n\n\t// Create an Object Bucket Claim (OBC) \n\t$ kubectl create -f object-bucket-claim-delete.yaml\nWhen the OBC is created, the Rook-Ceph bucket provisioner will create a new bucket.A `secret` and `ConfigMap` are created with the same name as the OBC and in the same namespace. The secret contains credentials used by the application pod to access the bucket. The ConfigMap contains bucket endpoint information and is also consumed by the pod. \n\n\t// Check the created bucket name, \"ceph-bkt-5124df41-7939-4aa6-b989-2bff0aa38deb\" as shown below.\n\t$ kubectl describe obc ceph-delete-bucket\n\t  ......\n\t  Spec:\n\t    Object Bucket Name:    obc-default-ceph-delete-bucket\n\t    Bucket Name:           ceph-bkt-5124df41-7939-4aa6-b989-2bff0aa38deb\n\t    Generate Bucket Name:  ceph-bkt\n\t    Storage Class Name:    rook-ceph-delete-bucket\n\t  Status:\n\t    Phase:  Bound\t\t// [Notice]: The Status must be Bound, if `Pending`, please wait or delete and recreate the obc.\n\t  Events:   <none>\nAn Object Bucket (OB) is a custom resource automatically generated when a bucket is provisioned. It is a global resource, typically not visible to non-admin users, and contains information specific to the bucket. It is described by an OB CRD.\n\n\t// Check the OB\n\t$ kubectl get ob\n\t  NAME                             AGE\n\t  obc-default-ceph-delete-bucket   5m16s\n### 3.2 Create another Bucket\nChange the ObjectBucketClaim metadata.name and create another bucket.\n\n\t$ vim object-bucket-claim-delete.yaml\n\t  apiVersion: objectbucket.io/v1alpha1\n\t  kind: ObjectBucketClaim\n\t  metadata:\n\t    name: ceph-bucket-new\t\t# Change bucket name\n\t  spec:\n\t    generateBucketName: ceph-bkt\n\t    storageClassName: rook-ceph-bucket\n\t$ kubectl create -f object-bucket-claim-delete.yaml\n**Client Connections**\nThe following commands extract key pieces of information from the secret and configmap:\n\n\t// config-map, secret, OBC will part of default if no specific name space mentioned\n\t$ export AWS_HOST=$(kubectl -n default get cm ceph-delete-bucket -o yaml | grep BUCKET_HOST | awk '{print $2}' | awk 'NR==1')\n\t$ export AWS_ACCESS_KEY_ID=$(kubectl -n default get secret ceph-delete-bucket -o yaml | grep AWS_ACCESS_KEY_ID | awk '{print $2}' | awk 'NR==1'| base64 --decode)\n\t$ export AWS_SECRET_ACCESS_KEY=$(kubectl -n default get secret ceph-delete-bucket -o yaml | grep AWS_SECRET_ACCESS_KEY | awk '{print $2}' | awk 'NR==1'| base64 --decode)\n\n### 4. Consume the Object Storage\n**Enter into the toolbox**\n\n\tkubectl exec $(kubectl get po -l app=rook-ceph-tools -n rook-ceph -o jsonpath='{.items[0].metadata.name}') -it -n rook-ceph -- bash\nConnected to the Rook toolbox Pod and then set the four environment variables for use by your client(ie. inside the toolbox).\n\n\t$ export AWS_HOST=<host>\n\t$ export AWS_ENDPOINT=<endpoint>\n\t$ export AWS_ACCESS_KEY_ID=<accessKey>\n\t$ export AWS_SECRET_ACCESS_KEY=<secretKey>\nEndpoint: The endpoint where the rgw service is listening. Run ```kubectl -n rook-ceph get svc rook-ceph-rgw-my-store```, then combine the clusterIP and the port.\n\n**Install s3cmd**\n\n\t$ echo proxy=http://Proxy-Name:913 >> /etc/yum.conf\n\t$ yum --assumeyes install s3cmd\n**PUT or GET an object**\nUpload a file to the newly created bucket\n\n\t$ echo \"Hello Rook\" > /tmp/rookObj\n\t$ s3cmd put /tmp/rookObj --no-ssl --host=${AWS_HOST} --host-bucket=  s3://<-Your-Bucket-Name-> // As follow.\n\t// $ s3cmd put /tmp/rookObj --no-ssl --host=${AWS_HOST} --host-bucket=  s3://ceph-bkt-5124df41-7939-4aa6-b989-2bff0aa38deb\n\t  upload: '/tmp/rookObj' -> 's3://ceph-bkt-5124df41-7939-4aa6-b989-2bff0aa38deb/rookObj'  [1 of 1]\n\t   11 of 11   100% in    0s   190.11 B/s  done\nDownload and verify the file from the bucket\n\n\t$ s3cmd get s3://<-Your-Bucket-Name->/rookObj /tmp/rookObj-download --no-ssl --host=${AWS_HOST} --host-bucket=\n\t  download: 's3://ceph-bkt-5124df41-7939-4aa6-b989-2bff0aa38deb/rookObj' -> '/tmp/rookObj-download'  [1 of 1]\n\t   11 of 11   100% in    0s   254.34 B/s  done\n\t$ cat /tmp/rookObj-download\nList the buckets\n\n\t$ s3cmd ls --no-ssl --host=${AWS_HOST} --host-bucket=\n\n## Teardown\n1. First you will need to clean up the resources created on top of the Rook cluster.  \n\n\n\t$ kubectl delete -n rook-ceph cephblockpool replicapool\n\t$ kubectl delete storageclass rook-ceph-block\n\t$ kubectl delete -f csi/cephfs/kube-registry.yaml\n\t$ kubectl delete storageclass csi-cephfs\n2. Delete the CephCluster CRD\n\n\n\t$ kubectl -n rook-ceph delete cephcluster rook-ceph\n3. Delete the Operator and related Resources\n\n\n\t$ kubectl delete -f operator.yaml\n\t$ kubectl delete -f common.yaml\n4. /var/lib/rook: Path on each host in the cluster where configuration is cached by the ceph mons and osds. so need to clean the files in the path.\n\n\n\t$ rm -rf /var/lib/rook/\nAdditional: If there are ceph related files in the \"/var/lib/kubelet/plugins/\" and \"/var/lib/kubelet/plugins_registry/\" path, delete them.\n\n\t$ rm -rf /var/lib/kubelet/plugins/*\n\t$ rm -rf /var/lib/kubelet/plugins_registry/*\n5. Delete the data on hosts\n\n\n\t#!/usr/bin/env bash\n\tDISK=\"/dev/sdb\"\n\t# Zap the disk to a fresh, usable state (zap-all is important, b/c MBR has to be clean)\n\t# You will have to run this step for all disks.\n\tsgdisk --zap-all $DISK\n\tdd if=/dev/zero of=\"$DISK\" bs=1M count=100 oflag=direct,dsync\n\t\n\t# These steps only have to be run once on each node\n\t# If rook sets up osds using ceph-volume, teardown leaves some devices mapped that lock the disks.\n\tls /dev/mapper/ceph-* | xargs -I% -- dmsetup remove %\n\t# ceph-volume setup can leave ceph-<UUID> directories in /dev (unnecessary clutter)\n\trm -rf /dev/ceph-*\n## FAQ\nIf the cluster resource still exists even though you have executed the delete command earlier, see the command below remove the finalizer.\n\n\t$ kubectl -n rook-ceph patch crd cephclusters.ceph.rook.io --type merge -p '{\"metadata\":{\"finalizers\": [null]}}'\n\n\n","slug":"storage/ceph_deployment_02","published":1,"date":"2020-08-12T16:05:48.438Z","updated":"2020-08-11T09:55:11.446Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmgv0069hohx49dx53cu","content":"<p>This document describes the steps to enable Ceph cluster in Kubernetes(k8s)  </p>\n<h2 id=\"Prerequisites\"><a href=\"#Prerequisites\" class=\"headerlink\" title=\"Prerequisites\"></a><strong>Prerequisites</strong></h2><ol>\n<li>A running Kubernetes environmen.  </li>\n</ol>\n<h2 id=\"Setup-steps\"><a href=\"#Setup-steps\" class=\"headerlink\" title=\"Setup steps\"></a><strong>Setup steps</strong></h2><ol>\n<li>The first step is to deploy the Rook operator. Check that you are using the example yaml files that correspond to your release of Rook.  </li>\n</ol>\n<pre><code>$ git clone --single-branch --branch release-1.3 https://github.com/rook/rook.git\n$ cd cluster/examples/kubernetes/ceph\n$ kubectl create -f common.yaml\n$ kubectl create -f operator.yaml\n\nVerify the rook-ceph-operator is in the Running state before proceeding\n$ kubectl -n rook-ceph get pod</code></pre><ol start=\"2\">\n<li>Now that the Rook operator is running we can create the Ceph cluster. For the cluster to survive reboots, make sure you set the dataDirHostPath property that is valid for your hosts.  </li>\n</ol>\n<pre><code>$ kubectl create -f cluster.yaml</code></pre><ol start=\"3\">\n<li>Use kubectl to list pods in the rook-ceph namespace. You should be able to see the following pods once they are all running. The number of osd pods will depend on the number of nodes in the cluster and the number of devices configured. If you did not modify the cluster.yaml above, it is expected that one OSD will be created per node. The CSI, rook-ceph-agent, and rook-discover pods are also optional depending on your settings.  </li>\n</ol>\n<pre><code>$ kubectl -n rook-ceph get pod\n  NAME                                                 READY   STATUS      RESTARTS   AGE\n  csi-cephfsplugin-provisioner-d77bb49c6-n5tgs         5/5     Running     0          140s\n  csi-cephfsplugin-provisioner-d77bb49c6-v9rvn         5/5     Running     0          140s\n  csi-cephfsplugin-rthrp                               3/3     Running     0          140s\n  csi-rbdplugin-hbsm7                                  3/3     Running     0          140s\n  csi-rbdplugin-provisioner-5b5cd64fd-nvk6c            6/6     Running     0          140s\n  csi-rbdplugin-provisioner-5b5cd64fd-q7bxl            6/6     Running     0          140s\n  rook-ceph-agent-4zkg8                                1/1     Running     0          140s\n  rook-ceph-crashcollector-minikube-5b57b7c5d4-hfldl   1/1     Running     0          105s\n  rook-ceph-mgr-a-64cd7cdf54-j8b5p                     1/1     Running     0          77s\n  rook-ceph-mon-a-694bb7987d-fp9w7                     1/1     Running     0          105s\n  rook-ceph-mon-b-856fdd5cb9-5h2qk                     1/1     Running     0          94s\n  rook-ceph-mon-c-57545897fc-j576h                     1/1     Running     0          85s\n  rook-ceph-operator-85f5b946bd-s8grz                  1/1     Running     0          92m\n  rook-ceph-osd-0-6bb747b6c5-lnvb6                     1/1     Running     0          23s\n  rook-ceph-osd-1-7f67f9646d-44p7v                     1/1     Running     0          24s\n  rook-ceph-osd-2-6cd4b776ff-v4d68                     1/1     Running     0          25s\n  rook-ceph-osd-prepare-node1-vx2rz                    0/2     Completed   0          60s\n  rook-ceph-osd-prepare-node2-ab3fd                    0/2     Completed   0          60s\n  rook-ceph-osd-prepare-node3-w4xyz                    0/2     Completed   0          60s\n  rook-discover-dhkb8                                  1/1     Running     0          140s</code></pre><ol start=\"4\">\n<li>To verify that the cluster is in a healthy state, connect to the Rook toolbox and run the ceph status command.  </li>\n</ol>\n<ul>\n<li>All mons should be in quorum  </li>\n<li>A mgr should be active  </li>\n<li>At least one OSD should be active  </li>\n<li>If the health is not HEALTH_OK, the warnings or errors should be investigated.  </li>\n</ul>\n<p>Running the Toolbox in Kubernetes:  </p>\n<pre><code>$ kubectl create -f toolbox.yaml</code></pre><p>Wait for the toolbox pod to download its container and get to the running state:</p>\n<pre><code>$ kubectl -n rook-ceph get pod -l &quot;app=rook-ceph-tools&quot;</code></pre><p>Once the rook-ceph-tools pod is running, you can connect to it with:</p>\n<pre><code>$ kubectl -n rook-ceph exec -it $(kubectl -n rook-ceph get pod -l &quot;app=rook-ceph-tools&quot; -o jsonpath=&apos;{.items[0].metadata.name}&apos;) bash</code></pre><p>Example:</p>\n<pre><code>$ ceph status\n  cluster:\n    id:     a0452c76-30d9-4c1a-a948-5d8405f19a7c\n    health: HEALTH_OK\n\n  services:\n    mon: 3 daemons, quorum a,b,c (age 3m)\n    mgr: a(active, since 2m)\n    osd: 3 osds: 3 up (since 1m), 3 in (since 1m)\n...</code></pre><p>When you are done with the toolbox, you can remove the deployment, but if you want continue to doing other test experiments below, please keep the toolbox:</p>\n<pre><code>$ kubectl -n rook-ceph delete deployment rook-ceph-tools</code></pre><h2 id=\"Object-Store\"><a href=\"#Object-Store\" class=\"headerlink\" title=\"Object Store\"></a><strong>Object Store</strong></h2><h3 id=\"1-Create-an-Object-Store\"><a href=\"#1-Create-an-Object-Store\" class=\"headerlink\" title=\"1. Create an Object Store\"></a>1. Create an Object Store</h3><pre><code>$ cd cluster/examples/kubernetes/ceph\n// Create the object store\n$ kubectl create -f object.yaml\n// To confirm the object store is configured, wait for the rgw pod to start\n$ kubectl -n rook-ceph get pod -l app=rook-ceph-rgw</code></pre><h3 id=\"2-Define-a-storage-class-that-will-allow-object-clients-to-create-a-bucket\"><a href=\"#2-Define-a-storage-class-that-will-allow-object-clients-to-create-a-bucket\" class=\"headerlink\" title=\"2. Define a storage class that will allow object clients to create a bucket.\"></a>2. Define a storage class that will allow object clients to create a bucket.</h3><pre><code>// Define the storage class that will allow object clients to create a bucket\n$ kubectl create -f storageclass-bucket-delete.yaml</code></pre><h3 id=\"3-1-Create-a-Bucket\"><a href=\"#3-1-Create-a-Bucket\" class=\"headerlink\" title=\"3.1 Create a Bucket\"></a>3.1 Create a Bucket</h3><p>An Object Bucket Claim (OBC) is custom resource which requests a bucket (new or existing) and is described by a Custom Resource Definition (CRD).</p>\n<pre><code>// Create an Object Bucket Claim (OBC) \n$ kubectl create -f object-bucket-claim-delete.yaml</code></pre><p>When the OBC is created, the Rook-Ceph bucket provisioner will create a new bucket.A <code>secret</code> and <code>ConfigMap</code> are created with the same name as the OBC and in the same namespace. The secret contains credentials used by the application pod to access the bucket. The ConfigMap contains bucket endpoint information and is also consumed by the pod. </p>\n<pre><code>// Check the created bucket name, &quot;ceph-bkt-5124df41-7939-4aa6-b989-2bff0aa38deb&quot; as shown below.\n$ kubectl describe obc ceph-delete-bucket\n  ......\n  Spec:\n    Object Bucket Name:    obc-default-ceph-delete-bucket\n    Bucket Name:           ceph-bkt-5124df41-7939-4aa6-b989-2bff0aa38deb\n    Generate Bucket Name:  ceph-bkt\n    Storage Class Name:    rook-ceph-delete-bucket\n  Status:\n    Phase:  Bound        // [Notice]: The Status must be Bound, if `Pending`, please wait or delete and recreate the obc.\n  Events:   &lt;none&gt;</code></pre><p>An Object Bucket (OB) is a custom resource automatically generated when a bucket is provisioned. It is a global resource, typically not visible to non-admin users, and contains information specific to the bucket. It is described by an OB CRD.</p>\n<pre><code>// Check the OB\n$ kubectl get ob\n  NAME                             AGE\n  obc-default-ceph-delete-bucket   5m16s</code></pre><h3 id=\"3-2-Create-another-Bucket\"><a href=\"#3-2-Create-another-Bucket\" class=\"headerlink\" title=\"3.2 Create another Bucket\"></a>3.2 Create another Bucket</h3><p>Change the ObjectBucketClaim metadata.name and create another bucket.</p>\n<pre><code>$ vim object-bucket-claim-delete.yaml\n  apiVersion: objectbucket.io/v1alpha1\n  kind: ObjectBucketClaim\n  metadata:\n    name: ceph-bucket-new        # Change bucket name\n  spec:\n    generateBucketName: ceph-bkt\n    storageClassName: rook-ceph-bucket\n$ kubectl create -f object-bucket-claim-delete.yaml</code></pre><p><strong>Client Connections</strong><br>The following commands extract key pieces of information from the secret and configmap:</p>\n<pre><code>// config-map, secret, OBC will part of default if no specific name space mentioned\n$ export AWS_HOST=$(kubectl -n default get cm ceph-delete-bucket -o yaml | grep BUCKET_HOST | awk &apos;{print $2}&apos; | awk &apos;NR==1&apos;)\n$ export AWS_ACCESS_KEY_ID=$(kubectl -n default get secret ceph-delete-bucket -o yaml | grep AWS_ACCESS_KEY_ID | awk &apos;{print $2}&apos; | awk &apos;NR==1&apos;| base64 --decode)\n$ export AWS_SECRET_ACCESS_KEY=$(kubectl -n default get secret ceph-delete-bucket -o yaml | grep AWS_SECRET_ACCESS_KEY | awk &apos;{print $2}&apos; | awk &apos;NR==1&apos;| base64 --decode)</code></pre><h3 id=\"4-Consume-the-Object-Storage\"><a href=\"#4-Consume-the-Object-Storage\" class=\"headerlink\" title=\"4. Consume the Object Storage\"></a>4. Consume the Object Storage</h3><p><strong>Enter into the toolbox</strong></p>\n<pre><code>kubectl exec $(kubectl get po -l app=rook-ceph-tools -n rook-ceph -o jsonpath=&apos;{.items[0].metadata.name}&apos;) -it -n rook-ceph -- bash</code></pre><p>Connected to the Rook toolbox Pod and then set the four environment variables for use by your client(ie. inside the toolbox).</p>\n<pre><code>$ export AWS_HOST=&lt;host&gt;\n$ export AWS_ENDPOINT=&lt;endpoint&gt;\n$ export AWS_ACCESS_KEY_ID=&lt;accessKey&gt;\n$ export AWS_SECRET_ACCESS_KEY=&lt;secretKey&gt;</code></pre><p>Endpoint: The endpoint where the rgw service is listening. Run <code>kubectl -n rook-ceph get svc rook-ceph-rgw-my-store</code>, then combine the clusterIP and the port.</p>\n<p><strong>Install s3cmd</strong></p>\n<pre><code>$ echo proxy=http://Proxy-Name:913 &gt;&gt; /etc/yum.conf\n$ yum --assumeyes install s3cmd</code></pre><p><strong>PUT or GET an object</strong><br>Upload a file to the newly created bucket</p>\n<pre><code>$ echo &quot;Hello Rook&quot; &gt; /tmp/rookObj\n$ s3cmd put /tmp/rookObj --no-ssl --host=${AWS_HOST} --host-bucket=  s3://&lt;-Your-Bucket-Name-&gt; // As follow.\n// $ s3cmd put /tmp/rookObj --no-ssl --host=${AWS_HOST} --host-bucket=  s3://ceph-bkt-5124df41-7939-4aa6-b989-2bff0aa38deb\n  upload: &apos;/tmp/rookObj&apos; -&gt; &apos;s3://ceph-bkt-5124df41-7939-4aa6-b989-2bff0aa38deb/rookObj&apos;  [1 of 1]\n   11 of 11   100% in    0s   190.11 B/s  done</code></pre><p>Download and verify the file from the bucket</p>\n<pre><code>$ s3cmd get s3://&lt;-Your-Bucket-Name-&gt;/rookObj /tmp/rookObj-download --no-ssl --host=${AWS_HOST} --host-bucket=\n  download: &apos;s3://ceph-bkt-5124df41-7939-4aa6-b989-2bff0aa38deb/rookObj&apos; -&gt; &apos;/tmp/rookObj-download&apos;  [1 of 1]\n   11 of 11   100% in    0s   254.34 B/s  done\n$ cat /tmp/rookObj-download</code></pre><p>List the buckets</p>\n<pre><code>$ s3cmd ls --no-ssl --host=${AWS_HOST} --host-bucket=</code></pre><h2 id=\"Teardown\"><a href=\"#Teardown\" class=\"headerlink\" title=\"Teardown\"></a>Teardown</h2><ol>\n<li>First you will need to clean up the resources created on top of the Rook cluster.  </li>\n</ol>\n<pre><code>$ kubectl delete -n rook-ceph cephblockpool replicapool\n$ kubectl delete storageclass rook-ceph-block\n$ kubectl delete -f csi/cephfs/kube-registry.yaml\n$ kubectl delete storageclass csi-cephfs</code></pre><ol start=\"2\">\n<li>Delete the CephCluster CRD</li>\n</ol>\n<pre><code>$ kubectl -n rook-ceph delete cephcluster rook-ceph</code></pre><ol start=\"3\">\n<li>Delete the Operator and related Resources</li>\n</ol>\n<pre><code>$ kubectl delete -f operator.yaml\n$ kubectl delete -f common.yaml</code></pre><ol start=\"4\">\n<li>/var/lib/rook: Path on each host in the cluster where configuration is cached by the ceph mons and osds. so need to clean the files in the path.</li>\n</ol>\n<pre><code>$ rm -rf /var/lib/rook/</code></pre><p>Additional: If there are ceph related files in the “/var/lib/kubelet/plugins/“ and “/var/lib/kubelet/plugins_registry/“ path, delete them.</p>\n<pre><code>$ rm -rf /var/lib/kubelet/plugins/*\n$ rm -rf /var/lib/kubelet/plugins_registry/*</code></pre><ol start=\"5\">\n<li>Delete the data on hosts</li>\n</ol>\n<pre><code>#!/usr/bin/env bash\nDISK=&quot;/dev/sdb&quot;\n# Zap the disk to a fresh, usable state (zap-all is important, b/c MBR has to be clean)\n# You will have to run this step for all disks.\nsgdisk --zap-all $DISK\ndd if=/dev/zero of=&quot;$DISK&quot; bs=1M count=100 oflag=direct,dsync\n\n# These steps only have to be run once on each node\n# If rook sets up osds using ceph-volume, teardown leaves some devices mapped that lock the disks.\nls /dev/mapper/ceph-* | xargs -I% -- dmsetup remove %\n# ceph-volume setup can leave ceph-&lt;UUID&gt; directories in /dev (unnecessary clutter)\nrm -rf /dev/ceph-*</code></pre><h2 id=\"FAQ\"><a href=\"#FAQ\" class=\"headerlink\" title=\"FAQ\"></a>FAQ</h2><p>If the cluster resource still exists even though you have executed the delete command earlier, see the command below remove the finalizer.</p>\n<pre><code>$ kubectl -n rook-ceph patch crd cephclusters.ceph.rook.io --type merge -p &apos;{&quot;metadata&quot;:{&quot;finalizers&quot;: [null]}}&apos;</code></pre>","site":{"data":{}},"excerpt":"","more":"<p>This document describes the steps to enable Ceph cluster in Kubernetes(k8s)  </p>\n<h2 id=\"Prerequisites\"><a href=\"#Prerequisites\" class=\"headerlink\" title=\"Prerequisites\"></a><strong>Prerequisites</strong></h2><ol>\n<li>A running Kubernetes environmen.  </li>\n</ol>\n<h2 id=\"Setup-steps\"><a href=\"#Setup-steps\" class=\"headerlink\" title=\"Setup steps\"></a><strong>Setup steps</strong></h2><ol>\n<li>The first step is to deploy the Rook operator. Check that you are using the example yaml files that correspond to your release of Rook.  </li>\n</ol>\n<pre><code>$ git clone --single-branch --branch release-1.3 https://github.com/rook/rook.git\n$ cd cluster/examples/kubernetes/ceph\n$ kubectl create -f common.yaml\n$ kubectl create -f operator.yaml\n\nVerify the rook-ceph-operator is in the Running state before proceeding\n$ kubectl -n rook-ceph get pod</code></pre><ol start=\"2\">\n<li>Now that the Rook operator is running we can create the Ceph cluster. For the cluster to survive reboots, make sure you set the dataDirHostPath property that is valid for your hosts.  </li>\n</ol>\n<pre><code>$ kubectl create -f cluster.yaml</code></pre><ol start=\"3\">\n<li>Use kubectl to list pods in the rook-ceph namespace. You should be able to see the following pods once they are all running. The number of osd pods will depend on the number of nodes in the cluster and the number of devices configured. If you did not modify the cluster.yaml above, it is expected that one OSD will be created per node. The CSI, rook-ceph-agent, and rook-discover pods are also optional depending on your settings.  </li>\n</ol>\n<pre><code>$ kubectl -n rook-ceph get pod\n  NAME                                                 READY   STATUS      RESTARTS   AGE\n  csi-cephfsplugin-provisioner-d77bb49c6-n5tgs         5/5     Running     0          140s\n  csi-cephfsplugin-provisioner-d77bb49c6-v9rvn         5/5     Running     0          140s\n  csi-cephfsplugin-rthrp                               3/3     Running     0          140s\n  csi-rbdplugin-hbsm7                                  3/3     Running     0          140s\n  csi-rbdplugin-provisioner-5b5cd64fd-nvk6c            6/6     Running     0          140s\n  csi-rbdplugin-provisioner-5b5cd64fd-q7bxl            6/6     Running     0          140s\n  rook-ceph-agent-4zkg8                                1/1     Running     0          140s\n  rook-ceph-crashcollector-minikube-5b57b7c5d4-hfldl   1/1     Running     0          105s\n  rook-ceph-mgr-a-64cd7cdf54-j8b5p                     1/1     Running     0          77s\n  rook-ceph-mon-a-694bb7987d-fp9w7                     1/1     Running     0          105s\n  rook-ceph-mon-b-856fdd5cb9-5h2qk                     1/1     Running     0          94s\n  rook-ceph-mon-c-57545897fc-j576h                     1/1     Running     0          85s\n  rook-ceph-operator-85f5b946bd-s8grz                  1/1     Running     0          92m\n  rook-ceph-osd-0-6bb747b6c5-lnvb6                     1/1     Running     0          23s\n  rook-ceph-osd-1-7f67f9646d-44p7v                     1/1     Running     0          24s\n  rook-ceph-osd-2-6cd4b776ff-v4d68                     1/1     Running     0          25s\n  rook-ceph-osd-prepare-node1-vx2rz                    0/2     Completed   0          60s\n  rook-ceph-osd-prepare-node2-ab3fd                    0/2     Completed   0          60s\n  rook-ceph-osd-prepare-node3-w4xyz                    0/2     Completed   0          60s\n  rook-discover-dhkb8                                  1/1     Running     0          140s</code></pre><ol start=\"4\">\n<li>To verify that the cluster is in a healthy state, connect to the Rook toolbox and run the ceph status command.  </li>\n</ol>\n<ul>\n<li>All mons should be in quorum  </li>\n<li>A mgr should be active  </li>\n<li>At least one OSD should be active  </li>\n<li>If the health is not HEALTH_OK, the warnings or errors should be investigated.  </li>\n</ul>\n<p>Running the Toolbox in Kubernetes:  </p>\n<pre><code>$ kubectl create -f toolbox.yaml</code></pre><p>Wait for the toolbox pod to download its container and get to the running state:</p>\n<pre><code>$ kubectl -n rook-ceph get pod -l &quot;app=rook-ceph-tools&quot;</code></pre><p>Once the rook-ceph-tools pod is running, you can connect to it with:</p>\n<pre><code>$ kubectl -n rook-ceph exec -it $(kubectl -n rook-ceph get pod -l &quot;app=rook-ceph-tools&quot; -o jsonpath=&apos;{.items[0].metadata.name}&apos;) bash</code></pre><p>Example:</p>\n<pre><code>$ ceph status\n  cluster:\n    id:     a0452c76-30d9-4c1a-a948-5d8405f19a7c\n    health: HEALTH_OK\n\n  services:\n    mon: 3 daemons, quorum a,b,c (age 3m)\n    mgr: a(active, since 2m)\n    osd: 3 osds: 3 up (since 1m), 3 in (since 1m)\n...</code></pre><p>When you are done with the toolbox, you can remove the deployment, but if you want continue to doing other test experiments below, please keep the toolbox:</p>\n<pre><code>$ kubectl -n rook-ceph delete deployment rook-ceph-tools</code></pre><h2 id=\"Object-Store\"><a href=\"#Object-Store\" class=\"headerlink\" title=\"Object Store\"></a><strong>Object Store</strong></h2><h3 id=\"1-Create-an-Object-Store\"><a href=\"#1-Create-an-Object-Store\" class=\"headerlink\" title=\"1. Create an Object Store\"></a>1. Create an Object Store</h3><pre><code>$ cd cluster/examples/kubernetes/ceph\n// Create the object store\n$ kubectl create -f object.yaml\n// To confirm the object store is configured, wait for the rgw pod to start\n$ kubectl -n rook-ceph get pod -l app=rook-ceph-rgw</code></pre><h3 id=\"2-Define-a-storage-class-that-will-allow-object-clients-to-create-a-bucket\"><a href=\"#2-Define-a-storage-class-that-will-allow-object-clients-to-create-a-bucket\" class=\"headerlink\" title=\"2. Define a storage class that will allow object clients to create a bucket.\"></a>2. Define a storage class that will allow object clients to create a bucket.</h3><pre><code>// Define the storage class that will allow object clients to create a bucket\n$ kubectl create -f storageclass-bucket-delete.yaml</code></pre><h3 id=\"3-1-Create-a-Bucket\"><a href=\"#3-1-Create-a-Bucket\" class=\"headerlink\" title=\"3.1 Create a Bucket\"></a>3.1 Create a Bucket</h3><p>An Object Bucket Claim (OBC) is custom resource which requests a bucket (new or existing) and is described by a Custom Resource Definition (CRD).</p>\n<pre><code>// Create an Object Bucket Claim (OBC) \n$ kubectl create -f object-bucket-claim-delete.yaml</code></pre><p>When the OBC is created, the Rook-Ceph bucket provisioner will create a new bucket.A <code>secret</code> and <code>ConfigMap</code> are created with the same name as the OBC and in the same namespace. The secret contains credentials used by the application pod to access the bucket. The ConfigMap contains bucket endpoint information and is also consumed by the pod. </p>\n<pre><code>// Check the created bucket name, &quot;ceph-bkt-5124df41-7939-4aa6-b989-2bff0aa38deb&quot; as shown below.\n$ kubectl describe obc ceph-delete-bucket\n  ......\n  Spec:\n    Object Bucket Name:    obc-default-ceph-delete-bucket\n    Bucket Name:           ceph-bkt-5124df41-7939-4aa6-b989-2bff0aa38deb\n    Generate Bucket Name:  ceph-bkt\n    Storage Class Name:    rook-ceph-delete-bucket\n  Status:\n    Phase:  Bound        // [Notice]: The Status must be Bound, if `Pending`, please wait or delete and recreate the obc.\n  Events:   &lt;none&gt;</code></pre><p>An Object Bucket (OB) is a custom resource automatically generated when a bucket is provisioned. It is a global resource, typically not visible to non-admin users, and contains information specific to the bucket. It is described by an OB CRD.</p>\n<pre><code>// Check the OB\n$ kubectl get ob\n  NAME                             AGE\n  obc-default-ceph-delete-bucket   5m16s</code></pre><h3 id=\"3-2-Create-another-Bucket\"><a href=\"#3-2-Create-another-Bucket\" class=\"headerlink\" title=\"3.2 Create another Bucket\"></a>3.2 Create another Bucket</h3><p>Change the ObjectBucketClaim metadata.name and create another bucket.</p>\n<pre><code>$ vim object-bucket-claim-delete.yaml\n  apiVersion: objectbucket.io/v1alpha1\n  kind: ObjectBucketClaim\n  metadata:\n    name: ceph-bucket-new        # Change bucket name\n  spec:\n    generateBucketName: ceph-bkt\n    storageClassName: rook-ceph-bucket\n$ kubectl create -f object-bucket-claim-delete.yaml</code></pre><p><strong>Client Connections</strong><br>The following commands extract key pieces of information from the secret and configmap:</p>\n<pre><code>// config-map, secret, OBC will part of default if no specific name space mentioned\n$ export AWS_HOST=$(kubectl -n default get cm ceph-delete-bucket -o yaml | grep BUCKET_HOST | awk &apos;{print $2}&apos; | awk &apos;NR==1&apos;)\n$ export AWS_ACCESS_KEY_ID=$(kubectl -n default get secret ceph-delete-bucket -o yaml | grep AWS_ACCESS_KEY_ID | awk &apos;{print $2}&apos; | awk &apos;NR==1&apos;| base64 --decode)\n$ export AWS_SECRET_ACCESS_KEY=$(kubectl -n default get secret ceph-delete-bucket -o yaml | grep AWS_SECRET_ACCESS_KEY | awk &apos;{print $2}&apos; | awk &apos;NR==1&apos;| base64 --decode)</code></pre><h3 id=\"4-Consume-the-Object-Storage\"><a href=\"#4-Consume-the-Object-Storage\" class=\"headerlink\" title=\"4. Consume the Object Storage\"></a>4. Consume the Object Storage</h3><p><strong>Enter into the toolbox</strong></p>\n<pre><code>kubectl exec $(kubectl get po -l app=rook-ceph-tools -n rook-ceph -o jsonpath=&apos;{.items[0].metadata.name}&apos;) -it -n rook-ceph -- bash</code></pre><p>Connected to the Rook toolbox Pod and then set the four environment variables for use by your client(ie. inside the toolbox).</p>\n<pre><code>$ export AWS_HOST=&lt;host&gt;\n$ export AWS_ENDPOINT=&lt;endpoint&gt;\n$ export AWS_ACCESS_KEY_ID=&lt;accessKey&gt;\n$ export AWS_SECRET_ACCESS_KEY=&lt;secretKey&gt;</code></pre><p>Endpoint: The endpoint where the rgw service is listening. Run <code>kubectl -n rook-ceph get svc rook-ceph-rgw-my-store</code>, then combine the clusterIP and the port.</p>\n<p><strong>Install s3cmd</strong></p>\n<pre><code>$ echo proxy=http://Proxy-Name:913 &gt;&gt; /etc/yum.conf\n$ yum --assumeyes install s3cmd</code></pre><p><strong>PUT or GET an object</strong><br>Upload a file to the newly created bucket</p>\n<pre><code>$ echo &quot;Hello Rook&quot; &gt; /tmp/rookObj\n$ s3cmd put /tmp/rookObj --no-ssl --host=${AWS_HOST} --host-bucket=  s3://&lt;-Your-Bucket-Name-&gt; // As follow.\n// $ s3cmd put /tmp/rookObj --no-ssl --host=${AWS_HOST} --host-bucket=  s3://ceph-bkt-5124df41-7939-4aa6-b989-2bff0aa38deb\n  upload: &apos;/tmp/rookObj&apos; -&gt; &apos;s3://ceph-bkt-5124df41-7939-4aa6-b989-2bff0aa38deb/rookObj&apos;  [1 of 1]\n   11 of 11   100% in    0s   190.11 B/s  done</code></pre><p>Download and verify the file from the bucket</p>\n<pre><code>$ s3cmd get s3://&lt;-Your-Bucket-Name-&gt;/rookObj /tmp/rookObj-download --no-ssl --host=${AWS_HOST} --host-bucket=\n  download: &apos;s3://ceph-bkt-5124df41-7939-4aa6-b989-2bff0aa38deb/rookObj&apos; -&gt; &apos;/tmp/rookObj-download&apos;  [1 of 1]\n   11 of 11   100% in    0s   254.34 B/s  done\n$ cat /tmp/rookObj-download</code></pre><p>List the buckets</p>\n<pre><code>$ s3cmd ls --no-ssl --host=${AWS_HOST} --host-bucket=</code></pre><h2 id=\"Teardown\"><a href=\"#Teardown\" class=\"headerlink\" title=\"Teardown\"></a>Teardown</h2><ol>\n<li>First you will need to clean up the resources created on top of the Rook cluster.  </li>\n</ol>\n<pre><code>$ kubectl delete -n rook-ceph cephblockpool replicapool\n$ kubectl delete storageclass rook-ceph-block\n$ kubectl delete -f csi/cephfs/kube-registry.yaml\n$ kubectl delete storageclass csi-cephfs</code></pre><ol start=\"2\">\n<li>Delete the CephCluster CRD</li>\n</ol>\n<pre><code>$ kubectl -n rook-ceph delete cephcluster rook-ceph</code></pre><ol start=\"3\">\n<li>Delete the Operator and related Resources</li>\n</ol>\n<pre><code>$ kubectl delete -f operator.yaml\n$ kubectl delete -f common.yaml</code></pre><ol start=\"4\">\n<li>/var/lib/rook: Path on each host in the cluster where configuration is cached by the ceph mons and osds. so need to clean the files in the path.</li>\n</ol>\n<pre><code>$ rm -rf /var/lib/rook/</code></pre><p>Additional: If there are ceph related files in the “/var/lib/kubelet/plugins/“ and “/var/lib/kubelet/plugins_registry/“ path, delete them.</p>\n<pre><code>$ rm -rf /var/lib/kubelet/plugins/*\n$ rm -rf /var/lib/kubelet/plugins_registry/*</code></pre><ol start=\"5\">\n<li>Delete the data on hosts</li>\n</ol>\n<pre><code>#!/usr/bin/env bash\nDISK=&quot;/dev/sdb&quot;\n# Zap the disk to a fresh, usable state (zap-all is important, b/c MBR has to be clean)\n# You will have to run this step for all disks.\nsgdisk --zap-all $DISK\ndd if=/dev/zero of=&quot;$DISK&quot; bs=1M count=100 oflag=direct,dsync\n\n# These steps only have to be run once on each node\n# If rook sets up osds using ceph-volume, teardown leaves some devices mapped that lock the disks.\nls /dev/mapper/ceph-* | xargs -I% -- dmsetup remove %\n# ceph-volume setup can leave ceph-&lt;UUID&gt; directories in /dev (unnecessary clutter)\nrm -rf /dev/ceph-*</code></pre><h2 id=\"FAQ\"><a href=\"#FAQ\" class=\"headerlink\" title=\"FAQ\"></a>FAQ</h2><p>If the cluster resource still exists even though you have executed the delete command earlier, see the command below remove the finalizer.</p>\n<pre><code>$ kubectl -n rook-ceph patch crd cephclusters.ceph.rook.io --type merge -p &apos;{&quot;metadata&quot;:{&quot;finalizers&quot;: [null]}}&apos;</code></pre>"},{"title":"MinIO deployment on kubernetes","_content":"在storage仓库里也存储了一份当时部署所使用的yaml等资源文件.\n\nQuick start:  \n  [https://docs.min.io/docs/minio-quickstart-guide.html](https://docs.min.io/docs/minio-quickstart-guide.html)\nDeployment on kubernetes:  \n  [https://docs.min.io/docs/deploy-minio-on-kubernetes.html](https://docs.min.io/docs/deploy-minio-on-kubernetes.html)\n  [https://github.com/minio/operator/blob/master/README.md](https://github.com/minio/operator/blob/master/README.md)\nEnable TLS:  \n  [https://github.com/minio/operator/blob/master/docs/tls.md](https://github.com/minio/operator/blob/master/docs/tls.md)\n\n## Prerequisites\n1. Kubernetes version v1.17.0 and above for compatibility. MinIO Operator uses k8s/client-go v0.18.0.\n2. kubectl configured to refer to a Kubernetes cluster.\n3. Create the required PVs as [direct CSI driver.](https://github.com/minio/minio-operator/blob/master/docs/using-direct-csi.md) or use the following installation step.\n\n## Using Direct CSI Driver\n\n\tcat << EOF > default.env\n\tDIRECT_CSI_DRIVES=data{1...4}\n\tDIRECT_CSI_DRIVES_DIR=/mnt\n\tEOF\n\t\n\t$ export $(cat default.env)\n\t$ kubectl apply -k direct-csi\n\n## Create Operator Deployment\n1. Create namespace minio for minIO to deploy.\n\n\n\t$ kubectl create ns minio\n2. To start MinIO-Operator with default configuration, use the minio-operator.yaml file.\n\n\n\t$ kubectl apply -f minio-operator.yaml -n minio\n\n## Create MinIO instances without tls\nOnce MinIO-Operator deployment is running, you can create MinIO instances using the below command\n\n\t$ kubectl apply -f minioinstance.yaml\n## Create NodePort service for minIO\n\n\t$ kubectl apply -f NodePort-minio.yaml\n## Access minIO from the browser\n\n\t// Minio Server没有配置TLS\n\t浏览器输入: http://127.0.0.1:30007\n\tdefault username: minio\n\tdefault password: minio123\n\t// Minio Server配置TLS\n\t浏览器输入: https://127.0.0.1:30007\n\n## **Secure access to MinIO server with TLS**\n**1.1. Generate a private key with ECDSA**\n\n\n\t$ openssl ecparam -genkey -name prime256v1 | openssl ec -out private.key\n\t  read EC key\n\t  writing EC key\nAlternatively, use the following command to generate a private ECDSA key protected by a password:\n\n\t$ openssl ecparam -genkey -name prime256v1 | openssl ec -aes256 -out private.key -passout pass:<PASSWORD>\n**1.2 Generate a private key with RSA.**\nUse the following command to generate a private key with RSA:\n\n\n\t$ openssl genrsa -out private.key 2048\n\tGenerating RSA private key, 2048 bit long modulus\n\t............................................+++\n\t...........+++\n\te is 65537 (0x10001)\n\t// openssl查看证书内容\n\t$ openssl rsa -in private.key -text -noout\nAlternatively, use the following command to generate a private RSA key protected by a password:\n\n\t$ openssl genrsa -aes256 -out private.key 2048 -passout pass:<PASSWORD>\n**Note:** When using a password-protected private key, the password must be provided through the environment variable MINIO_CERT_PASSWD using the following command:\n\n\t$ export MINIO_CERT_PASSWD=<PASSWORD>\n\t// 也就是在minioinstance.yaml中添加如下信息\n\tenv:\n\t  - MINIO_CERT_PASSWD\n\t    value: \"<YourPassword>\"\t\t// 一定要加上双引号\"\"\n**2. Generate a self-signed certificate.**\nUse the following command to generate a self-signed certificate and enter a passphrase when prompted:\n\n\n\t$ openssl req -new -x509 -days 3650 -key private.key -out public.crt -subj \"/C=US/ST=state/L=location/O=organization/CN=<domain.com>\"\n\t// 查看证书签名,算法,public key等信息\n\t$ openssl x509 -in public.crt -text -noout\n**Note:** Replace <domain.com> with the development domain name.\nAlternatively, use the command below to generate a self-signed wildcard certificate that is valid for all subdomains under <domain.com>. Wildcard certificates are useful for `deploying distributed MinIO instances`, where each instance runs on a subdomain under a single parent domain.\n\n\t$ openssl req -new -x509 -days 3650 -key private.key -out public.crt -subj \"/C=US/ST=state/L=location/O=organization/CN=*.minio-hl-svc.minio.svc.cluster.local\"\n**Note: 若是不知道怎么确定`<*.domain.com>`信息, 添加TLS后部署minio发现pod启动异常或者访问minio服务不正常, 查看pod的日志,`$ kubectl logs po/minio-0 -n minio`, 即可看到pod出现error信息，显示需要的certificates的commanName(简称CN), 然后将不同pod证书不同的内容用`*`替代, 其它的照搬，如上的例子`*.minio-hl-svc.minio.svc.cluster.local`.**\n\n**3. Use a Kubernetes Secret resource to store this information, create a Kubernetes Secret using:**\n\n\n\t$ kubectl create secret generic tls-ssl-minio --from-file=***/pki/private.key --from-file=***/pki/public.crt -n minio\n再将tenant.yaml或者改过名的minioinstance.yaml文件中的下列注释内容打开\n\n\texternalCertSecret:\n\t  name: tls-ssl-minio\n然后再重新部署minio\n\n\t$ kubectl apply -f minioinstance.yaml\n\n\n\n","source":"_posts/storage/minIO_02_deployment_on_kubernetes.md","raw":"---\ntitle: MinIO deployment on kubernetes\ntags: storage\ncategories:\n- storage\n---\n在storage仓库里也存储了一份当时部署所使用的yaml等资源文件.\n\nQuick start:  \n  [https://docs.min.io/docs/minio-quickstart-guide.html](https://docs.min.io/docs/minio-quickstart-guide.html)\nDeployment on kubernetes:  \n  [https://docs.min.io/docs/deploy-minio-on-kubernetes.html](https://docs.min.io/docs/deploy-minio-on-kubernetes.html)\n  [https://github.com/minio/operator/blob/master/README.md](https://github.com/minio/operator/blob/master/README.md)\nEnable TLS:  \n  [https://github.com/minio/operator/blob/master/docs/tls.md](https://github.com/minio/operator/blob/master/docs/tls.md)\n\n## Prerequisites\n1. Kubernetes version v1.17.0 and above for compatibility. MinIO Operator uses k8s/client-go v0.18.0.\n2. kubectl configured to refer to a Kubernetes cluster.\n3. Create the required PVs as [direct CSI driver.](https://github.com/minio/minio-operator/blob/master/docs/using-direct-csi.md) or use the following installation step.\n\n## Using Direct CSI Driver\n\n\tcat << EOF > default.env\n\tDIRECT_CSI_DRIVES=data{1...4}\n\tDIRECT_CSI_DRIVES_DIR=/mnt\n\tEOF\n\t\n\t$ export $(cat default.env)\n\t$ kubectl apply -k direct-csi\n\n## Create Operator Deployment\n1. Create namespace minio for minIO to deploy.\n\n\n\t$ kubectl create ns minio\n2. To start MinIO-Operator with default configuration, use the minio-operator.yaml file.\n\n\n\t$ kubectl apply -f minio-operator.yaml -n minio\n\n## Create MinIO instances without tls\nOnce MinIO-Operator deployment is running, you can create MinIO instances using the below command\n\n\t$ kubectl apply -f minioinstance.yaml\n## Create NodePort service for minIO\n\n\t$ kubectl apply -f NodePort-minio.yaml\n## Access minIO from the browser\n\n\t// Minio Server没有配置TLS\n\t浏览器输入: http://127.0.0.1:30007\n\tdefault username: minio\n\tdefault password: minio123\n\t// Minio Server配置TLS\n\t浏览器输入: https://127.0.0.1:30007\n\n## **Secure access to MinIO server with TLS**\n**1.1. Generate a private key with ECDSA**\n\n\n\t$ openssl ecparam -genkey -name prime256v1 | openssl ec -out private.key\n\t  read EC key\n\t  writing EC key\nAlternatively, use the following command to generate a private ECDSA key protected by a password:\n\n\t$ openssl ecparam -genkey -name prime256v1 | openssl ec -aes256 -out private.key -passout pass:<PASSWORD>\n**1.2 Generate a private key with RSA.**\nUse the following command to generate a private key with RSA:\n\n\n\t$ openssl genrsa -out private.key 2048\n\tGenerating RSA private key, 2048 bit long modulus\n\t............................................+++\n\t...........+++\n\te is 65537 (0x10001)\n\t// openssl查看证书内容\n\t$ openssl rsa -in private.key -text -noout\nAlternatively, use the following command to generate a private RSA key protected by a password:\n\n\t$ openssl genrsa -aes256 -out private.key 2048 -passout pass:<PASSWORD>\n**Note:** When using a password-protected private key, the password must be provided through the environment variable MINIO_CERT_PASSWD using the following command:\n\n\t$ export MINIO_CERT_PASSWD=<PASSWORD>\n\t// 也就是在minioinstance.yaml中添加如下信息\n\tenv:\n\t  - MINIO_CERT_PASSWD\n\t    value: \"<YourPassword>\"\t\t// 一定要加上双引号\"\"\n**2. Generate a self-signed certificate.**\nUse the following command to generate a self-signed certificate and enter a passphrase when prompted:\n\n\n\t$ openssl req -new -x509 -days 3650 -key private.key -out public.crt -subj \"/C=US/ST=state/L=location/O=organization/CN=<domain.com>\"\n\t// 查看证书签名,算法,public key等信息\n\t$ openssl x509 -in public.crt -text -noout\n**Note:** Replace <domain.com> with the development domain name.\nAlternatively, use the command below to generate a self-signed wildcard certificate that is valid for all subdomains under <domain.com>. Wildcard certificates are useful for `deploying distributed MinIO instances`, where each instance runs on a subdomain under a single parent domain.\n\n\t$ openssl req -new -x509 -days 3650 -key private.key -out public.crt -subj \"/C=US/ST=state/L=location/O=organization/CN=*.minio-hl-svc.minio.svc.cluster.local\"\n**Note: 若是不知道怎么确定`<*.domain.com>`信息, 添加TLS后部署minio发现pod启动异常或者访问minio服务不正常, 查看pod的日志,`$ kubectl logs po/minio-0 -n minio`, 即可看到pod出现error信息，显示需要的certificates的commanName(简称CN), 然后将不同pod证书不同的内容用`*`替代, 其它的照搬，如上的例子`*.minio-hl-svc.minio.svc.cluster.local`.**\n\n**3. Use a Kubernetes Secret resource to store this information, create a Kubernetes Secret using:**\n\n\n\t$ kubectl create secret generic tls-ssl-minio --from-file=***/pki/private.key --from-file=***/pki/public.crt -n minio\n再将tenant.yaml或者改过名的minioinstance.yaml文件中的下列注释内容打开\n\n\texternalCertSecret:\n\t  name: tls-ssl-minio\n然后再重新部署minio\n\n\t$ kubectl apply -f minioinstance.yaml\n\n\n\n","slug":"storage/minIO_02_deployment_on_kubernetes","published":1,"date":"2020-08-12T16:05:48.473Z","updated":"2020-08-11T12:24:16.375Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmgw006dhohx8sc6drtj","content":"<p>在storage仓库里也存储了一份当时部署所使用的yaml等资源文件.</p>\n<p>Quick start:<br>  <a href=\"https://docs.min.io/docs/minio-quickstart-guide.html\" target=\"_blank\" rel=\"noopener\">https://docs.min.io/docs/minio-quickstart-guide.html</a><br>Deployment on kubernetes:<br>  <a href=\"https://docs.min.io/docs/deploy-minio-on-kubernetes.html\" target=\"_blank\" rel=\"noopener\">https://docs.min.io/docs/deploy-minio-on-kubernetes.html</a><br>  <a href=\"https://github.com/minio/operator/blob/master/README.md\" target=\"_blank\" rel=\"noopener\">https://github.com/minio/operator/blob/master/README.md</a><br>Enable TLS:<br>  <a href=\"https://github.com/minio/operator/blob/master/docs/tls.md\" target=\"_blank\" rel=\"noopener\">https://github.com/minio/operator/blob/master/docs/tls.md</a></p>\n<h2 id=\"Prerequisites\"><a href=\"#Prerequisites\" class=\"headerlink\" title=\"Prerequisites\"></a>Prerequisites</h2><ol>\n<li>Kubernetes version v1.17.0 and above for compatibility. MinIO Operator uses k8s/client-go v0.18.0.</li>\n<li>kubectl configured to refer to a Kubernetes cluster.</li>\n<li>Create the required PVs as <a href=\"https://github.com/minio/minio-operator/blob/master/docs/using-direct-csi.md\" target=\"_blank\" rel=\"noopener\">direct CSI driver.</a> or use the following installation step.</li>\n</ol>\n<h2 id=\"Using-Direct-CSI-Driver\"><a href=\"#Using-Direct-CSI-Driver\" class=\"headerlink\" title=\"Using Direct CSI Driver\"></a>Using Direct CSI Driver</h2><pre><code>cat &lt;&lt; EOF &gt; default.env\nDIRECT_CSI_DRIVES=data{1...4}\nDIRECT_CSI_DRIVES_DIR=/mnt\nEOF\n\n$ export $(cat default.env)\n$ kubectl apply -k direct-csi</code></pre><h2 id=\"Create-Operator-Deployment\"><a href=\"#Create-Operator-Deployment\" class=\"headerlink\" title=\"Create Operator Deployment\"></a>Create Operator Deployment</h2><ol>\n<li>Create namespace minio for minIO to deploy.</li>\n</ol>\n<pre><code>$ kubectl create ns minio</code></pre><ol start=\"2\">\n<li>To start MinIO-Operator with default configuration, use the minio-operator.yaml file.</li>\n</ol>\n<pre><code>$ kubectl apply -f minio-operator.yaml -n minio</code></pre><h2 id=\"Create-MinIO-instances-without-tls\"><a href=\"#Create-MinIO-instances-without-tls\" class=\"headerlink\" title=\"Create MinIO instances without tls\"></a>Create MinIO instances without tls</h2><p>Once MinIO-Operator deployment is running, you can create MinIO instances using the below command</p>\n<pre><code>$ kubectl apply -f minioinstance.yaml</code></pre><h2 id=\"Create-NodePort-service-for-minIO\"><a href=\"#Create-NodePort-service-for-minIO\" class=\"headerlink\" title=\"Create NodePort service for minIO\"></a>Create NodePort service for minIO</h2><pre><code>$ kubectl apply -f NodePort-minio.yaml</code></pre><h2 id=\"Access-minIO-from-the-browser\"><a href=\"#Access-minIO-from-the-browser\" class=\"headerlink\" title=\"Access minIO from the browser\"></a>Access minIO from the browser</h2><pre><code>// Minio Server没有配置TLS\n浏览器输入: http://127.0.0.1:30007\ndefault username: minio\ndefault password: minio123\n// Minio Server配置TLS\n浏览器输入: https://127.0.0.1:30007</code></pre><h2 id=\"Secure-access-to-MinIO-server-with-TLS\"><a href=\"#Secure-access-to-MinIO-server-with-TLS\" class=\"headerlink\" title=\"Secure access to MinIO server with TLS\"></a><strong>Secure access to MinIO server with TLS</strong></h2><p><strong>1.1. Generate a private key with ECDSA</strong></p>\n<pre><code>$ openssl ecparam -genkey -name prime256v1 | openssl ec -out private.key\n  read EC key\n  writing EC key</code></pre><p>Alternatively, use the following command to generate a private ECDSA key protected by a password:</p>\n<pre><code>$ openssl ecparam -genkey -name prime256v1 | openssl ec -aes256 -out private.key -passout pass:&lt;PASSWORD&gt;</code></pre><p><strong>1.2 Generate a private key with RSA.</strong><br>Use the following command to generate a private key with RSA:</p>\n<pre><code>$ openssl genrsa -out private.key 2048\nGenerating RSA private key, 2048 bit long modulus\n............................................+++\n...........+++\ne is 65537 (0x10001)\n// openssl查看证书内容\n$ openssl rsa -in private.key -text -noout</code></pre><p>Alternatively, use the following command to generate a private RSA key protected by a password:</p>\n<pre><code>$ openssl genrsa -aes256 -out private.key 2048 -passout pass:&lt;PASSWORD&gt;</code></pre><p><strong>Note:</strong> When using a password-protected private key, the password must be provided through the environment variable MINIO_CERT_PASSWD using the following command:</p>\n<pre><code>$ export MINIO_CERT_PASSWD=&lt;PASSWORD&gt;\n// 也就是在minioinstance.yaml中添加如下信息\nenv:\n  - MINIO_CERT_PASSWD\n    value: &quot;&lt;YourPassword&gt;&quot;        // 一定要加上双引号&quot;&quot;</code></pre><p><strong>2. Generate a self-signed certificate.</strong><br>Use the following command to generate a self-signed certificate and enter a passphrase when prompted:</p>\n<pre><code>$ openssl req -new -x509 -days 3650 -key private.key -out public.crt -subj &quot;/C=US/ST=state/L=location/O=organization/CN=&lt;domain.com&gt;&quot;\n// 查看证书签名,算法,public key等信息\n$ openssl x509 -in public.crt -text -noout</code></pre><p><strong>Note:</strong> Replace &lt;domain.com&gt; with the development domain name.<br>Alternatively, use the command below to generate a self-signed wildcard certificate that is valid for all subdomains under &lt;domain.com&gt;. Wildcard certificates are useful for <code>deploying distributed MinIO instances</code>, where each instance runs on a subdomain under a single parent domain.</p>\n<pre><code>$ openssl req -new -x509 -days 3650 -key private.key -out public.crt -subj &quot;/C=US/ST=state/L=location/O=organization/CN=*.minio-hl-svc.minio.svc.cluster.local&quot;</code></pre><p><strong>Note: 若是不知道怎么确定<code>&lt;*.domain.com&gt;</code>信息, 添加TLS后部署minio发现pod启动异常或者访问minio服务不正常, 查看pod的日志,<code>$ kubectl logs po/minio-0 -n minio</code>, 即可看到pod出现error信息，显示需要的certificates的commanName(简称CN), 然后将不同pod证书不同的内容用<code>*</code>替代, 其它的照搬，如上的例子<code>*.minio-hl-svc.minio.svc.cluster.local</code>.</strong></p>\n<p><strong>3. Use a Kubernetes Secret resource to store this information, create a Kubernetes Secret using:</strong></p>\n<pre><code>$ kubectl create secret generic tls-ssl-minio --from-file=***/pki/private.key --from-file=***/pki/public.crt -n minio</code></pre><p>再将tenant.yaml或者改过名的minioinstance.yaml文件中的下列注释内容打开</p>\n<pre><code>externalCertSecret:\n  name: tls-ssl-minio</code></pre><p>然后再重新部署minio</p>\n<pre><code>$ kubectl apply -f minioinstance.yaml</code></pre>","site":{"data":{}},"excerpt":"","more":"<p>在storage仓库里也存储了一份当时部署所使用的yaml等资源文件.</p>\n<p>Quick start:<br>  <a href=\"https://docs.min.io/docs/minio-quickstart-guide.html\" target=\"_blank\" rel=\"noopener\">https://docs.min.io/docs/minio-quickstart-guide.html</a><br>Deployment on kubernetes:<br>  <a href=\"https://docs.min.io/docs/deploy-minio-on-kubernetes.html\" target=\"_blank\" rel=\"noopener\">https://docs.min.io/docs/deploy-minio-on-kubernetes.html</a><br>  <a href=\"https://github.com/minio/operator/blob/master/README.md\" target=\"_blank\" rel=\"noopener\">https://github.com/minio/operator/blob/master/README.md</a><br>Enable TLS:<br>  <a href=\"https://github.com/minio/operator/blob/master/docs/tls.md\" target=\"_blank\" rel=\"noopener\">https://github.com/minio/operator/blob/master/docs/tls.md</a></p>\n<h2 id=\"Prerequisites\"><a href=\"#Prerequisites\" class=\"headerlink\" title=\"Prerequisites\"></a>Prerequisites</h2><ol>\n<li>Kubernetes version v1.17.0 and above for compatibility. MinIO Operator uses k8s/client-go v0.18.0.</li>\n<li>kubectl configured to refer to a Kubernetes cluster.</li>\n<li>Create the required PVs as <a href=\"https://github.com/minio/minio-operator/blob/master/docs/using-direct-csi.md\" target=\"_blank\" rel=\"noopener\">direct CSI driver.</a> or use the following installation step.</li>\n</ol>\n<h2 id=\"Using-Direct-CSI-Driver\"><a href=\"#Using-Direct-CSI-Driver\" class=\"headerlink\" title=\"Using Direct CSI Driver\"></a>Using Direct CSI Driver</h2><pre><code>cat &lt;&lt; EOF &gt; default.env\nDIRECT_CSI_DRIVES=data{1...4}\nDIRECT_CSI_DRIVES_DIR=/mnt\nEOF\n\n$ export $(cat default.env)\n$ kubectl apply -k direct-csi</code></pre><h2 id=\"Create-Operator-Deployment\"><a href=\"#Create-Operator-Deployment\" class=\"headerlink\" title=\"Create Operator Deployment\"></a>Create Operator Deployment</h2><ol>\n<li>Create namespace minio for minIO to deploy.</li>\n</ol>\n<pre><code>$ kubectl create ns minio</code></pre><ol start=\"2\">\n<li>To start MinIO-Operator with default configuration, use the minio-operator.yaml file.</li>\n</ol>\n<pre><code>$ kubectl apply -f minio-operator.yaml -n minio</code></pre><h2 id=\"Create-MinIO-instances-without-tls\"><a href=\"#Create-MinIO-instances-without-tls\" class=\"headerlink\" title=\"Create MinIO instances without tls\"></a>Create MinIO instances without tls</h2><p>Once MinIO-Operator deployment is running, you can create MinIO instances using the below command</p>\n<pre><code>$ kubectl apply -f minioinstance.yaml</code></pre><h2 id=\"Create-NodePort-service-for-minIO\"><a href=\"#Create-NodePort-service-for-minIO\" class=\"headerlink\" title=\"Create NodePort service for minIO\"></a>Create NodePort service for minIO</h2><pre><code>$ kubectl apply -f NodePort-minio.yaml</code></pre><h2 id=\"Access-minIO-from-the-browser\"><a href=\"#Access-minIO-from-the-browser\" class=\"headerlink\" title=\"Access minIO from the browser\"></a>Access minIO from the browser</h2><pre><code>// Minio Server没有配置TLS\n浏览器输入: http://127.0.0.1:30007\ndefault username: minio\ndefault password: minio123\n// Minio Server配置TLS\n浏览器输入: https://127.0.0.1:30007</code></pre><h2 id=\"Secure-access-to-MinIO-server-with-TLS\"><a href=\"#Secure-access-to-MinIO-server-with-TLS\" class=\"headerlink\" title=\"Secure access to MinIO server with TLS\"></a><strong>Secure access to MinIO server with TLS</strong></h2><p><strong>1.1. Generate a private key with ECDSA</strong></p>\n<pre><code>$ openssl ecparam -genkey -name prime256v1 | openssl ec -out private.key\n  read EC key\n  writing EC key</code></pre><p>Alternatively, use the following command to generate a private ECDSA key protected by a password:</p>\n<pre><code>$ openssl ecparam -genkey -name prime256v1 | openssl ec -aes256 -out private.key -passout pass:&lt;PASSWORD&gt;</code></pre><p><strong>1.2 Generate a private key with RSA.</strong><br>Use the following command to generate a private key with RSA:</p>\n<pre><code>$ openssl genrsa -out private.key 2048\nGenerating RSA private key, 2048 bit long modulus\n............................................+++\n...........+++\ne is 65537 (0x10001)\n// openssl查看证书内容\n$ openssl rsa -in private.key -text -noout</code></pre><p>Alternatively, use the following command to generate a private RSA key protected by a password:</p>\n<pre><code>$ openssl genrsa -aes256 -out private.key 2048 -passout pass:&lt;PASSWORD&gt;</code></pre><p><strong>Note:</strong> When using a password-protected private key, the password must be provided through the environment variable MINIO_CERT_PASSWD using the following command:</p>\n<pre><code>$ export MINIO_CERT_PASSWD=&lt;PASSWORD&gt;\n// 也就是在minioinstance.yaml中添加如下信息\nenv:\n  - MINIO_CERT_PASSWD\n    value: &quot;&lt;YourPassword&gt;&quot;        // 一定要加上双引号&quot;&quot;</code></pre><p><strong>2. Generate a self-signed certificate.</strong><br>Use the following command to generate a self-signed certificate and enter a passphrase when prompted:</p>\n<pre><code>$ openssl req -new -x509 -days 3650 -key private.key -out public.crt -subj &quot;/C=US/ST=state/L=location/O=organization/CN=&lt;domain.com&gt;&quot;\n// 查看证书签名,算法,public key等信息\n$ openssl x509 -in public.crt -text -noout</code></pre><p><strong>Note:</strong> Replace &lt;domain.com&gt; with the development domain name.<br>Alternatively, use the command below to generate a self-signed wildcard certificate that is valid for all subdomains under &lt;domain.com&gt;. Wildcard certificates are useful for <code>deploying distributed MinIO instances</code>, where each instance runs on a subdomain under a single parent domain.</p>\n<pre><code>$ openssl req -new -x509 -days 3650 -key private.key -out public.crt -subj &quot;/C=US/ST=state/L=location/O=organization/CN=*.minio-hl-svc.minio.svc.cluster.local&quot;</code></pre><p><strong>Note: 若是不知道怎么确定<code>&lt;*.domain.com&gt;</code>信息, 添加TLS后部署minio发现pod启动异常或者访问minio服务不正常, 查看pod的日志,<code>$ kubectl logs po/minio-0 -n minio</code>, 即可看到pod出现error信息，显示需要的certificates的commanName(简称CN), 然后将不同pod证书不同的内容用<code>*</code>替代, 其它的照搬，如上的例子<code>*.minio-hl-svc.minio.svc.cluster.local</code>.</strong></p>\n<p><strong>3. Use a Kubernetes Secret resource to store this information, create a Kubernetes Secret using:</strong></p>\n<pre><code>$ kubectl create secret generic tls-ssl-minio --from-file=***/pki/private.key --from-file=***/pki/public.crt -n minio</code></pre><p>再将tenant.yaml或者改过名的minioinstance.yaml文件中的下列注释内容打开</p>\n<pre><code>externalCertSecret:\n  name: tls-ssl-minio</code></pre><p>然后再重新部署minio</p>\n<pre><code>$ kubectl apply -f minioinstance.yaml</code></pre>"},{"title":"Greenplum Deployment on Kubernetes","_content":"\n## **Prerequisites**\n1. [Kubernetes Node Configuration](http://greenplum-kubernetes.docs.pivotal.io/2-0/node-requirements.html) describes the Linux kernel configuration requirements for each Kubernetes node that is used in a Pivotal Greenplum cluster. These requirements are common to all Pivotal Greenplum deployments, regardless of which Kubernetes environment you use.\n2. Ensure that any previous Pivotal Greenplum installation has been uninstalled as described in Uninstalling Pivotal Greenplum.\n3. kubectl configured to refer to a Kubernetes cluster.\n\n## **Install Greenplum Operator for Kubernetes**\n1. Download the Pivotal Greenplum software from [VMware Tanzu Network](https://network.pivotal.io/products/greenplum-for-kubernetes) or skip to step 3 if have greenplum related files. The download file has the name: ```greenplum-for-kubernetes-<version>.tar.gz.```\n\n\n2. Go to the directory where you downloaded Greenplum for Kubernetes, and unpack the downloaded software. For example:\n\n\n\t$ cd ~/Downloads\n\t$ tar xzf greenplum-for-kubernetes-*.tar.gz\nThe above command unpacks the distribution into a new directory named ```greenplum-for-kubernetes-<version>```.\n3. Go into the new greenplum-for-kubernetes-<version> directory:\n\n\n\t$ cd ./greenplum-for-kubernetes-*\n4. Load the Greenplum for Kubernetes Docker image to the local Docker registry:\n\n\n\t$ docker load -i ./images/greenplum-for-kubernetes\n5. Load the Greenplum Operator Docker image to the Docker registry:\n\n\n\t$ docker load -i ./images/greenplum-operator\n6. Push the Greenplum docker images to the local container registry. For example:\n\n\n\t$ IMAGE_REPO=\"hci-node01:5000\"\n\t$ GREENPLUM_IMAGE_NAME=\"${IMAGE_REPO}/greenplum-for-kubernetes:$(cat ./images/greenplum-for-kubernetes-tag)\"\n\t$ docker tag $(cat ./images/greenplum-for-kubernetes-id) ${GREENPLUM_IMAGE_NAME}\n\t$ docker push ${GREENPLUM_IMAGE_NAME}\n\t\n\t$ OPERATOR_IMAGE_NAME=\"${IMAGE_REPO}/greenplum-operator:$(cat ./images/greenplum-operator-tag)\"\n\t$ docker tag $(cat ./images/greenplum-operator-id) ${OPERATOR_IMAGE_NAME}\n\t$ docker push ${OPERATOR_IMAGE_NAME}\n7. Create a new YAML file in the workspace subdirectory with two lines to indicate the registry where you pushed the images\n\n\n\tcat <<EOF >workspace/operator-values-overrides.yaml\n\toperatorImageRepository: ${IMAGE_REPO}/greenplum-operator\n\tgreenplumImageRepository: ${IMAGE_REPO}/greenplum-for-kubernetes\n\toperatorWorkerSelector: {\n\tgreenplum-operator: \"default\"\n\t}\n\tEOF\n8. Use helm to create a new Greenplum Operator release.\n\n\n\t// 先给某台机器添加标签来部署greenplum-operator\n\t$ kubectl label node hci-node02  greenplum-operator=default\n\t\n\t$ kubectl create namespace greenplum\n\t$ helm install -n greenplum-operator -f workspace/operator-values-overrides.yaml operator/ --namespace greenplum\n\t$ helm install greenplum-operator operator/\n\n## **Create Local Persistent Volumes for Greenplum**\n1. Create the directory, partition, or logical volume that you want to use as a Kubernetes local volume.\n\n\n2. Create the StorageClass definition, specifying no-provisioner in order to manually provision local persistent volumes. Using volumeBindingMode: WaitForFirstConsumer is also recommended to delay binding the local PersistenVolume until a pod requires.\n\n\n\t$ vim gpdb-storage-class.yaml\n\tkind: StorageClass\n\tapiVersion: storage.k8s.io/v1\n\tmetadata:\n\t  name: gpdb-storage\n\tprovisioner: kubernetes.io/no-provisioner\n\tvolumeBindingMode: WaitForFirstConsumer\n3. Create a PersistentVolume definition, specifying the local volume and the required NodeAffinity field. For example:\n\n\n\t$ vim pv-master.yaml\n\tapiVersion: v1\n\tkind: PersistentVolume\n\tmetadata:\n\t  name: greenplum-master-node02\n\tspec:\n\t  capacity:\n\t    storage: 1Gi\n\t  accessModes:\n\t  - ReadWriteOnce\n\t  persistentVolumeReclaimPolicy: Retain\n\t  storageClassName: gpdb-storage\n\t  local:\n\t    path: /mnt/disks/greenplum-master-vol0\t// 需要提前在相应机器上创建此目录\n\t  nodeAffinity:\n\t    required:\n\t      nodeSelectorTerms:\n\t      - matchExpressions:\n\t        - key: kubernetes.io/hostname\n\t          operator: In\n\t          values:\n\t          - hci-node02\n\t---\n\tapiVersion: v1\n\tkind: PersistentVolume\n\tmetadata:\n\t  name: greenplum-master-node02\n\t......重复上面的内容, 改变下local.path, nodeAffinity等在不同node机器上创建多个pv\n\n4. Repeat the previous step for each PersistentVolume required for your cluster. Remember that each Greenplum segment host requires a dedicated storage volume.\n\n5. Use kubectl to apply the StorageClass and PersistentVolume configurations that you created.\n\n6. Specify the local storage StorageClass name when you deploy a new Greenplum cluster as below.\n\n## **Deploy a greenplum cluster**\n1. Go to the workspace subdirectory where you unpacked the Pivotal Greenplum distribution for Kubernetes:\n\n\n\t$ cd ./greenplum-for-kubernetes-*/workspace\n2. If necessary, create a Kubernetes manifest file to specify the configuration of your Greenplum cluster. A sample file is provided in workspace/my-gp-instance.yaml. my-gp-instance.yaml contains the minimal set of instructions necessary to create a demonstration cluster named “my-greenplum” with a single segment and default storage, memory, and CPU settings:\n\n\n\tapiVersion: \"greenplum.pivotal.io/v1\"\n\tkind: \"GreenplumCluster\"\n\tmetadata:\n\t  name: my-greenplum\n\tspec:\n\t  masterAndStandby:\n\t    hostBasedAuthentication: |\n\t      # host   all   gpadmin   1.2.3.4/32   trust\n\t      # host   all   gpuser    0.0.0.0/0   md5\n\t    memory: \"800Mi\"\n\t    cpu: \"0.5\"\n\t    storageClassName: gpdb-storage\n\t    storage: 1G\n\t    antiAffinity: \"yes\"\n\t    workerSelector: {}\n\t  segments:\n\t    primarySegmentCount: 2\t\t# Expand the segment to 2\n\t    memory: \"800Mi\"\n\t    cpu: \"0.5\"\n\t    storageClassName: gpdb-storage\t\t# Use the specify storageclass\n\t    storage: 10G\t\t\t\t# Expand the storage to 10G\n\t    antiAffinity: \"yes\"\n\t    workerSelector: {}\n\t    mirrors: \"yes\"\n3. Use kubectl apply command and specify your manifest file to send the deployment request to the Greenplum Operator. For example, to use the sample my-gp-instance.yaml file:\n\n\n\t$ kubectl apply -f ./my-gp-instance.yaml \n\t  greenplumcluster.greenplum.pivotal.io/my-greenplum created\n## **Deploy multiple greenplum cluster**\n1. Create namespaces for greenplum cluster to deploy. Deploy two greenplum cluster instances:\n\n\n\t$ kubectl create namespace gpinstance-1\n\t$ kubectl create namespace gpinstance-2\n2. Deploy Greenplum cluster into the correspond namespace.\n\n\n\t$ cd workspace\n\t$ kubectl apply -f ./my-gp-instance.yaml -n gpinstance-1\n\t$ kubectl apply -f ./my-gp-instance.yaml -n gpinstance-2\n## **Test whether the Greenplum Cluster deployment is successful**\n\n\n\t$ kubectl exec -it master-0 -n greenplum -- bash -c \"source /opt/gpdb/greenplum_path.sh; psql\"\n\t psql (8.3.23)\n\t Type \"help\" for help.\n\t\n\t gpadmin=# select * from gp_segment_configuration;\n\t如果报一些错误无法执行可以:\n\t1. 先进入master-0: kubectl exec -it master-0 -n greenplum -- bash, 再查找greenplum_path.sh\n\t2. 执行`$ source /opt/gpdb/greenplum_path.sh`, 再 `$ exit`退出, 然后就可以用以上命令了\n(Enter `\\q` to exit the psql utility.)\n\n## **Delete a greenplum cluster and uninstall pivotal greenplum for kubernetes**\n\n### **Delete a greenplum cluster**\n1. Navigate to the workspace directory of the Pivotal Greenplum distribution (or to the location of the Kubernetes manifest that you used to deploy the cluster). For example:\n\n\n\t$ cd ./greenplum-for-kubernetes-*/workspace\n2. Execute the kubectl delete command, specifying the manifest that you used to deploy the cluster. For example:\n\n\n\t$ kubectl delete -f ./my-gp-instance.yaml --wait=false\n**Note:** Use the optional --wait=false flag to return immediately without waiting for the deletion to complete.\n3. Use kubectl to describe the Greenplum cluster to verify Status.Phase and Events:\n\n\n\t$ kubectl describe greenplumcluster my-greenplum\n\t [...]\n\t Status:\n\t   Instance Image:    greenplum-for-kubernetes:latest\n\t   Operator Version:  greenplum-operator:latest\n\t   Phase:             Deleting\n\t Events:\n\t   Type    Reason                    Age   From               Message\n\t   ----    ------                    ----  ----               -------\n\t   Normal  CreatingGreenplumCluster  3m    greenplumOperator  Creating Greenplum cluster my-greenplum in default\n\t   Normal  CreatedGreenplumCluster   1m    greenplumOperator  Successfully created Greenplum cluster my-greenplum in default\n\t   Normal  DeletingGreenplumCluster  6s    greenplumOperator  Deleting Greenplum cluster my-greenplum in default\nIf for any reason stopping the Greenplum instance fails, you should see a warning message in the greenplum-operator logs as shown below:\n\n\n\t$ kubectl logs -l app=greenplum-operator\n\t[...]\n\t{\"level\":\"INFO\",\"ts\":\"2020-01-24T19:03:22.874Z\",\"logger\":\"controllers.GreenplumCluster\",\"msg\":\"DeletingGreenplumCluster\",\"name\":\"my-greenplum\",\"namespace\":\"default\"}\n\t{\"level\":\"INFO\",\"ts\":\"2020-01-24T19:03:23.068Z\",\"logger\":\"controllers.GreenplumCluster\",\"msg\":\"initiating shutdown of the greenplum cluster\"}\n\t{\"level\":\"INFO\",\"ts\":\"2020-01-24T19:03:31.971Z\",\"logger\":\"controllers.GreenplumCluster\",\"msg\":\"gpstop did not stop cleanly. Please check gpAdminLogs for more info.\"}\n\t[...]\n\t{\"level\":\"INFO\",\"ts\":\"2020-01-24T19:03:32.252Z\",\"logger\":\"controllers.GreenplumCluster\",\"msg\":\"DeletedGreenplumCluster\",\"name\":\"my-greenplum\",\"namespace\":\"default\"}\n4. Use kubectl to monitor the progress of terminating Greenplum resources in your cluster. For example, if your cluster deployment was named my-greenplum:\n\n\n\t$ kubectl get all -l greenplum-cluster=my-greenplum\n\t$ kubectl label nodes hci-node01 greenplum-affinity-greenplum-master-\t// 去掉node上关于greenplum的label\n\t$ kubectl label nodes hci-node01 greenplum-affinity-greenplum-segment-\n### **Delete greenplum persistent volume claims**\n**Caution:** If the Persistent Volumes were created using dynamic provisioning, then deleting the PVCs will also delete the associated PVs. In this case, do not delete the PVCs unless you are certain that you no longer need the data.\n1. Verify that the PVCs are present for your cluster. For example, to show the Persistent Volume Claims created for a cluster named my-greenplum:\n\n\n\t$ kubectl get pvc -l greenplum-cluster=my-greenplum\n2. Use kubectl to delete the PVCs associated with the cluster. For example, to delete all PersistentVolume Claims created for a cluster named my-greenplum:\n\n\n\t$ kubectl delete pvc -l greenplum-cluster=my-greenplum\n3. If the Persistent Volumes were provisioned manually, then deleting the PVCs does not delete the associated PVs. (You can check for the PVs using kubectl get pv.) To delete any remaining Persistent Volumes, execute the command:\n\n\n\t$ kubectl delete pv -l greenplum-cluster=my-greenplum\n### **Uninstall pivotal greenplum for kubernetes**\n1. Use the helm delete command to delete the greenplum-operator release:\n\n\n\t$ helm delete greenplum-operator\n\t$ helm del --purge greenplum-operator;\n2. Delete the node label of greenplum operator when deployed on kubernetes\n\n\n\t$ kubectl label nodes hci-node02 greenplum-operator-\n3. Use docker rmi to delete images\n\n\n\t$ docker rmi <ImageName or ImgaeID>\n## **FAQ**\nWhen uninstall greenplum, encountered this problem: Object is being deleted: customresourcedefinitions.apiextensions.k8s.io \"greenplumclusters.greenplum.pivotal.io\" already exists.\n\nsolution refer to this:[delete crd](https://github.com/kubernetes/kubernetes/issues/60538)\n\n\n","source":"_posts/storage/greenplum.md","raw":"---\ntitle: Greenplum Deployment on Kubernetes\ntags: storage\ncategories:\n- storage\n---\n\n## **Prerequisites**\n1. [Kubernetes Node Configuration](http://greenplum-kubernetes.docs.pivotal.io/2-0/node-requirements.html) describes the Linux kernel configuration requirements for each Kubernetes node that is used in a Pivotal Greenplum cluster. These requirements are common to all Pivotal Greenplum deployments, regardless of which Kubernetes environment you use.\n2. Ensure that any previous Pivotal Greenplum installation has been uninstalled as described in Uninstalling Pivotal Greenplum.\n3. kubectl configured to refer to a Kubernetes cluster.\n\n## **Install Greenplum Operator for Kubernetes**\n1. Download the Pivotal Greenplum software from [VMware Tanzu Network](https://network.pivotal.io/products/greenplum-for-kubernetes) or skip to step 3 if have greenplum related files. The download file has the name: ```greenplum-for-kubernetes-<version>.tar.gz.```\n\n\n2. Go to the directory where you downloaded Greenplum for Kubernetes, and unpack the downloaded software. For example:\n\n\n\t$ cd ~/Downloads\n\t$ tar xzf greenplum-for-kubernetes-*.tar.gz\nThe above command unpacks the distribution into a new directory named ```greenplum-for-kubernetes-<version>```.\n3. Go into the new greenplum-for-kubernetes-<version> directory:\n\n\n\t$ cd ./greenplum-for-kubernetes-*\n4. Load the Greenplum for Kubernetes Docker image to the local Docker registry:\n\n\n\t$ docker load -i ./images/greenplum-for-kubernetes\n5. Load the Greenplum Operator Docker image to the Docker registry:\n\n\n\t$ docker load -i ./images/greenplum-operator\n6. Push the Greenplum docker images to the local container registry. For example:\n\n\n\t$ IMAGE_REPO=\"hci-node01:5000\"\n\t$ GREENPLUM_IMAGE_NAME=\"${IMAGE_REPO}/greenplum-for-kubernetes:$(cat ./images/greenplum-for-kubernetes-tag)\"\n\t$ docker tag $(cat ./images/greenplum-for-kubernetes-id) ${GREENPLUM_IMAGE_NAME}\n\t$ docker push ${GREENPLUM_IMAGE_NAME}\n\t\n\t$ OPERATOR_IMAGE_NAME=\"${IMAGE_REPO}/greenplum-operator:$(cat ./images/greenplum-operator-tag)\"\n\t$ docker tag $(cat ./images/greenplum-operator-id) ${OPERATOR_IMAGE_NAME}\n\t$ docker push ${OPERATOR_IMAGE_NAME}\n7. Create a new YAML file in the workspace subdirectory with two lines to indicate the registry where you pushed the images\n\n\n\tcat <<EOF >workspace/operator-values-overrides.yaml\n\toperatorImageRepository: ${IMAGE_REPO}/greenplum-operator\n\tgreenplumImageRepository: ${IMAGE_REPO}/greenplum-for-kubernetes\n\toperatorWorkerSelector: {\n\tgreenplum-operator: \"default\"\n\t}\n\tEOF\n8. Use helm to create a new Greenplum Operator release.\n\n\n\t// 先给某台机器添加标签来部署greenplum-operator\n\t$ kubectl label node hci-node02  greenplum-operator=default\n\t\n\t$ kubectl create namespace greenplum\n\t$ helm install -n greenplum-operator -f workspace/operator-values-overrides.yaml operator/ --namespace greenplum\n\t$ helm install greenplum-operator operator/\n\n## **Create Local Persistent Volumes for Greenplum**\n1. Create the directory, partition, or logical volume that you want to use as a Kubernetes local volume.\n\n\n2. Create the StorageClass definition, specifying no-provisioner in order to manually provision local persistent volumes. Using volumeBindingMode: WaitForFirstConsumer is also recommended to delay binding the local PersistenVolume until a pod requires.\n\n\n\t$ vim gpdb-storage-class.yaml\n\tkind: StorageClass\n\tapiVersion: storage.k8s.io/v1\n\tmetadata:\n\t  name: gpdb-storage\n\tprovisioner: kubernetes.io/no-provisioner\n\tvolumeBindingMode: WaitForFirstConsumer\n3. Create a PersistentVolume definition, specifying the local volume and the required NodeAffinity field. For example:\n\n\n\t$ vim pv-master.yaml\n\tapiVersion: v1\n\tkind: PersistentVolume\n\tmetadata:\n\t  name: greenplum-master-node02\n\tspec:\n\t  capacity:\n\t    storage: 1Gi\n\t  accessModes:\n\t  - ReadWriteOnce\n\t  persistentVolumeReclaimPolicy: Retain\n\t  storageClassName: gpdb-storage\n\t  local:\n\t    path: /mnt/disks/greenplum-master-vol0\t// 需要提前在相应机器上创建此目录\n\t  nodeAffinity:\n\t    required:\n\t      nodeSelectorTerms:\n\t      - matchExpressions:\n\t        - key: kubernetes.io/hostname\n\t          operator: In\n\t          values:\n\t          - hci-node02\n\t---\n\tapiVersion: v1\n\tkind: PersistentVolume\n\tmetadata:\n\t  name: greenplum-master-node02\n\t......重复上面的内容, 改变下local.path, nodeAffinity等在不同node机器上创建多个pv\n\n4. Repeat the previous step for each PersistentVolume required for your cluster. Remember that each Greenplum segment host requires a dedicated storage volume.\n\n5. Use kubectl to apply the StorageClass and PersistentVolume configurations that you created.\n\n6. Specify the local storage StorageClass name when you deploy a new Greenplum cluster as below.\n\n## **Deploy a greenplum cluster**\n1. Go to the workspace subdirectory where you unpacked the Pivotal Greenplum distribution for Kubernetes:\n\n\n\t$ cd ./greenplum-for-kubernetes-*/workspace\n2. If necessary, create a Kubernetes manifest file to specify the configuration of your Greenplum cluster. A sample file is provided in workspace/my-gp-instance.yaml. my-gp-instance.yaml contains the minimal set of instructions necessary to create a demonstration cluster named “my-greenplum” with a single segment and default storage, memory, and CPU settings:\n\n\n\tapiVersion: \"greenplum.pivotal.io/v1\"\n\tkind: \"GreenplumCluster\"\n\tmetadata:\n\t  name: my-greenplum\n\tspec:\n\t  masterAndStandby:\n\t    hostBasedAuthentication: |\n\t      # host   all   gpadmin   1.2.3.4/32   trust\n\t      # host   all   gpuser    0.0.0.0/0   md5\n\t    memory: \"800Mi\"\n\t    cpu: \"0.5\"\n\t    storageClassName: gpdb-storage\n\t    storage: 1G\n\t    antiAffinity: \"yes\"\n\t    workerSelector: {}\n\t  segments:\n\t    primarySegmentCount: 2\t\t# Expand the segment to 2\n\t    memory: \"800Mi\"\n\t    cpu: \"0.5\"\n\t    storageClassName: gpdb-storage\t\t# Use the specify storageclass\n\t    storage: 10G\t\t\t\t# Expand the storage to 10G\n\t    antiAffinity: \"yes\"\n\t    workerSelector: {}\n\t    mirrors: \"yes\"\n3. Use kubectl apply command and specify your manifest file to send the deployment request to the Greenplum Operator. For example, to use the sample my-gp-instance.yaml file:\n\n\n\t$ kubectl apply -f ./my-gp-instance.yaml \n\t  greenplumcluster.greenplum.pivotal.io/my-greenplum created\n## **Deploy multiple greenplum cluster**\n1. Create namespaces for greenplum cluster to deploy. Deploy two greenplum cluster instances:\n\n\n\t$ kubectl create namespace gpinstance-1\n\t$ kubectl create namespace gpinstance-2\n2. Deploy Greenplum cluster into the correspond namespace.\n\n\n\t$ cd workspace\n\t$ kubectl apply -f ./my-gp-instance.yaml -n gpinstance-1\n\t$ kubectl apply -f ./my-gp-instance.yaml -n gpinstance-2\n## **Test whether the Greenplum Cluster deployment is successful**\n\n\n\t$ kubectl exec -it master-0 -n greenplum -- bash -c \"source /opt/gpdb/greenplum_path.sh; psql\"\n\t psql (8.3.23)\n\t Type \"help\" for help.\n\t\n\t gpadmin=# select * from gp_segment_configuration;\n\t如果报一些错误无法执行可以:\n\t1. 先进入master-0: kubectl exec -it master-0 -n greenplum -- bash, 再查找greenplum_path.sh\n\t2. 执行`$ source /opt/gpdb/greenplum_path.sh`, 再 `$ exit`退出, 然后就可以用以上命令了\n(Enter `\\q` to exit the psql utility.)\n\n## **Delete a greenplum cluster and uninstall pivotal greenplum for kubernetes**\n\n### **Delete a greenplum cluster**\n1. Navigate to the workspace directory of the Pivotal Greenplum distribution (or to the location of the Kubernetes manifest that you used to deploy the cluster). For example:\n\n\n\t$ cd ./greenplum-for-kubernetes-*/workspace\n2. Execute the kubectl delete command, specifying the manifest that you used to deploy the cluster. For example:\n\n\n\t$ kubectl delete -f ./my-gp-instance.yaml --wait=false\n**Note:** Use the optional --wait=false flag to return immediately without waiting for the deletion to complete.\n3. Use kubectl to describe the Greenplum cluster to verify Status.Phase and Events:\n\n\n\t$ kubectl describe greenplumcluster my-greenplum\n\t [...]\n\t Status:\n\t   Instance Image:    greenplum-for-kubernetes:latest\n\t   Operator Version:  greenplum-operator:latest\n\t   Phase:             Deleting\n\t Events:\n\t   Type    Reason                    Age   From               Message\n\t   ----    ------                    ----  ----               -------\n\t   Normal  CreatingGreenplumCluster  3m    greenplumOperator  Creating Greenplum cluster my-greenplum in default\n\t   Normal  CreatedGreenplumCluster   1m    greenplumOperator  Successfully created Greenplum cluster my-greenplum in default\n\t   Normal  DeletingGreenplumCluster  6s    greenplumOperator  Deleting Greenplum cluster my-greenplum in default\nIf for any reason stopping the Greenplum instance fails, you should see a warning message in the greenplum-operator logs as shown below:\n\n\n\t$ kubectl logs -l app=greenplum-operator\n\t[...]\n\t{\"level\":\"INFO\",\"ts\":\"2020-01-24T19:03:22.874Z\",\"logger\":\"controllers.GreenplumCluster\",\"msg\":\"DeletingGreenplumCluster\",\"name\":\"my-greenplum\",\"namespace\":\"default\"}\n\t{\"level\":\"INFO\",\"ts\":\"2020-01-24T19:03:23.068Z\",\"logger\":\"controllers.GreenplumCluster\",\"msg\":\"initiating shutdown of the greenplum cluster\"}\n\t{\"level\":\"INFO\",\"ts\":\"2020-01-24T19:03:31.971Z\",\"logger\":\"controllers.GreenplumCluster\",\"msg\":\"gpstop did not stop cleanly. Please check gpAdminLogs for more info.\"}\n\t[...]\n\t{\"level\":\"INFO\",\"ts\":\"2020-01-24T19:03:32.252Z\",\"logger\":\"controllers.GreenplumCluster\",\"msg\":\"DeletedGreenplumCluster\",\"name\":\"my-greenplum\",\"namespace\":\"default\"}\n4. Use kubectl to monitor the progress of terminating Greenplum resources in your cluster. For example, if your cluster deployment was named my-greenplum:\n\n\n\t$ kubectl get all -l greenplum-cluster=my-greenplum\n\t$ kubectl label nodes hci-node01 greenplum-affinity-greenplum-master-\t// 去掉node上关于greenplum的label\n\t$ kubectl label nodes hci-node01 greenplum-affinity-greenplum-segment-\n### **Delete greenplum persistent volume claims**\n**Caution:** If the Persistent Volumes were created using dynamic provisioning, then deleting the PVCs will also delete the associated PVs. In this case, do not delete the PVCs unless you are certain that you no longer need the data.\n1. Verify that the PVCs are present for your cluster. For example, to show the Persistent Volume Claims created for a cluster named my-greenplum:\n\n\n\t$ kubectl get pvc -l greenplum-cluster=my-greenplum\n2. Use kubectl to delete the PVCs associated with the cluster. For example, to delete all PersistentVolume Claims created for a cluster named my-greenplum:\n\n\n\t$ kubectl delete pvc -l greenplum-cluster=my-greenplum\n3. If the Persistent Volumes were provisioned manually, then deleting the PVCs does not delete the associated PVs. (You can check for the PVs using kubectl get pv.) To delete any remaining Persistent Volumes, execute the command:\n\n\n\t$ kubectl delete pv -l greenplum-cluster=my-greenplum\n### **Uninstall pivotal greenplum for kubernetes**\n1. Use the helm delete command to delete the greenplum-operator release:\n\n\n\t$ helm delete greenplum-operator\n\t$ helm del --purge greenplum-operator;\n2. Delete the node label of greenplum operator when deployed on kubernetes\n\n\n\t$ kubectl label nodes hci-node02 greenplum-operator-\n3. Use docker rmi to delete images\n\n\n\t$ docker rmi <ImageName or ImgaeID>\n## **FAQ**\nWhen uninstall greenplum, encountered this problem: Object is being deleted: customresourcedefinitions.apiextensions.k8s.io \"greenplumclusters.greenplum.pivotal.io\" already exists.\n\nsolution refer to this:[delete crd](https://github.com/kubernetes/kubernetes/issues/60538)\n\n\n","slug":"storage/greenplum","published":1,"date":"2020-08-12T16:05:48.449Z","updated":"2020-08-10T16:29:52.138Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmgx006fhohx6s442w9z","content":"<h2 id=\"Prerequisites\"><a href=\"#Prerequisites\" class=\"headerlink\" title=\"Prerequisites\"></a><strong>Prerequisites</strong></h2><ol>\n<li><a href=\"http://greenplum-kubernetes.docs.pivotal.io/2-0/node-requirements.html\" target=\"_blank\" rel=\"noopener\">Kubernetes Node Configuration</a> describes the Linux kernel configuration requirements for each Kubernetes node that is used in a Pivotal Greenplum cluster. These requirements are common to all Pivotal Greenplum deployments, regardless of which Kubernetes environment you use.</li>\n<li>Ensure that any previous Pivotal Greenplum installation has been uninstalled as described in Uninstalling Pivotal Greenplum.</li>\n<li>kubectl configured to refer to a Kubernetes cluster.</li>\n</ol>\n<h2 id=\"Install-Greenplum-Operator-for-Kubernetes\"><a href=\"#Install-Greenplum-Operator-for-Kubernetes\" class=\"headerlink\" title=\"Install Greenplum Operator for Kubernetes\"></a><strong>Install Greenplum Operator for Kubernetes</strong></h2><ol>\n<li>Download the Pivotal Greenplum software from <a href=\"https://network.pivotal.io/products/greenplum-for-kubernetes\" target=\"_blank\" rel=\"noopener\">VMware Tanzu Network</a> or skip to step 3 if have greenplum related files. The download file has the name: <code>greenplum-for-kubernetes-&lt;version&gt;.tar.gz.</code></li>\n</ol>\n<ol start=\"2\">\n<li>Go to the directory where you downloaded Greenplum for Kubernetes, and unpack the downloaded software. For example:</li>\n</ol>\n<pre><code>$ cd ~/Downloads\n$ tar xzf greenplum-for-kubernetes-*.tar.gz</code></pre><p>The above command unpacks the distribution into a new directory named <code>greenplum-for-kubernetes-&lt;version&gt;</code>.<br>3. Go into the new greenplum-for-kubernetes-<version> directory:</p>\n<pre><code>$ cd ./greenplum-for-kubernetes-*</code></pre><ol start=\"4\">\n<li>Load the Greenplum for Kubernetes Docker image to the local Docker registry:</li>\n</ol>\n<pre><code>$ docker load -i ./images/greenplum-for-kubernetes</code></pre><ol start=\"5\">\n<li>Load the Greenplum Operator Docker image to the Docker registry:</li>\n</ol>\n<pre><code>$ docker load -i ./images/greenplum-operator</code></pre><ol start=\"6\">\n<li>Push the Greenplum docker images to the local container registry. For example:</li>\n</ol>\n<pre><code>$ IMAGE_REPO=&quot;hci-node01:5000&quot;\n$ GREENPLUM_IMAGE_NAME=&quot;${IMAGE_REPO}/greenplum-for-kubernetes:$(cat ./images/greenplum-for-kubernetes-tag)&quot;\n$ docker tag $(cat ./images/greenplum-for-kubernetes-id) ${GREENPLUM_IMAGE_NAME}\n$ docker push ${GREENPLUM_IMAGE_NAME}\n\n$ OPERATOR_IMAGE_NAME=&quot;${IMAGE_REPO}/greenplum-operator:$(cat ./images/greenplum-operator-tag)&quot;\n$ docker tag $(cat ./images/greenplum-operator-id) ${OPERATOR_IMAGE_NAME}\n$ docker push ${OPERATOR_IMAGE_NAME}</code></pre><ol start=\"7\">\n<li>Create a new YAML file in the workspace subdirectory with two lines to indicate the registry where you pushed the images</li>\n</ol>\n<pre><code>cat &lt;&lt;EOF &gt;workspace/operator-values-overrides.yaml\noperatorImageRepository: ${IMAGE_REPO}/greenplum-operator\ngreenplumImageRepository: ${IMAGE_REPO}/greenplum-for-kubernetes\noperatorWorkerSelector: {\ngreenplum-operator: &quot;default&quot;\n}\nEOF</code></pre><ol start=\"8\">\n<li>Use helm to create a new Greenplum Operator release.</li>\n</ol>\n<pre><code>// 先给某台机器添加标签来部署greenplum-operator\n$ kubectl label node hci-node02  greenplum-operator=default\n\n$ kubectl create namespace greenplum\n$ helm install -n greenplum-operator -f workspace/operator-values-overrides.yaml operator/ --namespace greenplum\n$ helm install greenplum-operator operator/</code></pre><h2 id=\"Create-Local-Persistent-Volumes-for-Greenplum\"><a href=\"#Create-Local-Persistent-Volumes-for-Greenplum\" class=\"headerlink\" title=\"Create Local Persistent Volumes for Greenplum\"></a><strong>Create Local Persistent Volumes for Greenplum</strong></h2><ol>\n<li>Create the directory, partition, or logical volume that you want to use as a Kubernetes local volume.</li>\n</ol>\n<ol start=\"2\">\n<li>Create the StorageClass definition, specifying no-provisioner in order to manually provision local persistent volumes. Using volumeBindingMode: WaitForFirstConsumer is also recommended to delay binding the local PersistenVolume until a pod requires.</li>\n</ol>\n<pre><code>$ vim gpdb-storage-class.yaml\nkind: StorageClass\napiVersion: storage.k8s.io/v1\nmetadata:\n  name: gpdb-storage\nprovisioner: kubernetes.io/no-provisioner\nvolumeBindingMode: WaitForFirstConsumer</code></pre><ol start=\"3\">\n<li>Create a PersistentVolume definition, specifying the local volume and the required NodeAffinity field. For example:</li>\n</ol>\n<pre><code>$ vim pv-master.yaml\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: greenplum-master-node02\nspec:\n  capacity:\n    storage: 1Gi\n  accessModes:\n  - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Retain\n  storageClassName: gpdb-storage\n  local:\n    path: /mnt/disks/greenplum-master-vol0    // 需要提前在相应机器上创建此目录\n  nodeAffinity:\n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - hci-node02\n---\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: greenplum-master-node02\n......重复上面的内容, 改变下local.path, nodeAffinity等在不同node机器上创建多个pv</code></pre><ol start=\"4\">\n<li><p>Repeat the previous step for each PersistentVolume required for your cluster. Remember that each Greenplum segment host requires a dedicated storage volume.</p>\n</li>\n<li><p>Use kubectl to apply the StorageClass and PersistentVolume configurations that you created.</p>\n</li>\n<li><p>Specify the local storage StorageClass name when you deploy a new Greenplum cluster as below.</p>\n</li>\n</ol>\n<h2 id=\"Deploy-a-greenplum-cluster\"><a href=\"#Deploy-a-greenplum-cluster\" class=\"headerlink\" title=\"Deploy a greenplum cluster\"></a><strong>Deploy a greenplum cluster</strong></h2><ol>\n<li>Go to the workspace subdirectory where you unpacked the Pivotal Greenplum distribution for Kubernetes:</li>\n</ol>\n<pre><code>$ cd ./greenplum-for-kubernetes-*/workspace</code></pre><ol start=\"2\">\n<li>If necessary, create a Kubernetes manifest file to specify the configuration of your Greenplum cluster. A sample file is provided in workspace/my-gp-instance.yaml. my-gp-instance.yaml contains the minimal set of instructions necessary to create a demonstration cluster named “my-greenplum” with a single segment and default storage, memory, and CPU settings:</li>\n</ol>\n<pre><code>apiVersion: &quot;greenplum.pivotal.io/v1&quot;\nkind: &quot;GreenplumCluster&quot;\nmetadata:\n  name: my-greenplum\nspec:\n  masterAndStandby:\n    hostBasedAuthentication: |\n      # host   all   gpadmin   1.2.3.4/32   trust\n      # host   all   gpuser    0.0.0.0/0   md5\n    memory: &quot;800Mi&quot;\n    cpu: &quot;0.5&quot;\n    storageClassName: gpdb-storage\n    storage: 1G\n    antiAffinity: &quot;yes&quot;\n    workerSelector: {}\n  segments:\n    primarySegmentCount: 2        # Expand the segment to 2\n    memory: &quot;800Mi&quot;\n    cpu: &quot;0.5&quot;\n    storageClassName: gpdb-storage        # Use the specify storageclass\n    storage: 10G                # Expand the storage to 10G\n    antiAffinity: &quot;yes&quot;\n    workerSelector: {}\n    mirrors: &quot;yes&quot;</code></pre><ol start=\"3\">\n<li>Use kubectl apply command and specify your manifest file to send the deployment request to the Greenplum Operator. For example, to use the sample my-gp-instance.yaml file:</li>\n</ol>\n<pre><code>$ kubectl apply -f ./my-gp-instance.yaml \n  greenplumcluster.greenplum.pivotal.io/my-greenplum created</code></pre><h2 id=\"Deploy-multiple-greenplum-cluster\"><a href=\"#Deploy-multiple-greenplum-cluster\" class=\"headerlink\" title=\"Deploy multiple greenplum cluster\"></a><strong>Deploy multiple greenplum cluster</strong></h2><ol>\n<li>Create namespaces for greenplum cluster to deploy. Deploy two greenplum cluster instances:</li>\n</ol>\n<pre><code>$ kubectl create namespace gpinstance-1\n$ kubectl create namespace gpinstance-2</code></pre><ol start=\"2\">\n<li>Deploy Greenplum cluster into the correspond namespace.</li>\n</ol>\n<pre><code>$ cd workspace\n$ kubectl apply -f ./my-gp-instance.yaml -n gpinstance-1\n$ kubectl apply -f ./my-gp-instance.yaml -n gpinstance-2</code></pre><h2 id=\"Test-whether-the-Greenplum-Cluster-deployment-is-successful\"><a href=\"#Test-whether-the-Greenplum-Cluster-deployment-is-successful\" class=\"headerlink\" title=\"Test whether the Greenplum Cluster deployment is successful\"></a><strong>Test whether the Greenplum Cluster deployment is successful</strong></h2><pre><code>$ kubectl exec -it master-0 -n greenplum -- bash -c &quot;source /opt/gpdb/greenplum_path.sh; psql&quot;\n psql (8.3.23)\n Type &quot;help&quot; for help.\n\n gpadmin=# select * from gp_segment_configuration;\n如果报一些错误无法执行可以:\n1. 先进入master-0: kubectl exec -it master-0 -n greenplum -- bash, 再查找greenplum_path.sh\n2. 执行`$ source /opt/gpdb/greenplum_path.sh`, 再 `$ exit`退出, 然后就可以用以上命令了</code></pre><p>(Enter <code>\\q</code> to exit the psql utility.)</p>\n<h2 id=\"Delete-a-greenplum-cluster-and-uninstall-pivotal-greenplum-for-kubernetes\"><a href=\"#Delete-a-greenplum-cluster-and-uninstall-pivotal-greenplum-for-kubernetes\" class=\"headerlink\" title=\"Delete a greenplum cluster and uninstall pivotal greenplum for kubernetes\"></a><strong>Delete a greenplum cluster and uninstall pivotal greenplum for kubernetes</strong></h2><h3 id=\"Delete-a-greenplum-cluster\"><a href=\"#Delete-a-greenplum-cluster\" class=\"headerlink\" title=\"Delete a greenplum cluster\"></a><strong>Delete a greenplum cluster</strong></h3><ol>\n<li>Navigate to the workspace directory of the Pivotal Greenplum distribution (or to the location of the Kubernetes manifest that you used to deploy the cluster). For example:</li>\n</ol>\n<pre><code>$ cd ./greenplum-for-kubernetes-*/workspace</code></pre><ol start=\"2\">\n<li>Execute the kubectl delete command, specifying the manifest that you used to deploy the cluster. For example:</li>\n</ol>\n<pre><code>$ kubectl delete -f ./my-gp-instance.yaml --wait=false</code></pre><p><strong>Note:</strong> Use the optional –wait=false flag to return immediately without waiting for the deletion to complete.<br>3. Use kubectl to describe the Greenplum cluster to verify Status.Phase and Events:</p>\n<pre><code>$ kubectl describe greenplumcluster my-greenplum\n [...]\n Status:\n   Instance Image:    greenplum-for-kubernetes:latest\n   Operator Version:  greenplum-operator:latest\n   Phase:             Deleting\n Events:\n   Type    Reason                    Age   From               Message\n   ----    ------                    ----  ----               -------\n   Normal  CreatingGreenplumCluster  3m    greenplumOperator  Creating Greenplum cluster my-greenplum in default\n   Normal  CreatedGreenplumCluster   1m    greenplumOperator  Successfully created Greenplum cluster my-greenplum in default\n   Normal  DeletingGreenplumCluster  6s    greenplumOperator  Deleting Greenplum cluster my-greenplum in default</code></pre><p>If for any reason stopping the Greenplum instance fails, you should see a warning message in the greenplum-operator logs as shown below:</p>\n<pre><code>$ kubectl logs -l app=greenplum-operator\n[...]\n{&quot;level&quot;:&quot;INFO&quot;,&quot;ts&quot;:&quot;2020-01-24T19:03:22.874Z&quot;,&quot;logger&quot;:&quot;controllers.GreenplumCluster&quot;,&quot;msg&quot;:&quot;DeletingGreenplumCluster&quot;,&quot;name&quot;:&quot;my-greenplum&quot;,&quot;namespace&quot;:&quot;default&quot;}\n{&quot;level&quot;:&quot;INFO&quot;,&quot;ts&quot;:&quot;2020-01-24T19:03:23.068Z&quot;,&quot;logger&quot;:&quot;controllers.GreenplumCluster&quot;,&quot;msg&quot;:&quot;initiating shutdown of the greenplum cluster&quot;}\n{&quot;level&quot;:&quot;INFO&quot;,&quot;ts&quot;:&quot;2020-01-24T19:03:31.971Z&quot;,&quot;logger&quot;:&quot;controllers.GreenplumCluster&quot;,&quot;msg&quot;:&quot;gpstop did not stop cleanly. Please check gpAdminLogs for more info.&quot;}\n[...]\n{&quot;level&quot;:&quot;INFO&quot;,&quot;ts&quot;:&quot;2020-01-24T19:03:32.252Z&quot;,&quot;logger&quot;:&quot;controllers.GreenplumCluster&quot;,&quot;msg&quot;:&quot;DeletedGreenplumCluster&quot;,&quot;name&quot;:&quot;my-greenplum&quot;,&quot;namespace&quot;:&quot;default&quot;}</code></pre><ol start=\"4\">\n<li>Use kubectl to monitor the progress of terminating Greenplum resources in your cluster. For example, if your cluster deployment was named my-greenplum:</li>\n</ol>\n<pre><code>$ kubectl get all -l greenplum-cluster=my-greenplum\n$ kubectl label nodes hci-node01 greenplum-affinity-greenplum-master-    // 去掉node上关于greenplum的label\n$ kubectl label nodes hci-node01 greenplum-affinity-greenplum-segment-</code></pre><h3 id=\"Delete-greenplum-persistent-volume-claims\"><a href=\"#Delete-greenplum-persistent-volume-claims\" class=\"headerlink\" title=\"Delete greenplum persistent volume claims\"></a><strong>Delete greenplum persistent volume claims</strong></h3><p><strong>Caution:</strong> If the Persistent Volumes were created using dynamic provisioning, then deleting the PVCs will also delete the associated PVs. In this case, do not delete the PVCs unless you are certain that you no longer need the data.</p>\n<ol>\n<li>Verify that the PVCs are present for your cluster. For example, to show the Persistent Volume Claims created for a cluster named my-greenplum:</li>\n</ol>\n<pre><code>$ kubectl get pvc -l greenplum-cluster=my-greenplum</code></pre><ol start=\"2\">\n<li>Use kubectl to delete the PVCs associated with the cluster. For example, to delete all PersistentVolume Claims created for a cluster named my-greenplum:</li>\n</ol>\n<pre><code>$ kubectl delete pvc -l greenplum-cluster=my-greenplum</code></pre><ol start=\"3\">\n<li>If the Persistent Volumes were provisioned manually, then deleting the PVCs does not delete the associated PVs. (You can check for the PVs using kubectl get pv.) To delete any remaining Persistent Volumes, execute the command:</li>\n</ol>\n<pre><code>$ kubectl delete pv -l greenplum-cluster=my-greenplum</code></pre><h3 id=\"Uninstall-pivotal-greenplum-for-kubernetes\"><a href=\"#Uninstall-pivotal-greenplum-for-kubernetes\" class=\"headerlink\" title=\"Uninstall pivotal greenplum for kubernetes\"></a><strong>Uninstall pivotal greenplum for kubernetes</strong></h3><ol>\n<li>Use the helm delete command to delete the greenplum-operator release:</li>\n</ol>\n<pre><code>$ helm delete greenplum-operator\n$ helm del --purge greenplum-operator;</code></pre><ol start=\"2\">\n<li>Delete the node label of greenplum operator when deployed on kubernetes</li>\n</ol>\n<pre><code>$ kubectl label nodes hci-node02 greenplum-operator-</code></pre><ol start=\"3\">\n<li>Use docker rmi to delete images</li>\n</ol>\n<pre><code>$ docker rmi &lt;ImageName or ImgaeID&gt;</code></pre><h2 id=\"FAQ\"><a href=\"#FAQ\" class=\"headerlink\" title=\"FAQ\"></a><strong>FAQ</strong></h2><p>When uninstall greenplum, encountered this problem: Object is being deleted: customresourcedefinitions.apiextensions.k8s.io “greenplumclusters.greenplum.pivotal.io” already exists.</p>\n<p>solution refer to this:<a href=\"https://github.com/kubernetes/kubernetes/issues/60538\" target=\"_blank\" rel=\"noopener\">delete crd</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Prerequisites\"><a href=\"#Prerequisites\" class=\"headerlink\" title=\"Prerequisites\"></a><strong>Prerequisites</strong></h2><ol>\n<li><a href=\"http://greenplum-kubernetes.docs.pivotal.io/2-0/node-requirements.html\" target=\"_blank\" rel=\"noopener\">Kubernetes Node Configuration</a> describes the Linux kernel configuration requirements for each Kubernetes node that is used in a Pivotal Greenplum cluster. These requirements are common to all Pivotal Greenplum deployments, regardless of which Kubernetes environment you use.</li>\n<li>Ensure that any previous Pivotal Greenplum installation has been uninstalled as described in Uninstalling Pivotal Greenplum.</li>\n<li>kubectl configured to refer to a Kubernetes cluster.</li>\n</ol>\n<h2 id=\"Install-Greenplum-Operator-for-Kubernetes\"><a href=\"#Install-Greenplum-Operator-for-Kubernetes\" class=\"headerlink\" title=\"Install Greenplum Operator for Kubernetes\"></a><strong>Install Greenplum Operator for Kubernetes</strong></h2><ol>\n<li>Download the Pivotal Greenplum software from <a href=\"https://network.pivotal.io/products/greenplum-for-kubernetes\" target=\"_blank\" rel=\"noopener\">VMware Tanzu Network</a> or skip to step 3 if have greenplum related files. The download file has the name: <code>greenplum-for-kubernetes-&lt;version&gt;.tar.gz.</code></li>\n</ol>\n<ol start=\"2\">\n<li>Go to the directory where you downloaded Greenplum for Kubernetes, and unpack the downloaded software. For example:</li>\n</ol>\n<pre><code>$ cd ~/Downloads\n$ tar xzf greenplum-for-kubernetes-*.tar.gz</code></pre><p>The above command unpacks the distribution into a new directory named <code>greenplum-for-kubernetes-&lt;version&gt;</code>.<br>3. Go into the new greenplum-for-kubernetes-<version> directory:</p>\n<pre><code>$ cd ./greenplum-for-kubernetes-*</code></pre><ol start=\"4\">\n<li>Load the Greenplum for Kubernetes Docker image to the local Docker registry:</li>\n</ol>\n<pre><code>$ docker load -i ./images/greenplum-for-kubernetes</code></pre><ol start=\"5\">\n<li>Load the Greenplum Operator Docker image to the Docker registry:</li>\n</ol>\n<pre><code>$ docker load -i ./images/greenplum-operator</code></pre><ol start=\"6\">\n<li>Push the Greenplum docker images to the local container registry. For example:</li>\n</ol>\n<pre><code>$ IMAGE_REPO=&quot;hci-node01:5000&quot;\n$ GREENPLUM_IMAGE_NAME=&quot;${IMAGE_REPO}/greenplum-for-kubernetes:$(cat ./images/greenplum-for-kubernetes-tag)&quot;\n$ docker tag $(cat ./images/greenplum-for-kubernetes-id) ${GREENPLUM_IMAGE_NAME}\n$ docker push ${GREENPLUM_IMAGE_NAME}\n\n$ OPERATOR_IMAGE_NAME=&quot;${IMAGE_REPO}/greenplum-operator:$(cat ./images/greenplum-operator-tag)&quot;\n$ docker tag $(cat ./images/greenplum-operator-id) ${OPERATOR_IMAGE_NAME}\n$ docker push ${OPERATOR_IMAGE_NAME}</code></pre><ol start=\"7\">\n<li>Create a new YAML file in the workspace subdirectory with two lines to indicate the registry where you pushed the images</li>\n</ol>\n<pre><code>cat &lt;&lt;EOF &gt;workspace/operator-values-overrides.yaml\noperatorImageRepository: ${IMAGE_REPO}/greenplum-operator\ngreenplumImageRepository: ${IMAGE_REPO}/greenplum-for-kubernetes\noperatorWorkerSelector: {\ngreenplum-operator: &quot;default&quot;\n}\nEOF</code></pre><ol start=\"8\">\n<li>Use helm to create a new Greenplum Operator release.</li>\n</ol>\n<pre><code>// 先给某台机器添加标签来部署greenplum-operator\n$ kubectl label node hci-node02  greenplum-operator=default\n\n$ kubectl create namespace greenplum\n$ helm install -n greenplum-operator -f workspace/operator-values-overrides.yaml operator/ --namespace greenplum\n$ helm install greenplum-operator operator/</code></pre><h2 id=\"Create-Local-Persistent-Volumes-for-Greenplum\"><a href=\"#Create-Local-Persistent-Volumes-for-Greenplum\" class=\"headerlink\" title=\"Create Local Persistent Volumes for Greenplum\"></a><strong>Create Local Persistent Volumes for Greenplum</strong></h2><ol>\n<li>Create the directory, partition, or logical volume that you want to use as a Kubernetes local volume.</li>\n</ol>\n<ol start=\"2\">\n<li>Create the StorageClass definition, specifying no-provisioner in order to manually provision local persistent volumes. Using volumeBindingMode: WaitForFirstConsumer is also recommended to delay binding the local PersistenVolume until a pod requires.</li>\n</ol>\n<pre><code>$ vim gpdb-storage-class.yaml\nkind: StorageClass\napiVersion: storage.k8s.io/v1\nmetadata:\n  name: gpdb-storage\nprovisioner: kubernetes.io/no-provisioner\nvolumeBindingMode: WaitForFirstConsumer</code></pre><ol start=\"3\">\n<li>Create a PersistentVolume definition, specifying the local volume and the required NodeAffinity field. For example:</li>\n</ol>\n<pre><code>$ vim pv-master.yaml\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: greenplum-master-node02\nspec:\n  capacity:\n    storage: 1Gi\n  accessModes:\n  - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Retain\n  storageClassName: gpdb-storage\n  local:\n    path: /mnt/disks/greenplum-master-vol0    // 需要提前在相应机器上创建此目录\n  nodeAffinity:\n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - hci-node02\n---\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: greenplum-master-node02\n......重复上面的内容, 改变下local.path, nodeAffinity等在不同node机器上创建多个pv</code></pre><ol start=\"4\">\n<li><p>Repeat the previous step for each PersistentVolume required for your cluster. Remember that each Greenplum segment host requires a dedicated storage volume.</p>\n</li>\n<li><p>Use kubectl to apply the StorageClass and PersistentVolume configurations that you created.</p>\n</li>\n<li><p>Specify the local storage StorageClass name when you deploy a new Greenplum cluster as below.</p>\n</li>\n</ol>\n<h2 id=\"Deploy-a-greenplum-cluster\"><a href=\"#Deploy-a-greenplum-cluster\" class=\"headerlink\" title=\"Deploy a greenplum cluster\"></a><strong>Deploy a greenplum cluster</strong></h2><ol>\n<li>Go to the workspace subdirectory where you unpacked the Pivotal Greenplum distribution for Kubernetes:</li>\n</ol>\n<pre><code>$ cd ./greenplum-for-kubernetes-*/workspace</code></pre><ol start=\"2\">\n<li>If necessary, create a Kubernetes manifest file to specify the configuration of your Greenplum cluster. A sample file is provided in workspace/my-gp-instance.yaml. my-gp-instance.yaml contains the minimal set of instructions necessary to create a demonstration cluster named “my-greenplum” with a single segment and default storage, memory, and CPU settings:</li>\n</ol>\n<pre><code>apiVersion: &quot;greenplum.pivotal.io/v1&quot;\nkind: &quot;GreenplumCluster&quot;\nmetadata:\n  name: my-greenplum\nspec:\n  masterAndStandby:\n    hostBasedAuthentication: |\n      # host   all   gpadmin   1.2.3.4/32   trust\n      # host   all   gpuser    0.0.0.0/0   md5\n    memory: &quot;800Mi&quot;\n    cpu: &quot;0.5&quot;\n    storageClassName: gpdb-storage\n    storage: 1G\n    antiAffinity: &quot;yes&quot;\n    workerSelector: {}\n  segments:\n    primarySegmentCount: 2        # Expand the segment to 2\n    memory: &quot;800Mi&quot;\n    cpu: &quot;0.5&quot;\n    storageClassName: gpdb-storage        # Use the specify storageclass\n    storage: 10G                # Expand the storage to 10G\n    antiAffinity: &quot;yes&quot;\n    workerSelector: {}\n    mirrors: &quot;yes&quot;</code></pre><ol start=\"3\">\n<li>Use kubectl apply command and specify your manifest file to send the deployment request to the Greenplum Operator. For example, to use the sample my-gp-instance.yaml file:</li>\n</ol>\n<pre><code>$ kubectl apply -f ./my-gp-instance.yaml \n  greenplumcluster.greenplum.pivotal.io/my-greenplum created</code></pre><h2 id=\"Deploy-multiple-greenplum-cluster\"><a href=\"#Deploy-multiple-greenplum-cluster\" class=\"headerlink\" title=\"Deploy multiple greenplum cluster\"></a><strong>Deploy multiple greenplum cluster</strong></h2><ol>\n<li>Create namespaces for greenplum cluster to deploy. Deploy two greenplum cluster instances:</li>\n</ol>\n<pre><code>$ kubectl create namespace gpinstance-1\n$ kubectl create namespace gpinstance-2</code></pre><ol start=\"2\">\n<li>Deploy Greenplum cluster into the correspond namespace.</li>\n</ol>\n<pre><code>$ cd workspace\n$ kubectl apply -f ./my-gp-instance.yaml -n gpinstance-1\n$ kubectl apply -f ./my-gp-instance.yaml -n gpinstance-2</code></pre><h2 id=\"Test-whether-the-Greenplum-Cluster-deployment-is-successful\"><a href=\"#Test-whether-the-Greenplum-Cluster-deployment-is-successful\" class=\"headerlink\" title=\"Test whether the Greenplum Cluster deployment is successful\"></a><strong>Test whether the Greenplum Cluster deployment is successful</strong></h2><pre><code>$ kubectl exec -it master-0 -n greenplum -- bash -c &quot;source /opt/gpdb/greenplum_path.sh; psql&quot;\n psql (8.3.23)\n Type &quot;help&quot; for help.\n\n gpadmin=# select * from gp_segment_configuration;\n如果报一些错误无法执行可以:\n1. 先进入master-0: kubectl exec -it master-0 -n greenplum -- bash, 再查找greenplum_path.sh\n2. 执行`$ source /opt/gpdb/greenplum_path.sh`, 再 `$ exit`退出, 然后就可以用以上命令了</code></pre><p>(Enter <code>\\q</code> to exit the psql utility.)</p>\n<h2 id=\"Delete-a-greenplum-cluster-and-uninstall-pivotal-greenplum-for-kubernetes\"><a href=\"#Delete-a-greenplum-cluster-and-uninstall-pivotal-greenplum-for-kubernetes\" class=\"headerlink\" title=\"Delete a greenplum cluster and uninstall pivotal greenplum for kubernetes\"></a><strong>Delete a greenplum cluster and uninstall pivotal greenplum for kubernetes</strong></h2><h3 id=\"Delete-a-greenplum-cluster\"><a href=\"#Delete-a-greenplum-cluster\" class=\"headerlink\" title=\"Delete a greenplum cluster\"></a><strong>Delete a greenplum cluster</strong></h3><ol>\n<li>Navigate to the workspace directory of the Pivotal Greenplum distribution (or to the location of the Kubernetes manifest that you used to deploy the cluster). For example:</li>\n</ol>\n<pre><code>$ cd ./greenplum-for-kubernetes-*/workspace</code></pre><ol start=\"2\">\n<li>Execute the kubectl delete command, specifying the manifest that you used to deploy the cluster. For example:</li>\n</ol>\n<pre><code>$ kubectl delete -f ./my-gp-instance.yaml --wait=false</code></pre><p><strong>Note:</strong> Use the optional –wait=false flag to return immediately without waiting for the deletion to complete.<br>3. Use kubectl to describe the Greenplum cluster to verify Status.Phase and Events:</p>\n<pre><code>$ kubectl describe greenplumcluster my-greenplum\n [...]\n Status:\n   Instance Image:    greenplum-for-kubernetes:latest\n   Operator Version:  greenplum-operator:latest\n   Phase:             Deleting\n Events:\n   Type    Reason                    Age   From               Message\n   ----    ------                    ----  ----               -------\n   Normal  CreatingGreenplumCluster  3m    greenplumOperator  Creating Greenplum cluster my-greenplum in default\n   Normal  CreatedGreenplumCluster   1m    greenplumOperator  Successfully created Greenplum cluster my-greenplum in default\n   Normal  DeletingGreenplumCluster  6s    greenplumOperator  Deleting Greenplum cluster my-greenplum in default</code></pre><p>If for any reason stopping the Greenplum instance fails, you should see a warning message in the greenplum-operator logs as shown below:</p>\n<pre><code>$ kubectl logs -l app=greenplum-operator\n[...]\n{&quot;level&quot;:&quot;INFO&quot;,&quot;ts&quot;:&quot;2020-01-24T19:03:22.874Z&quot;,&quot;logger&quot;:&quot;controllers.GreenplumCluster&quot;,&quot;msg&quot;:&quot;DeletingGreenplumCluster&quot;,&quot;name&quot;:&quot;my-greenplum&quot;,&quot;namespace&quot;:&quot;default&quot;}\n{&quot;level&quot;:&quot;INFO&quot;,&quot;ts&quot;:&quot;2020-01-24T19:03:23.068Z&quot;,&quot;logger&quot;:&quot;controllers.GreenplumCluster&quot;,&quot;msg&quot;:&quot;initiating shutdown of the greenplum cluster&quot;}\n{&quot;level&quot;:&quot;INFO&quot;,&quot;ts&quot;:&quot;2020-01-24T19:03:31.971Z&quot;,&quot;logger&quot;:&quot;controllers.GreenplumCluster&quot;,&quot;msg&quot;:&quot;gpstop did not stop cleanly. Please check gpAdminLogs for more info.&quot;}\n[...]\n{&quot;level&quot;:&quot;INFO&quot;,&quot;ts&quot;:&quot;2020-01-24T19:03:32.252Z&quot;,&quot;logger&quot;:&quot;controllers.GreenplumCluster&quot;,&quot;msg&quot;:&quot;DeletedGreenplumCluster&quot;,&quot;name&quot;:&quot;my-greenplum&quot;,&quot;namespace&quot;:&quot;default&quot;}</code></pre><ol start=\"4\">\n<li>Use kubectl to monitor the progress of terminating Greenplum resources in your cluster. For example, if your cluster deployment was named my-greenplum:</li>\n</ol>\n<pre><code>$ kubectl get all -l greenplum-cluster=my-greenplum\n$ kubectl label nodes hci-node01 greenplum-affinity-greenplum-master-    // 去掉node上关于greenplum的label\n$ kubectl label nodes hci-node01 greenplum-affinity-greenplum-segment-</code></pre><h3 id=\"Delete-greenplum-persistent-volume-claims\"><a href=\"#Delete-greenplum-persistent-volume-claims\" class=\"headerlink\" title=\"Delete greenplum persistent volume claims\"></a><strong>Delete greenplum persistent volume claims</strong></h3><p><strong>Caution:</strong> If the Persistent Volumes were created using dynamic provisioning, then deleting the PVCs will also delete the associated PVs. In this case, do not delete the PVCs unless you are certain that you no longer need the data.</p>\n<ol>\n<li>Verify that the PVCs are present for your cluster. For example, to show the Persistent Volume Claims created for a cluster named my-greenplum:</li>\n</ol>\n<pre><code>$ kubectl get pvc -l greenplum-cluster=my-greenplum</code></pre><ol start=\"2\">\n<li>Use kubectl to delete the PVCs associated with the cluster. For example, to delete all PersistentVolume Claims created for a cluster named my-greenplum:</li>\n</ol>\n<pre><code>$ kubectl delete pvc -l greenplum-cluster=my-greenplum</code></pre><ol start=\"3\">\n<li>If the Persistent Volumes were provisioned manually, then deleting the PVCs does not delete the associated PVs. (You can check for the PVs using kubectl get pv.) To delete any remaining Persistent Volumes, execute the command:</li>\n</ol>\n<pre><code>$ kubectl delete pv -l greenplum-cluster=my-greenplum</code></pre><h3 id=\"Uninstall-pivotal-greenplum-for-kubernetes\"><a href=\"#Uninstall-pivotal-greenplum-for-kubernetes\" class=\"headerlink\" title=\"Uninstall pivotal greenplum for kubernetes\"></a><strong>Uninstall pivotal greenplum for kubernetes</strong></h3><ol>\n<li>Use the helm delete command to delete the greenplum-operator release:</li>\n</ol>\n<pre><code>$ helm delete greenplum-operator\n$ helm del --purge greenplum-operator;</code></pre><ol start=\"2\">\n<li>Delete the node label of greenplum operator when deployed on kubernetes</li>\n</ol>\n<pre><code>$ kubectl label nodes hci-node02 greenplum-operator-</code></pre><ol start=\"3\">\n<li>Use docker rmi to delete images</li>\n</ol>\n<pre><code>$ docker rmi &lt;ImageName or ImgaeID&gt;</code></pre><h2 id=\"FAQ\"><a href=\"#FAQ\" class=\"headerlink\" title=\"FAQ\"></a><strong>FAQ</strong></h2><p>When uninstall greenplum, encountered this problem: Object is being deleted: customresourcedefinitions.apiextensions.k8s.io “greenplumclusters.greenplum.pivotal.io” already exists.</p>\n<p>solution refer to this:<a href=\"https://github.com/kubernetes/kubernetes/issues/60538\" target=\"_blank\" rel=\"noopener\">delete crd</a></p>\n"},{"title":"MinIO 01 conception","_content":"\nofficial website:[https://min.io/](https://min.io/)\n\n\n\n","source":"_posts/storage/minIO_01_conception.md","raw":"---\ntitle: MinIO 01 conception\ntags: storage\ncategories:\n- storage\n---\n\nofficial website:[https://min.io/](https://min.io/)\n\n\n\n","slug":"storage/minIO_01_conception","published":1,"date":"2020-08-12T16:05:48.470Z","updated":"2020-08-06T07:12:01.451Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmgz006ihohxe0t38dat","content":"<p>official website:<a href=\"https://min.io/\" target=\"_blank\" rel=\"noopener\">https://min.io/</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>official website:<a href=\"https://min.io/\" target=\"_blank\" rel=\"noopener\">https://min.io/</a></p>\n"},{"title":"MinIO 03 client","_content":"\nOfficial web site: [https://docs.min.io/docs/minio-client-quickstart-guide.html](https://docs.min.io/docs/minio-client-quickstart-guide.html)\n下面介绍的是使用MinIO自导的client： mc\n\n## **Download mc tool**\nGNU/Linux\n\n\t$ wget https://dl.min.io/client/mc/release/linux-amd64/mc\n\t$ chmod +x mc\n\t$ ./mc --help\n\t$ ./mc --version\n\nMicrosoft Windows\n\n\t下载:https://dl.min.io/client/mc/release/windows-amd64/mc.exe\n\tmc.exe --help\nMinIO Client (mc) provides a modern alternative to UNIX commands like ls, cat, cp, mirror, diff etc. It supports filesystems and Amazon S3 compatible cloud storage service (AWS Signature v2 and v4).\n\n\talias       set, remove and list aliases in configuration file\n\tls          list buckets and objects\n\tmb          make a bucket\n\trb          remove a bucket\n\tcp          copy objects\n\tmirror      synchronize object(s) to a remote site\n\tcat         display object contents\n\thead        display first 'n' lines of an object\n\tpipe        stream STDIN to an object\n\tshare       generate URL for temporary access to an object\n\tfind        search for objects\n\tsql         run sql queries on objects\n\tstat        show object metadata\n\tmv          move objects\n\ttree        list buckets and objects in a tree format\n\tdu          summarize disk usage recursively\n\tretention   set retention for object(s)\n\tlegalhold   set legal hold for object(s)\n\tdiff        list differences in object name, size, and date between two buckets\n\trm          remove objects\n\tversioning  manage bucket versioning\n\tlock        manage default bucket object lock configuration\n\tilm         manage bucket lifecycle\n\tencrypt     manage bucket encryption config\n\tevent       manage object notifications\n\twatch       listen for object notification events\n\tpolicy      manage anonymous access to buckets and objects\n\ttag         manage tags for bucket(s) and object(s)\n\tadmin       manage MinIO servers\n\tupdate      update mc to latest release\n\n## **Note**\n当MinIO server配置TLS时候，使用`mc`的命令中需要添加 `--insecure`, 如:\n\n\t$ ./mc ls myminio --insecure\n\n## Command List\n**查看，添加，移除minio host**\n\n\t// 查看 host\n\t$ mc config host list\n\t// 添加 host, server没有配置TLS\n\t$ mc config host add myminio http://127.0.0.1:30007 minio minio123 --api S3v4\n\t// 添加 host, server配置TLS, http变为https\n\t$ mc config host add myminio https://127.0.0.1:30007 minio minio123 --api S3v4\n\t// 移除 host\n\t$ mc config host remove myminio\n**查看bucket, object**\n\n\t//查看所有bucket\n\t$ mc ls myminio --insecure //server没有配置TLS可以不加`--insecure`\n\t//查看bucket下的object\n\t$ mc ls myminio/my-bucket01/\n**创建bucket**\n\n\t$ mc mb myminio/my-bucket03 --insecure\n**添加,删除文件(object)**\n\n\t// 添加文件(objcet)\n\t$ mc cp minioinstance.yaml myminio/my-bucket03 --insecure\n\t// 删除文件\n\t$ mc rm myminio/my-bucket03/minioinstance.yaml --insecure\n\n**查看bucket使用量**\n\n\t$ mc du myminio\n\n\n\n\n\n\n\n\n\n","source":"_posts/storage/minIO_03_client.md.md","raw":"---\ntitle: MinIO 03 client\ntags: storage\ncategories:\n- storage\n---\n\nOfficial web site: [https://docs.min.io/docs/minio-client-quickstart-guide.html](https://docs.min.io/docs/minio-client-quickstart-guide.html)\n下面介绍的是使用MinIO自导的client： mc\n\n## **Download mc tool**\nGNU/Linux\n\n\t$ wget https://dl.min.io/client/mc/release/linux-amd64/mc\n\t$ chmod +x mc\n\t$ ./mc --help\n\t$ ./mc --version\n\nMicrosoft Windows\n\n\t下载:https://dl.min.io/client/mc/release/windows-amd64/mc.exe\n\tmc.exe --help\nMinIO Client (mc) provides a modern alternative to UNIX commands like ls, cat, cp, mirror, diff etc. It supports filesystems and Amazon S3 compatible cloud storage service (AWS Signature v2 and v4).\n\n\talias       set, remove and list aliases in configuration file\n\tls          list buckets and objects\n\tmb          make a bucket\n\trb          remove a bucket\n\tcp          copy objects\n\tmirror      synchronize object(s) to a remote site\n\tcat         display object contents\n\thead        display first 'n' lines of an object\n\tpipe        stream STDIN to an object\n\tshare       generate URL for temporary access to an object\n\tfind        search for objects\n\tsql         run sql queries on objects\n\tstat        show object metadata\n\tmv          move objects\n\ttree        list buckets and objects in a tree format\n\tdu          summarize disk usage recursively\n\tretention   set retention for object(s)\n\tlegalhold   set legal hold for object(s)\n\tdiff        list differences in object name, size, and date between two buckets\n\trm          remove objects\n\tversioning  manage bucket versioning\n\tlock        manage default bucket object lock configuration\n\tilm         manage bucket lifecycle\n\tencrypt     manage bucket encryption config\n\tevent       manage object notifications\n\twatch       listen for object notification events\n\tpolicy      manage anonymous access to buckets and objects\n\ttag         manage tags for bucket(s) and object(s)\n\tadmin       manage MinIO servers\n\tupdate      update mc to latest release\n\n## **Note**\n当MinIO server配置TLS时候，使用`mc`的命令中需要添加 `--insecure`, 如:\n\n\t$ ./mc ls myminio --insecure\n\n## Command List\n**查看，添加，移除minio host**\n\n\t// 查看 host\n\t$ mc config host list\n\t// 添加 host, server没有配置TLS\n\t$ mc config host add myminio http://127.0.0.1:30007 minio minio123 --api S3v4\n\t// 添加 host, server配置TLS, http变为https\n\t$ mc config host add myminio https://127.0.0.1:30007 minio minio123 --api S3v4\n\t// 移除 host\n\t$ mc config host remove myminio\n**查看bucket, object**\n\n\t//查看所有bucket\n\t$ mc ls myminio --insecure //server没有配置TLS可以不加`--insecure`\n\t//查看bucket下的object\n\t$ mc ls myminio/my-bucket01/\n**创建bucket**\n\n\t$ mc mb myminio/my-bucket03 --insecure\n**添加,删除文件(object)**\n\n\t// 添加文件(objcet)\n\t$ mc cp minioinstance.yaml myminio/my-bucket03 --insecure\n\t// 删除文件\n\t$ mc rm myminio/my-bucket03/minioinstance.yaml --insecure\n\n**查看bucket使用量**\n\n\t$ mc du myminio\n\n\n\n\n\n\n\n\n\n","slug":"storage/minIO_03_client.md","published":1,"date":"2020-08-12T16:05:48.483Z","updated":"2020-08-06T07:58:53.555Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmh1006mhohxfsle9fob","content":"<p>Official web site: <a href=\"https://docs.min.io/docs/minio-client-quickstart-guide.html\" target=\"_blank\" rel=\"noopener\">https://docs.min.io/docs/minio-client-quickstart-guide.html</a><br>下面介绍的是使用MinIO自导的client： mc</p>\n<h2 id=\"Download-mc-tool\"><a href=\"#Download-mc-tool\" class=\"headerlink\" title=\"Download mc tool\"></a><strong>Download mc tool</strong></h2><p>GNU/Linux</p>\n<pre><code>$ wget https://dl.min.io/client/mc/release/linux-amd64/mc\n$ chmod +x mc\n$ ./mc --help\n$ ./mc --version</code></pre><p>Microsoft Windows</p>\n<pre><code>下载:https://dl.min.io/client/mc/release/windows-amd64/mc.exe\nmc.exe --help</code></pre><p>MinIO Client (mc) provides a modern alternative to UNIX commands like ls, cat, cp, mirror, diff etc. It supports filesystems and Amazon S3 compatible cloud storage service (AWS Signature v2 and v4).</p>\n<pre><code>alias       set, remove and list aliases in configuration file\nls          list buckets and objects\nmb          make a bucket\nrb          remove a bucket\ncp          copy objects\nmirror      synchronize object(s) to a remote site\ncat         display object contents\nhead        display first &apos;n&apos; lines of an object\npipe        stream STDIN to an object\nshare       generate URL for temporary access to an object\nfind        search for objects\nsql         run sql queries on objects\nstat        show object metadata\nmv          move objects\ntree        list buckets and objects in a tree format\ndu          summarize disk usage recursively\nretention   set retention for object(s)\nlegalhold   set legal hold for object(s)\ndiff        list differences in object name, size, and date between two buckets\nrm          remove objects\nversioning  manage bucket versioning\nlock        manage default bucket object lock configuration\nilm         manage bucket lifecycle\nencrypt     manage bucket encryption config\nevent       manage object notifications\nwatch       listen for object notification events\npolicy      manage anonymous access to buckets and objects\ntag         manage tags for bucket(s) and object(s)\nadmin       manage MinIO servers\nupdate      update mc to latest release</code></pre><h2 id=\"Note\"><a href=\"#Note\" class=\"headerlink\" title=\"Note\"></a><strong>Note</strong></h2><p>当MinIO server配置TLS时候，使用<code>mc</code>的命令中需要添加 <code>--insecure</code>, 如:</p>\n<pre><code>$ ./mc ls myminio --insecure</code></pre><h2 id=\"Command-List\"><a href=\"#Command-List\" class=\"headerlink\" title=\"Command List\"></a>Command List</h2><p><strong>查看，添加，移除minio host</strong></p>\n<pre><code>// 查看 host\n$ mc config host list\n// 添加 host, server没有配置TLS\n$ mc config host add myminio http://127.0.0.1:30007 minio minio123 --api S3v4\n// 添加 host, server配置TLS, http变为https\n$ mc config host add myminio https://127.0.0.1:30007 minio minio123 --api S3v4\n// 移除 host\n$ mc config host remove myminio</code></pre><p><strong>查看bucket, object</strong></p>\n<pre><code>//查看所有bucket\n$ mc ls myminio --insecure //server没有配置TLS可以不加`--insecure`\n//查看bucket下的object\n$ mc ls myminio/my-bucket01/</code></pre><p><strong>创建bucket</strong></p>\n<pre><code>$ mc mb myminio/my-bucket03 --insecure</code></pre><p><strong>添加,删除文件(object)</strong></p>\n<pre><code>// 添加文件(objcet)\n$ mc cp minioinstance.yaml myminio/my-bucket03 --insecure\n// 删除文件\n$ mc rm myminio/my-bucket03/minioinstance.yaml --insecure</code></pre><p><strong>查看bucket使用量</strong></p>\n<pre><code>$ mc du myminio</code></pre>","site":{"data":{}},"excerpt":"","more":"<p>Official web site: <a href=\"https://docs.min.io/docs/minio-client-quickstart-guide.html\" target=\"_blank\" rel=\"noopener\">https://docs.min.io/docs/minio-client-quickstart-guide.html</a><br>下面介绍的是使用MinIO自导的client： mc</p>\n<h2 id=\"Download-mc-tool\"><a href=\"#Download-mc-tool\" class=\"headerlink\" title=\"Download mc tool\"></a><strong>Download mc tool</strong></h2><p>GNU/Linux</p>\n<pre><code>$ wget https://dl.min.io/client/mc/release/linux-amd64/mc\n$ chmod +x mc\n$ ./mc --help\n$ ./mc --version</code></pre><p>Microsoft Windows</p>\n<pre><code>下载:https://dl.min.io/client/mc/release/windows-amd64/mc.exe\nmc.exe --help</code></pre><p>MinIO Client (mc) provides a modern alternative to UNIX commands like ls, cat, cp, mirror, diff etc. It supports filesystems and Amazon S3 compatible cloud storage service (AWS Signature v2 and v4).</p>\n<pre><code>alias       set, remove and list aliases in configuration file\nls          list buckets and objects\nmb          make a bucket\nrb          remove a bucket\ncp          copy objects\nmirror      synchronize object(s) to a remote site\ncat         display object contents\nhead        display first &apos;n&apos; lines of an object\npipe        stream STDIN to an object\nshare       generate URL for temporary access to an object\nfind        search for objects\nsql         run sql queries on objects\nstat        show object metadata\nmv          move objects\ntree        list buckets and objects in a tree format\ndu          summarize disk usage recursively\nretention   set retention for object(s)\nlegalhold   set legal hold for object(s)\ndiff        list differences in object name, size, and date between two buckets\nrm          remove objects\nversioning  manage bucket versioning\nlock        manage default bucket object lock configuration\nilm         manage bucket lifecycle\nencrypt     manage bucket encryption config\nevent       manage object notifications\nwatch       listen for object notification events\npolicy      manage anonymous access to buckets and objects\ntag         manage tags for bucket(s) and object(s)\nadmin       manage MinIO servers\nupdate      update mc to latest release</code></pre><h2 id=\"Note\"><a href=\"#Note\" class=\"headerlink\" title=\"Note\"></a><strong>Note</strong></h2><p>当MinIO server配置TLS时候，使用<code>mc</code>的命令中需要添加 <code>--insecure</code>, 如:</p>\n<pre><code>$ ./mc ls myminio --insecure</code></pre><h2 id=\"Command-List\"><a href=\"#Command-List\" class=\"headerlink\" title=\"Command List\"></a>Command List</h2><p><strong>查看，添加，移除minio host</strong></p>\n<pre><code>// 查看 host\n$ mc config host list\n// 添加 host, server没有配置TLS\n$ mc config host add myminio http://127.0.0.1:30007 minio minio123 --api S3v4\n// 添加 host, server配置TLS, http变为https\n$ mc config host add myminio https://127.0.0.1:30007 minio minio123 --api S3v4\n// 移除 host\n$ mc config host remove myminio</code></pre><p><strong>查看bucket, object</strong></p>\n<pre><code>//查看所有bucket\n$ mc ls myminio --insecure //server没有配置TLS可以不加`--insecure`\n//查看bucket下的object\n$ mc ls myminio/my-bucket01/</code></pre><p><strong>创建bucket</strong></p>\n<pre><code>$ mc mb myminio/my-bucket03 --insecure</code></pre><p><strong>添加,删除文件(object)</strong></p>\n<pre><code>// 添加文件(objcet)\n$ mc cp minioinstance.yaml myminio/my-bucket03 --insecure\n// 删除文件\n$ mc rm myminio/my-bucket03/minioinstance.yaml --insecure</code></pre><p><strong>查看bucket使用量</strong></p>\n<pre><code>$ mc du myminio</code></pre>"},{"title":"Intel_tips_at_work","_content":"\n### 聊天邮件等添加表情\nwindows键+分号键\";\" 能够选择表情\n\n### 关于cube主机连接网络问题\ncube 台式机网线连接C口，宿主主机安装Virtualbox后再安装linux虚拟机，网络选择桥接模式，跟宿主主机网络处于同一网段，与宿主主机互不影响.\n台式机连接A口，宿主主机设置proxy后可以连接外网，但是virtualbox安装的虚拟机就连不到外网了\n安装好虚拟机OS，\n$ sudo passwd root\n输入user用户密码，再设置root密码，下次就可以$ su root 获取root权限了\n","source":"_posts/technologies/Intel_tips_at_work.md","raw":"---\ntitle: Intel_tips_at_work\ntags:\ncategories:\n- technologies\n---\n\n### 聊天邮件等添加表情\nwindows键+分号键\";\" 能够选择表情\n\n### 关于cube主机连接网络问题\ncube 台式机网线连接C口，宿主主机安装Virtualbox后再安装linux虚拟机，网络选择桥接模式，跟宿主主机网络处于同一网段，与宿主主机互不影响.\n台式机连接A口，宿主主机设置proxy后可以连接外网，但是virtualbox安装的虚拟机就连不到外网了\n安装好虚拟机OS，\n$ sudo passwd root\n输入user用户密码，再设置root密码，下次就可以$ su root 获取root权限了\n","slug":"technologies/Intel_tips_at_work","published":1,"date":"2020-08-12T16:05:48.503Z","updated":"2020-04-17T13:50:55.010Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmh2006qhohx7s0z5lbe","content":"<h3 id=\"聊天邮件等添加表情\"><a href=\"#聊天邮件等添加表情\" class=\"headerlink\" title=\"聊天邮件等添加表情\"></a>聊天邮件等添加表情</h3><p>windows键+分号键”;” 能够选择表情</p>\n<h3 id=\"关于cube主机连接网络问题\"><a href=\"#关于cube主机连接网络问题\" class=\"headerlink\" title=\"关于cube主机连接网络问题\"></a>关于cube主机连接网络问题</h3><p>cube 台式机网线连接C口，宿主主机安装Virtualbox后再安装linux虚拟机，网络选择桥接模式，跟宿主主机网络处于同一网段，与宿主主机互不影响.<br>台式机连接A口，宿主主机设置proxy后可以连接外网，但是virtualbox安装的虚拟机就连不到外网了<br>安装好虚拟机OS，<br>$ sudo passwd root<br>输入user用户密码，再设置root密码，下次就可以$ su root 获取root权限了</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"聊天邮件等添加表情\"><a href=\"#聊天邮件等添加表情\" class=\"headerlink\" title=\"聊天邮件等添加表情\"></a>聊天邮件等添加表情</h3><p>windows键+分号键”;” 能够选择表情</p>\n<h3 id=\"关于cube主机连接网络问题\"><a href=\"#关于cube主机连接网络问题\" class=\"headerlink\" title=\"关于cube主机连接网络问题\"></a>关于cube主机连接网络问题</h3><p>cube 台式机网线连接C口，宿主主机安装Virtualbox后再安装linux虚拟机，网络选择桥接模式，跟宿主主机网络处于同一网段，与宿主主机互不影响.<br>台式机连接A口，宿主主机设置proxy后可以连接外网，但是virtualbox安装的虚拟机就连不到外网了<br>安装好虚拟机OS，<br>$ sudo passwd root<br>输入user用户密码，再设置root密码，下次就可以$ su root 获取root权限了</p>\n"},{"title":"git","_content":"\n## 查看github 贡献最多和增长最快链接:\nhttps://octoverse.github.com/#fastest-growing-oss-projects-by-contributors\n\n## 解决git bash 终端显示中文乱码\n\t在git bash的界面中右击空白处，弹出菜单，选择选项->文本->本地Locale，设置为zh_CN，而旁边的字符集选框选为UTF-8\n\t上面方法在git add带中文文件时候会出现 \"add不到匹配的文件\" 或者 重启还是出现中文乱码,解决方法如下(亲测有效)：\n\t1. 选择选项->文本->本地Locale，设置为(Defalult)\n\t2. $git config --global core.quotepath false 再重启gitbash终端可解决\n\n## git push免密登陆方法\n\t创建文件 C:\\Users\\hp\\.git-credentials(Windows系统, 惠普电脑, 其它种类OS和厂商路径类似)\n\t打开并添加内容 https://{username}:{password}@github.com\n\t2.添加git config内容\n\t$git config --global credential.helper store\n\t执行此命令后，用户主目录下的.gitconfig文件会多了一项：[credential]\n\thelper = store\n\t重新git push就不需要用户名密码了\n\n## git提示“warning: LF will be replaced by CRLF”\n遇到此问题场景: 在windows上用git提交linux文件, 这是因为在文本处理中，CR（CarriageReturn），LF（LineFeed），CR/LF是不同操作系统上使用的换行符.\n\n * Dos和Windows平台: 使用回车（CR）和换行（LF）两个字符来结束一行，回车+换行(CR+LF)，即“\\r\\n”；\n * Mac 和 Linux平台: 只使用换行（LF）一个字符来结束一行，即“\\n”；\n所以我们平时在windows上编写文件的`回车符`应该确切来说叫做`回车换行符`.\n\n许多 Windows 上的编辑器会悄悄把行尾的换行（LF）字符转换成回车（CR）和换行（LF），或在用户按下 Enter 键时，插入回车（CR）和换行（LF）两个字符.  \n\n**影响：**\n * Unix/Mac系统下的文件在Windows里打开的话，所有文字会变成一行.  \n * 而Windows里的文件在Unix/Mac下打开的话，在每行的结尾可能会多出一个^M符号.  \n * Linux保存的文件在windows上用记事本看的话会出现黑点.  \n通过一定方式进行转换统一:\n\n\t在linux下，命令unix2dos 是把linux文件格式转换成windows文件格式\n\t命令dos2unix 是把windows格式转换成linux文件格式.\n**情况一:**\nGit 可以在你提交时自动地把回车(CR)和换行(LF)转换成换行(LF), 而在检出代码时把换行(LF)转换成回车(CR)和换行(LF).  \n如果是在 Windows 系统上，把它设置成 true，这样在检出代码时，换行会被转换成回车和换行.  \n\n\t#提交时转换为LF，检出时转换为CRLF\n\t$ git config --global core.autocrlf true\n**情况二:**\n可以把 core.autocrlf 设置成 input 来告诉 Git 在提交时把回车和换行转换成换行，检出时不转换, 这样在 Windows 上的检出文件中会保留回车和换行，而在 Mac 和 Linux 上，以及版本库中会保留换行.  \n\n\t#提交时转换为LF，检出时不转换\n\t$ git config --global core.autocrlf input\n**情况三:**\n如果你是 Windows 程序员，且正在开发仅运行在 Windows 上的项目，可以设置 false 取消此功能，把回车保留在版本库中.  \n\n\t#提交检出均不转换\n\t$ git config --global core.autocrlf false\n**你也可以在文件提交时进行safecrlf检查**\n\n\t#拒绝提交包含混合换行符的文件\n\tgit config --global core.safecrlf true   \n\t\n\t#允许提交包含混合换行符的文件\n\tgit config --global core.safecrlf false   \n\t\n\t#提交包含混合换行符的文件时给出警告\n\tgit config --global core.safecrlf warn\n**通俗解释**\n * git 的 Windows 客户端基本都会默认设置 core.autocrlf=true，设置core.autocrlf=true, 只要保持工作区都是纯 CRLF 文件，编辑器用 CRLF 换行，就不会出现警告了.  \n * Linux 最好不要设置 core.autocrlf，因为这个配置算是为 Windows 平台定制.  \n * Windows 上设置 core.autocrlf=false，仓库里也没有配置 .gitattributes，很容易引入 CRLF 或者混合换行符（Mixed Line Endings，一个文件里既有 LF 又有CRLF）到版本库，这样就可能产生各种奇怪的问题.  \n\n\n\n\n\n","source":"_posts/technologies/git_problems_encountered.md","raw":"---\ntitle: git\ntags: git\ncategories:\n- technologies\n---\n\n## 查看github 贡献最多和增长最快链接:\nhttps://octoverse.github.com/#fastest-growing-oss-projects-by-contributors\n\n## 解决git bash 终端显示中文乱码\n\t在git bash的界面中右击空白处，弹出菜单，选择选项->文本->本地Locale，设置为zh_CN，而旁边的字符集选框选为UTF-8\n\t上面方法在git add带中文文件时候会出现 \"add不到匹配的文件\" 或者 重启还是出现中文乱码,解决方法如下(亲测有效)：\n\t1. 选择选项->文本->本地Locale，设置为(Defalult)\n\t2. $git config --global core.quotepath false 再重启gitbash终端可解决\n\n## git push免密登陆方法\n\t创建文件 C:\\Users\\hp\\.git-credentials(Windows系统, 惠普电脑, 其它种类OS和厂商路径类似)\n\t打开并添加内容 https://{username}:{password}@github.com\n\t2.添加git config内容\n\t$git config --global credential.helper store\n\t执行此命令后，用户主目录下的.gitconfig文件会多了一项：[credential]\n\thelper = store\n\t重新git push就不需要用户名密码了\n\n## git提示“warning: LF will be replaced by CRLF”\n遇到此问题场景: 在windows上用git提交linux文件, 这是因为在文本处理中，CR（CarriageReturn），LF（LineFeed），CR/LF是不同操作系统上使用的换行符.\n\n * Dos和Windows平台: 使用回车（CR）和换行（LF）两个字符来结束一行，回车+换行(CR+LF)，即“\\r\\n”；\n * Mac 和 Linux平台: 只使用换行（LF）一个字符来结束一行，即“\\n”；\n所以我们平时在windows上编写文件的`回车符`应该确切来说叫做`回车换行符`.\n\n许多 Windows 上的编辑器会悄悄把行尾的换行（LF）字符转换成回车（CR）和换行（LF），或在用户按下 Enter 键时，插入回车（CR）和换行（LF）两个字符.  \n\n**影响：**\n * Unix/Mac系统下的文件在Windows里打开的话，所有文字会变成一行.  \n * 而Windows里的文件在Unix/Mac下打开的话，在每行的结尾可能会多出一个^M符号.  \n * Linux保存的文件在windows上用记事本看的话会出现黑点.  \n通过一定方式进行转换统一:\n\n\t在linux下，命令unix2dos 是把linux文件格式转换成windows文件格式\n\t命令dos2unix 是把windows格式转换成linux文件格式.\n**情况一:**\nGit 可以在你提交时自动地把回车(CR)和换行(LF)转换成换行(LF), 而在检出代码时把换行(LF)转换成回车(CR)和换行(LF).  \n如果是在 Windows 系统上，把它设置成 true，这样在检出代码时，换行会被转换成回车和换行.  \n\n\t#提交时转换为LF，检出时转换为CRLF\n\t$ git config --global core.autocrlf true\n**情况二:**\n可以把 core.autocrlf 设置成 input 来告诉 Git 在提交时把回车和换行转换成换行，检出时不转换, 这样在 Windows 上的检出文件中会保留回车和换行，而在 Mac 和 Linux 上，以及版本库中会保留换行.  \n\n\t#提交时转换为LF，检出时不转换\n\t$ git config --global core.autocrlf input\n**情况三:**\n如果你是 Windows 程序员，且正在开发仅运行在 Windows 上的项目，可以设置 false 取消此功能，把回车保留在版本库中.  \n\n\t#提交检出均不转换\n\t$ git config --global core.autocrlf false\n**你也可以在文件提交时进行safecrlf检查**\n\n\t#拒绝提交包含混合换行符的文件\n\tgit config --global core.safecrlf true   \n\t\n\t#允许提交包含混合换行符的文件\n\tgit config --global core.safecrlf false   \n\t\n\t#提交包含混合换行符的文件时给出警告\n\tgit config --global core.safecrlf warn\n**通俗解释**\n * git 的 Windows 客户端基本都会默认设置 core.autocrlf=true，设置core.autocrlf=true, 只要保持工作区都是纯 CRLF 文件，编辑器用 CRLF 换行，就不会出现警告了.  \n * Linux 最好不要设置 core.autocrlf，因为这个配置算是为 Windows 平台定制.  \n * Windows 上设置 core.autocrlf=false，仓库里也没有配置 .gitattributes，很容易引入 CRLF 或者混合换行符（Mixed Line Endings，一个文件里既有 LF 又有CRLF）到版本库，这样就可能产生各种奇怪的问题.  \n\n\n\n\n\n","slug":"technologies/git_problems_encountered","published":1,"date":"2020-08-12T16:05:48.493Z","updated":"2020-08-06T14:44:17.796Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmh3006uhohxesbv6e2l","content":"<h2 id=\"查看github-贡献最多和增长最快链接\"><a href=\"#查看github-贡献最多和增长最快链接\" class=\"headerlink\" title=\"查看github 贡献最多和增长最快链接:\"></a>查看github 贡献最多和增长最快链接:</h2><p><a href=\"https://octoverse.github.com/#fastest-growing-oss-projects-by-contributors\" target=\"_blank\" rel=\"noopener\">https://octoverse.github.com/#fastest-growing-oss-projects-by-contributors</a></p>\n<h2 id=\"解决git-bash-终端显示中文乱码\"><a href=\"#解决git-bash-终端显示中文乱码\" class=\"headerlink\" title=\"解决git bash 终端显示中文乱码\"></a>解决git bash 终端显示中文乱码</h2><pre><code>在git bash的界面中右击空白处，弹出菜单，选择选项-&gt;文本-&gt;本地Locale，设置为zh_CN，而旁边的字符集选框选为UTF-8\n上面方法在git add带中文文件时候会出现 &quot;add不到匹配的文件&quot; 或者 重启还是出现中文乱码,解决方法如下(亲测有效)：\n1. 选择选项-&gt;文本-&gt;本地Locale，设置为(Defalult)\n2. $git config --global core.quotepath false 再重启gitbash终端可解决</code></pre><h2 id=\"git-push免密登陆方法\"><a href=\"#git-push免密登陆方法\" class=\"headerlink\" title=\"git push免密登陆方法\"></a>git push免密登陆方法</h2><pre><code>创建文件 C:\\Users\\hp\\.git-credentials(Windows系统, 惠普电脑, 其它种类OS和厂商路径类似)\n打开并添加内容 https://{username}:{password}@github.com\n2.添加git config内容\n$git config --global credential.helper store\n执行此命令后，用户主目录下的.gitconfig文件会多了一项：[credential]\nhelper = store\n重新git push就不需要用户名密码了</code></pre><h2 id=\"git提示“warning-LF-will-be-replaced-by-CRLF”\"><a href=\"#git提示“warning-LF-will-be-replaced-by-CRLF”\" class=\"headerlink\" title=\"git提示“warning: LF will be replaced by CRLF”\"></a>git提示“warning: LF will be replaced by CRLF”</h2><p>遇到此问题场景: 在windows上用git提交linux文件, 这是因为在文本处理中，CR（CarriageReturn），LF（LineFeed），CR/LF是不同操作系统上使用的换行符.</p>\n<ul>\n<li>Dos和Windows平台: 使用回车（CR）和换行（LF）两个字符来结束一行，回车+换行(CR+LF)，即“\\r\\n”；</li>\n<li>Mac 和 Linux平台: 只使用换行（LF）一个字符来结束一行，即“\\n”；<br>所以我们平时在windows上编写文件的<code>回车符</code>应该确切来说叫做<code>回车换行符</code>.</li>\n</ul>\n<p>许多 Windows 上的编辑器会悄悄把行尾的换行（LF）字符转换成回车（CR）和换行（LF），或在用户按下 Enter 键时，插入回车（CR）和换行（LF）两个字符.  </p>\n<p><strong>影响：</strong></p>\n<ul>\n<li><p>Unix/Mac系统下的文件在Windows里打开的话，所有文字会变成一行.  </p>\n</li>\n<li><p>而Windows里的文件在Unix/Mac下打开的话，在每行的结尾可能会多出一个^M符号.  </p>\n</li>\n<li><p>Linux保存的文件在windows上用记事本看的话会出现黑点.<br>通过一定方式进行转换统一:</p>\n<p> 在linux下，命令unix2dos 是把linux文件格式转换成windows文件格式<br> 命令dos2unix 是把windows格式转换成linux文件格式.<br><strong>情况一:</strong><br>Git 可以在你提交时自动地把回车(CR)和换行(LF)转换成换行(LF), 而在检出代码时把换行(LF)转换成回车(CR)和换行(LF).<br>如果是在 Windows 系统上，把它设置成 true，这样在检出代码时，换行会被转换成回车和换行.  </p>\n<p> #提交时转换为LF，检出时转换为CRLF<br> $ git config –global core.autocrlf true<br><strong>情况二:</strong><br>可以把 core.autocrlf 设置成 input 来告诉 Git 在提交时把回车和换行转换成换行，检出时不转换, 这样在 Windows 上的检出文件中会保留回车和换行，而在 Mac 和 Linux 上，以及版本库中会保留换行.  </p>\n<p> #提交时转换为LF，检出时不转换<br> $ git config –global core.autocrlf input<br><strong>情况三:</strong><br>如果你是 Windows 程序员，且正在开发仅运行在 Windows 上的项目，可以设置 false 取消此功能，把回车保留在版本库中.  </p>\n<p> #提交检出均不转换<br> $ git config –global core.autocrlf false<br><strong>你也可以在文件提交时进行safecrlf检查</strong></p>\n<p> #拒绝提交包含混合换行符的文件<br> git config –global core.safecrlf true   </p>\n<p> #允许提交包含混合换行符的文件<br> git config –global core.safecrlf false   </p>\n<p> #提交包含混合换行符的文件时给出警告<br> git config –global core.safecrlf warn<br><strong>通俗解释</strong></p>\n</li>\n<li><p>git 的 Windows 客户端基本都会默认设置 core.autocrlf=true，设置core.autocrlf=true, 只要保持工作区都是纯 CRLF 文件，编辑器用 CRLF 换行，就不会出现警告了.  </p>\n</li>\n<li><p>Linux 最好不要设置 core.autocrlf，因为这个配置算是为 Windows 平台定制.  </p>\n</li>\n<li><p>Windows 上设置 core.autocrlf=false，仓库里也没有配置 .gitattributes，很容易引入 CRLF 或者混合换行符（Mixed Line Endings，一个文件里既有 LF 又有CRLF）到版本库，这样就可能产生各种奇怪的问题.  </p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"查看github-贡献最多和增长最快链接\"><a href=\"#查看github-贡献最多和增长最快链接\" class=\"headerlink\" title=\"查看github 贡献最多和增长最快链接:\"></a>查看github 贡献最多和增长最快链接:</h2><p><a href=\"https://octoverse.github.com/#fastest-growing-oss-projects-by-contributors\" target=\"_blank\" rel=\"noopener\">https://octoverse.github.com/#fastest-growing-oss-projects-by-contributors</a></p>\n<h2 id=\"解决git-bash-终端显示中文乱码\"><a href=\"#解决git-bash-终端显示中文乱码\" class=\"headerlink\" title=\"解决git bash 终端显示中文乱码\"></a>解决git bash 终端显示中文乱码</h2><pre><code>在git bash的界面中右击空白处，弹出菜单，选择选项-&gt;文本-&gt;本地Locale，设置为zh_CN，而旁边的字符集选框选为UTF-8\n上面方法在git add带中文文件时候会出现 &quot;add不到匹配的文件&quot; 或者 重启还是出现中文乱码,解决方法如下(亲测有效)：\n1. 选择选项-&gt;文本-&gt;本地Locale，设置为(Defalult)\n2. $git config --global core.quotepath false 再重启gitbash终端可解决</code></pre><h2 id=\"git-push免密登陆方法\"><a href=\"#git-push免密登陆方法\" class=\"headerlink\" title=\"git push免密登陆方法\"></a>git push免密登陆方法</h2><pre><code>创建文件 C:\\Users\\hp\\.git-credentials(Windows系统, 惠普电脑, 其它种类OS和厂商路径类似)\n打开并添加内容 https://{username}:{password}@github.com\n2.添加git config内容\n$git config --global credential.helper store\n执行此命令后，用户主目录下的.gitconfig文件会多了一项：[credential]\nhelper = store\n重新git push就不需要用户名密码了</code></pre><h2 id=\"git提示“warning-LF-will-be-replaced-by-CRLF”\"><a href=\"#git提示“warning-LF-will-be-replaced-by-CRLF”\" class=\"headerlink\" title=\"git提示“warning: LF will be replaced by CRLF”\"></a>git提示“warning: LF will be replaced by CRLF”</h2><p>遇到此问题场景: 在windows上用git提交linux文件, 这是因为在文本处理中，CR（CarriageReturn），LF（LineFeed），CR/LF是不同操作系统上使用的换行符.</p>\n<ul>\n<li>Dos和Windows平台: 使用回车（CR）和换行（LF）两个字符来结束一行，回车+换行(CR+LF)，即“\\r\\n”；</li>\n<li>Mac 和 Linux平台: 只使用换行（LF）一个字符来结束一行，即“\\n”；<br>所以我们平时在windows上编写文件的<code>回车符</code>应该确切来说叫做<code>回车换行符</code>.</li>\n</ul>\n<p>许多 Windows 上的编辑器会悄悄把行尾的换行（LF）字符转换成回车（CR）和换行（LF），或在用户按下 Enter 键时，插入回车（CR）和换行（LF）两个字符.  </p>\n<p><strong>影响：</strong></p>\n<ul>\n<li><p>Unix/Mac系统下的文件在Windows里打开的话，所有文字会变成一行.  </p>\n</li>\n<li><p>而Windows里的文件在Unix/Mac下打开的话，在每行的结尾可能会多出一个^M符号.  </p>\n</li>\n<li><p>Linux保存的文件在windows上用记事本看的话会出现黑点.<br>通过一定方式进行转换统一:</p>\n<p> 在linux下，命令unix2dos 是把linux文件格式转换成windows文件格式<br> 命令dos2unix 是把windows格式转换成linux文件格式.<br><strong>情况一:</strong><br>Git 可以在你提交时自动地把回车(CR)和换行(LF)转换成换行(LF), 而在检出代码时把换行(LF)转换成回车(CR)和换行(LF).<br>如果是在 Windows 系统上，把它设置成 true，这样在检出代码时，换行会被转换成回车和换行.  </p>\n<p> #提交时转换为LF，检出时转换为CRLF<br> $ git config –global core.autocrlf true<br><strong>情况二:</strong><br>可以把 core.autocrlf 设置成 input 来告诉 Git 在提交时把回车和换行转换成换行，检出时不转换, 这样在 Windows 上的检出文件中会保留回车和换行，而在 Mac 和 Linux 上，以及版本库中会保留换行.  </p>\n<p> #提交时转换为LF，检出时不转换<br> $ git config –global core.autocrlf input<br><strong>情况三:</strong><br>如果你是 Windows 程序员，且正在开发仅运行在 Windows 上的项目，可以设置 false 取消此功能，把回车保留在版本库中.  </p>\n<p> #提交检出均不转换<br> $ git config –global core.autocrlf false<br><strong>你也可以在文件提交时进行safecrlf检查</strong></p>\n<p> #拒绝提交包含混合换行符的文件<br> git config –global core.safecrlf true   </p>\n<p> #允许提交包含混合换行符的文件<br> git config –global core.safecrlf false   </p>\n<p> #提交包含混合换行符的文件时给出警告<br> git config –global core.safecrlf warn<br><strong>通俗解释</strong></p>\n</li>\n<li><p>git 的 Windows 客户端基本都会默认设置 core.autocrlf=true，设置core.autocrlf=true, 只要保持工作区都是纯 CRLF 文件，编辑器用 CRLF 换行，就不会出现警告了.  </p>\n</li>\n<li><p>Linux 最好不要设置 core.autocrlf，因为这个配置算是为 Windows 平台定制.  </p>\n</li>\n<li><p>Windows 上设置 core.autocrlf=false，仓库里也没有配置 .gitattributes，很容易引入 CRLF 或者混合换行符（Mixed Line Endings，一个文件里既有 LF 又有CRLF）到版本库，这样就可能产生各种奇怪的问题.  </p>\n</li>\n</ul>\n"},{"title":"U盘分区之后如何恢复","_content":"\n1. 插入U盘。\n2. 按windows键，搜索cmd 选择以管理员身份运行。\n3. 输入diskpart,按enter。\n![](1.png)\n4. 输入list disk,按enter。\n![](2.png)\n5. 之后会看到\ndisk 0\ndisk 1\n如果你给你电脑磁盘分过区的话可能还有disk 2  、  disk 3等\n![](3.png)\n6. 输入select disk X(X代表磁盘后面的数字0、1，可磁盘的大小来判断数字是多少，一般是1),按enter\n![](4.png)\n7. 输入clean，按enter\n![](5.png)\n8. \n以上完成之后，到“磁盘管理”选择U盘，新建简单卷，并重命名你的U盘\n\n打开“磁盘管理”方法:\n任务栏\"Search\"输入\"disk management\", 选择运行\"Create and format hard disk partitions\"\n\"新建简单卷\"方法:\n打开磁盘管理后，选中U盘所在Disk 如Disk1， 右击鼠标，选中第一个新建卷，默认下一步，之后需要格式化, \"Volume lable\"输入盘volume名字如OS就可以了.\n\n","source":"_posts/windows/U盘分区之后如何恢复.md","raw":"---\ntitle: U盘分区之后如何恢复\ncategories:\n- windows\n---\n\n1. 插入U盘。\n2. 按windows键，搜索cmd 选择以管理员身份运行。\n3. 输入diskpart,按enter。\n![](1.png)\n4. 输入list disk,按enter。\n![](2.png)\n5. 之后会看到\ndisk 0\ndisk 1\n如果你给你电脑磁盘分过区的话可能还有disk 2  、  disk 3等\n![](3.png)\n6. 输入select disk X(X代表磁盘后面的数字0、1，可磁盘的大小来判断数字是多少，一般是1),按enter\n![](4.png)\n7. 输入clean，按enter\n![](5.png)\n8. \n以上完成之后，到“磁盘管理”选择U盘，新建简单卷，并重命名你的U盘\n\n打开“磁盘管理”方法:\n任务栏\"Search\"输入\"disk management\", 选择运行\"Create and format hard disk partitions\"\n\"新建简单卷\"方法:\n打开磁盘管理后，选中U盘所在Disk 如Disk1， 右击鼠标，选中第一个新建卷，默认下一步，之后需要格式化, \"Volume lable\"输入盘volume名字如OS就可以了.\n\n","slug":"windows/U盘分区之后如何恢复","published":1,"date":"2020-08-12T16:05:49.322Z","updated":"2020-03-16T11:17:47.431Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmh4006yhohx0hr06vgc","content":"<ol>\n<li>插入U盘。</li>\n<li>按windows键，搜索cmd 选择以管理员身份运行。</li>\n<li>输入diskpart,按enter。<br><img src=\"1.png\" alt=\"\"></li>\n<li>输入list disk,按enter。<br><img src=\"2.png\" alt=\"\"></li>\n<li>之后会看到<br>disk 0<br>disk 1<br>如果你给你电脑磁盘分过区的话可能还有disk 2  、  disk 3等<br><img src=\"3.png\" alt=\"\"></li>\n<li>输入select disk X(X代表磁盘后面的数字0、1，可磁盘的大小来判断数字是多少，一般是1),按enter<br><img src=\"4.png\" alt=\"\"></li>\n<li>输入clean，按enter<br><img src=\"5.png\" alt=\"\"></li>\n<li>以上完成之后，到“磁盘管理”选择U盘，新建简单卷，并重命名你的U盘</li>\n</ol>\n<p>打开“磁盘管理”方法:<br>任务栏”Search”输入”disk management”, 选择运行”Create and format hard disk partitions”<br>“新建简单卷”方法:<br>打开磁盘管理后，选中U盘所在Disk 如Disk1， 右击鼠标，选中第一个新建卷，默认下一步，之后需要格式化, “Volume lable”输入盘volume名字如OS就可以了.</p>\n","site":{"data":{}},"excerpt":"","more":"<ol>\n<li>插入U盘。</li>\n<li>按windows键，搜索cmd 选择以管理员身份运行。</li>\n<li>输入diskpart,按enter。<br><img src=\"1.png\" alt=\"\"></li>\n<li>输入list disk,按enter。<br><img src=\"2.png\" alt=\"\"></li>\n<li>之后会看到<br>disk 0<br>disk 1<br>如果你给你电脑磁盘分过区的话可能还有disk 2  、  disk 3等<br><img src=\"3.png\" alt=\"\"></li>\n<li>输入select disk X(X代表磁盘后面的数字0、1，可磁盘的大小来判断数字是多少，一般是1),按enter<br><img src=\"4.png\" alt=\"\"></li>\n<li>输入clean，按enter<br><img src=\"5.png\" alt=\"\"></li>\n<li>以上完成之后，到“磁盘管理”选择U盘，新建简单卷，并重命名你的U盘</li>\n</ol>\n<p>打开“磁盘管理”方法:<br>任务栏”Search”输入”disk management”, 选择运行”Create and format hard disk partitions”<br>“新建简单卷”方法:<br>打开磁盘管理后，选中U盘所在Disk 如Disk1， 右击鼠标，选中第一个新建卷，默认下一步，之后需要格式化, “Volume lable”输入盘volume名字如OS就可以了.</p>\n"},{"title":"Windows10_VScode远程连接linux编辑调试","_content":"\n1. 查看Windows10 是否已安装或开启ssh-client，默认Windows10自带的有\nWindows 10 : 设置 -> 应用(APPS) -> 应用和功能(APP & features) -> 管理可选功能(Manage app execution aliases)\n![](1.png)\n\n没有的话需要点击如图上面的Add a feature，install一下.\n\n2. Centos\n\t1. //安装 yum install -y openssl openssh-server \n\t//重启sshd服务 systemctl restart sshd.service \n\t//自动启动 systemctl enable sshd\n\t2. $cd ~/.ssh/\n\t此目录如果没有authorized_keys文件需要touch新建一个，里面需要存放Window10的公匙(id_rsa.pub,另外id_rsa是Window10的密匙).\n3. 安装VS code， 安装扩展(Extensions)\"Remote-Developoment\"插件，会自动安装其他的Remote插件，其中会包含Remote-SSH\n安装完成出现如下选项\n![](2.png)\n\n添加config文件\n![](3.png)\n\n添加linux主机\n\tHost 后面接空格，名字随便写，显示在左边\n\tHostName 主机IP\n\tUser root\n![](4.png)\n\n右击要连接的linux，选择在当前页面或新打开Vscode\n![](5.png)\n\n输入linux登录密码，这个过程可能需要输入密码多次…\n![](6.png)\n观察VScode右下角等待连接成功\n![](7.png)\n\n最后点击Open folder就可以了\n\n后边遇到vscode一直连不上linux情况\n解决方法一:\n\t$df -hl 查看linux ~/ 等主目录是否已占满，删除一些文件释放空间后再连接就可以了\n\n解决方法二:\n\t是查看linux /tmp 临时文件发现占满了，全部删掉，再用windows上得VS code连接就可以了\n\t原因是vscode连接linxu会自动在linux的/tmp生成一些文件\n\n## Linux 重装系统后再用windowsshangVScode连接报如下错误:\n\tCould not establish connection to \"IP\". The process tried to write to a nonexistent pipe.\n原因是windows与linux连接成功后会在C:\\Users\\用户名\\.ssh\\known_hosts添加对应Linux的密匙信息，把它相关的内容删掉.\n\n## VScode 连接Linux Waiting for /root/.vscode-server/bin/***/vscode-scp-done.flag and vscode-server.tar.gz to exist\n解决方法如下链接:\n![参考链接](https://blog.csdn.net/Ding19950107/article/details/103713556)\n","source":"_posts/windows/Windows10_VScode远程连接linux编辑调试.md","raw":"---\ntitle: Windows10_VScode远程连接linux编辑调试\ncategories:\n- windows\n---\n\n1. 查看Windows10 是否已安装或开启ssh-client，默认Windows10自带的有\nWindows 10 : 设置 -> 应用(APPS) -> 应用和功能(APP & features) -> 管理可选功能(Manage app execution aliases)\n![](1.png)\n\n没有的话需要点击如图上面的Add a feature，install一下.\n\n2. Centos\n\t1. //安装 yum install -y openssl openssh-server \n\t//重启sshd服务 systemctl restart sshd.service \n\t//自动启动 systemctl enable sshd\n\t2. $cd ~/.ssh/\n\t此目录如果没有authorized_keys文件需要touch新建一个，里面需要存放Window10的公匙(id_rsa.pub,另外id_rsa是Window10的密匙).\n3. 安装VS code， 安装扩展(Extensions)\"Remote-Developoment\"插件，会自动安装其他的Remote插件，其中会包含Remote-SSH\n安装完成出现如下选项\n![](2.png)\n\n添加config文件\n![](3.png)\n\n添加linux主机\n\tHost 后面接空格，名字随便写，显示在左边\n\tHostName 主机IP\n\tUser root\n![](4.png)\n\n右击要连接的linux，选择在当前页面或新打开Vscode\n![](5.png)\n\n输入linux登录密码，这个过程可能需要输入密码多次…\n![](6.png)\n观察VScode右下角等待连接成功\n![](7.png)\n\n最后点击Open folder就可以了\n\n后边遇到vscode一直连不上linux情况\n解决方法一:\n\t$df -hl 查看linux ~/ 等主目录是否已占满，删除一些文件释放空间后再连接就可以了\n\n解决方法二:\n\t是查看linux /tmp 临时文件发现占满了，全部删掉，再用windows上得VS code连接就可以了\n\t原因是vscode连接linxu会自动在linux的/tmp生成一些文件\n\n## Linux 重装系统后再用windowsshangVScode连接报如下错误:\n\tCould not establish connection to \"IP\". The process tried to write to a nonexistent pipe.\n原因是windows与linux连接成功后会在C:\\Users\\用户名\\.ssh\\known_hosts添加对应Linux的密匙信息，把它相关的内容删掉.\n\n## VScode 连接Linux Waiting for /root/.vscode-server/bin/***/vscode-scp-done.flag and vscode-server.tar.gz to exist\n解决方法如下链接:\n![参考链接](https://blog.csdn.net/Ding19950107/article/details/103713556)\n","slug":"windows/Windows10_VScode远程连接linux编辑调试","published":1,"date":"2020-08-12T16:05:49.334Z","updated":"2020-04-07T12:31:34.325Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmhz008ghohxfmf65p41","content":"<ol>\n<li>查看Windows10 是否已安装或开启ssh-client，默认Windows10自带的有<br>Windows 10 : 设置 -&gt; 应用(APPS) -&gt; 应用和功能(APP &amp; features) -&gt; 管理可选功能(Manage app execution aliases)<br><img src=\"1.png\" alt=\"\"></li>\n</ol>\n<p>没有的话需要点击如图上面的Add a feature，install一下.</p>\n<ol start=\"2\">\n<li>Centos<ol>\n<li>//安装 yum install -y openssl openssh-server<br>//重启sshd服务 systemctl restart sshd.service<br>//自动启动 systemctl enable sshd</li>\n<li>$cd ~/.ssh/<br>此目录如果没有authorized_keys文件需要touch新建一个，里面需要存放Window10的公匙(id_rsa.pub,另外id_rsa是Window10的密匙).</li>\n</ol>\n</li>\n<li>安装VS code， 安装扩展(Extensions)”Remote-Developoment”插件，会自动安装其他的Remote插件，其中会包含Remote-SSH<br>安装完成出现如下选项<br><img src=\"2.png\" alt=\"\"></li>\n</ol>\n<p>添加config文件<br><img src=\"3.png\" alt=\"\"></p>\n<p>添加linux主机<br>    Host 后面接空格，名字随便写，显示在左边<br>    HostName 主机IP<br>    User root<br><img src=\"4.png\" alt=\"\"></p>\n<p>右击要连接的linux，选择在当前页面或新打开Vscode<br><img src=\"5.png\" alt=\"\"></p>\n<p>输入linux登录密码，这个过程可能需要输入密码多次…<br><img src=\"6.png\" alt=\"\"><br>观察VScode右下角等待连接成功<br><img src=\"7.png\" alt=\"\"></p>\n<p>最后点击Open folder就可以了</p>\n<p>后边遇到vscode一直连不上linux情况<br>解决方法一:<br>    $df -hl 查看linux ~/ 等主目录是否已占满，删除一些文件释放空间后再连接就可以了</p>\n<p>解决方法二:<br>    是查看linux /tmp 临时文件发现占满了，全部删掉，再用windows上得VS code连接就可以了<br>    原因是vscode连接linxu会自动在linux的/tmp生成一些文件</p>\n<h2 id=\"Linux-重装系统后再用windowsshangVScode连接报如下错误\"><a href=\"#Linux-重装系统后再用windowsshangVScode连接报如下错误\" class=\"headerlink\" title=\"Linux 重装系统后再用windowsshangVScode连接报如下错误:\"></a>Linux 重装系统后再用windowsshangVScode连接报如下错误:</h2><pre><code>Could not establish connection to &quot;IP&quot;. The process tried to write to a nonexistent pipe.</code></pre><p>原因是windows与linux连接成功后会在C:\\Users\\用户名.ssh\\known_hosts添加对应Linux的密匙信息，把它相关的内容删掉.</p>\n<h2 id=\"VScode-连接Linux-Waiting-for-root-vscode-server-bin-vscode-scp-done-flag-and-vscode-server-tar-gz-to-exist\"><a href=\"#VScode-连接Linux-Waiting-for-root-vscode-server-bin-vscode-scp-done-flag-and-vscode-server-tar-gz-to-exist\" class=\"headerlink\" title=\"VScode 连接Linux Waiting for /root/.vscode-server/bin/***/vscode-scp-done.flag and vscode-server.tar.gz to exist\"></a>VScode 连接Linux Waiting for /root/.vscode-server/bin/***/vscode-scp-done.flag and vscode-server.tar.gz to exist</h2><p>解决方法如下链接:<br><img src=\"https://blog.csdn.net/Ding19950107/article/details/103713556\" alt=\"参考链接\"></p>\n","site":{"data":{}},"excerpt":"","more":"<ol>\n<li>查看Windows10 是否已安装或开启ssh-client，默认Windows10自带的有<br>Windows 10 : 设置 -&gt; 应用(APPS) -&gt; 应用和功能(APP &amp; features) -&gt; 管理可选功能(Manage app execution aliases)<br><img src=\"1.png\" alt=\"\"></li>\n</ol>\n<p>没有的话需要点击如图上面的Add a feature，install一下.</p>\n<ol start=\"2\">\n<li>Centos<ol>\n<li>//安装 yum install -y openssl openssh-server<br>//重启sshd服务 systemctl restart sshd.service<br>//自动启动 systemctl enable sshd</li>\n<li>$cd ~/.ssh/<br>此目录如果没有authorized_keys文件需要touch新建一个，里面需要存放Window10的公匙(id_rsa.pub,另外id_rsa是Window10的密匙).</li>\n</ol>\n</li>\n<li>安装VS code， 安装扩展(Extensions)”Remote-Developoment”插件，会自动安装其他的Remote插件，其中会包含Remote-SSH<br>安装完成出现如下选项<br><img src=\"2.png\" alt=\"\"></li>\n</ol>\n<p>添加config文件<br><img src=\"3.png\" alt=\"\"></p>\n<p>添加linux主机<br>    Host 后面接空格，名字随便写，显示在左边<br>    HostName 主机IP<br>    User root<br><img src=\"4.png\" alt=\"\"></p>\n<p>右击要连接的linux，选择在当前页面或新打开Vscode<br><img src=\"5.png\" alt=\"\"></p>\n<p>输入linux登录密码，这个过程可能需要输入密码多次…<br><img src=\"6.png\" alt=\"\"><br>观察VScode右下角等待连接成功<br><img src=\"7.png\" alt=\"\"></p>\n<p>最后点击Open folder就可以了</p>\n<p>后边遇到vscode一直连不上linux情况<br>解决方法一:<br>    $df -hl 查看linux ~/ 等主目录是否已占满，删除一些文件释放空间后再连接就可以了</p>\n<p>解决方法二:<br>    是查看linux /tmp 临时文件发现占满了，全部删掉，再用windows上得VS code连接就可以了<br>    原因是vscode连接linxu会自动在linux的/tmp生成一些文件</p>\n<h2 id=\"Linux-重装系统后再用windowsshangVScode连接报如下错误\"><a href=\"#Linux-重装系统后再用windowsshangVScode连接报如下错误\" class=\"headerlink\" title=\"Linux 重装系统后再用windowsshangVScode连接报如下错误:\"></a>Linux 重装系统后再用windowsshangVScode连接报如下错误:</h2><pre><code>Could not establish connection to &quot;IP&quot;. The process tried to write to a nonexistent pipe.</code></pre><p>原因是windows与linux连接成功后会在C:\\Users\\用户名.ssh\\known_hosts添加对应Linux的密匙信息，把它相关的内容删掉.</p>\n<h2 id=\"VScode-连接Linux-Waiting-for-root-vscode-server-bin-vscode-scp-done-flag-and-vscode-server-tar-gz-to-exist\"><a href=\"#VScode-连接Linux-Waiting-for-root-vscode-server-bin-vscode-scp-done-flag-and-vscode-server-tar-gz-to-exist\" class=\"headerlink\" title=\"VScode 连接Linux Waiting for /root/.vscode-server/bin/***/vscode-scp-done.flag and vscode-server.tar.gz to exist\"></a>VScode 连接Linux Waiting for /root/.vscode-server/bin/***/vscode-scp-done.flag and vscode-server.tar.gz to exist</h2><p>解决方法如下链接:<br><img src=\"https://blog.csdn.net/Ding19950107/article/details/103713556\" alt=\"参考链接\"></p>\n"},{"title":"go language","_content":"\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\nGo环境安装:\ngo: https://golang.google.cn/dl/\n\t go1.14.1.linux-amd64.tar.gz\t\n\t tar -C /usr/local -xzf go1.12.17.linux-amd64.tar.gz\n\t vim ~/.bashrc 添加 export PATH=$PATH:/usr/local/go/bin\n\t source ~/.bashrc\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n### 1. go环境安装\nGo 语言支持以下系统：\n- Linux\n- FreeBSD\n- Mac OS X（也称为 Darwin）\n- Windows\n安装包下载地址为：https://golang.org/dl/。\n如果打不开可以使用这个地址：https://golang.google.cn/dl/。\nWindows下.msi 文件会安装在 c:\\Go 目录下。你可以将 c:\\Go\\bin 目录添加到 Path 环境变量中。添加后你需要重启命令窗口才能生效。\n\ntest.go 文件代码：\n``` c\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n   fmt.Println(\"Hello, World!\")\n}\n```\n运行命令\n```\n第一种方式:可以使用 go run 命令\nC:\\Go_WorkSpace>go run test.go\n\tHello, World!\n\n第二种方式:还可以使用 go build 命令来生成二进制文件\n$ C:\\Go_WorkSpace>go build hello.go \n$ dir\nhello    hello.go\n$ hello.exe\nHello, World!\n\n```\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n### 2. 语言结构\nGo 语言的基础组成有以下几个部分：\n+ 包声明\n+ 引入包\n+ 函数\n+ 变量\n+ 语句 & 表达式\n+ 注释\n``` c\n// 当标识符（包括常量、变量、类型、函数名、结构字段等等）以一个大写字母开头，如：Group1, 标识符的对象就可以被外部包的代码所使用（客户端程序需要先导入这个包）,（像面向对象语言中的 public）\n// 标识符如果以小写字母开头，则对包外是不可见的，但是他们在整个包的内部是可见并且可用的（像面向对象语言中的 protected ）\n\t\t\t\t\t// 文件名与包名没有直接关系，不一定要将文件名与包名定成同一个。\n\t\t\t\t\t// 同一个文件夹下的文件只能有一个包名，否则编译报错。\npackage main\t\t// 定义了包名。你必须在源文件中非注释的第一行指明这个文件属于哪个包\n\t\t\t\t\t// package main表示一个可独立执行的程序，每个 Go 应用程序都包含一个名为 main 的包。\n\nimport \"fmt\"\t\t// 告诉 Go 编译器这个程序需要使用 fmt 包, fmt 包实现了格式化 IO（输入/输出）的函数\n\nfunc main() {\t\t// main 函数是每一个可执行程序所必须包含的, \"{\" 不能单独放在一行\n   /* 这是我的第一个简单的程序 */\n   fmt.Println(\"Hello, World!\")\t\t// fmt.Print(\"hello, world\\n\") 可以得到相同的结果\n}\n```\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※","source":"_posts/language/go/goLang.md","raw":"---\ntitle: go language\ntags: \ncategories:\n- language\n- go\n---\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\nGo环境安装:\ngo: https://golang.google.cn/dl/\n\t go1.14.1.linux-amd64.tar.gz\t\n\t tar -C /usr/local -xzf go1.12.17.linux-amd64.tar.gz\n\t vim ~/.bashrc 添加 export PATH=$PATH:/usr/local/go/bin\n\t source ~/.bashrc\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n### 1. go环境安装\nGo 语言支持以下系统：\n- Linux\n- FreeBSD\n- Mac OS X（也称为 Darwin）\n- Windows\n安装包下载地址为：https://golang.org/dl/。\n如果打不开可以使用这个地址：https://golang.google.cn/dl/。\nWindows下.msi 文件会安装在 c:\\Go 目录下。你可以将 c:\\Go\\bin 目录添加到 Path 环境变量中。添加后你需要重启命令窗口才能生效。\n\ntest.go 文件代码：\n``` c\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n   fmt.Println(\"Hello, World!\")\n}\n```\n运行命令\n```\n第一种方式:可以使用 go run 命令\nC:\\Go_WorkSpace>go run test.go\n\tHello, World!\n\n第二种方式:还可以使用 go build 命令来生成二进制文件\n$ C:\\Go_WorkSpace>go build hello.go \n$ dir\nhello    hello.go\n$ hello.exe\nHello, World!\n\n```\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n### 2. 语言结构\nGo 语言的基础组成有以下几个部分：\n+ 包声明\n+ 引入包\n+ 函数\n+ 变量\n+ 语句 & 表达式\n+ 注释\n``` c\n// 当标识符（包括常量、变量、类型、函数名、结构字段等等）以一个大写字母开头，如：Group1, 标识符的对象就可以被外部包的代码所使用（客户端程序需要先导入这个包）,（像面向对象语言中的 public）\n// 标识符如果以小写字母开头，则对包外是不可见的，但是他们在整个包的内部是可见并且可用的（像面向对象语言中的 protected ）\n\t\t\t\t\t// 文件名与包名没有直接关系，不一定要将文件名与包名定成同一个。\n\t\t\t\t\t// 同一个文件夹下的文件只能有一个包名，否则编译报错。\npackage main\t\t// 定义了包名。你必须在源文件中非注释的第一行指明这个文件属于哪个包\n\t\t\t\t\t// package main表示一个可独立执行的程序，每个 Go 应用程序都包含一个名为 main 的包。\n\nimport \"fmt\"\t\t// 告诉 Go 编译器这个程序需要使用 fmt 包, fmt 包实现了格式化 IO（输入/输出）的函数\n\nfunc main() {\t\t// main 函数是每一个可执行程序所必须包含的, \"{\" 不能单独放在一行\n   /* 这是我的第一个简单的程序 */\n   fmt.Println(\"Hello, World!\")\t\t// fmt.Print(\"hello, world\\n\") 可以得到相同的结果\n}\n```\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※","slug":"language/go/goLang","published":1,"date":"2020-08-12T16:05:45.445Z","updated":"2020-04-29T15:25:58.131Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hml2008ihohx0xbpcheg","content":"<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※<br>Go环境安装:<br>go: <a href=\"https://golang.google.cn/dl/\" target=\"_blank\" rel=\"noopener\">https://golang.google.cn/dl/</a><br>     go1.14.1.linux-amd64.tar.gz<br>     tar -C /usr/local -xzf go1.12.17.linux-amd64.tar.gz<br>     vim ~/.bashrc 添加 export PATH=$PATH:/usr/local/go/bin<br>     source ~/.bashrc</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<h3 id=\"1-go环境安装\"><a href=\"#1-go环境安装\" class=\"headerlink\" title=\"1. go环境安装\"></a>1. go环境安装</h3><p>Go 语言支持以下系统：</p>\n<ul>\n<li>Linux</li>\n<li>FreeBSD</li>\n<li>Mac OS X（也称为 Darwin）</li>\n<li>Windows<br>安装包下载地址为：<a href=\"https://golang.org/dl/。\" target=\"_blank\" rel=\"noopener\">https://golang.org/dl/。</a><br>如果打不开可以使用这个地址：<a href=\"https://golang.google.cn/dl/。\" target=\"_blank\" rel=\"noopener\">https://golang.google.cn/dl/。</a><br>Windows下.msi 文件会安装在 c:\\Go 目录下。你可以将 c:\\Go\\bin 目录添加到 Path 环境变量中。添加后你需要重启命令窗口才能生效。</li>\n</ul>\n<p>test.go 文件代码：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package main</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> <span class=\"string\">\"fmt\"</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">func <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">   fmt.Println(<span class=\"string\">\"Hello, World!\"</span>)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>运行命令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">第一种方式:可以使用 go run 命令</span><br><span class=\"line\">C:\\Go_WorkSpace&gt;go run test.go</span><br><span class=\"line\">\tHello, World!</span><br><span class=\"line\"></span><br><span class=\"line\">第二种方式:还可以使用 go build 命令来生成二进制文件</span><br><span class=\"line\">$ C:\\Go_WorkSpace&gt;go build hello.go </span><br><span class=\"line\">$ dir</span><br><span class=\"line\">hello    hello.go</span><br><span class=\"line\">$ hello.exe</span><br><span class=\"line\">Hello, World!</span><br></pre></td></tr></table></figure>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<h3 id=\"2-语言结构\"><a href=\"#2-语言结构\" class=\"headerlink\" title=\"2. 语言结构\"></a>2. 语言结构</h3><p>Go 语言的基础组成有以下几个部分：</p>\n<ul>\n<li>包声明</li>\n<li>引入包</li>\n<li>函数</li>\n<li>变量</li>\n<li>语句 &amp; 表达式</li>\n<li>注释<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 当标识符（包括常量、变量、类型、函数名、结构字段等等）以一个大写字母开头，如：Group1, 标识符的对象就可以被外部包的代码所使用（客户端程序需要先导入这个包）,（像面向对象语言中的 public）</span></span><br><span class=\"line\"><span class=\"comment\">// 标识符如果以小写字母开头，则对包外是不可见的，但是他们在整个包的内部是可见并且可用的（像面向对象语言中的 protected ）</span></span><br><span class=\"line\">\t\t\t\t\t<span class=\"comment\">// 文件名与包名没有直接关系，不一定要将文件名与包名定成同一个。</span></span><br><span class=\"line\">\t\t\t\t\t<span class=\"comment\">// 同一个文件夹下的文件只能有一个包名，否则编译报错。</span></span><br><span class=\"line\">package main\t\t<span class=\"comment\">// 定义了包名。你必须在源文件中非注释的第一行指明这个文件属于哪个包</span></span><br><span class=\"line\">\t\t\t\t\t<span class=\"comment\">// package main表示一个可独立执行的程序，每个 Go 应用程序都包含一个名为 main 的包。</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> <span class=\"string\">\"fmt\"</span>\t\t<span class=\"comment\">// 告诉 Go 编译器这个程序需要使用 fmt 包, fmt 包实现了格式化 IO（输入/输出）的函数</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">func <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;\t\t<span class=\"comment\">// main 函数是每一个可执行程序所必须包含的, \"&#123;\" 不能单独放在一行</span></span><br><span class=\"line\">   <span class=\"comment\">/* 这是我的第一个简单的程序 */</span></span><br><span class=\"line\">   fmt.Println(<span class=\"string\">\"Hello, World!\"</span>)\t\t<span class=\"comment\">// fmt.Print(\"hello, world\\n\") 可以得到相同的结果</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n</li>\n</ul>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n","site":{"data":{}},"excerpt":"","more":"<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※<br>Go环境安装:<br>go: <a href=\"https://golang.google.cn/dl/\" target=\"_blank\" rel=\"noopener\">https://golang.google.cn/dl/</a><br>     go1.14.1.linux-amd64.tar.gz<br>     tar -C /usr/local -xzf go1.12.17.linux-amd64.tar.gz<br>     vim ~/.bashrc 添加 export PATH=$PATH:/usr/local/go/bin<br>     source ~/.bashrc</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<h3 id=\"1-go环境安装\"><a href=\"#1-go环境安装\" class=\"headerlink\" title=\"1. go环境安装\"></a>1. go环境安装</h3><p>Go 语言支持以下系统：</p>\n<ul>\n<li>Linux</li>\n<li>FreeBSD</li>\n<li>Mac OS X（也称为 Darwin）</li>\n<li>Windows<br>安装包下载地址为：<a href=\"https://golang.org/dl/。\" target=\"_blank\" rel=\"noopener\">https://golang.org/dl/。</a><br>如果打不开可以使用这个地址：<a href=\"https://golang.google.cn/dl/。\" target=\"_blank\" rel=\"noopener\">https://golang.google.cn/dl/。</a><br>Windows下.msi 文件会安装在 c:\\Go 目录下。你可以将 c:\\Go\\bin 目录添加到 Path 环境变量中。添加后你需要重启命令窗口才能生效。</li>\n</ul>\n<p>test.go 文件代码：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package main</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> <span class=\"string\">\"fmt\"</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">func <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">   fmt.Println(<span class=\"string\">\"Hello, World!\"</span>)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>运行命令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">第一种方式:可以使用 go run 命令</span><br><span class=\"line\">C:\\Go_WorkSpace&gt;go run test.go</span><br><span class=\"line\">\tHello, World!</span><br><span class=\"line\"></span><br><span class=\"line\">第二种方式:还可以使用 go build 命令来生成二进制文件</span><br><span class=\"line\">$ C:\\Go_WorkSpace&gt;go build hello.go </span><br><span class=\"line\">$ dir</span><br><span class=\"line\">hello    hello.go</span><br><span class=\"line\">$ hello.exe</span><br><span class=\"line\">Hello, World!</span><br></pre></td></tr></table></figure>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<h3 id=\"2-语言结构\"><a href=\"#2-语言结构\" class=\"headerlink\" title=\"2. 语言结构\"></a>2. 语言结构</h3><p>Go 语言的基础组成有以下几个部分：</p>\n<ul>\n<li>包声明</li>\n<li>引入包</li>\n<li>函数</li>\n<li>变量</li>\n<li>语句 &amp; 表达式</li>\n<li>注释<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 当标识符（包括常量、变量、类型、函数名、结构字段等等）以一个大写字母开头，如：Group1, 标识符的对象就可以被外部包的代码所使用（客户端程序需要先导入这个包）,（像面向对象语言中的 public）</span></span><br><span class=\"line\"><span class=\"comment\">// 标识符如果以小写字母开头，则对包外是不可见的，但是他们在整个包的内部是可见并且可用的（像面向对象语言中的 protected ）</span></span><br><span class=\"line\">\t\t\t\t\t<span class=\"comment\">// 文件名与包名没有直接关系，不一定要将文件名与包名定成同一个。</span></span><br><span class=\"line\">\t\t\t\t\t<span class=\"comment\">// 同一个文件夹下的文件只能有一个包名，否则编译报错。</span></span><br><span class=\"line\">package main\t\t<span class=\"comment\">// 定义了包名。你必须在源文件中非注释的第一行指明这个文件属于哪个包</span></span><br><span class=\"line\">\t\t\t\t\t<span class=\"comment\">// package main表示一个可独立执行的程序，每个 Go 应用程序都包含一个名为 main 的包。</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> <span class=\"string\">\"fmt\"</span>\t\t<span class=\"comment\">// 告诉 Go 编译器这个程序需要使用 fmt 包, fmt 包实现了格式化 IO（输入/输出）的函数</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">func <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;\t\t<span class=\"comment\">// main 函数是每一个可执行程序所必须包含的, \"&#123;\" 不能单独放在一行</span></span><br><span class=\"line\">   <span class=\"comment\">/* 这是我的第一个简单的程序 */</span></span><br><span class=\"line\">   fmt.Println(<span class=\"string\">\"Hello, World!\"</span>)\t\t<span class=\"comment\">// fmt.Print(\"hello, world\\n\") 可以得到相同的结果</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n</li>\n</ul>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n"},{"title":"gdb","_content":"\ngcc main.c a.c b.c -o app -g\n-g:会保留函数名和变量名\n\n例如一个程序名为prog 参数为 -l a -C abc\n则，运行gcc/g++ -g  prog.c/cpp -o prog\n就可以用gdb调试程序prog\n#gdb prog\n进入gdb调试界面\n输入参数命令set args 后面加上程序所要用的参数，注意，不再带有程序名，直接加参数，如：\nset args -l a -C abc\n回车后输入\nr\n即可开\n\n\nstart\t 开始运行程序，只运行main函数里的第一行.\nrun\t运行程序直到断点或程序末尾\nc\t继续运行程序\nn\t运行一行代码\ns\t进入函数内部运行\n\t\n\n\n(gdb) show listsize\t默认显示10行源代码\n(gdb) set listsize=20\t设置默认显示20行源代码\n(gdb) l 30\t显示源代码第30行附近上下文\n(gdb) l functionname\t显示函数名的源代码\n(gdb) l insert_sort.c:15\t显示源代码所引用的insert_sort.c代码文件中第15行上下文\n(gdb) l insert_sort.c:functioname\t显示源代码所引用的insert_sort.c代码文件中的function函数的代码\n(gdb) l main.c:main\n\n\n\ngdb中的中文注释会乱码\n\nb 行号\t添加断点，//注释和\"{\", \"}\"等都是无效注释\nb 函数名\nb 文件名:行号\nb 文件名：函数名\ni(info) b\t查看设置过的所有断点\n\tNum: 断点编号\n\tEnb: enable 断点现在是否可用，y就是可用, n无效程序跑起来不会停到这个断点\n\tAddress: 断点在内存中的位置\n\tWhat: 如in functionname at main.c:12\n\t        在某个function->main.c文件->第12行\ni(info) display\t查看display的变量行号\n\tNum Enb Expression\n\t1        y      i\n\t2        y      array[i]\nd 编号\t删除断点编号\n\t如：d 1;  d 2 3;  d 4-5\ndis 行号\t设置指定断点无效，Enb为n\nena 行号\t设置指定断点有效，Enb为y\n设置条件断点\nb 行号 if i == 10\t在第num行打断点，当i == 10候停下来\n\t……\n\t9    for(int i = 0; i < 20; i++)\n\t10      printf(\"XXX\");\n\t……\np i\t查看i变量的值\nptype i\t查看变量类型\nptype array\ttype = int\n\ttype = int[31]\ndisplay array[i]\t设置变量的自动显示\ndisplay i\t每循环到断点处就输出array[i]的值\nundisplay Num\tNub为i display看到的Enm值，取消变量的自动显示\n\nset var 变量名=值\t设置变量值\n\nuntil\t跳出for循环，此循环执行完就退出，循环里的断点去掉或设置无效\nfinish\t跳出函数，函数里的断点去掉或设置无效\nq\t退出gdb调试\n\n","source":"_posts/language/c/gdb.md","raw":"---\ntitle: gdb\ntags: \ncategories: \n- language\n- c\n---\n\ngcc main.c a.c b.c -o app -g\n-g:会保留函数名和变量名\n\n例如一个程序名为prog 参数为 -l a -C abc\n则，运行gcc/g++ -g  prog.c/cpp -o prog\n就可以用gdb调试程序prog\n#gdb prog\n进入gdb调试界面\n输入参数命令set args 后面加上程序所要用的参数，注意，不再带有程序名，直接加参数，如：\nset args -l a -C abc\n回车后输入\nr\n即可开\n\n\nstart\t 开始运行程序，只运行main函数里的第一行.\nrun\t运行程序直到断点或程序末尾\nc\t继续运行程序\nn\t运行一行代码\ns\t进入函数内部运行\n\t\n\n\n(gdb) show listsize\t默认显示10行源代码\n(gdb) set listsize=20\t设置默认显示20行源代码\n(gdb) l 30\t显示源代码第30行附近上下文\n(gdb) l functionname\t显示函数名的源代码\n(gdb) l insert_sort.c:15\t显示源代码所引用的insert_sort.c代码文件中第15行上下文\n(gdb) l insert_sort.c:functioname\t显示源代码所引用的insert_sort.c代码文件中的function函数的代码\n(gdb) l main.c:main\n\n\n\ngdb中的中文注释会乱码\n\nb 行号\t添加断点，//注释和\"{\", \"}\"等都是无效注释\nb 函数名\nb 文件名:行号\nb 文件名：函数名\ni(info) b\t查看设置过的所有断点\n\tNum: 断点编号\n\tEnb: enable 断点现在是否可用，y就是可用, n无效程序跑起来不会停到这个断点\n\tAddress: 断点在内存中的位置\n\tWhat: 如in functionname at main.c:12\n\t        在某个function->main.c文件->第12行\ni(info) display\t查看display的变量行号\n\tNum Enb Expression\n\t1        y      i\n\t2        y      array[i]\nd 编号\t删除断点编号\n\t如：d 1;  d 2 3;  d 4-5\ndis 行号\t设置指定断点无效，Enb为n\nena 行号\t设置指定断点有效，Enb为y\n设置条件断点\nb 行号 if i == 10\t在第num行打断点，当i == 10候停下来\n\t……\n\t9    for(int i = 0; i < 20; i++)\n\t10      printf(\"XXX\");\n\t……\np i\t查看i变量的值\nptype i\t查看变量类型\nptype array\ttype = int\n\ttype = int[31]\ndisplay array[i]\t设置变量的自动显示\ndisplay i\t每循环到断点处就输出array[i]的值\nundisplay Num\tNub为i display看到的Enm值，取消变量的自动显示\n\nset var 变量名=值\t设置变量值\n\nuntil\t跳出for循环，此循环执行完就退出，循环里的断点去掉或设置无效\nfinish\t跳出函数，函数里的断点去掉或设置无效\nq\t退出gdb调试\n\n","slug":"language/c/gdb","published":1,"date":"2020-08-12T16:05:45.355Z","updated":"2020-08-03T13:03:56.512Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hml2008jhohxcueu4twc","content":"<p>gcc main.c a.c b.c -o app -g<br>-g:会保留函数名和变量名</p>\n<p>例如一个程序名为prog 参数为 -l a -C abc<br>则，运行gcc/g++ -g  prog.c/cpp -o prog<br>就可以用gdb调试程序prog<br>#gdb prog<br>进入gdb调试界面<br>输入参数命令set args 后面加上程序所要用的参数，注意，不再带有程序名，直接加参数，如：<br>set args -l a -C abc<br>回车后输入<br>r<br>即可开</p>\n<p>start     开始运行程序，只运行main函数里的第一行.<br>run    运行程序直到断点或程序末尾<br>c    继续运行程序<br>n    运行一行代码<br>s    进入函数内部运行</p>\n<p>(gdb) show listsize    默认显示10行源代码<br>(gdb) set listsize=20    设置默认显示20行源代码<br>(gdb) l 30    显示源代码第30行附近上下文<br>(gdb) l functionname    显示函数名的源代码<br>(gdb) l insert_sort.c:15    显示源代码所引用的insert_sort.c代码文件中第15行上下文<br>(gdb) l insert_sort.c:functioname    显示源代码所引用的insert_sort.c代码文件中的function函数的代码<br>(gdb) l main.c:main</p>\n<p>gdb中的中文注释会乱码</p>\n<p>b 行号    添加断点，//注释和”{“, “}”等都是无效注释<br>b 函数名<br>b 文件名:行号<br>b 文件名：函数名<br>i(info) b    查看设置过的所有断点<br>    Num: 断点编号<br>    Enb: enable 断点现在是否可用，y就是可用, n无效程序跑起来不会停到这个断点<br>    Address: 断点在内存中的位置<br>    What: 如in functionname at main.c:12<br>            在某个function-&gt;main.c文件-&gt;第12行<br>i(info) display    查看display的变量行号<br>    Num Enb Expression<br>    1        y      i<br>    2        y      array[i]<br>d 编号    删除断点编号<br>    如：d 1;  d 2 3;  d 4-5<br>dis 行号    设置指定断点无效，Enb为n<br>ena 行号    设置指定断点有效，Enb为y<br>设置条件断点<br>b 行号 if i == 10    在第num行打断点，当i == 10候停下来<br>    ……<br>    9    for(int i = 0; i &lt; 20; i++)<br>    10      printf(“XXX”);<br>    ……<br>p i    查看i变量的值<br>ptype i    查看变量类型<br>ptype array    type = int<br>    type = int[31]<br>display array[i]    设置变量的自动显示<br>display i    每循环到断点处就输出array[i]的值<br>undisplay Num    Nub为i display看到的Enm值，取消变量的自动显示</p>\n<p>set var 变量名=值    设置变量值</p>\n<p>until    跳出for循环，此循环执行完就退出，循环里的断点去掉或设置无效<br>finish    跳出函数，函数里的断点去掉或设置无效<br>q    退出gdb调试</p>\n","site":{"data":{}},"excerpt":"","more":"<p>gcc main.c a.c b.c -o app -g<br>-g:会保留函数名和变量名</p>\n<p>例如一个程序名为prog 参数为 -l a -C abc<br>则，运行gcc/g++ -g  prog.c/cpp -o prog<br>就可以用gdb调试程序prog<br>#gdb prog<br>进入gdb调试界面<br>输入参数命令set args 后面加上程序所要用的参数，注意，不再带有程序名，直接加参数，如：<br>set args -l a -C abc<br>回车后输入<br>r<br>即可开</p>\n<p>start     开始运行程序，只运行main函数里的第一行.<br>run    运行程序直到断点或程序末尾<br>c    继续运行程序<br>n    运行一行代码<br>s    进入函数内部运行</p>\n<p>(gdb) show listsize    默认显示10行源代码<br>(gdb) set listsize=20    设置默认显示20行源代码<br>(gdb) l 30    显示源代码第30行附近上下文<br>(gdb) l functionname    显示函数名的源代码<br>(gdb) l insert_sort.c:15    显示源代码所引用的insert_sort.c代码文件中第15行上下文<br>(gdb) l insert_sort.c:functioname    显示源代码所引用的insert_sort.c代码文件中的function函数的代码<br>(gdb) l main.c:main</p>\n<p>gdb中的中文注释会乱码</p>\n<p>b 行号    添加断点，//注释和”{“, “}”等都是无效注释<br>b 函数名<br>b 文件名:行号<br>b 文件名：函数名<br>i(info) b    查看设置过的所有断点<br>    Num: 断点编号<br>    Enb: enable 断点现在是否可用，y就是可用, n无效程序跑起来不会停到这个断点<br>    Address: 断点在内存中的位置<br>    What: 如in functionname at main.c:12<br>            在某个function-&gt;main.c文件-&gt;第12行<br>i(info) display    查看display的变量行号<br>    Num Enb Expression<br>    1        y      i<br>    2        y      array[i]<br>d 编号    删除断点编号<br>    如：d 1;  d 2 3;  d 4-5<br>dis 行号    设置指定断点无效，Enb为n<br>ena 行号    设置指定断点有效，Enb为y<br>设置条件断点<br>b 行号 if i == 10    在第num行打断点，当i == 10候停下来<br>    ……<br>    9    for(int i = 0; i &lt; 20; i++)<br>    10      printf(“XXX”);<br>    ……<br>p i    查看i变量的值<br>ptype i    查看变量类型<br>ptype array    type = int<br>    type = int[31]<br>display array[i]    设置变量的自动显示<br>display i    每循环到断点处就输出array[i]的值<br>undisplay Num    Nub为i display看到的Enm值，取消变量的自动显示</p>\n<p>set var 变量名=值    设置变量值</p>\n<p>until    跳出for循环，此循环执行完就退出，循环里的断点去掉或设置无效<br>finish    跳出函数，函数里的断点去掉或设置无效<br>q    退出gdb调试</p>\n"},{"title":"docker 02 private hub & journal","_content":"\n## Docker 引擎\n目前 Docker 支持 Docker 引 擎、 Docker Hub 、 Docker Cloud 等多种服务 。\n * Docker 引擎：包括支持在桌面系统或云平台安装 Docker，以及为企业提供简单安全弹性的容器集群编排和管理；\n * DockerHub ：官方提供的云托管服务，可以提供公有或私有的镜像仓库；\n * DockerCloud ：官方提供的容器云服务，可以完成容器的部署与管理，可以完整地支持容器化项目，还有 CI 、 CD 功能 \n用户可以通过如下命令检查自己的内核版本详细信息 ：\n\n\n\t$ uname -a\n\t$ cat /proc/version\n\n## 查看日志\n如果服务工作不正常，可以通过查看 Docker 服务的日志信息来确定问题，例如\n在 RedHat 系统上的系统运行日志文件为 \n\n\t/var/log/messages\n在 Ubuntu 或 CentOS 系统上可以执行命令\n\n\t$ journalctl -u docker.service \n\t$ journalctl -xe\n\t$ journalctl -f -n 10 -u docker.service //滚屏输出10条服务docker.service的log信息\n\n## 访问Docker 仓库 Repository\n分公共仓库和私有仓库\n### 公共仓库\nDocker Hub 是 Docker 官方提供的最大的公共镜像仓库, docker search 命令来查找官方仓库中的镜像\n\n\t$ docker search centos\n\t$ docker pull centos\n\t$ docker images 命令来查看下载到本地的镜像\n国内不少云服务商都提供了 Docker 镜像市场包括腾讯云 、 网易云、阿里云等\n下载第三方服务商如 腾讯云 提供的镜像格式为 index.tenxcloud.com/<namespace>/<repository>:<tag>\n\n\t$ docker pull index.tenxcloud.com/docker_library/node:latest\n下载后，可以更新镜像的标签，与官方标签保持一致，方便使用：\n\n\t$ docker tag index.tenxcloud.com/docker_library/node:latest node:latest\n\n\n## 搭建本地私有仓库\n### 使用 registry 镜像创建私有仓库\n> $ docker search registry --limit=5\t// Hub official website 查找registry镜像\n\n\troot@alpha:/home/test# docker run -d -p 5000:5000 registry:2\n\tUnable to find image 'registry:2' locally\n\t2: Pulling from library/registry\n\t486039affc0a: Downloading [==========>                                        ]  475.1kB/2.207MB\n\tba51a3b098e6: Download complete\n\t8bb4c43d6c8e: Downloading [==>                                                ]  363.8kB/6.824MB\n\t6f5f453e5f2d: Download complete\n\t42bc10b72f42: Download complete\n\n\t$ docker run -d -p 5000:5000 registry:2\n\n默认情况下，仓库会被创建在容器的 /var/lib/registry 目录下, 容器退出后, 存储的数据也会丢失.\n因此实际开发环境中私有仓库registry存储路径必须绑定到主机目录.\n可以通过 －v 参数来将镜像文件存放在本地的指定路径 。 例如下面的例子将上传的镜像放到/opt/data/registry 目录：\n\n\t$ docker run -d -p 5000:5000 -v /opt/data/registry:/var/lib/registry --restart=always --name registry registry:2 \n如果创建容器时没有添加自动重启参数 --restart=always ，导致的后果是：当 Docker 服务重启时，容器未能自动启动。\n第一种添加修改该参数(实测有效): \n\n\t$ docker container update --restart=always 容器名字或容器ID\n第二种修改该参数；\n\n\t首先停止容器，不然无法修改配置文件(实测中不用停止容器也修改了, 但是docker服务重启后容器没有重启)\n\t配置文件路径为：/var/lib/docker/containers/容器ID(容器ID通过 $ docker ps | grep 容器Name 进行查看)\n\t在该目录下找到一个文件 hostconfig.json ，找到该文件中关键字 RestartPolicy\n\t修改前配置：\"RestartPolicy\":{\"Name\":\"no\",\"MaximumRetryCount\":0}\n\t修改后配置：\"RestartPolicy\":{\"Name\":\"always\",\"MaximumRetryCount\":0}\n\t最后启动容器。\n\n\t另外也可以查看容器绑定存储文件路径\n\t\"Binds\":[\"/opt/data/registry1:/var/lib/registry\"]\n\t没有绑定到主机目录的容器此hostconfig.json文件内容为 \"Binds\":null\n\n此时， 在本地将启动一个私有仓库服务，监听端口为 5000 \n\n\t root@alpha:~# docker ps\n\t CONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS                    NAMES\n\t e0bb400f0ba6        registry:2             \"/entrypoint.sh /etc…\"   11 hours ago        Up 11 hours         0.0.0.0:5000->5000/tcp   registry\n\n\n### 从私有仓库上传下载镜像 & 查看\n> 应为docker客户端发送的是https请求，从私有仓库下载镜像时候需要用http请求协议，因此在其它机器上要上传或下载10.239.140.186:5000(me office)机器上的image时候会出问题\n> 需要在其它要下载10.239.140.186机器上image的机器比如10.239.85.243(solu02)上添加并修改如下文件：\nmaster和worker节点都需要添加启动仓库registry:2所在的机器IP和开放的端口，内容和步骤如下:\n\n\t$ vim /etc/docker/daemon.json\t// 没有的话需要新建这个json文件, 然后添加如下内容, 表示信任10.239.140.186机器5000端口提供的服务\n\t\t{\n\t\t\t\"insecure-registries\":[\"10.239.140.186:5000\"]\n\t\t}\n\t\n\t$ systemctl daemon-reload\t\t\t// 重新加载daemon\n\t$ systemctl restart docker\t\t\t// 重启docker\n\t$ systemctl enable docker.service\t// 开机默认启动\n\t如果是在运行registry容器的机器上重启docker service之后一定要查看registry容器是否重新启动.\n\t$ docker run -d -p 5000:5000 registry:2\n\n> 在solu02机器上从hub公共image库下载个image如ubuntu:latest\n\n\t$ dcoker pull ubuntu\t\t\t\t// 默认下载latest\n\t$ docker images\n\t➜  ~ docker images\n\tREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\n\tubuntu              latest              1d622ef86b13        5 days ago          73.9MB\n\n### 上传image\n给要上传的image重新打个标签\n\n\t$ docker tag ubuntu:latest 10.239.140.186:5000/solu02_utunbu:latest\n使用 docker push 上传标记的镜像：\n\n\t$ docker push 10.239.140.186:5000/solu02_utunbu:latest  // 要和 \"/etc/docker/daemon.json中配置的insecure-registries的值一致\"\n\t或者 $ docker push master-node:5000/solu02_utunbu:latest\n\t➜  ~ docker push 10.239.140.186:5000/solu02_utunbu:latest\n\tThe push refers to repository [10.239.140.186:5000/solu02_utunbu]\n\t8891751e0a17: Pushed\n\t2a19bd70fcd4: Pushed\n\t9e53fd489559: Pushed\n\t7789f1a3d4e9: Pushed\n\tlatest: digest: sha256:5747316366b8cc9e3021cd7286f42b2d6d81e3d743e2ab571f55bcd5df788cc8 size: 1152\n\t➜  ~\n\n### 查看image\n在仓库主机10.239.140.186机器上使用curl 查看仓库 10.239.140.186:5000(me office) 中的镜像：\n是用10.239.140.186访问, 还是用在/etc/hosts中将主机IP:10.239.140.186映射为master-node访问,\n主要是跟 /etc/docker/daemon-reload 设置的 insecure-registries 值一致.\n\n\t$ curl http://10.239.140.186:5000/v2/_catalog\n\t或 $ curl http://master-node:5000/v2/_catalog\n\t {\"repositories\":[\"solu02_utunbu\",\"test_ubuntu\",\"test_ubuntu1\",\"docker.io/nginx\"]}\n查看镜像和相应tag:\n\n\t$ curl -XGET http://master-node:5000/v2/{image_name}/tags/list\n\t$ curl 10.239.140.186:5000/v2/docker.io/nginx/tags/list\n\t {\"name\":\"docker.io/nginx\",\"tags\":[\"alpine\"]}\n\n浏览器输入如下地址查看\nhttp://localhost:5000/v2/_catalog \t\t\t\t\t// 查看所有images\nhttp://localhost:5000/v2/docker.io/nginx/tags/list\t// 查看所有images的tags\n\n### 下载image\n在solu02(10.239.85.243)机器上下载10.239.140.186私有仓库里的image:\n\n\t$ docker pull 10.239.140.186:5000/test_ubuntu\n拉去指定tag的image\n\n\t$ docker pull 10.239.140.186:5000/docker.io/nginx:alpine\n\n### DNS 解析IP\n用master-node等代替registry运行所在的主机的IP\n\n\t$ vim /etc/hosts\n\t 10.239.140.186 master-node\n\t 10.239.141.101 node-1\n\n\t$ vim /etc/docker/daemon.json\n\t { \"insecure-registries\": [\"master-node:5000\"] }\n\n## 配置docker的HTTP_PROXY, HTTPS_PROXY, NO_PROXY\n\n第一种: 放到一个文件里\n\n\t$ vim /etc/systemd/system/docker.service.d/http-proxy.conf\n\t [Service]\n\t Environment=\"HTTP_PROXY=http://proxy:913\" \"NO_PROXY=localhost,127.0.0.1,master-node\"\n第二种: 将docker的HTTP_PROXY, HTTPS_PROXY, NO_PROXY放到三个文件\n新建三个文件, 并添加类似的如下信息\n\n\t$ touch /etc/systemd/system/docker.service.d/no-proxy.conf\n\t [Service]\n\t Environment=\"NO_PROXY=10.67.108.211,10.67.109.142,10.67.109.147,10.67.109.144,hci-node01,hci-node02,hci-node03,hci-node04\"\n\t$ touch /etc/systemd/system/docker.service.d/http-proxy.conf\n\t [Service]\n\t Environment=\"HTTP_PROXY=http://proxy:913/\"\n\t$ touch /etc/systemd/system/docker.service.d/https-proxy.conf\n\t [Service]\n\t Environment=\"HTTPS_PROXY=http://proxy:913/\"\n\n\n修改完上面信息之后重启docker\n\n\t$ systemctl daemon-reload\n\t$ systemctl restart docker\n\n\t$ docker tag docker.io/nginx:alpine master-node:5000/docker.io/nginx:alpine\n\t$ docker push master-node:5000/docker.io/nginx:alpine\n\t$ curl 10.239.140.186:5000/v2/_catalog\n\t或者\n\t$ curl master-node:5000/v2/_catalog\n\t遇到访问不了如下面显示信息时候, 原因是通过curl方式访问master-node主机时仍通过linux设置的公司的proxy访问\n\t<HTML>\n\t<HEAD><TITLE>Redirection</TITLE></HEAD>\n\t<BODY><H1>Redirect</H1></BODY>\n\t</HTML>\n\t设置linux的NO_PROXY环境变量, 使curl访问 master-node 时不通过公司的proxy\n\t$ export NO_PROXY=master-node\n\t$ curl master-node:5000/v2/_catalog\n\t{\"repositories\":[\"docker.io/nginx\",\"hello-world\",\"hello-world1\",\"hello-world11\"]}\n\n\n\n","source":"_posts/technologies/docker/docker_step_02.md","raw":"---\ntitle: docker 02 private hub & journal\ntags: \ncategories:\n- technologies\n- docker\n---\n\n## Docker 引擎\n目前 Docker 支持 Docker 引 擎、 Docker Hub 、 Docker Cloud 等多种服务 。\n * Docker 引擎：包括支持在桌面系统或云平台安装 Docker，以及为企业提供简单安全弹性的容器集群编排和管理；\n * DockerHub ：官方提供的云托管服务，可以提供公有或私有的镜像仓库；\n * DockerCloud ：官方提供的容器云服务，可以完成容器的部署与管理，可以完整地支持容器化项目，还有 CI 、 CD 功能 \n用户可以通过如下命令检查自己的内核版本详细信息 ：\n\n\n\t$ uname -a\n\t$ cat /proc/version\n\n## 查看日志\n如果服务工作不正常，可以通过查看 Docker 服务的日志信息来确定问题，例如\n在 RedHat 系统上的系统运行日志文件为 \n\n\t/var/log/messages\n在 Ubuntu 或 CentOS 系统上可以执行命令\n\n\t$ journalctl -u docker.service \n\t$ journalctl -xe\n\t$ journalctl -f -n 10 -u docker.service //滚屏输出10条服务docker.service的log信息\n\n## 访问Docker 仓库 Repository\n分公共仓库和私有仓库\n### 公共仓库\nDocker Hub 是 Docker 官方提供的最大的公共镜像仓库, docker search 命令来查找官方仓库中的镜像\n\n\t$ docker search centos\n\t$ docker pull centos\n\t$ docker images 命令来查看下载到本地的镜像\n国内不少云服务商都提供了 Docker 镜像市场包括腾讯云 、 网易云、阿里云等\n下载第三方服务商如 腾讯云 提供的镜像格式为 index.tenxcloud.com/<namespace>/<repository>:<tag>\n\n\t$ docker pull index.tenxcloud.com/docker_library/node:latest\n下载后，可以更新镜像的标签，与官方标签保持一致，方便使用：\n\n\t$ docker tag index.tenxcloud.com/docker_library/node:latest node:latest\n\n\n## 搭建本地私有仓库\n### 使用 registry 镜像创建私有仓库\n> $ docker search registry --limit=5\t// Hub official website 查找registry镜像\n\n\troot@alpha:/home/test# docker run -d -p 5000:5000 registry:2\n\tUnable to find image 'registry:2' locally\n\t2: Pulling from library/registry\n\t486039affc0a: Downloading [==========>                                        ]  475.1kB/2.207MB\n\tba51a3b098e6: Download complete\n\t8bb4c43d6c8e: Downloading [==>                                                ]  363.8kB/6.824MB\n\t6f5f453e5f2d: Download complete\n\t42bc10b72f42: Download complete\n\n\t$ docker run -d -p 5000:5000 registry:2\n\n默认情况下，仓库会被创建在容器的 /var/lib/registry 目录下, 容器退出后, 存储的数据也会丢失.\n因此实际开发环境中私有仓库registry存储路径必须绑定到主机目录.\n可以通过 －v 参数来将镜像文件存放在本地的指定路径 。 例如下面的例子将上传的镜像放到/opt/data/registry 目录：\n\n\t$ docker run -d -p 5000:5000 -v /opt/data/registry:/var/lib/registry --restart=always --name registry registry:2 \n如果创建容器时没有添加自动重启参数 --restart=always ，导致的后果是：当 Docker 服务重启时，容器未能自动启动。\n第一种添加修改该参数(实测有效): \n\n\t$ docker container update --restart=always 容器名字或容器ID\n第二种修改该参数；\n\n\t首先停止容器，不然无法修改配置文件(实测中不用停止容器也修改了, 但是docker服务重启后容器没有重启)\n\t配置文件路径为：/var/lib/docker/containers/容器ID(容器ID通过 $ docker ps | grep 容器Name 进行查看)\n\t在该目录下找到一个文件 hostconfig.json ，找到该文件中关键字 RestartPolicy\n\t修改前配置：\"RestartPolicy\":{\"Name\":\"no\",\"MaximumRetryCount\":0}\n\t修改后配置：\"RestartPolicy\":{\"Name\":\"always\",\"MaximumRetryCount\":0}\n\t最后启动容器。\n\n\t另外也可以查看容器绑定存储文件路径\n\t\"Binds\":[\"/opt/data/registry1:/var/lib/registry\"]\n\t没有绑定到主机目录的容器此hostconfig.json文件内容为 \"Binds\":null\n\n此时， 在本地将启动一个私有仓库服务，监听端口为 5000 \n\n\t root@alpha:~# docker ps\n\t CONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS                    NAMES\n\t e0bb400f0ba6        registry:2             \"/entrypoint.sh /etc…\"   11 hours ago        Up 11 hours         0.0.0.0:5000->5000/tcp   registry\n\n\n### 从私有仓库上传下载镜像 & 查看\n> 应为docker客户端发送的是https请求，从私有仓库下载镜像时候需要用http请求协议，因此在其它机器上要上传或下载10.239.140.186:5000(me office)机器上的image时候会出问题\n> 需要在其它要下载10.239.140.186机器上image的机器比如10.239.85.243(solu02)上添加并修改如下文件：\nmaster和worker节点都需要添加启动仓库registry:2所在的机器IP和开放的端口，内容和步骤如下:\n\n\t$ vim /etc/docker/daemon.json\t// 没有的话需要新建这个json文件, 然后添加如下内容, 表示信任10.239.140.186机器5000端口提供的服务\n\t\t{\n\t\t\t\"insecure-registries\":[\"10.239.140.186:5000\"]\n\t\t}\n\t\n\t$ systemctl daemon-reload\t\t\t// 重新加载daemon\n\t$ systemctl restart docker\t\t\t// 重启docker\n\t$ systemctl enable docker.service\t// 开机默认启动\n\t如果是在运行registry容器的机器上重启docker service之后一定要查看registry容器是否重新启动.\n\t$ docker run -d -p 5000:5000 registry:2\n\n> 在solu02机器上从hub公共image库下载个image如ubuntu:latest\n\n\t$ dcoker pull ubuntu\t\t\t\t// 默认下载latest\n\t$ docker images\n\t➜  ~ docker images\n\tREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\n\tubuntu              latest              1d622ef86b13        5 days ago          73.9MB\n\n### 上传image\n给要上传的image重新打个标签\n\n\t$ docker tag ubuntu:latest 10.239.140.186:5000/solu02_utunbu:latest\n使用 docker push 上传标记的镜像：\n\n\t$ docker push 10.239.140.186:5000/solu02_utunbu:latest  // 要和 \"/etc/docker/daemon.json中配置的insecure-registries的值一致\"\n\t或者 $ docker push master-node:5000/solu02_utunbu:latest\n\t➜  ~ docker push 10.239.140.186:5000/solu02_utunbu:latest\n\tThe push refers to repository [10.239.140.186:5000/solu02_utunbu]\n\t8891751e0a17: Pushed\n\t2a19bd70fcd4: Pushed\n\t9e53fd489559: Pushed\n\t7789f1a3d4e9: Pushed\n\tlatest: digest: sha256:5747316366b8cc9e3021cd7286f42b2d6d81e3d743e2ab571f55bcd5df788cc8 size: 1152\n\t➜  ~\n\n### 查看image\n在仓库主机10.239.140.186机器上使用curl 查看仓库 10.239.140.186:5000(me office) 中的镜像：\n是用10.239.140.186访问, 还是用在/etc/hosts中将主机IP:10.239.140.186映射为master-node访问,\n主要是跟 /etc/docker/daemon-reload 设置的 insecure-registries 值一致.\n\n\t$ curl http://10.239.140.186:5000/v2/_catalog\n\t或 $ curl http://master-node:5000/v2/_catalog\n\t {\"repositories\":[\"solu02_utunbu\",\"test_ubuntu\",\"test_ubuntu1\",\"docker.io/nginx\"]}\n查看镜像和相应tag:\n\n\t$ curl -XGET http://master-node:5000/v2/{image_name}/tags/list\n\t$ curl 10.239.140.186:5000/v2/docker.io/nginx/tags/list\n\t {\"name\":\"docker.io/nginx\",\"tags\":[\"alpine\"]}\n\n浏览器输入如下地址查看\nhttp://localhost:5000/v2/_catalog \t\t\t\t\t// 查看所有images\nhttp://localhost:5000/v2/docker.io/nginx/tags/list\t// 查看所有images的tags\n\n### 下载image\n在solu02(10.239.85.243)机器上下载10.239.140.186私有仓库里的image:\n\n\t$ docker pull 10.239.140.186:5000/test_ubuntu\n拉去指定tag的image\n\n\t$ docker pull 10.239.140.186:5000/docker.io/nginx:alpine\n\n### DNS 解析IP\n用master-node等代替registry运行所在的主机的IP\n\n\t$ vim /etc/hosts\n\t 10.239.140.186 master-node\n\t 10.239.141.101 node-1\n\n\t$ vim /etc/docker/daemon.json\n\t { \"insecure-registries\": [\"master-node:5000\"] }\n\n## 配置docker的HTTP_PROXY, HTTPS_PROXY, NO_PROXY\n\n第一种: 放到一个文件里\n\n\t$ vim /etc/systemd/system/docker.service.d/http-proxy.conf\n\t [Service]\n\t Environment=\"HTTP_PROXY=http://proxy:913\" \"NO_PROXY=localhost,127.0.0.1,master-node\"\n第二种: 将docker的HTTP_PROXY, HTTPS_PROXY, NO_PROXY放到三个文件\n新建三个文件, 并添加类似的如下信息\n\n\t$ touch /etc/systemd/system/docker.service.d/no-proxy.conf\n\t [Service]\n\t Environment=\"NO_PROXY=10.67.108.211,10.67.109.142,10.67.109.147,10.67.109.144,hci-node01,hci-node02,hci-node03,hci-node04\"\n\t$ touch /etc/systemd/system/docker.service.d/http-proxy.conf\n\t [Service]\n\t Environment=\"HTTP_PROXY=http://proxy:913/\"\n\t$ touch /etc/systemd/system/docker.service.d/https-proxy.conf\n\t [Service]\n\t Environment=\"HTTPS_PROXY=http://proxy:913/\"\n\n\n修改完上面信息之后重启docker\n\n\t$ systemctl daemon-reload\n\t$ systemctl restart docker\n\n\t$ docker tag docker.io/nginx:alpine master-node:5000/docker.io/nginx:alpine\n\t$ docker push master-node:5000/docker.io/nginx:alpine\n\t$ curl 10.239.140.186:5000/v2/_catalog\n\t或者\n\t$ curl master-node:5000/v2/_catalog\n\t遇到访问不了如下面显示信息时候, 原因是通过curl方式访问master-node主机时仍通过linux设置的公司的proxy访问\n\t<HTML>\n\t<HEAD><TITLE>Redirection</TITLE></HEAD>\n\t<BODY><H1>Redirect</H1></BODY>\n\t</HTML>\n\t设置linux的NO_PROXY环境变量, 使curl访问 master-node 时不通过公司的proxy\n\t$ export NO_PROXY=master-node\n\t$ curl master-node:5000/v2/_catalog\n\t{\"repositories\":[\"docker.io/nginx\",\"hello-world\",\"hello-world1\",\"hello-world11\"]}\n\n\n\n","slug":"technologies/docker/docker_step_02","published":1,"date":"2020-08-12T16:05:48.526Z","updated":"2020-07-13T11:49:45.134Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hml3008lhohx0bz46jo7","content":"<h2 id=\"Docker-引擎\"><a href=\"#Docker-引擎\" class=\"headerlink\" title=\"Docker 引擎\"></a>Docker 引擎</h2><p>目前 Docker 支持 Docker 引 擎、 Docker Hub 、 Docker Cloud 等多种服务 。</p>\n<ul>\n<li>Docker 引擎：包括支持在桌面系统或云平台安装 Docker，以及为企业提供简单安全弹性的容器集群编排和管理；</li>\n<li>DockerHub ：官方提供的云托管服务，可以提供公有或私有的镜像仓库；</li>\n<li>DockerCloud ：官方提供的容器云服务，可以完成容器的部署与管理，可以完整地支持容器化项目，还有 CI 、 CD 功能<br>用户可以通过如下命令检查自己的内核版本详细信息 ：</li>\n</ul>\n<pre><code>$ uname -a\n$ cat /proc/version</code></pre><h2 id=\"查看日志\"><a href=\"#查看日志\" class=\"headerlink\" title=\"查看日志\"></a>查看日志</h2><p>如果服务工作不正常，可以通过查看 Docker 服务的日志信息来确定问题，例如<br>在 RedHat 系统上的系统运行日志文件为 </p>\n<pre><code>/var/log/messages</code></pre><p>在 Ubuntu 或 CentOS 系统上可以执行命令</p>\n<pre><code>$ journalctl -u docker.service \n$ journalctl -xe\n$ journalctl -f -n 10 -u docker.service //滚屏输出10条服务docker.service的log信息</code></pre><h2 id=\"访问Docker-仓库-Repository\"><a href=\"#访问Docker-仓库-Repository\" class=\"headerlink\" title=\"访问Docker 仓库 Repository\"></a>访问Docker 仓库 Repository</h2><p>分公共仓库和私有仓库</p>\n<h3 id=\"公共仓库\"><a href=\"#公共仓库\" class=\"headerlink\" title=\"公共仓库\"></a>公共仓库</h3><p>Docker Hub 是 Docker 官方提供的最大的公共镜像仓库, docker search 命令来查找官方仓库中的镜像</p>\n<pre><code>$ docker search centos\n$ docker pull centos\n$ docker images 命令来查看下载到本地的镜像</code></pre><p>国内不少云服务商都提供了 Docker 镜像市场包括腾讯云 、 网易云、阿里云等<br>下载第三方服务商如 腾讯云 提供的镜像格式为 index.tenxcloud.com/<namespace>/<repository>:<tag></p>\n<pre><code>$ docker pull index.tenxcloud.com/docker_library/node:latest</code></pre><p>下载后，可以更新镜像的标签，与官方标签保持一致，方便使用：</p>\n<pre><code>$ docker tag index.tenxcloud.com/docker_library/node:latest node:latest</code></pre><h2 id=\"搭建本地私有仓库\"><a href=\"#搭建本地私有仓库\" class=\"headerlink\" title=\"搭建本地私有仓库\"></a>搭建本地私有仓库</h2><h3 id=\"使用-registry-镜像创建私有仓库\"><a href=\"#使用-registry-镜像创建私有仓库\" class=\"headerlink\" title=\"使用 registry 镜像创建私有仓库\"></a>使用 registry 镜像创建私有仓库</h3><blockquote>\n<p>$ docker search registry –limit=5    // Hub official website 查找registry镜像</p>\n</blockquote>\n<pre><code>root@alpha:/home/test# docker run -d -p 5000:5000 registry:2\nUnable to find image &apos;registry:2&apos; locally\n2: Pulling from library/registry\n486039affc0a: Downloading [==========&gt;                                        ]  475.1kB/2.207MB\nba51a3b098e6: Download complete\n8bb4c43d6c8e: Downloading [==&gt;                                                ]  363.8kB/6.824MB\n6f5f453e5f2d: Download complete\n42bc10b72f42: Download complete\n\n$ docker run -d -p 5000:5000 registry:2</code></pre><p>默认情况下，仓库会被创建在容器的 /var/lib/registry 目录下, 容器退出后, 存储的数据也会丢失.<br>因此实际开发环境中私有仓库registry存储路径必须绑定到主机目录.<br>可以通过 －v 参数来将镜像文件存放在本地的指定路径 。 例如下面的例子将上传的镜像放到/opt/data/registry 目录：</p>\n<pre><code>$ docker run -d -p 5000:5000 -v /opt/data/registry:/var/lib/registry --restart=always --name registry registry:2 </code></pre><p>如果创建容器时没有添加自动重启参数 –restart=always ，导致的后果是：当 Docker 服务重启时，容器未能自动启动。<br>第一种添加修改该参数(实测有效): </p>\n<pre><code>$ docker container update --restart=always 容器名字或容器ID</code></pre><p>第二种修改该参数；</p>\n<pre><code>首先停止容器，不然无法修改配置文件(实测中不用停止容器也修改了, 但是docker服务重启后容器没有重启)\n配置文件路径为：/var/lib/docker/containers/容器ID(容器ID通过 $ docker ps | grep 容器Name 进行查看)\n在该目录下找到一个文件 hostconfig.json ，找到该文件中关键字 RestartPolicy\n修改前配置：&quot;RestartPolicy&quot;:{&quot;Name&quot;:&quot;no&quot;,&quot;MaximumRetryCount&quot;:0}\n修改后配置：&quot;RestartPolicy&quot;:{&quot;Name&quot;:&quot;always&quot;,&quot;MaximumRetryCount&quot;:0}\n最后启动容器。\n\n另外也可以查看容器绑定存储文件路径\n&quot;Binds&quot;:[&quot;/opt/data/registry1:/var/lib/registry&quot;]\n没有绑定到主机目录的容器此hostconfig.json文件内容为 &quot;Binds&quot;:null</code></pre><p>此时， 在本地将启动一个私有仓库服务，监听端口为 5000 </p>\n<pre><code>root@alpha:~# docker ps\nCONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS                    NAMES\ne0bb400f0ba6        registry:2             &quot;/entrypoint.sh /etc…&quot;   11 hours ago        Up 11 hours         0.0.0.0:5000-&gt;5000/tcp   registry</code></pre><h3 id=\"从私有仓库上传下载镜像-amp-查看\"><a href=\"#从私有仓库上传下载镜像-amp-查看\" class=\"headerlink\" title=\"从私有仓库上传下载镜像 &amp; 查看\"></a>从私有仓库上传下载镜像 &amp; 查看</h3><blockquote>\n<p>应为docker客户端发送的是https请求，从私有仓库下载镜像时候需要用http请求协议，因此在其它机器上要上传或下载10.239.140.186:5000(me office)机器上的image时候会出问题<br>需要在其它要下载10.239.140.186机器上image的机器比如10.239.85.243(solu02)上添加并修改如下文件：<br>master和worker节点都需要添加启动仓库registry:2所在的机器IP和开放的端口，内容和步骤如下:</p>\n</blockquote>\n<pre><code>$ vim /etc/docker/daemon.json    // 没有的话需要新建这个json文件, 然后添加如下内容, 表示信任10.239.140.186机器5000端口提供的服务\n    {\n        &quot;insecure-registries&quot;:[&quot;10.239.140.186:5000&quot;]\n    }\n\n$ systemctl daemon-reload            // 重新加载daemon\n$ systemctl restart docker            // 重启docker\n$ systemctl enable docker.service    // 开机默认启动\n如果是在运行registry容器的机器上重启docker service之后一定要查看registry容器是否重新启动.\n$ docker run -d -p 5000:5000 registry:2</code></pre><blockquote>\n<p>在solu02机器上从hub公共image库下载个image如ubuntu:latest</p>\n</blockquote>\n<pre><code>$ dcoker pull ubuntu                // 默认下载latest\n$ docker images\n➜  ~ docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nubuntu              latest              1d622ef86b13        5 days ago          73.9MB</code></pre><h3 id=\"上传image\"><a href=\"#上传image\" class=\"headerlink\" title=\"上传image\"></a>上传image</h3><p>给要上传的image重新打个标签</p>\n<pre><code>$ docker tag ubuntu:latest 10.239.140.186:5000/solu02_utunbu:latest</code></pre><p>使用 docker push 上传标记的镜像：</p>\n<pre><code>$ docker push 10.239.140.186:5000/solu02_utunbu:latest  // 要和 &quot;/etc/docker/daemon.json中配置的insecure-registries的值一致&quot;\n或者 $ docker push master-node:5000/solu02_utunbu:latest\n➜  ~ docker push 10.239.140.186:5000/solu02_utunbu:latest\nThe push refers to repository [10.239.140.186:5000/solu02_utunbu]\n8891751e0a17: Pushed\n2a19bd70fcd4: Pushed\n9e53fd489559: Pushed\n7789f1a3d4e9: Pushed\nlatest: digest: sha256:5747316366b8cc9e3021cd7286f42b2d6d81e3d743e2ab571f55bcd5df788cc8 size: 1152\n➜  ~</code></pre><h3 id=\"查看image\"><a href=\"#查看image\" class=\"headerlink\" title=\"查看image\"></a>查看image</h3><p>在仓库主机10.239.140.186机器上使用curl 查看仓库 10.239.140.186:5000(me office) 中的镜像：<br>是用10.239.140.186访问, 还是用在/etc/hosts中将主机IP:10.239.140.186映射为master-node访问,<br>主要是跟 /etc/docker/daemon-reload 设置的 insecure-registries 值一致.</p>\n<pre><code>$ curl http://10.239.140.186:5000/v2/_catalog\n或 $ curl http://master-node:5000/v2/_catalog\n {&quot;repositories&quot;:[&quot;solu02_utunbu&quot;,&quot;test_ubuntu&quot;,&quot;test_ubuntu1&quot;,&quot;docker.io/nginx&quot;]}</code></pre><p>查看镜像和相应tag:</p>\n<pre><code>$ curl -XGET http://master-node:5000/v2/{image_name}/tags/list\n$ curl 10.239.140.186:5000/v2/docker.io/nginx/tags/list\n {&quot;name&quot;:&quot;docker.io/nginx&quot;,&quot;tags&quot;:[&quot;alpine&quot;]}</code></pre><p>浏览器输入如下地址查看<br><a href=\"http://localhost:5000/v2/_catalog\" target=\"_blank\" rel=\"noopener\">http://localhost:5000/v2/_catalog</a>                     // 查看所有images<br><a href=\"http://localhost:5000/v2/docker.io/nginx/tags/list\" target=\"_blank\" rel=\"noopener\">http://localhost:5000/v2/docker.io/nginx/tags/list</a>    // 查看所有images的tags</p>\n<h3 id=\"下载image\"><a href=\"#下载image\" class=\"headerlink\" title=\"下载image\"></a>下载image</h3><p>在solu02(10.239.85.243)机器上下载10.239.140.186私有仓库里的image:</p>\n<pre><code>$ docker pull 10.239.140.186:5000/test_ubuntu</code></pre><p>拉去指定tag的image</p>\n<pre><code>$ docker pull 10.239.140.186:5000/docker.io/nginx:alpine</code></pre><h3 id=\"DNS-解析IP\"><a href=\"#DNS-解析IP\" class=\"headerlink\" title=\"DNS 解析IP\"></a>DNS 解析IP</h3><p>用master-node等代替registry运行所在的主机的IP</p>\n<pre><code>$ vim /etc/hosts\n 10.239.140.186 master-node\n 10.239.141.101 node-1\n\n$ vim /etc/docker/daemon.json\n { &quot;insecure-registries&quot;: [&quot;master-node:5000&quot;] }</code></pre><h2 id=\"配置docker的HTTP-PROXY-HTTPS-PROXY-NO-PROXY\"><a href=\"#配置docker的HTTP-PROXY-HTTPS-PROXY-NO-PROXY\" class=\"headerlink\" title=\"配置docker的HTTP_PROXY, HTTPS_PROXY, NO_PROXY\"></a>配置docker的HTTP_PROXY, HTTPS_PROXY, NO_PROXY</h2><p>第一种: 放到一个文件里</p>\n<pre><code>$ vim /etc/systemd/system/docker.service.d/http-proxy.conf\n [Service]\n Environment=&quot;HTTP_PROXY=http://proxy:913&quot; &quot;NO_PROXY=localhost,127.0.0.1,master-node&quot;</code></pre><p>第二种: 将docker的HTTP_PROXY, HTTPS_PROXY, NO_PROXY放到三个文件<br>新建三个文件, 并添加类似的如下信息</p>\n<pre><code>$ touch /etc/systemd/system/docker.service.d/no-proxy.conf\n [Service]\n Environment=&quot;NO_PROXY=10.67.108.211,10.67.109.142,10.67.109.147,10.67.109.144,hci-node01,hci-node02,hci-node03,hci-node04&quot;\n$ touch /etc/systemd/system/docker.service.d/http-proxy.conf\n [Service]\n Environment=&quot;HTTP_PROXY=http://proxy:913/&quot;\n$ touch /etc/systemd/system/docker.service.d/https-proxy.conf\n [Service]\n Environment=&quot;HTTPS_PROXY=http://proxy:913/&quot;</code></pre><p>修改完上面信息之后重启docker</p>\n<pre><code>$ systemctl daemon-reload\n$ systemctl restart docker\n\n$ docker tag docker.io/nginx:alpine master-node:5000/docker.io/nginx:alpine\n$ docker push master-node:5000/docker.io/nginx:alpine\n$ curl 10.239.140.186:5000/v2/_catalog\n或者\n$ curl master-node:5000/v2/_catalog\n遇到访问不了如下面显示信息时候, 原因是通过curl方式访问master-node主机时仍通过linux设置的公司的proxy访问\n&lt;HTML&gt;\n&lt;HEAD&gt;&lt;TITLE&gt;Redirection&lt;/TITLE&gt;&lt;/HEAD&gt;\n&lt;BODY&gt;&lt;H1&gt;Redirect&lt;/H1&gt;&lt;/BODY&gt;\n&lt;/HTML&gt;\n设置linux的NO_PROXY环境变量, 使curl访问 master-node 时不通过公司的proxy\n$ export NO_PROXY=master-node\n$ curl master-node:5000/v2/_catalog\n{&quot;repositories&quot;:[&quot;docker.io/nginx&quot;,&quot;hello-world&quot;,&quot;hello-world1&quot;,&quot;hello-world11&quot;]}</code></pre>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Docker-引擎\"><a href=\"#Docker-引擎\" class=\"headerlink\" title=\"Docker 引擎\"></a>Docker 引擎</h2><p>目前 Docker 支持 Docker 引 擎、 Docker Hub 、 Docker Cloud 等多种服务 。</p>\n<ul>\n<li>Docker 引擎：包括支持在桌面系统或云平台安装 Docker，以及为企业提供简单安全弹性的容器集群编排和管理；</li>\n<li>DockerHub ：官方提供的云托管服务，可以提供公有或私有的镜像仓库；</li>\n<li>DockerCloud ：官方提供的容器云服务，可以完成容器的部署与管理，可以完整地支持容器化项目，还有 CI 、 CD 功能<br>用户可以通过如下命令检查自己的内核版本详细信息 ：</li>\n</ul>\n<pre><code>$ uname -a\n$ cat /proc/version</code></pre><h2 id=\"查看日志\"><a href=\"#查看日志\" class=\"headerlink\" title=\"查看日志\"></a>查看日志</h2><p>如果服务工作不正常，可以通过查看 Docker 服务的日志信息来确定问题，例如<br>在 RedHat 系统上的系统运行日志文件为 </p>\n<pre><code>/var/log/messages</code></pre><p>在 Ubuntu 或 CentOS 系统上可以执行命令</p>\n<pre><code>$ journalctl -u docker.service \n$ journalctl -xe\n$ journalctl -f -n 10 -u docker.service //滚屏输出10条服务docker.service的log信息</code></pre><h2 id=\"访问Docker-仓库-Repository\"><a href=\"#访问Docker-仓库-Repository\" class=\"headerlink\" title=\"访问Docker 仓库 Repository\"></a>访问Docker 仓库 Repository</h2><p>分公共仓库和私有仓库</p>\n<h3 id=\"公共仓库\"><a href=\"#公共仓库\" class=\"headerlink\" title=\"公共仓库\"></a>公共仓库</h3><p>Docker Hub 是 Docker 官方提供的最大的公共镜像仓库, docker search 命令来查找官方仓库中的镜像</p>\n<pre><code>$ docker search centos\n$ docker pull centos\n$ docker images 命令来查看下载到本地的镜像</code></pre><p>国内不少云服务商都提供了 Docker 镜像市场包括腾讯云 、 网易云、阿里云等<br>下载第三方服务商如 腾讯云 提供的镜像格式为 index.tenxcloud.com/<namespace>/<repository>:<tag></p>\n<pre><code>$ docker pull index.tenxcloud.com/docker_library/node:latest</code></pre><p>下载后，可以更新镜像的标签，与官方标签保持一致，方便使用：</p>\n<pre><code>$ docker tag index.tenxcloud.com/docker_library/node:latest node:latest</code></pre><h2 id=\"搭建本地私有仓库\"><a href=\"#搭建本地私有仓库\" class=\"headerlink\" title=\"搭建本地私有仓库\"></a>搭建本地私有仓库</h2><h3 id=\"使用-registry-镜像创建私有仓库\"><a href=\"#使用-registry-镜像创建私有仓库\" class=\"headerlink\" title=\"使用 registry 镜像创建私有仓库\"></a>使用 registry 镜像创建私有仓库</h3><blockquote>\n<p>$ docker search registry –limit=5    // Hub official website 查找registry镜像</p>\n</blockquote>\n<pre><code>root@alpha:/home/test# docker run -d -p 5000:5000 registry:2\nUnable to find image &apos;registry:2&apos; locally\n2: Pulling from library/registry\n486039affc0a: Downloading [==========&gt;                                        ]  475.1kB/2.207MB\nba51a3b098e6: Download complete\n8bb4c43d6c8e: Downloading [==&gt;                                                ]  363.8kB/6.824MB\n6f5f453e5f2d: Download complete\n42bc10b72f42: Download complete\n\n$ docker run -d -p 5000:5000 registry:2</code></pre><p>默认情况下，仓库会被创建在容器的 /var/lib/registry 目录下, 容器退出后, 存储的数据也会丢失.<br>因此实际开发环境中私有仓库registry存储路径必须绑定到主机目录.<br>可以通过 －v 参数来将镜像文件存放在本地的指定路径 。 例如下面的例子将上传的镜像放到/opt/data/registry 目录：</p>\n<pre><code>$ docker run -d -p 5000:5000 -v /opt/data/registry:/var/lib/registry --restart=always --name registry registry:2 </code></pre><p>如果创建容器时没有添加自动重启参数 –restart=always ，导致的后果是：当 Docker 服务重启时，容器未能自动启动。<br>第一种添加修改该参数(实测有效): </p>\n<pre><code>$ docker container update --restart=always 容器名字或容器ID</code></pre><p>第二种修改该参数；</p>\n<pre><code>首先停止容器，不然无法修改配置文件(实测中不用停止容器也修改了, 但是docker服务重启后容器没有重启)\n配置文件路径为：/var/lib/docker/containers/容器ID(容器ID通过 $ docker ps | grep 容器Name 进行查看)\n在该目录下找到一个文件 hostconfig.json ，找到该文件中关键字 RestartPolicy\n修改前配置：&quot;RestartPolicy&quot;:{&quot;Name&quot;:&quot;no&quot;,&quot;MaximumRetryCount&quot;:0}\n修改后配置：&quot;RestartPolicy&quot;:{&quot;Name&quot;:&quot;always&quot;,&quot;MaximumRetryCount&quot;:0}\n最后启动容器。\n\n另外也可以查看容器绑定存储文件路径\n&quot;Binds&quot;:[&quot;/opt/data/registry1:/var/lib/registry&quot;]\n没有绑定到主机目录的容器此hostconfig.json文件内容为 &quot;Binds&quot;:null</code></pre><p>此时， 在本地将启动一个私有仓库服务，监听端口为 5000 </p>\n<pre><code>root@alpha:~# docker ps\nCONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS                    NAMES\ne0bb400f0ba6        registry:2             &quot;/entrypoint.sh /etc…&quot;   11 hours ago        Up 11 hours         0.0.0.0:5000-&gt;5000/tcp   registry</code></pre><h3 id=\"从私有仓库上传下载镜像-amp-查看\"><a href=\"#从私有仓库上传下载镜像-amp-查看\" class=\"headerlink\" title=\"从私有仓库上传下载镜像 &amp; 查看\"></a>从私有仓库上传下载镜像 &amp; 查看</h3><blockquote>\n<p>应为docker客户端发送的是https请求，从私有仓库下载镜像时候需要用http请求协议，因此在其它机器上要上传或下载10.239.140.186:5000(me office)机器上的image时候会出问题<br>需要在其它要下载10.239.140.186机器上image的机器比如10.239.85.243(solu02)上添加并修改如下文件：<br>master和worker节点都需要添加启动仓库registry:2所在的机器IP和开放的端口，内容和步骤如下:</p>\n</blockquote>\n<pre><code>$ vim /etc/docker/daemon.json    // 没有的话需要新建这个json文件, 然后添加如下内容, 表示信任10.239.140.186机器5000端口提供的服务\n    {\n        &quot;insecure-registries&quot;:[&quot;10.239.140.186:5000&quot;]\n    }\n\n$ systemctl daemon-reload            // 重新加载daemon\n$ systemctl restart docker            // 重启docker\n$ systemctl enable docker.service    // 开机默认启动\n如果是在运行registry容器的机器上重启docker service之后一定要查看registry容器是否重新启动.\n$ docker run -d -p 5000:5000 registry:2</code></pre><blockquote>\n<p>在solu02机器上从hub公共image库下载个image如ubuntu:latest</p>\n</blockquote>\n<pre><code>$ dcoker pull ubuntu                // 默认下载latest\n$ docker images\n➜  ~ docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nubuntu              latest              1d622ef86b13        5 days ago          73.9MB</code></pre><h3 id=\"上传image\"><a href=\"#上传image\" class=\"headerlink\" title=\"上传image\"></a>上传image</h3><p>给要上传的image重新打个标签</p>\n<pre><code>$ docker tag ubuntu:latest 10.239.140.186:5000/solu02_utunbu:latest</code></pre><p>使用 docker push 上传标记的镜像：</p>\n<pre><code>$ docker push 10.239.140.186:5000/solu02_utunbu:latest  // 要和 &quot;/etc/docker/daemon.json中配置的insecure-registries的值一致&quot;\n或者 $ docker push master-node:5000/solu02_utunbu:latest\n➜  ~ docker push 10.239.140.186:5000/solu02_utunbu:latest\nThe push refers to repository [10.239.140.186:5000/solu02_utunbu]\n8891751e0a17: Pushed\n2a19bd70fcd4: Pushed\n9e53fd489559: Pushed\n7789f1a3d4e9: Pushed\nlatest: digest: sha256:5747316366b8cc9e3021cd7286f42b2d6d81e3d743e2ab571f55bcd5df788cc8 size: 1152\n➜  ~</code></pre><h3 id=\"查看image\"><a href=\"#查看image\" class=\"headerlink\" title=\"查看image\"></a>查看image</h3><p>在仓库主机10.239.140.186机器上使用curl 查看仓库 10.239.140.186:5000(me office) 中的镜像：<br>是用10.239.140.186访问, 还是用在/etc/hosts中将主机IP:10.239.140.186映射为master-node访问,<br>主要是跟 /etc/docker/daemon-reload 设置的 insecure-registries 值一致.</p>\n<pre><code>$ curl http://10.239.140.186:5000/v2/_catalog\n或 $ curl http://master-node:5000/v2/_catalog\n {&quot;repositories&quot;:[&quot;solu02_utunbu&quot;,&quot;test_ubuntu&quot;,&quot;test_ubuntu1&quot;,&quot;docker.io/nginx&quot;]}</code></pre><p>查看镜像和相应tag:</p>\n<pre><code>$ curl -XGET http://master-node:5000/v2/{image_name}/tags/list\n$ curl 10.239.140.186:5000/v2/docker.io/nginx/tags/list\n {&quot;name&quot;:&quot;docker.io/nginx&quot;,&quot;tags&quot;:[&quot;alpine&quot;]}</code></pre><p>浏览器输入如下地址查看<br><a href=\"http://localhost:5000/v2/_catalog\" target=\"_blank\" rel=\"noopener\">http://localhost:5000/v2/_catalog</a>                     // 查看所有images<br><a href=\"http://localhost:5000/v2/docker.io/nginx/tags/list\" target=\"_blank\" rel=\"noopener\">http://localhost:5000/v2/docker.io/nginx/tags/list</a>    // 查看所有images的tags</p>\n<h3 id=\"下载image\"><a href=\"#下载image\" class=\"headerlink\" title=\"下载image\"></a>下载image</h3><p>在solu02(10.239.85.243)机器上下载10.239.140.186私有仓库里的image:</p>\n<pre><code>$ docker pull 10.239.140.186:5000/test_ubuntu</code></pre><p>拉去指定tag的image</p>\n<pre><code>$ docker pull 10.239.140.186:5000/docker.io/nginx:alpine</code></pre><h3 id=\"DNS-解析IP\"><a href=\"#DNS-解析IP\" class=\"headerlink\" title=\"DNS 解析IP\"></a>DNS 解析IP</h3><p>用master-node等代替registry运行所在的主机的IP</p>\n<pre><code>$ vim /etc/hosts\n 10.239.140.186 master-node\n 10.239.141.101 node-1\n\n$ vim /etc/docker/daemon.json\n { &quot;insecure-registries&quot;: [&quot;master-node:5000&quot;] }</code></pre><h2 id=\"配置docker的HTTP-PROXY-HTTPS-PROXY-NO-PROXY\"><a href=\"#配置docker的HTTP-PROXY-HTTPS-PROXY-NO-PROXY\" class=\"headerlink\" title=\"配置docker的HTTP_PROXY, HTTPS_PROXY, NO_PROXY\"></a>配置docker的HTTP_PROXY, HTTPS_PROXY, NO_PROXY</h2><p>第一种: 放到一个文件里</p>\n<pre><code>$ vim /etc/systemd/system/docker.service.d/http-proxy.conf\n [Service]\n Environment=&quot;HTTP_PROXY=http://proxy:913&quot; &quot;NO_PROXY=localhost,127.0.0.1,master-node&quot;</code></pre><p>第二种: 将docker的HTTP_PROXY, HTTPS_PROXY, NO_PROXY放到三个文件<br>新建三个文件, 并添加类似的如下信息</p>\n<pre><code>$ touch /etc/systemd/system/docker.service.d/no-proxy.conf\n [Service]\n Environment=&quot;NO_PROXY=10.67.108.211,10.67.109.142,10.67.109.147,10.67.109.144,hci-node01,hci-node02,hci-node03,hci-node04&quot;\n$ touch /etc/systemd/system/docker.service.d/http-proxy.conf\n [Service]\n Environment=&quot;HTTP_PROXY=http://proxy:913/&quot;\n$ touch /etc/systemd/system/docker.service.d/https-proxy.conf\n [Service]\n Environment=&quot;HTTPS_PROXY=http://proxy:913/&quot;</code></pre><p>修改完上面信息之后重启docker</p>\n<pre><code>$ systemctl daemon-reload\n$ systemctl restart docker\n\n$ docker tag docker.io/nginx:alpine master-node:5000/docker.io/nginx:alpine\n$ docker push master-node:5000/docker.io/nginx:alpine\n$ curl 10.239.140.186:5000/v2/_catalog\n或者\n$ curl master-node:5000/v2/_catalog\n遇到访问不了如下面显示信息时候, 原因是通过curl方式访问master-node主机时仍通过linux设置的公司的proxy访问\n&lt;HTML&gt;\n&lt;HEAD&gt;&lt;TITLE&gt;Redirection&lt;/TITLE&gt;&lt;/HEAD&gt;\n&lt;BODY&gt;&lt;H1&gt;Redirect&lt;/H1&gt;&lt;/BODY&gt;\n&lt;/HTML&gt;\n设置linux的NO_PROXY环境变量, 使curl访问 master-node 时不通过公司的proxy\n$ export NO_PROXY=master-node\n$ curl master-node:5000/v2/_catalog\n{&quot;repositories&quot;:[&quot;docker.io/nginx&quot;,&quot;hello-world&quot;,&quot;hello-world1&quot;,&quot;hello-world11&quot;]}</code></pre>"},{"title":"Install python3 & pip3 & pipenv","_content":"### 查看python库\n\t$ python -m site\t// python 2 版本\n\t$ python3 -m site\t// python 3 版本\n\n## 第一种，非源码安装\nubuntu18.04+python3，这个系统是默认自带了python3，且版本是python 3.6.8\n该python 3.6.8中并没有对应的pip3，于是执行命令 sudo apt-get install python3-pip，即可成功安装pip3\n然后即可通过 pip3 install pipenv , 安装自己需要的pipenv模块\n\n## 第二种，源码安装(非常不推荐，容易踩各种坑)\n### Install Python3\n\t$ yum install zlib-devel.x86_64\n\t$ yum -y install zlib1g-dev\n\t$ yum -y install libffi-devel\n\t$ yum install openssl-devel -y\n\t\n\t$ wget https://www.python.org/ftp/python/3.7.2/Python-3.7.2.tar.xz\n\t$ tar -xvJf  Python-3.7.2.tar.xz\n\t$ mkdir /usr/local/python3 \n\t$ cd Python-3.7.2\n\t$ ./configure --prefix=/usr/local/python3 --enable-optimizations --with-ssl \n\t#第一个指定安装的路径,不指定的话,安装过程中可能软件所需要的文件复制到其他不同目录,删除软件很不方便,复制软件也不方便.\n\t#第二个可以提高python10%-20%代码运行速度.\n\t#第三个是为了安装pip需要用到ssl,后面报错会有提到.\n\t$ make -j && make install\n\n### 创建软链接\n\t$ ln -s /usr/local/python3/bin/python3 /usr/bin/python3\n\t$ ln -s /usr/local/python3/bin/pip3 /usr/bin/pip3\n\tPATH路径需要有/usr/local/bin, 重启客户端\n\n### 验证是否成功\n\t$ python3 -V\n\t$ pip3 -V\n\n### 修改pip安装源\n\t$ cd ~\n\t$ mkdir .pip\n\t$ cd .pip\n\t$ vim pip.conf\n\t#进入后添加以下内容,保存退出.\n\t[global]\n\tindex-url = https://mirrors.aliyun.com/pypi/simple\n\n## 安装pipenv\npython里如果多个多个项目同时引用包，就会涉及到包版本的问题，包不同版本管理的问题可以用虚拟环境来管理\n创建虚拟环境，这里是用官方推荐的pipenv来创建\n\t安装pipenv\n\t第一种: pip3 install pipenv (亲测可用)\n\t第二种: pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple pipenv 使用国内源安装pipenv\n\t$ pip3 list\t// 查看 pipnev是否安装完成\n\tpipenv --version\t//报错如下:\n\t * -bash: pipenv: command not found\n\t原因：未建立软链接:\n\tln -s /usr/local/python3/bin/pipenv /usr/bin/pipenv\n\t\n\t在使用pipenv之前，必须彻底的忘记pip这个东西\n\t新建一个准备当环境的文件夹pipenvtest，并cd进入该文件夹：\n\t*. 确定python版本\n\t  pipenv --three 会使用当前系统的Python3创建环境\n\t  pipenv --python 3.6 指定某一Python版本创建环境\n\t  然后该目录下会有一个Pipfile文件, 内容为:\n\n![](pipfile.JPG)\n\t\n\t*.激活并查看环境\n\tpipenv shell 激活虚拟环境\n\tpipenv --where 显示目录信息\n\tpipenv --venv 显示虚拟环境信息\n\tpipenv --py 显示Python解释器信息\n\t\n\t*. 安装第三方包\n\tpipenv install [第三方库名] 安装相关模块并加入到Pipfile\n\tpipenv install django==1.11 安装固定版本模块并加入到Pipfile\n\t\n\tpipenv graph 查看目前安装的库及其依赖\n\t\n\t*. 卸载第三方包\n\tpipenv uninstall [第三方库名]\n\tpipenv uninstall --all  卸载当前环境下所有包\n\t\n\t*. 更新\n\tpipenv  update  --更新当前环境下所有包，升级到最新版本\n\t\n\t*. 退出\n\texit  推出虚拟环境\n\t\n\t*. 删除虚拟环境\n\tpipenv --rm  删除虚拟环境\n\n\n\n\n\n","source":"_posts/language/python/linux_install_python_pip_pipenv.md","raw":"---\ntitle: Install python3 & pip3 & pipenv\ntags:\ncategories:\n- language\n- python\n---\n### 查看python库\n\t$ python -m site\t// python 2 版本\n\t$ python3 -m site\t// python 3 版本\n\n## 第一种，非源码安装\nubuntu18.04+python3，这个系统是默认自带了python3，且版本是python 3.6.8\n该python 3.6.8中并没有对应的pip3，于是执行命令 sudo apt-get install python3-pip，即可成功安装pip3\n然后即可通过 pip3 install pipenv , 安装自己需要的pipenv模块\n\n## 第二种，源码安装(非常不推荐，容易踩各种坑)\n### Install Python3\n\t$ yum install zlib-devel.x86_64\n\t$ yum -y install zlib1g-dev\n\t$ yum -y install libffi-devel\n\t$ yum install openssl-devel -y\n\t\n\t$ wget https://www.python.org/ftp/python/3.7.2/Python-3.7.2.tar.xz\n\t$ tar -xvJf  Python-3.7.2.tar.xz\n\t$ mkdir /usr/local/python3 \n\t$ cd Python-3.7.2\n\t$ ./configure --prefix=/usr/local/python3 --enable-optimizations --with-ssl \n\t#第一个指定安装的路径,不指定的话,安装过程中可能软件所需要的文件复制到其他不同目录,删除软件很不方便,复制软件也不方便.\n\t#第二个可以提高python10%-20%代码运行速度.\n\t#第三个是为了安装pip需要用到ssl,后面报错会有提到.\n\t$ make -j && make install\n\n### 创建软链接\n\t$ ln -s /usr/local/python3/bin/python3 /usr/bin/python3\n\t$ ln -s /usr/local/python3/bin/pip3 /usr/bin/pip3\n\tPATH路径需要有/usr/local/bin, 重启客户端\n\n### 验证是否成功\n\t$ python3 -V\n\t$ pip3 -V\n\n### 修改pip安装源\n\t$ cd ~\n\t$ mkdir .pip\n\t$ cd .pip\n\t$ vim pip.conf\n\t#进入后添加以下内容,保存退出.\n\t[global]\n\tindex-url = https://mirrors.aliyun.com/pypi/simple\n\n## 安装pipenv\npython里如果多个多个项目同时引用包，就会涉及到包版本的问题，包不同版本管理的问题可以用虚拟环境来管理\n创建虚拟环境，这里是用官方推荐的pipenv来创建\n\t安装pipenv\n\t第一种: pip3 install pipenv (亲测可用)\n\t第二种: pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple pipenv 使用国内源安装pipenv\n\t$ pip3 list\t// 查看 pipnev是否安装完成\n\tpipenv --version\t//报错如下:\n\t * -bash: pipenv: command not found\n\t原因：未建立软链接:\n\tln -s /usr/local/python3/bin/pipenv /usr/bin/pipenv\n\t\n\t在使用pipenv之前，必须彻底的忘记pip这个东西\n\t新建一个准备当环境的文件夹pipenvtest，并cd进入该文件夹：\n\t*. 确定python版本\n\t  pipenv --three 会使用当前系统的Python3创建环境\n\t  pipenv --python 3.6 指定某一Python版本创建环境\n\t  然后该目录下会有一个Pipfile文件, 内容为:\n\n![](pipfile.JPG)\n\t\n\t*.激活并查看环境\n\tpipenv shell 激活虚拟环境\n\tpipenv --where 显示目录信息\n\tpipenv --venv 显示虚拟环境信息\n\tpipenv --py 显示Python解释器信息\n\t\n\t*. 安装第三方包\n\tpipenv install [第三方库名] 安装相关模块并加入到Pipfile\n\tpipenv install django==1.11 安装固定版本模块并加入到Pipfile\n\t\n\tpipenv graph 查看目前安装的库及其依赖\n\t\n\t*. 卸载第三方包\n\tpipenv uninstall [第三方库名]\n\tpipenv uninstall --all  卸载当前环境下所有包\n\t\n\t*. 更新\n\tpipenv  update  --更新当前环境下所有包，升级到最新版本\n\t\n\t*. 退出\n\texit  推出虚拟环境\n\t\n\t*. 删除虚拟环境\n\tpipenv --rm  删除虚拟环境\n\n\n\n\n\n","slug":"language/python/linux_install_python_pip_pipenv","published":1,"date":"2020-08-12T16:05:45.611Z","updated":"2020-04-29T15:25:10.249Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmlf008mhohxbvn33usu","content":"<h3 id=\"查看python库\"><a href=\"#查看python库\" class=\"headerlink\" title=\"查看python库\"></a>查看python库</h3><pre><code>$ python -m site    // python 2 版本\n$ python3 -m site    // python 3 版本</code></pre><h2 id=\"第一种，非源码安装\"><a href=\"#第一种，非源码安装\" class=\"headerlink\" title=\"第一种，非源码安装\"></a>第一种，非源码安装</h2><p>ubuntu18.04+python3，这个系统是默认自带了python3，且版本是python 3.6.8<br>该python 3.6.8中并没有对应的pip3，于是执行命令 sudo apt-get install python3-pip，即可成功安装pip3<br>然后即可通过 pip3 install pipenv , 安装自己需要的pipenv模块</p>\n<h2 id=\"第二种，源码安装-非常不推荐，容易踩各种坑\"><a href=\"#第二种，源码安装-非常不推荐，容易踩各种坑\" class=\"headerlink\" title=\"第二种，源码安装(非常不推荐，容易踩各种坑)\"></a>第二种，源码安装(非常不推荐，容易踩各种坑)</h2><h3 id=\"Install-Python3\"><a href=\"#Install-Python3\" class=\"headerlink\" title=\"Install Python3\"></a>Install Python3</h3><pre><code>$ yum install zlib-devel.x86_64\n$ yum -y install zlib1g-dev\n$ yum -y install libffi-devel\n$ yum install openssl-devel -y\n\n$ wget https://www.python.org/ftp/python/3.7.2/Python-3.7.2.tar.xz\n$ tar -xvJf  Python-3.7.2.tar.xz\n$ mkdir /usr/local/python3 \n$ cd Python-3.7.2\n$ ./configure --prefix=/usr/local/python3 --enable-optimizations --with-ssl \n#第一个指定安装的路径,不指定的话,安装过程中可能软件所需要的文件复制到其他不同目录,删除软件很不方便,复制软件也不方便.\n#第二个可以提高python10%-20%代码运行速度.\n#第三个是为了安装pip需要用到ssl,后面报错会有提到.\n$ make -j &amp;&amp; make install</code></pre><h3 id=\"创建软链接\"><a href=\"#创建软链接\" class=\"headerlink\" title=\"创建软链接\"></a>创建软链接</h3><pre><code>$ ln -s /usr/local/python3/bin/python3 /usr/bin/python3\n$ ln -s /usr/local/python3/bin/pip3 /usr/bin/pip3\nPATH路径需要有/usr/local/bin, 重启客户端</code></pre><h3 id=\"验证是否成功\"><a href=\"#验证是否成功\" class=\"headerlink\" title=\"验证是否成功\"></a>验证是否成功</h3><pre><code>$ python3 -V\n$ pip3 -V</code></pre><h3 id=\"修改pip安装源\"><a href=\"#修改pip安装源\" class=\"headerlink\" title=\"修改pip安装源\"></a>修改pip安装源</h3><pre><code>$ cd ~\n$ mkdir .pip\n$ cd .pip\n$ vim pip.conf\n#进入后添加以下内容,保存退出.\n[global]\nindex-url = https://mirrors.aliyun.com/pypi/simple</code></pre><h2 id=\"安装pipenv\"><a href=\"#安装pipenv\" class=\"headerlink\" title=\"安装pipenv\"></a>安装pipenv</h2><p>python里如果多个多个项目同时引用包，就会涉及到包版本的问题，包不同版本管理的问题可以用虚拟环境来管理<br>创建虚拟环境，这里是用官方推荐的pipenv来创建<br>    安装pipenv<br>    第一种: pip3 install pipenv (亲测可用)<br>    第二种: pip3 install -i <a href=\"https://pypi.tuna.tsinghua.edu.cn/simple\" target=\"_blank\" rel=\"noopener\">https://pypi.tuna.tsinghua.edu.cn/simple</a> pipenv 使用国内源安装pipenv<br>    $ pip3 list    // 查看 pipnev是否安装完成<br>    pipenv –version    //报错如下:<br>     * -bash: pipenv: command not found<br>    原因：未建立软链接:<br>    ln -s /usr/local/python3/bin/pipenv /usr/bin/pipenv</p>\n<pre><code>在使用pipenv之前，必须彻底的忘记pip这个东西\n新建一个准备当环境的文件夹pipenvtest，并cd进入该文件夹：\n*. 确定python版本\n  pipenv --three 会使用当前系统的Python3创建环境\n  pipenv --python 3.6 指定某一Python版本创建环境\n  然后该目录下会有一个Pipfile文件, 内容为:</code></pre><p><img src=\"pipfile.JPG\" alt=\"\"></p>\n<pre><code>*.激活并查看环境\npipenv shell 激活虚拟环境\npipenv --where 显示目录信息\npipenv --venv 显示虚拟环境信息\npipenv --py 显示Python解释器信息\n\n*. 安装第三方包\npipenv install [第三方库名] 安装相关模块并加入到Pipfile\npipenv install django==1.11 安装固定版本模块并加入到Pipfile\n\npipenv graph 查看目前安装的库及其依赖\n\n*. 卸载第三方包\npipenv uninstall [第三方库名]\npipenv uninstall --all  卸载当前环境下所有包\n\n*. 更新\npipenv  update  --更新当前环境下所有包，升级到最新版本\n\n*. 退出\nexit  推出虚拟环境\n\n*. 删除虚拟环境\npipenv --rm  删除虚拟环境</code></pre>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"查看python库\"><a href=\"#查看python库\" class=\"headerlink\" title=\"查看python库\"></a>查看python库</h3><pre><code>$ python -m site    // python 2 版本\n$ python3 -m site    // python 3 版本</code></pre><h2 id=\"第一种，非源码安装\"><a href=\"#第一种，非源码安装\" class=\"headerlink\" title=\"第一种，非源码安装\"></a>第一种，非源码安装</h2><p>ubuntu18.04+python3，这个系统是默认自带了python3，且版本是python 3.6.8<br>该python 3.6.8中并没有对应的pip3，于是执行命令 sudo apt-get install python3-pip，即可成功安装pip3<br>然后即可通过 pip3 install pipenv , 安装自己需要的pipenv模块</p>\n<h2 id=\"第二种，源码安装-非常不推荐，容易踩各种坑\"><a href=\"#第二种，源码安装-非常不推荐，容易踩各种坑\" class=\"headerlink\" title=\"第二种，源码安装(非常不推荐，容易踩各种坑)\"></a>第二种，源码安装(非常不推荐，容易踩各种坑)</h2><h3 id=\"Install-Python3\"><a href=\"#Install-Python3\" class=\"headerlink\" title=\"Install Python3\"></a>Install Python3</h3><pre><code>$ yum install zlib-devel.x86_64\n$ yum -y install zlib1g-dev\n$ yum -y install libffi-devel\n$ yum install openssl-devel -y\n\n$ wget https://www.python.org/ftp/python/3.7.2/Python-3.7.2.tar.xz\n$ tar -xvJf  Python-3.7.2.tar.xz\n$ mkdir /usr/local/python3 \n$ cd Python-3.7.2\n$ ./configure --prefix=/usr/local/python3 --enable-optimizations --with-ssl \n#第一个指定安装的路径,不指定的话,安装过程中可能软件所需要的文件复制到其他不同目录,删除软件很不方便,复制软件也不方便.\n#第二个可以提高python10%-20%代码运行速度.\n#第三个是为了安装pip需要用到ssl,后面报错会有提到.\n$ make -j &amp;&amp; make install</code></pre><h3 id=\"创建软链接\"><a href=\"#创建软链接\" class=\"headerlink\" title=\"创建软链接\"></a>创建软链接</h3><pre><code>$ ln -s /usr/local/python3/bin/python3 /usr/bin/python3\n$ ln -s /usr/local/python3/bin/pip3 /usr/bin/pip3\nPATH路径需要有/usr/local/bin, 重启客户端</code></pre><h3 id=\"验证是否成功\"><a href=\"#验证是否成功\" class=\"headerlink\" title=\"验证是否成功\"></a>验证是否成功</h3><pre><code>$ python3 -V\n$ pip3 -V</code></pre><h3 id=\"修改pip安装源\"><a href=\"#修改pip安装源\" class=\"headerlink\" title=\"修改pip安装源\"></a>修改pip安装源</h3><pre><code>$ cd ~\n$ mkdir .pip\n$ cd .pip\n$ vim pip.conf\n#进入后添加以下内容,保存退出.\n[global]\nindex-url = https://mirrors.aliyun.com/pypi/simple</code></pre><h2 id=\"安装pipenv\"><a href=\"#安装pipenv\" class=\"headerlink\" title=\"安装pipenv\"></a>安装pipenv</h2><p>python里如果多个多个项目同时引用包，就会涉及到包版本的问题，包不同版本管理的问题可以用虚拟环境来管理<br>创建虚拟环境，这里是用官方推荐的pipenv来创建<br>    安装pipenv<br>    第一种: pip3 install pipenv (亲测可用)<br>    第二种: pip3 install -i <a href=\"https://pypi.tuna.tsinghua.edu.cn/simple\" target=\"_blank\" rel=\"noopener\">https://pypi.tuna.tsinghua.edu.cn/simple</a> pipenv 使用国内源安装pipenv<br>    $ pip3 list    // 查看 pipnev是否安装完成<br>    pipenv –version    //报错如下:<br>     * -bash: pipenv: command not found<br>    原因：未建立软链接:<br>    ln -s /usr/local/python3/bin/pipenv /usr/bin/pipenv</p>\n<pre><code>在使用pipenv之前，必须彻底的忘记pip这个东西\n新建一个准备当环境的文件夹pipenvtest，并cd进入该文件夹：\n*. 确定python版本\n  pipenv --three 会使用当前系统的Python3创建环境\n  pipenv --python 3.6 指定某一Python版本创建环境\n  然后该目录下会有一个Pipfile文件, 内容为:</code></pre><p><img src=\"pipfile.JPG\" alt=\"\"></p>\n<pre><code>*.激活并查看环境\npipenv shell 激活虚拟环境\npipenv --where 显示目录信息\npipenv --venv 显示虚拟环境信息\npipenv --py 显示Python解释器信息\n\n*. 安装第三方包\npipenv install [第三方库名] 安装相关模块并加入到Pipfile\npipenv install django==1.11 安装固定版本模块并加入到Pipfile\n\npipenv graph 查看目前安装的库及其依赖\n\n*. 卸载第三方包\npipenv uninstall [第三方库名]\npipenv uninstall --all  卸载当前环境下所有包\n\n*. 更新\npipenv  update  --更新当前环境下所有包，升级到最新版本\n\n*. 退出\nexit  推出虚拟环境\n\n*. 删除虚拟环境\npipenv --rm  删除虚拟环境</code></pre>"},{"title":"docker 01 installation and control commands","_content":"\n## Docker 引擎\n目前 Docker 支持 Docker 引 擎、 Docker Hub 、 Docker Cloud 等多种服务 。\n * Docker 引擎：包括支持在桌面系统或云平台安装 Docker，以及为企业提供简单安全弹性的容器集群编排和管理；\n * DockerHub ：官方提供的云托管服务，可以提供公有或私有的镜像仓库；\n * DockerCloud ：官方提供的容器云服务，可以完成容器的部署与管理，可以完整地支持容器化项目，还有 CI 、 CD 功能 \n用户可以通过如下命令检查自己的内核版本详细信息 ：\n $ uname -a\n $ cat /proc/version\n\n## Ubuntu18.04 docker环境安装：\n官网: https://www.docker.com/get-started\n查找image: https://hub.docker.com/search?type=image\n\n## 简介\n> Docker 是基于 Go 语言实现的开源容器项目 。 它诞生于 2013 年年初，最初发起者是dotCloud 公司，dotCloud 公司也随之快速发展壮大，在 2013 年年底直接改名为 Docker Inc ，并专注于Docker 相关技术和产品的开发，目前已经成为全球最大的 Docker 容器服务提供商 。 官方网站为 docker.com \n> 在 Linux 基金会最近一次关于“最受欢 迎的 云 计算开源项目”的调查中， Docker 仅次于 2010 年发起的 OpenStack 项目，并仍处于上升趋势 。2014 年， Docker 镜像下载数达到了一百万次， 2015 年直接突破十亿次， 2017 年更是突破了惊人的百亿次\n> Docker 的构想是要实现“ Build , Ship and Run Any App, Anywhere ”，即通过对应用的封装（ Packaging）、分发（ Distribution ）、部署（ Deployment）、运行（ Runtime ）生命周期进行管理，达到应用组件级别的“一次封装 ，到处运行”\n> 与大部分新兴技术的诞生一样， Docker 也并非“从石头缝里蹦出来的”，而是站在前人的肩膀上。 其中最重要的就是 Linux 容器（ Linux Containers, LXC ）技术.\n> 每个容器内运行着一个应用，不同的容器相互隔离，容器之间也可以通过网络互相通信 。 容器的创建和停止十分快速，几乎跟创建和终止原生应用－致.\n> 容器自身对系统资源的额外需求也十分有限，远远低于传统虚拟机。 很多时候，甚至直接把容器当作应用本身也没有任何问题.\n\n## 为什么用Docker\n> 在云时代，开发者创建的应用必须要能很方便地在网络上传播，也就是说应用必须脱离底层物理硬件的限制；同时必须是“任何时间任何地点”可获取的 。 因此，开发者们需要一种新型的创建分布式应用程序的方式，快速分发和部署，而这正是 Docker 所能够提供的最大优势\n> Docker 提供了一种更为聪明的方式，通过容器来打包应用、解藕应用和运行平台。这意味着迁移的时候，只需要在新的服务器上启动需要的容器就可以了，无论新旧服务器是否是同一类型的平台 。 这无疑将帮助我们节约大量的宝贵时间，并降低部署过程出现问题的风险\n> 传统虚拟机方式运行 N 个不同的应用就要启用 N 个虚拟机（每个虚拟机需要单独分配独占的内存、磁盘等资源），而 Docker 只需要启动 N 个隔离得“很薄的”容器，并将应用放进容器内即可 。 应用获得的是接近原生的运行性能\n> 传统方式是在硬件层面实现虚拟化，需要有额外的虚拟机管理应用和虚拟机操作系统层。 Docker 容器是在操作系统层面上实现虚拟化，直接复用本地主机的操作系统，因此更加轻量级 \n\n## docker ce与 docker ee区别\n * Docker Engine改为Docker CE(社区版), 它包含了CLI客户端、后台进程/服务以及API。用户像以前以同样的方式获取。\n  docker-ce是docker公司维护的开源项目，是一个基于moby项目的免费的容器产品；\n\n * Docker Data Center改为Docker EE（企业版）\n  docker-ee是docker公司维护的闭源产品，是docker公司的商业产品；\n这些ce和ee版并不影响Docker Compose以及Docker Machine\ndocker-ce project是docker公司维护，docker-ee是闭源的；\n\n要使用免费的docker，从网页docker-ce上获取；\n\n要使用收费的docker，从网页docker-ee上获取\n\n## docker UCP 介绍\n> Docker Universal Control Plane（UCP）是Docker公司在2015年底巴塞罗那的开发者大会上发布的，这是一个跟单信用证，是一个新的Docker支付服务的组合的一部分,旨在帮助运维团队轻松地设置一个集群,使开发人员可以快速部署Dockerized应用。他们构建Docker DataCenter的其中重要的组成部分。\n> UCP集群包含两种节点：\n> Controller: 管理集群，并持久化集群配置\n> Node：运行容器\n\n## 安装curl:\n> * 第一种方法:\n>\t https://curl.haxx.se/download.html\n>\t $ curl-7.69.1.tar.gz\n>\t $ ./configure --prefix=/usr/local/curl\n>\t $ make -j12\n>\t $ make install\n>\t $ ln -s /usr/local/curl/bin/curl /usr/bin\n>\t $ vim ~/.bashrc 添加 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/curl/lib\n>\t $ source ~/.bashrc\n>\t $ curl --version \t\t// 查看curl版本和支持的协议如http, https\n> * 第二种方法(推荐，方便快捷):\n>    $ apt-get update\n>    $ apt-get upgrade\n>    $ apt-get install curl\n>    $ curl --version\n> * 提前设置好系统的proxy如:\n>    export http_proxy=child-prc.intel.com:913\n>    export https_proxy=child-prc.intel.com:913 // https的proxy与上面的http的要一样\n\n## 安装docker:\n>$ apt-get install docker\n>$ apt-get install docker.io\n>\n>$ mkdir -p /etc/systemd/system/docker.service.d\n>$ touch /etc/systemd/system/docker.service.d/http-proxy.conf\n```\n添加如下内容\n[Service]\nEnvironment=\"HTTP_PROXY=http://child-prc.intel.com:913/\"\nEnvironment=\"HTTPS_PROXY=http://child-prc.intel.com:913/\"\n```\n> Additional: 也可以在Docker服务启动配置中增加 --regis七ry-mirror=proxy_URL来指定镜像代理服务地址（如https://registry.docker-en.com)\n\n>$ cd /etc/docker\n>$ touch daemon.json\n>\t {\n>\t\t\"insecure-registries\" :[\"10.239.82.163:5000\"]  // 此文件设置为空, 需要从10.239.82.163这台机器拉镜像时候才需要添加此内容\n>\t }\n>$ systemctl daemon-reload\n>$ systemctl restart docker\n>$ docker search redis\n\n## 安装docker compose:\t\t// 关于此程序说明可以参考 https://www.runoob.com/docker/docker-compose.html\n\t https://github.com/docker/compose/releases\n\t curl -L https://github.com/docker/compose/releases/download/1.25.4/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose\n\t chmod +x /usr/local/bin/docker-compose\n\n## 容器的使用\n\n### 查看所有的容器\n\t$ docker ps -a\n\t$ docker ps -a --no-trunc\t\t// 不截短，全部输出container信息\n\t$ docker inspcet <Container>\t// 查看某个container的详细信息\n\t如果在容器内部。可以用 ps -fe 查看。其中1号进程就是启动命令\n\n### 查询最后一次创建的容器\n\t$ docker ps -l \n\n### 启动容器\n\t$ docker run -it --name ubuntu_container ubuntu /bin/bash\n  + -i: 交互式操作,则让容器的标准输入保持打开.\n  + -t: 终端, 让 Docker 分配一个伪终端（ pseudo－即）并绑定到容器的标准输入上，\n  + ubuntu: ubuntu 镜像。\n  + /bin/bash：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 /bin/bash。\n  当利用 docker [container] run 来创建并启动容器时， Docker 在后台运行的标准操作包括：\n  + 检查本地是否存在指定的镜像，不存在就从公有仓库下载；\n  + 利用镜像创建一个容器，并启动该容器；\n  + 分配一个文件系统给容器，并在只读的镜像层外面挂载一层可读写层 ；\n  + 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去；\n  + 从网桥的地址池配置一个 IP 地址给容器；\n  + 执行用户指定的应用程序；\n  + 执行完毕后容器被自动终止。\n\n### 启动并进入容器\n> $ docker run --name ubuntu_18.04_v1.0 ubuntu_test:18.04 /bin/echo 'hello' // 不加 -it容器执行完echo 'hello'后就退出\n> hello\n> $ docker run -itd --name ubuntu_18.04_v2.0 ubuntu_test:18.04 /bin/bash // 不加参数d容器退出后，就终止运行，最好加上d，容器退出后容器内进程仍然后台执行\n> $ docker exec -it ubuntu_18.04_v2.0 /bin/bash\n> root@1cf8105dbd62:/# ps\n>  PID TTY          TIME CMD\n>    1 pts/0    00:00:00 bash\n>   11 pts/0    00:00:00 ps\n> root@1cf8105dbd62:/#\n> 在容器内用 ps 命令查看进程，可以看到，只运行了 bash 应用，并没有运行其他无关的进程\n> Ctrl+d 或输入 exit 命令来退出容器：\n> root@afBbae53bdd3:/# exit\n> 进入容器后配置好proxy如:\n> $ export http_proxy=child-prc.intel.com:913\n> $ apt-get update\n> $ apt-get install python ......\n\n\n### 停止一个容器\n\t$ docker stop <容器 ID>\n\t停止的容器可以通过 docker restart 重启：\n\t$ docker restart <容器 ID>\n\n### 启动已停止运行的容器\n\t$ docker start b750bbbcfd88 \n\n### 后台运行\n\t$ docker run -itd --name ubuntu-test ubuntu /bin/bash\n  + -d: 指定容器的运行模式.\n  + 容器已启动，但是没登录，后端运行，可通过$ docker ps查看, 再执行 $ docker exec -it <容器ID> /bin/bash 即可进入\n\n### 进入容器\n\t// docker attach 1e560fca3906 \t\t\t\t//  如果从这个容器退出，会导致容器的停止, 不推荐使用\n\t$ docker exec -it 243c32535da7 /bin/bash\t\t// 从这个容器退出，不会导致容器的停止\n\n### 退出终端\n\troot@ed09e4490c57:/# exit\n\n### 导出容器\n * 第一种:\n\t$ docker export a1cb4017f313 > export_ubuntu_container.tar\t\t// 导出容器 1e560fca3906 快照到本地文件 ubuntu.tar。\n * 第二种:\n\t$ docker export -o export_ubuntu_container.tar a1cb4017f313\n之后，可将导出的 tar 文件传输到其他机器上，然后再通过导人命令导入到系统中，实现容器的迁移 \n\n### 导入容器(container)快照到本地image库\n> root@alpha:/home/dockers# cat export_ubuntu_container.tar | docker import - in_container/ubuntu:v1.0\n> sha256:31bfe55fe553047cd3cf513dc7d19ae15e746166685c90d8ac3afac9dcea755b\n> root@alpha:/home/dockers# docker images\n> REPOSITORY              TAG                 IMAGE ID            CREATED             SIZE\n> in_container/ubuntu     v1.0                31bfe55fe553        3 seconds ago       64.2MB\n> ubuntu_test             18.04               a4850ad0370a        About an hour ago   64.2MB\n\n> 既可以使用 $ docker load -i ubuntu_18.04.tar 命令来导入镜像存储文件到本地镜像库，也可以使用 $ cat export_ubuntu_container.tar | docker import - in_container/ubuntu:v1.0 命令来导入一个容器快照到本地镜像库。\n> 这两者的区别在于： 容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积更大。\n> 此外，从容器快照文件导人时可以重新指定标签等元数据信息 \n\n\n### 清理所有终止状态的容器\n\t$ docker container prune\n\n### 删除容器\n\t$ docker rm 1e560fca3906\n\t－f, --force=false ： 是否强行终止并删除一个运行中的容器 ；\n\t－l, --link=false ：删除容器的连接 ，但保留容器；\n\t－v, --volumes=false ：删除容器挂载的数据卷\n\n### 查看容器内的进程，端口映射，统计信息，容器详情, 容器文件变更， 更新容器配置等\n * 查看窑器内进程\n\t$ docker top a1cb4017f313\n\n * 查看容器端口与宿主主机端口映射情况\n\t$ docker port a1cb4017f313 // 或者 $ docker container port a1cb4017f313\n\n * 查看统计信息, 会显示 CPU 、内存、存储、网络等使用情况的统计信息\n\t$ docker stats a1cb4017f313\n\tCONTAINER ID        NAME                CPU %               MEM USAGE / LIMIT    MEM %               NET I/O             BLOCK I/O           PIDS\n\ta1cb4017f313        strange_mendeleev   0.00%               6.23MiB / 7.612GiB   0.08%               22kB / 0B           0B / 4.1kB          1\n\t + －a, -all ：输出所有容器统计信息，默认仅在运行中；\n\t + －format string ：格式化输出信息；\n\t + －no-stream ：不持续输出，默认会自动更新持续实时结果；\n\t + －no-trunc ：不截断输出信息。\n\n * 查看容器文件变更\n\t$ docker [container] diff a1cb4017f313\n\n * 查看容器信息\n\t$ docker inspect a1cb4017f313 // 或者 $ docker container inspect a1cb4017f313\n\n * 更新容器配置\n\t$ docker update --help查看支持的选项\n\t限制总配额为 1 秒，容器 test 所占用时间为 10% ，代码如下所示：\n\t$ docker update --cpu-quota 1000000 test\n\ttest\n\t$ docker update --cpu-period 100000 test\n\ttest\n\t支持的选项包括：\n\t + －blkio-weight uintl6 ：更新块 IO 限制， 10～ 1000 ，默认值为 0 ，代表着无限制；\n\t + －cpu-period int ：限制 CPU 调度器 CFS (Completely Fair Scheduler）使用时间，单位为微秒，最小 1000;\n\t + －cpu-quota int ：限制 CPU 调度器 CFS 配额，单位为微秒，最小 1000;\n\t + －cpu-rt-period int ：限制 CPU 调度器的实时周期，单位为微秒 ；\n\t + －cpu-rt-runtime int ：限制 CPU 调度器的实时运行时，单位为微秒；\n\t + －c, -cpu-shares int ： 限制 CPU 使用份额；\n\t + －cpus decimal ：限制 CPU 个数；\n\t + －cpuset-cpus string ：允许使用的 CPU 核，如 0-3, 0,1;\n\t + －cpuset-mems string ：允许使用的内存块，如 0-3, 0,1;\n\t + －kernel-memory bytes ：限制使用的内核内存；\n\t + －m, -memory bytes ： 限制使用的内存；\n\t + －memory-reservation bytes ：内存软限制；\n\t + －memory-swap bytes ：内存加上缓存区的限制， － 1 表示为对缓冲区无限制；\n\t + －restart stri口g ： 容器退出后的重启策略\n\t$ docker update --cpus 0 a1cb4017f313\n\t$ docker update -c 4 a1cb4017f313\n\t$ docker inspect a1cb4017f313\t// 查看容器信息 \"CpuShares\": 4\n\n### 容器与主机间复制文件\n> 主机上的t1.txt复制到容器ID为 a1cb4017f313 的/home目录\n> $ docker cp t1.txt a1cb4017f313:/home\n> * －a, -archive ：打包模式，复制文件会带有原始的 uid/gid 信息；\n> * －L, -follow-link ：跟随软连接。当原路径为软连接时＼默认只复制链接信息，使用该选项会复制链接的目标内容 。\n\n### 运行一个 web 应用\n\trunoob@runoob:~# docker pull training/webapp  # 载入镜像\n\trunoob@runoob:~# docker run -d -P training/webapp python app.py\n  + -d:让容器在后台运行。\n  + -P:将容器内部使用的网络端口映射到我们使用的主机上。\n   - runoob@runoob:~#  docker ps\n   - CONTAINER ID        IMAGE               COMMAND             ...        PORTS                 \n   - d3d5e39ed9d3        training/webapp     \"python app.py\"     ...        0.0.0.0:32769->5000/tcp\n  + Docker 开放了 5000 端口（默认 Python Flask 端口）映射到主机端口 32769 上。\n  + 这时我们可以通过浏览器访问WEB应用192.168.239.130:32769\n\t可以通过 -p 参数来设置不一样的端口：\n\trunoob@runoob:~$ docker run -d -p 5000:5000 training/webapp python app.py\n\n### 查看 WEB 应用程序日志\n\trunoob@runoob:~$ docker logs -f bf08b7f2cd89\t\t// -f: 让 docker logs 像使用 tail -f 一样来输出容器内部的标准输出。\n\n### 查看WEB应用程序容器的进程\n\trunoob@runoob:~$ docker top wizardly_chandrasekhar\n\n### 查看Docker 容器的配置和状态信息\n\trunoob@runoob:~$ docker inspect wizardly_chandrasekhar\t// 它会返回一个 JSON 文件记录着 Docker 容器的配置和状态信息。\n\n### 停止 WEB 应用容器\n\trunoob@runoob:~$ docker stop wizardly_chandrasekhar\n\n### 重启WEB应用容器\n\trunoob@runoob:~$ docker start wizardly_chandrasekhar\n\n### 移除WEB应用容器\n\trunoob@runoob:~$ docker rm wizardly_chandrasekhar \t\t// 删除不需要的容器, 容器必须是停止状态，否则会报错\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n## 镜像使用\n### 查找镜像\n\tDocker Hub 网址为： https://hub.docker.com/\n\t$ docker search httpd\t\t\t// 使用 docker search 命令来搜索镜像\n\t\n\t* 搜索官方提供的带 nginx关键字的镜像\n\t$ docker search --filter=is-official=true nginx\n\tNAME                DESCRIPTION                STARS               OFFICIAL            AUTOMATED\n\tnginx               Official build of Nginx.   13037               [OK]\n  + NAME: 镜像仓库源的名称\n  + DESCRIPTION: 镜像的描述\n  + STARS: 类似 Github 里面的 star，表示点赞、喜欢的意思。\n  + OFFICIAL: 是否 docker 官方发布\n  + AUTOMATED: 自动构建。\n  \n\t* 搜索所有收藏数超过 4 的关键词包括 tensorow 的镜像\n\t$ docker search --filter=stars=200 tensorflow\n\tNAME                          DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED\n\ttensorflow/tensorflow         Official Docker images for the machine learn…   1662\n\tjupyter/tensorflow-notebook   Jupyter Notebook Scientific Python Stack w/ …   209\n\t\n\t* 搜索所有收藏数超过 4 的关键词包括 tensorow 的镜像的前3个镜像\n\t$ docker search --filter=stars=4 --limit=3 tensorflow\n\tNAME                          DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED\n\ttensorflow/tensorflow         Official Docker images for the machine learn…   1662\n\tjupyter/tensorflow-notebook   Jupyter Notebook Scientific Python Stack w/ …   209\n\ttensorflow/serving            Official images for TensorFlow Serving (http…   83\n\n\n### 列出镜像列表\n\trunoob@runoob:~$ docker images\t\t// 列出本地主机上的镜像\n  + REPOSITORY：表示镜像的仓库源\n  + TAG：镜像的标签\n  + IMAGE ID：镜像ID, 如果两个镜像的ID 相同， 说明它们实际上指向了同一个镜像， 只是具有不同标签名称而已, 其中镜像的ID信息十分重要， 它唯一标识了镜像。在使用镜像ID的时候， 一般可以使用该ID的前若干个字符组成的可区分串来替代完整的ID\n  + CREATED：镜像创建时间\n  + SIZE：镜像大小, 镜像大小信息只是表示了该镜像的逻辑体积大小， 实际上由于相同的镜像层本地只会存储一份， 物理上占用的存储空间会小于各镜像逻辑体积之和\n\t同一仓库源可以有多个 TAG，代表这个仓库源的不同个版本\n   - REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\n   - ubuntu              14.04               90d5884b1ee0        5 days ago          188 MB\n   - php                 5.6                 f40e9e0f10c8        9 days ago          444.8 MB\n   - ubuntu              15.10               4e3b13c8a266        4 weeks ago         136.3 MB\n   - nginx               latest              6f8d099c3adc        12 days ago         182.7 MB\n\trunoob@runoob:~$ docker run -t -i ubuntu:15.10 /bin/bash \t// 使用版本为15.10的ubuntu系统镜像来运行容器\n\t如果你不指定一个镜像的版本标签，例如你只使用 ubuntu，docker 将默认使用 ubuntu:latest 镜像。\n\t-q, --quiet式rueI false: 仅输出ID信息， 默认为否\n\t$ docker images -q=true\n\t273c7fcf9499\n\t0d40868643c6\n\n### 获取镜像, 如果不显式指定TAG, 则默认会选择latest标签，这会下载仓库中最新版本的镜像\n> 严格地讲，镜像的仓库名称中还应该添加仓库地址（即registry, 注册服务器）作为前缀 ，只是默认使用的是官方DockerHub服务 ，该前缀可以忽略。\n> 例如，$ docker pull ubuntu：18.04 命令相当于 $ docker pull registry.hub.docker.com/ubuntu：18.04命令，即从默认的注册服务器DockerHub Registy中的 ubuntu仓库来下载标记为18.04的镜像。\n> 如果从非官方的仓库下载，则需要在仓库名称前指定完整的仓库地址。例如从网易蜂巢的镜像源来下载ubuntu:18.04镜像，可以使用如下命令，此时下载的镜像名称为hub.c.163.com/public/ubuntu:18.04: $ docker pull hub.c.163.com/public/ubuntu:18.04\n> 可以在Docker服务启动配置中增加 --registry-mirror=proxy_URL来指定镜像代理服务地址（如https://registry.docker-en.com)\n\t$ docker pull ubuntu:18.04 // 与下方命令一致,默认使用的是官方DockerHub服务 ，该前缀可以忽略.\n\t$ docker pull registry.hub.docker.com/ubuntu:18.04\n\t$ docker pull mysql:5.7\n> 一般来说， 镜像的latest 标签意味着该镜像的内容会跟踪最新版本的变更而变化, 内容是不稳定的。 因此，从稳定性上考虑，不要在生产环境中忽略镜像的标签信息或使用默认的latest 标记的镜像\n> 如果从非官方 的仓库 下载，则 需要在仓库 名称前指定完整的仓库地址\n\t$ docker pull hub.c.163.com/public/ubuntu:18.04\n\n### 改变标签\n $ docker tag mysql:5.7 my_mysql:5.7.0\n $ docker images\n\tREPOSITORY              TAG                 IMAGE ID            CREATED             SIZE\n\tmy_mysql                5.7.0               273c7fcf9499        4 days ago          455MB\n\tmysql                   5.7                 273c7fcf9499        4 days ago          455MB\n> 它们实际上指向了同一个镜像文件，只是别名不同而巳。docker tag命令添加的标签实际上起到了类似链接的作用\n\n### 查看imgage制作信息\n $ docker inspect mysql:5.7\n 只要其中一项内容时， 可以使用 -f 来指定\n $ docker inspect -f {{\".Architecture\"}} mysql:5.7\n $  docker inspect -f {{\".ContainerConfig\"}} mysql:5.7\n\n### 查看image历史\n $ docker history mysql:5.7\n\n\n\n### 删除镜像\n> -f, -force: 强制删除镜像， 即使有容器依赖它\n> -no-prune: 不要清理未带标签的父镜像\n> $ docker rmi hello-world\n> docker rmi 命令只是删除了该镜像多个标签中的指定标签而巳， 并不影响镜像文件\n> $ docker rmi my_mysql:5.7.0\n> Untagged: my_mysql:5.7.0\n> docker rmi 命令来删除只有一个标签的镜像， 可以看出会删除这个镜像文件的所有文件层\n> 当使用 docker rmi 命令， 并且后面跟上镜像的 ID (也可以是能进行区分的部分 ID 串前缀）时， 会先尝试删除所有指向该镜像的标签， 然后删除该镜像文件本身\n> 当有该镜像创建的容器存在时， 镜像文件默认是无法被删除的, 如果要想强行删除镜像， 可以使用-f参数\n> $ docker rmi -f ubuntu:18.04\n> 通常并不推荐使用-f参数来强制删除一个存在容器依赖的镜像。 正确的做法是，先删除依赖该镜像的所有容器， 再来删除镜像\n> 首先删除容器a21c0840213e:\n> $ docker rm a2lc0840213e\n> 然后使用ID来删除镜像， 此时会正常打印出删除的各层信息：\n> $ docker rmi Bflbd2lbd25c\n\n\n### 清理镜像\n\n\t$ docker image prune\n> -a, -all: 删除所有无用镜像， 不光是临时镜像；\n> -filter filter: 只清理符合给定过滤器的镜像；\n> -f, -force: 强制删除镜像， 而不进行提示确认\n\n### 创建镜像\n * 基于已有容器创建\n\n\n\t$ docker run -itd --name ubuntu18.04_v3.0 ubuntu:18.04 /bin/bash\n\t$ docker exec -it ubuntu18.04_v3.0 /bin/bash\n\troot@e2d52bc5c287:/# cd /home\n\troot@e2d52bc5c287:/home# mkdir test\t\t// 把初始的image创建一个文件夹再导出成新的image\n\troot@e2d52bc5c287:/home# exit\n\troot@alpha:~# docker commit -m \"add test file\" -a \"Docker Newbee\" e2d52bc5c287 test:0.1\n\n\n\t$ docker images\n\tREPOSITORY              TAG                 IMAGE ID            CREATED             SIZE\n\ttest                    0.1                 a4850ad0370a        15 seconds ago      64.2MB\n\tubuntu                  18.04               4e5021d210f6        4 weeks ago         64.2MB\n  + -a, --author=\"\": 作者信息\n  + -c, - -change=(] : 提交的时候执行 Dockerfle指令， 包括 CMD | ENTRYPOINT | ENV | EXPOSE |LABEL | ONBUILD | USER | VOLUME | WORKIR等\n  + -m, - -message=11 11: 提交消息\n  + -p, --pause式rue: 提交时暂停容器运行\n\n * 基于本地模板导入\n\n * 基于 Docke 「file 创建\n\n### 导出和载入镜像\n * 导出镜像\n\n\n $ docker save -o ubuntu_18.04.tar ubuntu:18.04\n * 载入镜像\n\n\n $ docker load -i ubuntu_18.04.tar 或者 docker load < ubuntu_18.04.tar\n\n## 重启docker服务\n\n\t$ service docker restart\n运行以下命令会出错，anyway 运行以上命令就可重启\n\n\t$ systemctl restart docker.service\n\n## docker存储路径\n查看 docker 存储路径\n\n\t$ docker info |grep 'Docker Root Dir'\n\t Docker Root Dir: /var/lib/docker\n修改 docker 存储路径\n\n\t$ vim /etc/docker/daemon.json\n\t{\n\t    \"graph\": \"/home/server/docker\"\n\t}\n\t$ systemctl daemon-reload\n\t$ systemctl restart docker\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※","source":"_posts/technologies/docker/docker_step_01.md","raw":"---\ntitle: docker 01 installation and control commands\ntags: \ncategories:\n- technologies\n- docker\n---\n\n## Docker 引擎\n目前 Docker 支持 Docker 引 擎、 Docker Hub 、 Docker Cloud 等多种服务 。\n * Docker 引擎：包括支持在桌面系统或云平台安装 Docker，以及为企业提供简单安全弹性的容器集群编排和管理；\n * DockerHub ：官方提供的云托管服务，可以提供公有或私有的镜像仓库；\n * DockerCloud ：官方提供的容器云服务，可以完成容器的部署与管理，可以完整地支持容器化项目，还有 CI 、 CD 功能 \n用户可以通过如下命令检查自己的内核版本详细信息 ：\n $ uname -a\n $ cat /proc/version\n\n## Ubuntu18.04 docker环境安装：\n官网: https://www.docker.com/get-started\n查找image: https://hub.docker.com/search?type=image\n\n## 简介\n> Docker 是基于 Go 语言实现的开源容器项目 。 它诞生于 2013 年年初，最初发起者是dotCloud 公司，dotCloud 公司也随之快速发展壮大，在 2013 年年底直接改名为 Docker Inc ，并专注于Docker 相关技术和产品的开发，目前已经成为全球最大的 Docker 容器服务提供商 。 官方网站为 docker.com \n> 在 Linux 基金会最近一次关于“最受欢 迎的 云 计算开源项目”的调查中， Docker 仅次于 2010 年发起的 OpenStack 项目，并仍处于上升趋势 。2014 年， Docker 镜像下载数达到了一百万次， 2015 年直接突破十亿次， 2017 年更是突破了惊人的百亿次\n> Docker 的构想是要实现“ Build , Ship and Run Any App, Anywhere ”，即通过对应用的封装（ Packaging）、分发（ Distribution ）、部署（ Deployment）、运行（ Runtime ）生命周期进行管理，达到应用组件级别的“一次封装 ，到处运行”\n> 与大部分新兴技术的诞生一样， Docker 也并非“从石头缝里蹦出来的”，而是站在前人的肩膀上。 其中最重要的就是 Linux 容器（ Linux Containers, LXC ）技术.\n> 每个容器内运行着一个应用，不同的容器相互隔离，容器之间也可以通过网络互相通信 。 容器的创建和停止十分快速，几乎跟创建和终止原生应用－致.\n> 容器自身对系统资源的额外需求也十分有限，远远低于传统虚拟机。 很多时候，甚至直接把容器当作应用本身也没有任何问题.\n\n## 为什么用Docker\n> 在云时代，开发者创建的应用必须要能很方便地在网络上传播，也就是说应用必须脱离底层物理硬件的限制；同时必须是“任何时间任何地点”可获取的 。 因此，开发者们需要一种新型的创建分布式应用程序的方式，快速分发和部署，而这正是 Docker 所能够提供的最大优势\n> Docker 提供了一种更为聪明的方式，通过容器来打包应用、解藕应用和运行平台。这意味着迁移的时候，只需要在新的服务器上启动需要的容器就可以了，无论新旧服务器是否是同一类型的平台 。 这无疑将帮助我们节约大量的宝贵时间，并降低部署过程出现问题的风险\n> 传统虚拟机方式运行 N 个不同的应用就要启用 N 个虚拟机（每个虚拟机需要单独分配独占的内存、磁盘等资源），而 Docker 只需要启动 N 个隔离得“很薄的”容器，并将应用放进容器内即可 。 应用获得的是接近原生的运行性能\n> 传统方式是在硬件层面实现虚拟化，需要有额外的虚拟机管理应用和虚拟机操作系统层。 Docker 容器是在操作系统层面上实现虚拟化，直接复用本地主机的操作系统，因此更加轻量级 \n\n## docker ce与 docker ee区别\n * Docker Engine改为Docker CE(社区版), 它包含了CLI客户端、后台进程/服务以及API。用户像以前以同样的方式获取。\n  docker-ce是docker公司维护的开源项目，是一个基于moby项目的免费的容器产品；\n\n * Docker Data Center改为Docker EE（企业版）\n  docker-ee是docker公司维护的闭源产品，是docker公司的商业产品；\n这些ce和ee版并不影响Docker Compose以及Docker Machine\ndocker-ce project是docker公司维护，docker-ee是闭源的；\n\n要使用免费的docker，从网页docker-ce上获取；\n\n要使用收费的docker，从网页docker-ee上获取\n\n## docker UCP 介绍\n> Docker Universal Control Plane（UCP）是Docker公司在2015年底巴塞罗那的开发者大会上发布的，这是一个跟单信用证，是一个新的Docker支付服务的组合的一部分,旨在帮助运维团队轻松地设置一个集群,使开发人员可以快速部署Dockerized应用。他们构建Docker DataCenter的其中重要的组成部分。\n> UCP集群包含两种节点：\n> Controller: 管理集群，并持久化集群配置\n> Node：运行容器\n\n## 安装curl:\n> * 第一种方法:\n>\t https://curl.haxx.se/download.html\n>\t $ curl-7.69.1.tar.gz\n>\t $ ./configure --prefix=/usr/local/curl\n>\t $ make -j12\n>\t $ make install\n>\t $ ln -s /usr/local/curl/bin/curl /usr/bin\n>\t $ vim ~/.bashrc 添加 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/curl/lib\n>\t $ source ~/.bashrc\n>\t $ curl --version \t\t// 查看curl版本和支持的协议如http, https\n> * 第二种方法(推荐，方便快捷):\n>    $ apt-get update\n>    $ apt-get upgrade\n>    $ apt-get install curl\n>    $ curl --version\n> * 提前设置好系统的proxy如:\n>    export http_proxy=child-prc.intel.com:913\n>    export https_proxy=child-prc.intel.com:913 // https的proxy与上面的http的要一样\n\n## 安装docker:\n>$ apt-get install docker\n>$ apt-get install docker.io\n>\n>$ mkdir -p /etc/systemd/system/docker.service.d\n>$ touch /etc/systemd/system/docker.service.d/http-proxy.conf\n```\n添加如下内容\n[Service]\nEnvironment=\"HTTP_PROXY=http://child-prc.intel.com:913/\"\nEnvironment=\"HTTPS_PROXY=http://child-prc.intel.com:913/\"\n```\n> Additional: 也可以在Docker服务启动配置中增加 --regis七ry-mirror=proxy_URL来指定镜像代理服务地址（如https://registry.docker-en.com)\n\n>$ cd /etc/docker\n>$ touch daemon.json\n>\t {\n>\t\t\"insecure-registries\" :[\"10.239.82.163:5000\"]  // 此文件设置为空, 需要从10.239.82.163这台机器拉镜像时候才需要添加此内容\n>\t }\n>$ systemctl daemon-reload\n>$ systemctl restart docker\n>$ docker search redis\n\n## 安装docker compose:\t\t// 关于此程序说明可以参考 https://www.runoob.com/docker/docker-compose.html\n\t https://github.com/docker/compose/releases\n\t curl -L https://github.com/docker/compose/releases/download/1.25.4/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose\n\t chmod +x /usr/local/bin/docker-compose\n\n## 容器的使用\n\n### 查看所有的容器\n\t$ docker ps -a\n\t$ docker ps -a --no-trunc\t\t// 不截短，全部输出container信息\n\t$ docker inspcet <Container>\t// 查看某个container的详细信息\n\t如果在容器内部。可以用 ps -fe 查看。其中1号进程就是启动命令\n\n### 查询最后一次创建的容器\n\t$ docker ps -l \n\n### 启动容器\n\t$ docker run -it --name ubuntu_container ubuntu /bin/bash\n  + -i: 交互式操作,则让容器的标准输入保持打开.\n  + -t: 终端, 让 Docker 分配一个伪终端（ pseudo－即）并绑定到容器的标准输入上，\n  + ubuntu: ubuntu 镜像。\n  + /bin/bash：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 /bin/bash。\n  当利用 docker [container] run 来创建并启动容器时， Docker 在后台运行的标准操作包括：\n  + 检查本地是否存在指定的镜像，不存在就从公有仓库下载；\n  + 利用镜像创建一个容器，并启动该容器；\n  + 分配一个文件系统给容器，并在只读的镜像层外面挂载一层可读写层 ；\n  + 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去；\n  + 从网桥的地址池配置一个 IP 地址给容器；\n  + 执行用户指定的应用程序；\n  + 执行完毕后容器被自动终止。\n\n### 启动并进入容器\n> $ docker run --name ubuntu_18.04_v1.0 ubuntu_test:18.04 /bin/echo 'hello' // 不加 -it容器执行完echo 'hello'后就退出\n> hello\n> $ docker run -itd --name ubuntu_18.04_v2.0 ubuntu_test:18.04 /bin/bash // 不加参数d容器退出后，就终止运行，最好加上d，容器退出后容器内进程仍然后台执行\n> $ docker exec -it ubuntu_18.04_v2.0 /bin/bash\n> root@1cf8105dbd62:/# ps\n>  PID TTY          TIME CMD\n>    1 pts/0    00:00:00 bash\n>   11 pts/0    00:00:00 ps\n> root@1cf8105dbd62:/#\n> 在容器内用 ps 命令查看进程，可以看到，只运行了 bash 应用，并没有运行其他无关的进程\n> Ctrl+d 或输入 exit 命令来退出容器：\n> root@afBbae53bdd3:/# exit\n> 进入容器后配置好proxy如:\n> $ export http_proxy=child-prc.intel.com:913\n> $ apt-get update\n> $ apt-get install python ......\n\n\n### 停止一个容器\n\t$ docker stop <容器 ID>\n\t停止的容器可以通过 docker restart 重启：\n\t$ docker restart <容器 ID>\n\n### 启动已停止运行的容器\n\t$ docker start b750bbbcfd88 \n\n### 后台运行\n\t$ docker run -itd --name ubuntu-test ubuntu /bin/bash\n  + -d: 指定容器的运行模式.\n  + 容器已启动，但是没登录，后端运行，可通过$ docker ps查看, 再执行 $ docker exec -it <容器ID> /bin/bash 即可进入\n\n### 进入容器\n\t// docker attach 1e560fca3906 \t\t\t\t//  如果从这个容器退出，会导致容器的停止, 不推荐使用\n\t$ docker exec -it 243c32535da7 /bin/bash\t\t// 从这个容器退出，不会导致容器的停止\n\n### 退出终端\n\troot@ed09e4490c57:/# exit\n\n### 导出容器\n * 第一种:\n\t$ docker export a1cb4017f313 > export_ubuntu_container.tar\t\t// 导出容器 1e560fca3906 快照到本地文件 ubuntu.tar。\n * 第二种:\n\t$ docker export -o export_ubuntu_container.tar a1cb4017f313\n之后，可将导出的 tar 文件传输到其他机器上，然后再通过导人命令导入到系统中，实现容器的迁移 \n\n### 导入容器(container)快照到本地image库\n> root@alpha:/home/dockers# cat export_ubuntu_container.tar | docker import - in_container/ubuntu:v1.0\n> sha256:31bfe55fe553047cd3cf513dc7d19ae15e746166685c90d8ac3afac9dcea755b\n> root@alpha:/home/dockers# docker images\n> REPOSITORY              TAG                 IMAGE ID            CREATED             SIZE\n> in_container/ubuntu     v1.0                31bfe55fe553        3 seconds ago       64.2MB\n> ubuntu_test             18.04               a4850ad0370a        About an hour ago   64.2MB\n\n> 既可以使用 $ docker load -i ubuntu_18.04.tar 命令来导入镜像存储文件到本地镜像库，也可以使用 $ cat export_ubuntu_container.tar | docker import - in_container/ubuntu:v1.0 命令来导入一个容器快照到本地镜像库。\n> 这两者的区别在于： 容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积更大。\n> 此外，从容器快照文件导人时可以重新指定标签等元数据信息 \n\n\n### 清理所有终止状态的容器\n\t$ docker container prune\n\n### 删除容器\n\t$ docker rm 1e560fca3906\n\t－f, --force=false ： 是否强行终止并删除一个运行中的容器 ；\n\t－l, --link=false ：删除容器的连接 ，但保留容器；\n\t－v, --volumes=false ：删除容器挂载的数据卷\n\n### 查看容器内的进程，端口映射，统计信息，容器详情, 容器文件变更， 更新容器配置等\n * 查看窑器内进程\n\t$ docker top a1cb4017f313\n\n * 查看容器端口与宿主主机端口映射情况\n\t$ docker port a1cb4017f313 // 或者 $ docker container port a1cb4017f313\n\n * 查看统计信息, 会显示 CPU 、内存、存储、网络等使用情况的统计信息\n\t$ docker stats a1cb4017f313\n\tCONTAINER ID        NAME                CPU %               MEM USAGE / LIMIT    MEM %               NET I/O             BLOCK I/O           PIDS\n\ta1cb4017f313        strange_mendeleev   0.00%               6.23MiB / 7.612GiB   0.08%               22kB / 0B           0B / 4.1kB          1\n\t + －a, -all ：输出所有容器统计信息，默认仅在运行中；\n\t + －format string ：格式化输出信息；\n\t + －no-stream ：不持续输出，默认会自动更新持续实时结果；\n\t + －no-trunc ：不截断输出信息。\n\n * 查看容器文件变更\n\t$ docker [container] diff a1cb4017f313\n\n * 查看容器信息\n\t$ docker inspect a1cb4017f313 // 或者 $ docker container inspect a1cb4017f313\n\n * 更新容器配置\n\t$ docker update --help查看支持的选项\n\t限制总配额为 1 秒，容器 test 所占用时间为 10% ，代码如下所示：\n\t$ docker update --cpu-quota 1000000 test\n\ttest\n\t$ docker update --cpu-period 100000 test\n\ttest\n\t支持的选项包括：\n\t + －blkio-weight uintl6 ：更新块 IO 限制， 10～ 1000 ，默认值为 0 ，代表着无限制；\n\t + －cpu-period int ：限制 CPU 调度器 CFS (Completely Fair Scheduler）使用时间，单位为微秒，最小 1000;\n\t + －cpu-quota int ：限制 CPU 调度器 CFS 配额，单位为微秒，最小 1000;\n\t + －cpu-rt-period int ：限制 CPU 调度器的实时周期，单位为微秒 ；\n\t + －cpu-rt-runtime int ：限制 CPU 调度器的实时运行时，单位为微秒；\n\t + －c, -cpu-shares int ： 限制 CPU 使用份额；\n\t + －cpus decimal ：限制 CPU 个数；\n\t + －cpuset-cpus string ：允许使用的 CPU 核，如 0-3, 0,1;\n\t + －cpuset-mems string ：允许使用的内存块，如 0-3, 0,1;\n\t + －kernel-memory bytes ：限制使用的内核内存；\n\t + －m, -memory bytes ： 限制使用的内存；\n\t + －memory-reservation bytes ：内存软限制；\n\t + －memory-swap bytes ：内存加上缓存区的限制， － 1 表示为对缓冲区无限制；\n\t + －restart stri口g ： 容器退出后的重启策略\n\t$ docker update --cpus 0 a1cb4017f313\n\t$ docker update -c 4 a1cb4017f313\n\t$ docker inspect a1cb4017f313\t// 查看容器信息 \"CpuShares\": 4\n\n### 容器与主机间复制文件\n> 主机上的t1.txt复制到容器ID为 a1cb4017f313 的/home目录\n> $ docker cp t1.txt a1cb4017f313:/home\n> * －a, -archive ：打包模式，复制文件会带有原始的 uid/gid 信息；\n> * －L, -follow-link ：跟随软连接。当原路径为软连接时＼默认只复制链接信息，使用该选项会复制链接的目标内容 。\n\n### 运行一个 web 应用\n\trunoob@runoob:~# docker pull training/webapp  # 载入镜像\n\trunoob@runoob:~# docker run -d -P training/webapp python app.py\n  + -d:让容器在后台运行。\n  + -P:将容器内部使用的网络端口映射到我们使用的主机上。\n   - runoob@runoob:~#  docker ps\n   - CONTAINER ID        IMAGE               COMMAND             ...        PORTS                 \n   - d3d5e39ed9d3        training/webapp     \"python app.py\"     ...        0.0.0.0:32769->5000/tcp\n  + Docker 开放了 5000 端口（默认 Python Flask 端口）映射到主机端口 32769 上。\n  + 这时我们可以通过浏览器访问WEB应用192.168.239.130:32769\n\t可以通过 -p 参数来设置不一样的端口：\n\trunoob@runoob:~$ docker run -d -p 5000:5000 training/webapp python app.py\n\n### 查看 WEB 应用程序日志\n\trunoob@runoob:~$ docker logs -f bf08b7f2cd89\t\t// -f: 让 docker logs 像使用 tail -f 一样来输出容器内部的标准输出。\n\n### 查看WEB应用程序容器的进程\n\trunoob@runoob:~$ docker top wizardly_chandrasekhar\n\n### 查看Docker 容器的配置和状态信息\n\trunoob@runoob:~$ docker inspect wizardly_chandrasekhar\t// 它会返回一个 JSON 文件记录着 Docker 容器的配置和状态信息。\n\n### 停止 WEB 应用容器\n\trunoob@runoob:~$ docker stop wizardly_chandrasekhar\n\n### 重启WEB应用容器\n\trunoob@runoob:~$ docker start wizardly_chandrasekhar\n\n### 移除WEB应用容器\n\trunoob@runoob:~$ docker rm wizardly_chandrasekhar \t\t// 删除不需要的容器, 容器必须是停止状态，否则会报错\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n## 镜像使用\n### 查找镜像\n\tDocker Hub 网址为： https://hub.docker.com/\n\t$ docker search httpd\t\t\t// 使用 docker search 命令来搜索镜像\n\t\n\t* 搜索官方提供的带 nginx关键字的镜像\n\t$ docker search --filter=is-official=true nginx\n\tNAME                DESCRIPTION                STARS               OFFICIAL            AUTOMATED\n\tnginx               Official build of Nginx.   13037               [OK]\n  + NAME: 镜像仓库源的名称\n  + DESCRIPTION: 镜像的描述\n  + STARS: 类似 Github 里面的 star，表示点赞、喜欢的意思。\n  + OFFICIAL: 是否 docker 官方发布\n  + AUTOMATED: 自动构建。\n  \n\t* 搜索所有收藏数超过 4 的关键词包括 tensorow 的镜像\n\t$ docker search --filter=stars=200 tensorflow\n\tNAME                          DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED\n\ttensorflow/tensorflow         Official Docker images for the machine learn…   1662\n\tjupyter/tensorflow-notebook   Jupyter Notebook Scientific Python Stack w/ …   209\n\t\n\t* 搜索所有收藏数超过 4 的关键词包括 tensorow 的镜像的前3个镜像\n\t$ docker search --filter=stars=4 --limit=3 tensorflow\n\tNAME                          DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED\n\ttensorflow/tensorflow         Official Docker images for the machine learn…   1662\n\tjupyter/tensorflow-notebook   Jupyter Notebook Scientific Python Stack w/ …   209\n\ttensorflow/serving            Official images for TensorFlow Serving (http…   83\n\n\n### 列出镜像列表\n\trunoob@runoob:~$ docker images\t\t// 列出本地主机上的镜像\n  + REPOSITORY：表示镜像的仓库源\n  + TAG：镜像的标签\n  + IMAGE ID：镜像ID, 如果两个镜像的ID 相同， 说明它们实际上指向了同一个镜像， 只是具有不同标签名称而已, 其中镜像的ID信息十分重要， 它唯一标识了镜像。在使用镜像ID的时候， 一般可以使用该ID的前若干个字符组成的可区分串来替代完整的ID\n  + CREATED：镜像创建时间\n  + SIZE：镜像大小, 镜像大小信息只是表示了该镜像的逻辑体积大小， 实际上由于相同的镜像层本地只会存储一份， 物理上占用的存储空间会小于各镜像逻辑体积之和\n\t同一仓库源可以有多个 TAG，代表这个仓库源的不同个版本\n   - REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\n   - ubuntu              14.04               90d5884b1ee0        5 days ago          188 MB\n   - php                 5.6                 f40e9e0f10c8        9 days ago          444.8 MB\n   - ubuntu              15.10               4e3b13c8a266        4 weeks ago         136.3 MB\n   - nginx               latest              6f8d099c3adc        12 days ago         182.7 MB\n\trunoob@runoob:~$ docker run -t -i ubuntu:15.10 /bin/bash \t// 使用版本为15.10的ubuntu系统镜像来运行容器\n\t如果你不指定一个镜像的版本标签，例如你只使用 ubuntu，docker 将默认使用 ubuntu:latest 镜像。\n\t-q, --quiet式rueI false: 仅输出ID信息， 默认为否\n\t$ docker images -q=true\n\t273c7fcf9499\n\t0d40868643c6\n\n### 获取镜像, 如果不显式指定TAG, 则默认会选择latest标签，这会下载仓库中最新版本的镜像\n> 严格地讲，镜像的仓库名称中还应该添加仓库地址（即registry, 注册服务器）作为前缀 ，只是默认使用的是官方DockerHub服务 ，该前缀可以忽略。\n> 例如，$ docker pull ubuntu：18.04 命令相当于 $ docker pull registry.hub.docker.com/ubuntu：18.04命令，即从默认的注册服务器DockerHub Registy中的 ubuntu仓库来下载标记为18.04的镜像。\n> 如果从非官方的仓库下载，则需要在仓库名称前指定完整的仓库地址。例如从网易蜂巢的镜像源来下载ubuntu:18.04镜像，可以使用如下命令，此时下载的镜像名称为hub.c.163.com/public/ubuntu:18.04: $ docker pull hub.c.163.com/public/ubuntu:18.04\n> 可以在Docker服务启动配置中增加 --registry-mirror=proxy_URL来指定镜像代理服务地址（如https://registry.docker-en.com)\n\t$ docker pull ubuntu:18.04 // 与下方命令一致,默认使用的是官方DockerHub服务 ，该前缀可以忽略.\n\t$ docker pull registry.hub.docker.com/ubuntu:18.04\n\t$ docker pull mysql:5.7\n> 一般来说， 镜像的latest 标签意味着该镜像的内容会跟踪最新版本的变更而变化, 内容是不稳定的。 因此，从稳定性上考虑，不要在生产环境中忽略镜像的标签信息或使用默认的latest 标记的镜像\n> 如果从非官方 的仓库 下载，则 需要在仓库 名称前指定完整的仓库地址\n\t$ docker pull hub.c.163.com/public/ubuntu:18.04\n\n### 改变标签\n $ docker tag mysql:5.7 my_mysql:5.7.0\n $ docker images\n\tREPOSITORY              TAG                 IMAGE ID            CREATED             SIZE\n\tmy_mysql                5.7.0               273c7fcf9499        4 days ago          455MB\n\tmysql                   5.7                 273c7fcf9499        4 days ago          455MB\n> 它们实际上指向了同一个镜像文件，只是别名不同而巳。docker tag命令添加的标签实际上起到了类似链接的作用\n\n### 查看imgage制作信息\n $ docker inspect mysql:5.7\n 只要其中一项内容时， 可以使用 -f 来指定\n $ docker inspect -f {{\".Architecture\"}} mysql:5.7\n $  docker inspect -f {{\".ContainerConfig\"}} mysql:5.7\n\n### 查看image历史\n $ docker history mysql:5.7\n\n\n\n### 删除镜像\n> -f, -force: 强制删除镜像， 即使有容器依赖它\n> -no-prune: 不要清理未带标签的父镜像\n> $ docker rmi hello-world\n> docker rmi 命令只是删除了该镜像多个标签中的指定标签而巳， 并不影响镜像文件\n> $ docker rmi my_mysql:5.7.0\n> Untagged: my_mysql:5.7.0\n> docker rmi 命令来删除只有一个标签的镜像， 可以看出会删除这个镜像文件的所有文件层\n> 当使用 docker rmi 命令， 并且后面跟上镜像的 ID (也可以是能进行区分的部分 ID 串前缀）时， 会先尝试删除所有指向该镜像的标签， 然后删除该镜像文件本身\n> 当有该镜像创建的容器存在时， 镜像文件默认是无法被删除的, 如果要想强行删除镜像， 可以使用-f参数\n> $ docker rmi -f ubuntu:18.04\n> 通常并不推荐使用-f参数来强制删除一个存在容器依赖的镜像。 正确的做法是，先删除依赖该镜像的所有容器， 再来删除镜像\n> 首先删除容器a21c0840213e:\n> $ docker rm a2lc0840213e\n> 然后使用ID来删除镜像， 此时会正常打印出删除的各层信息：\n> $ docker rmi Bflbd2lbd25c\n\n\n### 清理镜像\n\n\t$ docker image prune\n> -a, -all: 删除所有无用镜像， 不光是临时镜像；\n> -filter filter: 只清理符合给定过滤器的镜像；\n> -f, -force: 强制删除镜像， 而不进行提示确认\n\n### 创建镜像\n * 基于已有容器创建\n\n\n\t$ docker run -itd --name ubuntu18.04_v3.0 ubuntu:18.04 /bin/bash\n\t$ docker exec -it ubuntu18.04_v3.0 /bin/bash\n\troot@e2d52bc5c287:/# cd /home\n\troot@e2d52bc5c287:/home# mkdir test\t\t// 把初始的image创建一个文件夹再导出成新的image\n\troot@e2d52bc5c287:/home# exit\n\troot@alpha:~# docker commit -m \"add test file\" -a \"Docker Newbee\" e2d52bc5c287 test:0.1\n\n\n\t$ docker images\n\tREPOSITORY              TAG                 IMAGE ID            CREATED             SIZE\n\ttest                    0.1                 a4850ad0370a        15 seconds ago      64.2MB\n\tubuntu                  18.04               4e5021d210f6        4 weeks ago         64.2MB\n  + -a, --author=\"\": 作者信息\n  + -c, - -change=(] : 提交的时候执行 Dockerfle指令， 包括 CMD | ENTRYPOINT | ENV | EXPOSE |LABEL | ONBUILD | USER | VOLUME | WORKIR等\n  + -m, - -message=11 11: 提交消息\n  + -p, --pause式rue: 提交时暂停容器运行\n\n * 基于本地模板导入\n\n * 基于 Docke 「file 创建\n\n### 导出和载入镜像\n * 导出镜像\n\n\n $ docker save -o ubuntu_18.04.tar ubuntu:18.04\n * 载入镜像\n\n\n $ docker load -i ubuntu_18.04.tar 或者 docker load < ubuntu_18.04.tar\n\n## 重启docker服务\n\n\t$ service docker restart\n运行以下命令会出错，anyway 运行以上命令就可重启\n\n\t$ systemctl restart docker.service\n\n## docker存储路径\n查看 docker 存储路径\n\n\t$ docker info |grep 'Docker Root Dir'\n\t Docker Root Dir: /var/lib/docker\n修改 docker 存储路径\n\n\t$ vim /etc/docker/daemon.json\n\t{\n\t    \"graph\": \"/home/server/docker\"\n\t}\n\t$ systemctl daemon-reload\n\t$ systemctl restart docker\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※","slug":"technologies/docker/docker_step_01","published":1,"date":"2020-08-12T16:05:48.515Z","updated":"2020-08-13T13:59:03.293Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmlo008nhohxc36c95br","content":"<h2 id=\"Docker-引擎\"><a href=\"#Docker-引擎\" class=\"headerlink\" title=\"Docker 引擎\"></a>Docker 引擎</h2><p>目前 Docker 支持 Docker 引 擎、 Docker Hub 、 Docker Cloud 等多种服务 。</p>\n<ul>\n<li>Docker 引擎：包括支持在桌面系统或云平台安装 Docker，以及为企业提供简单安全弹性的容器集群编排和管理；</li>\n<li>DockerHub ：官方提供的云托管服务，可以提供公有或私有的镜像仓库；</li>\n<li>DockerCloud ：官方提供的容器云服务，可以完成容器的部署与管理，可以完整地支持容器化项目，还有 CI 、 CD 功能<br>用户可以通过如下命令检查自己的内核版本详细信息 ：<br>$ uname -a<br>$ cat /proc/version</li>\n</ul>\n<h2 id=\"Ubuntu18-04-docker环境安装：\"><a href=\"#Ubuntu18-04-docker环境安装：\" class=\"headerlink\" title=\"Ubuntu18.04 docker环境安装：\"></a>Ubuntu18.04 docker环境安装：</h2><p>官网: <a href=\"https://www.docker.com/get-started\" target=\"_blank\" rel=\"noopener\">https://www.docker.com/get-started</a><br>查找image: <a href=\"https://hub.docker.com/search?type=image\" target=\"_blank\" rel=\"noopener\">https://hub.docker.com/search?type=image</a></p>\n<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><blockquote>\n<p>Docker 是基于 Go 语言实现的开源容器项目 。 它诞生于 2013 年年初，最初发起者是dotCloud 公司，dotCloud 公司也随之快速发展壮大，在 2013 年年底直接改名为 Docker Inc ，并专注于Docker 相关技术和产品的开发，目前已经成为全球最大的 Docker 容器服务提供商 。 官方网站为 docker.com<br>在 Linux 基金会最近一次关于“最受欢 迎的 云 计算开源项目”的调查中， Docker 仅次于 2010 年发起的 OpenStack 项目，并仍处于上升趋势 。2014 年， Docker 镜像下载数达到了一百万次， 2015 年直接突破十亿次， 2017 年更是突破了惊人的百亿次<br>Docker 的构想是要实现“ Build , Ship and Run Any App, Anywhere ”，即通过对应用的封装（ Packaging）、分发（ Distribution ）、部署（ Deployment）、运行（ Runtime ）生命周期进行管理，达到应用组件级别的“一次封装 ，到处运行”<br>与大部分新兴技术的诞生一样， Docker 也并非“从石头缝里蹦出来的”，而是站在前人的肩膀上。 其中最重要的就是 Linux 容器（ Linux Containers, LXC ）技术.<br>每个容器内运行着一个应用，不同的容器相互隔离，容器之间也可以通过网络互相通信 。 容器的创建和停止十分快速，几乎跟创建和终止原生应用－致.<br>容器自身对系统资源的额外需求也十分有限，远远低于传统虚拟机。 很多时候，甚至直接把容器当作应用本身也没有任何问题.</p>\n</blockquote>\n<h2 id=\"为什么用Docker\"><a href=\"#为什么用Docker\" class=\"headerlink\" title=\"为什么用Docker\"></a>为什么用Docker</h2><blockquote>\n<p>在云时代，开发者创建的应用必须要能很方便地在网络上传播，也就是说应用必须脱离底层物理硬件的限制；同时必须是“任何时间任何地点”可获取的 。 因此，开发者们需要一种新型的创建分布式应用程序的方式，快速分发和部署，而这正是 Docker 所能够提供的最大优势<br>Docker 提供了一种更为聪明的方式，通过容器来打包应用、解藕应用和运行平台。这意味着迁移的时候，只需要在新的服务器上启动需要的容器就可以了，无论新旧服务器是否是同一类型的平台 。 这无疑将帮助我们节约大量的宝贵时间，并降低部署过程出现问题的风险<br>传统虚拟机方式运行 N 个不同的应用就要启用 N 个虚拟机（每个虚拟机需要单独分配独占的内存、磁盘等资源），而 Docker 只需要启动 N 个隔离得“很薄的”容器，并将应用放进容器内即可 。 应用获得的是接近原生的运行性能<br>传统方式是在硬件层面实现虚拟化，需要有额外的虚拟机管理应用和虚拟机操作系统层。 Docker 容器是在操作系统层面上实现虚拟化，直接复用本地主机的操作系统，因此更加轻量级 </p>\n</blockquote>\n<h2 id=\"docker-ce与-docker-ee区别\"><a href=\"#docker-ce与-docker-ee区别\" class=\"headerlink\" title=\"docker ce与 docker ee区别\"></a>docker ce与 docker ee区别</h2><ul>\n<li><p>Docker Engine改为Docker CE(社区版), 它包含了CLI客户端、后台进程/服务以及API。用户像以前以同样的方式获取。<br>docker-ce是docker公司维护的开源项目，是一个基于moby项目的免费的容器产品；</p>\n</li>\n<li><p>Docker Data Center改为Docker EE（企业版）<br>docker-ee是docker公司维护的闭源产品，是docker公司的商业产品；<br>这些ce和ee版并不影响Docker Compose以及Docker Machine<br>docker-ce project是docker公司维护，docker-ee是闭源的；</p>\n</li>\n</ul>\n<p>要使用免费的docker，从网页docker-ce上获取；</p>\n<p>要使用收费的docker，从网页docker-ee上获取</p>\n<h2 id=\"docker-UCP-介绍\"><a href=\"#docker-UCP-介绍\" class=\"headerlink\" title=\"docker UCP 介绍\"></a>docker UCP 介绍</h2><blockquote>\n<p>Docker Universal Control Plane（UCP）是Docker公司在2015年底巴塞罗那的开发者大会上发布的，这是一个跟单信用证，是一个新的Docker支付服务的组合的一部分,旨在帮助运维团队轻松地设置一个集群,使开发人员可以快速部署Dockerized应用。他们构建Docker DataCenter的其中重要的组成部分。<br>UCP集群包含两种节点：<br>Controller: 管理集群，并持久化集群配置<br>Node：运行容器</p>\n</blockquote>\n<h2 id=\"安装curl\"><a href=\"#安装curl\" class=\"headerlink\" title=\"安装curl:\"></a>安装curl:</h2><blockquote>\n<ul>\n<li>第一种方法:<br>  <a href=\"https://curl.haxx.se/download.html\" target=\"_blank\" rel=\"noopener\">https://curl.haxx.se/download.html</a><br>  $ curl-7.69.1.tar.gz<br>  $ ./configure –prefix=/usr/local/curl<br>  $ make -j12<br>  $ make install<br>  $ ln -s /usr/local/curl/bin/curl /usr/bin<br>  $ vim ~/.bashrc 添加 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/curl/lib<br>  $ source ~/.bashrc<br>  $ curl –version         // 查看curl版本和支持的协议如http, https</li>\n<li>第二种方法(推荐，方便快捷):<br> $ apt-get update<br> $ apt-get upgrade<br> $ apt-get install curl<br> $ curl –version</li>\n<li>提前设置好系统的proxy如:<br> export http_proxy=child-prc.intel.com:913<br> export https_proxy=child-prc.intel.com:913 // https的proxy与上面的http的要一样</li>\n</ul>\n</blockquote>\n<h2 id=\"安装docker\"><a href=\"#安装docker\" class=\"headerlink\" title=\"安装docker:\"></a>安装docker:</h2><blockquote>\n<p>$ apt-get install docker<br>$ apt-get install docker.io</p>\n<p>$ mkdir -p /etc/systemd/system/docker.service.d<br>$ touch /etc/systemd/system/docker.service.d/http-proxy.conf</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">添加如下内容</span><br><span class=\"line\">[Service]</span><br><span class=\"line\">Environment&#x3D;&quot;HTTP_PROXY&#x3D;http:&#x2F;&#x2F;child-prc.intel.com:913&#x2F;&quot;</span><br><span class=\"line\">Environment&#x3D;&quot;HTTPS_PROXY&#x3D;http:&#x2F;&#x2F;child-prc.intel.com:913&#x2F;&quot;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>Additional: 也可以在Docker服务启动配置中增加 –regis七ry-mirror=proxy_URL来指定镜像代理服务地址（如<a href=\"https://registry.docker-en.com\" target=\"_blank\" rel=\"noopener\">https://registry.docker-en.com</a>)</p>\n</blockquote>\n<blockquote>\n<p>$ cd /etc/docker<br>$ touch daemon.json<br>    {<br>       “insecure-registries” :[“10.239.82.163:5000”]  // 此文件设置为空, 需要从10.239.82.163这台机器拉镜像时候才需要添加此内容<br>    }<br>$ systemctl daemon-reload<br>$ systemctl restart docker<br>$ docker search redis</p>\n</blockquote>\n<h2 id=\"安装docker-compose-关于此程序说明可以参考-https-www-runoob-com-docker-docker-compose-html\"><a href=\"#安装docker-compose-关于此程序说明可以参考-https-www-runoob-com-docker-docker-compose-html\" class=\"headerlink\" title=\"安装docker compose:        // 关于此程序说明可以参考 https://www.runoob.com/docker/docker-compose.html\"></a>安装docker compose:        // 关于此程序说明可以参考 <a href=\"https://www.runoob.com/docker/docker-compose.html\" target=\"_blank\" rel=\"noopener\">https://www.runoob.com/docker/docker-compose.html</a></h2><pre><code>https://github.com/docker/compose/releases\ncurl -L https://github.com/docker/compose/releases/download/1.25.4/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose\nchmod +x /usr/local/bin/docker-compose</code></pre><h2 id=\"容器的使用\"><a href=\"#容器的使用\" class=\"headerlink\" title=\"容器的使用\"></a>容器的使用</h2><h3 id=\"查看所有的容器\"><a href=\"#查看所有的容器\" class=\"headerlink\" title=\"查看所有的容器\"></a>查看所有的容器</h3><pre><code>$ docker ps -a\n$ docker ps -a --no-trunc        // 不截短，全部输出container信息\n$ docker inspcet &lt;Container&gt;    // 查看某个container的详细信息\n如果在容器内部。可以用 ps -fe 查看。其中1号进程就是启动命令</code></pre><h3 id=\"查询最后一次创建的容器\"><a href=\"#查询最后一次创建的容器\" class=\"headerlink\" title=\"查询最后一次创建的容器\"></a>查询最后一次创建的容器</h3><pre><code>$ docker ps -l </code></pre><h3 id=\"启动容器\"><a href=\"#启动容器\" class=\"headerlink\" title=\"启动容器\"></a>启动容器</h3><pre><code>$ docker run -it --name ubuntu_container ubuntu /bin/bash</code></pre><ul>\n<li>-i: 交互式操作,则让容器的标准输入保持打开.</li>\n<li>-t: 终端, 让 Docker 分配一个伪终端（ pseudo－即）并绑定到容器的标准输入上，</li>\n<li>ubuntu: ubuntu 镜像。</li>\n<li>/bin/bash：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 /bin/bash。<br>当利用 docker [container] run 来创建并启动容器时， Docker 在后台运行的标准操作包括：</li>\n<li>检查本地是否存在指定的镜像，不存在就从公有仓库下载；</li>\n<li>利用镜像创建一个容器，并启动该容器；</li>\n<li>分配一个文件系统给容器，并在只读的镜像层外面挂载一层可读写层 ；</li>\n<li>从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去；</li>\n<li>从网桥的地址池配置一个 IP 地址给容器；</li>\n<li>执行用户指定的应用程序；</li>\n<li>执行完毕后容器被自动终止。</li>\n</ul>\n<h3 id=\"启动并进入容器\"><a href=\"#启动并进入容器\" class=\"headerlink\" title=\"启动并进入容器\"></a>启动并进入容器</h3><blockquote>\n<p>$ docker run –name ubuntu_18.04_v1.0 ubuntu_test:18.04 /bin/echo ‘hello’ // 不加 -it容器执行完echo ‘hello’后就退出<br>hello<br>$ docker run -itd –name ubuntu_18.04_v2.0 ubuntu_test:18.04 /bin/bash // 不加参数d容器退出后，就终止运行，最好加上d，容器退出后容器内进程仍然后台执行<br>$ docker exec -it ubuntu_18.04_v2.0 /bin/bash<br>root@1cf8105dbd62:/# ps<br> PID TTY          TIME CMD<br>   1 pts/0    00:00:00 bash<br>  11 pts/0    00:00:00 ps<br>root@1cf8105dbd62:/#<br>在容器内用 ps 命令查看进程，可以看到，只运行了 bash 应用，并没有运行其他无关的进程<br>Ctrl+d 或输入 exit 命令来退出容器：<br>root@afBbae53bdd3:/# exit<br>进入容器后配置好proxy如:<br>$ export http_proxy=child-prc.intel.com:913<br>$ apt-get update<br>$ apt-get install python ……</p>\n</blockquote>\n<h3 id=\"停止一个容器\"><a href=\"#停止一个容器\" class=\"headerlink\" title=\"停止一个容器\"></a>停止一个容器</h3><pre><code>$ docker stop &lt;容器 ID&gt;\n停止的容器可以通过 docker restart 重启：\n$ docker restart &lt;容器 ID&gt;</code></pre><h3 id=\"启动已停止运行的容器\"><a href=\"#启动已停止运行的容器\" class=\"headerlink\" title=\"启动已停止运行的容器\"></a>启动已停止运行的容器</h3><pre><code>$ docker start b750bbbcfd88 </code></pre><h3 id=\"后台运行\"><a href=\"#后台运行\" class=\"headerlink\" title=\"后台运行\"></a>后台运行</h3><pre><code>$ docker run -itd --name ubuntu-test ubuntu /bin/bash</code></pre><ul>\n<li>-d: 指定容器的运行模式.</li>\n<li>容器已启动，但是没登录，后端运行，可通过$ docker ps查看, 再执行 $ docker exec -it &lt;容器ID&gt; /bin/bash 即可进入</li>\n</ul>\n<h3 id=\"进入容器\"><a href=\"#进入容器\" class=\"headerlink\" title=\"进入容器\"></a>进入容器</h3><pre><code>// docker attach 1e560fca3906                 //  如果从这个容器退出，会导致容器的停止, 不推荐使用\n$ docker exec -it 243c32535da7 /bin/bash        // 从这个容器退出，不会导致容器的停止</code></pre><h3 id=\"退出终端\"><a href=\"#退出终端\" class=\"headerlink\" title=\"退出终端\"></a>退出终端</h3><pre><code>root@ed09e4490c57:/# exit</code></pre><h3 id=\"导出容器\"><a href=\"#导出容器\" class=\"headerlink\" title=\"导出容器\"></a>导出容器</h3><ul>\n<li>第一种:<br> $ docker export a1cb4017f313 &gt; export_ubuntu_container.tar        // 导出容器 1e560fca3906 快照到本地文件 ubuntu.tar。</li>\n<li>第二种:<br> $ docker export -o export_ubuntu_container.tar a1cb4017f313<br>之后，可将导出的 tar 文件传输到其他机器上，然后再通过导人命令导入到系统中，实现容器的迁移 </li>\n</ul>\n<h3 id=\"导入容器-container-快照到本地image库\"><a href=\"#导入容器-container-快照到本地image库\" class=\"headerlink\" title=\"导入容器(container)快照到本地image库\"></a>导入容器(container)快照到本地image库</h3><blockquote>\n<p>root@alpha:/home/dockers# cat export_ubuntu_container.tar | docker import - in_container/ubuntu:v1.0<br>sha256:31bfe55fe553047cd3cf513dc7d19ae15e746166685c90d8ac3afac9dcea755b<br>root@alpha:/home/dockers# docker images<br>REPOSITORY              TAG                 IMAGE ID            CREATED             SIZE<br>in_container/ubuntu     v1.0                31bfe55fe553        3 seconds ago       64.2MB<br>ubuntu_test             18.04               a4850ad0370a        About an hour ago   64.2MB</p>\n</blockquote>\n<blockquote>\n<p>既可以使用 $ docker load -i ubuntu_18.04.tar 命令来导入镜像存储文件到本地镜像库，也可以使用 $ cat export_ubuntu_container.tar | docker import - in_container/ubuntu:v1.0 命令来导入一个容器快照到本地镜像库。<br>这两者的区别在于： 容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积更大。<br>此外，从容器快照文件导人时可以重新指定标签等元数据信息 </p>\n</blockquote>\n<h3 id=\"清理所有终止状态的容器\"><a href=\"#清理所有终止状态的容器\" class=\"headerlink\" title=\"清理所有终止状态的容器\"></a>清理所有终止状态的容器</h3><pre><code>$ docker container prune</code></pre><h3 id=\"删除容器\"><a href=\"#删除容器\" class=\"headerlink\" title=\"删除容器\"></a>删除容器</h3><pre><code>$ docker rm 1e560fca3906\n－f, --force=false ： 是否强行终止并删除一个运行中的容器 ；\n－l, --link=false ：删除容器的连接 ，但保留容器；\n－v, --volumes=false ：删除容器挂载的数据卷</code></pre><h3 id=\"查看容器内的进程，端口映射，统计信息，容器详情-容器文件变更，-更新容器配置等\"><a href=\"#查看容器内的进程，端口映射，统计信息，容器详情-容器文件变更，-更新容器配置等\" class=\"headerlink\" title=\"查看容器内的进程，端口映射，统计信息，容器详情, 容器文件变更， 更新容器配置等\"></a>查看容器内的进程，端口映射，统计信息，容器详情, 容器文件变更， 更新容器配置等</h3><ul>\n<li><p>查看窑器内进程<br> $ docker top a1cb4017f313</p>\n</li>\n<li><p>查看容器端口与宿主主机端口映射情况<br> $ docker port a1cb4017f313 // 或者 $ docker container port a1cb4017f313</p>\n</li>\n<li><p>查看统计信息, 会显示 CPU 、内存、存储、网络等使用情况的统计信息<br> $ docker stats a1cb4017f313<br> CONTAINER ID        NAME                CPU %               MEM USAGE / LIMIT    MEM %               NET I/O             BLOCK I/O           PIDS<br> a1cb4017f313        strange_mendeleev   0.00%               6.23MiB / 7.612GiB   0.08%               22kB / 0B           0B / 4.1kB          1</p>\n<ul>\n<li>－a, -all ：输出所有容器统计信息，默认仅在运行中；</li>\n<li>－format string ：格式化输出信息；</li>\n<li>－no-stream ：不持续输出，默认会自动更新持续实时结果；</li>\n<li>－no-trunc ：不截断输出信息。</li>\n</ul>\n</li>\n<li><p>查看容器文件变更<br> $ docker [container] diff a1cb4017f313</p>\n</li>\n<li><p>查看容器信息<br> $ docker inspect a1cb4017f313 // 或者 $ docker container inspect a1cb4017f313</p>\n</li>\n<li><p>更新容器配置<br> $ docker update –help查看支持的选项<br> 限制总配额为 1 秒，容器 test 所占用时间为 10% ，代码如下所示：<br> $ docker update –cpu-quota 1000000 test<br> test<br> $ docker update –cpu-period 100000 test<br> test<br> 支持的选项包括：</p>\n<ul>\n<li>－blkio-weight uintl6 ：更新块 IO 限制， 10～ 1000 ，默认值为 0 ，代表着无限制；</li>\n<li>－cpu-period int ：限制 CPU 调度器 CFS (Completely Fair Scheduler）使用时间，单位为微秒，最小 1000;</li>\n<li>－cpu-quota int ：限制 CPU 调度器 CFS 配额，单位为微秒，最小 1000;</li>\n<li>－cpu-rt-period int ：限制 CPU 调度器的实时周期，单位为微秒 ；</li>\n<li>－cpu-rt-runtime int ：限制 CPU 调度器的实时运行时，单位为微秒；</li>\n<li>－c, -cpu-shares int ： 限制 CPU 使用份额；</li>\n<li>－cpus decimal ：限制 CPU 个数；</li>\n<li>－cpuset-cpus string ：允许使用的 CPU 核，如 0-3, 0,1;</li>\n<li>－cpuset-mems string ：允许使用的内存块，如 0-3, 0,1;</li>\n<li>－kernel-memory bytes ：限制使用的内核内存；</li>\n<li>－m, -memory bytes ： 限制使用的内存；</li>\n<li>－memory-reservation bytes ：内存软限制；</li>\n<li>－memory-swap bytes ：内存加上缓存区的限制， － 1 表示为对缓冲区无限制；</li>\n<li>－restart stri口g ： 容器退出后的重启策略<br>$ docker update –cpus 0 a1cb4017f313<br>$ docker update -c 4 a1cb4017f313<br>$ docker inspect a1cb4017f313    // 查看容器信息 “CpuShares”: 4</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"容器与主机间复制文件\"><a href=\"#容器与主机间复制文件\" class=\"headerlink\" title=\"容器与主机间复制文件\"></a>容器与主机间复制文件</h3><blockquote>\n<p>主机上的t1.txt复制到容器ID为 a1cb4017f313 的/home目录<br>$ docker cp t1.txt a1cb4017f313:/home</p>\n<ul>\n<li>－a, -archive ：打包模式，复制文件会带有原始的 uid/gid 信息；</li>\n<li>－L, -follow-link ：跟随软连接。当原路径为软连接时＼默认只复制链接信息，使用该选项会复制链接的目标内容 。</li>\n</ul>\n</blockquote>\n<h3 id=\"运行一个-web-应用\"><a href=\"#运行一个-web-应用\" class=\"headerlink\" title=\"运行一个 web 应用\"></a>运行一个 web 应用</h3><pre><code>runoob@runoob:~# docker pull training/webapp  # 载入镜像\nrunoob@runoob:~# docker run -d -P training/webapp python app.py</code></pre><ul>\n<li>-d:让容器在后台运行。</li>\n<li>-P:将容器内部使用的网络端口映射到我们使用的主机上。<ul>\n<li>runoob@runoob:~#  docker ps</li>\n<li>CONTAINER ID        IMAGE               COMMAND             …        PORTS                 </li>\n<li>d3d5e39ed9d3        training/webapp     “python app.py”     …        0.0.0.0:32769-&gt;5000/tcp</li>\n</ul>\n</li>\n<li>Docker 开放了 5000 端口（默认 Python Flask 端口）映射到主机端口 32769 上。</li>\n<li>这时我们可以通过浏览器访问WEB应用192.168.239.130:32769<br>可以通过 -p 参数来设置不一样的端口：<br>runoob@runoob:~$ docker run -d -p 5000:5000 training/webapp python app.py</li>\n</ul>\n<h3 id=\"查看-WEB-应用程序日志\"><a href=\"#查看-WEB-应用程序日志\" class=\"headerlink\" title=\"查看 WEB 应用程序日志\"></a>查看 WEB 应用程序日志</h3><pre><code>runoob@runoob:~$ docker logs -f bf08b7f2cd89        // -f: 让 docker logs 像使用 tail -f 一样来输出容器内部的标准输出。</code></pre><h3 id=\"查看WEB应用程序容器的进程\"><a href=\"#查看WEB应用程序容器的进程\" class=\"headerlink\" title=\"查看WEB应用程序容器的进程\"></a>查看WEB应用程序容器的进程</h3><pre><code>runoob@runoob:~$ docker top wizardly_chandrasekhar</code></pre><h3 id=\"查看Docker-容器的配置和状态信息\"><a href=\"#查看Docker-容器的配置和状态信息\" class=\"headerlink\" title=\"查看Docker 容器的配置和状态信息\"></a>查看Docker 容器的配置和状态信息</h3><pre><code>runoob@runoob:~$ docker inspect wizardly_chandrasekhar    // 它会返回一个 JSON 文件记录着 Docker 容器的配置和状态信息。</code></pre><h3 id=\"停止-WEB-应用容器\"><a href=\"#停止-WEB-应用容器\" class=\"headerlink\" title=\"停止 WEB 应用容器\"></a>停止 WEB 应用容器</h3><pre><code>runoob@runoob:~$ docker stop wizardly_chandrasekhar</code></pre><h3 id=\"重启WEB应用容器\"><a href=\"#重启WEB应用容器\" class=\"headerlink\" title=\"重启WEB应用容器\"></a>重启WEB应用容器</h3><pre><code>runoob@runoob:~$ docker start wizardly_chandrasekhar</code></pre><h3 id=\"移除WEB应用容器\"><a href=\"#移除WEB应用容器\" class=\"headerlink\" title=\"移除WEB应用容器\"></a>移除WEB应用容器</h3><pre><code>runoob@runoob:~$ docker rm wizardly_chandrasekhar         // 删除不需要的容器, 容器必须是停止状态，否则会报错</code></pre><p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<h2 id=\"镜像使用\"><a href=\"#镜像使用\" class=\"headerlink\" title=\"镜像使用\"></a>镜像使用</h2><h3 id=\"查找镜像\"><a href=\"#查找镜像\" class=\"headerlink\" title=\"查找镜像\"></a>查找镜像</h3><pre><code>Docker Hub 网址为： https://hub.docker.com/\n$ docker search httpd            // 使用 docker search 命令来搜索镜像\n\n* 搜索官方提供的带 nginx关键字的镜像\n$ docker search --filter=is-official=true nginx\nNAME                DESCRIPTION                STARS               OFFICIAL            AUTOMATED\nnginx               Official build of Nginx.   13037               [OK]</code></pre><ul>\n<li><p>NAME: 镜像仓库源的名称</p>\n</li>\n<li><p>DESCRIPTION: 镜像的描述</p>\n</li>\n<li><p>STARS: 类似 Github 里面的 star，表示点赞、喜欢的意思。</p>\n</li>\n<li><p>OFFICIAL: 是否 docker 官方发布</p>\n</li>\n<li><p>AUTOMATED: 自动构建。</p>\n<ul>\n<li><p>搜索所有收藏数超过 4 的关键词包括 tensorow 的镜像<br>$ docker search –filter=stars=200 tensorflow<br>NAME                          DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED<br>tensorflow/tensorflow         Official Docker images for the machine learn…   1662<br>jupyter/tensorflow-notebook   Jupyter Notebook Scientific Python Stack w/ …   209</p>\n</li>\n<li><p>搜索所有收藏数超过 4 的关键词包括 tensorow 的镜像的前3个镜像<br>$ docker search –filter=stars=4 –limit=3 tensorflow<br>NAME                          DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED<br>tensorflow/tensorflow         Official Docker images for the machine learn…   1662<br>jupyter/tensorflow-notebook   Jupyter Notebook Scientific Python Stack w/ …   209<br>tensorflow/serving            Official images for TensorFlow Serving (http…   83</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"列出镜像列表\"><a href=\"#列出镜像列表\" class=\"headerlink\" title=\"列出镜像列表\"></a>列出镜像列表</h3><pre><code>runoob@runoob:~$ docker images        // 列出本地主机上的镜像</code></pre><ul>\n<li>REPOSITORY：表示镜像的仓库源</li>\n<li>TAG：镜像的标签</li>\n<li>IMAGE ID：镜像ID, 如果两个镜像的ID 相同， 说明它们实际上指向了同一个镜像， 只是具有不同标签名称而已, 其中镜像的ID信息十分重要， 它唯一标识了镜像。在使用镜像ID的时候， 一般可以使用该ID的前若干个字符组成的可区分串来替代完整的ID</li>\n<li>CREATED：镜像创建时间</li>\n<li>SIZE：镜像大小, 镜像大小信息只是表示了该镜像的逻辑体积大小， 实际上由于相同的镜像层本地只会存储一份， 物理上占用的存储空间会小于各镜像逻辑体积之和<br>同一仓库源可以有多个 TAG，代表这个仓库源的不同个版本<ul>\n<li>REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</li>\n<li>ubuntu              14.04               90d5884b1ee0        5 days ago          188 MB</li>\n<li>php                 5.6                 f40e9e0f10c8        9 days ago          444.8 MB</li>\n<li>ubuntu              15.10               4e3b13c8a266        4 weeks ago         136.3 MB</li>\n<li>nginx               latest              6f8d099c3adc        12 days ago         182.7 MB<br>runoob@runoob:~$ docker run -t -i ubuntu:15.10 /bin/bash     // 使用版本为15.10的ubuntu系统镜像来运行容器<br>如果你不指定一个镜像的版本标签，例如你只使用 ubuntu，docker 将默认使用 ubuntu:latest 镜像。</li>\n<li>q, –quiet式rueI false: 仅输出ID信息， 默认为否<br>$ docker images -q=true<br>273c7fcf9499<br>0d40868643c6</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"获取镜像-如果不显式指定TAG-则默认会选择latest标签，这会下载仓库中最新版本的镜像\"><a href=\"#获取镜像-如果不显式指定TAG-则默认会选择latest标签，这会下载仓库中最新版本的镜像\" class=\"headerlink\" title=\"获取镜像, 如果不显式指定TAG, 则默认会选择latest标签，这会下载仓库中最新版本的镜像\"></a>获取镜像, 如果不显式指定TAG, 则默认会选择latest标签，这会下载仓库中最新版本的镜像</h3><blockquote>\n<p>严格地讲，镜像的仓库名称中还应该添加仓库地址（即registry, 注册服务器）作为前缀 ，只是默认使用的是官方DockerHub服务 ，该前缀可以忽略。<br>例如，$ docker pull ubuntu：18.04 命令相当于 $ docker pull registry.hub.docker.com/ubuntu：18.04命令，即从默认的注册服务器DockerHub Registy中的 ubuntu仓库来下载标记为18.04的镜像。<br>如果从非官方的仓库下载，则需要在仓库名称前指定完整的仓库地址。例如从网易蜂巢的镜像源来下载ubuntu:18.04镜像，可以使用如下命令，此时下载的镜像名称为hub.c.163.com/public/ubuntu:18.04: $ docker pull hub.c.163.com/public/ubuntu:18.04<br>可以在Docker服务启动配置中增加 –registry-mirror=proxy_URL来指定镜像代理服务地址（如<a href=\"https://registry.docker-en.com\" target=\"_blank\" rel=\"noopener\">https://registry.docker-en.com</a>)<br>    $ docker pull ubuntu:18.04 // 与下方命令一致,默认使用的是官方DockerHub服务 ，该前缀可以忽略.<br>    $ docker pull registry.hub.docker.com/ubuntu:18.04<br>    $ docker pull mysql:5.7<br>一般来说， 镜像的latest 标签意味着该镜像的内容会跟踪最新版本的变更而变化, 内容是不稳定的。 因此，从稳定性上考虑，不要在生产环境中忽略镜像的标签信息或使用默认的latest 标记的镜像<br>如果从非官方 的仓库 下载，则 需要在仓库 名称前指定完整的仓库地址<br>    $ docker pull hub.c.163.com/public/ubuntu:18.04</p>\n</blockquote>\n<h3 id=\"改变标签\"><a href=\"#改变标签\" class=\"headerlink\" title=\"改变标签\"></a>改变标签</h3><p> $ docker tag mysql:5.7 my_mysql:5.7.0<br> $ docker images<br>    REPOSITORY              TAG                 IMAGE ID            CREATED             SIZE<br>    my_mysql                5.7.0               273c7fcf9499        4 days ago          455MB<br>    mysql                   5.7                 273c7fcf9499        4 days ago          455MB</p>\n<blockquote>\n<p>它们实际上指向了同一个镜像文件，只是别名不同而巳。docker tag命令添加的标签实际上起到了类似链接的作用</p>\n</blockquote>\n<h3 id=\"查看imgage制作信息\"><a href=\"#查看imgage制作信息\" class=\"headerlink\" title=\"查看imgage制作信息\"></a>查看imgage制作信息</h3><p> $ docker inspect mysql:5.7<br> 只要其中一项内容时， 可以使用 -f 来指定<br> $ docker inspect -f {{\".Architecture\"}} mysql:5.7<br> $  docker inspect -f {{\".ContainerConfig\"}} mysql:5.7</p>\n<h3 id=\"查看image历史\"><a href=\"#查看image历史\" class=\"headerlink\" title=\"查看image历史\"></a>查看image历史</h3><p> $ docker history mysql:5.7</p>\n<h3 id=\"删除镜像\"><a href=\"#删除镜像\" class=\"headerlink\" title=\"删除镜像\"></a>删除镜像</h3><blockquote>\n<p>-f, -force: 强制删除镜像， 即使有容器依赖它<br>-no-prune: 不要清理未带标签的父镜像<br>$ docker rmi hello-world<br>docker rmi 命令只是删除了该镜像多个标签中的指定标签而巳， 并不影响镜像文件<br>$ docker rmi my_mysql:5.7.0<br>Untagged: my_mysql:5.7.0<br>docker rmi 命令来删除只有一个标签的镜像， 可以看出会删除这个镜像文件的所有文件层<br>当使用 docker rmi 命令， 并且后面跟上镜像的 ID (也可以是能进行区分的部分 ID 串前缀）时， 会先尝试删除所有指向该镜像的标签， 然后删除该镜像文件本身<br>当有该镜像创建的容器存在时， 镜像文件默认是无法被删除的, 如果要想强行删除镜像， 可以使用-f参数<br>$ docker rmi -f ubuntu:18.04<br>通常并不推荐使用-f参数来强制删除一个存在容器依赖的镜像。 正确的做法是，先删除依赖该镜像的所有容器， 再来删除镜像<br>首先删除容器a21c0840213e:<br>$ docker rm a2lc0840213e<br>然后使用ID来删除镜像， 此时会正常打印出删除的各层信息：<br>$ docker rmi Bflbd2lbd25c</p>\n</blockquote>\n<h3 id=\"清理镜像\"><a href=\"#清理镜像\" class=\"headerlink\" title=\"清理镜像\"></a>清理镜像</h3><pre><code>$ docker image prune</code></pre><blockquote>\n<p>-a, -all: 删除所有无用镜像， 不光是临时镜像；<br>-filter filter: 只清理符合给定过滤器的镜像；<br>-f, -force: 强制删除镜像， 而不进行提示确认</p>\n</blockquote>\n<h3 id=\"创建镜像\"><a href=\"#创建镜像\" class=\"headerlink\" title=\"创建镜像\"></a>创建镜像</h3><ul>\n<li>基于已有容器创建</li>\n</ul>\n<pre><code>$ docker run -itd --name ubuntu18.04_v3.0 ubuntu:18.04 /bin/bash\n$ docker exec -it ubuntu18.04_v3.0 /bin/bash\nroot@e2d52bc5c287:/# cd /home\nroot@e2d52bc5c287:/home# mkdir test        // 把初始的image创建一个文件夹再导出成新的image\nroot@e2d52bc5c287:/home# exit\nroot@alpha:~# docker commit -m &quot;add test file&quot; -a &quot;Docker Newbee&quot; e2d52bc5c287 test:0.1\n\n\n$ docker images\nREPOSITORY              TAG                 IMAGE ID            CREATED             SIZE\ntest                    0.1                 a4850ad0370a        15 seconds ago      64.2MB\nubuntu                  18.04               4e5021d210f6        4 weeks ago         64.2MB</code></pre><ul>\n<li><p>-a, –author=””: 作者信息</p>\n</li>\n<li><p>-c, - -change=(] : 提交的时候执行 Dockerfle指令， 包括 CMD | ENTRYPOINT | ENV | EXPOSE |LABEL | ONBUILD | USER | VOLUME | WORKIR等</p>\n</li>\n<li><p>-m, - -message=11 11: 提交消息</p>\n</li>\n<li><p>-p, –pause式rue: 提交时暂停容器运行</p>\n<ul>\n<li><p>基于本地模板导入</p>\n</li>\n<li><p>基于 Docke 「file 创建</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"导出和载入镜像\"><a href=\"#导出和载入镜像\" class=\"headerlink\" title=\"导出和载入镜像\"></a>导出和载入镜像</h3><ul>\n<li>导出镜像</li>\n</ul>\n<p> $ docker save -o ubuntu_18.04.tar ubuntu:18.04</p>\n<ul>\n<li>载入镜像</li>\n</ul>\n<p> $ docker load -i ubuntu_18.04.tar 或者 docker load &lt; ubuntu_18.04.tar</p>\n<h2 id=\"重启docker服务\"><a href=\"#重启docker服务\" class=\"headerlink\" title=\"重启docker服务\"></a>重启docker服务</h2><pre><code>$ service docker restart</code></pre><p>运行以下命令会出错，anyway 运行以上命令就可重启</p>\n<pre><code>$ systemctl restart docker.service</code></pre><h2 id=\"docker存储路径\"><a href=\"#docker存储路径\" class=\"headerlink\" title=\"docker存储路径\"></a>docker存储路径</h2><p>查看 docker 存储路径</p>\n<pre><code>$ docker info |grep &apos;Docker Root Dir&apos;\n Docker Root Dir: /var/lib/docker</code></pre><p>修改 docker 存储路径</p>\n<pre><code>$ vim /etc/docker/daemon.json\n{\n    &quot;graph&quot;: &quot;/home/server/docker&quot;\n}\n$ systemctl daemon-reload\n$ systemctl restart docker</code></pre><p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Docker-引擎\"><a href=\"#Docker-引擎\" class=\"headerlink\" title=\"Docker 引擎\"></a>Docker 引擎</h2><p>目前 Docker 支持 Docker 引 擎、 Docker Hub 、 Docker Cloud 等多种服务 。</p>\n<ul>\n<li>Docker 引擎：包括支持在桌面系统或云平台安装 Docker，以及为企业提供简单安全弹性的容器集群编排和管理；</li>\n<li>DockerHub ：官方提供的云托管服务，可以提供公有或私有的镜像仓库；</li>\n<li>DockerCloud ：官方提供的容器云服务，可以完成容器的部署与管理，可以完整地支持容器化项目，还有 CI 、 CD 功能<br>用户可以通过如下命令检查自己的内核版本详细信息 ：<br>$ uname -a<br>$ cat /proc/version</li>\n</ul>\n<h2 id=\"Ubuntu18-04-docker环境安装：\"><a href=\"#Ubuntu18-04-docker环境安装：\" class=\"headerlink\" title=\"Ubuntu18.04 docker环境安装：\"></a>Ubuntu18.04 docker环境安装：</h2><p>官网: <a href=\"https://www.docker.com/get-started\" target=\"_blank\" rel=\"noopener\">https://www.docker.com/get-started</a><br>查找image: <a href=\"https://hub.docker.com/search?type=image\" target=\"_blank\" rel=\"noopener\">https://hub.docker.com/search?type=image</a></p>\n<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><blockquote>\n<p>Docker 是基于 Go 语言实现的开源容器项目 。 它诞生于 2013 年年初，最初发起者是dotCloud 公司，dotCloud 公司也随之快速发展壮大，在 2013 年年底直接改名为 Docker Inc ，并专注于Docker 相关技术和产品的开发，目前已经成为全球最大的 Docker 容器服务提供商 。 官方网站为 docker.com<br>在 Linux 基金会最近一次关于“最受欢 迎的 云 计算开源项目”的调查中， Docker 仅次于 2010 年发起的 OpenStack 项目，并仍处于上升趋势 。2014 年， Docker 镜像下载数达到了一百万次， 2015 年直接突破十亿次， 2017 年更是突破了惊人的百亿次<br>Docker 的构想是要实现“ Build , Ship and Run Any App, Anywhere ”，即通过对应用的封装（ Packaging）、分发（ Distribution ）、部署（ Deployment）、运行（ Runtime ）生命周期进行管理，达到应用组件级别的“一次封装 ，到处运行”<br>与大部分新兴技术的诞生一样， Docker 也并非“从石头缝里蹦出来的”，而是站在前人的肩膀上。 其中最重要的就是 Linux 容器（ Linux Containers, LXC ）技术.<br>每个容器内运行着一个应用，不同的容器相互隔离，容器之间也可以通过网络互相通信 。 容器的创建和停止十分快速，几乎跟创建和终止原生应用－致.<br>容器自身对系统资源的额外需求也十分有限，远远低于传统虚拟机。 很多时候，甚至直接把容器当作应用本身也没有任何问题.</p>\n</blockquote>\n<h2 id=\"为什么用Docker\"><a href=\"#为什么用Docker\" class=\"headerlink\" title=\"为什么用Docker\"></a>为什么用Docker</h2><blockquote>\n<p>在云时代，开发者创建的应用必须要能很方便地在网络上传播，也就是说应用必须脱离底层物理硬件的限制；同时必须是“任何时间任何地点”可获取的 。 因此，开发者们需要一种新型的创建分布式应用程序的方式，快速分发和部署，而这正是 Docker 所能够提供的最大优势<br>Docker 提供了一种更为聪明的方式，通过容器来打包应用、解藕应用和运行平台。这意味着迁移的时候，只需要在新的服务器上启动需要的容器就可以了，无论新旧服务器是否是同一类型的平台 。 这无疑将帮助我们节约大量的宝贵时间，并降低部署过程出现问题的风险<br>传统虚拟机方式运行 N 个不同的应用就要启用 N 个虚拟机（每个虚拟机需要单独分配独占的内存、磁盘等资源），而 Docker 只需要启动 N 个隔离得“很薄的”容器，并将应用放进容器内即可 。 应用获得的是接近原生的运行性能<br>传统方式是在硬件层面实现虚拟化，需要有额外的虚拟机管理应用和虚拟机操作系统层。 Docker 容器是在操作系统层面上实现虚拟化，直接复用本地主机的操作系统，因此更加轻量级 </p>\n</blockquote>\n<h2 id=\"docker-ce与-docker-ee区别\"><a href=\"#docker-ce与-docker-ee区别\" class=\"headerlink\" title=\"docker ce与 docker ee区别\"></a>docker ce与 docker ee区别</h2><ul>\n<li><p>Docker Engine改为Docker CE(社区版), 它包含了CLI客户端、后台进程/服务以及API。用户像以前以同样的方式获取。<br>docker-ce是docker公司维护的开源项目，是一个基于moby项目的免费的容器产品；</p>\n</li>\n<li><p>Docker Data Center改为Docker EE（企业版）<br>docker-ee是docker公司维护的闭源产品，是docker公司的商业产品；<br>这些ce和ee版并不影响Docker Compose以及Docker Machine<br>docker-ce project是docker公司维护，docker-ee是闭源的；</p>\n</li>\n</ul>\n<p>要使用免费的docker，从网页docker-ce上获取；</p>\n<p>要使用收费的docker，从网页docker-ee上获取</p>\n<h2 id=\"docker-UCP-介绍\"><a href=\"#docker-UCP-介绍\" class=\"headerlink\" title=\"docker UCP 介绍\"></a>docker UCP 介绍</h2><blockquote>\n<p>Docker Universal Control Plane（UCP）是Docker公司在2015年底巴塞罗那的开发者大会上发布的，这是一个跟单信用证，是一个新的Docker支付服务的组合的一部分,旨在帮助运维团队轻松地设置一个集群,使开发人员可以快速部署Dockerized应用。他们构建Docker DataCenter的其中重要的组成部分。<br>UCP集群包含两种节点：<br>Controller: 管理集群，并持久化集群配置<br>Node：运行容器</p>\n</blockquote>\n<h2 id=\"安装curl\"><a href=\"#安装curl\" class=\"headerlink\" title=\"安装curl:\"></a>安装curl:</h2><blockquote>\n<ul>\n<li>第一种方法:<br>  <a href=\"https://curl.haxx.se/download.html\" target=\"_blank\" rel=\"noopener\">https://curl.haxx.se/download.html</a><br>  $ curl-7.69.1.tar.gz<br>  $ ./configure –prefix=/usr/local/curl<br>  $ make -j12<br>  $ make install<br>  $ ln -s /usr/local/curl/bin/curl /usr/bin<br>  $ vim ~/.bashrc 添加 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/curl/lib<br>  $ source ~/.bashrc<br>  $ curl –version         // 查看curl版本和支持的协议如http, https</li>\n<li>第二种方法(推荐，方便快捷):<br> $ apt-get update<br> $ apt-get upgrade<br> $ apt-get install curl<br> $ curl –version</li>\n<li>提前设置好系统的proxy如:<br> export http_proxy=child-prc.intel.com:913<br> export https_proxy=child-prc.intel.com:913 // https的proxy与上面的http的要一样</li>\n</ul>\n</blockquote>\n<h2 id=\"安装docker\"><a href=\"#安装docker\" class=\"headerlink\" title=\"安装docker:\"></a>安装docker:</h2><blockquote>\n<p>$ apt-get install docker<br>$ apt-get install docker.io</p>\n<p>$ mkdir -p /etc/systemd/system/docker.service.d<br>$ touch /etc/systemd/system/docker.service.d/http-proxy.conf</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">添加如下内容</span><br><span class=\"line\">[Service]</span><br><span class=\"line\">Environment&#x3D;&quot;HTTP_PROXY&#x3D;http:&#x2F;&#x2F;child-prc.intel.com:913&#x2F;&quot;</span><br><span class=\"line\">Environment&#x3D;&quot;HTTPS_PROXY&#x3D;http:&#x2F;&#x2F;child-prc.intel.com:913&#x2F;&quot;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>Additional: 也可以在Docker服务启动配置中增加 –regis七ry-mirror=proxy_URL来指定镜像代理服务地址（如<a href=\"https://registry.docker-en.com\" target=\"_blank\" rel=\"noopener\">https://registry.docker-en.com</a>)</p>\n</blockquote>\n<blockquote>\n<p>$ cd /etc/docker<br>$ touch daemon.json<br>    {<br>       “insecure-registries” :[“10.239.82.163:5000”]  // 此文件设置为空, 需要从10.239.82.163这台机器拉镜像时候才需要添加此内容<br>    }<br>$ systemctl daemon-reload<br>$ systemctl restart docker<br>$ docker search redis</p>\n</blockquote>\n<h2 id=\"安装docker-compose-关于此程序说明可以参考-https-www-runoob-com-docker-docker-compose-html\"><a href=\"#安装docker-compose-关于此程序说明可以参考-https-www-runoob-com-docker-docker-compose-html\" class=\"headerlink\" title=\"安装docker compose:        // 关于此程序说明可以参考 https://www.runoob.com/docker/docker-compose.html\"></a>安装docker compose:        // 关于此程序说明可以参考 <a href=\"https://www.runoob.com/docker/docker-compose.html\" target=\"_blank\" rel=\"noopener\">https://www.runoob.com/docker/docker-compose.html</a></h2><pre><code>https://github.com/docker/compose/releases\ncurl -L https://github.com/docker/compose/releases/download/1.25.4/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose\nchmod +x /usr/local/bin/docker-compose</code></pre><h2 id=\"容器的使用\"><a href=\"#容器的使用\" class=\"headerlink\" title=\"容器的使用\"></a>容器的使用</h2><h3 id=\"查看所有的容器\"><a href=\"#查看所有的容器\" class=\"headerlink\" title=\"查看所有的容器\"></a>查看所有的容器</h3><pre><code>$ docker ps -a\n$ docker ps -a --no-trunc        // 不截短，全部输出container信息\n$ docker inspcet &lt;Container&gt;    // 查看某个container的详细信息\n如果在容器内部。可以用 ps -fe 查看。其中1号进程就是启动命令</code></pre><h3 id=\"查询最后一次创建的容器\"><a href=\"#查询最后一次创建的容器\" class=\"headerlink\" title=\"查询最后一次创建的容器\"></a>查询最后一次创建的容器</h3><pre><code>$ docker ps -l </code></pre><h3 id=\"启动容器\"><a href=\"#启动容器\" class=\"headerlink\" title=\"启动容器\"></a>启动容器</h3><pre><code>$ docker run -it --name ubuntu_container ubuntu /bin/bash</code></pre><ul>\n<li>-i: 交互式操作,则让容器的标准输入保持打开.</li>\n<li>-t: 终端, 让 Docker 分配一个伪终端（ pseudo－即）并绑定到容器的标准输入上，</li>\n<li>ubuntu: ubuntu 镜像。</li>\n<li>/bin/bash：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 /bin/bash。<br>当利用 docker [container] run 来创建并启动容器时， Docker 在后台运行的标准操作包括：</li>\n<li>检查本地是否存在指定的镜像，不存在就从公有仓库下载；</li>\n<li>利用镜像创建一个容器，并启动该容器；</li>\n<li>分配一个文件系统给容器，并在只读的镜像层外面挂载一层可读写层 ；</li>\n<li>从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去；</li>\n<li>从网桥的地址池配置一个 IP 地址给容器；</li>\n<li>执行用户指定的应用程序；</li>\n<li>执行完毕后容器被自动终止。</li>\n</ul>\n<h3 id=\"启动并进入容器\"><a href=\"#启动并进入容器\" class=\"headerlink\" title=\"启动并进入容器\"></a>启动并进入容器</h3><blockquote>\n<p>$ docker run –name ubuntu_18.04_v1.0 ubuntu_test:18.04 /bin/echo ‘hello’ // 不加 -it容器执行完echo ‘hello’后就退出<br>hello<br>$ docker run -itd –name ubuntu_18.04_v2.0 ubuntu_test:18.04 /bin/bash // 不加参数d容器退出后，就终止运行，最好加上d，容器退出后容器内进程仍然后台执行<br>$ docker exec -it ubuntu_18.04_v2.0 /bin/bash<br>root@1cf8105dbd62:/# ps<br> PID TTY          TIME CMD<br>   1 pts/0    00:00:00 bash<br>  11 pts/0    00:00:00 ps<br>root@1cf8105dbd62:/#<br>在容器内用 ps 命令查看进程，可以看到，只运行了 bash 应用，并没有运行其他无关的进程<br>Ctrl+d 或输入 exit 命令来退出容器：<br>root@afBbae53bdd3:/# exit<br>进入容器后配置好proxy如:<br>$ export http_proxy=child-prc.intel.com:913<br>$ apt-get update<br>$ apt-get install python ……</p>\n</blockquote>\n<h3 id=\"停止一个容器\"><a href=\"#停止一个容器\" class=\"headerlink\" title=\"停止一个容器\"></a>停止一个容器</h3><pre><code>$ docker stop &lt;容器 ID&gt;\n停止的容器可以通过 docker restart 重启：\n$ docker restart &lt;容器 ID&gt;</code></pre><h3 id=\"启动已停止运行的容器\"><a href=\"#启动已停止运行的容器\" class=\"headerlink\" title=\"启动已停止运行的容器\"></a>启动已停止运行的容器</h3><pre><code>$ docker start b750bbbcfd88 </code></pre><h3 id=\"后台运行\"><a href=\"#后台运行\" class=\"headerlink\" title=\"后台运行\"></a>后台运行</h3><pre><code>$ docker run -itd --name ubuntu-test ubuntu /bin/bash</code></pre><ul>\n<li>-d: 指定容器的运行模式.</li>\n<li>容器已启动，但是没登录，后端运行，可通过$ docker ps查看, 再执行 $ docker exec -it &lt;容器ID&gt; /bin/bash 即可进入</li>\n</ul>\n<h3 id=\"进入容器\"><a href=\"#进入容器\" class=\"headerlink\" title=\"进入容器\"></a>进入容器</h3><pre><code>// docker attach 1e560fca3906                 //  如果从这个容器退出，会导致容器的停止, 不推荐使用\n$ docker exec -it 243c32535da7 /bin/bash        // 从这个容器退出，不会导致容器的停止</code></pre><h3 id=\"退出终端\"><a href=\"#退出终端\" class=\"headerlink\" title=\"退出终端\"></a>退出终端</h3><pre><code>root@ed09e4490c57:/# exit</code></pre><h3 id=\"导出容器\"><a href=\"#导出容器\" class=\"headerlink\" title=\"导出容器\"></a>导出容器</h3><ul>\n<li>第一种:<br> $ docker export a1cb4017f313 &gt; export_ubuntu_container.tar        // 导出容器 1e560fca3906 快照到本地文件 ubuntu.tar。</li>\n<li>第二种:<br> $ docker export -o export_ubuntu_container.tar a1cb4017f313<br>之后，可将导出的 tar 文件传输到其他机器上，然后再通过导人命令导入到系统中，实现容器的迁移 </li>\n</ul>\n<h3 id=\"导入容器-container-快照到本地image库\"><a href=\"#导入容器-container-快照到本地image库\" class=\"headerlink\" title=\"导入容器(container)快照到本地image库\"></a>导入容器(container)快照到本地image库</h3><blockquote>\n<p>root@alpha:/home/dockers# cat export_ubuntu_container.tar | docker import - in_container/ubuntu:v1.0<br>sha256:31bfe55fe553047cd3cf513dc7d19ae15e746166685c90d8ac3afac9dcea755b<br>root@alpha:/home/dockers# docker images<br>REPOSITORY              TAG                 IMAGE ID            CREATED             SIZE<br>in_container/ubuntu     v1.0                31bfe55fe553        3 seconds ago       64.2MB<br>ubuntu_test             18.04               a4850ad0370a        About an hour ago   64.2MB</p>\n</blockquote>\n<blockquote>\n<p>既可以使用 $ docker load -i ubuntu_18.04.tar 命令来导入镜像存储文件到本地镜像库，也可以使用 $ cat export_ubuntu_container.tar | docker import - in_container/ubuntu:v1.0 命令来导入一个容器快照到本地镜像库。<br>这两者的区别在于： 容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积更大。<br>此外，从容器快照文件导人时可以重新指定标签等元数据信息 </p>\n</blockquote>\n<h3 id=\"清理所有终止状态的容器\"><a href=\"#清理所有终止状态的容器\" class=\"headerlink\" title=\"清理所有终止状态的容器\"></a>清理所有终止状态的容器</h3><pre><code>$ docker container prune</code></pre><h3 id=\"删除容器\"><a href=\"#删除容器\" class=\"headerlink\" title=\"删除容器\"></a>删除容器</h3><pre><code>$ docker rm 1e560fca3906\n－f, --force=false ： 是否强行终止并删除一个运行中的容器 ；\n－l, --link=false ：删除容器的连接 ，但保留容器；\n－v, --volumes=false ：删除容器挂载的数据卷</code></pre><h3 id=\"查看容器内的进程，端口映射，统计信息，容器详情-容器文件变更，-更新容器配置等\"><a href=\"#查看容器内的进程，端口映射，统计信息，容器详情-容器文件变更，-更新容器配置等\" class=\"headerlink\" title=\"查看容器内的进程，端口映射，统计信息，容器详情, 容器文件变更， 更新容器配置等\"></a>查看容器内的进程，端口映射，统计信息，容器详情, 容器文件变更， 更新容器配置等</h3><ul>\n<li><p>查看窑器内进程<br> $ docker top a1cb4017f313</p>\n</li>\n<li><p>查看容器端口与宿主主机端口映射情况<br> $ docker port a1cb4017f313 // 或者 $ docker container port a1cb4017f313</p>\n</li>\n<li><p>查看统计信息, 会显示 CPU 、内存、存储、网络等使用情况的统计信息<br> $ docker stats a1cb4017f313<br> CONTAINER ID        NAME                CPU %               MEM USAGE / LIMIT    MEM %               NET I/O             BLOCK I/O           PIDS<br> a1cb4017f313        strange_mendeleev   0.00%               6.23MiB / 7.612GiB   0.08%               22kB / 0B           0B / 4.1kB          1</p>\n<ul>\n<li>－a, -all ：输出所有容器统计信息，默认仅在运行中；</li>\n<li>－format string ：格式化输出信息；</li>\n<li>－no-stream ：不持续输出，默认会自动更新持续实时结果；</li>\n<li>－no-trunc ：不截断输出信息。</li>\n</ul>\n</li>\n<li><p>查看容器文件变更<br> $ docker [container] diff a1cb4017f313</p>\n</li>\n<li><p>查看容器信息<br> $ docker inspect a1cb4017f313 // 或者 $ docker container inspect a1cb4017f313</p>\n</li>\n<li><p>更新容器配置<br> $ docker update –help查看支持的选项<br> 限制总配额为 1 秒，容器 test 所占用时间为 10% ，代码如下所示：<br> $ docker update –cpu-quota 1000000 test<br> test<br> $ docker update –cpu-period 100000 test<br> test<br> 支持的选项包括：</p>\n<ul>\n<li>－blkio-weight uintl6 ：更新块 IO 限制， 10～ 1000 ，默认值为 0 ，代表着无限制；</li>\n<li>－cpu-period int ：限制 CPU 调度器 CFS (Completely Fair Scheduler）使用时间，单位为微秒，最小 1000;</li>\n<li>－cpu-quota int ：限制 CPU 调度器 CFS 配额，单位为微秒，最小 1000;</li>\n<li>－cpu-rt-period int ：限制 CPU 调度器的实时周期，单位为微秒 ；</li>\n<li>－cpu-rt-runtime int ：限制 CPU 调度器的实时运行时，单位为微秒；</li>\n<li>－c, -cpu-shares int ： 限制 CPU 使用份额；</li>\n<li>－cpus decimal ：限制 CPU 个数；</li>\n<li>－cpuset-cpus string ：允许使用的 CPU 核，如 0-3, 0,1;</li>\n<li>－cpuset-mems string ：允许使用的内存块，如 0-3, 0,1;</li>\n<li>－kernel-memory bytes ：限制使用的内核内存；</li>\n<li>－m, -memory bytes ： 限制使用的内存；</li>\n<li>－memory-reservation bytes ：内存软限制；</li>\n<li>－memory-swap bytes ：内存加上缓存区的限制， － 1 表示为对缓冲区无限制；</li>\n<li>－restart stri口g ： 容器退出后的重启策略<br>$ docker update –cpus 0 a1cb4017f313<br>$ docker update -c 4 a1cb4017f313<br>$ docker inspect a1cb4017f313    // 查看容器信息 “CpuShares”: 4</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"容器与主机间复制文件\"><a href=\"#容器与主机间复制文件\" class=\"headerlink\" title=\"容器与主机间复制文件\"></a>容器与主机间复制文件</h3><blockquote>\n<p>主机上的t1.txt复制到容器ID为 a1cb4017f313 的/home目录<br>$ docker cp t1.txt a1cb4017f313:/home</p>\n<ul>\n<li>－a, -archive ：打包模式，复制文件会带有原始的 uid/gid 信息；</li>\n<li>－L, -follow-link ：跟随软连接。当原路径为软连接时＼默认只复制链接信息，使用该选项会复制链接的目标内容 。</li>\n</ul>\n</blockquote>\n<h3 id=\"运行一个-web-应用\"><a href=\"#运行一个-web-应用\" class=\"headerlink\" title=\"运行一个 web 应用\"></a>运行一个 web 应用</h3><pre><code>runoob@runoob:~# docker pull training/webapp  # 载入镜像\nrunoob@runoob:~# docker run -d -P training/webapp python app.py</code></pre><ul>\n<li>-d:让容器在后台运行。</li>\n<li>-P:将容器内部使用的网络端口映射到我们使用的主机上。<ul>\n<li>runoob@runoob:~#  docker ps</li>\n<li>CONTAINER ID        IMAGE               COMMAND             …        PORTS                 </li>\n<li>d3d5e39ed9d3        training/webapp     “python app.py”     …        0.0.0.0:32769-&gt;5000/tcp</li>\n</ul>\n</li>\n<li>Docker 开放了 5000 端口（默认 Python Flask 端口）映射到主机端口 32769 上。</li>\n<li>这时我们可以通过浏览器访问WEB应用192.168.239.130:32769<br>可以通过 -p 参数来设置不一样的端口：<br>runoob@runoob:~$ docker run -d -p 5000:5000 training/webapp python app.py</li>\n</ul>\n<h3 id=\"查看-WEB-应用程序日志\"><a href=\"#查看-WEB-应用程序日志\" class=\"headerlink\" title=\"查看 WEB 应用程序日志\"></a>查看 WEB 应用程序日志</h3><pre><code>runoob@runoob:~$ docker logs -f bf08b7f2cd89        // -f: 让 docker logs 像使用 tail -f 一样来输出容器内部的标准输出。</code></pre><h3 id=\"查看WEB应用程序容器的进程\"><a href=\"#查看WEB应用程序容器的进程\" class=\"headerlink\" title=\"查看WEB应用程序容器的进程\"></a>查看WEB应用程序容器的进程</h3><pre><code>runoob@runoob:~$ docker top wizardly_chandrasekhar</code></pre><h3 id=\"查看Docker-容器的配置和状态信息\"><a href=\"#查看Docker-容器的配置和状态信息\" class=\"headerlink\" title=\"查看Docker 容器的配置和状态信息\"></a>查看Docker 容器的配置和状态信息</h3><pre><code>runoob@runoob:~$ docker inspect wizardly_chandrasekhar    // 它会返回一个 JSON 文件记录着 Docker 容器的配置和状态信息。</code></pre><h3 id=\"停止-WEB-应用容器\"><a href=\"#停止-WEB-应用容器\" class=\"headerlink\" title=\"停止 WEB 应用容器\"></a>停止 WEB 应用容器</h3><pre><code>runoob@runoob:~$ docker stop wizardly_chandrasekhar</code></pre><h3 id=\"重启WEB应用容器\"><a href=\"#重启WEB应用容器\" class=\"headerlink\" title=\"重启WEB应用容器\"></a>重启WEB应用容器</h3><pre><code>runoob@runoob:~$ docker start wizardly_chandrasekhar</code></pre><h3 id=\"移除WEB应用容器\"><a href=\"#移除WEB应用容器\" class=\"headerlink\" title=\"移除WEB应用容器\"></a>移除WEB应用容器</h3><pre><code>runoob@runoob:~$ docker rm wizardly_chandrasekhar         // 删除不需要的容器, 容器必须是停止状态，否则会报错</code></pre><p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<h2 id=\"镜像使用\"><a href=\"#镜像使用\" class=\"headerlink\" title=\"镜像使用\"></a>镜像使用</h2><h3 id=\"查找镜像\"><a href=\"#查找镜像\" class=\"headerlink\" title=\"查找镜像\"></a>查找镜像</h3><pre><code>Docker Hub 网址为： https://hub.docker.com/\n$ docker search httpd            // 使用 docker search 命令来搜索镜像\n\n* 搜索官方提供的带 nginx关键字的镜像\n$ docker search --filter=is-official=true nginx\nNAME                DESCRIPTION                STARS               OFFICIAL            AUTOMATED\nnginx               Official build of Nginx.   13037               [OK]</code></pre><ul>\n<li><p>NAME: 镜像仓库源的名称</p>\n</li>\n<li><p>DESCRIPTION: 镜像的描述</p>\n</li>\n<li><p>STARS: 类似 Github 里面的 star，表示点赞、喜欢的意思。</p>\n</li>\n<li><p>OFFICIAL: 是否 docker 官方发布</p>\n</li>\n<li><p>AUTOMATED: 自动构建。</p>\n<ul>\n<li><p>搜索所有收藏数超过 4 的关键词包括 tensorow 的镜像<br>$ docker search –filter=stars=200 tensorflow<br>NAME                          DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED<br>tensorflow/tensorflow         Official Docker images for the machine learn…   1662<br>jupyter/tensorflow-notebook   Jupyter Notebook Scientific Python Stack w/ …   209</p>\n</li>\n<li><p>搜索所有收藏数超过 4 的关键词包括 tensorow 的镜像的前3个镜像<br>$ docker search –filter=stars=4 –limit=3 tensorflow<br>NAME                          DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED<br>tensorflow/tensorflow         Official Docker images for the machine learn…   1662<br>jupyter/tensorflow-notebook   Jupyter Notebook Scientific Python Stack w/ …   209<br>tensorflow/serving            Official images for TensorFlow Serving (http…   83</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"列出镜像列表\"><a href=\"#列出镜像列表\" class=\"headerlink\" title=\"列出镜像列表\"></a>列出镜像列表</h3><pre><code>runoob@runoob:~$ docker images        // 列出本地主机上的镜像</code></pre><ul>\n<li>REPOSITORY：表示镜像的仓库源</li>\n<li>TAG：镜像的标签</li>\n<li>IMAGE ID：镜像ID, 如果两个镜像的ID 相同， 说明它们实际上指向了同一个镜像， 只是具有不同标签名称而已, 其中镜像的ID信息十分重要， 它唯一标识了镜像。在使用镜像ID的时候， 一般可以使用该ID的前若干个字符组成的可区分串来替代完整的ID</li>\n<li>CREATED：镜像创建时间</li>\n<li>SIZE：镜像大小, 镜像大小信息只是表示了该镜像的逻辑体积大小， 实际上由于相同的镜像层本地只会存储一份， 物理上占用的存储空间会小于各镜像逻辑体积之和<br>同一仓库源可以有多个 TAG，代表这个仓库源的不同个版本<ul>\n<li>REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</li>\n<li>ubuntu              14.04               90d5884b1ee0        5 days ago          188 MB</li>\n<li>php                 5.6                 f40e9e0f10c8        9 days ago          444.8 MB</li>\n<li>ubuntu              15.10               4e3b13c8a266        4 weeks ago         136.3 MB</li>\n<li>nginx               latest              6f8d099c3adc        12 days ago         182.7 MB<br>runoob@runoob:~$ docker run -t -i ubuntu:15.10 /bin/bash     // 使用版本为15.10的ubuntu系统镜像来运行容器<br>如果你不指定一个镜像的版本标签，例如你只使用 ubuntu，docker 将默认使用 ubuntu:latest 镜像。</li>\n<li>q, –quiet式rueI false: 仅输出ID信息， 默认为否<br>$ docker images -q=true<br>273c7fcf9499<br>0d40868643c6</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"获取镜像-如果不显式指定TAG-则默认会选择latest标签，这会下载仓库中最新版本的镜像\"><a href=\"#获取镜像-如果不显式指定TAG-则默认会选择latest标签，这会下载仓库中最新版本的镜像\" class=\"headerlink\" title=\"获取镜像, 如果不显式指定TAG, 则默认会选择latest标签，这会下载仓库中最新版本的镜像\"></a>获取镜像, 如果不显式指定TAG, 则默认会选择latest标签，这会下载仓库中最新版本的镜像</h3><blockquote>\n<p>严格地讲，镜像的仓库名称中还应该添加仓库地址（即registry, 注册服务器）作为前缀 ，只是默认使用的是官方DockerHub服务 ，该前缀可以忽略。<br>例如，$ docker pull ubuntu：18.04 命令相当于 $ docker pull registry.hub.docker.com/ubuntu：18.04命令，即从默认的注册服务器DockerHub Registy中的 ubuntu仓库来下载标记为18.04的镜像。<br>如果从非官方的仓库下载，则需要在仓库名称前指定完整的仓库地址。例如从网易蜂巢的镜像源来下载ubuntu:18.04镜像，可以使用如下命令，此时下载的镜像名称为hub.c.163.com/public/ubuntu:18.04: $ docker pull hub.c.163.com/public/ubuntu:18.04<br>可以在Docker服务启动配置中增加 –registry-mirror=proxy_URL来指定镜像代理服务地址（如<a href=\"https://registry.docker-en.com\" target=\"_blank\" rel=\"noopener\">https://registry.docker-en.com</a>)<br>    $ docker pull ubuntu:18.04 // 与下方命令一致,默认使用的是官方DockerHub服务 ，该前缀可以忽略.<br>    $ docker pull registry.hub.docker.com/ubuntu:18.04<br>    $ docker pull mysql:5.7<br>一般来说， 镜像的latest 标签意味着该镜像的内容会跟踪最新版本的变更而变化, 内容是不稳定的。 因此，从稳定性上考虑，不要在生产环境中忽略镜像的标签信息或使用默认的latest 标记的镜像<br>如果从非官方 的仓库 下载，则 需要在仓库 名称前指定完整的仓库地址<br>    $ docker pull hub.c.163.com/public/ubuntu:18.04</p>\n</blockquote>\n<h3 id=\"改变标签\"><a href=\"#改变标签\" class=\"headerlink\" title=\"改变标签\"></a>改变标签</h3><p> $ docker tag mysql:5.7 my_mysql:5.7.0<br> $ docker images<br>    REPOSITORY              TAG                 IMAGE ID            CREATED             SIZE<br>    my_mysql                5.7.0               273c7fcf9499        4 days ago          455MB<br>    mysql                   5.7                 273c7fcf9499        4 days ago          455MB</p>\n<blockquote>\n<p>它们实际上指向了同一个镜像文件，只是别名不同而巳。docker tag命令添加的标签实际上起到了类似链接的作用</p>\n</blockquote>\n<h3 id=\"查看imgage制作信息\"><a href=\"#查看imgage制作信息\" class=\"headerlink\" title=\"查看imgage制作信息\"></a>查看imgage制作信息</h3><p> $ docker inspect mysql:5.7<br> 只要其中一项内容时， 可以使用 -f 来指定<br> $ docker inspect -f {{\".Architecture\"}} mysql:5.7<br> $  docker inspect -f {{\".ContainerConfig\"}} mysql:5.7</p>\n<h3 id=\"查看image历史\"><a href=\"#查看image历史\" class=\"headerlink\" title=\"查看image历史\"></a>查看image历史</h3><p> $ docker history mysql:5.7</p>\n<h3 id=\"删除镜像\"><a href=\"#删除镜像\" class=\"headerlink\" title=\"删除镜像\"></a>删除镜像</h3><blockquote>\n<p>-f, -force: 强制删除镜像， 即使有容器依赖它<br>-no-prune: 不要清理未带标签的父镜像<br>$ docker rmi hello-world<br>docker rmi 命令只是删除了该镜像多个标签中的指定标签而巳， 并不影响镜像文件<br>$ docker rmi my_mysql:5.7.0<br>Untagged: my_mysql:5.7.0<br>docker rmi 命令来删除只有一个标签的镜像， 可以看出会删除这个镜像文件的所有文件层<br>当使用 docker rmi 命令， 并且后面跟上镜像的 ID (也可以是能进行区分的部分 ID 串前缀）时， 会先尝试删除所有指向该镜像的标签， 然后删除该镜像文件本身<br>当有该镜像创建的容器存在时， 镜像文件默认是无法被删除的, 如果要想强行删除镜像， 可以使用-f参数<br>$ docker rmi -f ubuntu:18.04<br>通常并不推荐使用-f参数来强制删除一个存在容器依赖的镜像。 正确的做法是，先删除依赖该镜像的所有容器， 再来删除镜像<br>首先删除容器a21c0840213e:<br>$ docker rm a2lc0840213e<br>然后使用ID来删除镜像， 此时会正常打印出删除的各层信息：<br>$ docker rmi Bflbd2lbd25c</p>\n</blockquote>\n<h3 id=\"清理镜像\"><a href=\"#清理镜像\" class=\"headerlink\" title=\"清理镜像\"></a>清理镜像</h3><pre><code>$ docker image prune</code></pre><blockquote>\n<p>-a, -all: 删除所有无用镜像， 不光是临时镜像；<br>-filter filter: 只清理符合给定过滤器的镜像；<br>-f, -force: 强制删除镜像， 而不进行提示确认</p>\n</blockquote>\n<h3 id=\"创建镜像\"><a href=\"#创建镜像\" class=\"headerlink\" title=\"创建镜像\"></a>创建镜像</h3><ul>\n<li>基于已有容器创建</li>\n</ul>\n<pre><code>$ docker run -itd --name ubuntu18.04_v3.0 ubuntu:18.04 /bin/bash\n$ docker exec -it ubuntu18.04_v3.0 /bin/bash\nroot@e2d52bc5c287:/# cd /home\nroot@e2d52bc5c287:/home# mkdir test        // 把初始的image创建一个文件夹再导出成新的image\nroot@e2d52bc5c287:/home# exit\nroot@alpha:~# docker commit -m &quot;add test file&quot; -a &quot;Docker Newbee&quot; e2d52bc5c287 test:0.1\n\n\n$ docker images\nREPOSITORY              TAG                 IMAGE ID            CREATED             SIZE\ntest                    0.1                 a4850ad0370a        15 seconds ago      64.2MB\nubuntu                  18.04               4e5021d210f6        4 weeks ago         64.2MB</code></pre><ul>\n<li><p>-a, –author=””: 作者信息</p>\n</li>\n<li><p>-c, - -change=(] : 提交的时候执行 Dockerfle指令， 包括 CMD | ENTRYPOINT | ENV | EXPOSE |LABEL | ONBUILD | USER | VOLUME | WORKIR等</p>\n</li>\n<li><p>-m, - -message=11 11: 提交消息</p>\n</li>\n<li><p>-p, –pause式rue: 提交时暂停容器运行</p>\n<ul>\n<li><p>基于本地模板导入</p>\n</li>\n<li><p>基于 Docke 「file 创建</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"导出和载入镜像\"><a href=\"#导出和载入镜像\" class=\"headerlink\" title=\"导出和载入镜像\"></a>导出和载入镜像</h3><ul>\n<li>导出镜像</li>\n</ul>\n<p> $ docker save -o ubuntu_18.04.tar ubuntu:18.04</p>\n<ul>\n<li>载入镜像</li>\n</ul>\n<p> $ docker load -i ubuntu_18.04.tar 或者 docker load &lt; ubuntu_18.04.tar</p>\n<h2 id=\"重启docker服务\"><a href=\"#重启docker服务\" class=\"headerlink\" title=\"重启docker服务\"></a>重启docker服务</h2><pre><code>$ service docker restart</code></pre><p>运行以下命令会出错，anyway 运行以上命令就可重启</p>\n<pre><code>$ systemctl restart docker.service</code></pre><h2 id=\"docker存储路径\"><a href=\"#docker存储路径\" class=\"headerlink\" title=\"docker存储路径\"></a>docker存储路径</h2><p>查看 docker 存储路径</p>\n<pre><code>$ docker info |grep &apos;Docker Root Dir&apos;\n Docker Root Dir: /var/lib/docker</code></pre><p>修改 docker 存储路径</p>\n<pre><code>$ vim /etc/docker/daemon.json\n{\n    &quot;graph&quot;: &quot;/home/server/docker&quot;\n}\n$ systemctl daemon-reload\n$ systemctl restart docker</code></pre><p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n"},{"title":"IntelliJ idea","_content":"\n## 下载IntelliJ idea\n\n## 配置Maven\n\n## 选择自安装的JDK\n\n## 配置Proxy\n\n## 安装plugins\n\n## 安装thrift插件\n\n## Install shellchek to verify shell scripts\n","source":"_posts/technologies/maven/IntelliJ_idea.md","raw":"---\ntitle: IntelliJ idea\ntags: \ncategories:\n- technologies\n- maven\n---\n\n## 下载IntelliJ idea\n\n## 配置Maven\n\n## 选择自安装的JDK\n\n## 配置Proxy\n\n## 安装plugins\n\n## 安装thrift插件\n\n## Install shellchek to verify shell scripts\n","slug":"technologies/maven/IntelliJ_idea","published":1,"date":"2020-08-12T16:05:48.562Z","updated":"2020-04-08T13:11:20.735Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmly008phohx3rrd9vzx","content":"<h2 id=\"下载IntelliJ-idea\"><a href=\"#下载IntelliJ-idea\" class=\"headerlink\" title=\"下载IntelliJ idea\"></a>下载IntelliJ idea</h2><h2 id=\"配置Maven\"><a href=\"#配置Maven\" class=\"headerlink\" title=\"配置Maven\"></a>配置Maven</h2><h2 id=\"选择自安装的JDK\"><a href=\"#选择自安装的JDK\" class=\"headerlink\" title=\"选择自安装的JDK\"></a>选择自安装的JDK</h2><h2 id=\"配置Proxy\"><a href=\"#配置Proxy\" class=\"headerlink\" title=\"配置Proxy\"></a>配置Proxy</h2><h2 id=\"安装plugins\"><a href=\"#安装plugins\" class=\"headerlink\" title=\"安装plugins\"></a>安装plugins</h2><h2 id=\"安装thrift插件\"><a href=\"#安装thrift插件\" class=\"headerlink\" title=\"安装thrift插件\"></a>安装thrift插件</h2><h2 id=\"Install-shellchek-to-verify-shell-scripts\"><a href=\"#Install-shellchek-to-verify-shell-scripts\" class=\"headerlink\" title=\"Install shellchek to verify shell scripts\"></a>Install shellchek to verify shell scripts</h2>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"下载IntelliJ-idea\"><a href=\"#下载IntelliJ-idea\" class=\"headerlink\" title=\"下载IntelliJ idea\"></a>下载IntelliJ idea</h2><h2 id=\"配置Maven\"><a href=\"#配置Maven\" class=\"headerlink\" title=\"配置Maven\"></a>配置Maven</h2><h2 id=\"选择自安装的JDK\"><a href=\"#选择自安装的JDK\" class=\"headerlink\" title=\"选择自安装的JDK\"></a>选择自安装的JDK</h2><h2 id=\"配置Proxy\"><a href=\"#配置Proxy\" class=\"headerlink\" title=\"配置Proxy\"></a>配置Proxy</h2><h2 id=\"安装plugins\"><a href=\"#安装plugins\" class=\"headerlink\" title=\"安装plugins\"></a>安装plugins</h2><h2 id=\"安装thrift插件\"><a href=\"#安装thrift插件\" class=\"headerlink\" title=\"安装thrift插件\"></a>安装thrift插件</h2><h2 id=\"Install-shellchek-to-verify-shell-scripts\"><a href=\"#Install-shellchek-to-verify-shell-scripts\" class=\"headerlink\" title=\"Install shellchek to verify shell scripts\"></a>Install shellchek to verify shell scripts</h2>"},{"title":"Dockerfile introduction","tag":null,"_content":"\n## Dockerfile brief introduction\n> 在Docker中创建镜像最常用的方式，就是使用Dockerfile。Dockerfile是一个Docker镜像的描述文件，我们可以理解成火箭发射的A、B、C、D…的步骤。Dockerfile其内部包含了一条条的指令，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。\n![](01.png)\n![](02.png)\n\n### From\n指明构建的新镜像是来自于哪个基础镜像\n\n\tFrom ubuntu:18.04\n\n### MAINTAINER\n指明镜像维护着及其联系方式（一般是邮箱地址），例如：\n\n\tMAINTAINER Edison Zhou <edisonchou@hotmail.com>\n不过，MAINTAINER并不推荐使用，更推荐使用LABEL来指定镜像作者，例如：\n\n\tLABEL maintainer=\"edisonzhou.cn\"\n\n### RUN\n构建镜像时运行的Shell命令，例如：\n\n\tRUN [\"yum\", \"install\", \"httpd\"]\n\tRUN yum install httpd\n\n### ADD\n拷贝文件或目录到镜像中，例如：\n\n\tADD <src>...<dest>\n\tADD html.tar.gz /var/www/html\n\tADD https://xxx.com/html.tar.gz /var/www/html\n\tPS：如果是URL或压缩包，会自动下载或自动解压。\n\n### COPY\n拷贝文件或目录到镜像中，用法同ADD，只是不支持自动下载和解压，例如：\n\n\tCOPY ./start.sh /start.sh\n\n### WORKDIR\n为RUN、CMD、ENTRYPOINT以及COPY和AND设置工作目录，例如：\n\n\tWORKDIR /home/zhan\n\n### VOLUME\n指定容器挂载点到宿主机自动生成的目录或其他容器，例如：\n\n\tVOLUME [\"/var/lib/mysql\"]\n\tPS：一般不会在Dockerfile中用到，更常见的还是在docker run的时候指定-v数据卷。\n\n### EXPOSE\n声明容器运行的服务端口，例如：\n\n\tEXPOSE 80 443\n\n### CMD\n启动容器时执行的Shell命令，例如：\n\n\tCMD [\"-C\", \"/start.sh\"] \n\tCMD [\"/usr/sbin/sshd\", \"-D\"] \n\tCMD /usr/sbin/sshd -D\n\n### ENTRYPOINT\n启动容器时执行的Shell命令，同CMD类似，只是由ENTRYPOINT启动的程序不会被docker run命令行指定的参数所覆盖，而且，这些命令行参数会被当作参数传递给ENTRYPOINT指定指定的程序，例如：\n\n\tENTRYPOINT [\"/bin/bash\", \"-C\", \"/start.sh\"]\n\tENTRYPOINT /bin/bash -C '/start.sh'\n\tPS：Dockerfile文件中也可以存在多个ENTRYPOINT指令，但仅有最后一个会生效。\n\n### ENV\n设置环境内环境变量，例如：\n\n\tENV MYSQL_ROOT_PASSWORD 123456\n\tENV JAVA_HOME /usr/local/jdk1.8.0_45\n\tENV http_proxy http://proxy:913\n\n### USER\n为RUN、CMD和ENTRYPOINT执行Shell命令指定运行用户，例如：\n\n\tUSER <user>[:<usergroup>]\n\tUSER <UID>[:<UID>]\n\tUSER edisonzhou\n\n### HEALTHCHECK\n告诉Docker如何测试容器以检查它是否仍在工作，即健康检查，例如：\n\n\tHEALTHCHECK --interval=5m --timeout=3s --retries=3 \\\n\t\tCMD curl -f http:/localhost/ || exit 1\n\t其中，一些选项的说明：\n\t--interval=DURATION (default: 30s)：每隔多长时间探测一次，默认30秒\n\t-- timeout= DURATION (default: 30s)：服务响应超时时长，默认30秒\n\t--start-period= DURATION (default: 0s)：服务启动多久后开始探测，默认0秒\n\t--retries=N (default: 3)：认为检测失败几次为宕机，默认3次\n\t一些返回值的说明：\n\t0：容器成功是健康的，随时可以使用\n\t1：不健康的容器无法正常工作\n\t2：保留不使用此退出代码\n\n### ARG\n在构建镜像时，指定一些参数，例如：\n\n\tFROM centos:6\n\tARG user # ARG user=root\n\tUSER $user\n\t这时，我们在docker build时可以带上自定义参数user了，如下所示：\n\tdocker build --build-arg user=edisonzhou Dockerfile .\n\n\n## Use cases\n### Case1: 编译执行在一个image里\n\n\t$ cd /home/zhan\n\n\t$ touch test.c \ntest.c添加如下内容\n\n\t#include <stdio.h>\n\t\n\tint main(int argc, char* argv[])\n\t{\n\t\tprintf(\"Hello World!\\n\");\n\t\treturn 0;\n\t}\n\n\t$ touch Dockerfile \nDockerfile添加如下内容\n\n\tFrom ubuntu:18.04\n\tLABEL maintainer=\"tester.com\"\n\tRUN mkdir -p /home/zhan\n\tWORKDIR /home/zhan\n\tCOPY test.c .\n\tENV http_proxy http://proxy:913\n\tRUN apt-get update\n\tRUN apt-get install gcc -y\n\tRUN gcc -g test.c -o test.o\n\t#CMD [\"/bin/bash\"]\n\tCMD [\"./test.o\"]\n\n构建image\n\n\t$ docker build -t dockerfile-01:1.0 .\n\t$ docker images\n\tREPOSITORY                           TAG                 IMAGE ID            CREATED             SIZE\n\tdockerfile-01                        1.0                 cd9a95fccaa9        45 minutes ago      207MB\n\tubuntu                               18.04               4e5021d210f6        6 weeks ago         64.2MB\n\n * 第一种执行应用方式: 启动容器直接运行可执行文件\n\t$ docker run -rm dockerfile-01\n\t\tHello World!\n * 第二种执行应用方式: 启动容器，进入容器，再手动执行可执行文件\n\t$ docker run -itd --name test01 dockerfile-01 /bin/bash\n\t$ docker exec -it test01 /bin/bash\n\t\troot@bfb87ec4b27a:/home/zhan# ls\n\t\ttest.c  test.o\n\t\troot@bfb87ec4b27a:/home/zhan#\n进入容器可以看到直接到/home/zhan目录，有test.c和test.o两个文件\n\n### Case2: 编译执行在两个image里\n因为编译生成的image非常大，因此把编译生成的文件再copy到另一个image就减小了体积\nDockfile内容如下\n\n\tFrom ubuntu:18.04 as builder # 基于ubuntu:18.04创建第一个image\n\tLABEL maintainer=\"tester.com\"\n\tRUN mkdir -p /home/zhan\n\tWORKDIR /home/zhan\n\tCOPY test.c .\n\tENV http_proxy http://proxy:913\n\tRUN apt-get update\n\tRUN apt-get install gcc -y\n\tRUN gcc -g test.c -o test.o\n\t\n\tFROM ubuntu:18.04 # 基于ubuntu:18.04再创建第二个image\n\tWORKDIR /root/\n\t# 从上面的 image \"builder\" 拷贝编译好的可执行文件/home/zhan/test.o文件到当前image的/root/目录\n\tCOPY --from=builder /home/zhan/test.o .\n\tCMD [\"./test.o\"]\n\n构建image\n\n\t$ docker build -t dockerfile-01:2.0 .\n\t$ docker images\n\tREPOSITORY                           TAG                 IMAGE ID            CREATED             SIZE\n\tdockerfile-01                        2.0                 f29fa900630d        5 seconds ago       64.2MB\n\t<none>                               <none>              8bd7003b9cd8        2 minutes ago       207MB\n\tdockerfile-01                        1.0                 cd9a95fccaa9        45 minutes ago      207MB\n\tubuntu                               18.04               4e5021d210f6        6 weeks ago         64.2MB\n\t\n可以看到新生成的两个image， 一个image为<none>:<none> 大小为207MB, 另一个image为dockerfile-01:2.0 大小为64.2MB\n以后就可以用dockerfile-01:2.0作为项目中的应用docker容器\n\n* 第一种执行应用方式: 启动容器直接运行可执行文件\n\n\n\t$ docker run --rm dockerfile-01:2.0\n\t\tHello World!\n* 第二种执行应用方式: 启动容器，进入容器，再手动执行可执行文件\n\n\n\t$ docker run -itd --name test02 dockerfile-01:2.0 /bin/bash\n\t\tbaef91591402ac368816b8baf9251859db9aa9e378845d88009ad8dffdcb8028\n\t$ docker exec -it test02 /bin/bash\n\t\troot@baef91591402:~# ls\n\t\ttest.o\n\t\troot@baef91591402:~#\n进入容器可以看到直接进入/root目录，只有可执行文件test.o\n\n\n### Additional\n\n找一个目录新建两个文件app.js和Dockerfile\n\n\troot@alpha:/home/zhan/images_test# ls\n\tapp.js  Dockerfile\n\napp.js\n\n\tconst http = require('http');\n\tconst os = require('os');\n\tconsole.log(\"Kubia server starting ...\");\n\t\n\tvar handler = function(request, response) {\n\t\tconsole.log(\"Received request from\" + request.connection.remoteAddress);\n\t\tresponse.writeHead(200);\n\t\tresponse.end(\"You've hit \" + os.hostname() + \"\\n\");\n\t};\n\t\n\tvar www = http.createServer(handler);\n\twww.listen(8080);\n\nDockerfile\n\n\tFROM node:7\n\tADD app.js /app.js\n\tENTRYPOINT [\"node\",\"app.js\"]\n\n运行如下命令\n\n\t$ docker build -t kubia .\n\t$ docker images\n\t$ docker run --name kubia-container -p 8081:8080 -d kubia:latest\n\t$ curl 10.239.140.186:8081 或者 curl http://10.239.1n40.186:8081 (linux添加proxy如child-prc.intel.com:913后用这行命令)\n\tYou've hit fef0dd414fe4\n\t// 浏览器输入http://localhost:8081也能返回同样的container ID, \n\t// 如果机器没有添加proxy代理用 $ curl localhost:8081 就可以\n\n\t$ docker exec -it kubia-container1 bash\n\t$ cat /etc/hostname\n\tfef0dd414fe4 // 发现container的hostname和container ID是一样的十六进制数\n\n\t$ ps aux  // 查看容器内运行的进程\n\tUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n\troot         1  0.0  0.3 813600 26092 ?        Ssl  06:58   0:00 node app.js\n\troot        11  0.1  0.0  20244  3232 pts/0    Ss   07:24   0:00 bash\n\troot        17  0.0  0.0  17500  2048 pts/0    R+   07:26   0:00 ps aux\n\troot@fef0dd414fe4:/#\n\t在宿主主机上运行这个命令 $ ps aux | grep app.js\n\troot     12028  0.0  0.0  21532  1044 pts/1    S+   15:26   0:00 grep --color=auto app.js\n\troot     30631  0.0  0.3 813600 26092 ?        Ssl  14:58   0:00 node app.js\n\t发现进程的ID在容器中与主机上不同, 容器使用独立的PID Linux命名空间并且有着独立的系列号，完全独立于进程树.\n\t正如拥有独立的进程树一样，每个容器也拥有独立的文件系统.\n\t容器内的应用不仅拥有独立的文件系统，还有进程、用户、主机名和网络接口.\n\n## 遇到的问题\ndocker pull ubuntu等系统镜像后登陆上去，配置公司proxy后无法连接网络，apt-get update无法执行\n解决方案: 修改主机上的文件 /etc/docker/daemon.json 内容如下, 添加主机IP:\n\n\t{ \"insecure-registries\": [\"10.239.140.186\"] }\n之后重启docker\n\n\t$ systemctl daemon-reload\n\t$ systemctl restart docker.service\n再次登陆容器配置好proxy, apt-get update就可以执行了\n\n\n\n\n\n","source":"_posts/technologies/docker/dockerfile.md","raw":"---\ntitle: Dockerfile introduction\ntag: \ncategories:\n- technologies\n- docker\n---\n\n## Dockerfile brief introduction\n> 在Docker中创建镜像最常用的方式，就是使用Dockerfile。Dockerfile是一个Docker镜像的描述文件，我们可以理解成火箭发射的A、B、C、D…的步骤。Dockerfile其内部包含了一条条的指令，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。\n![](01.png)\n![](02.png)\n\n### From\n指明构建的新镜像是来自于哪个基础镜像\n\n\tFrom ubuntu:18.04\n\n### MAINTAINER\n指明镜像维护着及其联系方式（一般是邮箱地址），例如：\n\n\tMAINTAINER Edison Zhou <edisonchou@hotmail.com>\n不过，MAINTAINER并不推荐使用，更推荐使用LABEL来指定镜像作者，例如：\n\n\tLABEL maintainer=\"edisonzhou.cn\"\n\n### RUN\n构建镜像时运行的Shell命令，例如：\n\n\tRUN [\"yum\", \"install\", \"httpd\"]\n\tRUN yum install httpd\n\n### ADD\n拷贝文件或目录到镜像中，例如：\n\n\tADD <src>...<dest>\n\tADD html.tar.gz /var/www/html\n\tADD https://xxx.com/html.tar.gz /var/www/html\n\tPS：如果是URL或压缩包，会自动下载或自动解压。\n\n### COPY\n拷贝文件或目录到镜像中，用法同ADD，只是不支持自动下载和解压，例如：\n\n\tCOPY ./start.sh /start.sh\n\n### WORKDIR\n为RUN、CMD、ENTRYPOINT以及COPY和AND设置工作目录，例如：\n\n\tWORKDIR /home/zhan\n\n### VOLUME\n指定容器挂载点到宿主机自动生成的目录或其他容器，例如：\n\n\tVOLUME [\"/var/lib/mysql\"]\n\tPS：一般不会在Dockerfile中用到，更常见的还是在docker run的时候指定-v数据卷。\n\n### EXPOSE\n声明容器运行的服务端口，例如：\n\n\tEXPOSE 80 443\n\n### CMD\n启动容器时执行的Shell命令，例如：\n\n\tCMD [\"-C\", \"/start.sh\"] \n\tCMD [\"/usr/sbin/sshd\", \"-D\"] \n\tCMD /usr/sbin/sshd -D\n\n### ENTRYPOINT\n启动容器时执行的Shell命令，同CMD类似，只是由ENTRYPOINT启动的程序不会被docker run命令行指定的参数所覆盖，而且，这些命令行参数会被当作参数传递给ENTRYPOINT指定指定的程序，例如：\n\n\tENTRYPOINT [\"/bin/bash\", \"-C\", \"/start.sh\"]\n\tENTRYPOINT /bin/bash -C '/start.sh'\n\tPS：Dockerfile文件中也可以存在多个ENTRYPOINT指令，但仅有最后一个会生效。\n\n### ENV\n设置环境内环境变量，例如：\n\n\tENV MYSQL_ROOT_PASSWORD 123456\n\tENV JAVA_HOME /usr/local/jdk1.8.0_45\n\tENV http_proxy http://proxy:913\n\n### USER\n为RUN、CMD和ENTRYPOINT执行Shell命令指定运行用户，例如：\n\n\tUSER <user>[:<usergroup>]\n\tUSER <UID>[:<UID>]\n\tUSER edisonzhou\n\n### HEALTHCHECK\n告诉Docker如何测试容器以检查它是否仍在工作，即健康检查，例如：\n\n\tHEALTHCHECK --interval=5m --timeout=3s --retries=3 \\\n\t\tCMD curl -f http:/localhost/ || exit 1\n\t其中，一些选项的说明：\n\t--interval=DURATION (default: 30s)：每隔多长时间探测一次，默认30秒\n\t-- timeout= DURATION (default: 30s)：服务响应超时时长，默认30秒\n\t--start-period= DURATION (default: 0s)：服务启动多久后开始探测，默认0秒\n\t--retries=N (default: 3)：认为检测失败几次为宕机，默认3次\n\t一些返回值的说明：\n\t0：容器成功是健康的，随时可以使用\n\t1：不健康的容器无法正常工作\n\t2：保留不使用此退出代码\n\n### ARG\n在构建镜像时，指定一些参数，例如：\n\n\tFROM centos:6\n\tARG user # ARG user=root\n\tUSER $user\n\t这时，我们在docker build时可以带上自定义参数user了，如下所示：\n\tdocker build --build-arg user=edisonzhou Dockerfile .\n\n\n## Use cases\n### Case1: 编译执行在一个image里\n\n\t$ cd /home/zhan\n\n\t$ touch test.c \ntest.c添加如下内容\n\n\t#include <stdio.h>\n\t\n\tint main(int argc, char* argv[])\n\t{\n\t\tprintf(\"Hello World!\\n\");\n\t\treturn 0;\n\t}\n\n\t$ touch Dockerfile \nDockerfile添加如下内容\n\n\tFrom ubuntu:18.04\n\tLABEL maintainer=\"tester.com\"\n\tRUN mkdir -p /home/zhan\n\tWORKDIR /home/zhan\n\tCOPY test.c .\n\tENV http_proxy http://proxy:913\n\tRUN apt-get update\n\tRUN apt-get install gcc -y\n\tRUN gcc -g test.c -o test.o\n\t#CMD [\"/bin/bash\"]\n\tCMD [\"./test.o\"]\n\n构建image\n\n\t$ docker build -t dockerfile-01:1.0 .\n\t$ docker images\n\tREPOSITORY                           TAG                 IMAGE ID            CREATED             SIZE\n\tdockerfile-01                        1.0                 cd9a95fccaa9        45 minutes ago      207MB\n\tubuntu                               18.04               4e5021d210f6        6 weeks ago         64.2MB\n\n * 第一种执行应用方式: 启动容器直接运行可执行文件\n\t$ docker run -rm dockerfile-01\n\t\tHello World!\n * 第二种执行应用方式: 启动容器，进入容器，再手动执行可执行文件\n\t$ docker run -itd --name test01 dockerfile-01 /bin/bash\n\t$ docker exec -it test01 /bin/bash\n\t\troot@bfb87ec4b27a:/home/zhan# ls\n\t\ttest.c  test.o\n\t\troot@bfb87ec4b27a:/home/zhan#\n进入容器可以看到直接到/home/zhan目录，有test.c和test.o两个文件\n\n### Case2: 编译执行在两个image里\n因为编译生成的image非常大，因此把编译生成的文件再copy到另一个image就减小了体积\nDockfile内容如下\n\n\tFrom ubuntu:18.04 as builder # 基于ubuntu:18.04创建第一个image\n\tLABEL maintainer=\"tester.com\"\n\tRUN mkdir -p /home/zhan\n\tWORKDIR /home/zhan\n\tCOPY test.c .\n\tENV http_proxy http://proxy:913\n\tRUN apt-get update\n\tRUN apt-get install gcc -y\n\tRUN gcc -g test.c -o test.o\n\t\n\tFROM ubuntu:18.04 # 基于ubuntu:18.04再创建第二个image\n\tWORKDIR /root/\n\t# 从上面的 image \"builder\" 拷贝编译好的可执行文件/home/zhan/test.o文件到当前image的/root/目录\n\tCOPY --from=builder /home/zhan/test.o .\n\tCMD [\"./test.o\"]\n\n构建image\n\n\t$ docker build -t dockerfile-01:2.0 .\n\t$ docker images\n\tREPOSITORY                           TAG                 IMAGE ID            CREATED             SIZE\n\tdockerfile-01                        2.0                 f29fa900630d        5 seconds ago       64.2MB\n\t<none>                               <none>              8bd7003b9cd8        2 minutes ago       207MB\n\tdockerfile-01                        1.0                 cd9a95fccaa9        45 minutes ago      207MB\n\tubuntu                               18.04               4e5021d210f6        6 weeks ago         64.2MB\n\t\n可以看到新生成的两个image， 一个image为<none>:<none> 大小为207MB, 另一个image为dockerfile-01:2.0 大小为64.2MB\n以后就可以用dockerfile-01:2.0作为项目中的应用docker容器\n\n* 第一种执行应用方式: 启动容器直接运行可执行文件\n\n\n\t$ docker run --rm dockerfile-01:2.0\n\t\tHello World!\n* 第二种执行应用方式: 启动容器，进入容器，再手动执行可执行文件\n\n\n\t$ docker run -itd --name test02 dockerfile-01:2.0 /bin/bash\n\t\tbaef91591402ac368816b8baf9251859db9aa9e378845d88009ad8dffdcb8028\n\t$ docker exec -it test02 /bin/bash\n\t\troot@baef91591402:~# ls\n\t\ttest.o\n\t\troot@baef91591402:~#\n进入容器可以看到直接进入/root目录，只有可执行文件test.o\n\n\n### Additional\n\n找一个目录新建两个文件app.js和Dockerfile\n\n\troot@alpha:/home/zhan/images_test# ls\n\tapp.js  Dockerfile\n\napp.js\n\n\tconst http = require('http');\n\tconst os = require('os');\n\tconsole.log(\"Kubia server starting ...\");\n\t\n\tvar handler = function(request, response) {\n\t\tconsole.log(\"Received request from\" + request.connection.remoteAddress);\n\t\tresponse.writeHead(200);\n\t\tresponse.end(\"You've hit \" + os.hostname() + \"\\n\");\n\t};\n\t\n\tvar www = http.createServer(handler);\n\twww.listen(8080);\n\nDockerfile\n\n\tFROM node:7\n\tADD app.js /app.js\n\tENTRYPOINT [\"node\",\"app.js\"]\n\n运行如下命令\n\n\t$ docker build -t kubia .\n\t$ docker images\n\t$ docker run --name kubia-container -p 8081:8080 -d kubia:latest\n\t$ curl 10.239.140.186:8081 或者 curl http://10.239.1n40.186:8081 (linux添加proxy如child-prc.intel.com:913后用这行命令)\n\tYou've hit fef0dd414fe4\n\t// 浏览器输入http://localhost:8081也能返回同样的container ID, \n\t// 如果机器没有添加proxy代理用 $ curl localhost:8081 就可以\n\n\t$ docker exec -it kubia-container1 bash\n\t$ cat /etc/hostname\n\tfef0dd414fe4 // 发现container的hostname和container ID是一样的十六进制数\n\n\t$ ps aux  // 查看容器内运行的进程\n\tUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n\troot         1  0.0  0.3 813600 26092 ?        Ssl  06:58   0:00 node app.js\n\troot        11  0.1  0.0  20244  3232 pts/0    Ss   07:24   0:00 bash\n\troot        17  0.0  0.0  17500  2048 pts/0    R+   07:26   0:00 ps aux\n\troot@fef0dd414fe4:/#\n\t在宿主主机上运行这个命令 $ ps aux | grep app.js\n\troot     12028  0.0  0.0  21532  1044 pts/1    S+   15:26   0:00 grep --color=auto app.js\n\troot     30631  0.0  0.3 813600 26092 ?        Ssl  14:58   0:00 node app.js\n\t发现进程的ID在容器中与主机上不同, 容器使用独立的PID Linux命名空间并且有着独立的系列号，完全独立于进程树.\n\t正如拥有独立的进程树一样，每个容器也拥有独立的文件系统.\n\t容器内的应用不仅拥有独立的文件系统，还有进程、用户、主机名和网络接口.\n\n## 遇到的问题\ndocker pull ubuntu等系统镜像后登陆上去，配置公司proxy后无法连接网络，apt-get update无法执行\n解决方案: 修改主机上的文件 /etc/docker/daemon.json 内容如下, 添加主机IP:\n\n\t{ \"insecure-registries\": [\"10.239.140.186\"] }\n之后重启docker\n\n\t$ systemctl daemon-reload\n\t$ systemctl restart docker.service\n再次登陆容器配置好proxy, apt-get update就可以执行了\n\n\n\n\n\n","slug":"technologies/docker/dockerfile","published":1,"date":"2020-08-12T16:05:48.508Z","updated":"2020-05-31T12:04:21.054Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmm8008qhohx5tai17jd","content":"<h2 id=\"Dockerfile-brief-introduction\"><a href=\"#Dockerfile-brief-introduction\" class=\"headerlink\" title=\"Dockerfile brief introduction\"></a>Dockerfile brief introduction</h2><blockquote>\n<p>在Docker中创建镜像最常用的方式，就是使用Dockerfile。Dockerfile是一个Docker镜像的描述文件，我们可以理解成火箭发射的A、B、C、D…的步骤。Dockerfile其内部包含了一条条的指令，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。<br><img src=\"01.png\" alt=\"\"><br><img src=\"02.png\" alt=\"\"></p>\n</blockquote>\n<h3 id=\"From\"><a href=\"#From\" class=\"headerlink\" title=\"From\"></a>From</h3><p>指明构建的新镜像是来自于哪个基础镜像</p>\n<pre><code>From ubuntu:18.04</code></pre><h3 id=\"MAINTAINER\"><a href=\"#MAINTAINER\" class=\"headerlink\" title=\"MAINTAINER\"></a>MAINTAINER</h3><p>指明镜像维护着及其联系方式（一般是邮箱地址），例如：</p>\n<pre><code>MAINTAINER Edison Zhou &lt;edisonchou@hotmail.com&gt;</code></pre><p>不过，MAINTAINER并不推荐使用，更推荐使用LABEL来指定镜像作者，例如：</p>\n<pre><code>LABEL maintainer=&quot;edisonzhou.cn&quot;</code></pre><h3 id=\"RUN\"><a href=\"#RUN\" class=\"headerlink\" title=\"RUN\"></a>RUN</h3><p>构建镜像时运行的Shell命令，例如：</p>\n<pre><code>RUN [&quot;yum&quot;, &quot;install&quot;, &quot;httpd&quot;]\nRUN yum install httpd</code></pre><h3 id=\"ADD\"><a href=\"#ADD\" class=\"headerlink\" title=\"ADD\"></a>ADD</h3><p>拷贝文件或目录到镜像中，例如：</p>\n<pre><code>ADD &lt;src&gt;...&lt;dest&gt;\nADD html.tar.gz /var/www/html\nADD https://xxx.com/html.tar.gz /var/www/html\nPS：如果是URL或压缩包，会自动下载或自动解压。</code></pre><h3 id=\"COPY\"><a href=\"#COPY\" class=\"headerlink\" title=\"COPY\"></a>COPY</h3><p>拷贝文件或目录到镜像中，用法同ADD，只是不支持自动下载和解压，例如：</p>\n<pre><code>COPY ./start.sh /start.sh</code></pre><h3 id=\"WORKDIR\"><a href=\"#WORKDIR\" class=\"headerlink\" title=\"WORKDIR\"></a>WORKDIR</h3><p>为RUN、CMD、ENTRYPOINT以及COPY和AND设置工作目录，例如：</p>\n<pre><code>WORKDIR /home/zhan</code></pre><h3 id=\"VOLUME\"><a href=\"#VOLUME\" class=\"headerlink\" title=\"VOLUME\"></a>VOLUME</h3><p>指定容器挂载点到宿主机自动生成的目录或其他容器，例如：</p>\n<pre><code>VOLUME [&quot;/var/lib/mysql&quot;]\nPS：一般不会在Dockerfile中用到，更常见的还是在docker run的时候指定-v数据卷。</code></pre><h3 id=\"EXPOSE\"><a href=\"#EXPOSE\" class=\"headerlink\" title=\"EXPOSE\"></a>EXPOSE</h3><p>声明容器运行的服务端口，例如：</p>\n<pre><code>EXPOSE 80 443</code></pre><h3 id=\"CMD\"><a href=\"#CMD\" class=\"headerlink\" title=\"CMD\"></a>CMD</h3><p>启动容器时执行的Shell命令，例如：</p>\n<pre><code>CMD [&quot;-C&quot;, &quot;/start.sh&quot;] \nCMD [&quot;/usr/sbin/sshd&quot;, &quot;-D&quot;] \nCMD /usr/sbin/sshd -D</code></pre><h3 id=\"ENTRYPOINT\"><a href=\"#ENTRYPOINT\" class=\"headerlink\" title=\"ENTRYPOINT\"></a>ENTRYPOINT</h3><p>启动容器时执行的Shell命令，同CMD类似，只是由ENTRYPOINT启动的程序不会被docker run命令行指定的参数所覆盖，而且，这些命令行参数会被当作参数传递给ENTRYPOINT指定指定的程序，例如：</p>\n<pre><code>ENTRYPOINT [&quot;/bin/bash&quot;, &quot;-C&quot;, &quot;/start.sh&quot;]\nENTRYPOINT /bin/bash -C &apos;/start.sh&apos;\nPS：Dockerfile文件中也可以存在多个ENTRYPOINT指令，但仅有最后一个会生效。</code></pre><h3 id=\"ENV\"><a href=\"#ENV\" class=\"headerlink\" title=\"ENV\"></a>ENV</h3><p>设置环境内环境变量，例如：</p>\n<pre><code>ENV MYSQL_ROOT_PASSWORD 123456\nENV JAVA_HOME /usr/local/jdk1.8.0_45\nENV http_proxy http://proxy:913</code></pre><h3 id=\"USER\"><a href=\"#USER\" class=\"headerlink\" title=\"USER\"></a>USER</h3><p>为RUN、CMD和ENTRYPOINT执行Shell命令指定运行用户，例如：</p>\n<pre><code>USER &lt;user&gt;[:&lt;usergroup&gt;]\nUSER &lt;UID&gt;[:&lt;UID&gt;]\nUSER edisonzhou</code></pre><h3 id=\"HEALTHCHECK\"><a href=\"#HEALTHCHECK\" class=\"headerlink\" title=\"HEALTHCHECK\"></a>HEALTHCHECK</h3><p>告诉Docker如何测试容器以检查它是否仍在工作，即健康检查，例如：</p>\n<pre><code>HEALTHCHECK --interval=5m --timeout=3s --retries=3 \\\n    CMD curl -f http:/localhost/ || exit 1\n其中，一些选项的说明：\n--interval=DURATION (default: 30s)：每隔多长时间探测一次，默认30秒\n-- timeout= DURATION (default: 30s)：服务响应超时时长，默认30秒\n--start-period= DURATION (default: 0s)：服务启动多久后开始探测，默认0秒\n--retries=N (default: 3)：认为检测失败几次为宕机，默认3次\n一些返回值的说明：\n0：容器成功是健康的，随时可以使用\n1：不健康的容器无法正常工作\n2：保留不使用此退出代码</code></pre><h3 id=\"ARG\"><a href=\"#ARG\" class=\"headerlink\" title=\"ARG\"></a>ARG</h3><p>在构建镜像时，指定一些参数，例如：</p>\n<pre><code>FROM centos:6\nARG user # ARG user=root\nUSER $user\n这时，我们在docker build时可以带上自定义参数user了，如下所示：\ndocker build --build-arg user=edisonzhou Dockerfile .</code></pre><h2 id=\"Use-cases\"><a href=\"#Use-cases\" class=\"headerlink\" title=\"Use cases\"></a>Use cases</h2><h3 id=\"Case1-编译执行在一个image里\"><a href=\"#Case1-编译执行在一个image里\" class=\"headerlink\" title=\"Case1: 编译执行在一个image里\"></a>Case1: 编译执行在一个image里</h3><pre><code>$ cd /home/zhan\n\n$ touch test.c </code></pre><p>test.c添加如下内容</p>\n<pre><code>#include &lt;stdio.h&gt;\n\nint main(int argc, char* argv[])\n{\n    printf(&quot;Hello World!\\n&quot;);\n    return 0;\n}\n\n$ touch Dockerfile </code></pre><p>Dockerfile添加如下内容</p>\n<pre><code>From ubuntu:18.04\nLABEL maintainer=&quot;tester.com&quot;\nRUN mkdir -p /home/zhan\nWORKDIR /home/zhan\nCOPY test.c .\nENV http_proxy http://proxy:913\nRUN apt-get update\nRUN apt-get install gcc -y\nRUN gcc -g test.c -o test.o\n#CMD [&quot;/bin/bash&quot;]\nCMD [&quot;./test.o&quot;]</code></pre><p>构建image</p>\n<pre><code>$ docker build -t dockerfile-01:1.0 .\n$ docker images\nREPOSITORY                           TAG                 IMAGE ID            CREATED             SIZE\ndockerfile-01                        1.0                 cd9a95fccaa9        45 minutes ago      207MB\nubuntu                               18.04               4e5021d210f6        6 weeks ago         64.2MB</code></pre><ul>\n<li>第一种执行应用方式: 启动容器直接运行可执行文件<br> $ docker run -rm dockerfile-01<pre><code>Hello World!</code></pre></li>\n<li>第二种执行应用方式: 启动容器，进入容器，再手动执行可执行文件<br> $ docker run -itd –name test01 dockerfile-01 /bin/bash<br> $ docker exec -it test01 /bin/bash<pre><code>root@bfb87ec4b27a:/home/zhan# ls\ntest.c  test.o\nroot@bfb87ec4b27a:/home/zhan#</code></pre>进入容器可以看到直接到/home/zhan目录，有test.c和test.o两个文件</li>\n</ul>\n<h3 id=\"Case2-编译执行在两个image里\"><a href=\"#Case2-编译执行在两个image里\" class=\"headerlink\" title=\"Case2: 编译执行在两个image里\"></a>Case2: 编译执行在两个image里</h3><p>因为编译生成的image非常大，因此把编译生成的文件再copy到另一个image就减小了体积<br>Dockfile内容如下</p>\n<pre><code>From ubuntu:18.04 as builder # 基于ubuntu:18.04创建第一个image\nLABEL maintainer=&quot;tester.com&quot;\nRUN mkdir -p /home/zhan\nWORKDIR /home/zhan\nCOPY test.c .\nENV http_proxy http://proxy:913\nRUN apt-get update\nRUN apt-get install gcc -y\nRUN gcc -g test.c -o test.o\n\nFROM ubuntu:18.04 # 基于ubuntu:18.04再创建第二个image\nWORKDIR /root/\n# 从上面的 image &quot;builder&quot; 拷贝编译好的可执行文件/home/zhan/test.o文件到当前image的/root/目录\nCOPY --from=builder /home/zhan/test.o .\nCMD [&quot;./test.o&quot;]</code></pre><p>构建image</p>\n<pre><code>$ docker build -t dockerfile-01:2.0 .\n$ docker images\nREPOSITORY                           TAG                 IMAGE ID            CREATED             SIZE\ndockerfile-01                        2.0                 f29fa900630d        5 seconds ago       64.2MB\n&lt;none&gt;                               &lt;none&gt;              8bd7003b9cd8        2 minutes ago       207MB\ndockerfile-01                        1.0                 cd9a95fccaa9        45 minutes ago      207MB\nubuntu                               18.04               4e5021d210f6        6 weeks ago         64.2MB</code></pre><p>可以看到新生成的两个image， 一个image为<none>:<none> 大小为207MB, 另一个image为dockerfile-01:2.0 大小为64.2MB<br>以后就可以用dockerfile-01:2.0作为项目中的应用docker容器</p>\n<ul>\n<li>第一种执行应用方式: 启动容器直接运行可执行文件</li>\n</ul>\n<pre><code>$ docker run --rm dockerfile-01:2.0\n    Hello World!</code></pre><ul>\n<li>第二种执行应用方式: 启动容器，进入容器，再手动执行可执行文件</li>\n</ul>\n<pre><code>$ docker run -itd --name test02 dockerfile-01:2.0 /bin/bash\n    baef91591402ac368816b8baf9251859db9aa9e378845d88009ad8dffdcb8028\n$ docker exec -it test02 /bin/bash\n    root@baef91591402:~# ls\n    test.o\n    root@baef91591402:~#</code></pre><p>进入容器可以看到直接进入/root目录，只有可执行文件test.o</p>\n<h3 id=\"Additional\"><a href=\"#Additional\" class=\"headerlink\" title=\"Additional\"></a>Additional</h3><p>找一个目录新建两个文件app.js和Dockerfile</p>\n<pre><code>root@alpha:/home/zhan/images_test# ls\napp.js  Dockerfile</code></pre><p>app.js</p>\n<pre><code>const http = require(&apos;http&apos;);\nconst os = require(&apos;os&apos;);\nconsole.log(&quot;Kubia server starting ...&quot;);\n\nvar handler = function(request, response) {\n    console.log(&quot;Received request from&quot; + request.connection.remoteAddress);\n    response.writeHead(200);\n    response.end(&quot;You&apos;ve hit &quot; + os.hostname() + &quot;\\n&quot;);\n};\n\nvar www = http.createServer(handler);\nwww.listen(8080);</code></pre><p>Dockerfile</p>\n<pre><code>FROM node:7\nADD app.js /app.js\nENTRYPOINT [&quot;node&quot;,&quot;app.js&quot;]</code></pre><p>运行如下命令</p>\n<pre><code>$ docker build -t kubia .\n$ docker images\n$ docker run --name kubia-container -p 8081:8080 -d kubia:latest\n$ curl 10.239.140.186:8081 或者 curl http://10.239.1n40.186:8081 (linux添加proxy如child-prc.intel.com:913后用这行命令)\nYou&apos;ve hit fef0dd414fe4\n// 浏览器输入http://localhost:8081也能返回同样的container ID, \n// 如果机器没有添加proxy代理用 $ curl localhost:8081 就可以\n\n$ docker exec -it kubia-container1 bash\n$ cat /etc/hostname\nfef0dd414fe4 // 发现container的hostname和container ID是一样的十六进制数\n\n$ ps aux  // 查看容器内运行的进程\nUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot         1  0.0  0.3 813600 26092 ?        Ssl  06:58   0:00 node app.js\nroot        11  0.1  0.0  20244  3232 pts/0    Ss   07:24   0:00 bash\nroot        17  0.0  0.0  17500  2048 pts/0    R+   07:26   0:00 ps aux\nroot@fef0dd414fe4:/#\n在宿主主机上运行这个命令 $ ps aux | grep app.js\nroot     12028  0.0  0.0  21532  1044 pts/1    S+   15:26   0:00 grep --color=auto app.js\nroot     30631  0.0  0.3 813600 26092 ?        Ssl  14:58   0:00 node app.js\n发现进程的ID在容器中与主机上不同, 容器使用独立的PID Linux命名空间并且有着独立的系列号，完全独立于进程树.\n正如拥有独立的进程树一样，每个容器也拥有独立的文件系统.\n容器内的应用不仅拥有独立的文件系统，还有进程、用户、主机名和网络接口.</code></pre><h2 id=\"遇到的问题\"><a href=\"#遇到的问题\" class=\"headerlink\" title=\"遇到的问题\"></a>遇到的问题</h2><p>docker pull ubuntu等系统镜像后登陆上去，配置公司proxy后无法连接网络，apt-get update无法执行<br>解决方案: 修改主机上的文件 /etc/docker/daemon.json 内容如下, 添加主机IP:</p>\n<pre><code>{ &quot;insecure-registries&quot;: [&quot;10.239.140.186&quot;] }</code></pre><p>之后重启docker</p>\n<pre><code>$ systemctl daemon-reload\n$ systemctl restart docker.service</code></pre><p>再次登陆容器配置好proxy, apt-get update就可以执行了</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Dockerfile-brief-introduction\"><a href=\"#Dockerfile-brief-introduction\" class=\"headerlink\" title=\"Dockerfile brief introduction\"></a>Dockerfile brief introduction</h2><blockquote>\n<p>在Docker中创建镜像最常用的方式，就是使用Dockerfile。Dockerfile是一个Docker镜像的描述文件，我们可以理解成火箭发射的A、B、C、D…的步骤。Dockerfile其内部包含了一条条的指令，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。<br><img src=\"01.png\" alt=\"\"><br><img src=\"02.png\" alt=\"\"></p>\n</blockquote>\n<h3 id=\"From\"><a href=\"#From\" class=\"headerlink\" title=\"From\"></a>From</h3><p>指明构建的新镜像是来自于哪个基础镜像</p>\n<pre><code>From ubuntu:18.04</code></pre><h3 id=\"MAINTAINER\"><a href=\"#MAINTAINER\" class=\"headerlink\" title=\"MAINTAINER\"></a>MAINTAINER</h3><p>指明镜像维护着及其联系方式（一般是邮箱地址），例如：</p>\n<pre><code>MAINTAINER Edison Zhou &lt;edisonchou@hotmail.com&gt;</code></pre><p>不过，MAINTAINER并不推荐使用，更推荐使用LABEL来指定镜像作者，例如：</p>\n<pre><code>LABEL maintainer=&quot;edisonzhou.cn&quot;</code></pre><h3 id=\"RUN\"><a href=\"#RUN\" class=\"headerlink\" title=\"RUN\"></a>RUN</h3><p>构建镜像时运行的Shell命令，例如：</p>\n<pre><code>RUN [&quot;yum&quot;, &quot;install&quot;, &quot;httpd&quot;]\nRUN yum install httpd</code></pre><h3 id=\"ADD\"><a href=\"#ADD\" class=\"headerlink\" title=\"ADD\"></a>ADD</h3><p>拷贝文件或目录到镜像中，例如：</p>\n<pre><code>ADD &lt;src&gt;...&lt;dest&gt;\nADD html.tar.gz /var/www/html\nADD https://xxx.com/html.tar.gz /var/www/html\nPS：如果是URL或压缩包，会自动下载或自动解压。</code></pre><h3 id=\"COPY\"><a href=\"#COPY\" class=\"headerlink\" title=\"COPY\"></a>COPY</h3><p>拷贝文件或目录到镜像中，用法同ADD，只是不支持自动下载和解压，例如：</p>\n<pre><code>COPY ./start.sh /start.sh</code></pre><h3 id=\"WORKDIR\"><a href=\"#WORKDIR\" class=\"headerlink\" title=\"WORKDIR\"></a>WORKDIR</h3><p>为RUN、CMD、ENTRYPOINT以及COPY和AND设置工作目录，例如：</p>\n<pre><code>WORKDIR /home/zhan</code></pre><h3 id=\"VOLUME\"><a href=\"#VOLUME\" class=\"headerlink\" title=\"VOLUME\"></a>VOLUME</h3><p>指定容器挂载点到宿主机自动生成的目录或其他容器，例如：</p>\n<pre><code>VOLUME [&quot;/var/lib/mysql&quot;]\nPS：一般不会在Dockerfile中用到，更常见的还是在docker run的时候指定-v数据卷。</code></pre><h3 id=\"EXPOSE\"><a href=\"#EXPOSE\" class=\"headerlink\" title=\"EXPOSE\"></a>EXPOSE</h3><p>声明容器运行的服务端口，例如：</p>\n<pre><code>EXPOSE 80 443</code></pre><h3 id=\"CMD\"><a href=\"#CMD\" class=\"headerlink\" title=\"CMD\"></a>CMD</h3><p>启动容器时执行的Shell命令，例如：</p>\n<pre><code>CMD [&quot;-C&quot;, &quot;/start.sh&quot;] \nCMD [&quot;/usr/sbin/sshd&quot;, &quot;-D&quot;] \nCMD /usr/sbin/sshd -D</code></pre><h3 id=\"ENTRYPOINT\"><a href=\"#ENTRYPOINT\" class=\"headerlink\" title=\"ENTRYPOINT\"></a>ENTRYPOINT</h3><p>启动容器时执行的Shell命令，同CMD类似，只是由ENTRYPOINT启动的程序不会被docker run命令行指定的参数所覆盖，而且，这些命令行参数会被当作参数传递给ENTRYPOINT指定指定的程序，例如：</p>\n<pre><code>ENTRYPOINT [&quot;/bin/bash&quot;, &quot;-C&quot;, &quot;/start.sh&quot;]\nENTRYPOINT /bin/bash -C &apos;/start.sh&apos;\nPS：Dockerfile文件中也可以存在多个ENTRYPOINT指令，但仅有最后一个会生效。</code></pre><h3 id=\"ENV\"><a href=\"#ENV\" class=\"headerlink\" title=\"ENV\"></a>ENV</h3><p>设置环境内环境变量，例如：</p>\n<pre><code>ENV MYSQL_ROOT_PASSWORD 123456\nENV JAVA_HOME /usr/local/jdk1.8.0_45\nENV http_proxy http://proxy:913</code></pre><h3 id=\"USER\"><a href=\"#USER\" class=\"headerlink\" title=\"USER\"></a>USER</h3><p>为RUN、CMD和ENTRYPOINT执行Shell命令指定运行用户，例如：</p>\n<pre><code>USER &lt;user&gt;[:&lt;usergroup&gt;]\nUSER &lt;UID&gt;[:&lt;UID&gt;]\nUSER edisonzhou</code></pre><h3 id=\"HEALTHCHECK\"><a href=\"#HEALTHCHECK\" class=\"headerlink\" title=\"HEALTHCHECK\"></a>HEALTHCHECK</h3><p>告诉Docker如何测试容器以检查它是否仍在工作，即健康检查，例如：</p>\n<pre><code>HEALTHCHECK --interval=5m --timeout=3s --retries=3 \\\n    CMD curl -f http:/localhost/ || exit 1\n其中，一些选项的说明：\n--interval=DURATION (default: 30s)：每隔多长时间探测一次，默认30秒\n-- timeout= DURATION (default: 30s)：服务响应超时时长，默认30秒\n--start-period= DURATION (default: 0s)：服务启动多久后开始探测，默认0秒\n--retries=N (default: 3)：认为检测失败几次为宕机，默认3次\n一些返回值的说明：\n0：容器成功是健康的，随时可以使用\n1：不健康的容器无法正常工作\n2：保留不使用此退出代码</code></pre><h3 id=\"ARG\"><a href=\"#ARG\" class=\"headerlink\" title=\"ARG\"></a>ARG</h3><p>在构建镜像时，指定一些参数，例如：</p>\n<pre><code>FROM centos:6\nARG user # ARG user=root\nUSER $user\n这时，我们在docker build时可以带上自定义参数user了，如下所示：\ndocker build --build-arg user=edisonzhou Dockerfile .</code></pre><h2 id=\"Use-cases\"><a href=\"#Use-cases\" class=\"headerlink\" title=\"Use cases\"></a>Use cases</h2><h3 id=\"Case1-编译执行在一个image里\"><a href=\"#Case1-编译执行在一个image里\" class=\"headerlink\" title=\"Case1: 编译执行在一个image里\"></a>Case1: 编译执行在一个image里</h3><pre><code>$ cd /home/zhan\n\n$ touch test.c </code></pre><p>test.c添加如下内容</p>\n<pre><code>#include &lt;stdio.h&gt;\n\nint main(int argc, char* argv[])\n{\n    printf(&quot;Hello World!\\n&quot;);\n    return 0;\n}\n\n$ touch Dockerfile </code></pre><p>Dockerfile添加如下内容</p>\n<pre><code>From ubuntu:18.04\nLABEL maintainer=&quot;tester.com&quot;\nRUN mkdir -p /home/zhan\nWORKDIR /home/zhan\nCOPY test.c .\nENV http_proxy http://proxy:913\nRUN apt-get update\nRUN apt-get install gcc -y\nRUN gcc -g test.c -o test.o\n#CMD [&quot;/bin/bash&quot;]\nCMD [&quot;./test.o&quot;]</code></pre><p>构建image</p>\n<pre><code>$ docker build -t dockerfile-01:1.0 .\n$ docker images\nREPOSITORY                           TAG                 IMAGE ID            CREATED             SIZE\ndockerfile-01                        1.0                 cd9a95fccaa9        45 minutes ago      207MB\nubuntu                               18.04               4e5021d210f6        6 weeks ago         64.2MB</code></pre><ul>\n<li>第一种执行应用方式: 启动容器直接运行可执行文件<br> $ docker run -rm dockerfile-01<pre><code>Hello World!</code></pre></li>\n<li>第二种执行应用方式: 启动容器，进入容器，再手动执行可执行文件<br> $ docker run -itd –name test01 dockerfile-01 /bin/bash<br> $ docker exec -it test01 /bin/bash<pre><code>root@bfb87ec4b27a:/home/zhan# ls\ntest.c  test.o\nroot@bfb87ec4b27a:/home/zhan#</code></pre>进入容器可以看到直接到/home/zhan目录，有test.c和test.o两个文件</li>\n</ul>\n<h3 id=\"Case2-编译执行在两个image里\"><a href=\"#Case2-编译执行在两个image里\" class=\"headerlink\" title=\"Case2: 编译执行在两个image里\"></a>Case2: 编译执行在两个image里</h3><p>因为编译生成的image非常大，因此把编译生成的文件再copy到另一个image就减小了体积<br>Dockfile内容如下</p>\n<pre><code>From ubuntu:18.04 as builder # 基于ubuntu:18.04创建第一个image\nLABEL maintainer=&quot;tester.com&quot;\nRUN mkdir -p /home/zhan\nWORKDIR /home/zhan\nCOPY test.c .\nENV http_proxy http://proxy:913\nRUN apt-get update\nRUN apt-get install gcc -y\nRUN gcc -g test.c -o test.o\n\nFROM ubuntu:18.04 # 基于ubuntu:18.04再创建第二个image\nWORKDIR /root/\n# 从上面的 image &quot;builder&quot; 拷贝编译好的可执行文件/home/zhan/test.o文件到当前image的/root/目录\nCOPY --from=builder /home/zhan/test.o .\nCMD [&quot;./test.o&quot;]</code></pre><p>构建image</p>\n<pre><code>$ docker build -t dockerfile-01:2.0 .\n$ docker images\nREPOSITORY                           TAG                 IMAGE ID            CREATED             SIZE\ndockerfile-01                        2.0                 f29fa900630d        5 seconds ago       64.2MB\n&lt;none&gt;                               &lt;none&gt;              8bd7003b9cd8        2 minutes ago       207MB\ndockerfile-01                        1.0                 cd9a95fccaa9        45 minutes ago      207MB\nubuntu                               18.04               4e5021d210f6        6 weeks ago         64.2MB</code></pre><p>可以看到新生成的两个image， 一个image为<none>:<none> 大小为207MB, 另一个image为dockerfile-01:2.0 大小为64.2MB<br>以后就可以用dockerfile-01:2.0作为项目中的应用docker容器</p>\n<ul>\n<li>第一种执行应用方式: 启动容器直接运行可执行文件</li>\n</ul>\n<pre><code>$ docker run --rm dockerfile-01:2.0\n    Hello World!</code></pre><ul>\n<li>第二种执行应用方式: 启动容器，进入容器，再手动执行可执行文件</li>\n</ul>\n<pre><code>$ docker run -itd --name test02 dockerfile-01:2.0 /bin/bash\n    baef91591402ac368816b8baf9251859db9aa9e378845d88009ad8dffdcb8028\n$ docker exec -it test02 /bin/bash\n    root@baef91591402:~# ls\n    test.o\n    root@baef91591402:~#</code></pre><p>进入容器可以看到直接进入/root目录，只有可执行文件test.o</p>\n<h3 id=\"Additional\"><a href=\"#Additional\" class=\"headerlink\" title=\"Additional\"></a>Additional</h3><p>找一个目录新建两个文件app.js和Dockerfile</p>\n<pre><code>root@alpha:/home/zhan/images_test# ls\napp.js  Dockerfile</code></pre><p>app.js</p>\n<pre><code>const http = require(&apos;http&apos;);\nconst os = require(&apos;os&apos;);\nconsole.log(&quot;Kubia server starting ...&quot;);\n\nvar handler = function(request, response) {\n    console.log(&quot;Received request from&quot; + request.connection.remoteAddress);\n    response.writeHead(200);\n    response.end(&quot;You&apos;ve hit &quot; + os.hostname() + &quot;\\n&quot;);\n};\n\nvar www = http.createServer(handler);\nwww.listen(8080);</code></pre><p>Dockerfile</p>\n<pre><code>FROM node:7\nADD app.js /app.js\nENTRYPOINT [&quot;node&quot;,&quot;app.js&quot;]</code></pre><p>运行如下命令</p>\n<pre><code>$ docker build -t kubia .\n$ docker images\n$ docker run --name kubia-container -p 8081:8080 -d kubia:latest\n$ curl 10.239.140.186:8081 或者 curl http://10.239.1n40.186:8081 (linux添加proxy如child-prc.intel.com:913后用这行命令)\nYou&apos;ve hit fef0dd414fe4\n// 浏览器输入http://localhost:8081也能返回同样的container ID, \n// 如果机器没有添加proxy代理用 $ curl localhost:8081 就可以\n\n$ docker exec -it kubia-container1 bash\n$ cat /etc/hostname\nfef0dd414fe4 // 发现container的hostname和container ID是一样的十六进制数\n\n$ ps aux  // 查看容器内运行的进程\nUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot         1  0.0  0.3 813600 26092 ?        Ssl  06:58   0:00 node app.js\nroot        11  0.1  0.0  20244  3232 pts/0    Ss   07:24   0:00 bash\nroot        17  0.0  0.0  17500  2048 pts/0    R+   07:26   0:00 ps aux\nroot@fef0dd414fe4:/#\n在宿主主机上运行这个命令 $ ps aux | grep app.js\nroot     12028  0.0  0.0  21532  1044 pts/1    S+   15:26   0:00 grep --color=auto app.js\nroot     30631  0.0  0.3 813600 26092 ?        Ssl  14:58   0:00 node app.js\n发现进程的ID在容器中与主机上不同, 容器使用独立的PID Linux命名空间并且有着独立的系列号，完全独立于进程树.\n正如拥有独立的进程树一样，每个容器也拥有独立的文件系统.\n容器内的应用不仅拥有独立的文件系统，还有进程、用户、主机名和网络接口.</code></pre><h2 id=\"遇到的问题\"><a href=\"#遇到的问题\" class=\"headerlink\" title=\"遇到的问题\"></a>遇到的问题</h2><p>docker pull ubuntu等系统镜像后登陆上去，配置公司proxy后无法连接网络，apt-get update无法执行<br>解决方案: 修改主机上的文件 /etc/docker/daemon.json 内容如下, 添加主机IP:</p>\n<pre><code>{ &quot;insecure-registries&quot;: [&quot;10.239.140.186&quot;] }</code></pre><p>之后重启docker</p>\n<pre><code>$ systemctl daemon-reload\n$ systemctl restart docker.service</code></pre><p>再次登陆容器配置好proxy, apt-get update就可以执行了</p>\n"},{"title":"Maven_eclipse_tomcat_JDK1.8_configuration","_content":"\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\nWindows 环境:\n\n下载Maven，搜集网上配置PATH环境变量等\n$ vim apache-maven-3.6.3\\conf\\settings.xml\n$ C:\\Users\\UserName\\.m2\\settings.xml (没有.m2路径就不设)\n\n1. 设置local repository: // maven从中央仓库下载到本地仓库\n```\n    <localRepository>C:\\Users\\UserName\\***\\software_package\\Maven\\maven_repository</localRepository>\n```\n\n2. 设置proxy:\n```\n    <proxy>\n       <id>my-proxy1</id>\n       <active>true</active>\n       <protocol>http</protocol>\n       <host>child-prc.intel.com</host>\n       <port>913</port>\n    </proxy>\n    <proxy>\n       <id>my-proxy2</id>\n       <active>true</active>\n       <protocol>https</protocol>\n       <host>child-prc.intel.com</host>\n       <port>913</port>\n    </proxy>\n```\n\n3. 设置tomcat用户名和密码，如果tomcat安装时候或安装后tomcat的配置文件没有设置用户名和密码此处可忽略\n```\n    <server>\n      <id>tomcat8</id>\n      <username>admin</username>\n      <password>123456</password>\n    </server>\n```\n\n设置aliyun 镜像:\n```\n  <mirrors>\n    <mirror>\n        <id>nexus-aliyun</id>\n        <mirrorOf>central</mirrorOf>\n        <name>Nexus aliyun</name>\n        <url>http://maven.aliyun.com/nexus/content/repositories/central</url>\n        <!--<url>http://maven.aliyun.com/nexus/content/groups/public</url>-->\n    </mirror>\n  </mirrors>\n```\n\n打开cmd控制台输入：mvn -v 查看版本\n$ mvn help:system\t\t// 可看到数据正常下载即为成功\n// $ ping repo1.maven.org //此远程repo好像不能访问，不过没关系，上面成功即可\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n安装tomcat服务器\nhttp://tomcat.apache.org/\n然后配置到eclipse\n\n打开C:\\Program Files\\Tomcat 8.5\\conf\\server.xml\n\t网上说需把<Server port=\"-1\" shutdown=\"SHUTDOWN\"> 改为 <Server port=\"8005\" shutdown=\"SHUTDOWN\">\n\t这里没改, 运行OK\n\n打开C:\\Program Files\\Tomcat 8.5\\conf\\tomcat-users.xml\n添加如下内容, 设置tomcat密码，也可以不设置，设置后需要在maven的**\\config\\settings.xml配置文件中也添加tomcat密码\n```\n<role rolename=\"manager\"/>\n<role rolename=\"manager-gui\"/>\n<role rolename=\"admin\"/>\n<role rolename=\"admin-gui\"/>\n<role rolename=\"manager-script\"/>\n<user username=\"admin\" password=\"123456\" roles=\"admin-gui,admin,manager-gui,manager,manager-script\"/>\n```\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n官网下载eclipse（免费）\nhttps://www.eclipse.org/downloads/\n第一种: 下载安装包:\n\t直接点击下载，下载后安装选择Eclipse IDE for Enterprise Java Developers就可以了(提前安装配置好JDK1.8等版本环境变量)\n第二种： 下载压缩包(解压缩时候有问题),\n\tDownload Packages -> Eclipse IDE for Enterprise Java Developers (includes Incubating components)压缩包\n\t-> 选择中国镜像 -> 下载\n1. 打开eclipse, Window -> Preferences -> Maven -> installations -> Add -> 选择自己装的Maven，否则内嵌的Maven没有proxy\n2. 打开eclipse, Window -> Preferences -> Maven -> User Settings \n  -> Global/User Settings都设置为 ***/apache-maven-3.6.3\\conf\\settings.xml -> Update Settings -> Apply -> Apply and Close\n\n\n创建 maven web项目并运行:\n1. File -> New -> maven Project -> Create a simple project(skip archetype selection) \n\t-> Next -> 输入Group Id: com.test ,Artifact Id 输入 test_demo, Packaging： war(选择建立web服务此处必须选为war)\n2. 右击项目名 点击最下面Properties -> Maven下面的Project Facets -> 先不勾选Dynamic Web Module，选择右边的Runtimes并选中安装过的tomcat8.5\n\t-> Apply -> Apply and close -> 重新打开上面的页面 -> 选中Dynamic Web Module 并 修改右边 Version 试着选各个版本使支持\n\t-> 点击下面出现的 \"i Furtherconfiguration available...\" -> Conten directory: 内容改为 \"src/main/webapp\" \n\t-> 勾选中下面的Generate web.xml deployment descripter -> Apply -> Apply and Close\n3. 在 src/main/webapp 目录下新建个index.js文件内容如下:\n```\n<%@ page language=\"java\" contentType=\"text/html; charset=ISO-8859-1\"\n    pageEncoding=\"ISO-8859-1\"%>\n<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"ISO-8859-1\">\n<title>Insert title here</title>\n</head>\n<body>\n<p>Hello test demo</p>\n</body>\n</html>\n```\n\n4. 右击项目名 -> Run As -> Run on Server， 如果没有Run on Server选项重新打开Project Facets页面再Apply -> Apply and Close\n5. 浏览器输入http://localhost:8080/test_demo/即可看到信息: Hello test demo\n\n创建Parent/jar/web项目:\n\tFile -> New -> Other -> Maven -> Maven Project 按照网上操作即可创建maven pom/jar/war三种项目，其中pom是父类管理其它jar和war(web)等project\n\n> 创建好maven项目后，修改jar或war的pom.xml(项目对象模型(Project Object Modet,POM))文件后\n\t鼠标右击pom.xml -> Maven -> Update Project... -> 可勾选下面的Force Update of Snapshots/Releases -> OK\n```\n#> eclipse for java ee 创建好maven web项目后会出错，原因是缺少webDemo/src/main/webapp/WEB-INF/web.xml\n#第一种：\t手动创建文件夹WEB-INF和文件web.xml,然后添加如下内容\n#<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n#<web-app version=\"2.5\" xmlns=\"http://java.sun.com/xml/ns/javaee\"\n#\txmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n#\txsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee \n#\thttp://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\">\n#</web-app>\n#\n#第二种: 鼠标右击webDemo -> Java EE Tools -> Generate Deployment Descriptor Stub 即可自动生成上面的web.xml文件\n```\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\nVScode 配置 Maven 安装环境 创建Maven项目\n\nFile -> Perferences -> Settings -> 搜索Maven -> 点击打开 \"Edit in settings.json\"文件\n\n``` java\n\"remote.SSH.remotePlatform\": {\n        \"10.239.85.244\": \"linux\",\n        \"10.239.65.163\": \"linux\"\n    },\n\n * Windows 添加配置如下内容:\n\"java.home\": \"C:\\\\Program Files\\\\Java\\\\jdk1.8.0_241\",\n\"java.configuration.maven.userSettings\": \"C:\\\\Users\\\\UserName\\\\Desktop\\\\software_package\\\\apache-maven-3.6.3\\\\conf\\\\settings.xml\",\n\"maven.executable.path\": \"C:\\\\Users\\\\UserName\\\\Desktop\\\\software_package\\\\apache-maven-3.6.3\\\\bin\\\\mvn\",\n\n * Linux 添加配置如下内容:\n\"java.home\": \"/usr/local/jdk1.8/\",\n\"java.configuration.maven.userSettings\": \"/usr/maven/apache-maven-3.6.3/conf/settings.xml\",\n\"maven.executable.path\": \"/usr/maven/apache-maven-3.6.3/bin/mvn\",\n\n\"maven.terminal.customEnv\": [\n        {\n            \"environmentVariable\": \"JAVA_HOME\",\n            //\"value\": \"C:\\\\Program Files\\\\Java\\\\jdk1.8.0_241\"\t\t// Windows\n            \"value\": \"/usr/local/jdk1.8\"\t\t\t\t\t\t\t// Linux\n        }\n    ]\n\n\"remote.SSH.configFile\": \"C:\\\\Users\\\\UserName\\\\.ssh\\\\config\"\n```\n\n\nCtrl + shift + P 选择 \"Maven:Create Maven Project\" 创建 Maven 项目\nSelect an archetype: 选择 maven-archetype-quickstart -> 选择版本 -> 选择生成目录\n-> VScode 终端 输入Group Id: 如com.imooc -> 输入Artifact Id: 如microservice -> 输入package： 直接回车 -> 输入Version: 直接回车\n\n1. 第一此创建Maven 父 项目pom.xml 没有 <packaging>pom</packaging> 需要手动添加, 右击 pom.xml -> Update project configuration\n2. 创建子项目， 右击上面项目名， 选择 Create Maven Project ......'groupId': com.imooc -> 'artifactId': test -> 'version' 1.0-SNAPSHOT: :回车\n3. 创建子项目后查看pom.xml可以发现自动添加了<parent></parent>标签\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n","source":"_posts/technologies/maven/maven_eclipse_tomcat_JDK1.8_configuration.md","raw":"---\ntitle: Maven_eclipse_tomcat_JDK1.8_configuration\ntags: \ncategories:\n- technologies\n- maven\n---\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\nWindows 环境:\n\n下载Maven，搜集网上配置PATH环境变量等\n$ vim apache-maven-3.6.3\\conf\\settings.xml\n$ C:\\Users\\UserName\\.m2\\settings.xml (没有.m2路径就不设)\n\n1. 设置local repository: // maven从中央仓库下载到本地仓库\n```\n    <localRepository>C:\\Users\\UserName\\***\\software_package\\Maven\\maven_repository</localRepository>\n```\n\n2. 设置proxy:\n```\n    <proxy>\n       <id>my-proxy1</id>\n       <active>true</active>\n       <protocol>http</protocol>\n       <host>child-prc.intel.com</host>\n       <port>913</port>\n    </proxy>\n    <proxy>\n       <id>my-proxy2</id>\n       <active>true</active>\n       <protocol>https</protocol>\n       <host>child-prc.intel.com</host>\n       <port>913</port>\n    </proxy>\n```\n\n3. 设置tomcat用户名和密码，如果tomcat安装时候或安装后tomcat的配置文件没有设置用户名和密码此处可忽略\n```\n    <server>\n      <id>tomcat8</id>\n      <username>admin</username>\n      <password>123456</password>\n    </server>\n```\n\n设置aliyun 镜像:\n```\n  <mirrors>\n    <mirror>\n        <id>nexus-aliyun</id>\n        <mirrorOf>central</mirrorOf>\n        <name>Nexus aliyun</name>\n        <url>http://maven.aliyun.com/nexus/content/repositories/central</url>\n        <!--<url>http://maven.aliyun.com/nexus/content/groups/public</url>-->\n    </mirror>\n  </mirrors>\n```\n\n打开cmd控制台输入：mvn -v 查看版本\n$ mvn help:system\t\t// 可看到数据正常下载即为成功\n// $ ping repo1.maven.org //此远程repo好像不能访问，不过没关系，上面成功即可\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n安装tomcat服务器\nhttp://tomcat.apache.org/\n然后配置到eclipse\n\n打开C:\\Program Files\\Tomcat 8.5\\conf\\server.xml\n\t网上说需把<Server port=\"-1\" shutdown=\"SHUTDOWN\"> 改为 <Server port=\"8005\" shutdown=\"SHUTDOWN\">\n\t这里没改, 运行OK\n\n打开C:\\Program Files\\Tomcat 8.5\\conf\\tomcat-users.xml\n添加如下内容, 设置tomcat密码，也可以不设置，设置后需要在maven的**\\config\\settings.xml配置文件中也添加tomcat密码\n```\n<role rolename=\"manager\"/>\n<role rolename=\"manager-gui\"/>\n<role rolename=\"admin\"/>\n<role rolename=\"admin-gui\"/>\n<role rolename=\"manager-script\"/>\n<user username=\"admin\" password=\"123456\" roles=\"admin-gui,admin,manager-gui,manager,manager-script\"/>\n```\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n官网下载eclipse（免费）\nhttps://www.eclipse.org/downloads/\n第一种: 下载安装包:\n\t直接点击下载，下载后安装选择Eclipse IDE for Enterprise Java Developers就可以了(提前安装配置好JDK1.8等版本环境变量)\n第二种： 下载压缩包(解压缩时候有问题),\n\tDownload Packages -> Eclipse IDE for Enterprise Java Developers (includes Incubating components)压缩包\n\t-> 选择中国镜像 -> 下载\n1. 打开eclipse, Window -> Preferences -> Maven -> installations -> Add -> 选择自己装的Maven，否则内嵌的Maven没有proxy\n2. 打开eclipse, Window -> Preferences -> Maven -> User Settings \n  -> Global/User Settings都设置为 ***/apache-maven-3.6.3\\conf\\settings.xml -> Update Settings -> Apply -> Apply and Close\n\n\n创建 maven web项目并运行:\n1. File -> New -> maven Project -> Create a simple project(skip archetype selection) \n\t-> Next -> 输入Group Id: com.test ,Artifact Id 输入 test_demo, Packaging： war(选择建立web服务此处必须选为war)\n2. 右击项目名 点击最下面Properties -> Maven下面的Project Facets -> 先不勾选Dynamic Web Module，选择右边的Runtimes并选中安装过的tomcat8.5\n\t-> Apply -> Apply and close -> 重新打开上面的页面 -> 选中Dynamic Web Module 并 修改右边 Version 试着选各个版本使支持\n\t-> 点击下面出现的 \"i Furtherconfiguration available...\" -> Conten directory: 内容改为 \"src/main/webapp\" \n\t-> 勾选中下面的Generate web.xml deployment descripter -> Apply -> Apply and Close\n3. 在 src/main/webapp 目录下新建个index.js文件内容如下:\n```\n<%@ page language=\"java\" contentType=\"text/html; charset=ISO-8859-1\"\n    pageEncoding=\"ISO-8859-1\"%>\n<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"ISO-8859-1\">\n<title>Insert title here</title>\n</head>\n<body>\n<p>Hello test demo</p>\n</body>\n</html>\n```\n\n4. 右击项目名 -> Run As -> Run on Server， 如果没有Run on Server选项重新打开Project Facets页面再Apply -> Apply and Close\n5. 浏览器输入http://localhost:8080/test_demo/即可看到信息: Hello test demo\n\n创建Parent/jar/web项目:\n\tFile -> New -> Other -> Maven -> Maven Project 按照网上操作即可创建maven pom/jar/war三种项目，其中pom是父类管理其它jar和war(web)等project\n\n> 创建好maven项目后，修改jar或war的pom.xml(项目对象模型(Project Object Modet,POM))文件后\n\t鼠标右击pom.xml -> Maven -> Update Project... -> 可勾选下面的Force Update of Snapshots/Releases -> OK\n```\n#> eclipse for java ee 创建好maven web项目后会出错，原因是缺少webDemo/src/main/webapp/WEB-INF/web.xml\n#第一种：\t手动创建文件夹WEB-INF和文件web.xml,然后添加如下内容\n#<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n#<web-app version=\"2.5\" xmlns=\"http://java.sun.com/xml/ns/javaee\"\n#\txmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n#\txsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee \n#\thttp://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\">\n#</web-app>\n#\n#第二种: 鼠标右击webDemo -> Java EE Tools -> Generate Deployment Descriptor Stub 即可自动生成上面的web.xml文件\n```\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\nVScode 配置 Maven 安装环境 创建Maven项目\n\nFile -> Perferences -> Settings -> 搜索Maven -> 点击打开 \"Edit in settings.json\"文件\n\n``` java\n\"remote.SSH.remotePlatform\": {\n        \"10.239.85.244\": \"linux\",\n        \"10.239.65.163\": \"linux\"\n    },\n\n * Windows 添加配置如下内容:\n\"java.home\": \"C:\\\\Program Files\\\\Java\\\\jdk1.8.0_241\",\n\"java.configuration.maven.userSettings\": \"C:\\\\Users\\\\UserName\\\\Desktop\\\\software_package\\\\apache-maven-3.6.3\\\\conf\\\\settings.xml\",\n\"maven.executable.path\": \"C:\\\\Users\\\\UserName\\\\Desktop\\\\software_package\\\\apache-maven-3.6.3\\\\bin\\\\mvn\",\n\n * Linux 添加配置如下内容:\n\"java.home\": \"/usr/local/jdk1.8/\",\n\"java.configuration.maven.userSettings\": \"/usr/maven/apache-maven-3.6.3/conf/settings.xml\",\n\"maven.executable.path\": \"/usr/maven/apache-maven-3.6.3/bin/mvn\",\n\n\"maven.terminal.customEnv\": [\n        {\n            \"environmentVariable\": \"JAVA_HOME\",\n            //\"value\": \"C:\\\\Program Files\\\\Java\\\\jdk1.8.0_241\"\t\t// Windows\n            \"value\": \"/usr/local/jdk1.8\"\t\t\t\t\t\t\t// Linux\n        }\n    ]\n\n\"remote.SSH.configFile\": \"C:\\\\Users\\\\UserName\\\\.ssh\\\\config\"\n```\n\n\nCtrl + shift + P 选择 \"Maven:Create Maven Project\" 创建 Maven 项目\nSelect an archetype: 选择 maven-archetype-quickstart -> 选择版本 -> 选择生成目录\n-> VScode 终端 输入Group Id: 如com.imooc -> 输入Artifact Id: 如microservice -> 输入package： 直接回车 -> 输入Version: 直接回车\n\n1. 第一此创建Maven 父 项目pom.xml 没有 <packaging>pom</packaging> 需要手动添加, 右击 pom.xml -> Update project configuration\n2. 创建子项目， 右击上面项目名， 选择 Create Maven Project ......'groupId': com.imooc -> 'artifactId': test -> 'version' 1.0-SNAPSHOT: :回车\n3. 创建子项目后查看pom.xml可以发现自动添加了<parent></parent>标签\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n\n\n\n\n","slug":"technologies/maven/maven_eclipse_tomcat_JDK1.8_configuration","published":1,"date":"2020-08-12T16:05:48.564Z","updated":"2020-04-08T13:08:40.066Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmmj008shohx4nwc57ht","content":"<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※<br>Windows 环境:</p>\n<p>下载Maven，搜集网上配置PATH环境变量等<br>$ vim apache-maven-3.6.3\\conf\\settings.xml<br>$ C:\\Users\\UserName.m2\\settings.xml (没有.m2路径就不设)</p>\n<ol>\n<li><p>设置local repository: // maven从中央仓库下载到本地仓库</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;localRepository&gt;C:\\Users\\UserName\\***\\software_package\\Maven\\maven_repository&lt;&#x2F;localRepository&gt;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>设置proxy:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;proxy&gt;</span><br><span class=\"line\">   &lt;id&gt;my-proxy1&lt;&#x2F;id&gt;</span><br><span class=\"line\">   &lt;active&gt;true&lt;&#x2F;active&gt;</span><br><span class=\"line\">   &lt;protocol&gt;http&lt;&#x2F;protocol&gt;</span><br><span class=\"line\">   &lt;host&gt;child-prc.intel.com&lt;&#x2F;host&gt;</span><br><span class=\"line\">   &lt;port&gt;913&lt;&#x2F;port&gt;</span><br><span class=\"line\">&lt;&#x2F;proxy&gt;</span><br><span class=\"line\">&lt;proxy&gt;</span><br><span class=\"line\">   &lt;id&gt;my-proxy2&lt;&#x2F;id&gt;</span><br><span class=\"line\">   &lt;active&gt;true&lt;&#x2F;active&gt;</span><br><span class=\"line\">   &lt;protocol&gt;https&lt;&#x2F;protocol&gt;</span><br><span class=\"line\">   &lt;host&gt;child-prc.intel.com&lt;&#x2F;host&gt;</span><br><span class=\"line\">   &lt;port&gt;913&lt;&#x2F;port&gt;</span><br><span class=\"line\">&lt;&#x2F;proxy&gt;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>设置tomcat用户名和密码，如果tomcat安装时候或安装后tomcat的配置文件没有设置用户名和密码此处可忽略</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;server&gt;</span><br><span class=\"line\">  &lt;id&gt;tomcat8&lt;&#x2F;id&gt;</span><br><span class=\"line\">  &lt;username&gt;admin&lt;&#x2F;username&gt;</span><br><span class=\"line\">  &lt;password&gt;123456&lt;&#x2F;password&gt;</span><br><span class=\"line\">&lt;&#x2F;server&gt;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<p>设置aliyun 镜像:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;mirrors&gt;</span><br><span class=\"line\">  &lt;mirror&gt;</span><br><span class=\"line\">      &lt;id&gt;nexus-aliyun&lt;&#x2F;id&gt;</span><br><span class=\"line\">      &lt;mirrorOf&gt;central&lt;&#x2F;mirrorOf&gt;</span><br><span class=\"line\">      &lt;name&gt;Nexus aliyun&lt;&#x2F;name&gt;</span><br><span class=\"line\">      &lt;url&gt;http:&#x2F;&#x2F;maven.aliyun.com&#x2F;nexus&#x2F;content&#x2F;repositories&#x2F;central&lt;&#x2F;url&gt;</span><br><span class=\"line\">      &lt;!--&lt;url&gt;http:&#x2F;&#x2F;maven.aliyun.com&#x2F;nexus&#x2F;content&#x2F;groups&#x2F;public&lt;&#x2F;url&gt;--&gt;</span><br><span class=\"line\">  &lt;&#x2F;mirror&gt;</span><br><span class=\"line\">&lt;&#x2F;mirrors&gt;</span><br></pre></td></tr></table></figure>\n\n<p>打开cmd控制台输入：mvn -v 查看版本<br>$ mvn help:system        // 可看到数据正常下载即为成功<br>// $ ping repo1.maven.org //此远程repo好像不能访问，不过没关系，上面成功即可</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>安装tomcat服务器<br><a href=\"http://tomcat.apache.org/\" target=\"_blank\" rel=\"noopener\">http://tomcat.apache.org/</a><br>然后配置到eclipse</p>\n<p>打开C:\\Program Files\\Tomcat 8.5\\conf\\server.xml<br>    网上说需把<Server port=\"-1\" shutdown=\"SHUTDOWN\"> 改为 <Server port=\"8005\" shutdown=\"SHUTDOWN\"><br>    这里没改, 运行OK</p>\n<p>打开C:\\Program Files\\Tomcat 8.5\\conf\\tomcat-users.xml<br>添加如下内容, 设置tomcat密码，也可以不设置，设置后需要在maven的**\\config\\settings.xml配置文件中也添加tomcat密码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;role rolename&#x3D;&quot;manager&quot;&#x2F;&gt;</span><br><span class=\"line\">&lt;role rolename&#x3D;&quot;manager-gui&quot;&#x2F;&gt;</span><br><span class=\"line\">&lt;role rolename&#x3D;&quot;admin&quot;&#x2F;&gt;</span><br><span class=\"line\">&lt;role rolename&#x3D;&quot;admin-gui&quot;&#x2F;&gt;</span><br><span class=\"line\">&lt;role rolename&#x3D;&quot;manager-script&quot;&#x2F;&gt;</span><br><span class=\"line\">&lt;user username&#x3D;&quot;admin&quot; password&#x3D;&quot;123456&quot; roles&#x3D;&quot;admin-gui,admin,manager-gui,manager,manager-script&quot;&#x2F;&gt;</span><br></pre></td></tr></table></figure>\n\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※<br>官网下载eclipse（免费）<br><a href=\"https://www.eclipse.org/downloads/\" target=\"_blank\" rel=\"noopener\">https://www.eclipse.org/downloads/</a><br>第一种: 下载安装包:<br>    直接点击下载，下载后安装选择Eclipse IDE for Enterprise Java Developers就可以了(提前安装配置好JDK1.8等版本环境变量)<br>第二种： 下载压缩包(解压缩时候有问题),<br>    Download Packages -&gt; Eclipse IDE for Enterprise Java Developers (includes Incubating components)压缩包<br>    -&gt; 选择中国镜像 -&gt; 下载</p>\n<ol>\n<li>打开eclipse, Window -&gt; Preferences -&gt; Maven -&gt; installations -&gt; Add -&gt; 选择自己装的Maven，否则内嵌的Maven没有proxy</li>\n<li>打开eclipse, Window -&gt; Preferences -&gt; Maven -&gt; User Settings<br>-&gt; Global/User Settings都设置为 ***/apache-maven-3.6.3\\conf\\settings.xml -&gt; Update Settings -&gt; Apply -&gt; Apply and Close</li>\n</ol>\n<p>创建 maven web项目并运行:</p>\n<ol>\n<li><p>File -&gt; New -&gt; maven Project -&gt; Create a simple project(skip archetype selection)<br> -&gt; Next -&gt; 输入Group Id: com.test ,Artifact Id 输入 test_demo, Packaging： war(选择建立web服务此处必须选为war)</p>\n</li>\n<li><p>右击项目名 点击最下面Properties -&gt; Maven下面的Project Facets -&gt; 先不勾选Dynamic Web Module，选择右边的Runtimes并选中安装过的tomcat8.5<br> -&gt; Apply -&gt; Apply and close -&gt; 重新打开上面的页面 -&gt; 选中Dynamic Web Module 并 修改右边 Version 试着选各个版本使支持<br> -&gt; 点击下面出现的 “i Furtherconfiguration available…” -&gt; Conten directory: 内容改为 “src/main/webapp”<br> -&gt; 勾选中下面的Generate web.xml deployment descripter -&gt; Apply -&gt; Apply and Close</p>\n</li>\n<li><p>在 src/main/webapp 目录下新建个index.js文件内容如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;%@ page language&#x3D;&quot;java&quot; contentType&#x3D;&quot;text&#x2F;html; charset&#x3D;ISO-8859-1&quot;</span><br><span class=\"line\">    pageEncoding&#x3D;&quot;ISO-8859-1&quot;%&gt;</span><br><span class=\"line\">&lt;!DOCTYPE html&gt;</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;</span><br><span class=\"line\">&lt;meta charset&#x3D;&quot;ISO-8859-1&quot;&gt;</span><br><span class=\"line\">&lt;title&gt;Insert title here&lt;&#x2F;title&gt;</span><br><span class=\"line\">&lt;&#x2F;head&gt;</span><br><span class=\"line\">&lt;body&gt;</span><br><span class=\"line\">&lt;p&gt;Hello test demo&lt;&#x2F;p&gt;</span><br><span class=\"line\">&lt;&#x2F;body&gt;</span><br><span class=\"line\">&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>右击项目名 -&gt; Run As -&gt; Run on Server， 如果没有Run on Server选项重新打开Project Facets页面再Apply -&gt; Apply and Close</p>\n</li>\n<li><p>浏览器输入<a href=\"http://localhost:8080/test_demo/即可看到信息\" target=\"_blank\" rel=\"noopener\">http://localhost:8080/test_demo/即可看到信息</a>: Hello test demo</p>\n</li>\n</ol>\n<p>创建Parent/jar/web项目:<br>    File -&gt; New -&gt; Other -&gt; Maven -&gt; Maven Project 按照网上操作即可创建maven pom/jar/war三种项目，其中pom是父类管理其它jar和war(web)等project</p>\n<blockquote>\n<p>创建好maven项目后，修改jar或war的pom.xml(项目对象模型(Project Object Modet,POM))文件后<br>    鼠标右击pom.xml -&gt; Maven -&gt; Update Project… -&gt; 可勾选下面的Force Update of Snapshots/Releases -&gt; OK</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#&gt; eclipse for java ee 创建好maven web项目后会出错，原因是缺少webDemo&#x2F;src&#x2F;main&#x2F;webapp&#x2F;WEB-INF&#x2F;web.xml</span><br><span class=\"line\">#第一种：\t手动创建文件夹WEB-INF和文件web.xml,然后添加如下内容</span><br><span class=\"line\">#&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;</span><br><span class=\"line\">#&lt;web-app version&#x3D;&quot;2.5&quot; xmlns&#x3D;&quot;http:&#x2F;&#x2F;java.sun.com&#x2F;xml&#x2F;ns&#x2F;javaee&quot;</span><br><span class=\"line\">#\txmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;</span><br><span class=\"line\">#\txsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;java.sun.com&#x2F;xml&#x2F;ns&#x2F;javaee </span><br><span class=\"line\">#\thttp:&#x2F;&#x2F;java.sun.com&#x2F;xml&#x2F;ns&#x2F;javaee&#x2F;web-app_2_5.xsd&quot;&gt;</span><br><span class=\"line\">#&lt;&#x2F;web-app&gt;</span><br><span class=\"line\">#</span><br><span class=\"line\">#第二种: 鼠标右击webDemo -&gt; Java EE Tools -&gt; Generate Deployment Descriptor Stub 即可自动生成上面的web.xml文件</span><br></pre></td></tr></table></figure>\n\n\n\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>VScode 配置 Maven 安装环境 创建Maven项目</p>\n<p>File -&gt; Perferences -&gt; Settings -&gt; 搜索Maven -&gt; 点击打开 “Edit in settings.json”文件</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">\"remote.SSH.remotePlatform\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">\"10.239.85.244\"</span>: <span class=\"string\">\"linux\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"10.239.65.163\"</span>: <span class=\"string\">\"linux\"</span></span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\"></span><br><span class=\"line\"> * Windows 添加配置如下内容:</span><br><span class=\"line\"><span class=\"string\">\"java.home\"</span>: <span class=\"string\">\"C:\\\\Program Files\\\\Java\\\\jdk1.8.0_241\"</span>,</span><br><span class=\"line\"><span class=\"string\">\"java.configuration.maven.userSettings\"</span>: <span class=\"string\">\"C:\\\\Users\\\\UserName\\\\Desktop\\\\software_package\\\\apache-maven-3.6.3\\\\conf\\\\settings.xml\"</span>,</span><br><span class=\"line\"><span class=\"string\">\"maven.executable.path\"</span>: <span class=\"string\">\"C:\\\\Users\\\\UserName\\\\Desktop\\\\software_package\\\\apache-maven-3.6.3\\\\bin\\\\mvn\"</span>,</span><br><span class=\"line\"></span><br><span class=\"line\"> * Linux 添加配置如下内容:</span><br><span class=\"line\"><span class=\"string\">\"java.home\"</span>: <span class=\"string\">\"/usr/local/jdk1.8/\"</span>,</span><br><span class=\"line\"><span class=\"string\">\"java.configuration.maven.userSettings\"</span>: <span class=\"string\">\"/usr/maven/apache-maven-3.6.3/conf/settings.xml\"</span>,</span><br><span class=\"line\"><span class=\"string\">\"maven.executable.path\"</span>: <span class=\"string\">\"/usr/maven/apache-maven-3.6.3/bin/mvn\"</span>,</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">\"maven.terminal.customEnv\"</span>: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"string\">\"environmentVariable\"</span>: <span class=\"string\">\"JAVA_HOME\"</span>,</span><br><span class=\"line\">            <span class=\"comment\">//\"value\": \"C:\\\\Program Files\\\\Java\\\\jdk1.8.0_241\"\t\t// Windows</span></span><br><span class=\"line\">            <span class=\"string\">\"value\"</span>: <span class=\"string\">\"/usr/local/jdk1.8\"</span>\t\t\t\t\t\t\t<span class=\"comment\">// Linux</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">\"remote.SSH.configFile\"</span>: <span class=\"string\">\"C:\\\\Users\\\\UserName\\\\.ssh\\\\config\"</span></span><br></pre></td></tr></table></figure>\n\n\n<p>Ctrl + shift + P 选择 “Maven:Create Maven Project” 创建 Maven 项目<br>Select an archetype: 选择 maven-archetype-quickstart -&gt; 选择版本 -&gt; 选择生成目录<br>-&gt; VScode 终端 输入Group Id: 如com.imooc -&gt; 输入Artifact Id: 如microservice -&gt; 输入package： 直接回车 -&gt; 输入Version: 直接回车</p>\n<ol>\n<li>第一此创建Maven 父 项目pom.xml 没有 <packaging>pom</packaging> 需要手动添加, 右击 pom.xml -&gt; Update project configuration</li>\n<li>创建子项目， 右击上面项目名， 选择 Create Maven Project ……’groupId’: com.imooc -&gt; ‘artifactId’: test -&gt; ‘version’ 1.0-SNAPSHOT: :回车</li>\n<li>创建子项目后查看pom.xml可以发现自动添加了<parent></parent>标签</li>\n</ol>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n","site":{"data":{}},"excerpt":"","more":"<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※<br>Windows 环境:</p>\n<p>下载Maven，搜集网上配置PATH环境变量等<br>$ vim apache-maven-3.6.3\\conf\\settings.xml<br>$ C:\\Users\\UserName.m2\\settings.xml (没有.m2路径就不设)</p>\n<ol>\n<li><p>设置local repository: // maven从中央仓库下载到本地仓库</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;localRepository&gt;C:\\Users\\UserName\\***\\software_package\\Maven\\maven_repository&lt;&#x2F;localRepository&gt;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>设置proxy:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;proxy&gt;</span><br><span class=\"line\">   &lt;id&gt;my-proxy1&lt;&#x2F;id&gt;</span><br><span class=\"line\">   &lt;active&gt;true&lt;&#x2F;active&gt;</span><br><span class=\"line\">   &lt;protocol&gt;http&lt;&#x2F;protocol&gt;</span><br><span class=\"line\">   &lt;host&gt;child-prc.intel.com&lt;&#x2F;host&gt;</span><br><span class=\"line\">   &lt;port&gt;913&lt;&#x2F;port&gt;</span><br><span class=\"line\">&lt;&#x2F;proxy&gt;</span><br><span class=\"line\">&lt;proxy&gt;</span><br><span class=\"line\">   &lt;id&gt;my-proxy2&lt;&#x2F;id&gt;</span><br><span class=\"line\">   &lt;active&gt;true&lt;&#x2F;active&gt;</span><br><span class=\"line\">   &lt;protocol&gt;https&lt;&#x2F;protocol&gt;</span><br><span class=\"line\">   &lt;host&gt;child-prc.intel.com&lt;&#x2F;host&gt;</span><br><span class=\"line\">   &lt;port&gt;913&lt;&#x2F;port&gt;</span><br><span class=\"line\">&lt;&#x2F;proxy&gt;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>设置tomcat用户名和密码，如果tomcat安装时候或安装后tomcat的配置文件没有设置用户名和密码此处可忽略</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;server&gt;</span><br><span class=\"line\">  &lt;id&gt;tomcat8&lt;&#x2F;id&gt;</span><br><span class=\"line\">  &lt;username&gt;admin&lt;&#x2F;username&gt;</span><br><span class=\"line\">  &lt;password&gt;123456&lt;&#x2F;password&gt;</span><br><span class=\"line\">&lt;&#x2F;server&gt;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<p>设置aliyun 镜像:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;mirrors&gt;</span><br><span class=\"line\">  &lt;mirror&gt;</span><br><span class=\"line\">      &lt;id&gt;nexus-aliyun&lt;&#x2F;id&gt;</span><br><span class=\"line\">      &lt;mirrorOf&gt;central&lt;&#x2F;mirrorOf&gt;</span><br><span class=\"line\">      &lt;name&gt;Nexus aliyun&lt;&#x2F;name&gt;</span><br><span class=\"line\">      &lt;url&gt;http:&#x2F;&#x2F;maven.aliyun.com&#x2F;nexus&#x2F;content&#x2F;repositories&#x2F;central&lt;&#x2F;url&gt;</span><br><span class=\"line\">      &lt;!--&lt;url&gt;http:&#x2F;&#x2F;maven.aliyun.com&#x2F;nexus&#x2F;content&#x2F;groups&#x2F;public&lt;&#x2F;url&gt;--&gt;</span><br><span class=\"line\">  &lt;&#x2F;mirror&gt;</span><br><span class=\"line\">&lt;&#x2F;mirrors&gt;</span><br></pre></td></tr></table></figure>\n\n<p>打开cmd控制台输入：mvn -v 查看版本<br>$ mvn help:system        // 可看到数据正常下载即为成功<br>// $ ping repo1.maven.org //此远程repo好像不能访问，不过没关系，上面成功即可</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>安装tomcat服务器<br><a href=\"http://tomcat.apache.org/\" target=\"_blank\" rel=\"noopener\">http://tomcat.apache.org/</a><br>然后配置到eclipse</p>\n<p>打开C:\\Program Files\\Tomcat 8.5\\conf\\server.xml<br>    网上说需把<Server port=\"-1\" shutdown=\"SHUTDOWN\"> 改为 <Server port=\"8005\" shutdown=\"SHUTDOWN\"><br>    这里没改, 运行OK</p>\n<p>打开C:\\Program Files\\Tomcat 8.5\\conf\\tomcat-users.xml<br>添加如下内容, 设置tomcat密码，也可以不设置，设置后需要在maven的**\\config\\settings.xml配置文件中也添加tomcat密码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;role rolename&#x3D;&quot;manager&quot;&#x2F;&gt;</span><br><span class=\"line\">&lt;role rolename&#x3D;&quot;manager-gui&quot;&#x2F;&gt;</span><br><span class=\"line\">&lt;role rolename&#x3D;&quot;admin&quot;&#x2F;&gt;</span><br><span class=\"line\">&lt;role rolename&#x3D;&quot;admin-gui&quot;&#x2F;&gt;</span><br><span class=\"line\">&lt;role rolename&#x3D;&quot;manager-script&quot;&#x2F;&gt;</span><br><span class=\"line\">&lt;user username&#x3D;&quot;admin&quot; password&#x3D;&quot;123456&quot; roles&#x3D;&quot;admin-gui,admin,manager-gui,manager,manager-script&quot;&#x2F;&gt;</span><br></pre></td></tr></table></figure>\n\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※<br>官网下载eclipse（免费）<br><a href=\"https://www.eclipse.org/downloads/\" target=\"_blank\" rel=\"noopener\">https://www.eclipse.org/downloads/</a><br>第一种: 下载安装包:<br>    直接点击下载，下载后安装选择Eclipse IDE for Enterprise Java Developers就可以了(提前安装配置好JDK1.8等版本环境变量)<br>第二种： 下载压缩包(解压缩时候有问题),<br>    Download Packages -&gt; Eclipse IDE for Enterprise Java Developers (includes Incubating components)压缩包<br>    -&gt; 选择中国镜像 -&gt; 下载</p>\n<ol>\n<li>打开eclipse, Window -&gt; Preferences -&gt; Maven -&gt; installations -&gt; Add -&gt; 选择自己装的Maven，否则内嵌的Maven没有proxy</li>\n<li>打开eclipse, Window -&gt; Preferences -&gt; Maven -&gt; User Settings<br>-&gt; Global/User Settings都设置为 ***/apache-maven-3.6.3\\conf\\settings.xml -&gt; Update Settings -&gt; Apply -&gt; Apply and Close</li>\n</ol>\n<p>创建 maven web项目并运行:</p>\n<ol>\n<li><p>File -&gt; New -&gt; maven Project -&gt; Create a simple project(skip archetype selection)<br> -&gt; Next -&gt; 输入Group Id: com.test ,Artifact Id 输入 test_demo, Packaging： war(选择建立web服务此处必须选为war)</p>\n</li>\n<li><p>右击项目名 点击最下面Properties -&gt; Maven下面的Project Facets -&gt; 先不勾选Dynamic Web Module，选择右边的Runtimes并选中安装过的tomcat8.5<br> -&gt; Apply -&gt; Apply and close -&gt; 重新打开上面的页面 -&gt; 选中Dynamic Web Module 并 修改右边 Version 试着选各个版本使支持<br> -&gt; 点击下面出现的 “i Furtherconfiguration available…” -&gt; Conten directory: 内容改为 “src/main/webapp”<br> -&gt; 勾选中下面的Generate web.xml deployment descripter -&gt; Apply -&gt; Apply and Close</p>\n</li>\n<li><p>在 src/main/webapp 目录下新建个index.js文件内容如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;%@ page language&#x3D;&quot;java&quot; contentType&#x3D;&quot;text&#x2F;html; charset&#x3D;ISO-8859-1&quot;</span><br><span class=\"line\">    pageEncoding&#x3D;&quot;ISO-8859-1&quot;%&gt;</span><br><span class=\"line\">&lt;!DOCTYPE html&gt;</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;</span><br><span class=\"line\">&lt;meta charset&#x3D;&quot;ISO-8859-1&quot;&gt;</span><br><span class=\"line\">&lt;title&gt;Insert title here&lt;&#x2F;title&gt;</span><br><span class=\"line\">&lt;&#x2F;head&gt;</span><br><span class=\"line\">&lt;body&gt;</span><br><span class=\"line\">&lt;p&gt;Hello test demo&lt;&#x2F;p&gt;</span><br><span class=\"line\">&lt;&#x2F;body&gt;</span><br><span class=\"line\">&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>右击项目名 -&gt; Run As -&gt; Run on Server， 如果没有Run on Server选项重新打开Project Facets页面再Apply -&gt; Apply and Close</p>\n</li>\n<li><p>浏览器输入<a href=\"http://localhost:8080/test_demo/即可看到信息\" target=\"_blank\" rel=\"noopener\">http://localhost:8080/test_demo/即可看到信息</a>: Hello test demo</p>\n</li>\n</ol>\n<p>创建Parent/jar/web项目:<br>    File -&gt; New -&gt; Other -&gt; Maven -&gt; Maven Project 按照网上操作即可创建maven pom/jar/war三种项目，其中pom是父类管理其它jar和war(web)等project</p>\n<blockquote>\n<p>创建好maven项目后，修改jar或war的pom.xml(项目对象模型(Project Object Modet,POM))文件后<br>    鼠标右击pom.xml -&gt; Maven -&gt; Update Project… -&gt; 可勾选下面的Force Update of Snapshots/Releases -&gt; OK</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#&gt; eclipse for java ee 创建好maven web项目后会出错，原因是缺少webDemo&#x2F;src&#x2F;main&#x2F;webapp&#x2F;WEB-INF&#x2F;web.xml</span><br><span class=\"line\">#第一种：\t手动创建文件夹WEB-INF和文件web.xml,然后添加如下内容</span><br><span class=\"line\">#&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;</span><br><span class=\"line\">#&lt;web-app version&#x3D;&quot;2.5&quot; xmlns&#x3D;&quot;http:&#x2F;&#x2F;java.sun.com&#x2F;xml&#x2F;ns&#x2F;javaee&quot;</span><br><span class=\"line\">#\txmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;</span><br><span class=\"line\">#\txsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;java.sun.com&#x2F;xml&#x2F;ns&#x2F;javaee </span><br><span class=\"line\">#\thttp:&#x2F;&#x2F;java.sun.com&#x2F;xml&#x2F;ns&#x2F;javaee&#x2F;web-app_2_5.xsd&quot;&gt;</span><br><span class=\"line\">#&lt;&#x2F;web-app&gt;</span><br><span class=\"line\">#</span><br><span class=\"line\">#第二种: 鼠标右击webDemo -&gt; Java EE Tools -&gt; Generate Deployment Descriptor Stub 即可自动生成上面的web.xml文件</span><br></pre></td></tr></table></figure>\n\n\n\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>VScode 配置 Maven 安装环境 创建Maven项目</p>\n<p>File -&gt; Perferences -&gt; Settings -&gt; 搜索Maven -&gt; 点击打开 “Edit in settings.json”文件</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">\"remote.SSH.remotePlatform\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">\"10.239.85.244\"</span>: <span class=\"string\">\"linux\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"10.239.65.163\"</span>: <span class=\"string\">\"linux\"</span></span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\"></span><br><span class=\"line\"> * Windows 添加配置如下内容:</span><br><span class=\"line\"><span class=\"string\">\"java.home\"</span>: <span class=\"string\">\"C:\\\\Program Files\\\\Java\\\\jdk1.8.0_241\"</span>,</span><br><span class=\"line\"><span class=\"string\">\"java.configuration.maven.userSettings\"</span>: <span class=\"string\">\"C:\\\\Users\\\\UserName\\\\Desktop\\\\software_package\\\\apache-maven-3.6.3\\\\conf\\\\settings.xml\"</span>,</span><br><span class=\"line\"><span class=\"string\">\"maven.executable.path\"</span>: <span class=\"string\">\"C:\\\\Users\\\\UserName\\\\Desktop\\\\software_package\\\\apache-maven-3.6.3\\\\bin\\\\mvn\"</span>,</span><br><span class=\"line\"></span><br><span class=\"line\"> * Linux 添加配置如下内容:</span><br><span class=\"line\"><span class=\"string\">\"java.home\"</span>: <span class=\"string\">\"/usr/local/jdk1.8/\"</span>,</span><br><span class=\"line\"><span class=\"string\">\"java.configuration.maven.userSettings\"</span>: <span class=\"string\">\"/usr/maven/apache-maven-3.6.3/conf/settings.xml\"</span>,</span><br><span class=\"line\"><span class=\"string\">\"maven.executable.path\"</span>: <span class=\"string\">\"/usr/maven/apache-maven-3.6.3/bin/mvn\"</span>,</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">\"maven.terminal.customEnv\"</span>: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"string\">\"environmentVariable\"</span>: <span class=\"string\">\"JAVA_HOME\"</span>,</span><br><span class=\"line\">            <span class=\"comment\">//\"value\": \"C:\\\\Program Files\\\\Java\\\\jdk1.8.0_241\"\t\t// Windows</span></span><br><span class=\"line\">            <span class=\"string\">\"value\"</span>: <span class=\"string\">\"/usr/local/jdk1.8\"</span>\t\t\t\t\t\t\t<span class=\"comment\">// Linux</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">\"remote.SSH.configFile\"</span>: <span class=\"string\">\"C:\\\\Users\\\\UserName\\\\.ssh\\\\config\"</span></span><br></pre></td></tr></table></figure>\n\n\n<p>Ctrl + shift + P 选择 “Maven:Create Maven Project” 创建 Maven 项目<br>Select an archetype: 选择 maven-archetype-quickstart -&gt; 选择版本 -&gt; 选择生成目录<br>-&gt; VScode 终端 输入Group Id: 如com.imooc -&gt; 输入Artifact Id: 如microservice -&gt; 输入package： 直接回车 -&gt; 输入Version: 直接回车</p>\n<ol>\n<li>第一此创建Maven 父 项目pom.xml 没有 <packaging>pom</packaging> 需要手动添加, 右击 pom.xml -&gt; Update project configuration</li>\n<li>创建子项目， 右击上面项目名， 选择 Create Maven Project ……’groupId’: com.imooc -&gt; ‘artifactId’: test -&gt; ‘version’ 1.0-SNAPSHOT: :回车</li>\n<li>创建子项目后查看pom.xml可以发现自动添加了<parent></parent>标签</li>\n</ol>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<p>※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n"},{"title":"maven project","_content":"\n## Ubuntu18.04 安装 IntelliJ idea\n\thttps://blog.csdn.net/weixx3/article/details/81136822\n\n## 遇到的问题\n\n#### from thrift.Thrift import TType, TMessageType, TFrozenDict, TException, TApplicationException ImportError: cannot import name TFrozenDict\n\t解决方法是: 某些包没有关联上，装包时加上[hive]后缀\n\t$ pip install pyhive[hive]\n\n## 手动下载jar包并通过mvn安装到Linux或windows环境，供项目引用\n\thttps://repo1.maven.org/maven2/ 或者https://mvnrepository.com/\n * 如在pom.xml添加依赖但是下载不下来\n ```\n\t<dependency>\n      <groupId>org.apache.thrift</groupId>\n      <artifactId>libthrift</artifactId>\n      <version>0.10.0</version>\n    </dependency>\n ```\n * 浏览器连接https://repo1.maven.org/maven2/org/apache/thrift/libthrift/ 查看指定版本如0.10.0, 点击进去下载libthrift-0.10.0.jar\n * 执行如下命令\n\t```\n\t$ cd /home/ai/IdeaProjects/microservice/user-thrift-service\n\t$ mvn install:install-file -Dfile=/usr/maven/maven_repository/org/apache/thrift/libthrift/libthrift-0.10.0.jar -DgroupId=org.apache.thrift -DartifactId=libthrift -Dversion=0.10.0 -Dpackaging=jar\n\t```\n\tMaven 安装 JAR 包的命令是：mvn install:install-file -Dfile=本地jar包的位置  -DgroupId=上面的groupId  -DartifactId=上面的artifactId  -Dversion=上面的version  -Dpackaging=jar\n * 到maven设置的repository里查看\n```\n $ cd /usr/maven/maven_repository/org/apache/thrift/libthrift#\n $ ls -alh\n  drwxr-xr-x 2 root root 4.0K 4月   9 10:41 0.10.0\n  -rw-r--r-- 1 root root  308 4月   9 10:41 maven-metadata-local.xml\n```\n\n### Linux 命令行方式: 搭建，编译，测试，运行calss文件，打包，运行jar包，安装，部署， 清理 命令.\n * 1. mvn archetype:generate  -DinteractiveMode=false -DgroupId=com.HCI -DartifactId=HCI -Dpackage=com.HCI\n```\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n  <groupId>com.HCI</groupId>\n  <artifactId>HCI</artifactId>\n  <packaging>jar</packaging>\n  <version>1.0-SNAPSHOT</version>\n  <name>HCI</name>\n  <url>http://maven.apache.org</url>\n  <dependencies>\n    <dependency>\n      <groupId>junit</groupId>\n      <artifactId>junit</artifactId>\n      <version>3.8.1</version>\n      <scope>test</scope>\n    </dependency>\n  </dependencies>\n</project>\n```\n * 2. mvn compile：编译源代码\n ![](compile.JPG)\n * 3. mvn test: 测试编译过的代码\n * 4. mvn exec:java -Dexec.mainClass=\"com.HCI.App\"\n * 5. mvn package：生成构件包（一般为 jar 包或 war 包）\n ![](jar.JPG)\n * 6. java -cp target/HCI-1.0-SNAPSHOT.jar com.HCI.App\n * 7. mvn install：将构件包安装到本地仓库\n * 8. mvn deploy：将构件包部署到远程仓库\n * 9. mvn clean：清空输出目录（即 target 目录）\n\n创建Maven项目如HCI后，执行 Maven 其它命令需要注意的是：必须在 Maven 项目的根目录处执行，也就是当前目录下一定存在一个名为 pom.xml 的文件\n如进入/home/ai/IdeaProjects/microservice/user-thrift-service目录再执行mvn install:......命令\n\n```\n\n\n","source":"_posts/technologies/maven/maven_project.md","raw":"---\ntitle: maven project\ntags: \ncategories:\n- technologies\n- maven\n---\n\n## Ubuntu18.04 安装 IntelliJ idea\n\thttps://blog.csdn.net/weixx3/article/details/81136822\n\n## 遇到的问题\n\n#### from thrift.Thrift import TType, TMessageType, TFrozenDict, TException, TApplicationException ImportError: cannot import name TFrozenDict\n\t解决方法是: 某些包没有关联上，装包时加上[hive]后缀\n\t$ pip install pyhive[hive]\n\n## 手动下载jar包并通过mvn安装到Linux或windows环境，供项目引用\n\thttps://repo1.maven.org/maven2/ 或者https://mvnrepository.com/\n * 如在pom.xml添加依赖但是下载不下来\n ```\n\t<dependency>\n      <groupId>org.apache.thrift</groupId>\n      <artifactId>libthrift</artifactId>\n      <version>0.10.0</version>\n    </dependency>\n ```\n * 浏览器连接https://repo1.maven.org/maven2/org/apache/thrift/libthrift/ 查看指定版本如0.10.0, 点击进去下载libthrift-0.10.0.jar\n * 执行如下命令\n\t```\n\t$ cd /home/ai/IdeaProjects/microservice/user-thrift-service\n\t$ mvn install:install-file -Dfile=/usr/maven/maven_repository/org/apache/thrift/libthrift/libthrift-0.10.0.jar -DgroupId=org.apache.thrift -DartifactId=libthrift -Dversion=0.10.0 -Dpackaging=jar\n\t```\n\tMaven 安装 JAR 包的命令是：mvn install:install-file -Dfile=本地jar包的位置  -DgroupId=上面的groupId  -DartifactId=上面的artifactId  -Dversion=上面的version  -Dpackaging=jar\n * 到maven设置的repository里查看\n```\n $ cd /usr/maven/maven_repository/org/apache/thrift/libthrift#\n $ ls -alh\n  drwxr-xr-x 2 root root 4.0K 4月   9 10:41 0.10.0\n  -rw-r--r-- 1 root root  308 4月   9 10:41 maven-metadata-local.xml\n```\n\n### Linux 命令行方式: 搭建，编译，测试，运行calss文件，打包，运行jar包，安装，部署， 清理 命令.\n * 1. mvn archetype:generate  -DinteractiveMode=false -DgroupId=com.HCI -DartifactId=HCI -Dpackage=com.HCI\n```\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n  <groupId>com.HCI</groupId>\n  <artifactId>HCI</artifactId>\n  <packaging>jar</packaging>\n  <version>1.0-SNAPSHOT</version>\n  <name>HCI</name>\n  <url>http://maven.apache.org</url>\n  <dependencies>\n    <dependency>\n      <groupId>junit</groupId>\n      <artifactId>junit</artifactId>\n      <version>3.8.1</version>\n      <scope>test</scope>\n    </dependency>\n  </dependencies>\n</project>\n```\n * 2. mvn compile：编译源代码\n ![](compile.JPG)\n * 3. mvn test: 测试编译过的代码\n * 4. mvn exec:java -Dexec.mainClass=\"com.HCI.App\"\n * 5. mvn package：生成构件包（一般为 jar 包或 war 包）\n ![](jar.JPG)\n * 6. java -cp target/HCI-1.0-SNAPSHOT.jar com.HCI.App\n * 7. mvn install：将构件包安装到本地仓库\n * 8. mvn deploy：将构件包部署到远程仓库\n * 9. mvn clean：清空输出目录（即 target 目录）\n\n创建Maven项目如HCI后，执行 Maven 其它命令需要注意的是：必须在 Maven 项目的根目录处执行，也就是当前目录下一定存在一个名为 pom.xml 的文件\n如进入/home/ai/IdeaProjects/microservice/user-thrift-service目录再执行mvn install:......命令\n\n```\n\n\n","slug":"technologies/maven/maven_project","published":1,"date":"2020-08-12T16:05:48.577Z","updated":"2020-04-12T11:07:34.734Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmmw008thohx43wef4ec","content":"<h2 id=\"Ubuntu18-04-安装-IntelliJ-idea\"><a href=\"#Ubuntu18-04-安装-IntelliJ-idea\" class=\"headerlink\" title=\"Ubuntu18.04 安装 IntelliJ idea\"></a>Ubuntu18.04 安装 IntelliJ idea</h2><pre><code>https://blog.csdn.net/weixx3/article/details/81136822</code></pre><h2 id=\"遇到的问题\"><a href=\"#遇到的问题\" class=\"headerlink\" title=\"遇到的问题\"></a>遇到的问题</h2><h4 id=\"from-thrift-Thrift-import-TType-TMessageType-TFrozenDict-TException-TApplicationException-ImportError-cannot-import-name-TFrozenDict\"><a href=\"#from-thrift-Thrift-import-TType-TMessageType-TFrozenDict-TException-TApplicationException-ImportError-cannot-import-name-TFrozenDict\" class=\"headerlink\" title=\"from thrift.Thrift import TType, TMessageType, TFrozenDict, TException, TApplicationException ImportError: cannot import name TFrozenDict\"></a>from thrift.Thrift import TType, TMessageType, TFrozenDict, TException, TApplicationException ImportError: cannot import name TFrozenDict</h4><pre><code>解决方法是: 某些包没有关联上，装包时加上[hive]后缀\n$ pip install pyhive[hive]</code></pre><h2 id=\"手动下载jar包并通过mvn安装到Linux或windows环境，供项目引用\"><a href=\"#手动下载jar包并通过mvn安装到Linux或windows环境，供项目引用\" class=\"headerlink\" title=\"手动下载jar包并通过mvn安装到Linux或windows环境，供项目引用\"></a>手动下载jar包并通过mvn安装到Linux或windows环境，供项目引用</h2><pre><code>https://repo1.maven.org/maven2/ 或者https://mvnrepository.com/</code></pre><ul>\n<li>如在pom.xml添加依赖但是下载不下来<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">     &lt;groupId&gt;org.apache.thrift&lt;&#x2F;groupId&gt;</span><br><span class=\"line\">     &lt;artifactId&gt;libthrift&lt;&#x2F;artifactId&gt;</span><br><span class=\"line\">     &lt;version&gt;0.10.0&lt;&#x2F;version&gt;</span><br><span class=\"line\">   &lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure></li>\n<li>浏览器连接<a href=\"https://repo1.maven.org/maven2/org/apache/thrift/libthrift/\" target=\"_blank\" rel=\"noopener\">https://repo1.maven.org/maven2/org/apache/thrift/libthrift/</a> 查看指定版本如0.10.0, 点击进去下载libthrift-0.10.0.jar</li>\n<li>执行如下命令 <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cd &#x2F;home&#x2F;ai&#x2F;IdeaProjects&#x2F;microservice&#x2F;user-thrift-service</span><br><span class=\"line\">$ mvn install:install-file -Dfile&#x3D;&#x2F;usr&#x2F;maven&#x2F;maven_repository&#x2F;org&#x2F;apache&#x2F;thrift&#x2F;libthrift&#x2F;libthrift-0.10.0.jar -DgroupId&#x3D;org.apache.thrift -DartifactId&#x3D;libthrift -Dversion&#x3D;0.10.0 -Dpackaging&#x3D;jar</span><br></pre></td></tr></table></figure>\n Maven 安装 JAR 包的命令是：mvn install:install-file -Dfile=本地jar包的位置  -DgroupId=上面的groupId  -DartifactId=上面的artifactId  -Dversion=上面的version  -Dpackaging=jar</li>\n<li>到maven设置的repository里查看<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cd &#x2F;usr&#x2F;maven&#x2F;maven_repository&#x2F;org&#x2F;apache&#x2F;thrift&#x2F;libthrift#</span><br><span class=\"line\">$ ls -alh</span><br><span class=\"line\"> drwxr-xr-x 2 root root 4.0K 4月   9 10:41 0.10.0</span><br><span class=\"line\"> -rw-r--r-- 1 root root  308 4月   9 10:41 maven-metadata-local.xml</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<h3 id=\"Linux-命令行方式-搭建，编译，测试，运行calss文件，打包，运行jar包，安装，部署，-清理-命令\"><a href=\"#Linux-命令行方式-搭建，编译，测试，运行calss文件，打包，运行jar包，安装，部署，-清理-命令\" class=\"headerlink\" title=\"Linux 命令行方式: 搭建，编译，测试，运行calss文件，打包，运行jar包，安装，部署， 清理 命令.\"></a>Linux 命令行方式: 搭建，编译，测试，运行calss文件，打包，运行jar包，安装，部署， 清理 命令.</h3><ul>\n<li><ol>\n<li>mvn archetype:generate  -DinteractiveMode=false -DgroupId=com.HCI -DartifactId=HCI -Dpackage=com.HCI<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;project xmlns&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;</span><br><span class=\"line\">  xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0 http:&#x2F;&#x2F;maven.apache.org&#x2F;maven-v4_0_0.xsd&quot;&gt;</span><br><span class=\"line\">  &lt;modelVersion&gt;4.0.0&lt;&#x2F;modelVersion&gt;</span><br><span class=\"line\">  &lt;groupId&gt;com.HCI&lt;&#x2F;groupId&gt;</span><br><span class=\"line\">  &lt;artifactId&gt;HCI&lt;&#x2F;artifactId&gt;</span><br><span class=\"line\">  &lt;packaging&gt;jar&lt;&#x2F;packaging&gt;</span><br><span class=\"line\">  &lt;version&gt;1.0-SNAPSHOT&lt;&#x2F;version&gt;</span><br><span class=\"line\">  &lt;name&gt;HCI&lt;&#x2F;name&gt;</span><br><span class=\"line\">  &lt;url&gt;http:&#x2F;&#x2F;maven.apache.org&lt;&#x2F;url&gt;</span><br><span class=\"line\">  &lt;dependencies&gt;</span><br><span class=\"line\">    &lt;dependency&gt;</span><br><span class=\"line\">      &lt;groupId&gt;junit&lt;&#x2F;groupId&gt;</span><br><span class=\"line\">      &lt;artifactId&gt;junit&lt;&#x2F;artifactId&gt;</span><br><span class=\"line\">      &lt;version&gt;3.8.1&lt;&#x2F;version&gt;</span><br><span class=\"line\">      &lt;scope&gt;test&lt;&#x2F;scope&gt;</span><br><span class=\"line\">    &lt;&#x2F;dependency&gt;</span><br><span class=\"line\">  &lt;&#x2F;dependencies&gt;</span><br><span class=\"line\">&lt;&#x2F;project&gt;</span><br></pre></td></tr></table></figure></li>\n</ol>\n</li>\n<li><ol start=\"2\">\n<li>mvn compile：编译源代码<br><img src=\"compile.JPG\" alt=\"\"></li>\n</ol>\n</li>\n<li><ol start=\"3\">\n<li>mvn test: 测试编译过的代码</li>\n</ol>\n</li>\n<li><ol start=\"4\">\n<li>mvn exec:java -Dexec.mainClass=”com.HCI.App”</li>\n</ol>\n</li>\n<li><ol start=\"5\">\n<li>mvn package：生成构件包（一般为 jar 包或 war 包）<br><img src=\"jar.JPG\" alt=\"\"></li>\n</ol>\n</li>\n<li><ol start=\"6\">\n<li>java -cp target/HCI-1.0-SNAPSHOT.jar com.HCI.App</li>\n</ol>\n</li>\n<li><ol start=\"7\">\n<li>mvn install：将构件包安装到本地仓库</li>\n</ol>\n</li>\n<li><ol start=\"8\">\n<li>mvn deploy：将构件包部署到远程仓库</li>\n</ol>\n</li>\n<li><ol start=\"9\">\n<li>mvn clean：清空输出目录（即 target 目录）</li>\n</ol>\n</li>\n</ul>\n<p>创建Maven项目如HCI后，执行 Maven 其它命令需要注意的是：必须在 Maven 项目的根目录处执行，也就是当前目录下一定存在一个名为 pom.xml 的文件<br>如进入/home/ai/IdeaProjects/microservice/user-thrift-service目录再执行mvn install:……命令</p>\n<pre><code>\n</code></pre>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Ubuntu18-04-安装-IntelliJ-idea\"><a href=\"#Ubuntu18-04-安装-IntelliJ-idea\" class=\"headerlink\" title=\"Ubuntu18.04 安装 IntelliJ idea\"></a>Ubuntu18.04 安装 IntelliJ idea</h2><pre><code>https://blog.csdn.net/weixx3/article/details/81136822</code></pre><h2 id=\"遇到的问题\"><a href=\"#遇到的问题\" class=\"headerlink\" title=\"遇到的问题\"></a>遇到的问题</h2><h4 id=\"from-thrift-Thrift-import-TType-TMessageType-TFrozenDict-TException-TApplicationException-ImportError-cannot-import-name-TFrozenDict\"><a href=\"#from-thrift-Thrift-import-TType-TMessageType-TFrozenDict-TException-TApplicationException-ImportError-cannot-import-name-TFrozenDict\" class=\"headerlink\" title=\"from thrift.Thrift import TType, TMessageType, TFrozenDict, TException, TApplicationException ImportError: cannot import name TFrozenDict\"></a>from thrift.Thrift import TType, TMessageType, TFrozenDict, TException, TApplicationException ImportError: cannot import name TFrozenDict</h4><pre><code>解决方法是: 某些包没有关联上，装包时加上[hive]后缀\n$ pip install pyhive[hive]</code></pre><h2 id=\"手动下载jar包并通过mvn安装到Linux或windows环境，供项目引用\"><a href=\"#手动下载jar包并通过mvn安装到Linux或windows环境，供项目引用\" class=\"headerlink\" title=\"手动下载jar包并通过mvn安装到Linux或windows环境，供项目引用\"></a>手动下载jar包并通过mvn安装到Linux或windows环境，供项目引用</h2><pre><code>https://repo1.maven.org/maven2/ 或者https://mvnrepository.com/</code></pre><ul>\n<li>如在pom.xml添加依赖但是下载不下来<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">     &lt;groupId&gt;org.apache.thrift&lt;&#x2F;groupId&gt;</span><br><span class=\"line\">     &lt;artifactId&gt;libthrift&lt;&#x2F;artifactId&gt;</span><br><span class=\"line\">     &lt;version&gt;0.10.0&lt;&#x2F;version&gt;</span><br><span class=\"line\">   &lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure></li>\n<li>浏览器连接<a href=\"https://repo1.maven.org/maven2/org/apache/thrift/libthrift/\" target=\"_blank\" rel=\"noopener\">https://repo1.maven.org/maven2/org/apache/thrift/libthrift/</a> 查看指定版本如0.10.0, 点击进去下载libthrift-0.10.0.jar</li>\n<li>执行如下命令 <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cd &#x2F;home&#x2F;ai&#x2F;IdeaProjects&#x2F;microservice&#x2F;user-thrift-service</span><br><span class=\"line\">$ mvn install:install-file -Dfile&#x3D;&#x2F;usr&#x2F;maven&#x2F;maven_repository&#x2F;org&#x2F;apache&#x2F;thrift&#x2F;libthrift&#x2F;libthrift-0.10.0.jar -DgroupId&#x3D;org.apache.thrift -DartifactId&#x3D;libthrift -Dversion&#x3D;0.10.0 -Dpackaging&#x3D;jar</span><br></pre></td></tr></table></figure>\n Maven 安装 JAR 包的命令是：mvn install:install-file -Dfile=本地jar包的位置  -DgroupId=上面的groupId  -DartifactId=上面的artifactId  -Dversion=上面的version  -Dpackaging=jar</li>\n<li>到maven设置的repository里查看<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cd &#x2F;usr&#x2F;maven&#x2F;maven_repository&#x2F;org&#x2F;apache&#x2F;thrift&#x2F;libthrift#</span><br><span class=\"line\">$ ls -alh</span><br><span class=\"line\"> drwxr-xr-x 2 root root 4.0K 4月   9 10:41 0.10.0</span><br><span class=\"line\"> -rw-r--r-- 1 root root  308 4月   9 10:41 maven-metadata-local.xml</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<h3 id=\"Linux-命令行方式-搭建，编译，测试，运行calss文件，打包，运行jar包，安装，部署，-清理-命令\"><a href=\"#Linux-命令行方式-搭建，编译，测试，运行calss文件，打包，运行jar包，安装，部署，-清理-命令\" class=\"headerlink\" title=\"Linux 命令行方式: 搭建，编译，测试，运行calss文件，打包，运行jar包，安装，部署， 清理 命令.\"></a>Linux 命令行方式: 搭建，编译，测试，运行calss文件，打包，运行jar包，安装，部署， 清理 命令.</h3><ul>\n<li><ol>\n<li>mvn archetype:generate  -DinteractiveMode=false -DgroupId=com.HCI -DartifactId=HCI -Dpackage=com.HCI<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;project xmlns&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;</span><br><span class=\"line\">  xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0 http:&#x2F;&#x2F;maven.apache.org&#x2F;maven-v4_0_0.xsd&quot;&gt;</span><br><span class=\"line\">  &lt;modelVersion&gt;4.0.0&lt;&#x2F;modelVersion&gt;</span><br><span class=\"line\">  &lt;groupId&gt;com.HCI&lt;&#x2F;groupId&gt;</span><br><span class=\"line\">  &lt;artifactId&gt;HCI&lt;&#x2F;artifactId&gt;</span><br><span class=\"line\">  &lt;packaging&gt;jar&lt;&#x2F;packaging&gt;</span><br><span class=\"line\">  &lt;version&gt;1.0-SNAPSHOT&lt;&#x2F;version&gt;</span><br><span class=\"line\">  &lt;name&gt;HCI&lt;&#x2F;name&gt;</span><br><span class=\"line\">  &lt;url&gt;http:&#x2F;&#x2F;maven.apache.org&lt;&#x2F;url&gt;</span><br><span class=\"line\">  &lt;dependencies&gt;</span><br><span class=\"line\">    &lt;dependency&gt;</span><br><span class=\"line\">      &lt;groupId&gt;junit&lt;&#x2F;groupId&gt;</span><br><span class=\"line\">      &lt;artifactId&gt;junit&lt;&#x2F;artifactId&gt;</span><br><span class=\"line\">      &lt;version&gt;3.8.1&lt;&#x2F;version&gt;</span><br><span class=\"line\">      &lt;scope&gt;test&lt;&#x2F;scope&gt;</span><br><span class=\"line\">    &lt;&#x2F;dependency&gt;</span><br><span class=\"line\">  &lt;&#x2F;dependencies&gt;</span><br><span class=\"line\">&lt;&#x2F;project&gt;</span><br></pre></td></tr></table></figure></li>\n</ol>\n</li>\n<li><ol start=\"2\">\n<li>mvn compile：编译源代码<br><img src=\"compile.JPG\" alt=\"\"></li>\n</ol>\n</li>\n<li><ol start=\"3\">\n<li>mvn test: 测试编译过的代码</li>\n</ol>\n</li>\n<li><ol start=\"4\">\n<li>mvn exec:java -Dexec.mainClass=”com.HCI.App”</li>\n</ol>\n</li>\n<li><ol start=\"5\">\n<li>mvn package：生成构件包（一般为 jar 包或 war 包）<br><img src=\"jar.JPG\" alt=\"\"></li>\n</ol>\n</li>\n<li><ol start=\"6\">\n<li>java -cp target/HCI-1.0-SNAPSHOT.jar com.HCI.App</li>\n</ol>\n</li>\n<li><ol start=\"7\">\n<li>mvn install：将构件包安装到本地仓库</li>\n</ol>\n</li>\n<li><ol start=\"8\">\n<li>mvn deploy：将构件包部署到远程仓库</li>\n</ol>\n</li>\n<li><ol start=\"9\">\n<li>mvn clean：清空输出目录（即 target 目录）</li>\n</ol>\n</li>\n</ul>\n<p>创建Maven项目如HCI后，执行 Maven 其它命令需要注意的是：必须在 Maven 项目的根目录处执行，也就是当前目录下一定存在一个名为 pom.xml 的文件<br>如进入/home/ai/IdeaProjects/microservice/user-thrift-service目录再执行mvn install:……命令</p>\n<pre><code>\n</code></pre>"},{"title":"navicat","_content":"\n## Navicat简介\n\tNavicat是可以管理多种数据库Mysql, redis, MongoDB等等的软件，收费\n\n\n\n","source":"_posts/technologies/maven/navicat_premium.md","raw":"---\ntitle: navicat\ntags: \ncategories:\n- technologies\n- maven\n---\n\n## Navicat简介\n\tNavicat是可以管理多种数据库Mysql, redis, MongoDB等等的软件，收费\n\n\n\n","slug":"technologies/maven/navicat_premium","published":1,"date":"2020-08-12T16:05:48.584Z","updated":"2020-04-09T14:50:43.226Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmn6008vhohx91yv53kl","content":"<h2 id=\"Navicat简介\"><a href=\"#Navicat简介\" class=\"headerlink\" title=\"Navicat简介\"></a>Navicat简介</h2><pre><code>Navicat是可以管理多种数据库Mysql, redis, MongoDB等等的软件，收费</code></pre>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Navicat简介\"><a href=\"#Navicat简介\" class=\"headerlink\" title=\"Navicat简介\"></a>Navicat简介</h2><pre><code>Navicat是可以管理多种数据库Mysql, redis, MongoDB等等的软件，收费</code></pre>"},{"title":"thrift","_content":"\n## Thrift 简介\nThrift可以定义多种语言的函数接然后并生成源码文件.\n\n## Ubuntu18.04 安装 Thrift\n * 1. sudo apt-get install automake bison flex g++ git libboost-all-dev libevent-dev libssl-dev libtool make pkg-config\n * 2. tar -zxvf thrift-0.9.3.tar.gz\n * 3. cd thrift-0.9.3\n * 4.  ./configure CXXFLAGS='-ggdb3' --with-java --with-python --without-cpp --without-boost --without-csharp --without-erlang --without-perl --without-php --without-php_extension --without-ruby --without-haskell --without-go\n * 5. make\n * 6. make install\n * 7. thrift -version\n * 8. cd thrift-0.9.3/lib/py\n * 9. python setup.py install\n\n### 遇到的问题:\n#### 问题1: from thrift.Thrift import TType, TMessageType, TFrozenDict, TException, TApplicationException ImportError: cannot import name TFrozenDict\n#### 问题2: 安装sasl的时候报错：sasl/saslwrapper.h:22:23: fatal error: sasl/sasl.h: No such file or directory\n * 久经折腾，最终发现缺少包：https://pypi.python.org/pypi/sasl/0.1.3\n * Debian/Ubuntu:$ apt-get install python-dev libsasl2-dev gcc\n * CentOS/RHEL:$ yum install gcc-c++ python-devel.x86_64 cyrus-sasl-devel.x86_64\n * 最后安装: 某些包没有关联上，装包时加上[hive]后缀 $ pip install pyhive[hive]\n\n\n","source":"_posts/technologies/maven/thrift.md","raw":"---\ntitle: thrift\ntags: \ncategories:\n- technologies\n- maven\n---\n\n## Thrift 简介\nThrift可以定义多种语言的函数接然后并生成源码文件.\n\n## Ubuntu18.04 安装 Thrift\n * 1. sudo apt-get install automake bison flex g++ git libboost-all-dev libevent-dev libssl-dev libtool make pkg-config\n * 2. tar -zxvf thrift-0.9.3.tar.gz\n * 3. cd thrift-0.9.3\n * 4.  ./configure CXXFLAGS='-ggdb3' --with-java --with-python --without-cpp --without-boost --without-csharp --without-erlang --without-perl --without-php --without-php_extension --without-ruby --without-haskell --without-go\n * 5. make\n * 6. make install\n * 7. thrift -version\n * 8. cd thrift-0.9.3/lib/py\n * 9. python setup.py install\n\n### 遇到的问题:\n#### 问题1: from thrift.Thrift import TType, TMessageType, TFrozenDict, TException, TApplicationException ImportError: cannot import name TFrozenDict\n#### 问题2: 安装sasl的时候报错：sasl/saslwrapper.h:22:23: fatal error: sasl/sasl.h: No such file or directory\n * 久经折腾，最终发现缺少包：https://pypi.python.org/pypi/sasl/0.1.3\n * Debian/Ubuntu:$ apt-get install python-dev libsasl2-dev gcc\n * CentOS/RHEL:$ yum install gcc-c++ python-devel.x86_64 cyrus-sasl-devel.x86_64\n * 最后安装: 某些包没有关联上，装包时加上[hive]后缀 $ pip install pyhive[hive]\n\n\n","slug":"technologies/maven/thrift","published":1,"date":"2020-08-12T16:05:48.586Z","updated":"2020-04-08T13:14:36.164Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmnh008whohx0q2ib3xd","content":"<h2 id=\"Thrift-简介\"><a href=\"#Thrift-简介\" class=\"headerlink\" title=\"Thrift 简介\"></a>Thrift 简介</h2><p>Thrift可以定义多种语言的函数接然后并生成源码文件.</p>\n<h2 id=\"Ubuntu18-04-安装-Thrift\"><a href=\"#Ubuntu18-04-安装-Thrift\" class=\"headerlink\" title=\"Ubuntu18.04 安装 Thrift\"></a>Ubuntu18.04 安装 Thrift</h2><ul>\n<li><ol>\n<li>sudo apt-get install automake bison flex g++ git libboost-all-dev libevent-dev libssl-dev libtool make pkg-config</li>\n</ol>\n</li>\n<li><ol start=\"2\">\n<li>tar -zxvf thrift-0.9.3.tar.gz</li>\n</ol>\n</li>\n<li><ol start=\"3\">\n<li>cd thrift-0.9.3</li>\n</ol>\n</li>\n<li><ol start=\"4\">\n<li>./configure CXXFLAGS=’-ggdb3’ –with-java –with-python –without-cpp –without-boost –without-csharp –without-erlang –without-perl –without-php –without-php_extension –without-ruby –without-haskell –without-go</li>\n</ol>\n</li>\n<li><ol start=\"5\">\n<li>make</li>\n</ol>\n</li>\n<li><ol start=\"6\">\n<li>make install</li>\n</ol>\n</li>\n<li><ol start=\"7\">\n<li>thrift -version</li>\n</ol>\n</li>\n<li><ol start=\"8\">\n<li>cd thrift-0.9.3/lib/py</li>\n</ol>\n</li>\n<li><ol start=\"9\">\n<li>python setup.py install</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"遇到的问题\"><a href=\"#遇到的问题\" class=\"headerlink\" title=\"遇到的问题:\"></a>遇到的问题:</h3><h4 id=\"问题1-from-thrift-Thrift-import-TType-TMessageType-TFrozenDict-TException-TApplicationException-ImportError-cannot-import-name-TFrozenDict\"><a href=\"#问题1-from-thrift-Thrift-import-TType-TMessageType-TFrozenDict-TException-TApplicationException-ImportError-cannot-import-name-TFrozenDict\" class=\"headerlink\" title=\"问题1: from thrift.Thrift import TType, TMessageType, TFrozenDict, TException, TApplicationException ImportError: cannot import name TFrozenDict\"></a>问题1: from thrift.Thrift import TType, TMessageType, TFrozenDict, TException, TApplicationException ImportError: cannot import name TFrozenDict</h4><h4 id=\"问题2-安装sasl的时候报错：sasl-saslwrapper-h-22-23-fatal-error-sasl-sasl-h-No-such-file-or-directory\"><a href=\"#问题2-安装sasl的时候报错：sasl-saslwrapper-h-22-23-fatal-error-sasl-sasl-h-No-such-file-or-directory\" class=\"headerlink\" title=\"问题2: 安装sasl的时候报错：sasl/saslwrapper.h:22:23: fatal error: sasl/sasl.h: No such file or directory\"></a>问题2: 安装sasl的时候报错：sasl/saslwrapper.h:22:23: fatal error: sasl/sasl.h: No such file or directory</h4><ul>\n<li>久经折腾，最终发现缺少包：<a href=\"https://pypi.python.org/pypi/sasl/0.1.3\" target=\"_blank\" rel=\"noopener\">https://pypi.python.org/pypi/sasl/0.1.3</a></li>\n<li>Debian/Ubuntu:$ apt-get install python-dev libsasl2-dev gcc</li>\n<li>CentOS/RHEL:$ yum install gcc-c++ python-devel.x86_64 cyrus-sasl-devel.x86_64</li>\n<li>最后安装: 某些包没有关联上，装包时加上[hive]后缀 $ pip install pyhive[hive]</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Thrift-简介\"><a href=\"#Thrift-简介\" class=\"headerlink\" title=\"Thrift 简介\"></a>Thrift 简介</h2><p>Thrift可以定义多种语言的函数接然后并生成源码文件.</p>\n<h2 id=\"Ubuntu18-04-安装-Thrift\"><a href=\"#Ubuntu18-04-安装-Thrift\" class=\"headerlink\" title=\"Ubuntu18.04 安装 Thrift\"></a>Ubuntu18.04 安装 Thrift</h2><ul>\n<li><ol>\n<li>sudo apt-get install automake bison flex g++ git libboost-all-dev libevent-dev libssl-dev libtool make pkg-config</li>\n</ol>\n</li>\n<li><ol start=\"2\">\n<li>tar -zxvf thrift-0.9.3.tar.gz</li>\n</ol>\n</li>\n<li><ol start=\"3\">\n<li>cd thrift-0.9.3</li>\n</ol>\n</li>\n<li><ol start=\"4\">\n<li>./configure CXXFLAGS=’-ggdb3’ –with-java –with-python –without-cpp –without-boost –without-csharp –without-erlang –without-perl –without-php –without-php_extension –without-ruby –without-haskell –without-go</li>\n</ol>\n</li>\n<li><ol start=\"5\">\n<li>make</li>\n</ol>\n</li>\n<li><ol start=\"6\">\n<li>make install</li>\n</ol>\n</li>\n<li><ol start=\"7\">\n<li>thrift -version</li>\n</ol>\n</li>\n<li><ol start=\"8\">\n<li>cd thrift-0.9.3/lib/py</li>\n</ol>\n</li>\n<li><ol start=\"9\">\n<li>python setup.py install</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"遇到的问题\"><a href=\"#遇到的问题\" class=\"headerlink\" title=\"遇到的问题:\"></a>遇到的问题:</h3><h4 id=\"问题1-from-thrift-Thrift-import-TType-TMessageType-TFrozenDict-TException-TApplicationException-ImportError-cannot-import-name-TFrozenDict\"><a href=\"#问题1-from-thrift-Thrift-import-TType-TMessageType-TFrozenDict-TException-TApplicationException-ImportError-cannot-import-name-TFrozenDict\" class=\"headerlink\" title=\"问题1: from thrift.Thrift import TType, TMessageType, TFrozenDict, TException, TApplicationException ImportError: cannot import name TFrozenDict\"></a>问题1: from thrift.Thrift import TType, TMessageType, TFrozenDict, TException, TApplicationException ImportError: cannot import name TFrozenDict</h4><h4 id=\"问题2-安装sasl的时候报错：sasl-saslwrapper-h-22-23-fatal-error-sasl-sasl-h-No-such-file-or-directory\"><a href=\"#问题2-安装sasl的时候报错：sasl-saslwrapper-h-22-23-fatal-error-sasl-sasl-h-No-such-file-or-directory\" class=\"headerlink\" title=\"问题2: 安装sasl的时候报错：sasl/saslwrapper.h:22:23: fatal error: sasl/sasl.h: No such file or directory\"></a>问题2: 安装sasl的时候报错：sasl/saslwrapper.h:22:23: fatal error: sasl/sasl.h: No such file or directory</h4><ul>\n<li>久经折腾，最终发现缺少包：<a href=\"https://pypi.python.org/pypi/sasl/0.1.3\" target=\"_blank\" rel=\"noopener\">https://pypi.python.org/pypi/sasl/0.1.3</a></li>\n<li>Debian/Ubuntu:$ apt-get install python-dev libsasl2-dev gcc</li>\n<li>CentOS/RHEL:$ yum install gcc-c++ python-devel.x86_64 cyrus-sasl-devel.x86_64</li>\n<li>最后安装: 某些包没有关联上，装包时加上[hive]后缀 $ pip install pyhive[hive]</li>\n</ul>\n"},{"title":"algorithm security","_content":"\n# **Certificates Encryption Algorithm**\n\n## **RSA非对称加密算法**\nRSA(Rivest-Shamir-Adleman)\n> RSA是1977年由罗纳德·李维斯特（Ron Rivest）、阿迪·萨莫尔（Adi Shamir）和伦纳德·阿德曼（Leonard Adleman）一起提出的。当时他们三人都在麻省理工学院工作。RSA就是他们三人姓氏开头字母拼在一起组成的  \n\n非对称加密，公钥加密，私钥解密，反之亦然。由于需要大数的乘幂求模等算法，运行速度慢，不易于硬件实现。\n\n通常私钥长度有512bit，1024bit，2048bit，4096bit，长度越长，越安全，但是生成密钥越慢，加解密也越耗时。\n\n既然是加密，那肯定是不希望别人知道我的消息，所以只有我才能解密，所以可得出公钥负责加密，私钥负责解密；\n\n同理，既然是签名，那肯定是不希望有人冒充我发消息，只有我才能发布这个签名，所以可得出私钥负责签名，公钥负责验证。\n\n> 非对称加密算法实现机密信息交换的基本过程是：甲方生成一对密钥并将其中的一把作为公用密钥向其它方公开(用CA private key签名得到甲方证书)；用CA的public key解密得到该公用密钥的乙方使用该密钥对机密信息进行加密后再发送给甲方；甲方再用自己保存的另一把专用密钥对加密后的信息进行解密来获取信息.\n\n## **AES对称加密算法**\nAES,高级加密标准（Advanced Encryption Standard，缩写：AES）  \n\n对称加密，密钥最长只有256个bit，执行速度快，易于硬件实现。由于是对称加密，密钥需要在传输前通讯双方获知。\n\n基于以上特点，通常使用RSA来首先传输AES的密钥给对方，然后再使用AES来进行加密通讯。\n\nAES128和AES256主要区别是密钥长度不同（分别是128bits,256bits)、加密处理轮数不同（分别是10轮，14轮），后者强度高于前者。当前AES是较为安全的公认的对称加密算法。  \n\n现代密码学分为对称加密与非对称加密（公钥加密），代表算法分别有DES(现在发展为3DES）、AES与RSA等。非对称加密算法的资源消耗大于对称加密。一般是进行混合加密处理，例如使用RSA进行密钥分发、协商，使用AES进行业务数据的加解密。  \n\n# Signature Algorithm\n\n## **什么是SHA算法**\n> SHA的全称是“Secure Hash Algorithm”，中文翻译为：安全哈希算法，是由美国NSA和NIST两个组织共同发布的一系列密码散列函数，经历了SHA-0，SHA-1，SHA-2，SHA-3系列发展.\n\n### 什么是SHA-256算法\n> SHA256算法属于SHA-2系列，SHA-256对于任意长度的消息，都会产生一个256bit长的哈希值，称作消息摘要. 这个摘要相当于是个长度为32个字节的数组，通常用一个长度为64的十六进制字符串来表示.\n\n### 把消息转换为位字符串\nSHA-256算法是按照位作为输入，所以进行计算前必须把原始消息（比如字符串、文件等）转换成位字符串。\n比如，对字符串“abc”产生消息摘要，‘a’=97 ‘b’=98 ‘c’=99，先转换成24位的字符串：\n\n\t 01100001 01100010 01100011\n\n### 对转换得到的位字符串进行补位操作\n\n### 消息扩展、分组处理\n\n### 使用的常量和函数\n\n### 计算消息摘要\n\n### SHA-256安全性分析\nHash函数的安全性很大程度上取决于抗强碰撞的能力，即攻击者找出两个消息M和Mt，M≠Mt，使得H(M)=HMt  ,因此，评价一个Hash函数的安全性，就是看攻击者在现有的条件下，是否可以找到该函数的一对碰撞。目前已有的对Hash函数攻击的方法包括生日攻击、彩虹表攻击、差分攻击等。\n\n * 生日攻击：生日攻击是一种可用于攻击任何类型函数Hash函数的攻击方法。从攻击原理上看，它没有利用Hash函数的结构和任何代数弱性质，只依赖与Hash值的长度。因此，**抵御生日攻击最有效的方法是Hash值必须有足够的长度**。\n * 差分攻击：差分攻击是目前破译迭代Hash函数最有效的手法之一，其基本方法是利用明文的输入差值对输出差值的影响，运用差分的高概率的继承或者消除来产生最终的相同输出。\n\n用于消息唯一性和数据完整性验证的Hash函数，其安全性依赖于函数本身的属性和对抗碰撞的抵抗。Hash函数的算法结构特点和Hash值的长度是决定函数碰撞性的而主要因素，Hash值越长，越能抵御生日攻击。**SHA-256有256比特Hash值，MD5和SHA-1分别有128和160比特的Hash值。**因此，SHA-256比MD5和SHA-1能抵抗生日攻击。通过对Chabaud-Joux攻击SHA-256的分析，找到了SHA-256的一个部分碰撞，其复杂度为2^66，但无法找到SHA-256的一个整体碰撞，因此SHA-256算法也能抵御现有的差分攻击。由此可见，在抵御生日攻击和抵御已知差分攻击方面，SHA-256算法比现在广泛使用的MD5和SHA-1等更具安全性。\n\n### 比特币为什么选择SHA-256算法\n> SHA-256属于SHA-2系列，像之前的SHA0，SHA1都被证明是可以破解的，目前SHA2以及SHA3尚未被证实可以破解，至少目前来说是最安全的算法之一.\n> 未来即使使用量子计算机挖比特币，也无非是速度更快一点，比特币有难度调整机制，可以通过调整难度来对抗量子计算机，还可以通过升级算法到SHA-3系列来增加挖矿的难度.\n> 中本聪在设计比特币时，之所以选择SHA256，就是看中了SHA256的安全性，只要输入的数据有微小的区别，算出的结果就有天壤之别.\n\n# **AES-GCM加密算法**\n\n# 查看系统支持的密码列表\n\n**列出当前系统所支持的密码套件列表**\n\n\t$ openssl ciphers -V 'ALL:COMPLEMENTOFALL'\n**测试某个服务器是否支持特定的密码套件：**\n\n\t$ openssl s_client -cipher \"ECDHE-RSA-AES128-SHA\" -connect www.qq.com:443 -tls1_1\n\t# 参数说明\n\t# -cipher 参数表示本次连接支持的密码套件\n\t# -connect 表示连接服务器的 443 端口\n\t# -tls1_1 表示客户端最高支持的 TLS/SSL 版本是 TLS v1.1\nTLS deployment, viw version etc.[Security/Server Side TLS](https://wiki.mozilla.org/Security/Server_Side_TLS)\n\n\n\n\n","source":"_posts/technologies/security/algorithm_security.md","raw":"---\ntitle: algorithm security \ntags: security\ncategories:\n- technologies\n- security\n---\n\n# **Certificates Encryption Algorithm**\n\n## **RSA非对称加密算法**\nRSA(Rivest-Shamir-Adleman)\n> RSA是1977年由罗纳德·李维斯特（Ron Rivest）、阿迪·萨莫尔（Adi Shamir）和伦纳德·阿德曼（Leonard Adleman）一起提出的。当时他们三人都在麻省理工学院工作。RSA就是他们三人姓氏开头字母拼在一起组成的  \n\n非对称加密，公钥加密，私钥解密，反之亦然。由于需要大数的乘幂求模等算法，运行速度慢，不易于硬件实现。\n\n通常私钥长度有512bit，1024bit，2048bit，4096bit，长度越长，越安全，但是生成密钥越慢，加解密也越耗时。\n\n既然是加密，那肯定是不希望别人知道我的消息，所以只有我才能解密，所以可得出公钥负责加密，私钥负责解密；\n\n同理，既然是签名，那肯定是不希望有人冒充我发消息，只有我才能发布这个签名，所以可得出私钥负责签名，公钥负责验证。\n\n> 非对称加密算法实现机密信息交换的基本过程是：甲方生成一对密钥并将其中的一把作为公用密钥向其它方公开(用CA private key签名得到甲方证书)；用CA的public key解密得到该公用密钥的乙方使用该密钥对机密信息进行加密后再发送给甲方；甲方再用自己保存的另一把专用密钥对加密后的信息进行解密来获取信息.\n\n## **AES对称加密算法**\nAES,高级加密标准（Advanced Encryption Standard，缩写：AES）  \n\n对称加密，密钥最长只有256个bit，执行速度快，易于硬件实现。由于是对称加密，密钥需要在传输前通讯双方获知。\n\n基于以上特点，通常使用RSA来首先传输AES的密钥给对方，然后再使用AES来进行加密通讯。\n\nAES128和AES256主要区别是密钥长度不同（分别是128bits,256bits)、加密处理轮数不同（分别是10轮，14轮），后者强度高于前者。当前AES是较为安全的公认的对称加密算法。  \n\n现代密码学分为对称加密与非对称加密（公钥加密），代表算法分别有DES(现在发展为3DES）、AES与RSA等。非对称加密算法的资源消耗大于对称加密。一般是进行混合加密处理，例如使用RSA进行密钥分发、协商，使用AES进行业务数据的加解密。  \n\n# Signature Algorithm\n\n## **什么是SHA算法**\n> SHA的全称是“Secure Hash Algorithm”，中文翻译为：安全哈希算法，是由美国NSA和NIST两个组织共同发布的一系列密码散列函数，经历了SHA-0，SHA-1，SHA-2，SHA-3系列发展.\n\n### 什么是SHA-256算法\n> SHA256算法属于SHA-2系列，SHA-256对于任意长度的消息，都会产生一个256bit长的哈希值，称作消息摘要. 这个摘要相当于是个长度为32个字节的数组，通常用一个长度为64的十六进制字符串来表示.\n\n### 把消息转换为位字符串\nSHA-256算法是按照位作为输入，所以进行计算前必须把原始消息（比如字符串、文件等）转换成位字符串。\n比如，对字符串“abc”产生消息摘要，‘a’=97 ‘b’=98 ‘c’=99，先转换成24位的字符串：\n\n\t 01100001 01100010 01100011\n\n### 对转换得到的位字符串进行补位操作\n\n### 消息扩展、分组处理\n\n### 使用的常量和函数\n\n### 计算消息摘要\n\n### SHA-256安全性分析\nHash函数的安全性很大程度上取决于抗强碰撞的能力，即攻击者找出两个消息M和Mt，M≠Mt，使得H(M)=HMt  ,因此，评价一个Hash函数的安全性，就是看攻击者在现有的条件下，是否可以找到该函数的一对碰撞。目前已有的对Hash函数攻击的方法包括生日攻击、彩虹表攻击、差分攻击等。\n\n * 生日攻击：生日攻击是一种可用于攻击任何类型函数Hash函数的攻击方法。从攻击原理上看，它没有利用Hash函数的结构和任何代数弱性质，只依赖与Hash值的长度。因此，**抵御生日攻击最有效的方法是Hash值必须有足够的长度**。\n * 差分攻击：差分攻击是目前破译迭代Hash函数最有效的手法之一，其基本方法是利用明文的输入差值对输出差值的影响，运用差分的高概率的继承或者消除来产生最终的相同输出。\n\n用于消息唯一性和数据完整性验证的Hash函数，其安全性依赖于函数本身的属性和对抗碰撞的抵抗。Hash函数的算法结构特点和Hash值的长度是决定函数碰撞性的而主要因素，Hash值越长，越能抵御生日攻击。**SHA-256有256比特Hash值，MD5和SHA-1分别有128和160比特的Hash值。**因此，SHA-256比MD5和SHA-1能抵抗生日攻击。通过对Chabaud-Joux攻击SHA-256的分析，找到了SHA-256的一个部分碰撞，其复杂度为2^66，但无法找到SHA-256的一个整体碰撞，因此SHA-256算法也能抵御现有的差分攻击。由此可见，在抵御生日攻击和抵御已知差分攻击方面，SHA-256算法比现在广泛使用的MD5和SHA-1等更具安全性。\n\n### 比特币为什么选择SHA-256算法\n> SHA-256属于SHA-2系列，像之前的SHA0，SHA1都被证明是可以破解的，目前SHA2以及SHA3尚未被证实可以破解，至少目前来说是最安全的算法之一.\n> 未来即使使用量子计算机挖比特币，也无非是速度更快一点，比特币有难度调整机制，可以通过调整难度来对抗量子计算机，还可以通过升级算法到SHA-3系列来增加挖矿的难度.\n> 中本聪在设计比特币时，之所以选择SHA256，就是看中了SHA256的安全性，只要输入的数据有微小的区别，算出的结果就有天壤之别.\n\n# **AES-GCM加密算法**\n\n# 查看系统支持的密码列表\n\n**列出当前系统所支持的密码套件列表**\n\n\t$ openssl ciphers -V 'ALL:COMPLEMENTOFALL'\n**测试某个服务器是否支持特定的密码套件：**\n\n\t$ openssl s_client -cipher \"ECDHE-RSA-AES128-SHA\" -connect www.qq.com:443 -tls1_1\n\t# 参数说明\n\t# -cipher 参数表示本次连接支持的密码套件\n\t# -connect 表示连接服务器的 443 端口\n\t# -tls1_1 表示客户端最高支持的 TLS/SSL 版本是 TLS v1.1\nTLS deployment, viw version etc.[Security/Server Side TLS](https://wiki.mozilla.org/Security/Server_Side_TLS)\n\n\n\n\n","slug":"technologies/security/algorithm_security","published":1,"date":"2020-08-12T16:05:48.633Z","updated":"2020-08-10T16:34:16.111Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmns008zhohxbqh51bd7","content":"<h1 id=\"Certificates-Encryption-Algorithm\"><a href=\"#Certificates-Encryption-Algorithm\" class=\"headerlink\" title=\"Certificates Encryption Algorithm\"></a><strong>Certificates Encryption Algorithm</strong></h1><h2 id=\"RSA非对称加密算法\"><a href=\"#RSA非对称加密算法\" class=\"headerlink\" title=\"RSA非对称加密算法\"></a><strong>RSA非对称加密算法</strong></h2><p>RSA(Rivest-Shamir-Adleman)</p>\n<blockquote>\n<p>RSA是1977年由罗纳德·李维斯特（Ron Rivest）、阿迪·萨莫尔（Adi Shamir）和伦纳德·阿德曼（Leonard Adleman）一起提出的。当时他们三人都在麻省理工学院工作。RSA就是他们三人姓氏开头字母拼在一起组成的  </p>\n</blockquote>\n<p>非对称加密，公钥加密，私钥解密，反之亦然。由于需要大数的乘幂求模等算法，运行速度慢，不易于硬件实现。</p>\n<p>通常私钥长度有512bit，1024bit，2048bit，4096bit，长度越长，越安全，但是生成密钥越慢，加解密也越耗时。</p>\n<p>既然是加密，那肯定是不希望别人知道我的消息，所以只有我才能解密，所以可得出公钥负责加密，私钥负责解密；</p>\n<p>同理，既然是签名，那肯定是不希望有人冒充我发消息，只有我才能发布这个签名，所以可得出私钥负责签名，公钥负责验证。</p>\n<blockquote>\n<p>非对称加密算法实现机密信息交换的基本过程是：甲方生成一对密钥并将其中的一把作为公用密钥向其它方公开(用CA private key签名得到甲方证书)；用CA的public key解密得到该公用密钥的乙方使用该密钥对机密信息进行加密后再发送给甲方；甲方再用自己保存的另一把专用密钥对加密后的信息进行解密来获取信息.</p>\n</blockquote>\n<h2 id=\"AES对称加密算法\"><a href=\"#AES对称加密算法\" class=\"headerlink\" title=\"AES对称加密算法\"></a><strong>AES对称加密算法</strong></h2><p>AES,高级加密标准（Advanced Encryption Standard，缩写：AES）  </p>\n<p>对称加密，密钥最长只有256个bit，执行速度快，易于硬件实现。由于是对称加密，密钥需要在传输前通讯双方获知。</p>\n<p>基于以上特点，通常使用RSA来首先传输AES的密钥给对方，然后再使用AES来进行加密通讯。</p>\n<p>AES128和AES256主要区别是密钥长度不同（分别是128bits,256bits)、加密处理轮数不同（分别是10轮，14轮），后者强度高于前者。当前AES是较为安全的公认的对称加密算法。  </p>\n<p>现代密码学分为对称加密与非对称加密（公钥加密），代表算法分别有DES(现在发展为3DES）、AES与RSA等。非对称加密算法的资源消耗大于对称加密。一般是进行混合加密处理，例如使用RSA进行密钥分发、协商，使用AES进行业务数据的加解密。  </p>\n<h1 id=\"Signature-Algorithm\"><a href=\"#Signature-Algorithm\" class=\"headerlink\" title=\"Signature Algorithm\"></a>Signature Algorithm</h1><h2 id=\"什么是SHA算法\"><a href=\"#什么是SHA算法\" class=\"headerlink\" title=\"什么是SHA算法\"></a><strong>什么是SHA算法</strong></h2><blockquote>\n<p>SHA的全称是“Secure Hash Algorithm”，中文翻译为：安全哈希算法，是由美国NSA和NIST两个组织共同发布的一系列密码散列函数，经历了SHA-0，SHA-1，SHA-2，SHA-3系列发展.</p>\n</blockquote>\n<h3 id=\"什么是SHA-256算法\"><a href=\"#什么是SHA-256算法\" class=\"headerlink\" title=\"什么是SHA-256算法\"></a>什么是SHA-256算法</h3><blockquote>\n<p>SHA256算法属于SHA-2系列，SHA-256对于任意长度的消息，都会产生一个256bit长的哈希值，称作消息摘要. 这个摘要相当于是个长度为32个字节的数组，通常用一个长度为64的十六进制字符串来表示.</p>\n</blockquote>\n<h3 id=\"把消息转换为位字符串\"><a href=\"#把消息转换为位字符串\" class=\"headerlink\" title=\"把消息转换为位字符串\"></a>把消息转换为位字符串</h3><p>SHA-256算法是按照位作为输入，所以进行计算前必须把原始消息（比如字符串、文件等）转换成位字符串。<br>比如，对字符串“abc”产生消息摘要，‘a’=97 ‘b’=98 ‘c’=99，先转换成24位的字符串：</p>\n<pre><code>01100001 01100010 01100011</code></pre><h3 id=\"对转换得到的位字符串进行补位操作\"><a href=\"#对转换得到的位字符串进行补位操作\" class=\"headerlink\" title=\"对转换得到的位字符串进行补位操作\"></a>对转换得到的位字符串进行补位操作</h3><h3 id=\"消息扩展、分组处理\"><a href=\"#消息扩展、分组处理\" class=\"headerlink\" title=\"消息扩展、分组处理\"></a>消息扩展、分组处理</h3><h3 id=\"使用的常量和函数\"><a href=\"#使用的常量和函数\" class=\"headerlink\" title=\"使用的常量和函数\"></a>使用的常量和函数</h3><h3 id=\"计算消息摘要\"><a href=\"#计算消息摘要\" class=\"headerlink\" title=\"计算消息摘要\"></a>计算消息摘要</h3><h3 id=\"SHA-256安全性分析\"><a href=\"#SHA-256安全性分析\" class=\"headerlink\" title=\"SHA-256安全性分析\"></a>SHA-256安全性分析</h3><p>Hash函数的安全性很大程度上取决于抗强碰撞的能力，即攻击者找出两个消息M和Mt，M≠Mt，使得H(M)=HMt  ,因此，评价一个Hash函数的安全性，就是看攻击者在现有的条件下，是否可以找到该函数的一对碰撞。目前已有的对Hash函数攻击的方法包括生日攻击、彩虹表攻击、差分攻击等。</p>\n<ul>\n<li>生日攻击：生日攻击是一种可用于攻击任何类型函数Hash函数的攻击方法。从攻击原理上看，它没有利用Hash函数的结构和任何代数弱性质，只依赖与Hash值的长度。因此，<strong>抵御生日攻击最有效的方法是Hash值必须有足够的长度</strong>。</li>\n<li>差分攻击：差分攻击是目前破译迭代Hash函数最有效的手法之一，其基本方法是利用明文的输入差值对输出差值的影响，运用差分的高概率的继承或者消除来产生最终的相同输出。</li>\n</ul>\n<p>用于消息唯一性和数据完整性验证的Hash函数，其安全性依赖于函数本身的属性和对抗碰撞的抵抗。Hash函数的算法结构特点和Hash值的长度是决定函数碰撞性的而主要因素，Hash值越长，越能抵御生日攻击。<strong>SHA-256有256比特Hash值，MD5和SHA-1分别有128和160比特的Hash值。</strong>因此，SHA-256比MD5和SHA-1能抵抗生日攻击。通过对Chabaud-Joux攻击SHA-256的分析，找到了SHA-256的一个部分碰撞，其复杂度为2^66，但无法找到SHA-256的一个整体碰撞，因此SHA-256算法也能抵御现有的差分攻击。由此可见，在抵御生日攻击和抵御已知差分攻击方面，SHA-256算法比现在广泛使用的MD5和SHA-1等更具安全性。</p>\n<h3 id=\"比特币为什么选择SHA-256算法\"><a href=\"#比特币为什么选择SHA-256算法\" class=\"headerlink\" title=\"比特币为什么选择SHA-256算法\"></a>比特币为什么选择SHA-256算法</h3><blockquote>\n<p>SHA-256属于SHA-2系列，像之前的SHA0，SHA1都被证明是可以破解的，目前SHA2以及SHA3尚未被证实可以破解，至少目前来说是最安全的算法之一.<br>未来即使使用量子计算机挖比特币，也无非是速度更快一点，比特币有难度调整机制，可以通过调整难度来对抗量子计算机，还可以通过升级算法到SHA-3系列来增加挖矿的难度.<br>中本聪在设计比特币时，之所以选择SHA256，就是看中了SHA256的安全性，只要输入的数据有微小的区别，算出的结果就有天壤之别.</p>\n</blockquote>\n<h1 id=\"AES-GCM加密算法\"><a href=\"#AES-GCM加密算法\" class=\"headerlink\" title=\"AES-GCM加密算法\"></a><strong>AES-GCM加密算法</strong></h1><h1 id=\"查看系统支持的密码列表\"><a href=\"#查看系统支持的密码列表\" class=\"headerlink\" title=\"查看系统支持的密码列表\"></a>查看系统支持的密码列表</h1><p><strong>列出当前系统所支持的密码套件列表</strong></p>\n<pre><code>$ openssl ciphers -V &apos;ALL:COMPLEMENTOFALL&apos;</code></pre><p><strong>测试某个服务器是否支持特定的密码套件：</strong></p>\n<pre><code>$ openssl s_client -cipher &quot;ECDHE-RSA-AES128-SHA&quot; -connect www.qq.com:443 -tls1_1\n# 参数说明\n# -cipher 参数表示本次连接支持的密码套件\n# -connect 表示连接服务器的 443 端口\n# -tls1_1 表示客户端最高支持的 TLS/SSL 版本是 TLS v1.1</code></pre><p>TLS deployment, viw version etc.<a href=\"https://wiki.mozilla.org/Security/Server_Side_TLS\" target=\"_blank\" rel=\"noopener\">Security/Server Side TLS</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Certificates-Encryption-Algorithm\"><a href=\"#Certificates-Encryption-Algorithm\" class=\"headerlink\" title=\"Certificates Encryption Algorithm\"></a><strong>Certificates Encryption Algorithm</strong></h1><h2 id=\"RSA非对称加密算法\"><a href=\"#RSA非对称加密算法\" class=\"headerlink\" title=\"RSA非对称加密算法\"></a><strong>RSA非对称加密算法</strong></h2><p>RSA(Rivest-Shamir-Adleman)</p>\n<blockquote>\n<p>RSA是1977年由罗纳德·李维斯特（Ron Rivest）、阿迪·萨莫尔（Adi Shamir）和伦纳德·阿德曼（Leonard Adleman）一起提出的。当时他们三人都在麻省理工学院工作。RSA就是他们三人姓氏开头字母拼在一起组成的  </p>\n</blockquote>\n<p>非对称加密，公钥加密，私钥解密，反之亦然。由于需要大数的乘幂求模等算法，运行速度慢，不易于硬件实现。</p>\n<p>通常私钥长度有512bit，1024bit，2048bit，4096bit，长度越长，越安全，但是生成密钥越慢，加解密也越耗时。</p>\n<p>既然是加密，那肯定是不希望别人知道我的消息，所以只有我才能解密，所以可得出公钥负责加密，私钥负责解密；</p>\n<p>同理，既然是签名，那肯定是不希望有人冒充我发消息，只有我才能发布这个签名，所以可得出私钥负责签名，公钥负责验证。</p>\n<blockquote>\n<p>非对称加密算法实现机密信息交换的基本过程是：甲方生成一对密钥并将其中的一把作为公用密钥向其它方公开(用CA private key签名得到甲方证书)；用CA的public key解密得到该公用密钥的乙方使用该密钥对机密信息进行加密后再发送给甲方；甲方再用自己保存的另一把专用密钥对加密后的信息进行解密来获取信息.</p>\n</blockquote>\n<h2 id=\"AES对称加密算法\"><a href=\"#AES对称加密算法\" class=\"headerlink\" title=\"AES对称加密算法\"></a><strong>AES对称加密算法</strong></h2><p>AES,高级加密标准（Advanced Encryption Standard，缩写：AES）  </p>\n<p>对称加密，密钥最长只有256个bit，执行速度快，易于硬件实现。由于是对称加密，密钥需要在传输前通讯双方获知。</p>\n<p>基于以上特点，通常使用RSA来首先传输AES的密钥给对方，然后再使用AES来进行加密通讯。</p>\n<p>AES128和AES256主要区别是密钥长度不同（分别是128bits,256bits)、加密处理轮数不同（分别是10轮，14轮），后者强度高于前者。当前AES是较为安全的公认的对称加密算法。  </p>\n<p>现代密码学分为对称加密与非对称加密（公钥加密），代表算法分别有DES(现在发展为3DES）、AES与RSA等。非对称加密算法的资源消耗大于对称加密。一般是进行混合加密处理，例如使用RSA进行密钥分发、协商，使用AES进行业务数据的加解密。  </p>\n<h1 id=\"Signature-Algorithm\"><a href=\"#Signature-Algorithm\" class=\"headerlink\" title=\"Signature Algorithm\"></a>Signature Algorithm</h1><h2 id=\"什么是SHA算法\"><a href=\"#什么是SHA算法\" class=\"headerlink\" title=\"什么是SHA算法\"></a><strong>什么是SHA算法</strong></h2><blockquote>\n<p>SHA的全称是“Secure Hash Algorithm”，中文翻译为：安全哈希算法，是由美国NSA和NIST两个组织共同发布的一系列密码散列函数，经历了SHA-0，SHA-1，SHA-2，SHA-3系列发展.</p>\n</blockquote>\n<h3 id=\"什么是SHA-256算法\"><a href=\"#什么是SHA-256算法\" class=\"headerlink\" title=\"什么是SHA-256算法\"></a>什么是SHA-256算法</h3><blockquote>\n<p>SHA256算法属于SHA-2系列，SHA-256对于任意长度的消息，都会产生一个256bit长的哈希值，称作消息摘要. 这个摘要相当于是个长度为32个字节的数组，通常用一个长度为64的十六进制字符串来表示.</p>\n</blockquote>\n<h3 id=\"把消息转换为位字符串\"><a href=\"#把消息转换为位字符串\" class=\"headerlink\" title=\"把消息转换为位字符串\"></a>把消息转换为位字符串</h3><p>SHA-256算法是按照位作为输入，所以进行计算前必须把原始消息（比如字符串、文件等）转换成位字符串。<br>比如，对字符串“abc”产生消息摘要，‘a’=97 ‘b’=98 ‘c’=99，先转换成24位的字符串：</p>\n<pre><code>01100001 01100010 01100011</code></pre><h3 id=\"对转换得到的位字符串进行补位操作\"><a href=\"#对转换得到的位字符串进行补位操作\" class=\"headerlink\" title=\"对转换得到的位字符串进行补位操作\"></a>对转换得到的位字符串进行补位操作</h3><h3 id=\"消息扩展、分组处理\"><a href=\"#消息扩展、分组处理\" class=\"headerlink\" title=\"消息扩展、分组处理\"></a>消息扩展、分组处理</h3><h3 id=\"使用的常量和函数\"><a href=\"#使用的常量和函数\" class=\"headerlink\" title=\"使用的常量和函数\"></a>使用的常量和函数</h3><h3 id=\"计算消息摘要\"><a href=\"#计算消息摘要\" class=\"headerlink\" title=\"计算消息摘要\"></a>计算消息摘要</h3><h3 id=\"SHA-256安全性分析\"><a href=\"#SHA-256安全性分析\" class=\"headerlink\" title=\"SHA-256安全性分析\"></a>SHA-256安全性分析</h3><p>Hash函数的安全性很大程度上取决于抗强碰撞的能力，即攻击者找出两个消息M和Mt，M≠Mt，使得H(M)=HMt  ,因此，评价一个Hash函数的安全性，就是看攻击者在现有的条件下，是否可以找到该函数的一对碰撞。目前已有的对Hash函数攻击的方法包括生日攻击、彩虹表攻击、差分攻击等。</p>\n<ul>\n<li>生日攻击：生日攻击是一种可用于攻击任何类型函数Hash函数的攻击方法。从攻击原理上看，它没有利用Hash函数的结构和任何代数弱性质，只依赖与Hash值的长度。因此，<strong>抵御生日攻击最有效的方法是Hash值必须有足够的长度</strong>。</li>\n<li>差分攻击：差分攻击是目前破译迭代Hash函数最有效的手法之一，其基本方法是利用明文的输入差值对输出差值的影响，运用差分的高概率的继承或者消除来产生最终的相同输出。</li>\n</ul>\n<p>用于消息唯一性和数据完整性验证的Hash函数，其安全性依赖于函数本身的属性和对抗碰撞的抵抗。Hash函数的算法结构特点和Hash值的长度是决定函数碰撞性的而主要因素，Hash值越长，越能抵御生日攻击。<strong>SHA-256有256比特Hash值，MD5和SHA-1分别有128和160比特的Hash值。</strong>因此，SHA-256比MD5和SHA-1能抵抗生日攻击。通过对Chabaud-Joux攻击SHA-256的分析，找到了SHA-256的一个部分碰撞，其复杂度为2^66，但无法找到SHA-256的一个整体碰撞，因此SHA-256算法也能抵御现有的差分攻击。由此可见，在抵御生日攻击和抵御已知差分攻击方面，SHA-256算法比现在广泛使用的MD5和SHA-1等更具安全性。</p>\n<h3 id=\"比特币为什么选择SHA-256算法\"><a href=\"#比特币为什么选择SHA-256算法\" class=\"headerlink\" title=\"比特币为什么选择SHA-256算法\"></a>比特币为什么选择SHA-256算法</h3><blockquote>\n<p>SHA-256属于SHA-2系列，像之前的SHA0，SHA1都被证明是可以破解的，目前SHA2以及SHA3尚未被证实可以破解，至少目前来说是最安全的算法之一.<br>未来即使使用量子计算机挖比特币，也无非是速度更快一点，比特币有难度调整机制，可以通过调整难度来对抗量子计算机，还可以通过升级算法到SHA-3系列来增加挖矿的难度.<br>中本聪在设计比特币时，之所以选择SHA256，就是看中了SHA256的安全性，只要输入的数据有微小的区别，算出的结果就有天壤之别.</p>\n</blockquote>\n<h1 id=\"AES-GCM加密算法\"><a href=\"#AES-GCM加密算法\" class=\"headerlink\" title=\"AES-GCM加密算法\"></a><strong>AES-GCM加密算法</strong></h1><h1 id=\"查看系统支持的密码列表\"><a href=\"#查看系统支持的密码列表\" class=\"headerlink\" title=\"查看系统支持的密码列表\"></a>查看系统支持的密码列表</h1><p><strong>列出当前系统所支持的密码套件列表</strong></p>\n<pre><code>$ openssl ciphers -V &apos;ALL:COMPLEMENTOFALL&apos;</code></pre><p><strong>测试某个服务器是否支持特定的密码套件：</strong></p>\n<pre><code>$ openssl s_client -cipher &quot;ECDHE-RSA-AES128-SHA&quot; -connect www.qq.com:443 -tls1_1\n# 参数说明\n# -cipher 参数表示本次连接支持的密码套件\n# -connect 表示连接服务器的 443 端口\n# -tls1_1 表示客户端最高支持的 TLS/SSL 版本是 TLS v1.1</code></pre><p>TLS deployment, viw version etc.<a href=\"https://wiki.mozilla.org/Security/Server_Side_TLS\" target=\"_blank\" rel=\"noopener\">Security/Server Side TLS</a></p>\n"},{"title":"certificates, public/private key, signature digest","_content":"\n## **openssl概述**\nOpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及SSL协议，并提供丰富的应用程序供测试或其它目的使用。\n\n## **公钥/私钥/签名/验证签名/加密/解密/非对称加密**\n我们一般的加密是用一个密码加密文件,然后解密也用同样的密码.这很好理解,这个是对称加密.而有些加密时,加密用的一个密码,而解密用另外一组密码,这个叫非对称加密,意思就是加密解密的密码不一样.初次接触的人恐怕无论如何都理解不了.其实这是数学上的一个素数积求因子的原理的应用,如果你一定要搞懂,百度有大把大把的资料可以看,其结果就是用这一组密钥中的一个来加密数据,可以用另一个解开.是的没错,公钥和私钥都可以用来加密数据,相反用另一个解开,公钥加密数据,然后私钥解密的情况被称为加密解密,私钥加密数据,公钥解密一般被称为签名和验证签名.\n\n因为公钥加密的数据只有它相对应的私钥可以解开,所以你可以把公钥给人和人,让他加密他想要传送给你的数据,这个数据只有到了有私钥的你这里,才可以解开成有用的数据,其他人就是得到了,也看懂内容.同理,如果你用你的私钥对数据进行签名,那这个数据就只有配对的公钥可以解开,有这个私钥的只有你,所以如果配对的公钥解开了数据,就说明这数据是你发的,相反,则不是.这个被称为签名.\n\n实际应用中,一般都是和对方交换公钥,然后你要发给对方的数据,用他的公钥加密,他得到后用他的私钥解密,他要发给你的数据,用你的公钥加密,你得到后用你的私钥解密,这样最大程度保证了安全性.\n\n## **RSA/AES/DSA/SHA/MD5**\n非对称加密的算法有很多,比较著名的有RSA/DSA ,不同的是RSA可以用于加/解密,也可以用于签名验签,DSA则只能用于签名.  \n\n至于<font face=\"fantasy\" color=#0099ff>**SHA**</font>则是一种和md5相同的算法,它不是用于加密解密或者签名的,它被称为<font face=\"fantasy\" color=#0099ff>**摘要算法**</font>.就是通过一种算法,依据数据内容生成一种固定长度的摘要,这串摘要值与原数据存在对应关系,就是原数据会生成这个摘要,但是,这个摘要是不能还原成原数据的,嗯….,正常情况下是这样的,这个算法起的作用就是,如果你把原数据修改一点点,那么生成的摘要都会不同,传输过程中把原数据给你再给你一个摘要,你把得到的原数据同样做一次摘要算法,与给你的摘要相比较就可以知道这个数据有没有在传输过程中被修改了.  \nHash算法特别的地方在于它是一种单向算法，用户可以通过Hash算法对目标信息生成一段特定长度的唯一的Hash值，却不能通过这个Hash值重新获得目标信息。因此Hash算法常用在不可还原的密码存储、信息完整性校验等。\n\n常见的Hash算法有MD2、MD4、MD5、HAVAL、SHA.\n\n加密算法的效能通常可以按照算法本身的复杂程度、密钥长度（密钥越长越安全）、加解密速度等来衡量。上述的算法中，除了DES密钥长度不够、MD2速度较慢已逐渐被淘汰外，其他算法仍在目前的加密系统产品中使用。\n\n实际应用过程中,因为需要加密的数据可能会很大,进行加密费时费力,所以一般都会把原数据先进行摘要,然后对这个摘要值进行加密,将原数据的明文和加密后的摘要值一起传给你.这样你解开加密后的摘要值,再和你得到的数据进行的摘要值对应一下就可以知道数据有没有被修改了,而且,因为私钥只有你有,只有你能解密摘要值,所以别人就算把原数据做了修改,然后生成一个假的摘要给你也是不行的,你这边用密钥也根本解不开.  \n\n**RSA: **\n**非对称加密**，公钥加密，私钥解密，反之亦然。由于需要大数的乘幂求模等算法，运行速度慢，不易于硬件实现。\n\n通常私钥长度有512bit，1024bit，2048bit，4096bit，长度越长，越安全，但是生成密钥越慢，加解密也越耗时。\n\n既然是加密，那肯定是不希望别人知道我的消息，所以只有我才能解密，所以可得出公钥负责加密，私钥负责解密；\n\n同理，既然是签名，那肯定是不希望有人冒充我发消息，只有我才能发布这个签名，所以可得出私钥负责签名，公钥负责验证。\n\n**AES: **\n**对称加密**，密钥最长只有256个bit，执行速度快，易于硬件实现。由于是对称加密，密钥需要在传输前通讯双方获知。\n\n基于以上特点，通常使用RSA来首先传输AES的密钥给对方，然后再使用AES来进行加密通讯。\n\n## **CA/PEM/DER/X509/PKCS**\n一般的公钥不会用明文传输给别人的,正常情况下都会生成一个文件,这个文件就是公钥文件,然后这个文件可以交给其他人用于加密,但是传输过程中如果有人恶意破坏,将你的公钥换成了他的公钥,然后得到公钥的一方加密数据,不是他就可以用他自己的密钥解密看到数据了吗,为了解决这个问题,需要一个公证方来做这个事,任何人都可以找它来确认公钥是谁发的.这就是CA,CA确认公钥的原理也很简单,它将它自己的公钥发布给所有人,然后一个想要发布自己公钥的人可以将自己的公钥和一些身份信息发给CA,**CA用自己的密钥进行加密,这里也可以称为<font face=\"fantasy\" color=#0099ff>签名</font>.** 然后这个**包含了你的公钥和你的信息的文件就可以称为<font face=\"fantasy\" color=#0099ff>证书文件</font>了.**这样一来所有得到一些公钥文件的人,通过CA的公钥解密了文件,如果正常解密那么机密后里面的信息一定是真的,因为加密方只可能是CA,其他人没它的密钥啊.这样你解开公钥文件,看看里面的信息就知道这个是不是那个你需要用来加密的公钥了.\n\n实际应用中,一般人都不会找CA去签名,因为那是收钱的,所以可以自己做一个自签名的证书文件,就是自己生成一对密钥,然后再用自己生成的另外一对密钥对这对密钥进行签名,这个只用于真正需要签名证书的人,普通的加密解密数据,直接用公钥和私钥来做就可以了.\n\n密钥文件的格式用OpenSSL生成的就只有PEM和DER两种格式,PEM的是将密钥用base64编码表示出来的,直接打开你能看到一串的英文字母,DER格式是二进制的密钥文件,直接打开,你可以看到……..你什么也看不懂!  \n\n.X509是通用的证书文件格式定义.  \n\npkcs的一系列标准是指定的存放密钥的文件标准。  \n\n你只要知道PEM DER X509 PKCS这几种格式是可以互相转化的.  \n\n\n下面内容转自: [csdn certificate key blog](https://blog.csdn.net/qq_38684504/article/details/89083200?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase)\n\n## **一、公钥加密**\n\n假设一下，我找了两个数字，一个是1，一个是2。我喜欢2这个数字，就保留起来，不告诉你们(私钥），然后我告诉大家，1是我的公钥。\n\n我有一个文件，不能让别人看，我就用1加密了。别人找到了这个文件，但是他不知道2就是解密的私钥啊，所以他解不开，只有我可以用数字2，就是我的私钥，来解密。这样我就可以保护数据了。\n\n我的好朋友x用我的公钥1加密了字符a，加密后成了b，放在网上。别人偷到了这个文件，但是别人解不开，因为别人不知道2就是我的私钥，只有我才能解密，解密后就得到a。这样，我们就可以传送加密的数据了。\n\n## **二、私钥签名**\n\n如果我用私钥加密一段数据（当然只有我可以用私钥加密，因为只有我知道2是我的私钥），结果所有的人都看到我的内容了，因为他们都知道我的公钥是1，那么这种加密有什么用处呢？\n\n但是我的好朋友x说有人冒充我给他发信。怎么办呢？我把我要发的信，内容是c，用我的私钥2，加密，加密后的内容是d，发给x，再告诉他解密看是不是c。他用我的公钥1解密，发现果然是c。这个时候，他会想到，能够用我的公钥解密的数据，必然是用我的私钥加的密。只有我知道我的私钥，因此他就可以确认确实是我发的东西。\n\n这样我们就能确认发送方身份了。这个过程叫做数字签名。当然具体的过程要稍微复杂一些。<table><tr><td bgcolor=#54FF9F>用私钥来加密数据，用途就是数字签名.</td></tr></table>\n\n**总结：**\n\n     **公钥和私钥是成对的，它们互相解密。**\n\n     **公钥加密，私钥解密。**\n\n     **私钥数字签名，公钥验证。**\n\n> **数字签名**是指将摘要信息使用接收者的公钥进行加密，与密文一起发送给接收者。接收者使用自己的私钥对摘要信息进行解密，然后使用Hash函数对收到的密文产生一个摘要信息，然后将摘要信息与发送着传输过来解密后的摘要信息对比是否一致。如果一致，则表明数据信息没有被篡改。\n\n## **三、举例**\n\n比如有两个用户Alice和Bob，Alice想把一段明文通过双钥加密的技术发送给Bob，Bob有一对公钥和私钥，那么加密解密的过程如下：\n\n 1. Bob将他的公开密钥传送给Alice。\n 2. Alice用Bob的公开密钥加密她的消息，然后传送给Bob。\n 3. Bob用他的私人密钥解密Alice的消息。\n上面的过程可以用下图表示，Alice使用Bob的公钥进行加密，Bob用自己的私钥进行解密。\n![](0.PNG)\n例子和图出自《网络安全基础 应用与标准第二版》\n\n## **四、图解**\n\n今天，我读到一篇好文章。\n\n它用图片通俗易懂地解释了，\"数字签名\"（digital signature）和\"数字证书\"（digital certificate）到底是什么。\n\n我对这些问题的理解，一直是模模糊糊的，很多细节搞不清楚。读完这篇文章后，发现思路一下子就理清了。为了加深记忆，我把文字和图片都翻译出来了。\n\n数字签名是什么？\n\n作者：David Youd\n\n翻译：阮一峰\n\n原文网址：http://www.youdzone.com/signature.html\n\n1.\n\n![](1.png)\n\n鲍勃（服务器）有两把钥匙，一把是公钥，另一把是私钥。\n\n2.\n\n![](2.png)\n\n鲍勃把公钥送给他的朋友们----帕蒂（客户端1）、道格（客户端2）、苏珊（客户端3）----每人一把。\n\n3.\n\n![](3.png)\n\n苏珊（客户端3）给鲍勃（服务器）写信，写完后用鲍勃的公钥加密，达到保密的效果。\n\n4.\n\n![](4.png)\n\n鲍勃收信后，用私钥解密，看到信件内容。\n\n5.\n\n![](5.png)\n\n鲍勃给苏珊回信，写完后用Hash函数，生成信件的摘要（digest）。\n\n6.\n\n![](6.png)\n\n然后，<font face=\"fantasy\" color=#0099ff>**鲍勃使用私钥，对这个摘要加密，生成\"数字签名\"(signature).**</font>\n\n7.\n\n![](7.png)\n\n鲍勃将这个签名，附在信件下面，一起发给苏珊。\n\n8.\n\n![](8.png)\n\n苏珊收信后，取下数字签名，<font face=\"fantasy\" color=#0099ff>**用鲍勃的公钥解密，得到信件的摘要。**</font>由此证明，这封信确实是鲍勃发出的。\n\n9.\n\n![](9.png)\n\n苏珊再对信件本身<font face=\"fantasy\" color=#0099ff>**使用Hash函数，将得到的结果，与上一步得到的摘要进行对比。</font>**如果两者一致，就证明这封信未被修改过。\n\n10.\n\n![](10.png)\n\n复杂的情况出现了。道格（客户端2）想欺骗苏珊，他偷偷使用了苏珊的电脑，用自己的公钥换走了鲍勃的公钥。因此，他就可以冒充鲍勃，写信给苏珊。\n\n此时客户端2的想法是：自己生成了一对公私密钥对，然后给苏珊一个公钥，自己发送数据和签名给苏珊，苏珊在不知道公钥被替换的情况下不知道服务器已被冒充，这样便形成了数据信息的泄露。\n\n11.\n\n![](11.png)\n\n苏珊发现，自己无法确定公钥是否真的属于鲍勃。她想到了一个办法，要求鲍勃去找\"证书中心\"（certificate authority，简称CA），为公钥做认证。<font face=\"fantasy\" color=#0099ff>**证书中心用自己的私钥，对鲍勃的公钥和一些相关信息一起加密，生成\"数字证书\"(Digital Certificate).**</font>\n\n12.\n\n![](12.png)\n\n鲍勃拿到数字证书以后，就可以放心了。以后再给苏珊写信，只要在签名的同时，再附上数字证书就行了。\n\n13.\n\n![](13.png)\n\n苏珊收信后，用CA的公钥解开数字证书，就可以拿到鲍勃真实的公钥了，然后就能证明\"数字签名\"是否真的是鲍勃签的。\n\n14.\n\n![](14.jpg)\n\n下面，我们看一个应用\"数字证书\"的实例：https协议。这个协议主要用于网页加密。\n\n15.\n\n![](15.png)\n\n首先，客户端向服务器发出加密请求。\n\n16.\n\n![](16.png)\n\n服务器用自己的私钥加密网页以后，连同本身的数字证书，一起发送给客户端。\n\n17.\n\n![](17.png)\n\n客户端（浏览器）的\"证书管理器\"，有\"受信任的根证书颁发机构\"列表。客户端会根据这张列表，查看解开数字证书的公钥是否在列表之内。\n\n18.\n\n![](18.png)\n\n如果数字证书记载的网址，与你正在浏览的网址不一致，就说明这张证书可能被冒用，浏览器会发出警告。\n\n19.\n\n![](19.jpg)\n\n如果这张数字证书不是由受信任的机构颁发的，浏览器会发出另一种警告。\n\n20.\n\n![](20.png)\n\n数字证书如果是可靠的，客户端就可以使用证书中的服务器公钥，对信息进行加密，然后与服务器交换加密信息。\n\n\n\n\n","source":"_posts/technologies/security/key_digest_signature_certificates.md","raw":"---\ntitle: certificates, public/private key, signature digest\ntags: security\ncategories:\n- technologies\n- security\n---\n\n## **openssl概述**\nOpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及SSL协议，并提供丰富的应用程序供测试或其它目的使用。\n\n## **公钥/私钥/签名/验证签名/加密/解密/非对称加密**\n我们一般的加密是用一个密码加密文件,然后解密也用同样的密码.这很好理解,这个是对称加密.而有些加密时,加密用的一个密码,而解密用另外一组密码,这个叫非对称加密,意思就是加密解密的密码不一样.初次接触的人恐怕无论如何都理解不了.其实这是数学上的一个素数积求因子的原理的应用,如果你一定要搞懂,百度有大把大把的资料可以看,其结果就是用这一组密钥中的一个来加密数据,可以用另一个解开.是的没错,公钥和私钥都可以用来加密数据,相反用另一个解开,公钥加密数据,然后私钥解密的情况被称为加密解密,私钥加密数据,公钥解密一般被称为签名和验证签名.\n\n因为公钥加密的数据只有它相对应的私钥可以解开,所以你可以把公钥给人和人,让他加密他想要传送给你的数据,这个数据只有到了有私钥的你这里,才可以解开成有用的数据,其他人就是得到了,也看懂内容.同理,如果你用你的私钥对数据进行签名,那这个数据就只有配对的公钥可以解开,有这个私钥的只有你,所以如果配对的公钥解开了数据,就说明这数据是你发的,相反,则不是.这个被称为签名.\n\n实际应用中,一般都是和对方交换公钥,然后你要发给对方的数据,用他的公钥加密,他得到后用他的私钥解密,他要发给你的数据,用你的公钥加密,你得到后用你的私钥解密,这样最大程度保证了安全性.\n\n## **RSA/AES/DSA/SHA/MD5**\n非对称加密的算法有很多,比较著名的有RSA/DSA ,不同的是RSA可以用于加/解密,也可以用于签名验签,DSA则只能用于签名.  \n\n至于<font face=\"fantasy\" color=#0099ff>**SHA**</font>则是一种和md5相同的算法,它不是用于加密解密或者签名的,它被称为<font face=\"fantasy\" color=#0099ff>**摘要算法**</font>.就是通过一种算法,依据数据内容生成一种固定长度的摘要,这串摘要值与原数据存在对应关系,就是原数据会生成这个摘要,但是,这个摘要是不能还原成原数据的,嗯….,正常情况下是这样的,这个算法起的作用就是,如果你把原数据修改一点点,那么生成的摘要都会不同,传输过程中把原数据给你再给你一个摘要,你把得到的原数据同样做一次摘要算法,与给你的摘要相比较就可以知道这个数据有没有在传输过程中被修改了.  \nHash算法特别的地方在于它是一种单向算法，用户可以通过Hash算法对目标信息生成一段特定长度的唯一的Hash值，却不能通过这个Hash值重新获得目标信息。因此Hash算法常用在不可还原的密码存储、信息完整性校验等。\n\n常见的Hash算法有MD2、MD4、MD5、HAVAL、SHA.\n\n加密算法的效能通常可以按照算法本身的复杂程度、密钥长度（密钥越长越安全）、加解密速度等来衡量。上述的算法中，除了DES密钥长度不够、MD2速度较慢已逐渐被淘汰外，其他算法仍在目前的加密系统产品中使用。\n\n实际应用过程中,因为需要加密的数据可能会很大,进行加密费时费力,所以一般都会把原数据先进行摘要,然后对这个摘要值进行加密,将原数据的明文和加密后的摘要值一起传给你.这样你解开加密后的摘要值,再和你得到的数据进行的摘要值对应一下就可以知道数据有没有被修改了,而且,因为私钥只有你有,只有你能解密摘要值,所以别人就算把原数据做了修改,然后生成一个假的摘要给你也是不行的,你这边用密钥也根本解不开.  \n\n**RSA: **\n**非对称加密**，公钥加密，私钥解密，反之亦然。由于需要大数的乘幂求模等算法，运行速度慢，不易于硬件实现。\n\n通常私钥长度有512bit，1024bit，2048bit，4096bit，长度越长，越安全，但是生成密钥越慢，加解密也越耗时。\n\n既然是加密，那肯定是不希望别人知道我的消息，所以只有我才能解密，所以可得出公钥负责加密，私钥负责解密；\n\n同理，既然是签名，那肯定是不希望有人冒充我发消息，只有我才能发布这个签名，所以可得出私钥负责签名，公钥负责验证。\n\n**AES: **\n**对称加密**，密钥最长只有256个bit，执行速度快，易于硬件实现。由于是对称加密，密钥需要在传输前通讯双方获知。\n\n基于以上特点，通常使用RSA来首先传输AES的密钥给对方，然后再使用AES来进行加密通讯。\n\n## **CA/PEM/DER/X509/PKCS**\n一般的公钥不会用明文传输给别人的,正常情况下都会生成一个文件,这个文件就是公钥文件,然后这个文件可以交给其他人用于加密,但是传输过程中如果有人恶意破坏,将你的公钥换成了他的公钥,然后得到公钥的一方加密数据,不是他就可以用他自己的密钥解密看到数据了吗,为了解决这个问题,需要一个公证方来做这个事,任何人都可以找它来确认公钥是谁发的.这就是CA,CA确认公钥的原理也很简单,它将它自己的公钥发布给所有人,然后一个想要发布自己公钥的人可以将自己的公钥和一些身份信息发给CA,**CA用自己的密钥进行加密,这里也可以称为<font face=\"fantasy\" color=#0099ff>签名</font>.** 然后这个**包含了你的公钥和你的信息的文件就可以称为<font face=\"fantasy\" color=#0099ff>证书文件</font>了.**这样一来所有得到一些公钥文件的人,通过CA的公钥解密了文件,如果正常解密那么机密后里面的信息一定是真的,因为加密方只可能是CA,其他人没它的密钥啊.这样你解开公钥文件,看看里面的信息就知道这个是不是那个你需要用来加密的公钥了.\n\n实际应用中,一般人都不会找CA去签名,因为那是收钱的,所以可以自己做一个自签名的证书文件,就是自己生成一对密钥,然后再用自己生成的另外一对密钥对这对密钥进行签名,这个只用于真正需要签名证书的人,普通的加密解密数据,直接用公钥和私钥来做就可以了.\n\n密钥文件的格式用OpenSSL生成的就只有PEM和DER两种格式,PEM的是将密钥用base64编码表示出来的,直接打开你能看到一串的英文字母,DER格式是二进制的密钥文件,直接打开,你可以看到……..你什么也看不懂!  \n\n.X509是通用的证书文件格式定义.  \n\npkcs的一系列标准是指定的存放密钥的文件标准。  \n\n你只要知道PEM DER X509 PKCS这几种格式是可以互相转化的.  \n\n\n下面内容转自: [csdn certificate key blog](https://blog.csdn.net/qq_38684504/article/details/89083200?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase)\n\n## **一、公钥加密**\n\n假设一下，我找了两个数字，一个是1，一个是2。我喜欢2这个数字，就保留起来，不告诉你们(私钥），然后我告诉大家，1是我的公钥。\n\n我有一个文件，不能让别人看，我就用1加密了。别人找到了这个文件，但是他不知道2就是解密的私钥啊，所以他解不开，只有我可以用数字2，就是我的私钥，来解密。这样我就可以保护数据了。\n\n我的好朋友x用我的公钥1加密了字符a，加密后成了b，放在网上。别人偷到了这个文件，但是别人解不开，因为别人不知道2就是我的私钥，只有我才能解密，解密后就得到a。这样，我们就可以传送加密的数据了。\n\n## **二、私钥签名**\n\n如果我用私钥加密一段数据（当然只有我可以用私钥加密，因为只有我知道2是我的私钥），结果所有的人都看到我的内容了，因为他们都知道我的公钥是1，那么这种加密有什么用处呢？\n\n但是我的好朋友x说有人冒充我给他发信。怎么办呢？我把我要发的信，内容是c，用我的私钥2，加密，加密后的内容是d，发给x，再告诉他解密看是不是c。他用我的公钥1解密，发现果然是c。这个时候，他会想到，能够用我的公钥解密的数据，必然是用我的私钥加的密。只有我知道我的私钥，因此他就可以确认确实是我发的东西。\n\n这样我们就能确认发送方身份了。这个过程叫做数字签名。当然具体的过程要稍微复杂一些。<table><tr><td bgcolor=#54FF9F>用私钥来加密数据，用途就是数字签名.</td></tr></table>\n\n**总结：**\n\n     **公钥和私钥是成对的，它们互相解密。**\n\n     **公钥加密，私钥解密。**\n\n     **私钥数字签名，公钥验证。**\n\n> **数字签名**是指将摘要信息使用接收者的公钥进行加密，与密文一起发送给接收者。接收者使用自己的私钥对摘要信息进行解密，然后使用Hash函数对收到的密文产生一个摘要信息，然后将摘要信息与发送着传输过来解密后的摘要信息对比是否一致。如果一致，则表明数据信息没有被篡改。\n\n## **三、举例**\n\n比如有两个用户Alice和Bob，Alice想把一段明文通过双钥加密的技术发送给Bob，Bob有一对公钥和私钥，那么加密解密的过程如下：\n\n 1. Bob将他的公开密钥传送给Alice。\n 2. Alice用Bob的公开密钥加密她的消息，然后传送给Bob。\n 3. Bob用他的私人密钥解密Alice的消息。\n上面的过程可以用下图表示，Alice使用Bob的公钥进行加密，Bob用自己的私钥进行解密。\n![](0.PNG)\n例子和图出自《网络安全基础 应用与标准第二版》\n\n## **四、图解**\n\n今天，我读到一篇好文章。\n\n它用图片通俗易懂地解释了，\"数字签名\"（digital signature）和\"数字证书\"（digital certificate）到底是什么。\n\n我对这些问题的理解，一直是模模糊糊的，很多细节搞不清楚。读完这篇文章后，发现思路一下子就理清了。为了加深记忆，我把文字和图片都翻译出来了。\n\n数字签名是什么？\n\n作者：David Youd\n\n翻译：阮一峰\n\n原文网址：http://www.youdzone.com/signature.html\n\n1.\n\n![](1.png)\n\n鲍勃（服务器）有两把钥匙，一把是公钥，另一把是私钥。\n\n2.\n\n![](2.png)\n\n鲍勃把公钥送给他的朋友们----帕蒂（客户端1）、道格（客户端2）、苏珊（客户端3）----每人一把。\n\n3.\n\n![](3.png)\n\n苏珊（客户端3）给鲍勃（服务器）写信，写完后用鲍勃的公钥加密，达到保密的效果。\n\n4.\n\n![](4.png)\n\n鲍勃收信后，用私钥解密，看到信件内容。\n\n5.\n\n![](5.png)\n\n鲍勃给苏珊回信，写完后用Hash函数，生成信件的摘要（digest）。\n\n6.\n\n![](6.png)\n\n然后，<font face=\"fantasy\" color=#0099ff>**鲍勃使用私钥，对这个摘要加密，生成\"数字签名\"(signature).**</font>\n\n7.\n\n![](7.png)\n\n鲍勃将这个签名，附在信件下面，一起发给苏珊。\n\n8.\n\n![](8.png)\n\n苏珊收信后，取下数字签名，<font face=\"fantasy\" color=#0099ff>**用鲍勃的公钥解密，得到信件的摘要。**</font>由此证明，这封信确实是鲍勃发出的。\n\n9.\n\n![](9.png)\n\n苏珊再对信件本身<font face=\"fantasy\" color=#0099ff>**使用Hash函数，将得到的结果，与上一步得到的摘要进行对比。</font>**如果两者一致，就证明这封信未被修改过。\n\n10.\n\n![](10.png)\n\n复杂的情况出现了。道格（客户端2）想欺骗苏珊，他偷偷使用了苏珊的电脑，用自己的公钥换走了鲍勃的公钥。因此，他就可以冒充鲍勃，写信给苏珊。\n\n此时客户端2的想法是：自己生成了一对公私密钥对，然后给苏珊一个公钥，自己发送数据和签名给苏珊，苏珊在不知道公钥被替换的情况下不知道服务器已被冒充，这样便形成了数据信息的泄露。\n\n11.\n\n![](11.png)\n\n苏珊发现，自己无法确定公钥是否真的属于鲍勃。她想到了一个办法，要求鲍勃去找\"证书中心\"（certificate authority，简称CA），为公钥做认证。<font face=\"fantasy\" color=#0099ff>**证书中心用自己的私钥，对鲍勃的公钥和一些相关信息一起加密，生成\"数字证书\"(Digital Certificate).**</font>\n\n12.\n\n![](12.png)\n\n鲍勃拿到数字证书以后，就可以放心了。以后再给苏珊写信，只要在签名的同时，再附上数字证书就行了。\n\n13.\n\n![](13.png)\n\n苏珊收信后，用CA的公钥解开数字证书，就可以拿到鲍勃真实的公钥了，然后就能证明\"数字签名\"是否真的是鲍勃签的。\n\n14.\n\n![](14.jpg)\n\n下面，我们看一个应用\"数字证书\"的实例：https协议。这个协议主要用于网页加密。\n\n15.\n\n![](15.png)\n\n首先，客户端向服务器发出加密请求。\n\n16.\n\n![](16.png)\n\n服务器用自己的私钥加密网页以后，连同本身的数字证书，一起发送给客户端。\n\n17.\n\n![](17.png)\n\n客户端（浏览器）的\"证书管理器\"，有\"受信任的根证书颁发机构\"列表。客户端会根据这张列表，查看解开数字证书的公钥是否在列表之内。\n\n18.\n\n![](18.png)\n\n如果数字证书记载的网址，与你正在浏览的网址不一致，就说明这张证书可能被冒用，浏览器会发出警告。\n\n19.\n\n![](19.jpg)\n\n如果这张数字证书不是由受信任的机构颁发的，浏览器会发出另一种警告。\n\n20.\n\n![](20.png)\n\n数字证书如果是可靠的，客户端就可以使用证书中的服务器公钥，对信息进行加密，然后与服务器交换加密信息。\n\n\n\n\n","slug":"technologies/security/key_digest_signature_certificates","published":1,"date":"2020-08-12T16:05:48.671Z","updated":"2020-08-10T16:34:10.871Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmo40091hohx3f0hbr1d","content":"<h2 id=\"openssl概述\"><a href=\"#openssl概述\" class=\"headerlink\" title=\"openssl概述\"></a><strong>openssl概述</strong></h2><p>OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及SSL协议，并提供丰富的应用程序供测试或其它目的使用。</p>\n<h2 id=\"公钥-私钥-签名-验证签名-加密-解密-非对称加密\"><a href=\"#公钥-私钥-签名-验证签名-加密-解密-非对称加密\" class=\"headerlink\" title=\"公钥/私钥/签名/验证签名/加密/解密/非对称加密\"></a><strong>公钥/私钥/签名/验证签名/加密/解密/非对称加密</strong></h2><p>我们一般的加密是用一个密码加密文件,然后解密也用同样的密码.这很好理解,这个是对称加密.而有些加密时,加密用的一个密码,而解密用另外一组密码,这个叫非对称加密,意思就是加密解密的密码不一样.初次接触的人恐怕无论如何都理解不了.其实这是数学上的一个素数积求因子的原理的应用,如果你一定要搞懂,百度有大把大把的资料可以看,其结果就是用这一组密钥中的一个来加密数据,可以用另一个解开.是的没错,公钥和私钥都可以用来加密数据,相反用另一个解开,公钥加密数据,然后私钥解密的情况被称为加密解密,私钥加密数据,公钥解密一般被称为签名和验证签名.</p>\n<p>因为公钥加密的数据只有它相对应的私钥可以解开,所以你可以把公钥给人和人,让他加密他想要传送给你的数据,这个数据只有到了有私钥的你这里,才可以解开成有用的数据,其他人就是得到了,也看懂内容.同理,如果你用你的私钥对数据进行签名,那这个数据就只有配对的公钥可以解开,有这个私钥的只有你,所以如果配对的公钥解开了数据,就说明这数据是你发的,相反,则不是.这个被称为签名.</p>\n<p>实际应用中,一般都是和对方交换公钥,然后你要发给对方的数据,用他的公钥加密,他得到后用他的私钥解密,他要发给你的数据,用你的公钥加密,你得到后用你的私钥解密,这样最大程度保证了安全性.</p>\n<h2 id=\"RSA-AES-DSA-SHA-MD5\"><a href=\"#RSA-AES-DSA-SHA-MD5\" class=\"headerlink\" title=\"RSA/AES/DSA/SHA/MD5\"></a><strong>RSA/AES/DSA/SHA/MD5</strong></h2><p>非对称加密的算法有很多,比较著名的有RSA/DSA ,不同的是RSA可以用于加/解密,也可以用于签名验签,DSA则只能用于签名.  </p>\n<p>至于<font face=\"fantasy\" color=#0099ff><strong>SHA</strong></font>则是一种和md5相同的算法,它不是用于加密解密或者签名的,它被称为<font face=\"fantasy\" color=#0099ff><strong>摘要算法</strong></font>.就是通过一种算法,依据数据内容生成一种固定长度的摘要,这串摘要值与原数据存在对应关系,就是原数据会生成这个摘要,但是,这个摘要是不能还原成原数据的,嗯….,正常情况下是这样的,这个算法起的作用就是,如果你把原数据修改一点点,那么生成的摘要都会不同,传输过程中把原数据给你再给你一个摘要,你把得到的原数据同样做一次摘要算法,与给你的摘要相比较就可以知道这个数据有没有在传输过程中被修改了.<br>Hash算法特别的地方在于它是一种单向算法，用户可以通过Hash算法对目标信息生成一段特定长度的唯一的Hash值，却不能通过这个Hash值重新获得目标信息。因此Hash算法常用在不可还原的密码存储、信息完整性校验等。</p>\n<p>常见的Hash算法有MD2、MD4、MD5、HAVAL、SHA.</p>\n<p>加密算法的效能通常可以按照算法本身的复杂程度、密钥长度（密钥越长越安全）、加解密速度等来衡量。上述的算法中，除了DES密钥长度不够、MD2速度较慢已逐渐被淘汰外，其他算法仍在目前的加密系统产品中使用。</p>\n<p>实际应用过程中,因为需要加密的数据可能会很大,进行加密费时费力,所以一般都会把原数据先进行摘要,然后对这个摘要值进行加密,将原数据的明文和加密后的摘要值一起传给你.这样你解开加密后的摘要值,再和你得到的数据进行的摘要值对应一下就可以知道数据有没有被修改了,而且,因为私钥只有你有,只有你能解密摘要值,所以别人就算把原数据做了修改,然后生成一个假的摘要给你也是不行的,你这边用密钥也根本解不开.  </p>\n<p><strong>RSA: **<br>**非对称加密</strong>，公钥加密，私钥解密，反之亦然。由于需要大数的乘幂求模等算法，运行速度慢，不易于硬件实现。</p>\n<p>通常私钥长度有512bit，1024bit，2048bit，4096bit，长度越长，越安全，但是生成密钥越慢，加解密也越耗时。</p>\n<p>既然是加密，那肯定是不希望别人知道我的消息，所以只有我才能解密，所以可得出公钥负责加密，私钥负责解密；</p>\n<p>同理，既然是签名，那肯定是不希望有人冒充我发消息，只有我才能发布这个签名，所以可得出私钥负责签名，公钥负责验证。</p>\n<p><strong>AES: **<br>**对称加密</strong>，密钥最长只有256个bit，执行速度快，易于硬件实现。由于是对称加密，密钥需要在传输前通讯双方获知。</p>\n<p>基于以上特点，通常使用RSA来首先传输AES的密钥给对方，然后再使用AES来进行加密通讯。</p>\n<h2 id=\"CA-PEM-DER-X509-PKCS\"><a href=\"#CA-PEM-DER-X509-PKCS\" class=\"headerlink\" title=\"CA/PEM/DER/X509/PKCS\"></a><strong>CA/PEM/DER/X509/PKCS</strong></h2><p>一般的公钥不会用明文传输给别人的,正常情况下都会生成一个文件,这个文件就是公钥文件,然后这个文件可以交给其他人用于加密,但是传输过程中如果有人恶意破坏,将你的公钥换成了他的公钥,然后得到公钥的一方加密数据,不是他就可以用他自己的密钥解密看到数据了吗,为了解决这个问题,需要一个公证方来做这个事,任何人都可以找它来确认公钥是谁发的.这就是CA,CA确认公钥的原理也很简单,它将它自己的公钥发布给所有人,然后一个想要发布自己公钥的人可以将自己的公钥和一些身份信息发给CA,<strong>CA用自己的密钥进行加密,这里也可以称为<font face=\"fantasy\" color=#0099ff>签名</font>.</strong> 然后这个<strong>包含了你的公钥和你的信息的文件就可以称为<font face=\"fantasy\" color=#0099ff>证书文件</font>了.</strong>这样一来所有得到一些公钥文件的人,通过CA的公钥解密了文件,如果正常解密那么机密后里面的信息一定是真的,因为加密方只可能是CA,其他人没它的密钥啊.这样你解开公钥文件,看看里面的信息就知道这个是不是那个你需要用来加密的公钥了.</p>\n<p>实际应用中,一般人都不会找CA去签名,因为那是收钱的,所以可以自己做一个自签名的证书文件,就是自己生成一对密钥,然后再用自己生成的另外一对密钥对这对密钥进行签名,这个只用于真正需要签名证书的人,普通的加密解密数据,直接用公钥和私钥来做就可以了.</p>\n<p>密钥文件的格式用OpenSSL生成的就只有PEM和DER两种格式,PEM的是将密钥用base64编码表示出来的,直接打开你能看到一串的英文字母,DER格式是二进制的密钥文件,直接打开,你可以看到……..你什么也看不懂!  </p>\n<p>.X509是通用的证书文件格式定义.  </p>\n<p>pkcs的一系列标准是指定的存放密钥的文件标准。  </p>\n<p>你只要知道PEM DER X509 PKCS这几种格式是可以互相转化的.  </p>\n<p>下面内容转自: <a href=\"https://blog.csdn.net/qq_38684504/article/details/89083200?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase\" target=\"_blank\" rel=\"noopener\">csdn certificate key blog</a></p>\n<h2 id=\"一、公钥加密\"><a href=\"#一、公钥加密\" class=\"headerlink\" title=\"一、公钥加密\"></a><strong>一、公钥加密</strong></h2><p>假设一下，我找了两个数字，一个是1，一个是2。我喜欢2这个数字，就保留起来，不告诉你们(私钥），然后我告诉大家，1是我的公钥。</p>\n<p>我有一个文件，不能让别人看，我就用1加密了。别人找到了这个文件，但是他不知道2就是解密的私钥啊，所以他解不开，只有我可以用数字2，就是我的私钥，来解密。这样我就可以保护数据了。</p>\n<p>我的好朋友x用我的公钥1加密了字符a，加密后成了b，放在网上。别人偷到了这个文件，但是别人解不开，因为别人不知道2就是我的私钥，只有我才能解密，解密后就得到a。这样，我们就可以传送加密的数据了。</p>\n<h2 id=\"二、私钥签名\"><a href=\"#二、私钥签名\" class=\"headerlink\" title=\"二、私钥签名\"></a><strong>二、私钥签名</strong></h2><p>如果我用私钥加密一段数据（当然只有我可以用私钥加密，因为只有我知道2是我的私钥），结果所有的人都看到我的内容了，因为他们都知道我的公钥是1，那么这种加密有什么用处呢？</p>\n<p>但是我的好朋友x说有人冒充我给他发信。怎么办呢？我把我要发的信，内容是c，用我的私钥2，加密，加密后的内容是d，发给x，再告诉他解密看是不是c。他用我的公钥1解密，发现果然是c。这个时候，他会想到，能够用我的公钥解密的数据，必然是用我的私钥加的密。只有我知道我的私钥，因此他就可以确认确实是我发的东西。</p>\n<p>这样我们就能确认发送方身份了。这个过程叫做数字签名。当然具体的过程要稍微复杂一些。<table><tr><td bgcolor=#54FF9F>用私钥来加密数据，用途就是数字签名.</td></tr></table></p>\n<p><strong>总结：</strong></p>\n<pre><code>**公钥和私钥是成对的，它们互相解密。**\n\n**公钥加密，私钥解密。**\n\n**私钥数字签名，公钥验证。**</code></pre><blockquote>\n<p><strong>数字签名</strong>是指将摘要信息使用接收者的公钥进行加密，与密文一起发送给接收者。接收者使用自己的私钥对摘要信息进行解密，然后使用Hash函数对收到的密文产生一个摘要信息，然后将摘要信息与发送着传输过来解密后的摘要信息对比是否一致。如果一致，则表明数据信息没有被篡改。</p>\n</blockquote>\n<h2 id=\"三、举例\"><a href=\"#三、举例\" class=\"headerlink\" title=\"三、举例\"></a><strong>三、举例</strong></h2><p>比如有两个用户Alice和Bob，Alice想把一段明文通过双钥加密的技术发送给Bob，Bob有一对公钥和私钥，那么加密解密的过程如下：</p>\n<ol>\n<li>Bob将他的公开密钥传送给Alice。</li>\n<li>Alice用Bob的公开密钥加密她的消息，然后传送给Bob。</li>\n<li>Bob用他的私人密钥解密Alice的消息。<br>上面的过程可以用下图表示，Alice使用Bob的公钥进行加密，Bob用自己的私钥进行解密。<br><img src=\"0.PNG\" alt=\"\"><br>例子和图出自《网络安全基础 应用与标准第二版》</li>\n</ol>\n<h2 id=\"四、图解\"><a href=\"#四、图解\" class=\"headerlink\" title=\"四、图解\"></a><strong>四、图解</strong></h2><p>今天，我读到一篇好文章。</p>\n<p>它用图片通俗易懂地解释了，”数字签名”（digital signature）和”数字证书”（digital certificate）到底是什么。</p>\n<p>我对这些问题的理解，一直是模模糊糊的，很多细节搞不清楚。读完这篇文章后，发现思路一下子就理清了。为了加深记忆，我把文字和图片都翻译出来了。</p>\n<p>数字签名是什么？</p>\n<p>作者：David Youd</p>\n<p>翻译：阮一峰</p>\n<p>原文网址：<a href=\"http://www.youdzone.com/signature.html\" target=\"_blank\" rel=\"noopener\">http://www.youdzone.com/signature.html</a></p>\n<p>1.</p>\n<p><img src=\"1.png\" alt=\"\"></p>\n<p>鲍勃（服务器）有两把钥匙，一把是公钥，另一把是私钥。</p>\n<p>2.</p>\n<p><img src=\"2.png\" alt=\"\"></p>\n<p>鲍勃把公钥送给他的朋友们—-帕蒂（客户端1）、道格（客户端2）、苏珊（客户端3）—-每人一把。</p>\n<p>3.</p>\n<p><img src=\"3.png\" alt=\"\"></p>\n<p>苏珊（客户端3）给鲍勃（服务器）写信，写完后用鲍勃的公钥加密，达到保密的效果。</p>\n<p>4.</p>\n<p><img src=\"4.png\" alt=\"\"></p>\n<p>鲍勃收信后，用私钥解密，看到信件内容。</p>\n<p>5.</p>\n<p><img src=\"5.png\" alt=\"\"></p>\n<p>鲍勃给苏珊回信，写完后用Hash函数，生成信件的摘要（digest）。</p>\n<p>6.</p>\n<p><img src=\"6.png\" alt=\"\"></p>\n<p>然后，<font face=\"fantasy\" color=#0099ff><strong>鲍勃使用私钥，对这个摘要加密，生成”数字签名”(signature).</strong></font></p>\n<p>7.</p>\n<p><img src=\"7.png\" alt=\"\"></p>\n<p>鲍勃将这个签名，附在信件下面，一起发给苏珊。</p>\n<p>8.</p>\n<p><img src=\"8.png\" alt=\"\"></p>\n<p>苏珊收信后，取下数字签名，<font face=\"fantasy\" color=#0099ff><strong>用鲍勃的公钥解密，得到信件的摘要。</strong></font>由此证明，这封信确实是鲍勃发出的。</p>\n<p>9.</p>\n<p><img src=\"9.png\" alt=\"\"></p>\n<p>苏珊再对信件本身<font face=\"fantasy\" color=#0099ff><strong>使用Hash函数，将得到的结果，与上一步得到的摘要进行对比。</font></strong>如果两者一致，就证明这封信未被修改过。</p>\n<p>10.</p>\n<p><img src=\"10.png\" alt=\"\"></p>\n<p>复杂的情况出现了。道格（客户端2）想欺骗苏珊，他偷偷使用了苏珊的电脑，用自己的公钥换走了鲍勃的公钥。因此，他就可以冒充鲍勃，写信给苏珊。</p>\n<p>此时客户端2的想法是：自己生成了一对公私密钥对，然后给苏珊一个公钥，自己发送数据和签名给苏珊，苏珊在不知道公钥被替换的情况下不知道服务器已被冒充，这样便形成了数据信息的泄露。</p>\n<p>11.</p>\n<p><img src=\"11.png\" alt=\"\"></p>\n<p>苏珊发现，自己无法确定公钥是否真的属于鲍勃。她想到了一个办法，要求鲍勃去找”证书中心”（certificate authority，简称CA），为公钥做认证。<font face=\"fantasy\" color=#0099ff><strong>证书中心用自己的私钥，对鲍勃的公钥和一些相关信息一起加密，生成”数字证书”(Digital Certificate).</strong></font></p>\n<p>12.</p>\n<p><img src=\"12.png\" alt=\"\"></p>\n<p>鲍勃拿到数字证书以后，就可以放心了。以后再给苏珊写信，只要在签名的同时，再附上数字证书就行了。</p>\n<p>13.</p>\n<p><img src=\"13.png\" alt=\"\"></p>\n<p>苏珊收信后，用CA的公钥解开数字证书，就可以拿到鲍勃真实的公钥了，然后就能证明”数字签名”是否真的是鲍勃签的。</p>\n<p>14.</p>\n<p><img src=\"14.jpg\" alt=\"\"></p>\n<p>下面，我们看一个应用”数字证书”的实例：https协议。这个协议主要用于网页加密。</p>\n<p>15.</p>\n<p><img src=\"15.png\" alt=\"\"></p>\n<p>首先，客户端向服务器发出加密请求。</p>\n<p>16.</p>\n<p><img src=\"16.png\" alt=\"\"></p>\n<p>服务器用自己的私钥加密网页以后，连同本身的数字证书，一起发送给客户端。</p>\n<p>17.</p>\n<p><img src=\"17.png\" alt=\"\"></p>\n<p>客户端（浏览器）的”证书管理器”，有”受信任的根证书颁发机构”列表。客户端会根据这张列表，查看解开数字证书的公钥是否在列表之内。</p>\n<p>18.</p>\n<p><img src=\"18.png\" alt=\"\"></p>\n<p>如果数字证书记载的网址，与你正在浏览的网址不一致，就说明这张证书可能被冒用，浏览器会发出警告。</p>\n<p>19.</p>\n<p><img src=\"19.jpg\" alt=\"\"></p>\n<p>如果这张数字证书不是由受信任的机构颁发的，浏览器会发出另一种警告。</p>\n<p>20.</p>\n<p><img src=\"20.png\" alt=\"\"></p>\n<p>数字证书如果是可靠的，客户端就可以使用证书中的服务器公钥，对信息进行加密，然后与服务器交换加密信息。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"openssl概述\"><a href=\"#openssl概述\" class=\"headerlink\" title=\"openssl概述\"></a><strong>openssl概述</strong></h2><p>OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及SSL协议，并提供丰富的应用程序供测试或其它目的使用。</p>\n<h2 id=\"公钥-私钥-签名-验证签名-加密-解密-非对称加密\"><a href=\"#公钥-私钥-签名-验证签名-加密-解密-非对称加密\" class=\"headerlink\" title=\"公钥/私钥/签名/验证签名/加密/解密/非对称加密\"></a><strong>公钥/私钥/签名/验证签名/加密/解密/非对称加密</strong></h2><p>我们一般的加密是用一个密码加密文件,然后解密也用同样的密码.这很好理解,这个是对称加密.而有些加密时,加密用的一个密码,而解密用另外一组密码,这个叫非对称加密,意思就是加密解密的密码不一样.初次接触的人恐怕无论如何都理解不了.其实这是数学上的一个素数积求因子的原理的应用,如果你一定要搞懂,百度有大把大把的资料可以看,其结果就是用这一组密钥中的一个来加密数据,可以用另一个解开.是的没错,公钥和私钥都可以用来加密数据,相反用另一个解开,公钥加密数据,然后私钥解密的情况被称为加密解密,私钥加密数据,公钥解密一般被称为签名和验证签名.</p>\n<p>因为公钥加密的数据只有它相对应的私钥可以解开,所以你可以把公钥给人和人,让他加密他想要传送给你的数据,这个数据只有到了有私钥的你这里,才可以解开成有用的数据,其他人就是得到了,也看懂内容.同理,如果你用你的私钥对数据进行签名,那这个数据就只有配对的公钥可以解开,有这个私钥的只有你,所以如果配对的公钥解开了数据,就说明这数据是你发的,相反,则不是.这个被称为签名.</p>\n<p>实际应用中,一般都是和对方交换公钥,然后你要发给对方的数据,用他的公钥加密,他得到后用他的私钥解密,他要发给你的数据,用你的公钥加密,你得到后用你的私钥解密,这样最大程度保证了安全性.</p>\n<h2 id=\"RSA-AES-DSA-SHA-MD5\"><a href=\"#RSA-AES-DSA-SHA-MD5\" class=\"headerlink\" title=\"RSA/AES/DSA/SHA/MD5\"></a><strong>RSA/AES/DSA/SHA/MD5</strong></h2><p>非对称加密的算法有很多,比较著名的有RSA/DSA ,不同的是RSA可以用于加/解密,也可以用于签名验签,DSA则只能用于签名.  </p>\n<p>至于<font face=\"fantasy\" color=#0099ff><strong>SHA</strong></font>则是一种和md5相同的算法,它不是用于加密解密或者签名的,它被称为<font face=\"fantasy\" color=#0099ff><strong>摘要算法</strong></font>.就是通过一种算法,依据数据内容生成一种固定长度的摘要,这串摘要值与原数据存在对应关系,就是原数据会生成这个摘要,但是,这个摘要是不能还原成原数据的,嗯….,正常情况下是这样的,这个算法起的作用就是,如果你把原数据修改一点点,那么生成的摘要都会不同,传输过程中把原数据给你再给你一个摘要,你把得到的原数据同样做一次摘要算法,与给你的摘要相比较就可以知道这个数据有没有在传输过程中被修改了.<br>Hash算法特别的地方在于它是一种单向算法，用户可以通过Hash算法对目标信息生成一段特定长度的唯一的Hash值，却不能通过这个Hash值重新获得目标信息。因此Hash算法常用在不可还原的密码存储、信息完整性校验等。</p>\n<p>常见的Hash算法有MD2、MD4、MD5、HAVAL、SHA.</p>\n<p>加密算法的效能通常可以按照算法本身的复杂程度、密钥长度（密钥越长越安全）、加解密速度等来衡量。上述的算法中，除了DES密钥长度不够、MD2速度较慢已逐渐被淘汰外，其他算法仍在目前的加密系统产品中使用。</p>\n<p>实际应用过程中,因为需要加密的数据可能会很大,进行加密费时费力,所以一般都会把原数据先进行摘要,然后对这个摘要值进行加密,将原数据的明文和加密后的摘要值一起传给你.这样你解开加密后的摘要值,再和你得到的数据进行的摘要值对应一下就可以知道数据有没有被修改了,而且,因为私钥只有你有,只有你能解密摘要值,所以别人就算把原数据做了修改,然后生成一个假的摘要给你也是不行的,你这边用密钥也根本解不开.  </p>\n<p><strong>RSA: **<br>**非对称加密</strong>，公钥加密，私钥解密，反之亦然。由于需要大数的乘幂求模等算法，运行速度慢，不易于硬件实现。</p>\n<p>通常私钥长度有512bit，1024bit，2048bit，4096bit，长度越长，越安全，但是生成密钥越慢，加解密也越耗时。</p>\n<p>既然是加密，那肯定是不希望别人知道我的消息，所以只有我才能解密，所以可得出公钥负责加密，私钥负责解密；</p>\n<p>同理，既然是签名，那肯定是不希望有人冒充我发消息，只有我才能发布这个签名，所以可得出私钥负责签名，公钥负责验证。</p>\n<p><strong>AES: **<br>**对称加密</strong>，密钥最长只有256个bit，执行速度快，易于硬件实现。由于是对称加密，密钥需要在传输前通讯双方获知。</p>\n<p>基于以上特点，通常使用RSA来首先传输AES的密钥给对方，然后再使用AES来进行加密通讯。</p>\n<h2 id=\"CA-PEM-DER-X509-PKCS\"><a href=\"#CA-PEM-DER-X509-PKCS\" class=\"headerlink\" title=\"CA/PEM/DER/X509/PKCS\"></a><strong>CA/PEM/DER/X509/PKCS</strong></h2><p>一般的公钥不会用明文传输给别人的,正常情况下都会生成一个文件,这个文件就是公钥文件,然后这个文件可以交给其他人用于加密,但是传输过程中如果有人恶意破坏,将你的公钥换成了他的公钥,然后得到公钥的一方加密数据,不是他就可以用他自己的密钥解密看到数据了吗,为了解决这个问题,需要一个公证方来做这个事,任何人都可以找它来确认公钥是谁发的.这就是CA,CA确认公钥的原理也很简单,它将它自己的公钥发布给所有人,然后一个想要发布自己公钥的人可以将自己的公钥和一些身份信息发给CA,<strong>CA用自己的密钥进行加密,这里也可以称为<font face=\"fantasy\" color=#0099ff>签名</font>.</strong> 然后这个<strong>包含了你的公钥和你的信息的文件就可以称为<font face=\"fantasy\" color=#0099ff>证书文件</font>了.</strong>这样一来所有得到一些公钥文件的人,通过CA的公钥解密了文件,如果正常解密那么机密后里面的信息一定是真的,因为加密方只可能是CA,其他人没它的密钥啊.这样你解开公钥文件,看看里面的信息就知道这个是不是那个你需要用来加密的公钥了.</p>\n<p>实际应用中,一般人都不会找CA去签名,因为那是收钱的,所以可以自己做一个自签名的证书文件,就是自己生成一对密钥,然后再用自己生成的另外一对密钥对这对密钥进行签名,这个只用于真正需要签名证书的人,普通的加密解密数据,直接用公钥和私钥来做就可以了.</p>\n<p>密钥文件的格式用OpenSSL生成的就只有PEM和DER两种格式,PEM的是将密钥用base64编码表示出来的,直接打开你能看到一串的英文字母,DER格式是二进制的密钥文件,直接打开,你可以看到……..你什么也看不懂!  </p>\n<p>.X509是通用的证书文件格式定义.  </p>\n<p>pkcs的一系列标准是指定的存放密钥的文件标准。  </p>\n<p>你只要知道PEM DER X509 PKCS这几种格式是可以互相转化的.  </p>\n<p>下面内容转自: <a href=\"https://blog.csdn.net/qq_38684504/article/details/89083200?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase\" target=\"_blank\" rel=\"noopener\">csdn certificate key blog</a></p>\n<h2 id=\"一、公钥加密\"><a href=\"#一、公钥加密\" class=\"headerlink\" title=\"一、公钥加密\"></a><strong>一、公钥加密</strong></h2><p>假设一下，我找了两个数字，一个是1，一个是2。我喜欢2这个数字，就保留起来，不告诉你们(私钥），然后我告诉大家，1是我的公钥。</p>\n<p>我有一个文件，不能让别人看，我就用1加密了。别人找到了这个文件，但是他不知道2就是解密的私钥啊，所以他解不开，只有我可以用数字2，就是我的私钥，来解密。这样我就可以保护数据了。</p>\n<p>我的好朋友x用我的公钥1加密了字符a，加密后成了b，放在网上。别人偷到了这个文件，但是别人解不开，因为别人不知道2就是我的私钥，只有我才能解密，解密后就得到a。这样，我们就可以传送加密的数据了。</p>\n<h2 id=\"二、私钥签名\"><a href=\"#二、私钥签名\" class=\"headerlink\" title=\"二、私钥签名\"></a><strong>二、私钥签名</strong></h2><p>如果我用私钥加密一段数据（当然只有我可以用私钥加密，因为只有我知道2是我的私钥），结果所有的人都看到我的内容了，因为他们都知道我的公钥是1，那么这种加密有什么用处呢？</p>\n<p>但是我的好朋友x说有人冒充我给他发信。怎么办呢？我把我要发的信，内容是c，用我的私钥2，加密，加密后的内容是d，发给x，再告诉他解密看是不是c。他用我的公钥1解密，发现果然是c。这个时候，他会想到，能够用我的公钥解密的数据，必然是用我的私钥加的密。只有我知道我的私钥，因此他就可以确认确实是我发的东西。</p>\n<p>这样我们就能确认发送方身份了。这个过程叫做数字签名。当然具体的过程要稍微复杂一些。<table><tr><td bgcolor=#54FF9F>用私钥来加密数据，用途就是数字签名.</td></tr></table></p>\n<p><strong>总结：</strong></p>\n<pre><code>**公钥和私钥是成对的，它们互相解密。**\n\n**公钥加密，私钥解密。**\n\n**私钥数字签名，公钥验证。**</code></pre><blockquote>\n<p><strong>数字签名</strong>是指将摘要信息使用接收者的公钥进行加密，与密文一起发送给接收者。接收者使用自己的私钥对摘要信息进行解密，然后使用Hash函数对收到的密文产生一个摘要信息，然后将摘要信息与发送着传输过来解密后的摘要信息对比是否一致。如果一致，则表明数据信息没有被篡改。</p>\n</blockquote>\n<h2 id=\"三、举例\"><a href=\"#三、举例\" class=\"headerlink\" title=\"三、举例\"></a><strong>三、举例</strong></h2><p>比如有两个用户Alice和Bob，Alice想把一段明文通过双钥加密的技术发送给Bob，Bob有一对公钥和私钥，那么加密解密的过程如下：</p>\n<ol>\n<li>Bob将他的公开密钥传送给Alice。</li>\n<li>Alice用Bob的公开密钥加密她的消息，然后传送给Bob。</li>\n<li>Bob用他的私人密钥解密Alice的消息。<br>上面的过程可以用下图表示，Alice使用Bob的公钥进行加密，Bob用自己的私钥进行解密。<br><img src=\"0.PNG\" alt=\"\"><br>例子和图出自《网络安全基础 应用与标准第二版》</li>\n</ol>\n<h2 id=\"四、图解\"><a href=\"#四、图解\" class=\"headerlink\" title=\"四、图解\"></a><strong>四、图解</strong></h2><p>今天，我读到一篇好文章。</p>\n<p>它用图片通俗易懂地解释了，”数字签名”（digital signature）和”数字证书”（digital certificate）到底是什么。</p>\n<p>我对这些问题的理解，一直是模模糊糊的，很多细节搞不清楚。读完这篇文章后，发现思路一下子就理清了。为了加深记忆，我把文字和图片都翻译出来了。</p>\n<p>数字签名是什么？</p>\n<p>作者：David Youd</p>\n<p>翻译：阮一峰</p>\n<p>原文网址：<a href=\"http://www.youdzone.com/signature.html\" target=\"_blank\" rel=\"noopener\">http://www.youdzone.com/signature.html</a></p>\n<p>1.</p>\n<p><img src=\"1.png\" alt=\"\"></p>\n<p>鲍勃（服务器）有两把钥匙，一把是公钥，另一把是私钥。</p>\n<p>2.</p>\n<p><img src=\"2.png\" alt=\"\"></p>\n<p>鲍勃把公钥送给他的朋友们—-帕蒂（客户端1）、道格（客户端2）、苏珊（客户端3）—-每人一把。</p>\n<p>3.</p>\n<p><img src=\"3.png\" alt=\"\"></p>\n<p>苏珊（客户端3）给鲍勃（服务器）写信，写完后用鲍勃的公钥加密，达到保密的效果。</p>\n<p>4.</p>\n<p><img src=\"4.png\" alt=\"\"></p>\n<p>鲍勃收信后，用私钥解密，看到信件内容。</p>\n<p>5.</p>\n<p><img src=\"5.png\" alt=\"\"></p>\n<p>鲍勃给苏珊回信，写完后用Hash函数，生成信件的摘要（digest）。</p>\n<p>6.</p>\n<p><img src=\"6.png\" alt=\"\"></p>\n<p>然后，<font face=\"fantasy\" color=#0099ff><strong>鲍勃使用私钥，对这个摘要加密，生成”数字签名”(signature).</strong></font></p>\n<p>7.</p>\n<p><img src=\"7.png\" alt=\"\"></p>\n<p>鲍勃将这个签名，附在信件下面，一起发给苏珊。</p>\n<p>8.</p>\n<p><img src=\"8.png\" alt=\"\"></p>\n<p>苏珊收信后，取下数字签名，<font face=\"fantasy\" color=#0099ff><strong>用鲍勃的公钥解密，得到信件的摘要。</strong></font>由此证明，这封信确实是鲍勃发出的。</p>\n<p>9.</p>\n<p><img src=\"9.png\" alt=\"\"></p>\n<p>苏珊再对信件本身<font face=\"fantasy\" color=#0099ff><strong>使用Hash函数，将得到的结果，与上一步得到的摘要进行对比。</font></strong>如果两者一致，就证明这封信未被修改过。</p>\n<p>10.</p>\n<p><img src=\"10.png\" alt=\"\"></p>\n<p>复杂的情况出现了。道格（客户端2）想欺骗苏珊，他偷偷使用了苏珊的电脑，用自己的公钥换走了鲍勃的公钥。因此，他就可以冒充鲍勃，写信给苏珊。</p>\n<p>此时客户端2的想法是：自己生成了一对公私密钥对，然后给苏珊一个公钥，自己发送数据和签名给苏珊，苏珊在不知道公钥被替换的情况下不知道服务器已被冒充，这样便形成了数据信息的泄露。</p>\n<p>11.</p>\n<p><img src=\"11.png\" alt=\"\"></p>\n<p>苏珊发现，自己无法确定公钥是否真的属于鲍勃。她想到了一个办法，要求鲍勃去找”证书中心”（certificate authority，简称CA），为公钥做认证。<font face=\"fantasy\" color=#0099ff><strong>证书中心用自己的私钥，对鲍勃的公钥和一些相关信息一起加密，生成”数字证书”(Digital Certificate).</strong></font></p>\n<p>12.</p>\n<p><img src=\"12.png\" alt=\"\"></p>\n<p>鲍勃拿到数字证书以后，就可以放心了。以后再给苏珊写信，只要在签名的同时，再附上数字证书就行了。</p>\n<p>13.</p>\n<p><img src=\"13.png\" alt=\"\"></p>\n<p>苏珊收信后，用CA的公钥解开数字证书，就可以拿到鲍勃真实的公钥了，然后就能证明”数字签名”是否真的是鲍勃签的。</p>\n<p>14.</p>\n<p><img src=\"14.jpg\" alt=\"\"></p>\n<p>下面，我们看一个应用”数字证书”的实例：https协议。这个协议主要用于网页加密。</p>\n<p>15.</p>\n<p><img src=\"15.png\" alt=\"\"></p>\n<p>首先，客户端向服务器发出加密请求。</p>\n<p>16.</p>\n<p><img src=\"16.png\" alt=\"\"></p>\n<p>服务器用自己的私钥加密网页以后，连同本身的数字证书，一起发送给客户端。</p>\n<p>17.</p>\n<p><img src=\"17.png\" alt=\"\"></p>\n<p>客户端（浏览器）的”证书管理器”，有”受信任的根证书颁发机构”列表。客户端会根据这张列表，查看解开数字证书的公钥是否在列表之内。</p>\n<p>18.</p>\n<p><img src=\"18.png\" alt=\"\"></p>\n<p>如果数字证书记载的网址，与你正在浏览的网址不一致，就说明这张证书可能被冒用，浏览器会发出警告。</p>\n<p>19.</p>\n<p><img src=\"19.jpg\" alt=\"\"></p>\n<p>如果这张数字证书不是由受信任的机构颁发的，浏览器会发出另一种警告。</p>\n<p>20.</p>\n<p><img src=\"20.png\" alt=\"\"></p>\n<p>数字证书如果是可靠的，客户端就可以使用证书中的服务器公钥，对信息进行加密，然后与服务器交换加密信息。</p>\n"},{"title":"Ubuntu18.04 安装 Mysql8.0","_content":"\n# Mysql 安装:\n\n### 1. 下载deb包\n\thttps://dev.mysql.com/downloads/repo/apt/\n\n### 2. 跟新dpkg\n\t$ dpkg -i mysql-apt-config_0.8.15-1_all.deb\n\t$ apt update\n\n### 3. 安装mysql8\n\t$ apt install mysql-server\n\t输入密码123456\n\t最后加密方式选择Legacy(5.x)\n\n# Mysql 卸载:\n\n```\n搜索的一种卸载方式:\n首先在终端中查看MySQL的依赖项：dpkg --list|grep mysql\n卸载： sudo apt-get remove mysql-common\n卸载：sudo apt-get autoremove --purge mysql-server-5.7\n清除残留数据：dpkg -l|grep ^rc|awk ‘{print$2}’|sudo xargs dpkg -P\n再次查看MySQL的剩余依赖项：dpkg --list|grep mysql\n继续删除剩余依赖项，如：sudo apt-get autoremove --purge mysql-apt-config\n至此已经没有了MySQL的依赖项，彻底删除，Good Luck\n\n另外一种卸载方式:\nsudo apt-get autoremove --purge mysql-server \nsudo apt-get remove mysql-common\nsudo rm -rf /etc/mysql/ \nsudo rm -rf  /var/lib/mysql\n​​#清理残留数据\ndpkg -l |grep ^rc|awk '{print $2}' |sudo xargs dpkg -P  \nsudo apt autoremove\nsudo apt autoclean\n\n最终是用dpkg --list|grep mysql命令查看没有任何mysql信息输出即可\n```\n\n# Mysql登录\n\n### 第一种命令行方式:\n```\n $ mysql -uroot -p123456\n```\n### 第二种mysql-workbench\n * $ apt update\n * $ apt install mysql-workbench\n * $ mysql-workbench\t\t// 可以通过键入 mysql-workbench或单击 MySQL Workbench 图标 (Activities -> MySQL Workbench) 从命令行启动它。\n\n### 第三种Navigat 工具方式：\n - Navicat是可以管理多种数据库Mysql, redis, MongoDB等等的软件，收费\n * 连接名:localhost\n * 主机: 127.0.0.1\t\t// 用localhost 会报错 2002 - Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock'(2 \"No such file or directory\")\n * 端口: 3306\t\t\t// mysql安装后默认服务端口是3306， 可通过命令 \"netstat -tap | grep mysql\" 查看\n * 用户名: root\n * 密码: 123456\n \n# 重启Mysql server\n * $ systemctl restart mysql\t// Ubuntu18.04重启mysql会出错, 目前没解决，只是卸载mysql重装，最好别重启mysql服务\n\n","source":"_posts/technologies/maven/ubuntu18.04安装Mysql8.0.md","raw":"---\ntitle: Ubuntu18.04 安装 Mysql8.0\ntags: \ncategories:\n- technologies\n- maven\n---\n\n# Mysql 安装:\n\n### 1. 下载deb包\n\thttps://dev.mysql.com/downloads/repo/apt/\n\n### 2. 跟新dpkg\n\t$ dpkg -i mysql-apt-config_0.8.15-1_all.deb\n\t$ apt update\n\n### 3. 安装mysql8\n\t$ apt install mysql-server\n\t输入密码123456\n\t最后加密方式选择Legacy(5.x)\n\n# Mysql 卸载:\n\n```\n搜索的一种卸载方式:\n首先在终端中查看MySQL的依赖项：dpkg --list|grep mysql\n卸载： sudo apt-get remove mysql-common\n卸载：sudo apt-get autoremove --purge mysql-server-5.7\n清除残留数据：dpkg -l|grep ^rc|awk ‘{print$2}’|sudo xargs dpkg -P\n再次查看MySQL的剩余依赖项：dpkg --list|grep mysql\n继续删除剩余依赖项，如：sudo apt-get autoremove --purge mysql-apt-config\n至此已经没有了MySQL的依赖项，彻底删除，Good Luck\n\n另外一种卸载方式:\nsudo apt-get autoremove --purge mysql-server \nsudo apt-get remove mysql-common\nsudo rm -rf /etc/mysql/ \nsudo rm -rf  /var/lib/mysql\n​​#清理残留数据\ndpkg -l |grep ^rc|awk '{print $2}' |sudo xargs dpkg -P  \nsudo apt autoremove\nsudo apt autoclean\n\n最终是用dpkg --list|grep mysql命令查看没有任何mysql信息输出即可\n```\n\n# Mysql登录\n\n### 第一种命令行方式:\n```\n $ mysql -uroot -p123456\n```\n### 第二种mysql-workbench\n * $ apt update\n * $ apt install mysql-workbench\n * $ mysql-workbench\t\t// 可以通过键入 mysql-workbench或单击 MySQL Workbench 图标 (Activities -> MySQL Workbench) 从命令行启动它。\n\n### 第三种Navigat 工具方式：\n - Navicat是可以管理多种数据库Mysql, redis, MongoDB等等的软件，收费\n * 连接名:localhost\n * 主机: 127.0.0.1\t\t// 用localhost 会报错 2002 - Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock'(2 \"No such file or directory\")\n * 端口: 3306\t\t\t// mysql安装后默认服务端口是3306， 可通过命令 \"netstat -tap | grep mysql\" 查看\n * 用户名: root\n * 密码: 123456\n \n# 重启Mysql server\n * $ systemctl restart mysql\t// Ubuntu18.04重启mysql会出错, 目前没解决，只是卸载mysql重装，最好别重启mysql服务\n\n","slug":"technologies/maven/ubuntu18.04安装Mysql8.0","published":1,"date":"2020-08-12T16:05:48.593Z","updated":"2020-04-09T15:10:19.902Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmof0095hohx6hae5h92","content":"<h1 id=\"Mysql-安装\"><a href=\"#Mysql-安装\" class=\"headerlink\" title=\"Mysql 安装:\"></a>Mysql 安装:</h1><h3 id=\"1-下载deb包\"><a href=\"#1-下载deb包\" class=\"headerlink\" title=\"1. 下载deb包\"></a>1. 下载deb包</h3><pre><code>https://dev.mysql.com/downloads/repo/apt/</code></pre><h3 id=\"2-跟新dpkg\"><a href=\"#2-跟新dpkg\" class=\"headerlink\" title=\"2. 跟新dpkg\"></a>2. 跟新dpkg</h3><pre><code>$ dpkg -i mysql-apt-config_0.8.15-1_all.deb\n$ apt update</code></pre><h3 id=\"3-安装mysql8\"><a href=\"#3-安装mysql8\" class=\"headerlink\" title=\"3. 安装mysql8\"></a>3. 安装mysql8</h3><pre><code>$ apt install mysql-server\n输入密码123456\n最后加密方式选择Legacy(5.x)</code></pre><h1 id=\"Mysql-卸载\"><a href=\"#Mysql-卸载\" class=\"headerlink\" title=\"Mysql 卸载:\"></a>Mysql 卸载:</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">搜索的一种卸载方式:</span><br><span class=\"line\">首先在终端中查看MySQL的依赖项：dpkg --list|grep mysql</span><br><span class=\"line\">卸载： sudo apt-get remove mysql-common</span><br><span class=\"line\">卸载：sudo apt-get autoremove --purge mysql-server-5.7</span><br><span class=\"line\">清除残留数据：dpkg -l|grep ^rc|awk ‘&#123;print$2&#125;’|sudo xargs dpkg -P</span><br><span class=\"line\">再次查看MySQL的剩余依赖项：dpkg --list|grep mysql</span><br><span class=\"line\">继续删除剩余依赖项，如：sudo apt-get autoremove --purge mysql-apt-config</span><br><span class=\"line\">至此已经没有了MySQL的依赖项，彻底删除，Good Luck</span><br><span class=\"line\"></span><br><span class=\"line\">另外一种卸载方式:</span><br><span class=\"line\">sudo apt-get autoremove --purge mysql-server </span><br><span class=\"line\">sudo apt-get remove mysql-common</span><br><span class=\"line\">sudo rm -rf &#x2F;etc&#x2F;mysql&#x2F; </span><br><span class=\"line\">sudo rm -rf  &#x2F;var&#x2F;lib&#x2F;mysql</span><br><span class=\"line\">​​#清理残留数据</span><br><span class=\"line\">dpkg -l |grep ^rc|awk &#39;&#123;print $2&#125;&#39; |sudo xargs dpkg -P  </span><br><span class=\"line\">sudo apt autoremove</span><br><span class=\"line\">sudo apt autoclean</span><br><span class=\"line\"></span><br><span class=\"line\">最终是用dpkg --list|grep mysql命令查看没有任何mysql信息输出即可</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"Mysql登录\"><a href=\"#Mysql登录\" class=\"headerlink\" title=\"Mysql登录\"></a>Mysql登录</h1><h3 id=\"第一种命令行方式\"><a href=\"#第一种命令行方式\" class=\"headerlink\" title=\"第一种命令行方式:\"></a>第一种命令行方式:</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ mysql -uroot -p123456</span><br></pre></td></tr></table></figure>\n<h3 id=\"第二种mysql-workbench\"><a href=\"#第二种mysql-workbench\" class=\"headerlink\" title=\"第二种mysql-workbench\"></a>第二种mysql-workbench</h3><ul>\n<li>$ apt update</li>\n<li>$ apt install mysql-workbench</li>\n<li>$ mysql-workbench        // 可以通过键入 mysql-workbench或单击 MySQL Workbench 图标 (Activities -&gt; MySQL Workbench) 从命令行启动它。</li>\n</ul>\n<h3 id=\"第三种Navigat-工具方式：\"><a href=\"#第三种Navigat-工具方式：\" class=\"headerlink\" title=\"第三种Navigat 工具方式：\"></a>第三种Navigat 工具方式：</h3><ul>\n<li>Navicat是可以管理多种数据库Mysql, redis, MongoDB等等的软件，收费</li>\n</ul>\n<ul>\n<li>连接名:localhost</li>\n<li>主机: 127.0.0.1        // 用localhost 会报错 2002 - Can’t connect to local MySQL server through socket ‘/var/lib/mysql/mysql.sock’(2 “No such file or directory”)</li>\n<li>端口: 3306            // mysql安装后默认服务端口是3306， 可通过命令 “netstat -tap | grep mysql” 查看</li>\n<li>用户名: root</li>\n<li>密码: 123456</li>\n</ul>\n<h1 id=\"重启Mysql-server\"><a href=\"#重启Mysql-server\" class=\"headerlink\" title=\"重启Mysql server\"></a>重启Mysql server</h1><ul>\n<li>$ systemctl restart mysql    // Ubuntu18.04重启mysql会出错, 目前没解决，只是卸载mysql重装，最好别重启mysql服务</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Mysql-安装\"><a href=\"#Mysql-安装\" class=\"headerlink\" title=\"Mysql 安装:\"></a>Mysql 安装:</h1><h3 id=\"1-下载deb包\"><a href=\"#1-下载deb包\" class=\"headerlink\" title=\"1. 下载deb包\"></a>1. 下载deb包</h3><pre><code>https://dev.mysql.com/downloads/repo/apt/</code></pre><h3 id=\"2-跟新dpkg\"><a href=\"#2-跟新dpkg\" class=\"headerlink\" title=\"2. 跟新dpkg\"></a>2. 跟新dpkg</h3><pre><code>$ dpkg -i mysql-apt-config_0.8.15-1_all.deb\n$ apt update</code></pre><h3 id=\"3-安装mysql8\"><a href=\"#3-安装mysql8\" class=\"headerlink\" title=\"3. 安装mysql8\"></a>3. 安装mysql8</h3><pre><code>$ apt install mysql-server\n输入密码123456\n最后加密方式选择Legacy(5.x)</code></pre><h1 id=\"Mysql-卸载\"><a href=\"#Mysql-卸载\" class=\"headerlink\" title=\"Mysql 卸载:\"></a>Mysql 卸载:</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">搜索的一种卸载方式:</span><br><span class=\"line\">首先在终端中查看MySQL的依赖项：dpkg --list|grep mysql</span><br><span class=\"line\">卸载： sudo apt-get remove mysql-common</span><br><span class=\"line\">卸载：sudo apt-get autoremove --purge mysql-server-5.7</span><br><span class=\"line\">清除残留数据：dpkg -l|grep ^rc|awk ‘&#123;print$2&#125;’|sudo xargs dpkg -P</span><br><span class=\"line\">再次查看MySQL的剩余依赖项：dpkg --list|grep mysql</span><br><span class=\"line\">继续删除剩余依赖项，如：sudo apt-get autoremove --purge mysql-apt-config</span><br><span class=\"line\">至此已经没有了MySQL的依赖项，彻底删除，Good Luck</span><br><span class=\"line\"></span><br><span class=\"line\">另外一种卸载方式:</span><br><span class=\"line\">sudo apt-get autoremove --purge mysql-server </span><br><span class=\"line\">sudo apt-get remove mysql-common</span><br><span class=\"line\">sudo rm -rf &#x2F;etc&#x2F;mysql&#x2F; </span><br><span class=\"line\">sudo rm -rf  &#x2F;var&#x2F;lib&#x2F;mysql</span><br><span class=\"line\">​​#清理残留数据</span><br><span class=\"line\">dpkg -l |grep ^rc|awk &#39;&#123;print $2&#125;&#39; |sudo xargs dpkg -P  </span><br><span class=\"line\">sudo apt autoremove</span><br><span class=\"line\">sudo apt autoclean</span><br><span class=\"line\"></span><br><span class=\"line\">最终是用dpkg --list|grep mysql命令查看没有任何mysql信息输出即可</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"Mysql登录\"><a href=\"#Mysql登录\" class=\"headerlink\" title=\"Mysql登录\"></a>Mysql登录</h1><h3 id=\"第一种命令行方式\"><a href=\"#第一种命令行方式\" class=\"headerlink\" title=\"第一种命令行方式:\"></a>第一种命令行方式:</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ mysql -uroot -p123456</span><br></pre></td></tr></table></figure>\n<h3 id=\"第二种mysql-workbench\"><a href=\"#第二种mysql-workbench\" class=\"headerlink\" title=\"第二种mysql-workbench\"></a>第二种mysql-workbench</h3><ul>\n<li>$ apt update</li>\n<li>$ apt install mysql-workbench</li>\n<li>$ mysql-workbench        // 可以通过键入 mysql-workbench或单击 MySQL Workbench 图标 (Activities -&gt; MySQL Workbench) 从命令行启动它。</li>\n</ul>\n<h3 id=\"第三种Navigat-工具方式：\"><a href=\"#第三种Navigat-工具方式：\" class=\"headerlink\" title=\"第三种Navigat 工具方式：\"></a>第三种Navigat 工具方式：</h3><ul>\n<li>Navicat是可以管理多种数据库Mysql, redis, MongoDB等等的软件，收费</li>\n</ul>\n<ul>\n<li>连接名:localhost</li>\n<li>主机: 127.0.0.1        // 用localhost 会报错 2002 - Can’t connect to local MySQL server through socket ‘/var/lib/mysql/mysql.sock’(2 “No such file or directory”)</li>\n<li>端口: 3306            // mysql安装后默认服务端口是3306， 可通过命令 “netstat -tap | grep mysql” 查看</li>\n<li>用户名: root</li>\n<li>密码: 123456</li>\n</ul>\n<h1 id=\"重启Mysql-server\"><a href=\"#重启Mysql-server\" class=\"headerlink\" title=\"重启Mysql server\"></a>重启Mysql server</h1><ul>\n<li>$ systemctl restart mysql    // Ubuntu18.04重启mysql会出错, 目前没解决，只是卸载mysql重装，最好别重启mysql服务</li>\n</ul>\n"},{"title":"PKI 体系概述","_content":"\nReference: [简述 PKI体系概述](https://www.jianshu.com/p/46a911bd49a7)\n\n# **Public Key Infrastructure(PKI)**\nCA 中心管理并运营 CA 系统，CA 系统负责颁发数字证书。  \n专门负责颁发数字证书的系统称为 CA 系统，负责管理并运营 CA 系统的机构称为 CA 中心。所有与数字证书相关的各种概念和技术，统称为 **PKI（Public Key Infrastructure）**  \n\n# **加密基元**\n加密基元就是一些基础的密码学算法，通过它们才能够构建更多的密码学算法、协议、应用程序。\n![](base_encryption.png)\n说明：\n * 散列函数（散列（hash）、指纹、消息摘要、摘要算法、杂凑函数）：把任意长度的输入消息数据转化成固定长度的输出数据的一种密码算法。\n * 消息验证代码：验证数据完整性，即数据没有被篡改。\n * 数字签名：RSA私钥加密，公钥解密，结合散列函数。验证消息真实性。\n * 伪随机函数（PRF）：生成任意数量的伪随机数据。\n * RSA：可以同时用于密钥交换和身份验证（数字签名）。\n * DHE_RSA：DHE 算法：密钥协商，RSA 算法：身份验证（数字签名）。\n * ECDHE_RSA： ECDHE 算法：密钥协商，RSA 算法：身份验证（数字签名）。\n * ECDHE_ECDSA ：ECDHE 算法：密钥协商，ECDSA 算法：身份验证（数字签名）。\n\n# **密钥管理**\n![](key_save.png)\n密钥管理模式：\n * 无中心模式；\n * 有中心模式；\n\n# **PKI 模式**\nPKI 是 Public Key Infrastructure 的缩写，其主要功能是绑定证书持有者的身份和相关的密钥对（通过为公钥及相关的用户身份信息签发数字证书），为用户提供方便的证书申请、证书作废、证书获取、证书状态查询的途径，并利用数字证书及相关的各种服务（证书发布，黑名单发布，时间戳服务等）实现通信中各实体的身份认证、完整性、抗抵赖性和保密性。  \n![](pki_mode.png)\n * 数字证书：解决公钥与用户映射关系问题；\n * CA：解决数字证书签发问题；\n * KMC：解决私钥的备份与恢复问题；\n * 双证书机制：「签名证书及私钥」只用于签名验签，「加密证书及私钥」只用于加密解密。\n * LDAP：解决数字证书查询和下载的性能问题，避免 CA 中心成为性能瓶颈。\n * CRL（证书作废列表） 和 OSCP（在线证书状态协议）：方便用户快速获得证书状态。\n * RA：方便证书业务远程办理、方便证书管理流程与应用系统结合。\n * 电子认证服务机构：保证 CA 系统在数字证书管理方面的规范性、合规性和安全性。\n\n## 基于数字证书可以实现四种基本安全功能:\n 1. 身份认证；\n 2. 保密性；\n 3. 完整性；\n 4. 抗抵赖性；\n\n# **PKI 基本系统组件**\n完整的 PKI 系统必须具有数字证书、认证中心（CA）、证书资料库、证书吊销系统、密钥备份及恢复系统、PKI 应用接口系统等构成部分。  \n**组件描述:**\n * **数字证书:** 包含了用于签名和加密数据的公钥的电子凭证，是PKI的核心元素\n * **认证中心（CA）:** 数字证书的申请及签发机关，CA必须具备权威性\n * **证书资料库:** 存储已签发的数字证书和公钥，以及相关证书目录，用户可由此获得所需的其他用户的证书及公钥\n * **证书吊销列表（CRL）/OCSP:** 在有效期内吊销的证书列表，在线证书状态协议OCSP是获得证书状态的国际协议\n * **密钥备份及恢复:** 为避免因用户丢失解密密钥而无法解密合法数据的情况，PKI提供备份与恢复密钥的机制。必须由可信的机构来完成。并且，密钥备份与恢复只能针对解密密钥，签名私钥不能够作备份\n * **PKI应用接口（API）:** 为各种各样的应用提供安全、一致、 可信的方式与PKI交互，确保建立起来的网络环境安全可靠，并降低管理成本\n\n# **TLS**\n![](tls_deployment.jpg)\n**密码套件**决定了本次连接采用哪一种加密算法、密钥协商算法、HMAC 算法，即各个密码学算法的组合。\n\n","source":"_posts/technologies/security/pki.md","raw":"---\ntitle: PKI 体系概述\ntags: security\ncategories:\n- technologies\n- security\n---\n\nReference: [简述 PKI体系概述](https://www.jianshu.com/p/46a911bd49a7)\n\n# **Public Key Infrastructure(PKI)**\nCA 中心管理并运营 CA 系统，CA 系统负责颁发数字证书。  \n专门负责颁发数字证书的系统称为 CA 系统，负责管理并运营 CA 系统的机构称为 CA 中心。所有与数字证书相关的各种概念和技术，统称为 **PKI（Public Key Infrastructure）**  \n\n# **加密基元**\n加密基元就是一些基础的密码学算法，通过它们才能够构建更多的密码学算法、协议、应用程序。\n![](base_encryption.png)\n说明：\n * 散列函数（散列（hash）、指纹、消息摘要、摘要算法、杂凑函数）：把任意长度的输入消息数据转化成固定长度的输出数据的一种密码算法。\n * 消息验证代码：验证数据完整性，即数据没有被篡改。\n * 数字签名：RSA私钥加密，公钥解密，结合散列函数。验证消息真实性。\n * 伪随机函数（PRF）：生成任意数量的伪随机数据。\n * RSA：可以同时用于密钥交换和身份验证（数字签名）。\n * DHE_RSA：DHE 算法：密钥协商，RSA 算法：身份验证（数字签名）。\n * ECDHE_RSA： ECDHE 算法：密钥协商，RSA 算法：身份验证（数字签名）。\n * ECDHE_ECDSA ：ECDHE 算法：密钥协商，ECDSA 算法：身份验证（数字签名）。\n\n# **密钥管理**\n![](key_save.png)\n密钥管理模式：\n * 无中心模式；\n * 有中心模式；\n\n# **PKI 模式**\nPKI 是 Public Key Infrastructure 的缩写，其主要功能是绑定证书持有者的身份和相关的密钥对（通过为公钥及相关的用户身份信息签发数字证书），为用户提供方便的证书申请、证书作废、证书获取、证书状态查询的途径，并利用数字证书及相关的各种服务（证书发布，黑名单发布，时间戳服务等）实现通信中各实体的身份认证、完整性、抗抵赖性和保密性。  \n![](pki_mode.png)\n * 数字证书：解决公钥与用户映射关系问题；\n * CA：解决数字证书签发问题；\n * KMC：解决私钥的备份与恢复问题；\n * 双证书机制：「签名证书及私钥」只用于签名验签，「加密证书及私钥」只用于加密解密。\n * LDAP：解决数字证书查询和下载的性能问题，避免 CA 中心成为性能瓶颈。\n * CRL（证书作废列表） 和 OSCP（在线证书状态协议）：方便用户快速获得证书状态。\n * RA：方便证书业务远程办理、方便证书管理流程与应用系统结合。\n * 电子认证服务机构：保证 CA 系统在数字证书管理方面的规范性、合规性和安全性。\n\n## 基于数字证书可以实现四种基本安全功能:\n 1. 身份认证；\n 2. 保密性；\n 3. 完整性；\n 4. 抗抵赖性；\n\n# **PKI 基本系统组件**\n完整的 PKI 系统必须具有数字证书、认证中心（CA）、证书资料库、证书吊销系统、密钥备份及恢复系统、PKI 应用接口系统等构成部分。  \n**组件描述:**\n * **数字证书:** 包含了用于签名和加密数据的公钥的电子凭证，是PKI的核心元素\n * **认证中心（CA）:** 数字证书的申请及签发机关，CA必须具备权威性\n * **证书资料库:** 存储已签发的数字证书和公钥，以及相关证书目录，用户可由此获得所需的其他用户的证书及公钥\n * **证书吊销列表（CRL）/OCSP:** 在有效期内吊销的证书列表，在线证书状态协议OCSP是获得证书状态的国际协议\n * **密钥备份及恢复:** 为避免因用户丢失解密密钥而无法解密合法数据的情况，PKI提供备份与恢复密钥的机制。必须由可信的机构来完成。并且，密钥备份与恢复只能针对解密密钥，签名私钥不能够作备份\n * **PKI应用接口（API）:** 为各种各样的应用提供安全、一致、 可信的方式与PKI交互，确保建立起来的网络环境安全可靠，并降低管理成本\n\n# **TLS**\n![](tls_deployment.jpg)\n**密码套件**决定了本次连接采用哪一种加密算法、密钥协商算法、HMAC 算法，即各个密码学算法的组合。\n\n","slug":"technologies/security/pki","published":1,"date":"2020-08-12T16:05:48.705Z","updated":"2020-08-10T16:34:00.552Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmog0097hohxck5b6kgy","content":"<p>Reference: <a href=\"https://www.jianshu.com/p/46a911bd49a7\" target=\"_blank\" rel=\"noopener\">简述 PKI体系概述</a></p>\n<h1 id=\"Public-Key-Infrastructure-PKI\"><a href=\"#Public-Key-Infrastructure-PKI\" class=\"headerlink\" title=\"Public Key Infrastructure(PKI)\"></a><strong>Public Key Infrastructure(PKI)</strong></h1><p>CA 中心管理并运营 CA 系统，CA 系统负责颁发数字证书。<br>专门负责颁发数字证书的系统称为 CA 系统，负责管理并运营 CA 系统的机构称为 CA 中心。所有与数字证书相关的各种概念和技术，统称为 <strong>PKI（Public Key Infrastructure）</strong>  </p>\n<h1 id=\"加密基元\"><a href=\"#加密基元\" class=\"headerlink\" title=\"加密基元\"></a><strong>加密基元</strong></h1><p>加密基元就是一些基础的密码学算法，通过它们才能够构建更多的密码学算法、协议、应用程序。<br><img src=\"base_encryption.png\" alt=\"\"><br>说明：</p>\n<ul>\n<li>散列函数（散列（hash）、指纹、消息摘要、摘要算法、杂凑函数）：把任意长度的输入消息数据转化成固定长度的输出数据的一种密码算法。</li>\n<li>消息验证代码：验证数据完整性，即数据没有被篡改。</li>\n<li>数字签名：RSA私钥加密，公钥解密，结合散列函数。验证消息真实性。</li>\n<li>伪随机函数（PRF）：生成任意数量的伪随机数据。</li>\n<li>RSA：可以同时用于密钥交换和身份验证（数字签名）。</li>\n<li>DHE_RSA：DHE 算法：密钥协商，RSA 算法：身份验证（数字签名）。</li>\n<li>ECDHE_RSA： ECDHE 算法：密钥协商，RSA 算法：身份验证（数字签名）。</li>\n<li>ECDHE_ECDSA ：ECDHE 算法：密钥协商，ECDSA 算法：身份验证（数字签名）。</li>\n</ul>\n<h1 id=\"密钥管理\"><a href=\"#密钥管理\" class=\"headerlink\" title=\"密钥管理\"></a><strong>密钥管理</strong></h1><p><img src=\"key_save.png\" alt=\"\"><br>密钥管理模式：</p>\n<ul>\n<li>无中心模式；</li>\n<li>有中心模式；</li>\n</ul>\n<h1 id=\"PKI-模式\"><a href=\"#PKI-模式\" class=\"headerlink\" title=\"PKI 模式\"></a><strong>PKI 模式</strong></h1><p>PKI 是 Public Key Infrastructure 的缩写，其主要功能是绑定证书持有者的身份和相关的密钥对（通过为公钥及相关的用户身份信息签发数字证书），为用户提供方便的证书申请、证书作废、证书获取、证书状态查询的途径，并利用数字证书及相关的各种服务（证书发布，黑名单发布，时间戳服务等）实现通信中各实体的身份认证、完整性、抗抵赖性和保密性。<br><img src=\"pki_mode.png\" alt=\"\"></p>\n<ul>\n<li>数字证书：解决公钥与用户映射关系问题；</li>\n<li>CA：解决数字证书签发问题；</li>\n<li>KMC：解决私钥的备份与恢复问题；</li>\n<li>双证书机制：「签名证书及私钥」只用于签名验签，「加密证书及私钥」只用于加密解密。</li>\n<li>LDAP：解决数字证书查询和下载的性能问题，避免 CA 中心成为性能瓶颈。</li>\n<li>CRL（证书作废列表） 和 OSCP（在线证书状态协议）：方便用户快速获得证书状态。</li>\n<li>RA：方便证书业务远程办理、方便证书管理流程与应用系统结合。</li>\n<li>电子认证服务机构：保证 CA 系统在数字证书管理方面的规范性、合规性和安全性。</li>\n</ul>\n<h2 id=\"基于数字证书可以实现四种基本安全功能\"><a href=\"#基于数字证书可以实现四种基本安全功能\" class=\"headerlink\" title=\"基于数字证书可以实现四种基本安全功能:\"></a>基于数字证书可以实现四种基本安全功能:</h2><ol>\n<li>身份认证；</li>\n<li>保密性；</li>\n<li>完整性；</li>\n<li>抗抵赖性；</li>\n</ol>\n<h1 id=\"PKI-基本系统组件\"><a href=\"#PKI-基本系统组件\" class=\"headerlink\" title=\"PKI 基本系统组件\"></a><strong>PKI 基本系统组件</strong></h1><p>完整的 PKI 系统必须具有数字证书、认证中心（CA）、证书资料库、证书吊销系统、密钥备份及恢复系统、PKI 应用接口系统等构成部分。<br><strong>组件描述:</strong></p>\n<ul>\n<li><strong>数字证书:</strong> 包含了用于签名和加密数据的公钥的电子凭证，是PKI的核心元素</li>\n<li><strong>认证中心（CA）:</strong> 数字证书的申请及签发机关，CA必须具备权威性</li>\n<li><strong>证书资料库:</strong> 存储已签发的数字证书和公钥，以及相关证书目录，用户可由此获得所需的其他用户的证书及公钥</li>\n<li><strong>证书吊销列表（CRL）/OCSP:</strong> 在有效期内吊销的证书列表，在线证书状态协议OCSP是获得证书状态的国际协议</li>\n<li><strong>密钥备份及恢复:</strong> 为避免因用户丢失解密密钥而无法解密合法数据的情况，PKI提供备份与恢复密钥的机制。必须由可信的机构来完成。并且，密钥备份与恢复只能针对解密密钥，签名私钥不能够作备份</li>\n<li><strong>PKI应用接口（API）:</strong> 为各种各样的应用提供安全、一致、 可信的方式与PKI交互，确保建立起来的网络环境安全可靠，并降低管理成本</li>\n</ul>\n<h1 id=\"TLS\"><a href=\"#TLS\" class=\"headerlink\" title=\"TLS\"></a><strong>TLS</strong></h1><p><img src=\"tls_deployment.jpg\" alt=\"\"><br><strong>密码套件</strong>决定了本次连接采用哪一种加密算法、密钥协商算法、HMAC 算法，即各个密码学算法的组合。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Reference: <a href=\"https://www.jianshu.com/p/46a911bd49a7\" target=\"_blank\" rel=\"noopener\">简述 PKI体系概述</a></p>\n<h1 id=\"Public-Key-Infrastructure-PKI\"><a href=\"#Public-Key-Infrastructure-PKI\" class=\"headerlink\" title=\"Public Key Infrastructure(PKI)\"></a><strong>Public Key Infrastructure(PKI)</strong></h1><p>CA 中心管理并运营 CA 系统，CA 系统负责颁发数字证书。<br>专门负责颁发数字证书的系统称为 CA 系统，负责管理并运营 CA 系统的机构称为 CA 中心。所有与数字证书相关的各种概念和技术，统称为 <strong>PKI（Public Key Infrastructure）</strong>  </p>\n<h1 id=\"加密基元\"><a href=\"#加密基元\" class=\"headerlink\" title=\"加密基元\"></a><strong>加密基元</strong></h1><p>加密基元就是一些基础的密码学算法，通过它们才能够构建更多的密码学算法、协议、应用程序。<br><img src=\"base_encryption.png\" alt=\"\"><br>说明：</p>\n<ul>\n<li>散列函数（散列（hash）、指纹、消息摘要、摘要算法、杂凑函数）：把任意长度的输入消息数据转化成固定长度的输出数据的一种密码算法。</li>\n<li>消息验证代码：验证数据完整性，即数据没有被篡改。</li>\n<li>数字签名：RSA私钥加密，公钥解密，结合散列函数。验证消息真实性。</li>\n<li>伪随机函数（PRF）：生成任意数量的伪随机数据。</li>\n<li>RSA：可以同时用于密钥交换和身份验证（数字签名）。</li>\n<li>DHE_RSA：DHE 算法：密钥协商，RSA 算法：身份验证（数字签名）。</li>\n<li>ECDHE_RSA： ECDHE 算法：密钥协商，RSA 算法：身份验证（数字签名）。</li>\n<li>ECDHE_ECDSA ：ECDHE 算法：密钥协商，ECDSA 算法：身份验证（数字签名）。</li>\n</ul>\n<h1 id=\"密钥管理\"><a href=\"#密钥管理\" class=\"headerlink\" title=\"密钥管理\"></a><strong>密钥管理</strong></h1><p><img src=\"key_save.png\" alt=\"\"><br>密钥管理模式：</p>\n<ul>\n<li>无中心模式；</li>\n<li>有中心模式；</li>\n</ul>\n<h1 id=\"PKI-模式\"><a href=\"#PKI-模式\" class=\"headerlink\" title=\"PKI 模式\"></a><strong>PKI 模式</strong></h1><p>PKI 是 Public Key Infrastructure 的缩写，其主要功能是绑定证书持有者的身份和相关的密钥对（通过为公钥及相关的用户身份信息签发数字证书），为用户提供方便的证书申请、证书作废、证书获取、证书状态查询的途径，并利用数字证书及相关的各种服务（证书发布，黑名单发布，时间戳服务等）实现通信中各实体的身份认证、完整性、抗抵赖性和保密性。<br><img src=\"pki_mode.png\" alt=\"\"></p>\n<ul>\n<li>数字证书：解决公钥与用户映射关系问题；</li>\n<li>CA：解决数字证书签发问题；</li>\n<li>KMC：解决私钥的备份与恢复问题；</li>\n<li>双证书机制：「签名证书及私钥」只用于签名验签，「加密证书及私钥」只用于加密解密。</li>\n<li>LDAP：解决数字证书查询和下载的性能问题，避免 CA 中心成为性能瓶颈。</li>\n<li>CRL（证书作废列表） 和 OSCP（在线证书状态协议）：方便用户快速获得证书状态。</li>\n<li>RA：方便证书业务远程办理、方便证书管理流程与应用系统结合。</li>\n<li>电子认证服务机构：保证 CA 系统在数字证书管理方面的规范性、合规性和安全性。</li>\n</ul>\n<h2 id=\"基于数字证书可以实现四种基本安全功能\"><a href=\"#基于数字证书可以实现四种基本安全功能\" class=\"headerlink\" title=\"基于数字证书可以实现四种基本安全功能:\"></a>基于数字证书可以实现四种基本安全功能:</h2><ol>\n<li>身份认证；</li>\n<li>保密性；</li>\n<li>完整性；</li>\n<li>抗抵赖性；</li>\n</ol>\n<h1 id=\"PKI-基本系统组件\"><a href=\"#PKI-基本系统组件\" class=\"headerlink\" title=\"PKI 基本系统组件\"></a><strong>PKI 基本系统组件</strong></h1><p>完整的 PKI 系统必须具有数字证书、认证中心（CA）、证书资料库、证书吊销系统、密钥备份及恢复系统、PKI 应用接口系统等构成部分。<br><strong>组件描述:</strong></p>\n<ul>\n<li><strong>数字证书:</strong> 包含了用于签名和加密数据的公钥的电子凭证，是PKI的核心元素</li>\n<li><strong>认证中心（CA）:</strong> 数字证书的申请及签发机关，CA必须具备权威性</li>\n<li><strong>证书资料库:</strong> 存储已签发的数字证书和公钥，以及相关证书目录，用户可由此获得所需的其他用户的证书及公钥</li>\n<li><strong>证书吊销列表（CRL）/OCSP:</strong> 在有效期内吊销的证书列表，在线证书状态协议OCSP是获得证书状态的国际协议</li>\n<li><strong>密钥备份及恢复:</strong> 为避免因用户丢失解密密钥而无法解密合法数据的情况，PKI提供备份与恢复密钥的机制。必须由可信的机构来完成。并且，密钥备份与恢复只能针对解密密钥，签名私钥不能够作备份</li>\n<li><strong>PKI应用接口（API）:</strong> 为各种各样的应用提供安全、一致、 可信的方式与PKI交互，确保建立起来的网络环境安全可靠，并降低管理成本</li>\n</ul>\n<h1 id=\"TLS\"><a href=\"#TLS\" class=\"headerlink\" title=\"TLS\"></a><strong>TLS</strong></h1><p><img src=\"tls_deployment.jpg\" alt=\"\"><br><strong>密码套件</strong>决定了本次连接采用哪一种加密算法、密钥协商算法、HMAC 算法，即各个密码学算法的组合。</p>\n"},{"title":"openssl certificates","_content":"\n# **X.509证书标准定义的两种编码格式PEM和DER**\n\n## **PEM编码（Privacy Enhanced Mail）**\n特点：纯文本文件, 以-----BEGIN CERTIFICATE-----开头, 以-----END CERTIFICATE-----结尾,  \n内容是 base64 编码. 但使用文本编辑器只能查看表面的结构, 需要输入命令例如  \n\n\t$ openssl x509 -in 某个PEM格式数字证书.pem -text -noout\n才能看到原始的数字证书信息.  \n\n\t-----BEGIN CERTIFICATE-----\n\tMIID7TCCAtWgAwIBAgIJAOIRDhOcxsx6MA0GCSqGSIb3DQEBCwUAMIGLMQswCQYD\n\t……\n\txAJz+w8tjrDWcf826VN14IL+/Cmqlg/rIfB5CHdwVIfWwpuGB66q/UiPegZMNs8a\n\t3g==\n\t-----END CERTIFICATE-----\n## **DER编码（Distinguished Encoding Rules）**\n特点：二进制文件格式, 一般应使用 Windows/Java 开发工具打开, 也可以使用openssl命令行工具提取其中信息或进行编码转换.  \n\n\t$ openssl x509 -in 某个DER格式的数字证书.der -inform der -text -noout  \n上面这个命令查看二进制文件中的证书信息.  \n\n## **文件扩展名**\n<table><tr><td bgcolor=#54FF9F><font face=\"fantasy\" size=4>我们身边有很多常见的数字证书文件, 他们的扩展名通常既不叫\".pem\"也不叫\".der\", 但无论扩展名是什么, 其内部编码格式只能从PEM和DER这两种编码格式中选择一种.</font></td></tr></table>  \n不同平台所偏好的编码格式不同, 不同类型的数字证书文件中存储的内容也略有差别, 不过对于大部分证书文件, 我们都可以借助命令行工具随时将其转换成另一种编码格式.  \n\n * **CRT** - CRT应该是certificate的三个字母,其实还是证书的意思,常见于NIX系统,有可能是PEM编码,也有可能是DER编码,大多数应该是PEM编码,相信你已经知道怎么辨别. **证书内容包含: signer(如CA:kubernetes),个人信息,过期时间,公钥public key,加密算法(非对称加密算法RSA2048, 对称机密算法AES256等),签名算法(sign algorithm)等信息.**  \n * **KEY** - 通常用来存放一个公钥或者私钥,并非X.509证书,编码同样的,可能是PEM,也可能是DER.  \n查看KEY的办法:  \n\n\n\t$ openssl rsa -in mykey.key -text -noout\n如果是DER格式的话,同理应该这样了:\n\n\t$ openssl rsa -in mykey.key -text -noout -inform der\n\n\t$ cd /home/zhan/istio-1.6.0/samples/certs/\n\t$ openssl x509 -in root-cert.pem -text -noout\n\tSignature Algorithm: sha256WithRSAEncryption\n\t$ openssl x509 -in root-cert.pem -text -noout | grep Validity -A 2\n\tValidity\n\t        Not Before: Jan 24 19:15:51 2018 GMT\n\t        Not After : Dec 31 19:15:51 2117 GMT\n\t-A n这样的shell写法，输出当前行之后的n行内容\n\n\n * **CSR - Certificate Signing Request**,即证书签名请求,这个并不是证书,而是向权威证书颁发机构获得签名证书的申请,其核心内容是一个**公钥和个人信息**,在生成这个申请的时候, 要对应生成的有一个私钥,私钥要自己保管好, client端把包含public key的csr文件发给CA, 用CA的private key给csr文件做签名(sign)生成client端证书. **CSR文件**内容一般包含: **个人信息,公钥public key,加密算法(非对称加密算法RSA2048, 对称机密算法AES256等),签名算法(sign algorithm)等信息.**  \n查看的办法:\n\n\n\t$ openssl req -noout -text -in my.csr\n(如果是DER格式的话照旧命令行加上-inform der,这里不写了)\n\n\n## **证书编码的转换**\n\n • PEM转为DER：\n\n\n\t$ openssl x509 -in cert.crt -outform der -out cert.der\n • DER转为PEM：\n\n\n\t$ openssl x509 -in cert.crt -inform der -outform pem -out cert.pem\n## **获得证书的步骤**\n\n<table><tr><td bgcolor=#54FF9F> • 向权威证书颁发机构申请证书</td></tr></table>\n用以下命令生成一个csr:\n\n\n\t$ openssl req -newkey rsa:2048 -new -nodes -keyout my.key -out my.csr\n\t$ ls\n\tmy.csr  my.key\n把**csr**交给权威证书颁发机构,权威证书颁发机构对此进行签名,完成.保留好csr,**当权威证书颁发机构颁发的证书过期的时候,你还可以用同样的csr来申请新的证书,key保持不变.**\n\n<table><tr><td bgcolor=#54FF9F> • 或者生成自签名的证书</td></tr></table>\n\n\n\t$ openssl req -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout key.pem -out cert.pem\n\t$ ls\n\tcert.pem  key.pem\n在生成证书的过程中会要你填一堆的东西,其实真正要填的只有Common Name,通常填写你服务器的域名,如\"yourcompany.com\",或者你服务器的IP地址,其它都可以留空的.\n生产环境中还是不要使用自签的证书,否则浏览器会不认,或者如果你是企业应用的话能够强制让用户的浏览器接受你的自签证书也行.向权威机构要证书通常是要钱的,但现在也有免费的,仅仅需要一个简单的域名验证即可.有兴趣的话查查\"沃通数字证书\".\n\n## **生成证书**\n\n### **一：生成CA证书**\n目前不使用第三方权威机构的CA来认证，自己充当CA的角色。\n网上下载一个openssl软件\n1.创建私钥：\n通常是rsa算法  \n<table><tr><td bgcolor=#54FF9F>**ca-key.pem**</td></tr></table>\n\n\t$ openssl genrsa -out ca/ca-key.pem 2048\n\t查看key\n\t$ openssl rsa -in ca/ca-key.pem -text -noout\n\t如果是DER格式的话,同理应该这样\n\t$ openssl rsa -in ca/ca-key.pem -text -noout -inform der\n\n2.创建证书请求：  \n> 因此在用户向CA申请数字证书时，用户首先需要在自己的电脑中先产生一个公私钥对。用户需要保管好自己的私钥，然后再把公钥和你的个人信息发送给CA机构，CA机构通过你的公钥和个人信息最终签发出数字证书。  \n> 而CSR文件，其实就是包含了用户公钥和个人信息的一个数据文件。用户产生出这个CSR文件，再把这个CSR文件发送给CA，CA就会根据CSR中的内容来签发出数字证书。  \n\n在制作csr文件的时，必须使用自己的私钥来签署申，还可以设定一个密钥.\n<table><tr><td bgcolor=#54FF9F>**ca-req.csr**</td></tr></table>\n\n\t$ openssl req -new -out ca/ca-req.csr -key ca/ca-key.pem\n\t  Country Name (2 letter code) [AU]:cn\n\t  State or Province Name (full name) [Some-State]:zhejiang\n\t  Locality Name (eg, city) []:hangzhou\n\t  Organization Name (eg, company) [Internet Widgits Pty Ltd]:skyvision\n\t  Organizational Unit Name (eg, section) []:test\n\t  Common Name (eg, YOUR name) []:root\n\t  Email Address []:sky\n\n3.自签署证书 ：\n<table><tr><td bgcolor=#54FF9F>**ca/ca-cert.pem**</td></tr></table>\n\n\t$ openssl x509 -req -in ca/ca-req.csr -out ca/ca-cert.pem -signkey ca/ca-key.pem -days 3650\n\t查看证书格式:\n\t$ openssl x509 -in ca/ca-cert.pem -text -noout\n\n4.将证书导出成浏览器支持的.p12格式 ：\n\n\t$ openssl pkcs12 -export -clcerts -in ca/ca-cert.pem -inkey ca/ca-key.pem -out ca/ca.p12\n密码：changeit\n\n### **二.生成server证书。**\n1.创建私钥 ：\n<table><tr><td bgcolor=#54FF9F>**server/server-key.pem**</td></tr></table>\n\n\t$ openssl genrsa -out server/server-key.pem 2048\n\t查看key\n\t$ openssl rsa -in server/server-key.pem -text -noout\n\t如果是DER格式的话,同理应该这样\n\t$ openssl rsa -in server/server-key.pem -text -noout -inform der\n\n2.创建证书请求 ：\n<table><tr><td bgcolor=#54FF9F>**server/server-req.csr**</td></tr></table>\n\n\t$ openssl req -new -out server/server-req.csr -key server/server-key.pem\n\t  Country Name (2 letter code) [AU]:cn\n\t  State or Province Name (full name) [Some-State]:zhejiang\n\t  Locality Name (eg, city) []:hangzhou\n\t  Organization Name (eg, company) [Internet Widgits Pty Ltd]:skyvision\n\t  Organizational Unit Name (eg, section) []:test\n\t  Common Name (eg, YOUR name) []:192.168.1.246 注释：一定要写服务器所在的ip地址\n\t  Email Address []:sky\n\t查看csr文件内容:\n\t$ $ openssl req -in server-req.csr -text -noout // -noout 不用输出csr文件原始内容\n\tCertificate Request:\n\t    Data:\n\t        Version: 0 (0x0)\n\t        Subject: C=XX, L=Default City, O=Default Company Ltd, CN=10.239.140.186\n\t        Subject Public Key Info:\n\t            Public Key Algorithm: rsaEncryption\n\t                Public-Key: (2048 bit)\n\t                Modulus:\n\t                    00:e2:0c:a7:33:33:d9:9b:90:1b:29:30:3c:81:31:\n\t                    09:97:0a:a9:76:d5:54:be:63:17:21:0c:b9:3a:f0:\n\t                    a6:02:37:1a:d4:1e:53:4e:e0:c8:d9:5f:27:57:7f:\n\t                    f3:eb:7f:9d:ad:79:d6:e7:40:64:c8:bc:3d:f3:b4:\n\t                    16:d6:30:e9:16:04:b6:a0:0e:8f:75:e4:4b:d6:8e:\n\t                    0a:8e:75:d8:41:89:09:90:96:b0:8d:32:5f:b5:96:\n\t                    1d:65:d6:a6:b4:c7:eb:3d:3b:f9:62:36:69:7d:07:\n\t                    6d:05:89:ce:a6:a5:98:a0:b2:5f:ab:bc:25:ba:08:\n\t                    d8:86:0a:b9:c0:91:ca:f8:d3:bb:36:14:21:f9:c2:\n\t                    b5:53:43:a9:2c:03:39:9b:93:ef:1d:d9:20:ef:dd:\n\t                    ff:57:c6:b5:47:e8:bb:46:32:e3:1d:3b:2e:5b:15:\n\t                    11:80:72:f6:2e:f5:b2:cc:02:7f:b1:d6:e9:3d:8e:\n\t                    0e:66:f6:6d:45:0e:2f:8c:d5:c3:92:dc:a1:9a:d9:\n\t                    b0:33:82:30:69:0a:05:ee:08:1b:a6:81:f4:bb:31:\n\t                    0d:fa:26:37:eb:4f:c8:58:df:e5:be:cc:ac:9a:62:\n\t                    42:f1:af:8c:35:88:e4:f3:b4:76:8f:6c:13:1f:9a:\n\t                    61:e0:08:0f:f2:b1:d6:f3:61:b4:0a:5d:9a:61:5f:\n\t                    e1:0b\n\t                Exponent: 65537 (0x10001)\n\t        Attributes:\n\t            a0:00\n\t    Signature Algorithm: sha256WithRSAEncryption\n\t         5b:62:35:07:43:99:dc:af:7c:61:1e:76:4e:f8:ef:59:b2:27:\n\t         60:71:30:15:5d:f3:0b:b1:b4:53:29:ec:d1:7c:18:48:0a:b3:\n\t         fe:b7:6d:80:ef:dc:c6:24:04:3d:bd:c1:b8:61:49:f3:1e:fb:\n\t         22:0f:fb:06:99:ec:db:18:ac:34:ff:4b:15:f8:84:06:01:4d:\n\t         68:4f:0c:a2:a5:34:dc:1b:61:44:c7:ff:ef:5d:92:a1:09:3f:\n\t         11:27:1c:a7:30:8e:97:6a:08:03:99:e6:6a:8f:1d:d6:ea:e7:\n\t         cd:18:a7:eb:36:3d:e7:6b:5e:ef:72:85:ca:eb:89:97:02:cf:\n\t         fc:38:31:58:e1:66:85:d1:e7:49:e2:72:ef:b1:60:36:55:d7:\n\t         90:bd:8d:0e:d8:c6:8f:d2:bf:bf:43:85:36:04:2e:f1:ec:5f:\n\t         d8:1b:17:22:a4:6a:de:a7:b2:2b:00:30:27:e6:4b:32:4d:55:\n\t         70:b0:61:3d:3f:f2:9d:e7:24:f6:4c:1f:bf:63:6a:d9:16:ef:\n\t         cb:91:a3:a4:43:b5:1f:11:85:ad:0e:b1:57:39:f2:0a:56:ec:\n\t         52:90:b0:11:96:c6:28:e0:de:0c:eb:f2:b1:66:ce:04:48:7f:\n\t         11:90:09:1d:fd:ca:a7:25:66:32:a2:64:33:1a:5e:a9:85:50:\n\t         8a:2d:90:a5\n\n3.自签署证书 ：\n<table><tr><td bgcolor=#54FF9F>**server/server-cert.pem**</td></tr></table>\n\n\t$ openssl x509 -req -in server/server-req.csr -out server/server-cert.pem -signkey server/server-key.pem -CA ca/ca-cert.pem -CAkey ca/ca-key.pem -CAcreateserial -days 3650\n\t * -CA选项指明用于被签名的csr证书\n\t * -CAkey选项指明用于签名的密钥\n\t * -CAcreateserial指明文件不存在时自动生成\n\t查看证书格式:\n\t$ openssl x509 -in server/server-cert.pem -text -noout\n\t可以查看到证书里所包含的public key等相关信息:\n\tCertificate:\n\tData:\n\t    Version: 1 (0x0)\n\t    Serial Number:\n\t        cc:db:c0:f2:12:e8:09:27\n\tSignature Algorithm: sha256WithRSAEncryption\n\t    Issuer: C=XX, L=Default City, O=Default Company Ltd, CN=AI\t// 签发者(CA机构)\n\t    Validity\n\t        Not Before: Jul 16 07:01:18 2020 GMT\n\t        Not After : Jul 14 07:01:18 2030 GMT\n\t    Subject: C=XX, L=Default City, O=Default Company Ltd, CN=sky\n\t    Subject Public Key Info:\n\t        Public Key Algorithm: rsaEncryption\n\t            Public-Key: (2048 bit)\t\t\t// public key, 因此本地可以不需要再存储保留public key, 证书里已包含.\n\t            Modulus:\n\t                00:cd:d7:ed:e9:c6:5e:fa:bc:ef:1e:4e:92:52:99:\n\t                f0:34:96:67:7b:32:1b:f6:53:df:ca:7b:e5:72:6a:\n\t                29:e5:85:27:eb:71:00:c6:90:ac:c1:64:62:0d:2b:\n\t                b1:bc:b8:ee:e1:d4:54:b7:95:21:1e:de:56:c7:25:\n\t                4c:d4:2d:29:5f:48:19:8a:05:c4:33:d3:06:16:ec:\n\t                68:e2:81:07:cf:f9:d1:15:b2:68:3d:da:44:c3:d5:\n\t                ba:a3:0f:9e:34:34:71:53:4f:02:4b:eb:f8:de:fd:\n\t                94:3f:f4:ee:12:48:ea:b1:60:62:be:58:47:78:29:\n\t                59:5b:ae:57:53:23:31:aa:78:cc:6c:f0:f7:e9:76:\n\t                4a:b9:25:79:3f:9c:05:4e:f0:8e:87:32:df:87:72:\n\t                67:64:2e:9f:85:15:64:bf:ca:ce:33:71:ee:bb:1a:\n\t                d3:26:09:34:9b:65:b9:15:71:28:14:37:48:79:1b:\n\t                b1:99:a4:8c:cc:27:a1:a4:c4:28:8e:01:e5:08:db:\n\t                e6:45:6e:3d:d9:03:a9:cb:17:25:b7:c9:c9:4b:fb:\n\t                e5:93:d1:de:31:fe:a9:34:29:c3:29:a4:27:c2:eb:\n\t                66:99:c6:db:ba:52:07:30:97:d4:0a:1e:1b:5d:72:\n\t                f6:ff:19:92:22:c0:44:76:74:f7:a7:0d:c5:77:c8:\n\t                1c:55\n\t            Exponent: 65537 (0x10001)\n\tSignature Algorithm: sha256WithRSAEncryption\n\t     28:d1:d9:29:a5:40:f3:d3:d6:95:87:fd:2c:70:dc:0f:1c:86:\n\t     08:35:d0:a8:8e:d0:5d:78:28:ae:88:33:61:db:cd:b6:80:1c:\n\t     88:62:b8:ce:cf:87:14:15:bd:27:9a:3e:77:cb:a1:e0:11:0d:\n\t     89:ef:f2:e8:b2:2c:cf:96:26:bd:06:3a:7b:8f:4b:fa:b2:c3:\n\t     f9:14:3e:18:ef:57:b5:37:95:01:a0:0f:bf:6e:5c:c9:47:7b:\n\t     1a:ed:ca:7a:31:a1:89:e8:0d:4d:95:d2:61:e3:b8:48:e5:86:\n\t     19:91:3e:00:86:07:50:df:e2:57:29:69:61:c4:cc:55:8f:60:\n\t     de:20:c1:0d:7d:c7:98:52:f4:34:08:90:c5:90:34:ec:86:0f:\n\t     ad:9b:e7:1a:d4:7b:d9:dd:59:82:de:54:d3:87:8e:e7:82:ae:\n\t     22:70:cf:e7:d7:8c:f1:55:57:6d:41:e6:44:3c:83:b7:73:7e:\n\t     9a:d5:1d:af:72:e9:4e:88:d4:4f:9f:33:2f:dc:1b:50:10:8b:\n\t     db:cd:e4:0e:e6:96:cd:c6:27:c7:4b:c7:9f:05:74:32:35:7e:\n\t     99:78:36:30:ae:78:4b:c3:1a:6b:b8:db:62:23:b8:ab:22:11:\n\t     11:81:95:5d:46:f0:45:15:77:1f:6b:c0:bf:9d:a2:d2:b4:62:\n\t     c9:b5:2b:dd\n\t\n4.将证书导出成浏览器支持的.p12格式 ：\n\n\t$ openssl pkcs12 -export -clcerts -in server/server-cert.pem -inkey server/server-key.pem -out server/server.p12\n密码：changeit\n\nAdditional：\n因为server端的证书是由CA的private key签名(sign)server端的public key及其持有者的真实身份得到的, 因此server端证书里就包含server的public key.  \n就不需要用Openssl生成server端的public key. 用server端的**csr（certificate signing requests）**生成server证书即可. client端也一样.  \nclient端只需要用CA的public key(CA的public key所有人都能获取)解密server端存放在CA的证书文件就可以得到Server端的public key.  \n然后client端就可以用解密得到的server端的public key对server端用自身private key加密的信息附带的摘要A(digest)进行解密.  \nclient端将server端发过来的信息用Hash得到摘要B(digest)与解密得到的摘要A(digest)对比, 如果一直则说明信息没有被黑客篡改.  \n如果中间黑客把server端加密的摘要A(digest)修改了，则client用从CA的public key解密得到的server端的public key是解不开摘要A(digest)的, 说明摘要信息被黑客篡改, 内容不可靠.  \n\n如果要生成RSA公钥, command如下:\n\n\t$ openssl rsa -in server/server-key.pem -pubout -out server/server-public-key.pem\n\n### **三.生成client证书。**\n1.创建私钥 ：\n<table><tr><td bgcolor=#54FF9F>**client/client-key.pem**</td></tr></table>\n\n\t$ openssl genrsa -out client/client-key.pem 2048\n\t查看key\n\t$ openssl rsa -in client/client-key.pem -text -noout\n\t如果是DER格式的话,同理应该这样\n\t$ openssl rsa -in client/client-key.pem -text -noout -inform der\n\n2.创建证书请求 ：\n<table><tr><td bgcolor=#54FF9F>**client/client-req.csr**</td></tr></table>\n\n\t$ openssl req -new -out client/client-req.csr -key client/client-key.pem\n\t  Country Name (2 letter code) [AU]:cn\n\t  State or Province Name (full name) [Some-State]:zhejiang\n\t  Locality Name (eg, city) []:hangzhou\n\t  Organization Name (eg, company) [Internet Widgits Pty Ltd]:skyvision\n\t  Organizational Unit Name (eg, section) []:test\n\t  Common Name (eg, YOUR name) []:sky\n\t  Email Address []:sky 注释：就是登入中心的用户（本来用户名应该是Common Name，但是中山公安的不知道为什么使用的Email Address，其他版本没有测试）\n\t  Please enter the following ‘extra’ attributes\n\t  to be sent with your certificate request\n\t  A challenge password []:123456\n\t  An optional company name []:tsing\n\n3.自签署证书 ：\n<table><tr><td bgcolor=#54FF9F>**client/client-cert.pem**</td></tr></table>\n\n\t$ openssl x509 -req -in client/client-req.csr -out client/client-cert.pem -signkey client/client-key.pem -CA ca/ca-cert.pem -CAkey ca/ca-key.pem -CAcreateserial -days 3650\n\t * -CA选项指明用于被签名的csr证书\n\t * -CAkey选项指明用于签名的密钥\n\t * -CAcreateserial指明文件不存在时自动生成\n\t查看证书格式:\n\t$ openssl x509 -in client/client-cert.pem -text -noout\n\n4.将证书导出成浏览器支持的.p12格式 ：\n\n\t$ openssl pkcs12 -export -clcerts -in client/client-cert.pem -inkey client/client-key.pem -out client/client.p12\n密码：changeit\n\nAdditional. 生成RSA公钥:\n\n\t$ openssl rsa -in client/client-key.pem -pubout -out client/client-public-key.pem\n\n请一定严格根据里面的步骤来，待实验成功后，修改你自己想要修改的内容。我就是一开始没有安装该填写的来，结果生成的证书就无法配对成功。\n\n\n","source":"_posts/technologies/security/openssl_certificates.md","raw":"---\ntitle: openssl certificates\ntags: security\ncategories:\n- technologies\n- security\n---\n\n# **X.509证书标准定义的两种编码格式PEM和DER**\n\n## **PEM编码（Privacy Enhanced Mail）**\n特点：纯文本文件, 以-----BEGIN CERTIFICATE-----开头, 以-----END CERTIFICATE-----结尾,  \n内容是 base64 编码. 但使用文本编辑器只能查看表面的结构, 需要输入命令例如  \n\n\t$ openssl x509 -in 某个PEM格式数字证书.pem -text -noout\n才能看到原始的数字证书信息.  \n\n\t-----BEGIN CERTIFICATE-----\n\tMIID7TCCAtWgAwIBAgIJAOIRDhOcxsx6MA0GCSqGSIb3DQEBCwUAMIGLMQswCQYD\n\t……\n\txAJz+w8tjrDWcf826VN14IL+/Cmqlg/rIfB5CHdwVIfWwpuGB66q/UiPegZMNs8a\n\t3g==\n\t-----END CERTIFICATE-----\n## **DER编码（Distinguished Encoding Rules）**\n特点：二进制文件格式, 一般应使用 Windows/Java 开发工具打开, 也可以使用openssl命令行工具提取其中信息或进行编码转换.  \n\n\t$ openssl x509 -in 某个DER格式的数字证书.der -inform der -text -noout  \n上面这个命令查看二进制文件中的证书信息.  \n\n## **文件扩展名**\n<table><tr><td bgcolor=#54FF9F><font face=\"fantasy\" size=4>我们身边有很多常见的数字证书文件, 他们的扩展名通常既不叫\".pem\"也不叫\".der\", 但无论扩展名是什么, 其内部编码格式只能从PEM和DER这两种编码格式中选择一种.</font></td></tr></table>  \n不同平台所偏好的编码格式不同, 不同类型的数字证书文件中存储的内容也略有差别, 不过对于大部分证书文件, 我们都可以借助命令行工具随时将其转换成另一种编码格式.  \n\n * **CRT** - CRT应该是certificate的三个字母,其实还是证书的意思,常见于NIX系统,有可能是PEM编码,也有可能是DER编码,大多数应该是PEM编码,相信你已经知道怎么辨别. **证书内容包含: signer(如CA:kubernetes),个人信息,过期时间,公钥public key,加密算法(非对称加密算法RSA2048, 对称机密算法AES256等),签名算法(sign algorithm)等信息.**  \n * **KEY** - 通常用来存放一个公钥或者私钥,并非X.509证书,编码同样的,可能是PEM,也可能是DER.  \n查看KEY的办法:  \n\n\n\t$ openssl rsa -in mykey.key -text -noout\n如果是DER格式的话,同理应该这样了:\n\n\t$ openssl rsa -in mykey.key -text -noout -inform der\n\n\t$ cd /home/zhan/istio-1.6.0/samples/certs/\n\t$ openssl x509 -in root-cert.pem -text -noout\n\tSignature Algorithm: sha256WithRSAEncryption\n\t$ openssl x509 -in root-cert.pem -text -noout | grep Validity -A 2\n\tValidity\n\t        Not Before: Jan 24 19:15:51 2018 GMT\n\t        Not After : Dec 31 19:15:51 2117 GMT\n\t-A n这样的shell写法，输出当前行之后的n行内容\n\n\n * **CSR - Certificate Signing Request**,即证书签名请求,这个并不是证书,而是向权威证书颁发机构获得签名证书的申请,其核心内容是一个**公钥和个人信息**,在生成这个申请的时候, 要对应生成的有一个私钥,私钥要自己保管好, client端把包含public key的csr文件发给CA, 用CA的private key给csr文件做签名(sign)生成client端证书. **CSR文件**内容一般包含: **个人信息,公钥public key,加密算法(非对称加密算法RSA2048, 对称机密算法AES256等),签名算法(sign algorithm)等信息.**  \n查看的办法:\n\n\n\t$ openssl req -noout -text -in my.csr\n(如果是DER格式的话照旧命令行加上-inform der,这里不写了)\n\n\n## **证书编码的转换**\n\n • PEM转为DER：\n\n\n\t$ openssl x509 -in cert.crt -outform der -out cert.der\n • DER转为PEM：\n\n\n\t$ openssl x509 -in cert.crt -inform der -outform pem -out cert.pem\n## **获得证书的步骤**\n\n<table><tr><td bgcolor=#54FF9F> • 向权威证书颁发机构申请证书</td></tr></table>\n用以下命令生成一个csr:\n\n\n\t$ openssl req -newkey rsa:2048 -new -nodes -keyout my.key -out my.csr\n\t$ ls\n\tmy.csr  my.key\n把**csr**交给权威证书颁发机构,权威证书颁发机构对此进行签名,完成.保留好csr,**当权威证书颁发机构颁发的证书过期的时候,你还可以用同样的csr来申请新的证书,key保持不变.**\n\n<table><tr><td bgcolor=#54FF9F> • 或者生成自签名的证书</td></tr></table>\n\n\n\t$ openssl req -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout key.pem -out cert.pem\n\t$ ls\n\tcert.pem  key.pem\n在生成证书的过程中会要你填一堆的东西,其实真正要填的只有Common Name,通常填写你服务器的域名,如\"yourcompany.com\",或者你服务器的IP地址,其它都可以留空的.\n生产环境中还是不要使用自签的证书,否则浏览器会不认,或者如果你是企业应用的话能够强制让用户的浏览器接受你的自签证书也行.向权威机构要证书通常是要钱的,但现在也有免费的,仅仅需要一个简单的域名验证即可.有兴趣的话查查\"沃通数字证书\".\n\n## **生成证书**\n\n### **一：生成CA证书**\n目前不使用第三方权威机构的CA来认证，自己充当CA的角色。\n网上下载一个openssl软件\n1.创建私钥：\n通常是rsa算法  \n<table><tr><td bgcolor=#54FF9F>**ca-key.pem**</td></tr></table>\n\n\t$ openssl genrsa -out ca/ca-key.pem 2048\n\t查看key\n\t$ openssl rsa -in ca/ca-key.pem -text -noout\n\t如果是DER格式的话,同理应该这样\n\t$ openssl rsa -in ca/ca-key.pem -text -noout -inform der\n\n2.创建证书请求：  \n> 因此在用户向CA申请数字证书时，用户首先需要在自己的电脑中先产生一个公私钥对。用户需要保管好自己的私钥，然后再把公钥和你的个人信息发送给CA机构，CA机构通过你的公钥和个人信息最终签发出数字证书。  \n> 而CSR文件，其实就是包含了用户公钥和个人信息的一个数据文件。用户产生出这个CSR文件，再把这个CSR文件发送给CA，CA就会根据CSR中的内容来签发出数字证书。  \n\n在制作csr文件的时，必须使用自己的私钥来签署申，还可以设定一个密钥.\n<table><tr><td bgcolor=#54FF9F>**ca-req.csr**</td></tr></table>\n\n\t$ openssl req -new -out ca/ca-req.csr -key ca/ca-key.pem\n\t  Country Name (2 letter code) [AU]:cn\n\t  State or Province Name (full name) [Some-State]:zhejiang\n\t  Locality Name (eg, city) []:hangzhou\n\t  Organization Name (eg, company) [Internet Widgits Pty Ltd]:skyvision\n\t  Organizational Unit Name (eg, section) []:test\n\t  Common Name (eg, YOUR name) []:root\n\t  Email Address []:sky\n\n3.自签署证书 ：\n<table><tr><td bgcolor=#54FF9F>**ca/ca-cert.pem**</td></tr></table>\n\n\t$ openssl x509 -req -in ca/ca-req.csr -out ca/ca-cert.pem -signkey ca/ca-key.pem -days 3650\n\t查看证书格式:\n\t$ openssl x509 -in ca/ca-cert.pem -text -noout\n\n4.将证书导出成浏览器支持的.p12格式 ：\n\n\t$ openssl pkcs12 -export -clcerts -in ca/ca-cert.pem -inkey ca/ca-key.pem -out ca/ca.p12\n密码：changeit\n\n### **二.生成server证书。**\n1.创建私钥 ：\n<table><tr><td bgcolor=#54FF9F>**server/server-key.pem**</td></tr></table>\n\n\t$ openssl genrsa -out server/server-key.pem 2048\n\t查看key\n\t$ openssl rsa -in server/server-key.pem -text -noout\n\t如果是DER格式的话,同理应该这样\n\t$ openssl rsa -in server/server-key.pem -text -noout -inform der\n\n2.创建证书请求 ：\n<table><tr><td bgcolor=#54FF9F>**server/server-req.csr**</td></tr></table>\n\n\t$ openssl req -new -out server/server-req.csr -key server/server-key.pem\n\t  Country Name (2 letter code) [AU]:cn\n\t  State or Province Name (full name) [Some-State]:zhejiang\n\t  Locality Name (eg, city) []:hangzhou\n\t  Organization Name (eg, company) [Internet Widgits Pty Ltd]:skyvision\n\t  Organizational Unit Name (eg, section) []:test\n\t  Common Name (eg, YOUR name) []:192.168.1.246 注释：一定要写服务器所在的ip地址\n\t  Email Address []:sky\n\t查看csr文件内容:\n\t$ $ openssl req -in server-req.csr -text -noout // -noout 不用输出csr文件原始内容\n\tCertificate Request:\n\t    Data:\n\t        Version: 0 (0x0)\n\t        Subject: C=XX, L=Default City, O=Default Company Ltd, CN=10.239.140.186\n\t        Subject Public Key Info:\n\t            Public Key Algorithm: rsaEncryption\n\t                Public-Key: (2048 bit)\n\t                Modulus:\n\t                    00:e2:0c:a7:33:33:d9:9b:90:1b:29:30:3c:81:31:\n\t                    09:97:0a:a9:76:d5:54:be:63:17:21:0c:b9:3a:f0:\n\t                    a6:02:37:1a:d4:1e:53:4e:e0:c8:d9:5f:27:57:7f:\n\t                    f3:eb:7f:9d:ad:79:d6:e7:40:64:c8:bc:3d:f3:b4:\n\t                    16:d6:30:e9:16:04:b6:a0:0e:8f:75:e4:4b:d6:8e:\n\t                    0a:8e:75:d8:41:89:09:90:96:b0:8d:32:5f:b5:96:\n\t                    1d:65:d6:a6:b4:c7:eb:3d:3b:f9:62:36:69:7d:07:\n\t                    6d:05:89:ce:a6:a5:98:a0:b2:5f:ab:bc:25:ba:08:\n\t                    d8:86:0a:b9:c0:91:ca:f8:d3:bb:36:14:21:f9:c2:\n\t                    b5:53:43:a9:2c:03:39:9b:93:ef:1d:d9:20:ef:dd:\n\t                    ff:57:c6:b5:47:e8:bb:46:32:e3:1d:3b:2e:5b:15:\n\t                    11:80:72:f6:2e:f5:b2:cc:02:7f:b1:d6:e9:3d:8e:\n\t                    0e:66:f6:6d:45:0e:2f:8c:d5:c3:92:dc:a1:9a:d9:\n\t                    b0:33:82:30:69:0a:05:ee:08:1b:a6:81:f4:bb:31:\n\t                    0d:fa:26:37:eb:4f:c8:58:df:e5:be:cc:ac:9a:62:\n\t                    42:f1:af:8c:35:88:e4:f3:b4:76:8f:6c:13:1f:9a:\n\t                    61:e0:08:0f:f2:b1:d6:f3:61:b4:0a:5d:9a:61:5f:\n\t                    e1:0b\n\t                Exponent: 65537 (0x10001)\n\t        Attributes:\n\t            a0:00\n\t    Signature Algorithm: sha256WithRSAEncryption\n\t         5b:62:35:07:43:99:dc:af:7c:61:1e:76:4e:f8:ef:59:b2:27:\n\t         60:71:30:15:5d:f3:0b:b1:b4:53:29:ec:d1:7c:18:48:0a:b3:\n\t         fe:b7:6d:80:ef:dc:c6:24:04:3d:bd:c1:b8:61:49:f3:1e:fb:\n\t         22:0f:fb:06:99:ec:db:18:ac:34:ff:4b:15:f8:84:06:01:4d:\n\t         68:4f:0c:a2:a5:34:dc:1b:61:44:c7:ff:ef:5d:92:a1:09:3f:\n\t         11:27:1c:a7:30:8e:97:6a:08:03:99:e6:6a:8f:1d:d6:ea:e7:\n\t         cd:18:a7:eb:36:3d:e7:6b:5e:ef:72:85:ca:eb:89:97:02:cf:\n\t         fc:38:31:58:e1:66:85:d1:e7:49:e2:72:ef:b1:60:36:55:d7:\n\t         90:bd:8d:0e:d8:c6:8f:d2:bf:bf:43:85:36:04:2e:f1:ec:5f:\n\t         d8:1b:17:22:a4:6a:de:a7:b2:2b:00:30:27:e6:4b:32:4d:55:\n\t         70:b0:61:3d:3f:f2:9d:e7:24:f6:4c:1f:bf:63:6a:d9:16:ef:\n\t         cb:91:a3:a4:43:b5:1f:11:85:ad:0e:b1:57:39:f2:0a:56:ec:\n\t         52:90:b0:11:96:c6:28:e0:de:0c:eb:f2:b1:66:ce:04:48:7f:\n\t         11:90:09:1d:fd:ca:a7:25:66:32:a2:64:33:1a:5e:a9:85:50:\n\t         8a:2d:90:a5\n\n3.自签署证书 ：\n<table><tr><td bgcolor=#54FF9F>**server/server-cert.pem**</td></tr></table>\n\n\t$ openssl x509 -req -in server/server-req.csr -out server/server-cert.pem -signkey server/server-key.pem -CA ca/ca-cert.pem -CAkey ca/ca-key.pem -CAcreateserial -days 3650\n\t * -CA选项指明用于被签名的csr证书\n\t * -CAkey选项指明用于签名的密钥\n\t * -CAcreateserial指明文件不存在时自动生成\n\t查看证书格式:\n\t$ openssl x509 -in server/server-cert.pem -text -noout\n\t可以查看到证书里所包含的public key等相关信息:\n\tCertificate:\n\tData:\n\t    Version: 1 (0x0)\n\t    Serial Number:\n\t        cc:db:c0:f2:12:e8:09:27\n\tSignature Algorithm: sha256WithRSAEncryption\n\t    Issuer: C=XX, L=Default City, O=Default Company Ltd, CN=AI\t// 签发者(CA机构)\n\t    Validity\n\t        Not Before: Jul 16 07:01:18 2020 GMT\n\t        Not After : Jul 14 07:01:18 2030 GMT\n\t    Subject: C=XX, L=Default City, O=Default Company Ltd, CN=sky\n\t    Subject Public Key Info:\n\t        Public Key Algorithm: rsaEncryption\n\t            Public-Key: (2048 bit)\t\t\t// public key, 因此本地可以不需要再存储保留public key, 证书里已包含.\n\t            Modulus:\n\t                00:cd:d7:ed:e9:c6:5e:fa:bc:ef:1e:4e:92:52:99:\n\t                f0:34:96:67:7b:32:1b:f6:53:df:ca:7b:e5:72:6a:\n\t                29:e5:85:27:eb:71:00:c6:90:ac:c1:64:62:0d:2b:\n\t                b1:bc:b8:ee:e1:d4:54:b7:95:21:1e:de:56:c7:25:\n\t                4c:d4:2d:29:5f:48:19:8a:05:c4:33:d3:06:16:ec:\n\t                68:e2:81:07:cf:f9:d1:15:b2:68:3d:da:44:c3:d5:\n\t                ba:a3:0f:9e:34:34:71:53:4f:02:4b:eb:f8:de:fd:\n\t                94:3f:f4:ee:12:48:ea:b1:60:62:be:58:47:78:29:\n\t                59:5b:ae:57:53:23:31:aa:78:cc:6c:f0:f7:e9:76:\n\t                4a:b9:25:79:3f:9c:05:4e:f0:8e:87:32:df:87:72:\n\t                67:64:2e:9f:85:15:64:bf:ca:ce:33:71:ee:bb:1a:\n\t                d3:26:09:34:9b:65:b9:15:71:28:14:37:48:79:1b:\n\t                b1:99:a4:8c:cc:27:a1:a4:c4:28:8e:01:e5:08:db:\n\t                e6:45:6e:3d:d9:03:a9:cb:17:25:b7:c9:c9:4b:fb:\n\t                e5:93:d1:de:31:fe:a9:34:29:c3:29:a4:27:c2:eb:\n\t                66:99:c6:db:ba:52:07:30:97:d4:0a:1e:1b:5d:72:\n\t                f6:ff:19:92:22:c0:44:76:74:f7:a7:0d:c5:77:c8:\n\t                1c:55\n\t            Exponent: 65537 (0x10001)\n\tSignature Algorithm: sha256WithRSAEncryption\n\t     28:d1:d9:29:a5:40:f3:d3:d6:95:87:fd:2c:70:dc:0f:1c:86:\n\t     08:35:d0:a8:8e:d0:5d:78:28:ae:88:33:61:db:cd:b6:80:1c:\n\t     88:62:b8:ce:cf:87:14:15:bd:27:9a:3e:77:cb:a1:e0:11:0d:\n\t     89:ef:f2:e8:b2:2c:cf:96:26:bd:06:3a:7b:8f:4b:fa:b2:c3:\n\t     f9:14:3e:18:ef:57:b5:37:95:01:a0:0f:bf:6e:5c:c9:47:7b:\n\t     1a:ed:ca:7a:31:a1:89:e8:0d:4d:95:d2:61:e3:b8:48:e5:86:\n\t     19:91:3e:00:86:07:50:df:e2:57:29:69:61:c4:cc:55:8f:60:\n\t     de:20:c1:0d:7d:c7:98:52:f4:34:08:90:c5:90:34:ec:86:0f:\n\t     ad:9b:e7:1a:d4:7b:d9:dd:59:82:de:54:d3:87:8e:e7:82:ae:\n\t     22:70:cf:e7:d7:8c:f1:55:57:6d:41:e6:44:3c:83:b7:73:7e:\n\t     9a:d5:1d:af:72:e9:4e:88:d4:4f:9f:33:2f:dc:1b:50:10:8b:\n\t     db:cd:e4:0e:e6:96:cd:c6:27:c7:4b:c7:9f:05:74:32:35:7e:\n\t     99:78:36:30:ae:78:4b:c3:1a:6b:b8:db:62:23:b8:ab:22:11:\n\t     11:81:95:5d:46:f0:45:15:77:1f:6b:c0:bf:9d:a2:d2:b4:62:\n\t     c9:b5:2b:dd\n\t\n4.将证书导出成浏览器支持的.p12格式 ：\n\n\t$ openssl pkcs12 -export -clcerts -in server/server-cert.pem -inkey server/server-key.pem -out server/server.p12\n密码：changeit\n\nAdditional：\n因为server端的证书是由CA的private key签名(sign)server端的public key及其持有者的真实身份得到的, 因此server端证书里就包含server的public key.  \n就不需要用Openssl生成server端的public key. 用server端的**csr（certificate signing requests）**生成server证书即可. client端也一样.  \nclient端只需要用CA的public key(CA的public key所有人都能获取)解密server端存放在CA的证书文件就可以得到Server端的public key.  \n然后client端就可以用解密得到的server端的public key对server端用自身private key加密的信息附带的摘要A(digest)进行解密.  \nclient端将server端发过来的信息用Hash得到摘要B(digest)与解密得到的摘要A(digest)对比, 如果一直则说明信息没有被黑客篡改.  \n如果中间黑客把server端加密的摘要A(digest)修改了，则client用从CA的public key解密得到的server端的public key是解不开摘要A(digest)的, 说明摘要信息被黑客篡改, 内容不可靠.  \n\n如果要生成RSA公钥, command如下:\n\n\t$ openssl rsa -in server/server-key.pem -pubout -out server/server-public-key.pem\n\n### **三.生成client证书。**\n1.创建私钥 ：\n<table><tr><td bgcolor=#54FF9F>**client/client-key.pem**</td></tr></table>\n\n\t$ openssl genrsa -out client/client-key.pem 2048\n\t查看key\n\t$ openssl rsa -in client/client-key.pem -text -noout\n\t如果是DER格式的话,同理应该这样\n\t$ openssl rsa -in client/client-key.pem -text -noout -inform der\n\n2.创建证书请求 ：\n<table><tr><td bgcolor=#54FF9F>**client/client-req.csr**</td></tr></table>\n\n\t$ openssl req -new -out client/client-req.csr -key client/client-key.pem\n\t  Country Name (2 letter code) [AU]:cn\n\t  State or Province Name (full name) [Some-State]:zhejiang\n\t  Locality Name (eg, city) []:hangzhou\n\t  Organization Name (eg, company) [Internet Widgits Pty Ltd]:skyvision\n\t  Organizational Unit Name (eg, section) []:test\n\t  Common Name (eg, YOUR name) []:sky\n\t  Email Address []:sky 注释：就是登入中心的用户（本来用户名应该是Common Name，但是中山公安的不知道为什么使用的Email Address，其他版本没有测试）\n\t  Please enter the following ‘extra’ attributes\n\t  to be sent with your certificate request\n\t  A challenge password []:123456\n\t  An optional company name []:tsing\n\n3.自签署证书 ：\n<table><tr><td bgcolor=#54FF9F>**client/client-cert.pem**</td></tr></table>\n\n\t$ openssl x509 -req -in client/client-req.csr -out client/client-cert.pem -signkey client/client-key.pem -CA ca/ca-cert.pem -CAkey ca/ca-key.pem -CAcreateserial -days 3650\n\t * -CA选项指明用于被签名的csr证书\n\t * -CAkey选项指明用于签名的密钥\n\t * -CAcreateserial指明文件不存在时自动生成\n\t查看证书格式:\n\t$ openssl x509 -in client/client-cert.pem -text -noout\n\n4.将证书导出成浏览器支持的.p12格式 ：\n\n\t$ openssl pkcs12 -export -clcerts -in client/client-cert.pem -inkey client/client-key.pem -out client/client.p12\n密码：changeit\n\nAdditional. 生成RSA公钥:\n\n\t$ openssl rsa -in client/client-key.pem -pubout -out client/client-public-key.pem\n\n请一定严格根据里面的步骤来，待实验成功后，修改你自己想要修改的内容。我就是一开始没有安装该填写的来，结果生成的证书就无法配对成功。\n\n\n","slug":"technologies/security/openssl_certificates","published":1,"date":"2020-08-12T16:05:48.673Z","updated":"2020-08-10T16:40:24.116Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmoh009ahohx21pa71os","content":"<h1 id=\"X-509证书标准定义的两种编码格式PEM和DER\"><a href=\"#X-509证书标准定义的两种编码格式PEM和DER\" class=\"headerlink\" title=\"X.509证书标准定义的两种编码格式PEM和DER\"></a><strong>X.509证书标准定义的两种编码格式PEM和DER</strong></h1><h2 id=\"PEM编码（Privacy-Enhanced-Mail）\"><a href=\"#PEM编码（Privacy-Enhanced-Mail）\" class=\"headerlink\" title=\"PEM编码（Privacy Enhanced Mail）\"></a><strong>PEM编码（Privacy Enhanced Mail）</strong></h2><p>特点：纯文本文件, 以—–BEGIN CERTIFICATE—–开头, 以—–END CERTIFICATE—–结尾,<br>内容是 base64 编码. 但使用文本编辑器只能查看表面的结构, 需要输入命令例如  </p>\n<pre><code>$ openssl x509 -in 某个PEM格式数字证书.pem -text -noout</code></pre><p>才能看到原始的数字证书信息.  </p>\n<pre><code>-----BEGIN CERTIFICATE-----\nMIID7TCCAtWgAwIBAgIJAOIRDhOcxsx6MA0GCSqGSIb3DQEBCwUAMIGLMQswCQYD\n……\nxAJz+w8tjrDWcf826VN14IL+/Cmqlg/rIfB5CHdwVIfWwpuGB66q/UiPegZMNs8a\n3g==\n-----END CERTIFICATE-----</code></pre><h2 id=\"DER编码（Distinguished-Encoding-Rules）\"><a href=\"#DER编码（Distinguished-Encoding-Rules）\" class=\"headerlink\" title=\"DER编码（Distinguished Encoding Rules）\"></a><strong>DER编码（Distinguished Encoding Rules）</strong></h2><p>特点：二进制文件格式, 一般应使用 Windows/Java 开发工具打开, 也可以使用openssl命令行工具提取其中信息或进行编码转换.  </p>\n<pre><code>$ openssl x509 -in 某个DER格式的数字证书.der -inform der -text -noout  </code></pre><p>上面这个命令查看二进制文件中的证书信息.  </p>\n<h2 id=\"文件扩展名\"><a href=\"#文件扩展名\" class=\"headerlink\" title=\"文件扩展名\"></a><strong>文件扩展名</strong></h2><table><tr><td bgcolor=#54FF9F><font face=\"fantasy\" size=4>我们身边有很多常见的数字证书文件, 他们的扩展名通常既不叫\".pem\"也不叫\".der\", 但无论扩展名是什么, 其内部编码格式只能从PEM和DER这两种编码格式中选择一种.</font></td></tr></table>  \n不同平台所偏好的编码格式不同, 不同类型的数字证书文件中存储的内容也略有差别, 不过对于大部分证书文件, 我们都可以借助命令行工具随时将其转换成另一种编码格式.  \n\n<ul>\n<li><strong>CRT</strong> - CRT应该是certificate的三个字母,其实还是证书的意思,常见于NIX系统,有可能是PEM编码,也有可能是DER编码,大多数应该是PEM编码,相信你已经知道怎么辨别. <strong>证书内容包含: signer(如CA:kubernetes),个人信息,过期时间,公钥public key,加密算法(非对称加密算法RSA2048, 对称机密算法AES256等),签名算法(sign algorithm)等信息.</strong>  </li>\n<li><strong>KEY</strong> - 通常用来存放一个公钥或者私钥,并非X.509证书,编码同样的,可能是PEM,也可能是DER.<br>查看KEY的办法:  </li>\n</ul>\n<pre><code>$ openssl rsa -in mykey.key -text -noout</code></pre><p>如果是DER格式的话,同理应该这样了:</p>\n<pre><code>$ openssl rsa -in mykey.key -text -noout -inform der\n\n$ cd /home/zhan/istio-1.6.0/samples/certs/\n$ openssl x509 -in root-cert.pem -text -noout\nSignature Algorithm: sha256WithRSAEncryption\n$ openssl x509 -in root-cert.pem -text -noout | grep Validity -A 2\nValidity\n        Not Before: Jan 24 19:15:51 2018 GMT\n        Not After : Dec 31 19:15:51 2117 GMT\n-A n这样的shell写法，输出当前行之后的n行内容</code></pre><ul>\n<li><strong>CSR - Certificate Signing Request</strong>,即证书签名请求,这个并不是证书,而是向权威证书颁发机构获得签名证书的申请,其核心内容是一个<strong>公钥和个人信息</strong>,在生成这个申请的时候, 要对应生成的有一个私钥,私钥要自己保管好, client端把包含public key的csr文件发给CA, 用CA的private key给csr文件做签名(sign)生成client端证书. <strong>CSR文件</strong>内容一般包含: <strong>个人信息,公钥public key,加密算法(非对称加密算法RSA2048, 对称机密算法AES256等),签名算法(sign algorithm)等信息.</strong><br>查看的办法:</li>\n</ul>\n<pre><code>$ openssl req -noout -text -in my.csr</code></pre><p>(如果是DER格式的话照旧命令行加上-inform der,这里不写了)</p>\n<h2 id=\"证书编码的转换\"><a href=\"#证书编码的转换\" class=\"headerlink\" title=\"证书编码的转换\"></a><strong>证书编码的转换</strong></h2><p> • PEM转为DER：</p>\n<pre><code>$ openssl x509 -in cert.crt -outform der -out cert.der</code></pre><p> • DER转为PEM：</p>\n<pre><code>$ openssl x509 -in cert.crt -inform der -outform pem -out cert.pem</code></pre><h2 id=\"获得证书的步骤\"><a href=\"#获得证书的步骤\" class=\"headerlink\" title=\"获得证书的步骤\"></a><strong>获得证书的步骤</strong></h2><table><tr><td bgcolor=#54FF9F> • 向权威证书颁发机构申请证书</td></tr></table>\n用以下命令生成一个csr:\n\n\n<pre><code>$ openssl req -newkey rsa:2048 -new -nodes -keyout my.key -out my.csr\n$ ls\nmy.csr  my.key</code></pre><p>把<strong>csr</strong>交给权威证书颁发机构,权威证书颁发机构对此进行签名,完成.保留好csr,<strong>当权威证书颁发机构颁发的证书过期的时候,你还可以用同样的csr来申请新的证书,key保持不变.</strong></p>\n<table><tr><td bgcolor=#54FF9F> • 或者生成自签名的证书</td></tr></table>\n\n\n<pre><code>$ openssl req -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout key.pem -out cert.pem\n$ ls\ncert.pem  key.pem</code></pre><p>在生成证书的过程中会要你填一堆的东西,其实真正要填的只有Common Name,通常填写你服务器的域名,如”yourcompany.com”,或者你服务器的IP地址,其它都可以留空的.<br>生产环境中还是不要使用自签的证书,否则浏览器会不认,或者如果你是企业应用的话能够强制让用户的浏览器接受你的自签证书也行.向权威机构要证书通常是要钱的,但现在也有免费的,仅仅需要一个简单的域名验证即可.有兴趣的话查查”沃通数字证书”.</p>\n<h2 id=\"生成证书\"><a href=\"#生成证书\" class=\"headerlink\" title=\"生成证书\"></a><strong>生成证书</strong></h2><h3 id=\"一：生成CA证书\"><a href=\"#一：生成CA证书\" class=\"headerlink\" title=\"一：生成CA证书\"></a><strong>一：生成CA证书</strong></h3><p>目前不使用第三方权威机构的CA来认证，自己充当CA的角色。<br>网上下载一个openssl软件<br>1.创建私钥：<br>通常是rsa算法  </p>\n<table><tr><td bgcolor=#54FF9F>**ca-key.pem**</td></tr></table>\n\n<pre><code>$ openssl genrsa -out ca/ca-key.pem 2048\n查看key\n$ openssl rsa -in ca/ca-key.pem -text -noout\n如果是DER格式的话,同理应该这样\n$ openssl rsa -in ca/ca-key.pem -text -noout -inform der</code></pre><p>2.创建证书请求：  </p>\n<blockquote>\n<p>因此在用户向CA申请数字证书时，用户首先需要在自己的电脑中先产生一个公私钥对。用户需要保管好自己的私钥，然后再把公钥和你的个人信息发送给CA机构，CA机构通过你的公钥和个人信息最终签发出数字证书。<br>而CSR文件，其实就是包含了用户公钥和个人信息的一个数据文件。用户产生出这个CSR文件，再把这个CSR文件发送给CA，CA就会根据CSR中的内容来签发出数字证书。  </p>\n</blockquote>\n<p>在制作csr文件的时，必须使用自己的私钥来签署申，还可以设定一个密钥.</p>\n<table><tr><td bgcolor=#54FF9F>**ca-req.csr**</td></tr></table>\n\n<pre><code>$ openssl req -new -out ca/ca-req.csr -key ca/ca-key.pem\n  Country Name (2 letter code) [AU]:cn\n  State or Province Name (full name) [Some-State]:zhejiang\n  Locality Name (eg, city) []:hangzhou\n  Organization Name (eg, company) [Internet Widgits Pty Ltd]:skyvision\n  Organizational Unit Name (eg, section) []:test\n  Common Name (eg, YOUR name) []:root\n  Email Address []:sky</code></pre><p>3.自签署证书 ：</p>\n<table><tr><td bgcolor=#54FF9F>**ca/ca-cert.pem**</td></tr></table>\n\n<pre><code>$ openssl x509 -req -in ca/ca-req.csr -out ca/ca-cert.pem -signkey ca/ca-key.pem -days 3650\n查看证书格式:\n$ openssl x509 -in ca/ca-cert.pem -text -noout</code></pre><p>4.将证书导出成浏览器支持的.p12格式 ：</p>\n<pre><code>$ openssl pkcs12 -export -clcerts -in ca/ca-cert.pem -inkey ca/ca-key.pem -out ca/ca.p12</code></pre><p>密码：changeit</p>\n<h3 id=\"二-生成server证书。\"><a href=\"#二-生成server证书。\" class=\"headerlink\" title=\"二.生成server证书。\"></a><strong>二.生成server证书。</strong></h3><p>1.创建私钥 ：</p>\n<table><tr><td bgcolor=#54FF9F>**server/server-key.pem**</td></tr></table>\n\n<pre><code>$ openssl genrsa -out server/server-key.pem 2048\n查看key\n$ openssl rsa -in server/server-key.pem -text -noout\n如果是DER格式的话,同理应该这样\n$ openssl rsa -in server/server-key.pem -text -noout -inform der</code></pre><p>2.创建证书请求 ：</p>\n<table><tr><td bgcolor=#54FF9F>**server/server-req.csr**</td></tr></table>\n\n<pre><code>$ openssl req -new -out server/server-req.csr -key server/server-key.pem\n  Country Name (2 letter code) [AU]:cn\n  State or Province Name (full name) [Some-State]:zhejiang\n  Locality Name (eg, city) []:hangzhou\n  Organization Name (eg, company) [Internet Widgits Pty Ltd]:skyvision\n  Organizational Unit Name (eg, section) []:test\n  Common Name (eg, YOUR name) []:192.168.1.246 注释：一定要写服务器所在的ip地址\n  Email Address []:sky\n查看csr文件内容:\n$ $ openssl req -in server-req.csr -text -noout // -noout 不用输出csr文件原始内容\nCertificate Request:\n    Data:\n        Version: 0 (0x0)\n        Subject: C=XX, L=Default City, O=Default Company Ltd, CN=10.239.140.186\n        Subject Public Key Info:\n            Public Key Algorithm: rsaEncryption\n                Public-Key: (2048 bit)\n                Modulus:\n                    00:e2:0c:a7:33:33:d9:9b:90:1b:29:30:3c:81:31:\n                    09:97:0a:a9:76:d5:54:be:63:17:21:0c:b9:3a:f0:\n                    a6:02:37:1a:d4:1e:53:4e:e0:c8:d9:5f:27:57:7f:\n                    f3:eb:7f:9d:ad:79:d6:e7:40:64:c8:bc:3d:f3:b4:\n                    16:d6:30:e9:16:04:b6:a0:0e:8f:75:e4:4b:d6:8e:\n                    0a:8e:75:d8:41:89:09:90:96:b0:8d:32:5f:b5:96:\n                    1d:65:d6:a6:b4:c7:eb:3d:3b:f9:62:36:69:7d:07:\n                    6d:05:89:ce:a6:a5:98:a0:b2:5f:ab:bc:25:ba:08:\n                    d8:86:0a:b9:c0:91:ca:f8:d3:bb:36:14:21:f9:c2:\n                    b5:53:43:a9:2c:03:39:9b:93:ef:1d:d9:20:ef:dd:\n                    ff:57:c6:b5:47:e8:bb:46:32:e3:1d:3b:2e:5b:15:\n                    11:80:72:f6:2e:f5:b2:cc:02:7f:b1:d6:e9:3d:8e:\n                    0e:66:f6:6d:45:0e:2f:8c:d5:c3:92:dc:a1:9a:d9:\n                    b0:33:82:30:69:0a:05:ee:08:1b:a6:81:f4:bb:31:\n                    0d:fa:26:37:eb:4f:c8:58:df:e5:be:cc:ac:9a:62:\n                    42:f1:af:8c:35:88:e4:f3:b4:76:8f:6c:13:1f:9a:\n                    61:e0:08:0f:f2:b1:d6:f3:61:b4:0a:5d:9a:61:5f:\n                    e1:0b\n                Exponent: 65537 (0x10001)\n        Attributes:\n            a0:00\n    Signature Algorithm: sha256WithRSAEncryption\n         5b:62:35:07:43:99:dc:af:7c:61:1e:76:4e:f8:ef:59:b2:27:\n         60:71:30:15:5d:f3:0b:b1:b4:53:29:ec:d1:7c:18:48:0a:b3:\n         fe:b7:6d:80:ef:dc:c6:24:04:3d:bd:c1:b8:61:49:f3:1e:fb:\n         22:0f:fb:06:99:ec:db:18:ac:34:ff:4b:15:f8:84:06:01:4d:\n         68:4f:0c:a2:a5:34:dc:1b:61:44:c7:ff:ef:5d:92:a1:09:3f:\n         11:27:1c:a7:30:8e:97:6a:08:03:99:e6:6a:8f:1d:d6:ea:e7:\n         cd:18:a7:eb:36:3d:e7:6b:5e:ef:72:85:ca:eb:89:97:02:cf:\n         fc:38:31:58:e1:66:85:d1:e7:49:e2:72:ef:b1:60:36:55:d7:\n         90:bd:8d:0e:d8:c6:8f:d2:bf:bf:43:85:36:04:2e:f1:ec:5f:\n         d8:1b:17:22:a4:6a:de:a7:b2:2b:00:30:27:e6:4b:32:4d:55:\n         70:b0:61:3d:3f:f2:9d:e7:24:f6:4c:1f:bf:63:6a:d9:16:ef:\n         cb:91:a3:a4:43:b5:1f:11:85:ad:0e:b1:57:39:f2:0a:56:ec:\n         52:90:b0:11:96:c6:28:e0:de:0c:eb:f2:b1:66:ce:04:48:7f:\n         11:90:09:1d:fd:ca:a7:25:66:32:a2:64:33:1a:5e:a9:85:50:\n         8a:2d:90:a5</code></pre><p>3.自签署证书 ：</p>\n<table><tr><td bgcolor=#54FF9F>**server/server-cert.pem**</td></tr></table>\n\n<pre><code>$ openssl x509 -req -in server/server-req.csr -out server/server-cert.pem -signkey server/server-key.pem -CA ca/ca-cert.pem -CAkey ca/ca-key.pem -CAcreateserial -days 3650\n * -CA选项指明用于被签名的csr证书\n * -CAkey选项指明用于签名的密钥\n * -CAcreateserial指明文件不存在时自动生成\n查看证书格式:\n$ openssl x509 -in server/server-cert.pem -text -noout\n可以查看到证书里所包含的public key等相关信息:\nCertificate:\nData:\n    Version: 1 (0x0)\n    Serial Number:\n        cc:db:c0:f2:12:e8:09:27\nSignature Algorithm: sha256WithRSAEncryption\n    Issuer: C=XX, L=Default City, O=Default Company Ltd, CN=AI    // 签发者(CA机构)\n    Validity\n        Not Before: Jul 16 07:01:18 2020 GMT\n        Not After : Jul 14 07:01:18 2030 GMT\n    Subject: C=XX, L=Default City, O=Default Company Ltd, CN=sky\n    Subject Public Key Info:\n        Public Key Algorithm: rsaEncryption\n            Public-Key: (2048 bit)            // public key, 因此本地可以不需要再存储保留public key, 证书里已包含.\n            Modulus:\n                00:cd:d7:ed:e9:c6:5e:fa:bc:ef:1e:4e:92:52:99:\n                f0:34:96:67:7b:32:1b:f6:53:df:ca:7b:e5:72:6a:\n                29:e5:85:27:eb:71:00:c6:90:ac:c1:64:62:0d:2b:\n                b1:bc:b8:ee:e1:d4:54:b7:95:21:1e:de:56:c7:25:\n                4c:d4:2d:29:5f:48:19:8a:05:c4:33:d3:06:16:ec:\n                68:e2:81:07:cf:f9:d1:15:b2:68:3d:da:44:c3:d5:\n                ba:a3:0f:9e:34:34:71:53:4f:02:4b:eb:f8:de:fd:\n                94:3f:f4:ee:12:48:ea:b1:60:62:be:58:47:78:29:\n                59:5b:ae:57:53:23:31:aa:78:cc:6c:f0:f7:e9:76:\n                4a:b9:25:79:3f:9c:05:4e:f0:8e:87:32:df:87:72:\n                67:64:2e:9f:85:15:64:bf:ca:ce:33:71:ee:bb:1a:\n                d3:26:09:34:9b:65:b9:15:71:28:14:37:48:79:1b:\n                b1:99:a4:8c:cc:27:a1:a4:c4:28:8e:01:e5:08:db:\n                e6:45:6e:3d:d9:03:a9:cb:17:25:b7:c9:c9:4b:fb:\n                e5:93:d1:de:31:fe:a9:34:29:c3:29:a4:27:c2:eb:\n                66:99:c6:db:ba:52:07:30:97:d4:0a:1e:1b:5d:72:\n                f6:ff:19:92:22:c0:44:76:74:f7:a7:0d:c5:77:c8:\n                1c:55\n            Exponent: 65537 (0x10001)\nSignature Algorithm: sha256WithRSAEncryption\n     28:d1:d9:29:a5:40:f3:d3:d6:95:87:fd:2c:70:dc:0f:1c:86:\n     08:35:d0:a8:8e:d0:5d:78:28:ae:88:33:61:db:cd:b6:80:1c:\n     88:62:b8:ce:cf:87:14:15:bd:27:9a:3e:77:cb:a1:e0:11:0d:\n     89:ef:f2:e8:b2:2c:cf:96:26:bd:06:3a:7b:8f:4b:fa:b2:c3:\n     f9:14:3e:18:ef:57:b5:37:95:01:a0:0f:bf:6e:5c:c9:47:7b:\n     1a:ed:ca:7a:31:a1:89:e8:0d:4d:95:d2:61:e3:b8:48:e5:86:\n     19:91:3e:00:86:07:50:df:e2:57:29:69:61:c4:cc:55:8f:60:\n     de:20:c1:0d:7d:c7:98:52:f4:34:08:90:c5:90:34:ec:86:0f:\n     ad:9b:e7:1a:d4:7b:d9:dd:59:82:de:54:d3:87:8e:e7:82:ae:\n     22:70:cf:e7:d7:8c:f1:55:57:6d:41:e6:44:3c:83:b7:73:7e:\n     9a:d5:1d:af:72:e9:4e:88:d4:4f:9f:33:2f:dc:1b:50:10:8b:\n     db:cd:e4:0e:e6:96:cd:c6:27:c7:4b:c7:9f:05:74:32:35:7e:\n     99:78:36:30:ae:78:4b:c3:1a:6b:b8:db:62:23:b8:ab:22:11:\n     11:81:95:5d:46:f0:45:15:77:1f:6b:c0:bf:9d:a2:d2:b4:62:\n     c9:b5:2b:dd</code></pre><p>4.将证书导出成浏览器支持的.p12格式 ：</p>\n<pre><code>$ openssl pkcs12 -export -clcerts -in server/server-cert.pem -inkey server/server-key.pem -out server/server.p12</code></pre><p>密码：changeit</p>\n<p>Additional：<br>因为server端的证书是由CA的private key签名(sign)server端的public key及其持有者的真实身份得到的, 因此server端证书里就包含server的public key.<br>就不需要用Openssl生成server端的public key. 用server端的<strong>csr（certificate signing requests）</strong>生成server证书即可. client端也一样.<br>client端只需要用CA的public key(CA的public key所有人都能获取)解密server端存放在CA的证书文件就可以得到Server端的public key.<br>然后client端就可以用解密得到的server端的public key对server端用自身private key加密的信息附带的摘要A(digest)进行解密.<br>client端将server端发过来的信息用Hash得到摘要B(digest)与解密得到的摘要A(digest)对比, 如果一直则说明信息没有被黑客篡改.<br>如果中间黑客把server端加密的摘要A(digest)修改了，则client用从CA的public key解密得到的server端的public key是解不开摘要A(digest)的, 说明摘要信息被黑客篡改, 内容不可靠.  </p>\n<p>如果要生成RSA公钥, command如下:</p>\n<pre><code>$ openssl rsa -in server/server-key.pem -pubout -out server/server-public-key.pem</code></pre><h3 id=\"三-生成client证书。\"><a href=\"#三-生成client证书。\" class=\"headerlink\" title=\"三.生成client证书。\"></a><strong>三.生成client证书。</strong></h3><p>1.创建私钥 ：</p>\n<table><tr><td bgcolor=#54FF9F>**client/client-key.pem**</td></tr></table>\n\n<pre><code>$ openssl genrsa -out client/client-key.pem 2048\n查看key\n$ openssl rsa -in client/client-key.pem -text -noout\n如果是DER格式的话,同理应该这样\n$ openssl rsa -in client/client-key.pem -text -noout -inform der</code></pre><p>2.创建证书请求 ：</p>\n<table><tr><td bgcolor=#54FF9F>**client/client-req.csr**</td></tr></table>\n\n<pre><code>$ openssl req -new -out client/client-req.csr -key client/client-key.pem\n  Country Name (2 letter code) [AU]:cn\n  State or Province Name (full name) [Some-State]:zhejiang\n  Locality Name (eg, city) []:hangzhou\n  Organization Name (eg, company) [Internet Widgits Pty Ltd]:skyvision\n  Organizational Unit Name (eg, section) []:test\n  Common Name (eg, YOUR name) []:sky\n  Email Address []:sky 注释：就是登入中心的用户（本来用户名应该是Common Name，但是中山公安的不知道为什么使用的Email Address，其他版本没有测试）\n  Please enter the following ‘extra’ attributes\n  to be sent with your certificate request\n  A challenge password []:123456\n  An optional company name []:tsing</code></pre><p>3.自签署证书 ：</p>\n<table><tr><td bgcolor=#54FF9F>**client/client-cert.pem**</td></tr></table>\n\n<pre><code>$ openssl x509 -req -in client/client-req.csr -out client/client-cert.pem -signkey client/client-key.pem -CA ca/ca-cert.pem -CAkey ca/ca-key.pem -CAcreateserial -days 3650\n * -CA选项指明用于被签名的csr证书\n * -CAkey选项指明用于签名的密钥\n * -CAcreateserial指明文件不存在时自动生成\n查看证书格式:\n$ openssl x509 -in client/client-cert.pem -text -noout</code></pre><p>4.将证书导出成浏览器支持的.p12格式 ：</p>\n<pre><code>$ openssl pkcs12 -export -clcerts -in client/client-cert.pem -inkey client/client-key.pem -out client/client.p12</code></pre><p>密码：changeit</p>\n<p>Additional. 生成RSA公钥:</p>\n<pre><code>$ openssl rsa -in client/client-key.pem -pubout -out client/client-public-key.pem</code></pre><p>请一定严格根据里面的步骤来，待实验成功后，修改你自己想要修改的内容。我就是一开始没有安装该填写的来，结果生成的证书就无法配对成功。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"X-509证书标准定义的两种编码格式PEM和DER\"><a href=\"#X-509证书标准定义的两种编码格式PEM和DER\" class=\"headerlink\" title=\"X.509证书标准定义的两种编码格式PEM和DER\"></a><strong>X.509证书标准定义的两种编码格式PEM和DER</strong></h1><h2 id=\"PEM编码（Privacy-Enhanced-Mail）\"><a href=\"#PEM编码（Privacy-Enhanced-Mail）\" class=\"headerlink\" title=\"PEM编码（Privacy Enhanced Mail）\"></a><strong>PEM编码（Privacy Enhanced Mail）</strong></h2><p>特点：纯文本文件, 以—–BEGIN CERTIFICATE—–开头, 以—–END CERTIFICATE—–结尾,<br>内容是 base64 编码. 但使用文本编辑器只能查看表面的结构, 需要输入命令例如  </p>\n<pre><code>$ openssl x509 -in 某个PEM格式数字证书.pem -text -noout</code></pre><p>才能看到原始的数字证书信息.  </p>\n<pre><code>-----BEGIN CERTIFICATE-----\nMIID7TCCAtWgAwIBAgIJAOIRDhOcxsx6MA0GCSqGSIb3DQEBCwUAMIGLMQswCQYD\n……\nxAJz+w8tjrDWcf826VN14IL+/Cmqlg/rIfB5CHdwVIfWwpuGB66q/UiPegZMNs8a\n3g==\n-----END CERTIFICATE-----</code></pre><h2 id=\"DER编码（Distinguished-Encoding-Rules）\"><a href=\"#DER编码（Distinguished-Encoding-Rules）\" class=\"headerlink\" title=\"DER编码（Distinguished Encoding Rules）\"></a><strong>DER编码（Distinguished Encoding Rules）</strong></h2><p>特点：二进制文件格式, 一般应使用 Windows/Java 开发工具打开, 也可以使用openssl命令行工具提取其中信息或进行编码转换.  </p>\n<pre><code>$ openssl x509 -in 某个DER格式的数字证书.der -inform der -text -noout  </code></pre><p>上面这个命令查看二进制文件中的证书信息.  </p>\n<h2 id=\"文件扩展名\"><a href=\"#文件扩展名\" class=\"headerlink\" title=\"文件扩展名\"></a><strong>文件扩展名</strong></h2><table><tr><td bgcolor=#54FF9F><font face=\"fantasy\" size=4>我们身边有很多常见的数字证书文件, 他们的扩展名通常既不叫\".pem\"也不叫\".der\", 但无论扩展名是什么, 其内部编码格式只能从PEM和DER这两种编码格式中选择一种.</font></td></tr></table>  \n不同平台所偏好的编码格式不同, 不同类型的数字证书文件中存储的内容也略有差别, 不过对于大部分证书文件, 我们都可以借助命令行工具随时将其转换成另一种编码格式.  \n\n<ul>\n<li><strong>CRT</strong> - CRT应该是certificate的三个字母,其实还是证书的意思,常见于NIX系统,有可能是PEM编码,也有可能是DER编码,大多数应该是PEM编码,相信你已经知道怎么辨别. <strong>证书内容包含: signer(如CA:kubernetes),个人信息,过期时间,公钥public key,加密算法(非对称加密算法RSA2048, 对称机密算法AES256等),签名算法(sign algorithm)等信息.</strong>  </li>\n<li><strong>KEY</strong> - 通常用来存放一个公钥或者私钥,并非X.509证书,编码同样的,可能是PEM,也可能是DER.<br>查看KEY的办法:  </li>\n</ul>\n<pre><code>$ openssl rsa -in mykey.key -text -noout</code></pre><p>如果是DER格式的话,同理应该这样了:</p>\n<pre><code>$ openssl rsa -in mykey.key -text -noout -inform der\n\n$ cd /home/zhan/istio-1.6.0/samples/certs/\n$ openssl x509 -in root-cert.pem -text -noout\nSignature Algorithm: sha256WithRSAEncryption\n$ openssl x509 -in root-cert.pem -text -noout | grep Validity -A 2\nValidity\n        Not Before: Jan 24 19:15:51 2018 GMT\n        Not After : Dec 31 19:15:51 2117 GMT\n-A n这样的shell写法，输出当前行之后的n行内容</code></pre><ul>\n<li><strong>CSR - Certificate Signing Request</strong>,即证书签名请求,这个并不是证书,而是向权威证书颁发机构获得签名证书的申请,其核心内容是一个<strong>公钥和个人信息</strong>,在生成这个申请的时候, 要对应生成的有一个私钥,私钥要自己保管好, client端把包含public key的csr文件发给CA, 用CA的private key给csr文件做签名(sign)生成client端证书. <strong>CSR文件</strong>内容一般包含: <strong>个人信息,公钥public key,加密算法(非对称加密算法RSA2048, 对称机密算法AES256等),签名算法(sign algorithm)等信息.</strong><br>查看的办法:</li>\n</ul>\n<pre><code>$ openssl req -noout -text -in my.csr</code></pre><p>(如果是DER格式的话照旧命令行加上-inform der,这里不写了)</p>\n<h2 id=\"证书编码的转换\"><a href=\"#证书编码的转换\" class=\"headerlink\" title=\"证书编码的转换\"></a><strong>证书编码的转换</strong></h2><p> • PEM转为DER：</p>\n<pre><code>$ openssl x509 -in cert.crt -outform der -out cert.der</code></pre><p> • DER转为PEM：</p>\n<pre><code>$ openssl x509 -in cert.crt -inform der -outform pem -out cert.pem</code></pre><h2 id=\"获得证书的步骤\"><a href=\"#获得证书的步骤\" class=\"headerlink\" title=\"获得证书的步骤\"></a><strong>获得证书的步骤</strong></h2><table><tr><td bgcolor=#54FF9F> • 向权威证书颁发机构申请证书</td></tr></table>\n用以下命令生成一个csr:\n\n\n<pre><code>$ openssl req -newkey rsa:2048 -new -nodes -keyout my.key -out my.csr\n$ ls\nmy.csr  my.key</code></pre><p>把<strong>csr</strong>交给权威证书颁发机构,权威证书颁发机构对此进行签名,完成.保留好csr,<strong>当权威证书颁发机构颁发的证书过期的时候,你还可以用同样的csr来申请新的证书,key保持不变.</strong></p>\n<table><tr><td bgcolor=#54FF9F> • 或者生成自签名的证书</td></tr></table>\n\n\n<pre><code>$ openssl req -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout key.pem -out cert.pem\n$ ls\ncert.pem  key.pem</code></pre><p>在生成证书的过程中会要你填一堆的东西,其实真正要填的只有Common Name,通常填写你服务器的域名,如”yourcompany.com”,或者你服务器的IP地址,其它都可以留空的.<br>生产环境中还是不要使用自签的证书,否则浏览器会不认,或者如果你是企业应用的话能够强制让用户的浏览器接受你的自签证书也行.向权威机构要证书通常是要钱的,但现在也有免费的,仅仅需要一个简单的域名验证即可.有兴趣的话查查”沃通数字证书”.</p>\n<h2 id=\"生成证书\"><a href=\"#生成证书\" class=\"headerlink\" title=\"生成证书\"></a><strong>生成证书</strong></h2><h3 id=\"一：生成CA证书\"><a href=\"#一：生成CA证书\" class=\"headerlink\" title=\"一：生成CA证书\"></a><strong>一：生成CA证书</strong></h3><p>目前不使用第三方权威机构的CA来认证，自己充当CA的角色。<br>网上下载一个openssl软件<br>1.创建私钥：<br>通常是rsa算法  </p>\n<table><tr><td bgcolor=#54FF9F>**ca-key.pem**</td></tr></table>\n\n<pre><code>$ openssl genrsa -out ca/ca-key.pem 2048\n查看key\n$ openssl rsa -in ca/ca-key.pem -text -noout\n如果是DER格式的话,同理应该这样\n$ openssl rsa -in ca/ca-key.pem -text -noout -inform der</code></pre><p>2.创建证书请求：  </p>\n<blockquote>\n<p>因此在用户向CA申请数字证书时，用户首先需要在自己的电脑中先产生一个公私钥对。用户需要保管好自己的私钥，然后再把公钥和你的个人信息发送给CA机构，CA机构通过你的公钥和个人信息最终签发出数字证书。<br>而CSR文件，其实就是包含了用户公钥和个人信息的一个数据文件。用户产生出这个CSR文件，再把这个CSR文件发送给CA，CA就会根据CSR中的内容来签发出数字证书。  </p>\n</blockquote>\n<p>在制作csr文件的时，必须使用自己的私钥来签署申，还可以设定一个密钥.</p>\n<table><tr><td bgcolor=#54FF9F>**ca-req.csr**</td></tr></table>\n\n<pre><code>$ openssl req -new -out ca/ca-req.csr -key ca/ca-key.pem\n  Country Name (2 letter code) [AU]:cn\n  State or Province Name (full name) [Some-State]:zhejiang\n  Locality Name (eg, city) []:hangzhou\n  Organization Name (eg, company) [Internet Widgits Pty Ltd]:skyvision\n  Organizational Unit Name (eg, section) []:test\n  Common Name (eg, YOUR name) []:root\n  Email Address []:sky</code></pre><p>3.自签署证书 ：</p>\n<table><tr><td bgcolor=#54FF9F>**ca/ca-cert.pem**</td></tr></table>\n\n<pre><code>$ openssl x509 -req -in ca/ca-req.csr -out ca/ca-cert.pem -signkey ca/ca-key.pem -days 3650\n查看证书格式:\n$ openssl x509 -in ca/ca-cert.pem -text -noout</code></pre><p>4.将证书导出成浏览器支持的.p12格式 ：</p>\n<pre><code>$ openssl pkcs12 -export -clcerts -in ca/ca-cert.pem -inkey ca/ca-key.pem -out ca/ca.p12</code></pre><p>密码：changeit</p>\n<h3 id=\"二-生成server证书。\"><a href=\"#二-生成server证书。\" class=\"headerlink\" title=\"二.生成server证书。\"></a><strong>二.生成server证书。</strong></h3><p>1.创建私钥 ：</p>\n<table><tr><td bgcolor=#54FF9F>**server/server-key.pem**</td></tr></table>\n\n<pre><code>$ openssl genrsa -out server/server-key.pem 2048\n查看key\n$ openssl rsa -in server/server-key.pem -text -noout\n如果是DER格式的话,同理应该这样\n$ openssl rsa -in server/server-key.pem -text -noout -inform der</code></pre><p>2.创建证书请求 ：</p>\n<table><tr><td bgcolor=#54FF9F>**server/server-req.csr**</td></tr></table>\n\n<pre><code>$ openssl req -new -out server/server-req.csr -key server/server-key.pem\n  Country Name (2 letter code) [AU]:cn\n  State or Province Name (full name) [Some-State]:zhejiang\n  Locality Name (eg, city) []:hangzhou\n  Organization Name (eg, company) [Internet Widgits Pty Ltd]:skyvision\n  Organizational Unit Name (eg, section) []:test\n  Common Name (eg, YOUR name) []:192.168.1.246 注释：一定要写服务器所在的ip地址\n  Email Address []:sky\n查看csr文件内容:\n$ $ openssl req -in server-req.csr -text -noout // -noout 不用输出csr文件原始内容\nCertificate Request:\n    Data:\n        Version: 0 (0x0)\n        Subject: C=XX, L=Default City, O=Default Company Ltd, CN=10.239.140.186\n        Subject Public Key Info:\n            Public Key Algorithm: rsaEncryption\n                Public-Key: (2048 bit)\n                Modulus:\n                    00:e2:0c:a7:33:33:d9:9b:90:1b:29:30:3c:81:31:\n                    09:97:0a:a9:76:d5:54:be:63:17:21:0c:b9:3a:f0:\n                    a6:02:37:1a:d4:1e:53:4e:e0:c8:d9:5f:27:57:7f:\n                    f3:eb:7f:9d:ad:79:d6:e7:40:64:c8:bc:3d:f3:b4:\n                    16:d6:30:e9:16:04:b6:a0:0e:8f:75:e4:4b:d6:8e:\n                    0a:8e:75:d8:41:89:09:90:96:b0:8d:32:5f:b5:96:\n                    1d:65:d6:a6:b4:c7:eb:3d:3b:f9:62:36:69:7d:07:\n                    6d:05:89:ce:a6:a5:98:a0:b2:5f:ab:bc:25:ba:08:\n                    d8:86:0a:b9:c0:91:ca:f8:d3:bb:36:14:21:f9:c2:\n                    b5:53:43:a9:2c:03:39:9b:93:ef:1d:d9:20:ef:dd:\n                    ff:57:c6:b5:47:e8:bb:46:32:e3:1d:3b:2e:5b:15:\n                    11:80:72:f6:2e:f5:b2:cc:02:7f:b1:d6:e9:3d:8e:\n                    0e:66:f6:6d:45:0e:2f:8c:d5:c3:92:dc:a1:9a:d9:\n                    b0:33:82:30:69:0a:05:ee:08:1b:a6:81:f4:bb:31:\n                    0d:fa:26:37:eb:4f:c8:58:df:e5:be:cc:ac:9a:62:\n                    42:f1:af:8c:35:88:e4:f3:b4:76:8f:6c:13:1f:9a:\n                    61:e0:08:0f:f2:b1:d6:f3:61:b4:0a:5d:9a:61:5f:\n                    e1:0b\n                Exponent: 65537 (0x10001)\n        Attributes:\n            a0:00\n    Signature Algorithm: sha256WithRSAEncryption\n         5b:62:35:07:43:99:dc:af:7c:61:1e:76:4e:f8:ef:59:b2:27:\n         60:71:30:15:5d:f3:0b:b1:b4:53:29:ec:d1:7c:18:48:0a:b3:\n         fe:b7:6d:80:ef:dc:c6:24:04:3d:bd:c1:b8:61:49:f3:1e:fb:\n         22:0f:fb:06:99:ec:db:18:ac:34:ff:4b:15:f8:84:06:01:4d:\n         68:4f:0c:a2:a5:34:dc:1b:61:44:c7:ff:ef:5d:92:a1:09:3f:\n         11:27:1c:a7:30:8e:97:6a:08:03:99:e6:6a:8f:1d:d6:ea:e7:\n         cd:18:a7:eb:36:3d:e7:6b:5e:ef:72:85:ca:eb:89:97:02:cf:\n         fc:38:31:58:e1:66:85:d1:e7:49:e2:72:ef:b1:60:36:55:d7:\n         90:bd:8d:0e:d8:c6:8f:d2:bf:bf:43:85:36:04:2e:f1:ec:5f:\n         d8:1b:17:22:a4:6a:de:a7:b2:2b:00:30:27:e6:4b:32:4d:55:\n         70:b0:61:3d:3f:f2:9d:e7:24:f6:4c:1f:bf:63:6a:d9:16:ef:\n         cb:91:a3:a4:43:b5:1f:11:85:ad:0e:b1:57:39:f2:0a:56:ec:\n         52:90:b0:11:96:c6:28:e0:de:0c:eb:f2:b1:66:ce:04:48:7f:\n         11:90:09:1d:fd:ca:a7:25:66:32:a2:64:33:1a:5e:a9:85:50:\n         8a:2d:90:a5</code></pre><p>3.自签署证书 ：</p>\n<table><tr><td bgcolor=#54FF9F>**server/server-cert.pem**</td></tr></table>\n\n<pre><code>$ openssl x509 -req -in server/server-req.csr -out server/server-cert.pem -signkey server/server-key.pem -CA ca/ca-cert.pem -CAkey ca/ca-key.pem -CAcreateserial -days 3650\n * -CA选项指明用于被签名的csr证书\n * -CAkey选项指明用于签名的密钥\n * -CAcreateserial指明文件不存在时自动生成\n查看证书格式:\n$ openssl x509 -in server/server-cert.pem -text -noout\n可以查看到证书里所包含的public key等相关信息:\nCertificate:\nData:\n    Version: 1 (0x0)\n    Serial Number:\n        cc:db:c0:f2:12:e8:09:27\nSignature Algorithm: sha256WithRSAEncryption\n    Issuer: C=XX, L=Default City, O=Default Company Ltd, CN=AI    // 签发者(CA机构)\n    Validity\n        Not Before: Jul 16 07:01:18 2020 GMT\n        Not After : Jul 14 07:01:18 2030 GMT\n    Subject: C=XX, L=Default City, O=Default Company Ltd, CN=sky\n    Subject Public Key Info:\n        Public Key Algorithm: rsaEncryption\n            Public-Key: (2048 bit)            // public key, 因此本地可以不需要再存储保留public key, 证书里已包含.\n            Modulus:\n                00:cd:d7:ed:e9:c6:5e:fa:bc:ef:1e:4e:92:52:99:\n                f0:34:96:67:7b:32:1b:f6:53:df:ca:7b:e5:72:6a:\n                29:e5:85:27:eb:71:00:c6:90:ac:c1:64:62:0d:2b:\n                b1:bc:b8:ee:e1:d4:54:b7:95:21:1e:de:56:c7:25:\n                4c:d4:2d:29:5f:48:19:8a:05:c4:33:d3:06:16:ec:\n                68:e2:81:07:cf:f9:d1:15:b2:68:3d:da:44:c3:d5:\n                ba:a3:0f:9e:34:34:71:53:4f:02:4b:eb:f8:de:fd:\n                94:3f:f4:ee:12:48:ea:b1:60:62:be:58:47:78:29:\n                59:5b:ae:57:53:23:31:aa:78:cc:6c:f0:f7:e9:76:\n                4a:b9:25:79:3f:9c:05:4e:f0:8e:87:32:df:87:72:\n                67:64:2e:9f:85:15:64:bf:ca:ce:33:71:ee:bb:1a:\n                d3:26:09:34:9b:65:b9:15:71:28:14:37:48:79:1b:\n                b1:99:a4:8c:cc:27:a1:a4:c4:28:8e:01:e5:08:db:\n                e6:45:6e:3d:d9:03:a9:cb:17:25:b7:c9:c9:4b:fb:\n                e5:93:d1:de:31:fe:a9:34:29:c3:29:a4:27:c2:eb:\n                66:99:c6:db:ba:52:07:30:97:d4:0a:1e:1b:5d:72:\n                f6:ff:19:92:22:c0:44:76:74:f7:a7:0d:c5:77:c8:\n                1c:55\n            Exponent: 65537 (0x10001)\nSignature Algorithm: sha256WithRSAEncryption\n     28:d1:d9:29:a5:40:f3:d3:d6:95:87:fd:2c:70:dc:0f:1c:86:\n     08:35:d0:a8:8e:d0:5d:78:28:ae:88:33:61:db:cd:b6:80:1c:\n     88:62:b8:ce:cf:87:14:15:bd:27:9a:3e:77:cb:a1:e0:11:0d:\n     89:ef:f2:e8:b2:2c:cf:96:26:bd:06:3a:7b:8f:4b:fa:b2:c3:\n     f9:14:3e:18:ef:57:b5:37:95:01:a0:0f:bf:6e:5c:c9:47:7b:\n     1a:ed:ca:7a:31:a1:89:e8:0d:4d:95:d2:61:e3:b8:48:e5:86:\n     19:91:3e:00:86:07:50:df:e2:57:29:69:61:c4:cc:55:8f:60:\n     de:20:c1:0d:7d:c7:98:52:f4:34:08:90:c5:90:34:ec:86:0f:\n     ad:9b:e7:1a:d4:7b:d9:dd:59:82:de:54:d3:87:8e:e7:82:ae:\n     22:70:cf:e7:d7:8c:f1:55:57:6d:41:e6:44:3c:83:b7:73:7e:\n     9a:d5:1d:af:72:e9:4e:88:d4:4f:9f:33:2f:dc:1b:50:10:8b:\n     db:cd:e4:0e:e6:96:cd:c6:27:c7:4b:c7:9f:05:74:32:35:7e:\n     99:78:36:30:ae:78:4b:c3:1a:6b:b8:db:62:23:b8:ab:22:11:\n     11:81:95:5d:46:f0:45:15:77:1f:6b:c0:bf:9d:a2:d2:b4:62:\n     c9:b5:2b:dd</code></pre><p>4.将证书导出成浏览器支持的.p12格式 ：</p>\n<pre><code>$ openssl pkcs12 -export -clcerts -in server/server-cert.pem -inkey server/server-key.pem -out server/server.p12</code></pre><p>密码：changeit</p>\n<p>Additional：<br>因为server端的证书是由CA的private key签名(sign)server端的public key及其持有者的真实身份得到的, 因此server端证书里就包含server的public key.<br>就不需要用Openssl生成server端的public key. 用server端的<strong>csr（certificate signing requests）</strong>生成server证书即可. client端也一样.<br>client端只需要用CA的public key(CA的public key所有人都能获取)解密server端存放在CA的证书文件就可以得到Server端的public key.<br>然后client端就可以用解密得到的server端的public key对server端用自身private key加密的信息附带的摘要A(digest)进行解密.<br>client端将server端发过来的信息用Hash得到摘要B(digest)与解密得到的摘要A(digest)对比, 如果一直则说明信息没有被黑客篡改.<br>如果中间黑客把server端加密的摘要A(digest)修改了，则client用从CA的public key解密得到的server端的public key是解不开摘要A(digest)的, 说明摘要信息被黑客篡改, 内容不可靠.  </p>\n<p>如果要生成RSA公钥, command如下:</p>\n<pre><code>$ openssl rsa -in server/server-key.pem -pubout -out server/server-public-key.pem</code></pre><h3 id=\"三-生成client证书。\"><a href=\"#三-生成client证书。\" class=\"headerlink\" title=\"三.生成client证书。\"></a><strong>三.生成client证书。</strong></h3><p>1.创建私钥 ：</p>\n<table><tr><td bgcolor=#54FF9F>**client/client-key.pem**</td></tr></table>\n\n<pre><code>$ openssl genrsa -out client/client-key.pem 2048\n查看key\n$ openssl rsa -in client/client-key.pem -text -noout\n如果是DER格式的话,同理应该这样\n$ openssl rsa -in client/client-key.pem -text -noout -inform der</code></pre><p>2.创建证书请求 ：</p>\n<table><tr><td bgcolor=#54FF9F>**client/client-req.csr**</td></tr></table>\n\n<pre><code>$ openssl req -new -out client/client-req.csr -key client/client-key.pem\n  Country Name (2 letter code) [AU]:cn\n  State or Province Name (full name) [Some-State]:zhejiang\n  Locality Name (eg, city) []:hangzhou\n  Organization Name (eg, company) [Internet Widgits Pty Ltd]:skyvision\n  Organizational Unit Name (eg, section) []:test\n  Common Name (eg, YOUR name) []:sky\n  Email Address []:sky 注释：就是登入中心的用户（本来用户名应该是Common Name，但是中山公安的不知道为什么使用的Email Address，其他版本没有测试）\n  Please enter the following ‘extra’ attributes\n  to be sent with your certificate request\n  A challenge password []:123456\n  An optional company name []:tsing</code></pre><p>3.自签署证书 ：</p>\n<table><tr><td bgcolor=#54FF9F>**client/client-cert.pem**</td></tr></table>\n\n<pre><code>$ openssl x509 -req -in client/client-req.csr -out client/client-cert.pem -signkey client/client-key.pem -CA ca/ca-cert.pem -CAkey ca/ca-key.pem -CAcreateserial -days 3650\n * -CA选项指明用于被签名的csr证书\n * -CAkey选项指明用于签名的密钥\n * -CAcreateserial指明文件不存在时自动生成\n查看证书格式:\n$ openssl x509 -in client/client-cert.pem -text -noout</code></pre><p>4.将证书导出成浏览器支持的.p12格式 ：</p>\n<pre><code>$ openssl pkcs12 -export -clcerts -in client/client-cert.pem -inkey client/client-key.pem -out client/client.p12</code></pre><p>密码：changeit</p>\n<p>Additional. 生成RSA公钥:</p>\n<pre><code>$ openssl rsa -in client/client-key.pem -pubout -out client/client-public-key.pem</code></pre><p>请一定严格根据里面的步骤来，待实验成功后，修改你自己想要修改的内容。我就是一开始没有安装该填写的来，结果生成的证书就无法配对成功。</p>\n"},{"title":"TLS/SSL/HTTP/HTTPS protocol","_content":"\n## What is protocol\n网络协议通俗的讲是网络上两台计算机之间通信所要共同遵守的标准。协议规定了一种信息交流的格式和规范。协议本身并不是一种软件，只是一种通信的标准，协议最终需要由软件来实现，网络协议的实现就是在不同的软件和硬件环境下，执行可运行于开中环境的“协议”翻译程序。说白了就是软件要实现这个协议翻译程序，从而使双方遵守这某一协议。不同的网络交互软件的功能可能不同，但是都会翻译同一种网络协议。实现网络协议，就像是给所有接入网络的设备配备了一个“通用语言翻译器”，这些翻译都懂通用语言：例如国际上的英语，同时它也懂得本国的语言。这样就能实现不同国家不同环境的人接入同一个网络并进行交流。  \n\n**协议分层**：我用英语说：“How are you.” 不一定表示“你好！”，我们可以事先约定，这句话表示“再看一遍”的意思。这就象是所谓的江湖“黑话”，或叫“专业术语”。实际上，这时我们自己制定了一个新的通信标准，一个新的“高层协议”己经诞生了。这个协议在“英语”的基础上，再制定自己的通信标准，这种新的通信标准就是基于“英语”这种“底层协议”的“高层协议”，我们可以把这种协议取名为“讲课协议”。说白了协议的分层就是在一个既定的协议之上再添加某些限定条件。创造一个新的协议。比如果规定双方用英语交流，那么在使用英语交流的过程中，对英语中的“Hello”单词，定义他的意思是”帅哥“。那么它在双方交流的时候就被理解为帅哥的意思。这就是又制定了一个新的协议。协议除了分层之外，还可以组合，比如将IP协议，TCP协议以及UDP协议组合在一起称为TCP/IP协议。  \n\n所以说下面的SSL协议就是在TCP协议的基础上，又对信息传输做了某些规定，从而产生的一种新的协议。\n\n## HTTPS、TLS、SSL\nHTTPS，也称作HTTP over TLS。TLS的前身是SSL，TLS 1.0通常被标示为SSL 3.1，TLS 1.1为SSL 3.2，TLS 1.2为SSL 3.3。下图描述了在TCP/IP协议栈中TLS(各子协议)和HTTP的关系。  \n![](http_tls_ssl.png)\n\n## HTTPS protocol\n![](https.png)\n由于http明文传输，很不安全所以出现了https.\n\nhttps是由http“调用”SSL/TLS中的加密算法和协议逻辑，实现保密传输。\n\nhttps不能说是一个协议，只能说是一种应用。SSL加密http中的内容。然后默认使用433端口进行传输，SSL还可以加密Email，默认使用955，465端口。任何一个应用层协议都可以调用TLS/SSL来加密其明文数据。\n\n所以简单总结就是 : https = http + SSL/TLS  \nHTTPS在RFC2818被标准化, HTTPS工作在443端口，而HTTP默认工作在80端口。  \nHTTP的连接很简单,是无状态的。  \nHTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比HTTP协议安全。  \n\n从上面可看出，HTTPS和HTTP协议相比提供了  \n· 数据完整性：内容传输经过完整性校验  \n\n· 数据隐私性：内容经过对称加密，每个连接生成一个唯一的加密密钥  \n\n· 身份认证：第三方无法伪造服务端(客户端)身份  \n\n其中，数据完整性和隐私性由TLS Record Protocol保证，身份认证由TLS Handshaking Protocols实现。  \n\n## SSL protocol\nSSL协议（Secure Socket Layer安全套接层）是Netscape研发的，保障在Internet上数据传输安全的一个协议，它利用数据加密技术，可以确保数据在网络上的传输过程不被截取或者窃听。被广泛应用于Web浏览器和服务器之间的身份认证和加密数据传输。\n\nSSL协议位于TCP/IP协议与各种应用层协议之间。为数据通讯提供安全支持。\n\nSSL协议可以分为两层：\n\n**SSL记录协议**：建立在可靠的传输协议（如TCP）上，为高层协议提供数据封装，压缩，加密，解密基本功能。\n**SSL握手协议**：建立在SSL记录协议止尚，用于在实际的数据传输开始之前，通讯双方进行身份验证，协商加密算法，交换加密密钥等。\n\nEmail over SSL: \n类似于HTTP over SSL，邮件协议例如：  \n * SMTP，POP3、IMAP也能支持SSL。  \n * SMTP over TLS的标准文档在RFC2487  \n * POP3和IMAP over TLS的标准化文档在RFC2595.  \n\n## TLS protocol\nTLS协议Transport Layer Security 传输层安全）是SSL协议经历了SSL1.0,2.0,3.0版本后发展成为的一种新的安全标准协议。TLS有1.0，1.1，1.2，1.3这几个版本.  \n\nTLS全称是安全传输层协议，用于在两个通信应用程序之间提供保密性和数据完整性。\n\n该协议由两层组成：\n\n**TLS记录协议**，**TLS握手协议**，较底层的是TLS记录协议。位于某个可靠的传输协议（如TCP）之上。\n\n一次加密通信需要实现3个任务：机密性，完整性，身份认证。\n\n版本号：TLS记录合适与SSL记录格式相同，但是版本号值不同，TLS的版本1.0使用的版本号为SSLV3.1.\n\n## TLS/SSL在网络通信模型中的位置\n * 在OSI协议层中\n![](osi.png)\n7\t应用层  \napplication layer\t例如HTTP、SMTP、SNMP、FTP、Telnet、SIP、SSH、NFS、RTSP、XMPP、Whois、ENRP  \n6\t表示层  \npresentation layer\t例如XDR、ASN.1、SMB、AFP、NCP  \n5\t会话层  \nsession layer\t例如ASAP、SSH、ISO 8327 / CCITT X.225、RPC、NetBIOS、ASP、IGMP、Winsock、BSD sockets  \n4\t传输层  \ntransport layer\t例如TCP、UDP、TLS、RTP、SCTP、SPX、ATP、IL  \n3\t网络层  \nnetwork layer\t例如IP、ICMP、IPX、BGP、OSPF、RIP、IGRP、EIGRP、ARP、RARP、X.25  \n2\t数据链路层  \ndata link layer\t例如以太网、令牌环、HDLC、帧中继、ISDN、ATM、IEEE 802.11、FDDI、PPP  \n1\t物理层  \nphysical layer\t例如线路、无线电、光纤  \n\n * TCP/IP协议中\n![](tcp_ip.png)\n4\t应用层  \napplication layer\t例如HTTP、FTP、DNS  \n（如BGP和RIP这样的路由协议，尽管由于各种各样的原因它们分别运行在TCP和UDP上，仍然可以将它们看作网络层的一部分）  \n3\t传输层  \ntransport layer\t例如TCP、UDP、RTP、SCTP  \n（如OSPF这样的路由协议，尽管运行在IP上也可以看作是网络层的一部分）  \n2\t网络互连层  \ninternet layer\t对于TCP/IP来说这是因特网协议（IP）  \n（如ICMP和IGMP这样的必须协议尽管运行在IP上，也仍然可以看作是网络互连层的一部分；ARP不运行在IP上）  \n1\t网络接口层  \nlink layer\t例如以太网、Wi-Fi、MPLS等。  \n\n\n\n\n\n\n\n\n\n","source":"_posts/technologies/security/tls_ssl_https_http_protocol.md","raw":"---\ntitle: TLS/SSL/HTTP/HTTPS protocol\ntags: security\ncategories:\n- technologies\n- security\n---\n\n## What is protocol\n网络协议通俗的讲是网络上两台计算机之间通信所要共同遵守的标准。协议规定了一种信息交流的格式和规范。协议本身并不是一种软件，只是一种通信的标准，协议最终需要由软件来实现，网络协议的实现就是在不同的软件和硬件环境下，执行可运行于开中环境的“协议”翻译程序。说白了就是软件要实现这个协议翻译程序，从而使双方遵守这某一协议。不同的网络交互软件的功能可能不同，但是都会翻译同一种网络协议。实现网络协议，就像是给所有接入网络的设备配备了一个“通用语言翻译器”，这些翻译都懂通用语言：例如国际上的英语，同时它也懂得本国的语言。这样就能实现不同国家不同环境的人接入同一个网络并进行交流。  \n\n**协议分层**：我用英语说：“How are you.” 不一定表示“你好！”，我们可以事先约定，这句话表示“再看一遍”的意思。这就象是所谓的江湖“黑话”，或叫“专业术语”。实际上，这时我们自己制定了一个新的通信标准，一个新的“高层协议”己经诞生了。这个协议在“英语”的基础上，再制定自己的通信标准，这种新的通信标准就是基于“英语”这种“底层协议”的“高层协议”，我们可以把这种协议取名为“讲课协议”。说白了协议的分层就是在一个既定的协议之上再添加某些限定条件。创造一个新的协议。比如果规定双方用英语交流，那么在使用英语交流的过程中，对英语中的“Hello”单词，定义他的意思是”帅哥“。那么它在双方交流的时候就被理解为帅哥的意思。这就是又制定了一个新的协议。协议除了分层之外，还可以组合，比如将IP协议，TCP协议以及UDP协议组合在一起称为TCP/IP协议。  \n\n所以说下面的SSL协议就是在TCP协议的基础上，又对信息传输做了某些规定，从而产生的一种新的协议。\n\n## HTTPS、TLS、SSL\nHTTPS，也称作HTTP over TLS。TLS的前身是SSL，TLS 1.0通常被标示为SSL 3.1，TLS 1.1为SSL 3.2，TLS 1.2为SSL 3.3。下图描述了在TCP/IP协议栈中TLS(各子协议)和HTTP的关系。  \n![](http_tls_ssl.png)\n\n## HTTPS protocol\n![](https.png)\n由于http明文传输，很不安全所以出现了https.\n\nhttps是由http“调用”SSL/TLS中的加密算法和协议逻辑，实现保密传输。\n\nhttps不能说是一个协议，只能说是一种应用。SSL加密http中的内容。然后默认使用433端口进行传输，SSL还可以加密Email，默认使用955，465端口。任何一个应用层协议都可以调用TLS/SSL来加密其明文数据。\n\n所以简单总结就是 : https = http + SSL/TLS  \nHTTPS在RFC2818被标准化, HTTPS工作在443端口，而HTTP默认工作在80端口。  \nHTTP的连接很简单,是无状态的。  \nHTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比HTTP协议安全。  \n\n从上面可看出，HTTPS和HTTP协议相比提供了  \n· 数据完整性：内容传输经过完整性校验  \n\n· 数据隐私性：内容经过对称加密，每个连接生成一个唯一的加密密钥  \n\n· 身份认证：第三方无法伪造服务端(客户端)身份  \n\n其中，数据完整性和隐私性由TLS Record Protocol保证，身份认证由TLS Handshaking Protocols实现。  \n\n## SSL protocol\nSSL协议（Secure Socket Layer安全套接层）是Netscape研发的，保障在Internet上数据传输安全的一个协议，它利用数据加密技术，可以确保数据在网络上的传输过程不被截取或者窃听。被广泛应用于Web浏览器和服务器之间的身份认证和加密数据传输。\n\nSSL协议位于TCP/IP协议与各种应用层协议之间。为数据通讯提供安全支持。\n\nSSL协议可以分为两层：\n\n**SSL记录协议**：建立在可靠的传输协议（如TCP）上，为高层协议提供数据封装，压缩，加密，解密基本功能。\n**SSL握手协议**：建立在SSL记录协议止尚，用于在实际的数据传输开始之前，通讯双方进行身份验证，协商加密算法，交换加密密钥等。\n\nEmail over SSL: \n类似于HTTP over SSL，邮件协议例如：  \n * SMTP，POP3、IMAP也能支持SSL。  \n * SMTP over TLS的标准文档在RFC2487  \n * POP3和IMAP over TLS的标准化文档在RFC2595.  \n\n## TLS protocol\nTLS协议Transport Layer Security 传输层安全）是SSL协议经历了SSL1.0,2.0,3.0版本后发展成为的一种新的安全标准协议。TLS有1.0，1.1，1.2，1.3这几个版本.  \n\nTLS全称是安全传输层协议，用于在两个通信应用程序之间提供保密性和数据完整性。\n\n该协议由两层组成：\n\n**TLS记录协议**，**TLS握手协议**，较底层的是TLS记录协议。位于某个可靠的传输协议（如TCP）之上。\n\n一次加密通信需要实现3个任务：机密性，完整性，身份认证。\n\n版本号：TLS记录合适与SSL记录格式相同，但是版本号值不同，TLS的版本1.0使用的版本号为SSLV3.1.\n\n## TLS/SSL在网络通信模型中的位置\n * 在OSI协议层中\n![](osi.png)\n7\t应用层  \napplication layer\t例如HTTP、SMTP、SNMP、FTP、Telnet、SIP、SSH、NFS、RTSP、XMPP、Whois、ENRP  \n6\t表示层  \npresentation layer\t例如XDR、ASN.1、SMB、AFP、NCP  \n5\t会话层  \nsession layer\t例如ASAP、SSH、ISO 8327 / CCITT X.225、RPC、NetBIOS、ASP、IGMP、Winsock、BSD sockets  \n4\t传输层  \ntransport layer\t例如TCP、UDP、TLS、RTP、SCTP、SPX、ATP、IL  \n3\t网络层  \nnetwork layer\t例如IP、ICMP、IPX、BGP、OSPF、RIP、IGRP、EIGRP、ARP、RARP、X.25  \n2\t数据链路层  \ndata link layer\t例如以太网、令牌环、HDLC、帧中继、ISDN、ATM、IEEE 802.11、FDDI、PPP  \n1\t物理层  \nphysical layer\t例如线路、无线电、光纤  \n\n * TCP/IP协议中\n![](tcp_ip.png)\n4\t应用层  \napplication layer\t例如HTTP、FTP、DNS  \n（如BGP和RIP这样的路由协议，尽管由于各种各样的原因它们分别运行在TCP和UDP上，仍然可以将它们看作网络层的一部分）  \n3\t传输层  \ntransport layer\t例如TCP、UDP、RTP、SCTP  \n（如OSPF这样的路由协议，尽管运行在IP上也可以看作是网络层的一部分）  \n2\t网络互连层  \ninternet layer\t对于TCP/IP来说这是因特网协议（IP）  \n（如ICMP和IGMP这样的必须协议尽管运行在IP上，也仍然可以看作是网络互连层的一部分；ARP不运行在IP上）  \n1\t网络接口层  \nlink layer\t例如以太网、Wi-Fi、MPLS等。  \n\n\n\n\n\n\n\n\n\n","slug":"technologies/security/tls_ssl_https_http_protocol","published":1,"date":"2020-08-12T16:05:48.736Z","updated":"2020-08-10T16:33:47.732Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmoi009ehohx3zwu66wj","content":"<h2 id=\"What-is-protocol\"><a href=\"#What-is-protocol\" class=\"headerlink\" title=\"What is protocol\"></a>What is protocol</h2><p>网络协议通俗的讲是网络上两台计算机之间通信所要共同遵守的标准。协议规定了一种信息交流的格式和规范。协议本身并不是一种软件，只是一种通信的标准，协议最终需要由软件来实现，网络协议的实现就是在不同的软件和硬件环境下，执行可运行于开中环境的“协议”翻译程序。说白了就是软件要实现这个协议翻译程序，从而使双方遵守这某一协议。不同的网络交互软件的功能可能不同，但是都会翻译同一种网络协议。实现网络协议，就像是给所有接入网络的设备配备了一个“通用语言翻译器”，这些翻译都懂通用语言：例如国际上的英语，同时它也懂得本国的语言。这样就能实现不同国家不同环境的人接入同一个网络并进行交流。  </p>\n<p><strong>协议分层</strong>：我用英语说：“How are you.” 不一定表示“你好！”，我们可以事先约定，这句话表示“再看一遍”的意思。这就象是所谓的江湖“黑话”，或叫“专业术语”。实际上，这时我们自己制定了一个新的通信标准，一个新的“高层协议”己经诞生了。这个协议在“英语”的基础上，再制定自己的通信标准，这种新的通信标准就是基于“英语”这种“底层协议”的“高层协议”，我们可以把这种协议取名为“讲课协议”。说白了协议的分层就是在一个既定的协议之上再添加某些限定条件。创造一个新的协议。比如果规定双方用英语交流，那么在使用英语交流的过程中，对英语中的“Hello”单词，定义他的意思是”帅哥“。那么它在双方交流的时候就被理解为帅哥的意思。这就是又制定了一个新的协议。协议除了分层之外，还可以组合，比如将IP协议，TCP协议以及UDP协议组合在一起称为TCP/IP协议。  </p>\n<p>所以说下面的SSL协议就是在TCP协议的基础上，又对信息传输做了某些规定，从而产生的一种新的协议。</p>\n<h2 id=\"HTTPS、TLS、SSL\"><a href=\"#HTTPS、TLS、SSL\" class=\"headerlink\" title=\"HTTPS、TLS、SSL\"></a>HTTPS、TLS、SSL</h2><p>HTTPS，也称作HTTP over TLS。TLS的前身是SSL，TLS 1.0通常被标示为SSL 3.1，TLS 1.1为SSL 3.2，TLS 1.2为SSL 3.3。下图描述了在TCP/IP协议栈中TLS(各子协议)和HTTP的关系。<br><img src=\"http_tls_ssl.png\" alt=\"\"></p>\n<h2 id=\"HTTPS-protocol\"><a href=\"#HTTPS-protocol\" class=\"headerlink\" title=\"HTTPS protocol\"></a>HTTPS protocol</h2><p><img src=\"https.png\" alt=\"\"><br>由于http明文传输，很不安全所以出现了https.</p>\n<p>https是由http“调用”SSL/TLS中的加密算法和协议逻辑，实现保密传输。</p>\n<p>https不能说是一个协议，只能说是一种应用。SSL加密http中的内容。然后默认使用433端口进行传输，SSL还可以加密Email，默认使用955，465端口。任何一个应用层协议都可以调用TLS/SSL来加密其明文数据。</p>\n<p>所以简单总结就是 : https = http + SSL/TLS<br>HTTPS在RFC2818被标准化, HTTPS工作在443端口，而HTTP默认工作在80端口。<br>HTTP的连接很简单,是无状态的。<br>HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比HTTP协议安全。  </p>\n<p>从上面可看出，HTTPS和HTTP协议相比提供了<br>· 数据完整性：内容传输经过完整性校验  </p>\n<p>· 数据隐私性：内容经过对称加密，每个连接生成一个唯一的加密密钥  </p>\n<p>· 身份认证：第三方无法伪造服务端(客户端)身份  </p>\n<p>其中，数据完整性和隐私性由TLS Record Protocol保证，身份认证由TLS Handshaking Protocols实现。  </p>\n<h2 id=\"SSL-protocol\"><a href=\"#SSL-protocol\" class=\"headerlink\" title=\"SSL protocol\"></a>SSL protocol</h2><p>SSL协议（Secure Socket Layer安全套接层）是Netscape研发的，保障在Internet上数据传输安全的一个协议，它利用数据加密技术，可以确保数据在网络上的传输过程不被截取或者窃听。被广泛应用于Web浏览器和服务器之间的身份认证和加密数据传输。</p>\n<p>SSL协议位于TCP/IP协议与各种应用层协议之间。为数据通讯提供安全支持。</p>\n<p>SSL协议可以分为两层：</p>\n<p><strong>SSL记录协议</strong>：建立在可靠的传输协议（如TCP）上，为高层协议提供数据封装，压缩，加密，解密基本功能。<br><strong>SSL握手协议</strong>：建立在SSL记录协议止尚，用于在实际的数据传输开始之前，通讯双方进行身份验证，协商加密算法，交换加密密钥等。</p>\n<p>Email over SSL:<br>类似于HTTP over SSL，邮件协议例如：  </p>\n<ul>\n<li>SMTP，POP3、IMAP也能支持SSL。  </li>\n<li>SMTP over TLS的标准文档在RFC2487  </li>\n<li>POP3和IMAP over TLS的标准化文档在RFC2595.  </li>\n</ul>\n<h2 id=\"TLS-protocol\"><a href=\"#TLS-protocol\" class=\"headerlink\" title=\"TLS protocol\"></a>TLS protocol</h2><p>TLS协议Transport Layer Security 传输层安全）是SSL协议经历了SSL1.0,2.0,3.0版本后发展成为的一种新的安全标准协议。TLS有1.0，1.1，1.2，1.3这几个版本.  </p>\n<p>TLS全称是安全传输层协议，用于在两个通信应用程序之间提供保密性和数据完整性。</p>\n<p>该协议由两层组成：</p>\n<p><strong>TLS记录协议</strong>，<strong>TLS握手协议</strong>，较底层的是TLS记录协议。位于某个可靠的传输协议（如TCP）之上。</p>\n<p>一次加密通信需要实现3个任务：机密性，完整性，身份认证。</p>\n<p>版本号：TLS记录合适与SSL记录格式相同，但是版本号值不同，TLS的版本1.0使用的版本号为SSLV3.1.</p>\n<h2 id=\"TLS-SSL在网络通信模型中的位置\"><a href=\"#TLS-SSL在网络通信模型中的位置\" class=\"headerlink\" title=\"TLS/SSL在网络通信模型中的位置\"></a>TLS/SSL在网络通信模型中的位置</h2><ul>\n<li><p>在OSI协议层中<br><img src=\"osi.png\" alt=\"\"><br>7    应用层<br>application layer    例如HTTP、SMTP、SNMP、FTP、Telnet、SIP、SSH、NFS、RTSP、XMPP、Whois、ENRP<br>6    表示层<br>presentation layer    例如XDR、ASN.1、SMB、AFP、NCP<br>5    会话层<br>session layer    例如ASAP、SSH、ISO 8327 / CCITT X.225、RPC、NetBIOS、ASP、IGMP、Winsock、BSD sockets<br>4    传输层<br>transport layer    例如TCP、UDP、TLS、RTP、SCTP、SPX、ATP、IL<br>3    网络层<br>network layer    例如IP、ICMP、IPX、BGP、OSPF、RIP、IGRP、EIGRP、ARP、RARP、X.25<br>2    数据链路层<br>data link layer    例如以太网、令牌环、HDLC、帧中继、ISDN、ATM、IEEE 802.11、FDDI、PPP<br>1    物理层<br>physical layer    例如线路、无线电、光纤  </p>\n</li>\n<li><p>TCP/IP协议中<br><img src=\"tcp_ip.png\" alt=\"\"><br>4    应用层<br>application layer    例如HTTP、FTP、DNS<br>（如BGP和RIP这样的路由协议，尽管由于各种各样的原因它们分别运行在TCP和UDP上，仍然可以将它们看作网络层的一部分）<br>3    传输层<br>transport layer    例如TCP、UDP、RTP、SCTP<br>（如OSPF这样的路由协议，尽管运行在IP上也可以看作是网络层的一部分）<br>2    网络互连层<br>internet layer    对于TCP/IP来说这是因特网协议（IP）<br>（如ICMP和IGMP这样的必须协议尽管运行在IP上，也仍然可以看作是网络互连层的一部分；ARP不运行在IP上）<br>1    网络接口层<br>link layer    例如以太网、Wi-Fi、MPLS等。  </p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"What-is-protocol\"><a href=\"#What-is-protocol\" class=\"headerlink\" title=\"What is protocol\"></a>What is protocol</h2><p>网络协议通俗的讲是网络上两台计算机之间通信所要共同遵守的标准。协议规定了一种信息交流的格式和规范。协议本身并不是一种软件，只是一种通信的标准，协议最终需要由软件来实现，网络协议的实现就是在不同的软件和硬件环境下，执行可运行于开中环境的“协议”翻译程序。说白了就是软件要实现这个协议翻译程序，从而使双方遵守这某一协议。不同的网络交互软件的功能可能不同，但是都会翻译同一种网络协议。实现网络协议，就像是给所有接入网络的设备配备了一个“通用语言翻译器”，这些翻译都懂通用语言：例如国际上的英语，同时它也懂得本国的语言。这样就能实现不同国家不同环境的人接入同一个网络并进行交流。  </p>\n<p><strong>协议分层</strong>：我用英语说：“How are you.” 不一定表示“你好！”，我们可以事先约定，这句话表示“再看一遍”的意思。这就象是所谓的江湖“黑话”，或叫“专业术语”。实际上，这时我们自己制定了一个新的通信标准，一个新的“高层协议”己经诞生了。这个协议在“英语”的基础上，再制定自己的通信标准，这种新的通信标准就是基于“英语”这种“底层协议”的“高层协议”，我们可以把这种协议取名为“讲课协议”。说白了协议的分层就是在一个既定的协议之上再添加某些限定条件。创造一个新的协议。比如果规定双方用英语交流，那么在使用英语交流的过程中，对英语中的“Hello”单词，定义他的意思是”帅哥“。那么它在双方交流的时候就被理解为帅哥的意思。这就是又制定了一个新的协议。协议除了分层之外，还可以组合，比如将IP协议，TCP协议以及UDP协议组合在一起称为TCP/IP协议。  </p>\n<p>所以说下面的SSL协议就是在TCP协议的基础上，又对信息传输做了某些规定，从而产生的一种新的协议。</p>\n<h2 id=\"HTTPS、TLS、SSL\"><a href=\"#HTTPS、TLS、SSL\" class=\"headerlink\" title=\"HTTPS、TLS、SSL\"></a>HTTPS、TLS、SSL</h2><p>HTTPS，也称作HTTP over TLS。TLS的前身是SSL，TLS 1.0通常被标示为SSL 3.1，TLS 1.1为SSL 3.2，TLS 1.2为SSL 3.3。下图描述了在TCP/IP协议栈中TLS(各子协议)和HTTP的关系。<br><img src=\"http_tls_ssl.png\" alt=\"\"></p>\n<h2 id=\"HTTPS-protocol\"><a href=\"#HTTPS-protocol\" class=\"headerlink\" title=\"HTTPS protocol\"></a>HTTPS protocol</h2><p><img src=\"https.png\" alt=\"\"><br>由于http明文传输，很不安全所以出现了https.</p>\n<p>https是由http“调用”SSL/TLS中的加密算法和协议逻辑，实现保密传输。</p>\n<p>https不能说是一个协议，只能说是一种应用。SSL加密http中的内容。然后默认使用433端口进行传输，SSL还可以加密Email，默认使用955，465端口。任何一个应用层协议都可以调用TLS/SSL来加密其明文数据。</p>\n<p>所以简单总结就是 : https = http + SSL/TLS<br>HTTPS在RFC2818被标准化, HTTPS工作在443端口，而HTTP默认工作在80端口。<br>HTTP的连接很简单,是无状态的。<br>HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比HTTP协议安全。  </p>\n<p>从上面可看出，HTTPS和HTTP协议相比提供了<br>· 数据完整性：内容传输经过完整性校验  </p>\n<p>· 数据隐私性：内容经过对称加密，每个连接生成一个唯一的加密密钥  </p>\n<p>· 身份认证：第三方无法伪造服务端(客户端)身份  </p>\n<p>其中，数据完整性和隐私性由TLS Record Protocol保证，身份认证由TLS Handshaking Protocols实现。  </p>\n<h2 id=\"SSL-protocol\"><a href=\"#SSL-protocol\" class=\"headerlink\" title=\"SSL protocol\"></a>SSL protocol</h2><p>SSL协议（Secure Socket Layer安全套接层）是Netscape研发的，保障在Internet上数据传输安全的一个协议，它利用数据加密技术，可以确保数据在网络上的传输过程不被截取或者窃听。被广泛应用于Web浏览器和服务器之间的身份认证和加密数据传输。</p>\n<p>SSL协议位于TCP/IP协议与各种应用层协议之间。为数据通讯提供安全支持。</p>\n<p>SSL协议可以分为两层：</p>\n<p><strong>SSL记录协议</strong>：建立在可靠的传输协议（如TCP）上，为高层协议提供数据封装，压缩，加密，解密基本功能。<br><strong>SSL握手协议</strong>：建立在SSL记录协议止尚，用于在实际的数据传输开始之前，通讯双方进行身份验证，协商加密算法，交换加密密钥等。</p>\n<p>Email over SSL:<br>类似于HTTP over SSL，邮件协议例如：  </p>\n<ul>\n<li>SMTP，POP3、IMAP也能支持SSL。  </li>\n<li>SMTP over TLS的标准文档在RFC2487  </li>\n<li>POP3和IMAP over TLS的标准化文档在RFC2595.  </li>\n</ul>\n<h2 id=\"TLS-protocol\"><a href=\"#TLS-protocol\" class=\"headerlink\" title=\"TLS protocol\"></a>TLS protocol</h2><p>TLS协议Transport Layer Security 传输层安全）是SSL协议经历了SSL1.0,2.0,3.0版本后发展成为的一种新的安全标准协议。TLS有1.0，1.1，1.2，1.3这几个版本.  </p>\n<p>TLS全称是安全传输层协议，用于在两个通信应用程序之间提供保密性和数据完整性。</p>\n<p>该协议由两层组成：</p>\n<p><strong>TLS记录协议</strong>，<strong>TLS握手协议</strong>，较底层的是TLS记录协议。位于某个可靠的传输协议（如TCP）之上。</p>\n<p>一次加密通信需要实现3个任务：机密性，完整性，身份认证。</p>\n<p>版本号：TLS记录合适与SSL记录格式相同，但是版本号值不同，TLS的版本1.0使用的版本号为SSLV3.1.</p>\n<h2 id=\"TLS-SSL在网络通信模型中的位置\"><a href=\"#TLS-SSL在网络通信模型中的位置\" class=\"headerlink\" title=\"TLS/SSL在网络通信模型中的位置\"></a>TLS/SSL在网络通信模型中的位置</h2><ul>\n<li><p>在OSI协议层中<br><img src=\"osi.png\" alt=\"\"><br>7    应用层<br>application layer    例如HTTP、SMTP、SNMP、FTP、Telnet、SIP、SSH、NFS、RTSP、XMPP、Whois、ENRP<br>6    表示层<br>presentation layer    例如XDR、ASN.1、SMB、AFP、NCP<br>5    会话层<br>session layer    例如ASAP、SSH、ISO 8327 / CCITT X.225、RPC、NetBIOS、ASP、IGMP、Winsock、BSD sockets<br>4    传输层<br>transport layer    例如TCP、UDP、TLS、RTP、SCTP、SPX、ATP、IL<br>3    网络层<br>network layer    例如IP、ICMP、IPX、BGP、OSPF、RIP、IGRP、EIGRP、ARP、RARP、X.25<br>2    数据链路层<br>data link layer    例如以太网、令牌环、HDLC、帧中继、ISDN、ATM、IEEE 802.11、FDDI、PPP<br>1    物理层<br>physical layer    例如线路、无线电、光纤  </p>\n</li>\n<li><p>TCP/IP协议中<br><img src=\"tcp_ip.png\" alt=\"\"><br>4    应用层<br>application layer    例如HTTP、FTP、DNS<br>（如BGP和RIP这样的路由协议，尽管由于各种各样的原因它们分别运行在TCP和UDP上，仍然可以将它们看作网络层的一部分）<br>3    传输层<br>transport layer    例如TCP、UDP、RTP、SCTP<br>（如OSPF这样的路由协议，尽管运行在IP上也可以看作是网络层的一部分）<br>2    网络互连层<br>internet layer    对于TCP/IP来说这是因特网协议（IP）<br>（如ICMP和IGMP这样的必须协议尽管运行在IP上，也仍然可以看作是网络互连层的一部分；ARP不运行在IP上）<br>1    网络接口层<br>link layer    例如以太网、Wi-Fi、MPLS等。  </p>\n</li>\n</ul>\n"},{"title":"Token jwt","_content":"\n# Reference\n * [csdn blog](https://www.cnblogs.com/MyCode1990/p/13096423.html)\n * [简书](https://www.jianshu.com/p/4941a269a9d8)\n\n# **Json Web Token(JWT)简介**\nJWT属于Token验证方式的一种方法.\n> JSON Web Token（JWT）是一个开放标准（RFC 7519），它定义了一种紧凑的、自包含的方式，用于作为JSON对象在各方之间安全地传输信息。此信息可以验证和信任，因为它是数字签名的。JWTs可以使用密钥（使用HMAC算法）或使用RSA或ECDSA的公钥/私钥对进行签名.\n\n# **传统服务端验证客户端身份的方法**\nHTTP 是一种没有状态的协议，也就是它并不知道是谁是访问应用。这里我们把用户看成是客户端，客户端使用用户名还有密码通过了身份验证，不过下回这个客户端再发送请求时候，还得再验证一下。\n\n解决的方法就是，当用户请求登录的时候，如果没有问题，我们在服务端生成一条记录，这个记录里可以说明一下登录的用户是谁，然后把这条记录的 ID 号发送给客户端，客户端收到以后把这个 ID 号存储在 Cookie 里，下次这个用户再向服务端发送请求的时候，可以带着这个 Cookie ，这样服务端会验证一个这个 Cookie 里的信息，看看能不能在服务端这里找到对应的记录，如果可以，说明用户已经通过了身份验证，就把用户请求的数据返回给客户端。\n\n上面说的就是 Session，我们需要在服务端存储为登录的用户生成的 Session ，这些 Session 可能会存储在内存，磁盘，或者数据库里。我们可能需要在服务端定期的去清理过期的 Session 。\n\n# **基于 Token 的身份验证方法**\nToken是在客户端频繁向服务端请求数据，服务端频繁的去数据库查询用户名和密码并进行对比，判断用户名和密码正确与否，并作出相应提示，在这样的背景下，Token便应运而生。  \nToken是服务端生成的一串字符串，以作客户端进行请求的一个令牌，当第一次登录后，服务器生成一个Token便将此Token返回给客户端，以后客户端只需带上这个Token前来请求数据即可，无需再次带上用户名和密码。  \n使用基于 Token 的身份验证方法，在服务端不需要存储用户的登录记录。大概的流程是这样的：\n 1. 客户端使用用户名跟密码请求登录\n 2. 服务端收到请求，去验证用户名与密码\n 3. 验证成功后，服务端会签发一个 Token，再把这个 Token 发送给客户端\n 4. 客户端收到 Token 以后可以把它存储起来，比如放在 Cookie 里或者 Local Storage 里\n 5. 客户端每次向服务端请求资源的时候需要带着服务端签发的 Token\n 6. 服务端收到请求，然后去验证客户端请求里面带着的 Token，如果验证成功，就向客户端返回请求的数据\n\n# **为什么要使用JSON Web Token**\n * Token的目的是为了减轻服务器的压力，减少频繁的查询数据库，使服务器更加健壮.\n * JSON比XML不那么冗长，当它被编码时，它的大小也更小，使得JWT比SAML更紧凑。这使得JWT成为在HTML和HTTP环境中传递的一个很好的选择。\n * 安全方面，使用HMAC算法，SWT只能由共享密钥对称签名。但是，JWT和SAML令牌可以使用X.509证书形式的公钥/私钥对进行签名。与签名JSON的简单性相比，使用XML数字签名来签名XML而不引入隐藏的安全漏洞是非常困难的。\n * JSON解析器在大多数编程语言中都很常见，因为它们直接映射到对象。相反，XML没有自然的文档到对象的映射。这使得使用JWT比使用SAML断言更容易。\n * 在使用方面，JWT是在互联网上使用的。这突出了JSON Web令牌在多个平台（尤其是移动平台）上客户端处理的方便性。\n * 比较编码JWT和编码SAML的长度.\n\n# **JWT(Json Web Token 一种Token验证方法)**\n\n实施 Token 验证的方法挺多的，还有一些标准方法，比如 JWT，读作：jot ，表示：JSON Web Tokens 。JWT 标准的 Token 有三个部分：\n\n * header（头部）\n * payload（荷载,数据）\n * signature（签名）\n中间用点分隔开，并且都会使用 Base64 编码，所以真正的 Token 看起来像这样：\n\n\teyJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ.SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc\n\n\n## **Header 头部**\n * 令牌的类型\n * 正在使用的签名算法(HMAC, SHA256, RSA等)。\n\n每个 JWT token 里面都有一个 header，也就是头部数据。里面包含了使用的算法，这个 JWT 是不是带签名的或者加密的。主要就是说明一下怎么处理这个 JWT token 。  \n头部里包含的东西可能会根据 JWT 的类型有所变化，比如一个加密的 JWT 里面要包含使用的加密的算法。唯一在头部里面要包含的是 alg 这个属性，如果是加密的 JWT，这个属性的值就是使用的签名或者解密用的算法。如果是未加密的 JWT，这个属性的值要设置成 none。  \n示例：\n\n\t{\n\t  \"typ\": \"JWT\",\n\t  \"alg\": \"HS256\"\n\t}\n意思是这个 JWT 用的算法是 HS256。上面的内容得用 base64url 的形式编码一下，所以就变成这样：\n\n\teyJhbGciOiJIUzI1NiJ9\n\n## **Payload 有效负载**\n有效负载包含了\"声明(claims)\", 有三种类型的claims：\n * registered claims 已注册的 (不是强制的，而是推荐,iss（发行者）、exp（到期时间）、sub（主题）、aud（受众）和其他)\n * public claims 公开的 (可以由使用JWT的用户随意定义, 为了避免冲突，应该在[IANA JSON Web令牌注册表](https://www.iana.org/assignments/jwt/jwt.xhtml)中定义它们，或者将它们定义为包含防冲突命名空间的URI)\n * private claims 私有的\n\nPayload 里面是 Token 的具体内容，这些内容里面有一些是标准字段，你也可以添加其它需要的内容。下面是标准字段：\n * iss：Issuer，发行者\n * sub：Subject，主题\n * aud：Audience，观众\n * exp：Expiration time，过期时间\n * nbf：Not before\n * iat：Issued at，发行时间\n * jti：JWT ID\n\n比如下面这个 Payload ，用到了 iss 发行人，还有 exp 过期时间这两个标准字段。另外还有两个自定义的字段，一个是 name ，还有一个是 admin 。\n\n\t{\n\t  \"sub\": \"1234567890\",\n\t  \"name\": \"John Doe\",\n\t  \"iss\": \"ninghao.net\",\n\t  \"exp\": \"1438955445\",\n\t  \"admin\": true\n\t}\n使用 base64url 编码以后就变成了这个样子：\n\n\t eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ\n**请注意，对于已签名的令牌，此信息虽然受保护不受篡改，但任何人都可以读取。除非经过加密，否则不要将机密信息放在JWT的有效负载或头部**.\n\n## **Signature 签名**\n要创建签名部分，您必须已经有了 经过编码的**头部**、经过编码的**负载**、一个**秘钥**、在头部中指定的**算法**，这样就可以进行签名了.  \nSignature这部分内容有三个部分，先是用 Base64 编码的 header.payload ，再用加密算法加密一下，加密的时候要放进去一个 Secret ，这个相当于是一个密码，这个密码秘密地存储在服务端。  \n\n * header\n * payload\n * secret\n\n\n\tconst encodedString = base64UrlEncode(header) + \".\" + base64UrlEncode(payload); \n\tHMACSHA256(encodedString, 'secret');\n处理完成以后看起来像这样：\n\n\t SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc\n最后这个在服务端生成并且要发送给客户端的 Token 看起来像这样：\n\n\t eyJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ.SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc\n输出的内容是三个由点分隔的Base64 URL字符串。它可以在HTML和HTTP环境中轻松传递，它比XML的标准（如SAML）更加紧凑.  \n客户端收到这个 Token 以后把它存储下来，下回向服务端发送请求的时候就带着这个 Token 。服务端收到这个 Token ，然后进行验证，通过以后就会返回给客户端想要的资源。\n\n## **签名的作用:**  \n(1) 签名用于验证消息在传输过程中没有被更改。\n(2) 使用私钥签名的令牌，还可以验证JWT的发送者是它所说的发送者。\n\n# **签发 Json Web Token(JWT)**\n * JWT 对 “信息” 进行签名，产生一个令牌。\n * 签名的令牌可以验证其中包含的内容的完整性（防篡改）。\n * 也可对“信息”加密，加密的令牌则对其他方隐藏这些内容。\n * 当令牌使用公钥/私钥对签名时，签名还证明只有持有私钥的一方才是签名方。可以非对称加密方式证明了\n\n\n## **HS256 算法签发Json Web Token(JWT)**\n这种算法需要一个密钥（密码）.  \n在项目里随便添加一个 .js 文件，比如 index.js，在文件里添加下面这些代码：  \n\n\tconst jwt = require('jsonwebtoken')\n\t// Token 数据\n\tconst payload = {\n\tname: 'wanghao',\n\tadmin: true\n\t}\n\t// 密钥\n\tconst secret = 'ILOVENINGHAO'\n\t// 签发 Token\n\tconst token = jwt.sign(payload, secret, { expiresIn: '1day' })\n\t// 输出签发的 Token\n\tconsole.log(token)\n非常简单，就是用了刚刚为项目安装的 jsonwebtoken 里面提供的 jwt.sign 功能，去签发一个 token。这个 sign 方法需要三个参数：\n * playload：签发的 token 里面要包含的一些数据。\n * secret：签发 token 用的密钥，在验证 token 的时候同样需要用到这个密钥。\n * options：一些其它的选项。\n\n在命令行下面，用 node 命令，执行一下项目里的 index.js 这个文件（node index.js），会输出应用签发的 token：\n\n\teyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlLCJpYXQiOjE1MjkwMzM5MDYsImV4cCI6MTUyOTEyMDMwNn0.DctA2QlUCrM6wLWkIO78wBVN0NLpjoIq4T5B_2WJ-PU\n上面的 Token 内容并没有加密，所以如果用一些 JWT 解码功能，可以看到 Token 里面包含的内容，内容由三个部分组成，像这样：\n\n\t// header\n\t{\n\t  \"alg\": \"HS256\", \n\t  \"typ\": \"JWT\"\n\t}\n\t// payload\n\t{\n\t  \"admin\": true, \n\t  \"iat\": 1529033906, \n\t  \"name\": \"wanghao\", \n\t  \"exp\": 1529120306\n\t}\n\t// signature\n\tDctA2QlUCrM6wLWkIO78wBVN0NLpjoIq4T5B_2WJ-PU\n> 假设用户通过了某种身份验证，你就可以使用上面的签发 Token 的功能为用户签发一个 Token。一般在客户端那里会把它保存在 Cookie 或 LocalStorage 里面。\n> 用户下次向我们的应用请求受保护的资源的时候，可以在请求里带着我们给它签发的这个 Token，后端应用收到请求，检查签名，如果验证通过确定这个 Token 是我们自己签发的，那就可以为用户响应回他需要的资源。\n\n## **RS256 算法签发Json Web Token(JWT)**\n默认签发还有验证 Token 的时候用的是 HS256 算法，这种算法需要一个密钥（密码）。我们还可以使用 RS256 算法签发与验证 JWT。这种方法可以让我们分离开签发与验证，签发时需要用一个密钥，验证时使用公钥，也就是有公钥的地方只能做验证，但不能签发 JWT。\n\n在项目下面创建一个新的目录，里面可以存储即将生成的密钥与公钥文件。\n\n\t$ cd ~/desktop/jwt-demo\n\t$ mkdir config\n\t$ cd config\n**密钥:**\n先生成一个密钥文件：\n\n\t ssh-keygen -t rsa -b 2048 -f private.key\n**公钥:**\n基于上面生成的密钥，再去创建一个对应的公钥：\n\n\t openssl rsa -in private.key -pubout -outform PEM -out public.key\n**签发 JWT（RS256 算法）**\n用 RS256 算法签发 JWT 的时候，需要从文件系统上读取创建的密钥文件里的内容。\n\n\t const fs = require('fs')\n\t // 获取签发 JWT 时需要用的密钥\n\t const privateKey = fs.readFileSync('./config/private.key')\n\t 签发仍然使用 jwt.sign 方法，只不过在选项参数里特别说明一下使用的算法是 RS256：\n\t // 签发 Token\n\t const tokenRS256 = jwt.sign(payload, privateKey, { algorithm: 'RS256' })\n\t // 输出签发的 Token\n\t console.log('RS256 算法：', tokenRS256)\n\n# **验证Json Web Token(JWT)**\n\n## **HS256 算法验证Json Web TOken(JWT)**\n需要一个签发token时候用的密钥（密码）来验证,这种算法需要一个密钥（密码）.  \n验证 JWT 的用效性，确定一下用户的 JWT 是我们自己签发的，首先要得到用户的这个 JWT Token，然后用 jwt.verify 这个方法去做一下验证。这个方法是 Node.js 的 jsonwebtoken 这个包里提供的，在其它的应用框架或者系统里，你可能会找到类似的方法来验证 JWT。  \n打开项目的 index.js 文件，里面添加几行代码：\n\n\t// 验证 Token\n\tjwt.verify(token, 'bad secret', (error, decoded) => {\n\t  if (error) {\n\t    console.log(error.message)\n\t    return\n\t  }\n\t  console.log(decoded)\n\t})\n把要验证的 Token 数据，还有签发这个 Token 的时候用的那个密钥告诉 verify 这个方法，在一个回调里面有两个参数，error 表示错误，decoded 是解码之后的 Token 数据。\n\n执行：\n\n\t$ node ~/desktop/jwt-demo/index.js\n输出：\n\n\teyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlLCJpYXQiOjE1MjkwMzQ3MzMsImV4cCI6MTUyOTEyMTEzM30.swXojmu7VimFu3BoIgAxxpmm2J05dvD0HT3yu10vuqU\n\tinvalid signature\n注意输出了一个 invalid signature ，表示 Token 里的签名不对，这是因为我们组长 verify 方法提供的密钥并不是签发 Token 的时候用的那个密钥。这样修改一下：\n\n\tjwt.verify(token, secret, (error, decoded) => { ...\n再次运行，会输出类似的数据：\n\n\teyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlLCJpYXQiOjE1MjkwMzUzODYsImV4cCI6MTUyOTEyMTc4Nn0.mkNrt4TfcfmP22xd3C_GQn8qnUmlB39dKT9SpIBTBGI\n\t{ name: 'wanghao', admin: true, iat: 1529035386, exp: 1529121786 }\n\n## **RS256 算法验证Json Web Token(JWT)**\n验证 JWT（RS256 算法）\n验证使用 RS256 算法签发的 JWT，需要在文件系统上读取公钥文件里的内容。然后用 jwt 的 verify 方法去做验证。\n\n\t// 获取验证 JWT 时需要用的公钥\n\tconst publicKey = fs.readFileSync('./config/public.key')\n\t\n\t// 验证 Token\n\tjwt.verify(tokenRS256, publicKey, (error, decoded) => {\n\t  if (error) {\n\t    console.log(error.message)\n\t    return\n\t  }\n\t  console.log(decoded)\n\t})\n\n# **使用场景**\n![](token_scene1.png)\n\n1. 应用程序或客户端，向授权服务器请求授权。\n2. 当授权被通过时，授权服务器将向应用程序返回一个访问令牌token。\n3. 应用程序使用访问令牌访问受保护的资源。\n**请注意，使用签名的令牌，令牌中包含的所有信息都将公开给用户或其他方（虽然他们无法更改它，但可以阅读）。这意味着您不应将机密信息放入令牌中.**\n\n\n\n","source":"_posts/technologies/security/token_jwt.md","raw":"---\ntitle: Token jwt\ntags: security\ncategories:\n- technologies\n- security\n---\n\n# Reference\n * [csdn blog](https://www.cnblogs.com/MyCode1990/p/13096423.html)\n * [简书](https://www.jianshu.com/p/4941a269a9d8)\n\n# **Json Web Token(JWT)简介**\nJWT属于Token验证方式的一种方法.\n> JSON Web Token（JWT）是一个开放标准（RFC 7519），它定义了一种紧凑的、自包含的方式，用于作为JSON对象在各方之间安全地传输信息。此信息可以验证和信任，因为它是数字签名的。JWTs可以使用密钥（使用HMAC算法）或使用RSA或ECDSA的公钥/私钥对进行签名.\n\n# **传统服务端验证客户端身份的方法**\nHTTP 是一种没有状态的协议，也就是它并不知道是谁是访问应用。这里我们把用户看成是客户端，客户端使用用户名还有密码通过了身份验证，不过下回这个客户端再发送请求时候，还得再验证一下。\n\n解决的方法就是，当用户请求登录的时候，如果没有问题，我们在服务端生成一条记录，这个记录里可以说明一下登录的用户是谁，然后把这条记录的 ID 号发送给客户端，客户端收到以后把这个 ID 号存储在 Cookie 里，下次这个用户再向服务端发送请求的时候，可以带着这个 Cookie ，这样服务端会验证一个这个 Cookie 里的信息，看看能不能在服务端这里找到对应的记录，如果可以，说明用户已经通过了身份验证，就把用户请求的数据返回给客户端。\n\n上面说的就是 Session，我们需要在服务端存储为登录的用户生成的 Session ，这些 Session 可能会存储在内存，磁盘，或者数据库里。我们可能需要在服务端定期的去清理过期的 Session 。\n\n# **基于 Token 的身份验证方法**\nToken是在客户端频繁向服务端请求数据，服务端频繁的去数据库查询用户名和密码并进行对比，判断用户名和密码正确与否，并作出相应提示，在这样的背景下，Token便应运而生。  \nToken是服务端生成的一串字符串，以作客户端进行请求的一个令牌，当第一次登录后，服务器生成一个Token便将此Token返回给客户端，以后客户端只需带上这个Token前来请求数据即可，无需再次带上用户名和密码。  \n使用基于 Token 的身份验证方法，在服务端不需要存储用户的登录记录。大概的流程是这样的：\n 1. 客户端使用用户名跟密码请求登录\n 2. 服务端收到请求，去验证用户名与密码\n 3. 验证成功后，服务端会签发一个 Token，再把这个 Token 发送给客户端\n 4. 客户端收到 Token 以后可以把它存储起来，比如放在 Cookie 里或者 Local Storage 里\n 5. 客户端每次向服务端请求资源的时候需要带着服务端签发的 Token\n 6. 服务端收到请求，然后去验证客户端请求里面带着的 Token，如果验证成功，就向客户端返回请求的数据\n\n# **为什么要使用JSON Web Token**\n * Token的目的是为了减轻服务器的压力，减少频繁的查询数据库，使服务器更加健壮.\n * JSON比XML不那么冗长，当它被编码时，它的大小也更小，使得JWT比SAML更紧凑。这使得JWT成为在HTML和HTTP环境中传递的一个很好的选择。\n * 安全方面，使用HMAC算法，SWT只能由共享密钥对称签名。但是，JWT和SAML令牌可以使用X.509证书形式的公钥/私钥对进行签名。与签名JSON的简单性相比，使用XML数字签名来签名XML而不引入隐藏的安全漏洞是非常困难的。\n * JSON解析器在大多数编程语言中都很常见，因为它们直接映射到对象。相反，XML没有自然的文档到对象的映射。这使得使用JWT比使用SAML断言更容易。\n * 在使用方面，JWT是在互联网上使用的。这突出了JSON Web令牌在多个平台（尤其是移动平台）上客户端处理的方便性。\n * 比较编码JWT和编码SAML的长度.\n\n# **JWT(Json Web Token 一种Token验证方法)**\n\n实施 Token 验证的方法挺多的，还有一些标准方法，比如 JWT，读作：jot ，表示：JSON Web Tokens 。JWT 标准的 Token 有三个部分：\n\n * header（头部）\n * payload（荷载,数据）\n * signature（签名）\n中间用点分隔开，并且都会使用 Base64 编码，所以真正的 Token 看起来像这样：\n\n\teyJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ.SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc\n\n\n## **Header 头部**\n * 令牌的类型\n * 正在使用的签名算法(HMAC, SHA256, RSA等)。\n\n每个 JWT token 里面都有一个 header，也就是头部数据。里面包含了使用的算法，这个 JWT 是不是带签名的或者加密的。主要就是说明一下怎么处理这个 JWT token 。  \n头部里包含的东西可能会根据 JWT 的类型有所变化，比如一个加密的 JWT 里面要包含使用的加密的算法。唯一在头部里面要包含的是 alg 这个属性，如果是加密的 JWT，这个属性的值就是使用的签名或者解密用的算法。如果是未加密的 JWT，这个属性的值要设置成 none。  \n示例：\n\n\t{\n\t  \"typ\": \"JWT\",\n\t  \"alg\": \"HS256\"\n\t}\n意思是这个 JWT 用的算法是 HS256。上面的内容得用 base64url 的形式编码一下，所以就变成这样：\n\n\teyJhbGciOiJIUzI1NiJ9\n\n## **Payload 有效负载**\n有效负载包含了\"声明(claims)\", 有三种类型的claims：\n * registered claims 已注册的 (不是强制的，而是推荐,iss（发行者）、exp（到期时间）、sub（主题）、aud（受众）和其他)\n * public claims 公开的 (可以由使用JWT的用户随意定义, 为了避免冲突，应该在[IANA JSON Web令牌注册表](https://www.iana.org/assignments/jwt/jwt.xhtml)中定义它们，或者将它们定义为包含防冲突命名空间的URI)\n * private claims 私有的\n\nPayload 里面是 Token 的具体内容，这些内容里面有一些是标准字段，你也可以添加其它需要的内容。下面是标准字段：\n * iss：Issuer，发行者\n * sub：Subject，主题\n * aud：Audience，观众\n * exp：Expiration time，过期时间\n * nbf：Not before\n * iat：Issued at，发行时间\n * jti：JWT ID\n\n比如下面这个 Payload ，用到了 iss 发行人，还有 exp 过期时间这两个标准字段。另外还有两个自定义的字段，一个是 name ，还有一个是 admin 。\n\n\t{\n\t  \"sub\": \"1234567890\",\n\t  \"name\": \"John Doe\",\n\t  \"iss\": \"ninghao.net\",\n\t  \"exp\": \"1438955445\",\n\t  \"admin\": true\n\t}\n使用 base64url 编码以后就变成了这个样子：\n\n\t eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ\n**请注意，对于已签名的令牌，此信息虽然受保护不受篡改，但任何人都可以读取。除非经过加密，否则不要将机密信息放在JWT的有效负载或头部**.\n\n## **Signature 签名**\n要创建签名部分，您必须已经有了 经过编码的**头部**、经过编码的**负载**、一个**秘钥**、在头部中指定的**算法**，这样就可以进行签名了.  \nSignature这部分内容有三个部分，先是用 Base64 编码的 header.payload ，再用加密算法加密一下，加密的时候要放进去一个 Secret ，这个相当于是一个密码，这个密码秘密地存储在服务端。  \n\n * header\n * payload\n * secret\n\n\n\tconst encodedString = base64UrlEncode(header) + \".\" + base64UrlEncode(payload); \n\tHMACSHA256(encodedString, 'secret');\n处理完成以后看起来像这样：\n\n\t SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc\n最后这个在服务端生成并且要发送给客户端的 Token 看起来像这样：\n\n\t eyJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ.SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc\n输出的内容是三个由点分隔的Base64 URL字符串。它可以在HTML和HTTP环境中轻松传递，它比XML的标准（如SAML）更加紧凑.  \n客户端收到这个 Token 以后把它存储下来，下回向服务端发送请求的时候就带着这个 Token 。服务端收到这个 Token ，然后进行验证，通过以后就会返回给客户端想要的资源。\n\n## **签名的作用:**  \n(1) 签名用于验证消息在传输过程中没有被更改。\n(2) 使用私钥签名的令牌，还可以验证JWT的发送者是它所说的发送者。\n\n# **签发 Json Web Token(JWT)**\n * JWT 对 “信息” 进行签名，产生一个令牌。\n * 签名的令牌可以验证其中包含的内容的完整性（防篡改）。\n * 也可对“信息”加密，加密的令牌则对其他方隐藏这些内容。\n * 当令牌使用公钥/私钥对签名时，签名还证明只有持有私钥的一方才是签名方。可以非对称加密方式证明了\n\n\n## **HS256 算法签发Json Web Token(JWT)**\n这种算法需要一个密钥（密码）.  \n在项目里随便添加一个 .js 文件，比如 index.js，在文件里添加下面这些代码：  \n\n\tconst jwt = require('jsonwebtoken')\n\t// Token 数据\n\tconst payload = {\n\tname: 'wanghao',\n\tadmin: true\n\t}\n\t// 密钥\n\tconst secret = 'ILOVENINGHAO'\n\t// 签发 Token\n\tconst token = jwt.sign(payload, secret, { expiresIn: '1day' })\n\t// 输出签发的 Token\n\tconsole.log(token)\n非常简单，就是用了刚刚为项目安装的 jsonwebtoken 里面提供的 jwt.sign 功能，去签发一个 token。这个 sign 方法需要三个参数：\n * playload：签发的 token 里面要包含的一些数据。\n * secret：签发 token 用的密钥，在验证 token 的时候同样需要用到这个密钥。\n * options：一些其它的选项。\n\n在命令行下面，用 node 命令，执行一下项目里的 index.js 这个文件（node index.js），会输出应用签发的 token：\n\n\teyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlLCJpYXQiOjE1MjkwMzM5MDYsImV4cCI6MTUyOTEyMDMwNn0.DctA2QlUCrM6wLWkIO78wBVN0NLpjoIq4T5B_2WJ-PU\n上面的 Token 内容并没有加密，所以如果用一些 JWT 解码功能，可以看到 Token 里面包含的内容，内容由三个部分组成，像这样：\n\n\t// header\n\t{\n\t  \"alg\": \"HS256\", \n\t  \"typ\": \"JWT\"\n\t}\n\t// payload\n\t{\n\t  \"admin\": true, \n\t  \"iat\": 1529033906, \n\t  \"name\": \"wanghao\", \n\t  \"exp\": 1529120306\n\t}\n\t// signature\n\tDctA2QlUCrM6wLWkIO78wBVN0NLpjoIq4T5B_2WJ-PU\n> 假设用户通过了某种身份验证，你就可以使用上面的签发 Token 的功能为用户签发一个 Token。一般在客户端那里会把它保存在 Cookie 或 LocalStorage 里面。\n> 用户下次向我们的应用请求受保护的资源的时候，可以在请求里带着我们给它签发的这个 Token，后端应用收到请求，检查签名，如果验证通过确定这个 Token 是我们自己签发的，那就可以为用户响应回他需要的资源。\n\n## **RS256 算法签发Json Web Token(JWT)**\n默认签发还有验证 Token 的时候用的是 HS256 算法，这种算法需要一个密钥（密码）。我们还可以使用 RS256 算法签发与验证 JWT。这种方法可以让我们分离开签发与验证，签发时需要用一个密钥，验证时使用公钥，也就是有公钥的地方只能做验证，但不能签发 JWT。\n\n在项目下面创建一个新的目录，里面可以存储即将生成的密钥与公钥文件。\n\n\t$ cd ~/desktop/jwt-demo\n\t$ mkdir config\n\t$ cd config\n**密钥:**\n先生成一个密钥文件：\n\n\t ssh-keygen -t rsa -b 2048 -f private.key\n**公钥:**\n基于上面生成的密钥，再去创建一个对应的公钥：\n\n\t openssl rsa -in private.key -pubout -outform PEM -out public.key\n**签发 JWT（RS256 算法）**\n用 RS256 算法签发 JWT 的时候，需要从文件系统上读取创建的密钥文件里的内容。\n\n\t const fs = require('fs')\n\t // 获取签发 JWT 时需要用的密钥\n\t const privateKey = fs.readFileSync('./config/private.key')\n\t 签发仍然使用 jwt.sign 方法，只不过在选项参数里特别说明一下使用的算法是 RS256：\n\t // 签发 Token\n\t const tokenRS256 = jwt.sign(payload, privateKey, { algorithm: 'RS256' })\n\t // 输出签发的 Token\n\t console.log('RS256 算法：', tokenRS256)\n\n# **验证Json Web Token(JWT)**\n\n## **HS256 算法验证Json Web TOken(JWT)**\n需要一个签发token时候用的密钥（密码）来验证,这种算法需要一个密钥（密码）.  \n验证 JWT 的用效性，确定一下用户的 JWT 是我们自己签发的，首先要得到用户的这个 JWT Token，然后用 jwt.verify 这个方法去做一下验证。这个方法是 Node.js 的 jsonwebtoken 这个包里提供的，在其它的应用框架或者系统里，你可能会找到类似的方法来验证 JWT。  \n打开项目的 index.js 文件，里面添加几行代码：\n\n\t// 验证 Token\n\tjwt.verify(token, 'bad secret', (error, decoded) => {\n\t  if (error) {\n\t    console.log(error.message)\n\t    return\n\t  }\n\t  console.log(decoded)\n\t})\n把要验证的 Token 数据，还有签发这个 Token 的时候用的那个密钥告诉 verify 这个方法，在一个回调里面有两个参数，error 表示错误，decoded 是解码之后的 Token 数据。\n\n执行：\n\n\t$ node ~/desktop/jwt-demo/index.js\n输出：\n\n\teyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlLCJpYXQiOjE1MjkwMzQ3MzMsImV4cCI6MTUyOTEyMTEzM30.swXojmu7VimFu3BoIgAxxpmm2J05dvD0HT3yu10vuqU\n\tinvalid signature\n注意输出了一个 invalid signature ，表示 Token 里的签名不对，这是因为我们组长 verify 方法提供的密钥并不是签发 Token 的时候用的那个密钥。这样修改一下：\n\n\tjwt.verify(token, secret, (error, decoded) => { ...\n再次运行，会输出类似的数据：\n\n\teyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlLCJpYXQiOjE1MjkwMzUzODYsImV4cCI6MTUyOTEyMTc4Nn0.mkNrt4TfcfmP22xd3C_GQn8qnUmlB39dKT9SpIBTBGI\n\t{ name: 'wanghao', admin: true, iat: 1529035386, exp: 1529121786 }\n\n## **RS256 算法验证Json Web Token(JWT)**\n验证 JWT（RS256 算法）\n验证使用 RS256 算法签发的 JWT，需要在文件系统上读取公钥文件里的内容。然后用 jwt 的 verify 方法去做验证。\n\n\t// 获取验证 JWT 时需要用的公钥\n\tconst publicKey = fs.readFileSync('./config/public.key')\n\t\n\t// 验证 Token\n\tjwt.verify(tokenRS256, publicKey, (error, decoded) => {\n\t  if (error) {\n\t    console.log(error.message)\n\t    return\n\t  }\n\t  console.log(decoded)\n\t})\n\n# **使用场景**\n![](token_scene1.png)\n\n1. 应用程序或客户端，向授权服务器请求授权。\n2. 当授权被通过时，授权服务器将向应用程序返回一个访问令牌token。\n3. 应用程序使用访问令牌访问受保护的资源。\n**请注意，使用签名的令牌，令牌中包含的所有信息都将公开给用户或其他方（虽然他们无法更改它，但可以阅读）。这意味着您不应将机密信息放入令牌中.**\n\n\n\n","slug":"technologies/security/token_jwt","published":1,"date":"2020-08-12T16:05:48.739Z","updated":"2020-08-10T16:33:53.942Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmoj009hhohxapct2xgn","content":"<h1 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h1><ul>\n<li><a href=\"https://www.cnblogs.com/MyCode1990/p/13096423.html\" target=\"_blank\" rel=\"noopener\">csdn blog</a></li>\n<li><a href=\"https://www.jianshu.com/p/4941a269a9d8\" target=\"_blank\" rel=\"noopener\">简书</a></li>\n</ul>\n<h1 id=\"Json-Web-Token-JWT-简介\"><a href=\"#Json-Web-Token-JWT-简介\" class=\"headerlink\" title=\"Json Web Token(JWT)简介\"></a><strong>Json Web Token(JWT)简介</strong></h1><p>JWT属于Token验证方式的一种方法.</p>\n<blockquote>\n<p>JSON Web Token（JWT）是一个开放标准（RFC 7519），它定义了一种紧凑的、自包含的方式，用于作为JSON对象在各方之间安全地传输信息。此信息可以验证和信任，因为它是数字签名的。JWTs可以使用密钥（使用HMAC算法）或使用RSA或ECDSA的公钥/私钥对进行签名.</p>\n</blockquote>\n<h1 id=\"传统服务端验证客户端身份的方法\"><a href=\"#传统服务端验证客户端身份的方法\" class=\"headerlink\" title=\"传统服务端验证客户端身份的方法\"></a><strong>传统服务端验证客户端身份的方法</strong></h1><p>HTTP 是一种没有状态的协议，也就是它并不知道是谁是访问应用。这里我们把用户看成是客户端，客户端使用用户名还有密码通过了身份验证，不过下回这个客户端再发送请求时候，还得再验证一下。</p>\n<p>解决的方法就是，当用户请求登录的时候，如果没有问题，我们在服务端生成一条记录，这个记录里可以说明一下登录的用户是谁，然后把这条记录的 ID 号发送给客户端，客户端收到以后把这个 ID 号存储在 Cookie 里，下次这个用户再向服务端发送请求的时候，可以带着这个 Cookie ，这样服务端会验证一个这个 Cookie 里的信息，看看能不能在服务端这里找到对应的记录，如果可以，说明用户已经通过了身份验证，就把用户请求的数据返回给客户端。</p>\n<p>上面说的就是 Session，我们需要在服务端存储为登录的用户生成的 Session ，这些 Session 可能会存储在内存，磁盘，或者数据库里。我们可能需要在服务端定期的去清理过期的 Session 。</p>\n<h1 id=\"基于-Token-的身份验证方法\"><a href=\"#基于-Token-的身份验证方法\" class=\"headerlink\" title=\"基于 Token 的身份验证方法\"></a><strong>基于 Token 的身份验证方法</strong></h1><p>Token是在客户端频繁向服务端请求数据，服务端频繁的去数据库查询用户名和密码并进行对比，判断用户名和密码正确与否，并作出相应提示，在这样的背景下，Token便应运而生。<br>Token是服务端生成的一串字符串，以作客户端进行请求的一个令牌，当第一次登录后，服务器生成一个Token便将此Token返回给客户端，以后客户端只需带上这个Token前来请求数据即可，无需再次带上用户名和密码。<br>使用基于 Token 的身份验证方法，在服务端不需要存储用户的登录记录。大概的流程是这样的：</p>\n<ol>\n<li>客户端使用用户名跟密码请求登录</li>\n<li>服务端收到请求，去验证用户名与密码</li>\n<li>验证成功后，服务端会签发一个 Token，再把这个 Token 发送给客户端</li>\n<li>客户端收到 Token 以后可以把它存储起来，比如放在 Cookie 里或者 Local Storage 里</li>\n<li>客户端每次向服务端请求资源的时候需要带着服务端签发的 Token</li>\n<li>服务端收到请求，然后去验证客户端请求里面带着的 Token，如果验证成功，就向客户端返回请求的数据</li>\n</ol>\n<h1 id=\"为什么要使用JSON-Web-Token\"><a href=\"#为什么要使用JSON-Web-Token\" class=\"headerlink\" title=\"为什么要使用JSON Web Token\"></a><strong>为什么要使用JSON Web Token</strong></h1><ul>\n<li>Token的目的是为了减轻服务器的压力，减少频繁的查询数据库，使服务器更加健壮.</li>\n<li>JSON比XML不那么冗长，当它被编码时，它的大小也更小，使得JWT比SAML更紧凑。这使得JWT成为在HTML和HTTP环境中传递的一个很好的选择。</li>\n<li>安全方面，使用HMAC算法，SWT只能由共享密钥对称签名。但是，JWT和SAML令牌可以使用X.509证书形式的公钥/私钥对进行签名。与签名JSON的简单性相比，使用XML数字签名来签名XML而不引入隐藏的安全漏洞是非常困难的。</li>\n<li>JSON解析器在大多数编程语言中都很常见，因为它们直接映射到对象。相反，XML没有自然的文档到对象的映射。这使得使用JWT比使用SAML断言更容易。</li>\n<li>在使用方面，JWT是在互联网上使用的。这突出了JSON Web令牌在多个平台（尤其是移动平台）上客户端处理的方便性。</li>\n<li>比较编码JWT和编码SAML的长度.</li>\n</ul>\n<h1 id=\"JWT-Json-Web-Token-一种Token验证方法\"><a href=\"#JWT-Json-Web-Token-一种Token验证方法\" class=\"headerlink\" title=\"JWT(Json Web Token 一种Token验证方法)\"></a><strong>JWT(Json Web Token 一种Token验证方法)</strong></h1><p>实施 Token 验证的方法挺多的，还有一些标准方法，比如 JWT，读作：jot ，表示：JSON Web Tokens 。JWT 标准的 Token 有三个部分：</p>\n<ul>\n<li><p>header（头部）</p>\n</li>\n<li><p>payload（荷载,数据）</p>\n</li>\n<li><p>signature（签名）<br>中间用点分隔开，并且都会使用 Base64 编码，所以真正的 Token 看起来像这样：</p>\n<p> eyJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ.SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc</p>\n</li>\n</ul>\n<h2 id=\"Header-头部\"><a href=\"#Header-头部\" class=\"headerlink\" title=\"Header 头部\"></a><strong>Header 头部</strong></h2><ul>\n<li>令牌的类型</li>\n<li>正在使用的签名算法(HMAC, SHA256, RSA等)。</li>\n</ul>\n<p>每个 JWT token 里面都有一个 header，也就是头部数据。里面包含了使用的算法，这个 JWT 是不是带签名的或者加密的。主要就是说明一下怎么处理这个 JWT token 。<br>头部里包含的东西可能会根据 JWT 的类型有所变化，比如一个加密的 JWT 里面要包含使用的加密的算法。唯一在头部里面要包含的是 alg 这个属性，如果是加密的 JWT，这个属性的值就是使用的签名或者解密用的算法。如果是未加密的 JWT，这个属性的值要设置成 none。<br>示例：</p>\n<pre><code>{\n  &quot;typ&quot;: &quot;JWT&quot;,\n  &quot;alg&quot;: &quot;HS256&quot;\n}</code></pre><p>意思是这个 JWT 用的算法是 HS256。上面的内容得用 base64url 的形式编码一下，所以就变成这样：</p>\n<pre><code>eyJhbGciOiJIUzI1NiJ9</code></pre><h2 id=\"Payload-有效负载\"><a href=\"#Payload-有效负载\" class=\"headerlink\" title=\"Payload 有效负载\"></a><strong>Payload 有效负载</strong></h2><p>有效负载包含了”声明(claims)”, 有三种类型的claims：</p>\n<ul>\n<li>registered claims 已注册的 (不是强制的，而是推荐,iss（发行者）、exp（到期时间）、sub（主题）、aud（受众）和其他)</li>\n<li>public claims 公开的 (可以由使用JWT的用户随意定义, 为了避免冲突，应该在<a href=\"https://www.iana.org/assignments/jwt/jwt.xhtml\" target=\"_blank\" rel=\"noopener\">IANA JSON Web令牌注册表</a>中定义它们，或者将它们定义为包含防冲突命名空间的URI)</li>\n<li>private claims 私有的</li>\n</ul>\n<p>Payload 里面是 Token 的具体内容，这些内容里面有一些是标准字段，你也可以添加其它需要的内容。下面是标准字段：</p>\n<ul>\n<li>iss：Issuer，发行者</li>\n<li>sub：Subject，主题</li>\n<li>aud：Audience，观众</li>\n<li>exp：Expiration time，过期时间</li>\n<li>nbf：Not before</li>\n<li>iat：Issued at，发行时间</li>\n<li>jti：JWT ID</li>\n</ul>\n<p>比如下面这个 Payload ，用到了 iss 发行人，还有 exp 过期时间这两个标准字段。另外还有两个自定义的字段，一个是 name ，还有一个是 admin 。</p>\n<pre><code>{\n  &quot;sub&quot;: &quot;1234567890&quot;,\n  &quot;name&quot;: &quot;John Doe&quot;,\n  &quot;iss&quot;: &quot;ninghao.net&quot;,\n  &quot;exp&quot;: &quot;1438955445&quot;,\n  &quot;admin&quot;: true\n}</code></pre><p>使用 base64url 编码以后就变成了这个样子：</p>\n<pre><code>eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ</code></pre><p><strong>请注意，对于已签名的令牌，此信息虽然受保护不受篡改，但任何人都可以读取。除非经过加密，否则不要将机密信息放在JWT的有效负载或头部</strong>.</p>\n<h2 id=\"Signature-签名\"><a href=\"#Signature-签名\" class=\"headerlink\" title=\"Signature 签名\"></a><strong>Signature 签名</strong></h2><p>要创建签名部分，您必须已经有了 经过编码的<strong>头部</strong>、经过编码的<strong>负载</strong>、一个<strong>秘钥</strong>、在头部中指定的<strong>算法</strong>，这样就可以进行签名了.<br>Signature这部分内容有三个部分，先是用 Base64 编码的 header.payload ，再用加密算法加密一下，加密的时候要放进去一个 Secret ，这个相当于是一个密码，这个密码秘密地存储在服务端。  </p>\n<ul>\n<li>header</li>\n<li>payload</li>\n<li>secret</li>\n</ul>\n<pre><code>const encodedString = base64UrlEncode(header) + &quot;.&quot; + base64UrlEncode(payload); \nHMACSHA256(encodedString, &apos;secret&apos;);</code></pre><p>处理完成以后看起来像这样：</p>\n<pre><code>SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc</code></pre><p>最后这个在服务端生成并且要发送给客户端的 Token 看起来像这样：</p>\n<pre><code>eyJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ.SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc</code></pre><p>输出的内容是三个由点分隔的Base64 URL字符串。它可以在HTML和HTTP环境中轻松传递，它比XML的标准（如SAML）更加紧凑.<br>客户端收到这个 Token 以后把它存储下来，下回向服务端发送请求的时候就带着这个 Token 。服务端收到这个 Token ，然后进行验证，通过以后就会返回给客户端想要的资源。</p>\n<h2 id=\"签名的作用\"><a href=\"#签名的作用\" class=\"headerlink\" title=\"签名的作用:\"></a><strong>签名的作用:</strong></h2><p>(1) 签名用于验证消息在传输过程中没有被更改。<br>(2) 使用私钥签名的令牌，还可以验证JWT的发送者是它所说的发送者。</p>\n<h1 id=\"签发-Json-Web-Token-JWT\"><a href=\"#签发-Json-Web-Token-JWT\" class=\"headerlink\" title=\"签发 Json Web Token(JWT)\"></a><strong>签发 Json Web Token(JWT)</strong></h1><ul>\n<li>JWT 对 “信息” 进行签名，产生一个令牌。</li>\n<li>签名的令牌可以验证其中包含的内容的完整性（防篡改）。</li>\n<li>也可对“信息”加密，加密的令牌则对其他方隐藏这些内容。</li>\n<li>当令牌使用公钥/私钥对签名时，签名还证明只有持有私钥的一方才是签名方。可以非对称加密方式证明了</li>\n</ul>\n<h2 id=\"HS256-算法签发Json-Web-Token-JWT\"><a href=\"#HS256-算法签发Json-Web-Token-JWT\" class=\"headerlink\" title=\"HS256 算法签发Json Web Token(JWT)\"></a><strong>HS256 算法签发Json Web Token(JWT)</strong></h2><p>这种算法需要一个密钥（密码）.<br>在项目里随便添加一个 .js 文件，比如 index.js，在文件里添加下面这些代码：  </p>\n<pre><code>const jwt = require(&apos;jsonwebtoken&apos;)\n// Token 数据\nconst payload = {\nname: &apos;wanghao&apos;,\nadmin: true\n}\n// 密钥\nconst secret = &apos;ILOVENINGHAO&apos;\n// 签发 Token\nconst token = jwt.sign(payload, secret, { expiresIn: &apos;1day&apos; })\n// 输出签发的 Token\nconsole.log(token)</code></pre><p>非常简单，就是用了刚刚为项目安装的 jsonwebtoken 里面提供的 jwt.sign 功能，去签发一个 token。这个 sign 方法需要三个参数：</p>\n<ul>\n<li>playload：签发的 token 里面要包含的一些数据。</li>\n<li>secret：签发 token 用的密钥，在验证 token 的时候同样需要用到这个密钥。</li>\n<li>options：一些其它的选项。</li>\n</ul>\n<p>在命令行下面，用 node 命令，执行一下项目里的 index.js 这个文件（node index.js），会输出应用签发的 token：</p>\n<pre><code>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlLCJpYXQiOjE1MjkwMzM5MDYsImV4cCI6MTUyOTEyMDMwNn0.DctA2QlUCrM6wLWkIO78wBVN0NLpjoIq4T5B_2WJ-PU</code></pre><p>上面的 Token 内容并没有加密，所以如果用一些 JWT 解码功能，可以看到 Token 里面包含的内容，内容由三个部分组成，像这样：</p>\n<pre><code>// header\n{\n  &quot;alg&quot;: &quot;HS256&quot;, \n  &quot;typ&quot;: &quot;JWT&quot;\n}\n// payload\n{\n  &quot;admin&quot;: true, \n  &quot;iat&quot;: 1529033906, \n  &quot;name&quot;: &quot;wanghao&quot;, \n  &quot;exp&quot;: 1529120306\n}\n// signature\nDctA2QlUCrM6wLWkIO78wBVN0NLpjoIq4T5B_2WJ-PU</code></pre><blockquote>\n<p>假设用户通过了某种身份验证，你就可以使用上面的签发 Token 的功能为用户签发一个 Token。一般在客户端那里会把它保存在 Cookie 或 LocalStorage 里面。<br>用户下次向我们的应用请求受保护的资源的时候，可以在请求里带着我们给它签发的这个 Token，后端应用收到请求，检查签名，如果验证通过确定这个 Token 是我们自己签发的，那就可以为用户响应回他需要的资源。</p>\n</blockquote>\n<h2 id=\"RS256-算法签发Json-Web-Token-JWT\"><a href=\"#RS256-算法签发Json-Web-Token-JWT\" class=\"headerlink\" title=\"RS256 算法签发Json Web Token(JWT)\"></a><strong>RS256 算法签发Json Web Token(JWT)</strong></h2><p>默认签发还有验证 Token 的时候用的是 HS256 算法，这种算法需要一个密钥（密码）。我们还可以使用 RS256 算法签发与验证 JWT。这种方法可以让我们分离开签发与验证，签发时需要用一个密钥，验证时使用公钥，也就是有公钥的地方只能做验证，但不能签发 JWT。</p>\n<p>在项目下面创建一个新的目录，里面可以存储即将生成的密钥与公钥文件。</p>\n<pre><code>$ cd ~/desktop/jwt-demo\n$ mkdir config\n$ cd config</code></pre><p><strong>密钥:</strong><br>先生成一个密钥文件：</p>\n<pre><code>ssh-keygen -t rsa -b 2048 -f private.key</code></pre><p><strong>公钥:</strong><br>基于上面生成的密钥，再去创建一个对应的公钥：</p>\n<pre><code>openssl rsa -in private.key -pubout -outform PEM -out public.key</code></pre><p><strong>签发 JWT（RS256 算法）</strong><br>用 RS256 算法签发 JWT 的时候，需要从文件系统上读取创建的密钥文件里的内容。</p>\n<pre><code>const fs = require(&apos;fs&apos;)\n// 获取签发 JWT 时需要用的密钥\nconst privateKey = fs.readFileSync(&apos;./config/private.key&apos;)\n签发仍然使用 jwt.sign 方法，只不过在选项参数里特别说明一下使用的算法是 RS256：\n// 签发 Token\nconst tokenRS256 = jwt.sign(payload, privateKey, { algorithm: &apos;RS256&apos; })\n// 输出签发的 Token\nconsole.log(&apos;RS256 算法：&apos;, tokenRS256)</code></pre><h1 id=\"验证Json-Web-Token-JWT\"><a href=\"#验证Json-Web-Token-JWT\" class=\"headerlink\" title=\"验证Json Web Token(JWT)\"></a><strong>验证Json Web Token(JWT)</strong></h1><h2 id=\"HS256-算法验证Json-Web-TOken-JWT\"><a href=\"#HS256-算法验证Json-Web-TOken-JWT\" class=\"headerlink\" title=\"HS256 算法验证Json Web TOken(JWT)\"></a><strong>HS256 算法验证Json Web TOken(JWT)</strong></h2><p>需要一个签发token时候用的密钥（密码）来验证,这种算法需要一个密钥（密码）.<br>验证 JWT 的用效性，确定一下用户的 JWT 是我们自己签发的，首先要得到用户的这个 JWT Token，然后用 jwt.verify 这个方法去做一下验证。这个方法是 Node.js 的 jsonwebtoken 这个包里提供的，在其它的应用框架或者系统里，你可能会找到类似的方法来验证 JWT。<br>打开项目的 index.js 文件，里面添加几行代码：</p>\n<pre><code>// 验证 Token\njwt.verify(token, &apos;bad secret&apos;, (error, decoded) =&gt; {\n  if (error) {\n    console.log(error.message)\n    return\n  }\n  console.log(decoded)\n})</code></pre><p>把要验证的 Token 数据，还有签发这个 Token 的时候用的那个密钥告诉 verify 这个方法，在一个回调里面有两个参数，error 表示错误，decoded 是解码之后的 Token 数据。</p>\n<p>执行：</p>\n<pre><code>$ node ~/desktop/jwt-demo/index.js</code></pre><p>输出：</p>\n<pre><code>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlLCJpYXQiOjE1MjkwMzQ3MzMsImV4cCI6MTUyOTEyMTEzM30.swXojmu7VimFu3BoIgAxxpmm2J05dvD0HT3yu10vuqU\ninvalid signature</code></pre><p>注意输出了一个 invalid signature ，表示 Token 里的签名不对，这是因为我们组长 verify 方法提供的密钥并不是签发 Token 的时候用的那个密钥。这样修改一下：</p>\n<pre><code>jwt.verify(token, secret, (error, decoded) =&gt; { ...</code></pre><p>再次运行，会输出类似的数据：</p>\n<pre><code>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlLCJpYXQiOjE1MjkwMzUzODYsImV4cCI6MTUyOTEyMTc4Nn0.mkNrt4TfcfmP22xd3C_GQn8qnUmlB39dKT9SpIBTBGI\n{ name: &apos;wanghao&apos;, admin: true, iat: 1529035386, exp: 1529121786 }</code></pre><h2 id=\"RS256-算法验证Json-Web-Token-JWT\"><a href=\"#RS256-算法验证Json-Web-Token-JWT\" class=\"headerlink\" title=\"RS256 算法验证Json Web Token(JWT)\"></a><strong>RS256 算法验证Json Web Token(JWT)</strong></h2><p>验证 JWT（RS256 算法）<br>验证使用 RS256 算法签发的 JWT，需要在文件系统上读取公钥文件里的内容。然后用 jwt 的 verify 方法去做验证。</p>\n<pre><code>// 获取验证 JWT 时需要用的公钥\nconst publicKey = fs.readFileSync(&apos;./config/public.key&apos;)\n\n// 验证 Token\njwt.verify(tokenRS256, publicKey, (error, decoded) =&gt; {\n  if (error) {\n    console.log(error.message)\n    return\n  }\n  console.log(decoded)\n})</code></pre><h1 id=\"使用场景\"><a href=\"#使用场景\" class=\"headerlink\" title=\"使用场景\"></a><strong>使用场景</strong></h1><p><img src=\"token_scene1.png\" alt=\"\"></p>\n<ol>\n<li>应用程序或客户端，向授权服务器请求授权。</li>\n<li>当授权被通过时，授权服务器将向应用程序返回一个访问令牌token。</li>\n<li>应用程序使用访问令牌访问受保护的资源。</li>\n</ol>\n<p><strong>请注意，使用签名的令牌，令牌中包含的所有信息都将公开给用户或其他方（虽然他们无法更改它，但可以阅读）。这意味着您不应将机密信息放入令牌中.</strong></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h1><ul>\n<li><a href=\"https://www.cnblogs.com/MyCode1990/p/13096423.html\" target=\"_blank\" rel=\"noopener\">csdn blog</a></li>\n<li><a href=\"https://www.jianshu.com/p/4941a269a9d8\" target=\"_blank\" rel=\"noopener\">简书</a></li>\n</ul>\n<h1 id=\"Json-Web-Token-JWT-简介\"><a href=\"#Json-Web-Token-JWT-简介\" class=\"headerlink\" title=\"Json Web Token(JWT)简介\"></a><strong>Json Web Token(JWT)简介</strong></h1><p>JWT属于Token验证方式的一种方法.</p>\n<blockquote>\n<p>JSON Web Token（JWT）是一个开放标准（RFC 7519），它定义了一种紧凑的、自包含的方式，用于作为JSON对象在各方之间安全地传输信息。此信息可以验证和信任，因为它是数字签名的。JWTs可以使用密钥（使用HMAC算法）或使用RSA或ECDSA的公钥/私钥对进行签名.</p>\n</blockquote>\n<h1 id=\"传统服务端验证客户端身份的方法\"><a href=\"#传统服务端验证客户端身份的方法\" class=\"headerlink\" title=\"传统服务端验证客户端身份的方法\"></a><strong>传统服务端验证客户端身份的方法</strong></h1><p>HTTP 是一种没有状态的协议，也就是它并不知道是谁是访问应用。这里我们把用户看成是客户端，客户端使用用户名还有密码通过了身份验证，不过下回这个客户端再发送请求时候，还得再验证一下。</p>\n<p>解决的方法就是，当用户请求登录的时候，如果没有问题，我们在服务端生成一条记录，这个记录里可以说明一下登录的用户是谁，然后把这条记录的 ID 号发送给客户端，客户端收到以后把这个 ID 号存储在 Cookie 里，下次这个用户再向服务端发送请求的时候，可以带着这个 Cookie ，这样服务端会验证一个这个 Cookie 里的信息，看看能不能在服务端这里找到对应的记录，如果可以，说明用户已经通过了身份验证，就把用户请求的数据返回给客户端。</p>\n<p>上面说的就是 Session，我们需要在服务端存储为登录的用户生成的 Session ，这些 Session 可能会存储在内存，磁盘，或者数据库里。我们可能需要在服务端定期的去清理过期的 Session 。</p>\n<h1 id=\"基于-Token-的身份验证方法\"><a href=\"#基于-Token-的身份验证方法\" class=\"headerlink\" title=\"基于 Token 的身份验证方法\"></a><strong>基于 Token 的身份验证方法</strong></h1><p>Token是在客户端频繁向服务端请求数据，服务端频繁的去数据库查询用户名和密码并进行对比，判断用户名和密码正确与否，并作出相应提示，在这样的背景下，Token便应运而生。<br>Token是服务端生成的一串字符串，以作客户端进行请求的一个令牌，当第一次登录后，服务器生成一个Token便将此Token返回给客户端，以后客户端只需带上这个Token前来请求数据即可，无需再次带上用户名和密码。<br>使用基于 Token 的身份验证方法，在服务端不需要存储用户的登录记录。大概的流程是这样的：</p>\n<ol>\n<li>客户端使用用户名跟密码请求登录</li>\n<li>服务端收到请求，去验证用户名与密码</li>\n<li>验证成功后，服务端会签发一个 Token，再把这个 Token 发送给客户端</li>\n<li>客户端收到 Token 以后可以把它存储起来，比如放在 Cookie 里或者 Local Storage 里</li>\n<li>客户端每次向服务端请求资源的时候需要带着服务端签发的 Token</li>\n<li>服务端收到请求，然后去验证客户端请求里面带着的 Token，如果验证成功，就向客户端返回请求的数据</li>\n</ol>\n<h1 id=\"为什么要使用JSON-Web-Token\"><a href=\"#为什么要使用JSON-Web-Token\" class=\"headerlink\" title=\"为什么要使用JSON Web Token\"></a><strong>为什么要使用JSON Web Token</strong></h1><ul>\n<li>Token的目的是为了减轻服务器的压力，减少频繁的查询数据库，使服务器更加健壮.</li>\n<li>JSON比XML不那么冗长，当它被编码时，它的大小也更小，使得JWT比SAML更紧凑。这使得JWT成为在HTML和HTTP环境中传递的一个很好的选择。</li>\n<li>安全方面，使用HMAC算法，SWT只能由共享密钥对称签名。但是，JWT和SAML令牌可以使用X.509证书形式的公钥/私钥对进行签名。与签名JSON的简单性相比，使用XML数字签名来签名XML而不引入隐藏的安全漏洞是非常困难的。</li>\n<li>JSON解析器在大多数编程语言中都很常见，因为它们直接映射到对象。相反，XML没有自然的文档到对象的映射。这使得使用JWT比使用SAML断言更容易。</li>\n<li>在使用方面，JWT是在互联网上使用的。这突出了JSON Web令牌在多个平台（尤其是移动平台）上客户端处理的方便性。</li>\n<li>比较编码JWT和编码SAML的长度.</li>\n</ul>\n<h1 id=\"JWT-Json-Web-Token-一种Token验证方法\"><a href=\"#JWT-Json-Web-Token-一种Token验证方法\" class=\"headerlink\" title=\"JWT(Json Web Token 一种Token验证方法)\"></a><strong>JWT(Json Web Token 一种Token验证方法)</strong></h1><p>实施 Token 验证的方法挺多的，还有一些标准方法，比如 JWT，读作：jot ，表示：JSON Web Tokens 。JWT 标准的 Token 有三个部分：</p>\n<ul>\n<li><p>header（头部）</p>\n</li>\n<li><p>payload（荷载,数据）</p>\n</li>\n<li><p>signature（签名）<br>中间用点分隔开，并且都会使用 Base64 编码，所以真正的 Token 看起来像这样：</p>\n<p> eyJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ.SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc</p>\n</li>\n</ul>\n<h2 id=\"Header-头部\"><a href=\"#Header-头部\" class=\"headerlink\" title=\"Header 头部\"></a><strong>Header 头部</strong></h2><ul>\n<li>令牌的类型</li>\n<li>正在使用的签名算法(HMAC, SHA256, RSA等)。</li>\n</ul>\n<p>每个 JWT token 里面都有一个 header，也就是头部数据。里面包含了使用的算法，这个 JWT 是不是带签名的或者加密的。主要就是说明一下怎么处理这个 JWT token 。<br>头部里包含的东西可能会根据 JWT 的类型有所变化，比如一个加密的 JWT 里面要包含使用的加密的算法。唯一在头部里面要包含的是 alg 这个属性，如果是加密的 JWT，这个属性的值就是使用的签名或者解密用的算法。如果是未加密的 JWT，这个属性的值要设置成 none。<br>示例：</p>\n<pre><code>{\n  &quot;typ&quot;: &quot;JWT&quot;,\n  &quot;alg&quot;: &quot;HS256&quot;\n}</code></pre><p>意思是这个 JWT 用的算法是 HS256。上面的内容得用 base64url 的形式编码一下，所以就变成这样：</p>\n<pre><code>eyJhbGciOiJIUzI1NiJ9</code></pre><h2 id=\"Payload-有效负载\"><a href=\"#Payload-有效负载\" class=\"headerlink\" title=\"Payload 有效负载\"></a><strong>Payload 有效负载</strong></h2><p>有效负载包含了”声明(claims)”, 有三种类型的claims：</p>\n<ul>\n<li>registered claims 已注册的 (不是强制的，而是推荐,iss（发行者）、exp（到期时间）、sub（主题）、aud（受众）和其他)</li>\n<li>public claims 公开的 (可以由使用JWT的用户随意定义, 为了避免冲突，应该在<a href=\"https://www.iana.org/assignments/jwt/jwt.xhtml\" target=\"_blank\" rel=\"noopener\">IANA JSON Web令牌注册表</a>中定义它们，或者将它们定义为包含防冲突命名空间的URI)</li>\n<li>private claims 私有的</li>\n</ul>\n<p>Payload 里面是 Token 的具体内容，这些内容里面有一些是标准字段，你也可以添加其它需要的内容。下面是标准字段：</p>\n<ul>\n<li>iss：Issuer，发行者</li>\n<li>sub：Subject，主题</li>\n<li>aud：Audience，观众</li>\n<li>exp：Expiration time，过期时间</li>\n<li>nbf：Not before</li>\n<li>iat：Issued at，发行时间</li>\n<li>jti：JWT ID</li>\n</ul>\n<p>比如下面这个 Payload ，用到了 iss 发行人，还有 exp 过期时间这两个标准字段。另外还有两个自定义的字段，一个是 name ，还有一个是 admin 。</p>\n<pre><code>{\n  &quot;sub&quot;: &quot;1234567890&quot;,\n  &quot;name&quot;: &quot;John Doe&quot;,\n  &quot;iss&quot;: &quot;ninghao.net&quot;,\n  &quot;exp&quot;: &quot;1438955445&quot;,\n  &quot;admin&quot;: true\n}</code></pre><p>使用 base64url 编码以后就变成了这个样子：</p>\n<pre><code>eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ</code></pre><p><strong>请注意，对于已签名的令牌，此信息虽然受保护不受篡改，但任何人都可以读取。除非经过加密，否则不要将机密信息放在JWT的有效负载或头部</strong>.</p>\n<h2 id=\"Signature-签名\"><a href=\"#Signature-签名\" class=\"headerlink\" title=\"Signature 签名\"></a><strong>Signature 签名</strong></h2><p>要创建签名部分，您必须已经有了 经过编码的<strong>头部</strong>、经过编码的<strong>负载</strong>、一个<strong>秘钥</strong>、在头部中指定的<strong>算法</strong>，这样就可以进行签名了.<br>Signature这部分内容有三个部分，先是用 Base64 编码的 header.payload ，再用加密算法加密一下，加密的时候要放进去一个 Secret ，这个相当于是一个密码，这个密码秘密地存储在服务端。  </p>\n<ul>\n<li>header</li>\n<li>payload</li>\n<li>secret</li>\n</ul>\n<pre><code>const encodedString = base64UrlEncode(header) + &quot;.&quot; + base64UrlEncode(payload); \nHMACSHA256(encodedString, &apos;secret&apos;);</code></pre><p>处理完成以后看起来像这样：</p>\n<pre><code>SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc</code></pre><p>最后这个在服务端生成并且要发送给客户端的 Token 看起来像这样：</p>\n<pre><code>eyJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ.SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc</code></pre><p>输出的内容是三个由点分隔的Base64 URL字符串。它可以在HTML和HTTP环境中轻松传递，它比XML的标准（如SAML）更加紧凑.<br>客户端收到这个 Token 以后把它存储下来，下回向服务端发送请求的时候就带着这个 Token 。服务端收到这个 Token ，然后进行验证，通过以后就会返回给客户端想要的资源。</p>\n<h2 id=\"签名的作用\"><a href=\"#签名的作用\" class=\"headerlink\" title=\"签名的作用:\"></a><strong>签名的作用:</strong></h2><p>(1) 签名用于验证消息在传输过程中没有被更改。<br>(2) 使用私钥签名的令牌，还可以验证JWT的发送者是它所说的发送者。</p>\n<h1 id=\"签发-Json-Web-Token-JWT\"><a href=\"#签发-Json-Web-Token-JWT\" class=\"headerlink\" title=\"签发 Json Web Token(JWT)\"></a><strong>签发 Json Web Token(JWT)</strong></h1><ul>\n<li>JWT 对 “信息” 进行签名，产生一个令牌。</li>\n<li>签名的令牌可以验证其中包含的内容的完整性（防篡改）。</li>\n<li>也可对“信息”加密，加密的令牌则对其他方隐藏这些内容。</li>\n<li>当令牌使用公钥/私钥对签名时，签名还证明只有持有私钥的一方才是签名方。可以非对称加密方式证明了</li>\n</ul>\n<h2 id=\"HS256-算法签发Json-Web-Token-JWT\"><a href=\"#HS256-算法签发Json-Web-Token-JWT\" class=\"headerlink\" title=\"HS256 算法签发Json Web Token(JWT)\"></a><strong>HS256 算法签发Json Web Token(JWT)</strong></h2><p>这种算法需要一个密钥（密码）.<br>在项目里随便添加一个 .js 文件，比如 index.js，在文件里添加下面这些代码：  </p>\n<pre><code>const jwt = require(&apos;jsonwebtoken&apos;)\n// Token 数据\nconst payload = {\nname: &apos;wanghao&apos;,\nadmin: true\n}\n// 密钥\nconst secret = &apos;ILOVENINGHAO&apos;\n// 签发 Token\nconst token = jwt.sign(payload, secret, { expiresIn: &apos;1day&apos; })\n// 输出签发的 Token\nconsole.log(token)</code></pre><p>非常简单，就是用了刚刚为项目安装的 jsonwebtoken 里面提供的 jwt.sign 功能，去签发一个 token。这个 sign 方法需要三个参数：</p>\n<ul>\n<li>playload：签发的 token 里面要包含的一些数据。</li>\n<li>secret：签发 token 用的密钥，在验证 token 的时候同样需要用到这个密钥。</li>\n<li>options：一些其它的选项。</li>\n</ul>\n<p>在命令行下面，用 node 命令，执行一下项目里的 index.js 这个文件（node index.js），会输出应用签发的 token：</p>\n<pre><code>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlLCJpYXQiOjE1MjkwMzM5MDYsImV4cCI6MTUyOTEyMDMwNn0.DctA2QlUCrM6wLWkIO78wBVN0NLpjoIq4T5B_2WJ-PU</code></pre><p>上面的 Token 内容并没有加密，所以如果用一些 JWT 解码功能，可以看到 Token 里面包含的内容，内容由三个部分组成，像这样：</p>\n<pre><code>// header\n{\n  &quot;alg&quot;: &quot;HS256&quot;, \n  &quot;typ&quot;: &quot;JWT&quot;\n}\n// payload\n{\n  &quot;admin&quot;: true, \n  &quot;iat&quot;: 1529033906, \n  &quot;name&quot;: &quot;wanghao&quot;, \n  &quot;exp&quot;: 1529120306\n}\n// signature\nDctA2QlUCrM6wLWkIO78wBVN0NLpjoIq4T5B_2WJ-PU</code></pre><blockquote>\n<p>假设用户通过了某种身份验证，你就可以使用上面的签发 Token 的功能为用户签发一个 Token。一般在客户端那里会把它保存在 Cookie 或 LocalStorage 里面。<br>用户下次向我们的应用请求受保护的资源的时候，可以在请求里带着我们给它签发的这个 Token，后端应用收到请求，检查签名，如果验证通过确定这个 Token 是我们自己签发的，那就可以为用户响应回他需要的资源。</p>\n</blockquote>\n<h2 id=\"RS256-算法签发Json-Web-Token-JWT\"><a href=\"#RS256-算法签发Json-Web-Token-JWT\" class=\"headerlink\" title=\"RS256 算法签发Json Web Token(JWT)\"></a><strong>RS256 算法签发Json Web Token(JWT)</strong></h2><p>默认签发还有验证 Token 的时候用的是 HS256 算法，这种算法需要一个密钥（密码）。我们还可以使用 RS256 算法签发与验证 JWT。这种方法可以让我们分离开签发与验证，签发时需要用一个密钥，验证时使用公钥，也就是有公钥的地方只能做验证，但不能签发 JWT。</p>\n<p>在项目下面创建一个新的目录，里面可以存储即将生成的密钥与公钥文件。</p>\n<pre><code>$ cd ~/desktop/jwt-demo\n$ mkdir config\n$ cd config</code></pre><p><strong>密钥:</strong><br>先生成一个密钥文件：</p>\n<pre><code>ssh-keygen -t rsa -b 2048 -f private.key</code></pre><p><strong>公钥:</strong><br>基于上面生成的密钥，再去创建一个对应的公钥：</p>\n<pre><code>openssl rsa -in private.key -pubout -outform PEM -out public.key</code></pre><p><strong>签发 JWT（RS256 算法）</strong><br>用 RS256 算法签发 JWT 的时候，需要从文件系统上读取创建的密钥文件里的内容。</p>\n<pre><code>const fs = require(&apos;fs&apos;)\n// 获取签发 JWT 时需要用的密钥\nconst privateKey = fs.readFileSync(&apos;./config/private.key&apos;)\n签发仍然使用 jwt.sign 方法，只不过在选项参数里特别说明一下使用的算法是 RS256：\n// 签发 Token\nconst tokenRS256 = jwt.sign(payload, privateKey, { algorithm: &apos;RS256&apos; })\n// 输出签发的 Token\nconsole.log(&apos;RS256 算法：&apos;, tokenRS256)</code></pre><h1 id=\"验证Json-Web-Token-JWT\"><a href=\"#验证Json-Web-Token-JWT\" class=\"headerlink\" title=\"验证Json Web Token(JWT)\"></a><strong>验证Json Web Token(JWT)</strong></h1><h2 id=\"HS256-算法验证Json-Web-TOken-JWT\"><a href=\"#HS256-算法验证Json-Web-TOken-JWT\" class=\"headerlink\" title=\"HS256 算法验证Json Web TOken(JWT)\"></a><strong>HS256 算法验证Json Web TOken(JWT)</strong></h2><p>需要一个签发token时候用的密钥（密码）来验证,这种算法需要一个密钥（密码）.<br>验证 JWT 的用效性，确定一下用户的 JWT 是我们自己签发的，首先要得到用户的这个 JWT Token，然后用 jwt.verify 这个方法去做一下验证。这个方法是 Node.js 的 jsonwebtoken 这个包里提供的，在其它的应用框架或者系统里，你可能会找到类似的方法来验证 JWT。<br>打开项目的 index.js 文件，里面添加几行代码：</p>\n<pre><code>// 验证 Token\njwt.verify(token, &apos;bad secret&apos;, (error, decoded) =&gt; {\n  if (error) {\n    console.log(error.message)\n    return\n  }\n  console.log(decoded)\n})</code></pre><p>把要验证的 Token 数据，还有签发这个 Token 的时候用的那个密钥告诉 verify 这个方法，在一个回调里面有两个参数，error 表示错误，decoded 是解码之后的 Token 数据。</p>\n<p>执行：</p>\n<pre><code>$ node ~/desktop/jwt-demo/index.js</code></pre><p>输出：</p>\n<pre><code>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlLCJpYXQiOjE1MjkwMzQ3MzMsImV4cCI6MTUyOTEyMTEzM30.swXojmu7VimFu3BoIgAxxpmm2J05dvD0HT3yu10vuqU\ninvalid signature</code></pre><p>注意输出了一个 invalid signature ，表示 Token 里的签名不对，这是因为我们组长 verify 方法提供的密钥并不是签发 Token 的时候用的那个密钥。这样修改一下：</p>\n<pre><code>jwt.verify(token, secret, (error, decoded) =&gt; { ...</code></pre><p>再次运行，会输出类似的数据：</p>\n<pre><code>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlLCJpYXQiOjE1MjkwMzUzODYsImV4cCI6MTUyOTEyMTc4Nn0.mkNrt4TfcfmP22xd3C_GQn8qnUmlB39dKT9SpIBTBGI\n{ name: &apos;wanghao&apos;, admin: true, iat: 1529035386, exp: 1529121786 }</code></pre><h2 id=\"RS256-算法验证Json-Web-Token-JWT\"><a href=\"#RS256-算法验证Json-Web-Token-JWT\" class=\"headerlink\" title=\"RS256 算法验证Json Web Token(JWT)\"></a><strong>RS256 算法验证Json Web Token(JWT)</strong></h2><p>验证 JWT（RS256 算法）<br>验证使用 RS256 算法签发的 JWT，需要在文件系统上读取公钥文件里的内容。然后用 jwt 的 verify 方法去做验证。</p>\n<pre><code>// 获取验证 JWT 时需要用的公钥\nconst publicKey = fs.readFileSync(&apos;./config/public.key&apos;)\n\n// 验证 Token\njwt.verify(tokenRS256, publicKey, (error, decoded) =&gt; {\n  if (error) {\n    console.log(error.message)\n    return\n  }\n  console.log(decoded)\n})</code></pre><h1 id=\"使用场景\"><a href=\"#使用场景\" class=\"headerlink\" title=\"使用场景\"></a><strong>使用场景</strong></h1><p><img src=\"token_scene1.png\" alt=\"\"></p>\n<ol>\n<li>应用程序或客户端，向授权服务器请求授权。</li>\n<li>当授权被通过时，授权服务器将向应用程序返回一个访问令牌token。</li>\n<li>应用程序使用访问令牌访问受保护的资源。</li>\n</ol>\n<p><strong>请注意，使用签名的令牌，令牌中包含的所有信息都将公开给用户或其他方（虽然他们无法更改它，但可以阅读）。这意味着您不应将机密信息放入令牌中.</strong></p>\n"},{"title":"bootstrap","_content":"\n#### bootstrap介绍\nBootstrap 是最流行的开发响应式 web 的 HTML, CSS, 和 JS 框架。  \nBootstrap 帮助您开发在任何尺寸都外观出众的站点：显示器、笔记本电脑、平板电脑或手机  \n\n\n\n","source":"_posts/technologies/web/bootstrap.md","raw":"---\ntitle: bootstrap\ncategories:\n- technologies\n- web前端\n---\n\n#### bootstrap介绍\nBootstrap 是最流行的开发响应式 web 的 HTML, CSS, 和 JS 框架。  \nBootstrap 帮助您开发在任何尺寸都外观出众的站点：显示器、笔记本电脑、平板电脑或手机  \n\n\n\n","slug":"technologies/web/bootstrap","published":1,"date":"2020-08-12T16:05:49.101Z","updated":"2020-03-16T11:12:38.841Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmok009lhohx6rp67lmw","content":"<h4 id=\"bootstrap介绍\"><a href=\"#bootstrap介绍\" class=\"headerlink\" title=\"bootstrap介绍\"></a>bootstrap介绍</h4><p>Bootstrap 是最流行的开发响应式 web 的 HTML, CSS, 和 JS 框架。<br>Bootstrap 帮助您开发在任何尺寸都外观出众的站点：显示器、笔记本电脑、平板电脑或手机  </p>\n","site":{"data":{}},"excerpt":"","more":"<h4 id=\"bootstrap介绍\"><a href=\"#bootstrap介绍\" class=\"headerlink\" title=\"bootstrap介绍\"></a>bootstrap介绍</h4><p>Bootstrap 是最流行的开发响应式 web 的 HTML, CSS, 和 JS 框架。<br>Bootstrap 帮助您开发在任何尺寸都外观出众的站点：显示器、笔记本电脑、平板电脑或手机  </p>\n"},{"title":"web前端datatables框架","_content":"\n框架网站:\nhttps://datatables.net/\n\n使用样例:\nhttps://datatables.net/examples/data_sources/\n\n\n","source":"_posts/technologies/web/datatables.md","raw":"---\ntitle: web前端datatables框架\ncategories:\n- technologies\n- web前端\n---\n\n框架网站:\nhttps://datatables.net/\n\n使用样例:\nhttps://datatables.net/examples/data_sources/\n\n\n","slug":"technologies/web/datatables","published":1,"date":"2020-08-12T16:05:49.111Z","updated":"2020-03-16T11:30:22.341Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmol009nhohx9itzcmpq","content":"<p>框架网站:<br><a href=\"https://datatables.net/\" target=\"_blank\" rel=\"noopener\">https://datatables.net/</a></p>\n<p>使用样例:<br><a href=\"https://datatables.net/examples/data_sources/\" target=\"_blank\" rel=\"noopener\">https://datatables.net/examples/data_sources/</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>框架网站:<br><a href=\"https://datatables.net/\" target=\"_blank\" rel=\"noopener\">https://datatables.net/</a></p>\n<p>使用样例:<br><a href=\"https://datatables.net/examples/data_sources/\" target=\"_blank\" rel=\"noopener\">https://datatables.net/examples/data_sources/</a></p>\n"},{"title":"JavaScript","_content":"\n### ES6 新特性\n\n//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n### ES6 let 块作用域\n``` javascript\nif(true){\n    let a = 123;  // let 是块作用域，只能再if作用域使用\n    console.log(a);\n}\n``` \n//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n### ES6 模板语法\n``` javascript\nvar name = \"张三\";\nvar age = 20;\nconsole.log(`${name}的年龄是${age}`);  // 不是引号''，而是键盘左上角的`\n```\n//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n### ES6 属性的简写\n``` javascript\nvar name = \"zhangsan\";\n//1.\nvar app1 = {\n    name:name\n}\n//2.\nvar app2 = {\n    \"name\":name\n}\n//3. 简写\nvar app3 = {\n    name\n}\nconsole.log(app1.name);\nconsole.log(app2.name);\nconsole.log(app3.name);\n``` \n//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n### ES6 buffer简写\n``` javascript\nvar name = \"李四\";\nvar app4 = {\n    name,\n    run:function(){\n        console.log(`${this.name}在跑步`);\n    }\n}\nvar app5 = {\n    name,\n    run(){\n        console.log(`${this.name}在跑步`);\n    }\n}\napp5.run()\n```\n//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n### 箭头函数\n``` javascript\nsetTimeout(function(){\n    console.log(\"执行\");\n},1000);\nsetTimeout(()=>{\n    console.log(\"执行\");\n}, 1000);\n\n// 回调函数获取异步函数里数据\n//1.\nfunction getData1(){\n    //ajax, 异步\n    setTimeout(()=>{\n        var name1 = \"张三1\";\n    },1000);\n    return name1;   // 执行会出错，找不到name1变量\n}\n//console.log(getData1());  // 出错这是获取不到name1的\n//2.\nfunction getData2(callback){\n    setTimeout(()=>{\n       var name2 = \"张三2\";\n       callback(name2);\n    });\n}\ngetData2((aaa)=>{\n    console.log(aaa);\n});\n//3. Promise来处理异步  resolve 成功的回调函数   reject失败的回调函数\nvar p1 = new Promise((resolve, reject)=>{\n    setTimeout(()=>{\n        var name3 = \"张三3\";\n        resolve(name3);\n    },1000);\n});\np1.then((data)=>{\n   console.log(data);\n});\n//4. 提取一下Promise里参数\nfunction getData3(resolve, reject){\n    setTimeout(()=>{\n        var name4 = \"张三4\";\n        resolve(name4);\n    }, 1000);\n}\nvar p2 = new Promise(getData3);\np2.then((data)=>{\n    console.log(data);\n})\n```\n//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n### async声明异步方法, await等待异步方法执行完成\n``` javascript\n//1.\nasync function test1(){     // 函数定义为async，返回Promise { '您好！' }\n    return \"您好！\";\n}\n// console.log(await test());   // 出错， await必须用在async函数方法中\n//2.\nasync function test2(){\n    return new Promise((resolve, reject)=>{\n        setTimeout(()=>{\n            var name5 = \"张三5\";\n            resolve(name5)\n        }, 1000);\n    });\n}\nasync function output(){\n    var data = await test2();    // 如果不加await，返回是 Promise { '您好！' }\n    console.log(data);          // 返回 您好！\n}\noutput();\n\n// 判断一个资源到底是目录还是文件，此方法里有异步函数，需要加上async标签，再用Promise来获取异步返回，最后再用await来调用等待此异步方法执行完\nasync function isDir(path){\n    return new Promise((resolve, reject)=>{\n        fs.stat(path, (err, states)=>{\n            if(err){\n                console.log(err);\n                reject(err);\n                return ;\n            }\n            if(states.isDirectory()){\n                resolve(true);\n            }else{\n                resolve(false);\n            }\n        });\n    });\n}\n// 获取所有资源\nfunction getDir(){          // 此方法不需要加async, await只在它所在的函数上加上async就可以了，更外层的函数不需要加上asycn\n    var path = \"./testfs\";\n    var dirArr = [];\n    fs.readdir(path, async (err, data)=>{   //回调函数需要加async，因为此函数里需要用await\n        if(err){\n            console.log(err);\n            return ;\n        }\n        for(var i = 0; i < data.length; i++){\n            if(await isDir(path + \"/\" +data[i])){\n                dirArr.push(data[i]);\n            }\n        }\n        console.log(dirArr);    // 输出 [ 'fs1', 'fs2' ]\n    });\n}\ngetDir();\n//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n```\n\n\n### JSON.parse(text[, reviver])\n\t参数说明：\n\ttext:\n\t\t必需， 一个有效的 JSON 字符串。\n\treviver: \n\t\t可选，一个转换结果的函数， 将为对象的每个成员调用此函数。\n\t返回值：\n\t\t返回给定 JSON 字符串转换后的对象。\n\n``` html\n<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"utf-8\">\n<title>title)</title>\n</head>\n<body>\n<p id=\"demo\">测试JSP函数库JSON.parse()</p>\n<script>\nconst json_str = '{\"result\":true, \"count\":42}';\nconst json = { \"name\":\"MYZ\" };\n\n// 用来解析JSON字符串，构造由字符串描述的JavaScript值或对象\nconst obj = JSON.parse(json_str);\nconsole.log(obj.count);\t\t// expected output: 42\nconsole.log(obj.result);\t// expected output: true\n\nconsole.log(obj);\t\t// > Object { result: true, count: 42 }\nconsole.log(json);\t\t// > Object { age: 23 }\nconsole.log(typeof(json_str));\t\t\t// > \"string\"\nconsole.log(typeof(json));\t\t\t\t// > \"object\"\nconsole.log(typeof(obj) === typeof(json));\t// > true\n\nfor(x in json){\n  console.log(x);\t\t// > \"name\"\n  console.log(json[x]);\t\t// > \"MYZ\"\n}\n\nJSON.parse('{\"result\":true, \"count\":42}', function(k, v) {\n  console.log( k );\t\t// 输出当前三个属性，最后一个为 \"\", > \"result\", > \"count\", > \"\"\n  return v;\t\t\t// 返回修改的值\n});\n\nJSON.parse('{\"1\": 7, \"2\": 2, \"3\": {\"4\": 4, \"5\": {\"6\": 6}}}', function(k, v) {\n  console.log( k );\t\t// 输出当前属性，最后一个为 \"\" > \"1\", > \"2\", > \"4\", > \"6\", > \"5\", > \"3\", > \"\"\n  return v;\t\t\t// 返回修改的值\n});\n\n</script>\n</body>\n</html>\n```\n\n### JSON.stringify(value[, replacer [, space]])\n\tvalue:\n\t\t将要序列化成 一个 JSON 字符串的值。\n\treplacer 可选:\n\t\t如果该参数是一个函数，则在序列化过程中，被序列化的值的每个属性都会经过该函数的转换和处理；\n\t\t如果该参数是一个数组，则只有包含在这个数组中的属性名才会被序列化到最终的 JSON 字符串中；\n\t\t如果该参数为 null 或者未提供，则对象所有的属性都会被序列化；\n\t\t关于该参数更详细的解释和示例，请参考使用原生的 JSON 对象一文。\n\tspace 可选:\n\t\t指定缩进用的空白字符串，用于美化输出（pretty-print）；\n\t\t如果参数是个数字，它代表有多少的空格；上限为10。该值若小于1，则意味着没有空格；\n\t\t如果该参数为字符串（当字符串长度超过10个字母，取其前10个字母），该字符串将被作为空格；\n\t\t如果该参数没有提供（或者为 null），将没有空格。\n\t返回值:\n\t一个表示给定值的JSON字符串。\n\n``` javascript\nconst json_str = '{\"result\":true, \"count\":42}';\nconst json = { \"name\":\"MYZ\" };\nconsole.log(typeof(json_str));\t// > \"string\"\nconsole.log(json_str);\t\t\t// > \"{\"result\":true, \"count\":42}\"\nconsole.log(typeof(json));\t\t// > \"object\"\nconsole.log(json);\t\t\t\t// > Object { name: \"MYZ\" }\n\n// JSON.stringify() 将值转换为相应的JSON格式, 也就是将JSON对象转换为字符串：\n// JSON对象可以进行如json[\"name\"]来取值，JSON字符串就行如‘{ \"name\":\"MYZ\" }’\njson_ify = JSON.stringify(json);\nconsole.log(typeof(json_ify));\t// > \"string\"\nconsole.log(json_ify);\t\t\t// > \"{\"name\":\"MYZ\"}\"\n\njson_parse = JSON.parse(json_ify);\nconsole.log(typeof(json_parse));\t// > \"object\"\nconsole.log(json_parse);\t\t\t// > Object { name: \"MYZ\" }\n\nconsole.log(json[\"name\"]);\t\t\t// > \"MYZ\"\nconsole.log(json_parse[\"name\"]);\t// > \"MYZ\"\nconsole.log(json[\"name\"] === json_parse[\"name\"]);\t// > true\n```\n\n``` javascript\nconst json_str = '{\"result\":true,\"count\":42}';\nconst json = { \"name\":\"MYZ\" };\n\nvar obj1 = JSON.parse(json_str);\nvar obj2 = JSON.stringify(obj1);\nconsole.log(json_str);\t\t\t> \"{\"result\":true,\"count\":42}\"\nconsole.log(obj2);\t\t\t\t> \"{\"result\":true,\"count\":42}\"\nconsole.log(obj2 === json_str);\t> true\n```\n\n``` javascript\nconst json_str = '{\"result\":true, \"count\":42}';\t//字符串中间有一个空格\nconst json = { \"name\":\"MYZ\" };\n\nvar obj1 = JSON.parse(json_str);\nvar obj2 = JSON.stringify(obj1);\t// 转化的字符串中间没有空格\nconsole.log(json_str);\t\t\t// > \"{\"result\":true,\"count\":42}\"\nconsole.log(obj2);\t\t\t\t// > \"{\"result\":true,\"count\":42}\"\nconsole.log(obj2 === json_str);\t// > false // 就因为多了空格因此两个字符串不相等\n```\n\n``` javascript\nconst json_str = '{\"result\": true,\"count\":42}';\nconst json = { \"name\":\"MYZ\" };\n\nvar obj1 = JSON.parse(json_str);\nvar obj2 = JSON.stringify(obj1);\nconsole.log(json_str);\t\t\t// > \"{\"result\":true,\"count\":42}\"\nconsole.log(obj2);\t\t\t\t// > \"{\"result\":true,\"count\":42}\"\nconsole.log(obj2 === json_str);\t// > false\n```\n\n### html+JS 实现循环编辑HTML标签\n![](pic.JPG)\n\n``` html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>Employee</title>\n</head>\n<body>\n    <div class=\"znfz-cont\">\n        <ul id=\"data\" class=\"znfz-list\">\n        </ul>\n    </div>\n    \n    <div id=\"myDIV\"> \n        <p class=\"child\"> div 元素中 class=\"child\" 的 p </p>\n        <p class=\"child\"> div 元素中 class=\"child\" 的另外一个 p </p>\n        <p>在 div 中的 p 元素插入 <span class=\"child\">class=\"child\" 的 span 元素</span> 。</p>\n    </div>\n    <p>点击按钮为 id=\"myDIV\" 的 div 元素中所有 class=\"child\" 元素添加背景颜色。 </p>\n    <button onclick=\"myFunction()\">点我</button>\n    <p><strong>注意:</strong> Internet Explorer 8 及更早 IE 版本不支持 getElementsByClassName() 方法。</p>\n\n    <script>\n        function myFunction() {\n            var x = document.getElementById(\"myDIV\");\n            var y = x.getElementsByClassName(\"child\");\n            var i;\n            for (i = 0; i < y.length; i++) {\n                y[i].style.backgroundColor = \"red\";\n            }\n        }\n    </script>\n\n</body>\n<script>\nvar lists =[\n    {\n        \"content\":\"尾矿库风险单元划分?\",\n        \"read_num\":256\n    },\n    {\n        \"content\":\"尾矿库今年发生的事故?\",\n        \"read_num\":65\n    }\n]\nvar str=\"\";\nfor (var i = 0; i < lists.length; i++) {\n    str += \"<li class='znfz-num'>\" + i + \"</li>\";\n    str += \"<router-link class='znfz-txt' to=''>\" + lists[i].content + \"</router-link>\"\n    str += \"<span class='read-num'>\" + lists[i].read_num + \"</span>\"\n}\n\n// 下面两种方法都可以，只不过getElementsByClassName返回的是数组元素，需要加上索引值如[0]\n//document.getElementById(\"data\").innerHTML=str;\ndocument.getElementsByClassName(\"znfz-list\")[0].innerHTML=str;\n\nvar name = \"张三\";\nvar age = 20;\nconsole.log(`${name}的年龄是${age}`);\n\n</script>\n</html>\n```\n\n\n\n\n\n\n","source":"_posts/technologies/web/JavaScript.md","raw":"---\ntitle: JavaScript\ntags:\ncategories:\n- technologies\n- web前端\n---\n\n### ES6 新特性\n\n//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n### ES6 let 块作用域\n``` javascript\nif(true){\n    let a = 123;  // let 是块作用域，只能再if作用域使用\n    console.log(a);\n}\n``` \n//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n### ES6 模板语法\n``` javascript\nvar name = \"张三\";\nvar age = 20;\nconsole.log(`${name}的年龄是${age}`);  // 不是引号''，而是键盘左上角的`\n```\n//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n### ES6 属性的简写\n``` javascript\nvar name = \"zhangsan\";\n//1.\nvar app1 = {\n    name:name\n}\n//2.\nvar app2 = {\n    \"name\":name\n}\n//3. 简写\nvar app3 = {\n    name\n}\nconsole.log(app1.name);\nconsole.log(app2.name);\nconsole.log(app3.name);\n``` \n//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n### ES6 buffer简写\n``` javascript\nvar name = \"李四\";\nvar app4 = {\n    name,\n    run:function(){\n        console.log(`${this.name}在跑步`);\n    }\n}\nvar app5 = {\n    name,\n    run(){\n        console.log(`${this.name}在跑步`);\n    }\n}\napp5.run()\n```\n//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n### 箭头函数\n``` javascript\nsetTimeout(function(){\n    console.log(\"执行\");\n},1000);\nsetTimeout(()=>{\n    console.log(\"执行\");\n}, 1000);\n\n// 回调函数获取异步函数里数据\n//1.\nfunction getData1(){\n    //ajax, 异步\n    setTimeout(()=>{\n        var name1 = \"张三1\";\n    },1000);\n    return name1;   // 执行会出错，找不到name1变量\n}\n//console.log(getData1());  // 出错这是获取不到name1的\n//2.\nfunction getData2(callback){\n    setTimeout(()=>{\n       var name2 = \"张三2\";\n       callback(name2);\n    });\n}\ngetData2((aaa)=>{\n    console.log(aaa);\n});\n//3. Promise来处理异步  resolve 成功的回调函数   reject失败的回调函数\nvar p1 = new Promise((resolve, reject)=>{\n    setTimeout(()=>{\n        var name3 = \"张三3\";\n        resolve(name3);\n    },1000);\n});\np1.then((data)=>{\n   console.log(data);\n});\n//4. 提取一下Promise里参数\nfunction getData3(resolve, reject){\n    setTimeout(()=>{\n        var name4 = \"张三4\";\n        resolve(name4);\n    }, 1000);\n}\nvar p2 = new Promise(getData3);\np2.then((data)=>{\n    console.log(data);\n})\n```\n//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n### async声明异步方法, await等待异步方法执行完成\n``` javascript\n//1.\nasync function test1(){     // 函数定义为async，返回Promise { '您好！' }\n    return \"您好！\";\n}\n// console.log(await test());   // 出错， await必须用在async函数方法中\n//2.\nasync function test2(){\n    return new Promise((resolve, reject)=>{\n        setTimeout(()=>{\n            var name5 = \"张三5\";\n            resolve(name5)\n        }, 1000);\n    });\n}\nasync function output(){\n    var data = await test2();    // 如果不加await，返回是 Promise { '您好！' }\n    console.log(data);          // 返回 您好！\n}\noutput();\n\n// 判断一个资源到底是目录还是文件，此方法里有异步函数，需要加上async标签，再用Promise来获取异步返回，最后再用await来调用等待此异步方法执行完\nasync function isDir(path){\n    return new Promise((resolve, reject)=>{\n        fs.stat(path, (err, states)=>{\n            if(err){\n                console.log(err);\n                reject(err);\n                return ;\n            }\n            if(states.isDirectory()){\n                resolve(true);\n            }else{\n                resolve(false);\n            }\n        });\n    });\n}\n// 获取所有资源\nfunction getDir(){          // 此方法不需要加async, await只在它所在的函数上加上async就可以了，更外层的函数不需要加上asycn\n    var path = \"./testfs\";\n    var dirArr = [];\n    fs.readdir(path, async (err, data)=>{   //回调函数需要加async，因为此函数里需要用await\n        if(err){\n            console.log(err);\n            return ;\n        }\n        for(var i = 0; i < data.length; i++){\n            if(await isDir(path + \"/\" +data[i])){\n                dirArr.push(data[i]);\n            }\n        }\n        console.log(dirArr);    // 输出 [ 'fs1', 'fs2' ]\n    });\n}\ngetDir();\n//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※\n```\n\n\n### JSON.parse(text[, reviver])\n\t参数说明：\n\ttext:\n\t\t必需， 一个有效的 JSON 字符串。\n\treviver: \n\t\t可选，一个转换结果的函数， 将为对象的每个成员调用此函数。\n\t返回值：\n\t\t返回给定 JSON 字符串转换后的对象。\n\n``` html\n<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"utf-8\">\n<title>title)</title>\n</head>\n<body>\n<p id=\"demo\">测试JSP函数库JSON.parse()</p>\n<script>\nconst json_str = '{\"result\":true, \"count\":42}';\nconst json = { \"name\":\"MYZ\" };\n\n// 用来解析JSON字符串，构造由字符串描述的JavaScript值或对象\nconst obj = JSON.parse(json_str);\nconsole.log(obj.count);\t\t// expected output: 42\nconsole.log(obj.result);\t// expected output: true\n\nconsole.log(obj);\t\t// > Object { result: true, count: 42 }\nconsole.log(json);\t\t// > Object { age: 23 }\nconsole.log(typeof(json_str));\t\t\t// > \"string\"\nconsole.log(typeof(json));\t\t\t\t// > \"object\"\nconsole.log(typeof(obj) === typeof(json));\t// > true\n\nfor(x in json){\n  console.log(x);\t\t// > \"name\"\n  console.log(json[x]);\t\t// > \"MYZ\"\n}\n\nJSON.parse('{\"result\":true, \"count\":42}', function(k, v) {\n  console.log( k );\t\t// 输出当前三个属性，最后一个为 \"\", > \"result\", > \"count\", > \"\"\n  return v;\t\t\t// 返回修改的值\n});\n\nJSON.parse('{\"1\": 7, \"2\": 2, \"3\": {\"4\": 4, \"5\": {\"6\": 6}}}', function(k, v) {\n  console.log( k );\t\t// 输出当前属性，最后一个为 \"\" > \"1\", > \"2\", > \"4\", > \"6\", > \"5\", > \"3\", > \"\"\n  return v;\t\t\t// 返回修改的值\n});\n\n</script>\n</body>\n</html>\n```\n\n### JSON.stringify(value[, replacer [, space]])\n\tvalue:\n\t\t将要序列化成 一个 JSON 字符串的值。\n\treplacer 可选:\n\t\t如果该参数是一个函数，则在序列化过程中，被序列化的值的每个属性都会经过该函数的转换和处理；\n\t\t如果该参数是一个数组，则只有包含在这个数组中的属性名才会被序列化到最终的 JSON 字符串中；\n\t\t如果该参数为 null 或者未提供，则对象所有的属性都会被序列化；\n\t\t关于该参数更详细的解释和示例，请参考使用原生的 JSON 对象一文。\n\tspace 可选:\n\t\t指定缩进用的空白字符串，用于美化输出（pretty-print）；\n\t\t如果参数是个数字，它代表有多少的空格；上限为10。该值若小于1，则意味着没有空格；\n\t\t如果该参数为字符串（当字符串长度超过10个字母，取其前10个字母），该字符串将被作为空格；\n\t\t如果该参数没有提供（或者为 null），将没有空格。\n\t返回值:\n\t一个表示给定值的JSON字符串。\n\n``` javascript\nconst json_str = '{\"result\":true, \"count\":42}';\nconst json = { \"name\":\"MYZ\" };\nconsole.log(typeof(json_str));\t// > \"string\"\nconsole.log(json_str);\t\t\t// > \"{\"result\":true, \"count\":42}\"\nconsole.log(typeof(json));\t\t// > \"object\"\nconsole.log(json);\t\t\t\t// > Object { name: \"MYZ\" }\n\n// JSON.stringify() 将值转换为相应的JSON格式, 也就是将JSON对象转换为字符串：\n// JSON对象可以进行如json[\"name\"]来取值，JSON字符串就行如‘{ \"name\":\"MYZ\" }’\njson_ify = JSON.stringify(json);\nconsole.log(typeof(json_ify));\t// > \"string\"\nconsole.log(json_ify);\t\t\t// > \"{\"name\":\"MYZ\"}\"\n\njson_parse = JSON.parse(json_ify);\nconsole.log(typeof(json_parse));\t// > \"object\"\nconsole.log(json_parse);\t\t\t// > Object { name: \"MYZ\" }\n\nconsole.log(json[\"name\"]);\t\t\t// > \"MYZ\"\nconsole.log(json_parse[\"name\"]);\t// > \"MYZ\"\nconsole.log(json[\"name\"] === json_parse[\"name\"]);\t// > true\n```\n\n``` javascript\nconst json_str = '{\"result\":true,\"count\":42}';\nconst json = { \"name\":\"MYZ\" };\n\nvar obj1 = JSON.parse(json_str);\nvar obj2 = JSON.stringify(obj1);\nconsole.log(json_str);\t\t\t> \"{\"result\":true,\"count\":42}\"\nconsole.log(obj2);\t\t\t\t> \"{\"result\":true,\"count\":42}\"\nconsole.log(obj2 === json_str);\t> true\n```\n\n``` javascript\nconst json_str = '{\"result\":true, \"count\":42}';\t//字符串中间有一个空格\nconst json = { \"name\":\"MYZ\" };\n\nvar obj1 = JSON.parse(json_str);\nvar obj2 = JSON.stringify(obj1);\t// 转化的字符串中间没有空格\nconsole.log(json_str);\t\t\t// > \"{\"result\":true,\"count\":42}\"\nconsole.log(obj2);\t\t\t\t// > \"{\"result\":true,\"count\":42}\"\nconsole.log(obj2 === json_str);\t// > false // 就因为多了空格因此两个字符串不相等\n```\n\n``` javascript\nconst json_str = '{\"result\": true,\"count\":42}';\nconst json = { \"name\":\"MYZ\" };\n\nvar obj1 = JSON.parse(json_str);\nvar obj2 = JSON.stringify(obj1);\nconsole.log(json_str);\t\t\t// > \"{\"result\":true,\"count\":42}\"\nconsole.log(obj2);\t\t\t\t// > \"{\"result\":true,\"count\":42}\"\nconsole.log(obj2 === json_str);\t// > false\n```\n\n### html+JS 实现循环编辑HTML标签\n![](pic.JPG)\n\n``` html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>Employee</title>\n</head>\n<body>\n    <div class=\"znfz-cont\">\n        <ul id=\"data\" class=\"znfz-list\">\n        </ul>\n    </div>\n    \n    <div id=\"myDIV\"> \n        <p class=\"child\"> div 元素中 class=\"child\" 的 p </p>\n        <p class=\"child\"> div 元素中 class=\"child\" 的另外一个 p </p>\n        <p>在 div 中的 p 元素插入 <span class=\"child\">class=\"child\" 的 span 元素</span> 。</p>\n    </div>\n    <p>点击按钮为 id=\"myDIV\" 的 div 元素中所有 class=\"child\" 元素添加背景颜色。 </p>\n    <button onclick=\"myFunction()\">点我</button>\n    <p><strong>注意:</strong> Internet Explorer 8 及更早 IE 版本不支持 getElementsByClassName() 方法。</p>\n\n    <script>\n        function myFunction() {\n            var x = document.getElementById(\"myDIV\");\n            var y = x.getElementsByClassName(\"child\");\n            var i;\n            for (i = 0; i < y.length; i++) {\n                y[i].style.backgroundColor = \"red\";\n            }\n        }\n    </script>\n\n</body>\n<script>\nvar lists =[\n    {\n        \"content\":\"尾矿库风险单元划分?\",\n        \"read_num\":256\n    },\n    {\n        \"content\":\"尾矿库今年发生的事故?\",\n        \"read_num\":65\n    }\n]\nvar str=\"\";\nfor (var i = 0; i < lists.length; i++) {\n    str += \"<li class='znfz-num'>\" + i + \"</li>\";\n    str += \"<router-link class='znfz-txt' to=''>\" + lists[i].content + \"</router-link>\"\n    str += \"<span class='read-num'>\" + lists[i].read_num + \"</span>\"\n}\n\n// 下面两种方法都可以，只不过getElementsByClassName返回的是数组元素，需要加上索引值如[0]\n//document.getElementById(\"data\").innerHTML=str;\ndocument.getElementsByClassName(\"znfz-list\")[0].innerHTML=str;\n\nvar name = \"张三\";\nvar age = 20;\nconsole.log(`${name}的年龄是${age}`);\n\n</script>\n</html>\n```\n\n\n\n\n\n\n","slug":"technologies/web/JavaScript","published":1,"date":"2020-08-12T16:05:49.124Z","updated":"2020-04-15T11:09:29.781Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmom009rhohxdv7h9kc8","content":"<h3 id=\"ES6-新特性\"><a href=\"#ES6-新特性\" class=\"headerlink\" title=\"ES6 新特性\"></a>ES6 新特性</h3><p>//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<h3 id=\"ES6-let-块作用域\"><a href=\"#ES6-let-块作用域\" class=\"headerlink\" title=\"ES6 let 块作用域\"></a>ES6 let 块作用域</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span>(<span class=\"literal\">true</span>)&#123;</span><br><span class=\"line\">    <span class=\"keyword\">let</span> a = <span class=\"number\">123</span>;  <span class=\"comment\">// let 是块作用域，只能再if作用域使用</span></span><br><span class=\"line\">    <span class=\"built_in\">console</span>.log(a);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"string\">``</span><span class=\"string\">` </span></span><br><span class=\"line\"><span class=\"string\">//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</span></span><br><span class=\"line\"><span class=\"string\">### ES6 模板语法</span></span><br><span class=\"line\"><span class=\"string\">`</span><span class=\"string\">``</span> javascript</span><br><span class=\"line\"><span class=\"keyword\">var</span> name = <span class=\"string\">\"张三\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">var</span> age = <span class=\"number\">20</span>;</span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(<span class=\"string\">`<span class=\"subst\">$&#123;name&#125;</span>的年龄是<span class=\"subst\">$&#123;age&#125;</span>`</span>);  <span class=\"comment\">// 不是引号''，而是键盘左上角的`</span></span><br></pre></td></tr></table></figure>\n<p>//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<h3 id=\"ES6-属性的简写\"><a href=\"#ES6-属性的简写\" class=\"headerlink\" title=\"ES6 属性的简写\"></a>ES6 属性的简写</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> name = <span class=\"string\">\"zhangsan\"</span>;</span><br><span class=\"line\"><span class=\"comment\">//1.</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> app1 = &#123;</span><br><span class=\"line\">    name:name</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//2.</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> app2 = &#123;</span><br><span class=\"line\">    <span class=\"string\">\"name\"</span>:name</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//3. 简写</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> app3 = &#123;</span><br><span class=\"line\">    name</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(app1.name);</span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(app2.name);</span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(app3.name);</span><br><span class=\"line\"><span class=\"string\">``</span><span class=\"string\">` </span></span><br><span class=\"line\"><span class=\"string\">//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</span></span><br><span class=\"line\"><span class=\"string\">### ES6 buffer简写</span></span><br><span class=\"line\"><span class=\"string\">`</span><span class=\"string\">``</span> javascript</span><br><span class=\"line\"><span class=\"keyword\">var</span> name = <span class=\"string\">\"李四\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">var</span> app4 = &#123;</span><br><span class=\"line\">    name,</span><br><span class=\"line\">    run:<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">        <span class=\"built_in\">console</span>.log(<span class=\"string\">`<span class=\"subst\">$&#123;<span class=\"keyword\">this</span>.name&#125;</span>在跑步`</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">var</span> app5 = &#123;</span><br><span class=\"line\">    name,</span><br><span class=\"line\">    run()&#123;</span><br><span class=\"line\">        <span class=\"built_in\">console</span>.log(<span class=\"string\">`<span class=\"subst\">$&#123;<span class=\"keyword\">this</span>.name&#125;</span>在跑步`</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">app5.run()</span><br></pre></td></tr></table></figure>\n<p>//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<h3 id=\"箭头函数\"><a href=\"#箭头函数\" class=\"headerlink\" title=\"箭头函数\"></a>箭头函数</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">setTimeout(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">console</span>.log(<span class=\"string\">\"执行\"</span>);</span><br><span class=\"line\">&#125;,<span class=\"number\">1000</span>);</span><br><span class=\"line\">setTimeout(<span class=\"function\"><span class=\"params\">()</span>=&gt;</span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">console</span>.log(<span class=\"string\">\"执行\"</span>);</span><br><span class=\"line\">&#125;, <span class=\"number\">1000</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 回调函数获取异步函数里数据</span></span><br><span class=\"line\"><span class=\"comment\">//1.</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">getData1</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//ajax, 异步</span></span><br><span class=\"line\">    setTimeout(<span class=\"function\"><span class=\"params\">()</span>=&gt;</span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">var</span> name1 = <span class=\"string\">\"张三1\"</span>;</span><br><span class=\"line\">    &#125;,<span class=\"number\">1000</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> name1;   <span class=\"comment\">// 执行会出错，找不到name1变量</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//console.log(getData1());  // 出错这是获取不到name1的</span></span><br><span class=\"line\"><span class=\"comment\">//2.</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">getData2</span>(<span class=\"params\">callback</span>)</span>&#123;</span><br><span class=\"line\">    setTimeout(<span class=\"function\"><span class=\"params\">()</span>=&gt;</span>&#123;</span><br><span class=\"line\">       <span class=\"keyword\">var</span> name2 = <span class=\"string\">\"张三2\"</span>;</span><br><span class=\"line\">       callback(name2);</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">getData2(<span class=\"function\">(<span class=\"params\">aaa</span>)=&gt;</span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">console</span>.log(aaa);</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"><span class=\"comment\">//3. Promise来处理异步  resolve 成功的回调函数   reject失败的回调函数</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> p1 = <span class=\"keyword\">new</span> <span class=\"built_in\">Promise</span>(<span class=\"function\">(<span class=\"params\">resolve, reject</span>)=&gt;</span>&#123;</span><br><span class=\"line\">    setTimeout(<span class=\"function\"><span class=\"params\">()</span>=&gt;</span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">var</span> name3 = <span class=\"string\">\"张三3\"</span>;</span><br><span class=\"line\">        resolve(name3);</span><br><span class=\"line\">    &#125;,<span class=\"number\">1000</span>);</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\">p1.then(<span class=\"function\">(<span class=\"params\">data</span>)=&gt;</span>&#123;</span><br><span class=\"line\">   <span class=\"built_in\">console</span>.log(data);</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"><span class=\"comment\">//4. 提取一下Promise里参数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">getData3</span>(<span class=\"params\">resolve, reject</span>)</span>&#123;</span><br><span class=\"line\">    setTimeout(<span class=\"function\"><span class=\"params\">()</span>=&gt;</span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">var</span> name4 = <span class=\"string\">\"张三4\"</span>;</span><br><span class=\"line\">        resolve(name4);</span><br><span class=\"line\">    &#125;, <span class=\"number\">1000</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">var</span> p2 = <span class=\"keyword\">new</span> <span class=\"built_in\">Promise</span>(getData3);</span><br><span class=\"line\">p2.then(<span class=\"function\">(<span class=\"params\">data</span>)=&gt;</span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">console</span>.log(data);</span><br><span class=\"line\">&#125;)</span><br></pre></td></tr></table></figure>\n<p>//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<h3 id=\"async声明异步方法-await等待异步方法执行完成\"><a href=\"#async声明异步方法-await等待异步方法执行完成\" class=\"headerlink\" title=\"async声明异步方法, await等待异步方法执行完成\"></a>async声明异步方法, await等待异步方法执行完成</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//1.</span></span><br><span class=\"line\"><span class=\"keyword\">async</span> <span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">test1</span>(<span class=\"params\"></span>)</span>&#123;     <span class=\"comment\">// 函数定义为async，返回Promise &#123; '您好！' &#125;</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"string\">\"您好！\"</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// console.log(await test());   // 出错， await必须用在async函数方法中</span></span><br><span class=\"line\"><span class=\"comment\">//2.</span></span><br><span class=\"line\"><span class=\"keyword\">async</span> <span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">test2</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> <span class=\"built_in\">Promise</span>(<span class=\"function\">(<span class=\"params\">resolve, reject</span>)=&gt;</span>&#123;</span><br><span class=\"line\">        setTimeout(<span class=\"function\"><span class=\"params\">()</span>=&gt;</span>&#123;</span><br><span class=\"line\">            <span class=\"keyword\">var</span> name5 = <span class=\"string\">\"张三5\"</span>;</span><br><span class=\"line\">            resolve(name5)</span><br><span class=\"line\">        &#125;, <span class=\"number\">1000</span>);</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">async</span> <span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">output</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">var</span> data = <span class=\"keyword\">await</span> test2();    <span class=\"comment\">// 如果不加await，返回是 Promise &#123; '您好！' &#125;</span></span><br><span class=\"line\">    <span class=\"built_in\">console</span>.log(data);          <span class=\"comment\">// 返回 您好！</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">output();</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 判断一个资源到底是目录还是文件，此方法里有异步函数，需要加上async标签，再用Promise来获取异步返回，最后再用await来调用等待此异步方法执行完</span></span><br><span class=\"line\"><span class=\"keyword\">async</span> <span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">isDir</span>(<span class=\"params\">path</span>)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> <span class=\"built_in\">Promise</span>(<span class=\"function\">(<span class=\"params\">resolve, reject</span>)=&gt;</span>&#123;</span><br><span class=\"line\">        fs.stat(path, (err, states)=&gt;&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(err)&#123;</span><br><span class=\"line\">                <span class=\"built_in\">console</span>.log(err);</span><br><span class=\"line\">                reject(err);</span><br><span class=\"line\">                <span class=\"keyword\">return</span> ;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(states.isDirectory())&#123;</span><br><span class=\"line\">                resolve(<span class=\"literal\">true</span>);</span><br><span class=\"line\">            &#125;<span class=\"keyword\">else</span>&#123;</span><br><span class=\"line\">                resolve(<span class=\"literal\">false</span>);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// 获取所有资源</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">getDir</span>(<span class=\"params\"></span>)</span>&#123;          <span class=\"comment\">// 此方法不需要加async, await只在它所在的函数上加上async就可以了，更外层的函数不需要加上asycn</span></span><br><span class=\"line\">    <span class=\"keyword\">var</span> path = <span class=\"string\">\"./testfs\"</span>;</span><br><span class=\"line\">    <span class=\"keyword\">var</span> dirArr = [];</span><br><span class=\"line\">    fs.readdir(path, <span class=\"keyword\">async</span> (err, data)=&gt;&#123;   <span class=\"comment\">//回调函数需要加async，因为此函数里需要用await</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(err)&#123;</span><br><span class=\"line\">            <span class=\"built_in\">console</span>.log(err);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> ;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">var</span> i = <span class=\"number\">0</span>; i &lt; data.length; i++)&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(<span class=\"keyword\">await</span> isDir(path + <span class=\"string\">\"/\"</span> +data[i]))&#123;</span><br><span class=\"line\">                dirArr.push(data[i]);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"built_in\">console</span>.log(dirArr);    <span class=\"comment\">// 输出 [ 'fs1', 'fs2' ]</span></span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">getDir();</span><br><span class=\"line\"><span class=\"comment\">//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</span></span><br></pre></td></tr></table></figure>\n\n\n<h3 id=\"JSON-parse-text-reviver\"><a href=\"#JSON-parse-text-reviver\" class=\"headerlink\" title=\"JSON.parse(text[, reviver])\"></a>JSON.parse(text[, reviver])</h3><pre><code>参数说明：\ntext:\n    必需， 一个有效的 JSON 字符串。\nreviver: \n    可选，一个转换结果的函数， 将为对象的每个成员调用此函数。\n返回值：\n    返回给定 JSON 字符串转换后的对象。</code></pre><figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&lt;!DOCTYPE <span class=\"meta-keyword\">html</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">charset</span>=<span class=\"string\">\"utf-8\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">title</span>&gt;</span>title)<span class=\"tag\">&lt;/<span class=\"name\">title</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">p</span> <span class=\"attr\">id</span>=<span class=\"string\">\"demo\"</span>&gt;</span>测试JSP函数库JSON.parse()<span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span>&gt;</span></span><br><span class=\"line\"><span class=\"actionscript\"><span class=\"keyword\">const</span> json_str = <span class=\"string\">'&#123;\"result\":true, \"count\":42&#125;'</span>;</span></span><br><span class=\"line\"><span class=\"actionscript\"><span class=\"keyword\">const</span> json = &#123; <span class=\"string\">\"name\"</span>:<span class=\"string\">\"MYZ\"</span> &#125;;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"actionscript\"><span class=\"comment\">// 用来解析JSON字符串，构造由字符串描述的JavaScript值或对象</span></span></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"keyword\">const</span> obj = <span class=\"built_in\">JSON</span>.parse(json_str);</span></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"built_in\">console</span>.log(obj.count);\t\t<span class=\"comment\">// expected output: 42</span></span></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"built_in\">console</span>.log(obj.result);\t<span class=\"comment\">// expected output: true</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"built_in\">console</span>.log(obj);\t\t<span class=\"comment\">// &gt; Object &#123; result: true, count: 42 &#125;</span></span></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"built_in\">console</span>.log(json);\t\t<span class=\"comment\">// &gt; Object &#123; age: 23 &#125;</span></span></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"built_in\">console</span>.log(<span class=\"keyword\">typeof</span>(json_str));\t\t\t<span class=\"comment\">// &gt; \"string\"</span></span></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"built_in\">console</span>.log(<span class=\"keyword\">typeof</span>(json));\t\t\t\t<span class=\"comment\">// &gt; \"object\"</span></span></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"built_in\">console</span>.log(<span class=\"keyword\">typeof</span>(obj) === <span class=\"keyword\">typeof</span>(json));\t<span class=\"comment\">// &gt; true</span></span></span><br><span class=\"line\"></span><br><span class=\"line\">for(x in json)&#123;</span><br><span class=\"line\"><span class=\"javascript\">  <span class=\"built_in\">console</span>.log(x);\t\t<span class=\"comment\">// &gt; \"name\"</span></span></span><br><span class=\"line\"><span class=\"javascript\">  <span class=\"built_in\">console</span>.log(json[x]);\t\t<span class=\"comment\">// &gt; \"MYZ\"</span></span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"built_in\">JSON</span>.parse(<span class=\"string\">'&#123;\"result\":true, \"count\":42&#125;'</span>, <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">k, v</span>) </span>&#123;</span></span><br><span class=\"line\"><span class=\"javascript\">  <span class=\"built_in\">console</span>.log( k );\t\t<span class=\"comment\">// 输出当前三个属性，最后一个为 \"\", &gt; \"result\", &gt; \"count\", &gt; \"\"</span></span></span><br><span class=\"line\"><span class=\"actionscript\">  <span class=\"keyword\">return</span> v;\t\t\t<span class=\"comment\">// 返回修改的值</span></span></span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"built_in\">JSON</span>.parse(<span class=\"string\">'&#123;\"1\": 7, \"2\": 2, \"3\": &#123;\"4\": 4, \"5\": &#123;\"6\": 6&#125;&#125;&#125;'</span>, <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">k, v</span>) </span>&#123;</span></span><br><span class=\"line\"><span class=\"javascript\">  <span class=\"built_in\">console</span>.log( k );\t\t<span class=\"comment\">// 输出当前属性，最后一个为 \"\" &gt; \"1\", &gt; \"2\", &gt; \"4\", &gt; \"6\", &gt; \"5\", &gt; \"3\", &gt; \"\"</span></span></span><br><span class=\"line\"><span class=\"actionscript\">  <span class=\"keyword\">return</span> v;\t\t\t<span class=\"comment\">// 返回修改的值</span></span></span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">html</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"JSON-stringify-value-replacer-space\"><a href=\"#JSON-stringify-value-replacer-space\" class=\"headerlink\" title=\"JSON.stringify(value[, replacer [, space]])\"></a>JSON.stringify(value[, replacer [, space]])</h3><pre><code>value:\n    将要序列化成 一个 JSON 字符串的值。\nreplacer 可选:\n    如果该参数是一个函数，则在序列化过程中，被序列化的值的每个属性都会经过该函数的转换和处理；\n    如果该参数是一个数组，则只有包含在这个数组中的属性名才会被序列化到最终的 JSON 字符串中；\n    如果该参数为 null 或者未提供，则对象所有的属性都会被序列化；\n    关于该参数更详细的解释和示例，请参考使用原生的 JSON 对象一文。\nspace 可选:\n    指定缩进用的空白字符串，用于美化输出（pretty-print）；\n    如果参数是个数字，它代表有多少的空格；上限为10。该值若小于1，则意味着没有空格；\n    如果该参数为字符串（当字符串长度超过10个字母，取其前10个字母），该字符串将被作为空格；\n    如果该参数没有提供（或者为 null），将没有空格。\n返回值:\n一个表示给定值的JSON字符串。</code></pre><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> json_str = <span class=\"string\">'&#123;\"result\":true, \"count\":42&#125;'</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> json = &#123; <span class=\"string\">\"name\"</span>:<span class=\"string\">\"MYZ\"</span> &#125;;</span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(<span class=\"keyword\">typeof</span>(json_str));\t<span class=\"comment\">// &gt; \"string\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(json_str);\t\t\t<span class=\"comment\">// &gt; \"&#123;\"result\":true, \"count\":42&#125;\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(<span class=\"keyword\">typeof</span>(json));\t\t<span class=\"comment\">// &gt; \"object\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(json);\t\t\t\t<span class=\"comment\">// &gt; Object &#123; name: \"MYZ\" &#125;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// JSON.stringify() 将值转换为相应的JSON格式, 也就是将JSON对象转换为字符串：</span></span><br><span class=\"line\"><span class=\"comment\">// JSON对象可以进行如json[\"name\"]来取值，JSON字符串就行如‘&#123; \"name\":\"MYZ\" &#125;’</span></span><br><span class=\"line\">json_ify = <span class=\"built_in\">JSON</span>.stringify(json);</span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(<span class=\"keyword\">typeof</span>(json_ify));\t<span class=\"comment\">// &gt; \"string\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(json_ify);\t\t\t<span class=\"comment\">// &gt; \"&#123;\"name\":\"MYZ\"&#125;\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">json_parse = <span class=\"built_in\">JSON</span>.parse(json_ify);</span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(<span class=\"keyword\">typeof</span>(json_parse));\t<span class=\"comment\">// &gt; \"object\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(json_parse);\t\t\t<span class=\"comment\">// &gt; Object &#123; name: \"MYZ\" &#125;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(json[<span class=\"string\">\"name\"</span>]);\t\t\t<span class=\"comment\">// &gt; \"MYZ\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(json_parse[<span class=\"string\">\"name\"</span>]);\t<span class=\"comment\">// &gt; \"MYZ\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(json[<span class=\"string\">\"name\"</span>] === json_parse[<span class=\"string\">\"name\"</span>]);\t<span class=\"comment\">// &gt; true</span></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> json_str = <span class=\"string\">'&#123;\"result\":true,\"count\":42&#125;'</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> json = &#123; <span class=\"string\">\"name\"</span>:<span class=\"string\">\"MYZ\"</span> &#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> obj1 = <span class=\"built_in\">JSON</span>.parse(json_str);</span><br><span class=\"line\"><span class=\"keyword\">var</span> obj2 = <span class=\"built_in\">JSON</span>.stringify(obj1);</span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(json_str);\t\t\t&gt; <span class=\"string\">\"&#123;\"</span>result<span class=\"string\">\":true,\"</span>count<span class=\"string\">\":42&#125;\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(obj2);\t\t\t\t&gt; <span class=\"string\">\"&#123;\"</span>result<span class=\"string\">\":true,\"</span>count<span class=\"string\">\":42&#125;\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(obj2 === json_str);\t&gt; <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> json_str = <span class=\"string\">'&#123;\"result\":true, \"count\":42&#125;'</span>;\t<span class=\"comment\">//字符串中间有一个空格</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> json = &#123; <span class=\"string\">\"name\"</span>:<span class=\"string\">\"MYZ\"</span> &#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> obj1 = <span class=\"built_in\">JSON</span>.parse(json_str);</span><br><span class=\"line\"><span class=\"keyword\">var</span> obj2 = <span class=\"built_in\">JSON</span>.stringify(obj1);\t<span class=\"comment\">// 转化的字符串中间没有空格</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(json_str);\t\t\t<span class=\"comment\">// &gt; \"&#123;\"result\":true,\"count\":42&#125;\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(obj2);\t\t\t\t<span class=\"comment\">// &gt; \"&#123;\"result\":true,\"count\":42&#125;\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(obj2 === json_str);\t<span class=\"comment\">// &gt; false // 就因为多了空格因此两个字符串不相等</span></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> json_str = <span class=\"string\">'&#123;\"result\": true,\"count\":42&#125;'</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> json = &#123; <span class=\"string\">\"name\"</span>:<span class=\"string\">\"MYZ\"</span> &#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> obj1 = <span class=\"built_in\">JSON</span>.parse(json_str);</span><br><span class=\"line\"><span class=\"keyword\">var</span> obj2 = <span class=\"built_in\">JSON</span>.stringify(obj1);</span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(json_str);\t\t\t<span class=\"comment\">// &gt; \"&#123;\"result\":true,\"count\":42&#125;\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(obj2);\t\t\t\t<span class=\"comment\">// &gt; \"&#123;\"result\":true,\"count\":42&#125;\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(obj2 === json_str);\t<span class=\"comment\">// &gt; false</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"html-JS-实现循环编辑HTML标签\"><a href=\"#html-JS-实现循环编辑HTML标签\" class=\"headerlink\" title=\"html+JS 实现循环编辑HTML标签\"></a>html+JS 实现循环编辑HTML标签</h3><p><img src=\"pic.JPG\" alt=\"\"></p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&lt;!DOCTYPE <span class=\"meta-keyword\">html</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span> <span class=\"attr\">lang</span>=<span class=\"string\">\"en\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">charset</span>=<span class=\"string\">\"UTF-8\"</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">title</span>&gt;</span>Employee<span class=\"tag\">&lt;/<span class=\"name\">title</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">class</span>=<span class=\"string\">\"znfz-cont\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">ul</span> <span class=\"attr\">id</span>=<span class=\"string\">\"data\"</span> <span class=\"attr\">class</span>=<span class=\"string\">\"znfz-list\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">ul</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">id</span>=<span class=\"string\">\"myDIV\"</span>&gt;</span> </span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">p</span> <span class=\"attr\">class</span>=<span class=\"string\">\"child\"</span>&gt;</span> div 元素中 class=\"child\" 的 p <span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">p</span> <span class=\"attr\">class</span>=<span class=\"string\">\"child\"</span>&gt;</span> div 元素中 class=\"child\" 的另外一个 p <span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span>在 div 中的 p 元素插入 <span class=\"tag\">&lt;<span class=\"name\">span</span> <span class=\"attr\">class</span>=<span class=\"string\">\"child\"</span>&gt;</span>class=\"child\" 的 span 元素<span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span> 。<span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span>点击按钮为 id=\"myDIV\" 的 div 元素中所有 class=\"child\" 元素添加背景颜色。 <span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">button</span> <span class=\"attr\">onclick</span>=<span class=\"string\">\"myFunction()\"</span>&gt;</span>点我<span class=\"tag\">&lt;/<span class=\"name\">button</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">strong</span>&gt;</span>注意:<span class=\"tag\">&lt;/<span class=\"name\">strong</span>&gt;</span> Internet Explorer 8 及更早 IE 版本不支持 getElementsByClassName() 方法。<span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">script</span>&gt;</span></span><br><span class=\"line\"><span class=\"actionscript\">        <span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">myFunction</span><span class=\"params\">()</span> </span>&#123;</span></span><br><span class=\"line\"><span class=\"javascript\">            <span class=\"keyword\">var</span> x = <span class=\"built_in\">document</span>.getElementById(<span class=\"string\">\"myDIV\"</span>);</span></span><br><span class=\"line\"><span class=\"actionscript\">            <span class=\"keyword\">var</span> y = x.getElementsByClassName(<span class=\"string\">\"child\"</span>);</span></span><br><span class=\"line\"><span class=\"actionscript\">            <span class=\"keyword\">var</span> i;</span></span><br><span class=\"line\">            for (i = 0; i &lt; y.length; i++) &#123;</span><br><span class=\"line\"><span class=\"actionscript\">                y[i].style.backgroundColor = <span class=\"string\">\"red\"</span>;</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span>&gt;</span></span><br><span class=\"line\"><span class=\"actionscript\"><span class=\"keyword\">var</span> lists =[</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\"><span class=\"actionscript\">        <span class=\"string\">\"content\"</span>:<span class=\"string\">\"尾矿库风险单元划分?\"</span>,</span></span><br><span class=\"line\"><span class=\"actionscript\">        <span class=\"string\">\"read_num\"</span>:<span class=\"number\">256</span></span></span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\"><span class=\"actionscript\">        <span class=\"string\">\"content\"</span>:<span class=\"string\">\"尾矿库今年发生的事故?\"</span>,</span></span><br><span class=\"line\"><span class=\"actionscript\">        <span class=\"string\">\"read_num\"</span>:<span class=\"number\">65</span></span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">]</span><br><span class=\"line\"><span class=\"actionscript\"><span class=\"keyword\">var</span> str=<span class=\"string\">\"\"</span>;</span></span><br><span class=\"line\"><span class=\"actionscript\"><span class=\"keyword\">for</span> (<span class=\"keyword\">var</span> i = <span class=\"number\">0</span>; i &lt; lists.length; i++) &#123;</span></span><br><span class=\"line\"><span class=\"handlebars\"><span class=\"xml\">    str += \"<span class=\"tag\">&lt;<span class=\"name\">li</span> <span class=\"attr\">class</span>=<span class=\"string\">'znfz-num'</span>&gt;</span>\" + i + \"<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span>\";</span></span></span><br><span class=\"line\"><span class=\"handlebars\"><span class=\"xml\">    str += \"<span class=\"tag\">&lt;<span class=\"name\">router-link</span> <span class=\"attr\">class</span>=<span class=\"string\">'znfz-txt'</span> <span class=\"attr\">to</span>=<span class=\"string\">''</span>&gt;</span>\" + lists[i].content + \"<span class=\"tag\">&lt;/<span class=\"name\">router-link</span>&gt;</span>\"</span></span></span><br><span class=\"line\"><span class=\"handlebars\"><span class=\"xml\">    str += \"<span class=\"tag\">&lt;<span class=\"name\">span</span> <span class=\"attr\">class</span>=<span class=\"string\">'read-num'</span>&gt;</span>\" + lists[i].read_num + \"<span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span>\"</span></span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"actionscript\"><span class=\"comment\">// 下面两种方法都可以，只不过getElementsByClassName返回的是数组元素，需要加上索引值如[0]</span></span></span><br><span class=\"line\"><span class=\"actionscript\"><span class=\"comment\">//document.getElementById(\"data\").innerHTML=str;</span></span></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"built_in\">document</span>.getElementsByClassName(<span class=\"string\">\"znfz-list\"</span>)[<span class=\"number\">0</span>].innerHTML=str;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"actionscript\"><span class=\"keyword\">var</span> name = <span class=\"string\">\"张三\"</span>;</span></span><br><span class=\"line\"><span class=\"actionscript\"><span class=\"keyword\">var</span> age = <span class=\"number\">20</span>;</span></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"built_in\">console</span>.log(<span class=\"string\">`<span class=\"subst\">$&#123;name&#125;</span>的年龄是<span class=\"subst\">$&#123;age&#125;</span>`</span>);</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">html</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n\n\n\n\n\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"ES6-新特性\"><a href=\"#ES6-新特性\" class=\"headerlink\" title=\"ES6 新特性\"></a>ES6 新特性</h3><p>//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<h3 id=\"ES6-let-块作用域\"><a href=\"#ES6-let-块作用域\" class=\"headerlink\" title=\"ES6 let 块作用域\"></a>ES6 let 块作用域</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span>(<span class=\"literal\">true</span>)&#123;</span><br><span class=\"line\">    <span class=\"keyword\">let</span> a = <span class=\"number\">123</span>;  <span class=\"comment\">// let 是块作用域，只能再if作用域使用</span></span><br><span class=\"line\">    <span class=\"built_in\">console</span>.log(a);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"string\">``</span><span class=\"string\">` </span></span><br><span class=\"line\"><span class=\"string\">//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</span></span><br><span class=\"line\"><span class=\"string\">### ES6 模板语法</span></span><br><span class=\"line\"><span class=\"string\">`</span><span class=\"string\">``</span> javascript</span><br><span class=\"line\"><span class=\"keyword\">var</span> name = <span class=\"string\">\"张三\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">var</span> age = <span class=\"number\">20</span>;</span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(<span class=\"string\">`<span class=\"subst\">$&#123;name&#125;</span>的年龄是<span class=\"subst\">$&#123;age&#125;</span>`</span>);  <span class=\"comment\">// 不是引号''，而是键盘左上角的`</span></span><br></pre></td></tr></table></figure>\n<p>//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<h3 id=\"ES6-属性的简写\"><a href=\"#ES6-属性的简写\" class=\"headerlink\" title=\"ES6 属性的简写\"></a>ES6 属性的简写</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> name = <span class=\"string\">\"zhangsan\"</span>;</span><br><span class=\"line\"><span class=\"comment\">//1.</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> app1 = &#123;</span><br><span class=\"line\">    name:name</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//2.</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> app2 = &#123;</span><br><span class=\"line\">    <span class=\"string\">\"name\"</span>:name</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//3. 简写</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> app3 = &#123;</span><br><span class=\"line\">    name</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(app1.name);</span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(app2.name);</span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(app3.name);</span><br><span class=\"line\"><span class=\"string\">``</span><span class=\"string\">` </span></span><br><span class=\"line\"><span class=\"string\">//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</span></span><br><span class=\"line\"><span class=\"string\">### ES6 buffer简写</span></span><br><span class=\"line\"><span class=\"string\">`</span><span class=\"string\">``</span> javascript</span><br><span class=\"line\"><span class=\"keyword\">var</span> name = <span class=\"string\">\"李四\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">var</span> app4 = &#123;</span><br><span class=\"line\">    name,</span><br><span class=\"line\">    run:<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">        <span class=\"built_in\">console</span>.log(<span class=\"string\">`<span class=\"subst\">$&#123;<span class=\"keyword\">this</span>.name&#125;</span>在跑步`</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">var</span> app5 = &#123;</span><br><span class=\"line\">    name,</span><br><span class=\"line\">    run()&#123;</span><br><span class=\"line\">        <span class=\"built_in\">console</span>.log(<span class=\"string\">`<span class=\"subst\">$&#123;<span class=\"keyword\">this</span>.name&#125;</span>在跑步`</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">app5.run()</span><br></pre></td></tr></table></figure>\n<p>//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<h3 id=\"箭头函数\"><a href=\"#箭头函数\" class=\"headerlink\" title=\"箭头函数\"></a>箭头函数</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">setTimeout(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">console</span>.log(<span class=\"string\">\"执行\"</span>);</span><br><span class=\"line\">&#125;,<span class=\"number\">1000</span>);</span><br><span class=\"line\">setTimeout(<span class=\"function\"><span class=\"params\">()</span>=&gt;</span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">console</span>.log(<span class=\"string\">\"执行\"</span>);</span><br><span class=\"line\">&#125;, <span class=\"number\">1000</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 回调函数获取异步函数里数据</span></span><br><span class=\"line\"><span class=\"comment\">//1.</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">getData1</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//ajax, 异步</span></span><br><span class=\"line\">    setTimeout(<span class=\"function\"><span class=\"params\">()</span>=&gt;</span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">var</span> name1 = <span class=\"string\">\"张三1\"</span>;</span><br><span class=\"line\">    &#125;,<span class=\"number\">1000</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> name1;   <span class=\"comment\">// 执行会出错，找不到name1变量</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//console.log(getData1());  // 出错这是获取不到name1的</span></span><br><span class=\"line\"><span class=\"comment\">//2.</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">getData2</span>(<span class=\"params\">callback</span>)</span>&#123;</span><br><span class=\"line\">    setTimeout(<span class=\"function\"><span class=\"params\">()</span>=&gt;</span>&#123;</span><br><span class=\"line\">       <span class=\"keyword\">var</span> name2 = <span class=\"string\">\"张三2\"</span>;</span><br><span class=\"line\">       callback(name2);</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">getData2(<span class=\"function\">(<span class=\"params\">aaa</span>)=&gt;</span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">console</span>.log(aaa);</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"><span class=\"comment\">//3. Promise来处理异步  resolve 成功的回调函数   reject失败的回调函数</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> p1 = <span class=\"keyword\">new</span> <span class=\"built_in\">Promise</span>(<span class=\"function\">(<span class=\"params\">resolve, reject</span>)=&gt;</span>&#123;</span><br><span class=\"line\">    setTimeout(<span class=\"function\"><span class=\"params\">()</span>=&gt;</span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">var</span> name3 = <span class=\"string\">\"张三3\"</span>;</span><br><span class=\"line\">        resolve(name3);</span><br><span class=\"line\">    &#125;,<span class=\"number\">1000</span>);</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\">p1.then(<span class=\"function\">(<span class=\"params\">data</span>)=&gt;</span>&#123;</span><br><span class=\"line\">   <span class=\"built_in\">console</span>.log(data);</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"><span class=\"comment\">//4. 提取一下Promise里参数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">getData3</span>(<span class=\"params\">resolve, reject</span>)</span>&#123;</span><br><span class=\"line\">    setTimeout(<span class=\"function\"><span class=\"params\">()</span>=&gt;</span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">var</span> name4 = <span class=\"string\">\"张三4\"</span>;</span><br><span class=\"line\">        resolve(name4);</span><br><span class=\"line\">    &#125;, <span class=\"number\">1000</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">var</span> p2 = <span class=\"keyword\">new</span> <span class=\"built_in\">Promise</span>(getData3);</span><br><span class=\"line\">p2.then(<span class=\"function\">(<span class=\"params\">data</span>)=&gt;</span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">console</span>.log(data);</span><br><span class=\"line\">&#125;)</span><br></pre></td></tr></table></figure>\n<p>//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</p>\n<h3 id=\"async声明异步方法-await等待异步方法执行完成\"><a href=\"#async声明异步方法-await等待异步方法执行完成\" class=\"headerlink\" title=\"async声明异步方法, await等待异步方法执行完成\"></a>async声明异步方法, await等待异步方法执行完成</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//1.</span></span><br><span class=\"line\"><span class=\"keyword\">async</span> <span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">test1</span>(<span class=\"params\"></span>)</span>&#123;     <span class=\"comment\">// 函数定义为async，返回Promise &#123; '您好！' &#125;</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"string\">\"您好！\"</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// console.log(await test());   // 出错， await必须用在async函数方法中</span></span><br><span class=\"line\"><span class=\"comment\">//2.</span></span><br><span class=\"line\"><span class=\"keyword\">async</span> <span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">test2</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> <span class=\"built_in\">Promise</span>(<span class=\"function\">(<span class=\"params\">resolve, reject</span>)=&gt;</span>&#123;</span><br><span class=\"line\">        setTimeout(<span class=\"function\"><span class=\"params\">()</span>=&gt;</span>&#123;</span><br><span class=\"line\">            <span class=\"keyword\">var</span> name5 = <span class=\"string\">\"张三5\"</span>;</span><br><span class=\"line\">            resolve(name5)</span><br><span class=\"line\">        &#125;, <span class=\"number\">1000</span>);</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">async</span> <span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">output</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">var</span> data = <span class=\"keyword\">await</span> test2();    <span class=\"comment\">// 如果不加await，返回是 Promise &#123; '您好！' &#125;</span></span><br><span class=\"line\">    <span class=\"built_in\">console</span>.log(data);          <span class=\"comment\">// 返回 您好！</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">output();</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 判断一个资源到底是目录还是文件，此方法里有异步函数，需要加上async标签，再用Promise来获取异步返回，最后再用await来调用等待此异步方法执行完</span></span><br><span class=\"line\"><span class=\"keyword\">async</span> <span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">isDir</span>(<span class=\"params\">path</span>)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> <span class=\"built_in\">Promise</span>(<span class=\"function\">(<span class=\"params\">resolve, reject</span>)=&gt;</span>&#123;</span><br><span class=\"line\">        fs.stat(path, (err, states)=&gt;&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(err)&#123;</span><br><span class=\"line\">                <span class=\"built_in\">console</span>.log(err);</span><br><span class=\"line\">                reject(err);</span><br><span class=\"line\">                <span class=\"keyword\">return</span> ;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(states.isDirectory())&#123;</span><br><span class=\"line\">                resolve(<span class=\"literal\">true</span>);</span><br><span class=\"line\">            &#125;<span class=\"keyword\">else</span>&#123;</span><br><span class=\"line\">                resolve(<span class=\"literal\">false</span>);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// 获取所有资源</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">getDir</span>(<span class=\"params\"></span>)</span>&#123;          <span class=\"comment\">// 此方法不需要加async, await只在它所在的函数上加上async就可以了，更外层的函数不需要加上asycn</span></span><br><span class=\"line\">    <span class=\"keyword\">var</span> path = <span class=\"string\">\"./testfs\"</span>;</span><br><span class=\"line\">    <span class=\"keyword\">var</span> dirArr = [];</span><br><span class=\"line\">    fs.readdir(path, <span class=\"keyword\">async</span> (err, data)=&gt;&#123;   <span class=\"comment\">//回调函数需要加async，因为此函数里需要用await</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(err)&#123;</span><br><span class=\"line\">            <span class=\"built_in\">console</span>.log(err);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> ;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">var</span> i = <span class=\"number\">0</span>; i &lt; data.length; i++)&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(<span class=\"keyword\">await</span> isDir(path + <span class=\"string\">\"/\"</span> +data[i]))&#123;</span><br><span class=\"line\">                dirArr.push(data[i]);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"built_in\">console</span>.log(dirArr);    <span class=\"comment\">// 输出 [ 'fs1', 'fs2' ]</span></span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">getDir();</span><br><span class=\"line\"><span class=\"comment\">//※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※※</span></span><br></pre></td></tr></table></figure>\n\n\n<h3 id=\"JSON-parse-text-reviver\"><a href=\"#JSON-parse-text-reviver\" class=\"headerlink\" title=\"JSON.parse(text[, reviver])\"></a>JSON.parse(text[, reviver])</h3><pre><code>参数说明：\ntext:\n    必需， 一个有效的 JSON 字符串。\nreviver: \n    可选，一个转换结果的函数， 将为对象的每个成员调用此函数。\n返回值：\n    返回给定 JSON 字符串转换后的对象。</code></pre><figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&lt;!DOCTYPE <span class=\"meta-keyword\">html</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">charset</span>=<span class=\"string\">\"utf-8\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">title</span>&gt;</span>title)<span class=\"tag\">&lt;/<span class=\"name\">title</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">p</span> <span class=\"attr\">id</span>=<span class=\"string\">\"demo\"</span>&gt;</span>测试JSP函数库JSON.parse()<span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span>&gt;</span></span><br><span class=\"line\"><span class=\"actionscript\"><span class=\"keyword\">const</span> json_str = <span class=\"string\">'&#123;\"result\":true, \"count\":42&#125;'</span>;</span></span><br><span class=\"line\"><span class=\"actionscript\"><span class=\"keyword\">const</span> json = &#123; <span class=\"string\">\"name\"</span>:<span class=\"string\">\"MYZ\"</span> &#125;;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"actionscript\"><span class=\"comment\">// 用来解析JSON字符串，构造由字符串描述的JavaScript值或对象</span></span></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"keyword\">const</span> obj = <span class=\"built_in\">JSON</span>.parse(json_str);</span></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"built_in\">console</span>.log(obj.count);\t\t<span class=\"comment\">// expected output: 42</span></span></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"built_in\">console</span>.log(obj.result);\t<span class=\"comment\">// expected output: true</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"built_in\">console</span>.log(obj);\t\t<span class=\"comment\">// &gt; Object &#123; result: true, count: 42 &#125;</span></span></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"built_in\">console</span>.log(json);\t\t<span class=\"comment\">// &gt; Object &#123; age: 23 &#125;</span></span></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"built_in\">console</span>.log(<span class=\"keyword\">typeof</span>(json_str));\t\t\t<span class=\"comment\">// &gt; \"string\"</span></span></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"built_in\">console</span>.log(<span class=\"keyword\">typeof</span>(json));\t\t\t\t<span class=\"comment\">// &gt; \"object\"</span></span></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"built_in\">console</span>.log(<span class=\"keyword\">typeof</span>(obj) === <span class=\"keyword\">typeof</span>(json));\t<span class=\"comment\">// &gt; true</span></span></span><br><span class=\"line\"></span><br><span class=\"line\">for(x in json)&#123;</span><br><span class=\"line\"><span class=\"javascript\">  <span class=\"built_in\">console</span>.log(x);\t\t<span class=\"comment\">// &gt; \"name\"</span></span></span><br><span class=\"line\"><span class=\"javascript\">  <span class=\"built_in\">console</span>.log(json[x]);\t\t<span class=\"comment\">// &gt; \"MYZ\"</span></span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"built_in\">JSON</span>.parse(<span class=\"string\">'&#123;\"result\":true, \"count\":42&#125;'</span>, <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">k, v</span>) </span>&#123;</span></span><br><span class=\"line\"><span class=\"javascript\">  <span class=\"built_in\">console</span>.log( k );\t\t<span class=\"comment\">// 输出当前三个属性，最后一个为 \"\", &gt; \"result\", &gt; \"count\", &gt; \"\"</span></span></span><br><span class=\"line\"><span class=\"actionscript\">  <span class=\"keyword\">return</span> v;\t\t\t<span class=\"comment\">// 返回修改的值</span></span></span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"built_in\">JSON</span>.parse(<span class=\"string\">'&#123;\"1\": 7, \"2\": 2, \"3\": &#123;\"4\": 4, \"5\": &#123;\"6\": 6&#125;&#125;&#125;'</span>, <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">k, v</span>) </span>&#123;</span></span><br><span class=\"line\"><span class=\"javascript\">  <span class=\"built_in\">console</span>.log( k );\t\t<span class=\"comment\">// 输出当前属性，最后一个为 \"\" &gt; \"1\", &gt; \"2\", &gt; \"4\", &gt; \"6\", &gt; \"5\", &gt; \"3\", &gt; \"\"</span></span></span><br><span class=\"line\"><span class=\"actionscript\">  <span class=\"keyword\">return</span> v;\t\t\t<span class=\"comment\">// 返回修改的值</span></span></span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">html</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"JSON-stringify-value-replacer-space\"><a href=\"#JSON-stringify-value-replacer-space\" class=\"headerlink\" title=\"JSON.stringify(value[, replacer [, space]])\"></a>JSON.stringify(value[, replacer [, space]])</h3><pre><code>value:\n    将要序列化成 一个 JSON 字符串的值。\nreplacer 可选:\n    如果该参数是一个函数，则在序列化过程中，被序列化的值的每个属性都会经过该函数的转换和处理；\n    如果该参数是一个数组，则只有包含在这个数组中的属性名才会被序列化到最终的 JSON 字符串中；\n    如果该参数为 null 或者未提供，则对象所有的属性都会被序列化；\n    关于该参数更详细的解释和示例，请参考使用原生的 JSON 对象一文。\nspace 可选:\n    指定缩进用的空白字符串，用于美化输出（pretty-print）；\n    如果参数是个数字，它代表有多少的空格；上限为10。该值若小于1，则意味着没有空格；\n    如果该参数为字符串（当字符串长度超过10个字母，取其前10个字母），该字符串将被作为空格；\n    如果该参数没有提供（或者为 null），将没有空格。\n返回值:\n一个表示给定值的JSON字符串。</code></pre><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> json_str = <span class=\"string\">'&#123;\"result\":true, \"count\":42&#125;'</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> json = &#123; <span class=\"string\">\"name\"</span>:<span class=\"string\">\"MYZ\"</span> &#125;;</span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(<span class=\"keyword\">typeof</span>(json_str));\t<span class=\"comment\">// &gt; \"string\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(json_str);\t\t\t<span class=\"comment\">// &gt; \"&#123;\"result\":true, \"count\":42&#125;\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(<span class=\"keyword\">typeof</span>(json));\t\t<span class=\"comment\">// &gt; \"object\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(json);\t\t\t\t<span class=\"comment\">// &gt; Object &#123; name: \"MYZ\" &#125;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// JSON.stringify() 将值转换为相应的JSON格式, 也就是将JSON对象转换为字符串：</span></span><br><span class=\"line\"><span class=\"comment\">// JSON对象可以进行如json[\"name\"]来取值，JSON字符串就行如‘&#123; \"name\":\"MYZ\" &#125;’</span></span><br><span class=\"line\">json_ify = <span class=\"built_in\">JSON</span>.stringify(json);</span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(<span class=\"keyword\">typeof</span>(json_ify));\t<span class=\"comment\">// &gt; \"string\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(json_ify);\t\t\t<span class=\"comment\">// &gt; \"&#123;\"name\":\"MYZ\"&#125;\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">json_parse = <span class=\"built_in\">JSON</span>.parse(json_ify);</span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(<span class=\"keyword\">typeof</span>(json_parse));\t<span class=\"comment\">// &gt; \"object\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(json_parse);\t\t\t<span class=\"comment\">// &gt; Object &#123; name: \"MYZ\" &#125;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(json[<span class=\"string\">\"name\"</span>]);\t\t\t<span class=\"comment\">// &gt; \"MYZ\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(json_parse[<span class=\"string\">\"name\"</span>]);\t<span class=\"comment\">// &gt; \"MYZ\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(json[<span class=\"string\">\"name\"</span>] === json_parse[<span class=\"string\">\"name\"</span>]);\t<span class=\"comment\">// &gt; true</span></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> json_str = <span class=\"string\">'&#123;\"result\":true,\"count\":42&#125;'</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> json = &#123; <span class=\"string\">\"name\"</span>:<span class=\"string\">\"MYZ\"</span> &#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> obj1 = <span class=\"built_in\">JSON</span>.parse(json_str);</span><br><span class=\"line\"><span class=\"keyword\">var</span> obj2 = <span class=\"built_in\">JSON</span>.stringify(obj1);</span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(json_str);\t\t\t&gt; <span class=\"string\">\"&#123;\"</span>result<span class=\"string\">\":true,\"</span>count<span class=\"string\">\":42&#125;\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(obj2);\t\t\t\t&gt; <span class=\"string\">\"&#123;\"</span>result<span class=\"string\">\":true,\"</span>count<span class=\"string\">\":42&#125;\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(obj2 === json_str);\t&gt; <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> json_str = <span class=\"string\">'&#123;\"result\":true, \"count\":42&#125;'</span>;\t<span class=\"comment\">//字符串中间有一个空格</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> json = &#123; <span class=\"string\">\"name\"</span>:<span class=\"string\">\"MYZ\"</span> &#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> obj1 = <span class=\"built_in\">JSON</span>.parse(json_str);</span><br><span class=\"line\"><span class=\"keyword\">var</span> obj2 = <span class=\"built_in\">JSON</span>.stringify(obj1);\t<span class=\"comment\">// 转化的字符串中间没有空格</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(json_str);\t\t\t<span class=\"comment\">// &gt; \"&#123;\"result\":true,\"count\":42&#125;\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(obj2);\t\t\t\t<span class=\"comment\">// &gt; \"&#123;\"result\":true,\"count\":42&#125;\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(obj2 === json_str);\t<span class=\"comment\">// &gt; false // 就因为多了空格因此两个字符串不相等</span></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> json_str = <span class=\"string\">'&#123;\"result\": true,\"count\":42&#125;'</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> json = &#123; <span class=\"string\">\"name\"</span>:<span class=\"string\">\"MYZ\"</span> &#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> obj1 = <span class=\"built_in\">JSON</span>.parse(json_str);</span><br><span class=\"line\"><span class=\"keyword\">var</span> obj2 = <span class=\"built_in\">JSON</span>.stringify(obj1);</span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(json_str);\t\t\t<span class=\"comment\">// &gt; \"&#123;\"result\":true,\"count\":42&#125;\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(obj2);\t\t\t\t<span class=\"comment\">// &gt; \"&#123;\"result\":true,\"count\":42&#125;\"</span></span><br><span class=\"line\"><span class=\"built_in\">console</span>.log(obj2 === json_str);\t<span class=\"comment\">// &gt; false</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"html-JS-实现循环编辑HTML标签\"><a href=\"#html-JS-实现循环编辑HTML标签\" class=\"headerlink\" title=\"html+JS 实现循环编辑HTML标签\"></a>html+JS 实现循环编辑HTML标签</h3><p><img src=\"pic.JPG\" alt=\"\"></p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&lt;!DOCTYPE <span class=\"meta-keyword\">html</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span> <span class=\"attr\">lang</span>=<span class=\"string\">\"en\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">charset</span>=<span class=\"string\">\"UTF-8\"</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">title</span>&gt;</span>Employee<span class=\"tag\">&lt;/<span class=\"name\">title</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">class</span>=<span class=\"string\">\"znfz-cont\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">ul</span> <span class=\"attr\">id</span>=<span class=\"string\">\"data\"</span> <span class=\"attr\">class</span>=<span class=\"string\">\"znfz-list\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">ul</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">id</span>=<span class=\"string\">\"myDIV\"</span>&gt;</span> </span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">p</span> <span class=\"attr\">class</span>=<span class=\"string\">\"child\"</span>&gt;</span> div 元素中 class=\"child\" 的 p <span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">p</span> <span class=\"attr\">class</span>=<span class=\"string\">\"child\"</span>&gt;</span> div 元素中 class=\"child\" 的另外一个 p <span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span>在 div 中的 p 元素插入 <span class=\"tag\">&lt;<span class=\"name\">span</span> <span class=\"attr\">class</span>=<span class=\"string\">\"child\"</span>&gt;</span>class=\"child\" 的 span 元素<span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span> 。<span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span>点击按钮为 id=\"myDIV\" 的 div 元素中所有 class=\"child\" 元素添加背景颜色。 <span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">button</span> <span class=\"attr\">onclick</span>=<span class=\"string\">\"myFunction()\"</span>&gt;</span>点我<span class=\"tag\">&lt;/<span class=\"name\">button</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">strong</span>&gt;</span>注意:<span class=\"tag\">&lt;/<span class=\"name\">strong</span>&gt;</span> Internet Explorer 8 及更早 IE 版本不支持 getElementsByClassName() 方法。<span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">script</span>&gt;</span></span><br><span class=\"line\"><span class=\"actionscript\">        <span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">myFunction</span><span class=\"params\">()</span> </span>&#123;</span></span><br><span class=\"line\"><span class=\"javascript\">            <span class=\"keyword\">var</span> x = <span class=\"built_in\">document</span>.getElementById(<span class=\"string\">\"myDIV\"</span>);</span></span><br><span class=\"line\"><span class=\"actionscript\">            <span class=\"keyword\">var</span> y = x.getElementsByClassName(<span class=\"string\">\"child\"</span>);</span></span><br><span class=\"line\"><span class=\"actionscript\">            <span class=\"keyword\">var</span> i;</span></span><br><span class=\"line\">            for (i = 0; i &lt; y.length; i++) &#123;</span><br><span class=\"line\"><span class=\"actionscript\">                y[i].style.backgroundColor = <span class=\"string\">\"red\"</span>;</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span>&gt;</span></span><br><span class=\"line\"><span class=\"actionscript\"><span class=\"keyword\">var</span> lists =[</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\"><span class=\"actionscript\">        <span class=\"string\">\"content\"</span>:<span class=\"string\">\"尾矿库风险单元划分?\"</span>,</span></span><br><span class=\"line\"><span class=\"actionscript\">        <span class=\"string\">\"read_num\"</span>:<span class=\"number\">256</span></span></span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\"><span class=\"actionscript\">        <span class=\"string\">\"content\"</span>:<span class=\"string\">\"尾矿库今年发生的事故?\"</span>,</span></span><br><span class=\"line\"><span class=\"actionscript\">        <span class=\"string\">\"read_num\"</span>:<span class=\"number\">65</span></span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">]</span><br><span class=\"line\"><span class=\"actionscript\"><span class=\"keyword\">var</span> str=<span class=\"string\">\"\"</span>;</span></span><br><span class=\"line\"><span class=\"actionscript\"><span class=\"keyword\">for</span> (<span class=\"keyword\">var</span> i = <span class=\"number\">0</span>; i &lt; lists.length; i++) &#123;</span></span><br><span class=\"line\"><span class=\"handlebars\"><span class=\"xml\">    str += \"<span class=\"tag\">&lt;<span class=\"name\">li</span> <span class=\"attr\">class</span>=<span class=\"string\">'znfz-num'</span>&gt;</span>\" + i + \"<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span>\";</span></span></span><br><span class=\"line\"><span class=\"handlebars\"><span class=\"xml\">    str += \"<span class=\"tag\">&lt;<span class=\"name\">router-link</span> <span class=\"attr\">class</span>=<span class=\"string\">'znfz-txt'</span> <span class=\"attr\">to</span>=<span class=\"string\">''</span>&gt;</span>\" + lists[i].content + \"<span class=\"tag\">&lt;/<span class=\"name\">router-link</span>&gt;</span>\"</span></span></span><br><span class=\"line\"><span class=\"handlebars\"><span class=\"xml\">    str += \"<span class=\"tag\">&lt;<span class=\"name\">span</span> <span class=\"attr\">class</span>=<span class=\"string\">'read-num'</span>&gt;</span>\" + lists[i].read_num + \"<span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span>\"</span></span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"actionscript\"><span class=\"comment\">// 下面两种方法都可以，只不过getElementsByClassName返回的是数组元素，需要加上索引值如[0]</span></span></span><br><span class=\"line\"><span class=\"actionscript\"><span class=\"comment\">//document.getElementById(\"data\").innerHTML=str;</span></span></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"built_in\">document</span>.getElementsByClassName(<span class=\"string\">\"znfz-list\"</span>)[<span class=\"number\">0</span>].innerHTML=str;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"actionscript\"><span class=\"keyword\">var</span> name = <span class=\"string\">\"张三\"</span>;</span></span><br><span class=\"line\"><span class=\"actionscript\"><span class=\"keyword\">var</span> age = <span class=\"number\">20</span>;</span></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"built_in\">console</span>.log(<span class=\"string\">`<span class=\"subst\">$&#123;name&#125;</span>的年龄是<span class=\"subst\">$&#123;age&#125;</span>`</span>);</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">html</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n\n\n\n\n\n"},{"title":"HTML","_content":"\n### 1.HTML 链接&锚语法\n链接的 HTML 代码很简单。它类似这样：\n``` HTML  \n\t<a href=\"https://www.baidu.com\">Link text</a>\n```\n命名锚的语法：\n``` HTML\n\t<a name=\"label\">锚（显示在页面上的文本）</a>\n\t您可以使用 id 属性来替代 name 属性，命名锚同样有效。\n\t<a name=\"tips\">基本的注意事项 - 有用的提示</a>\n\t<a href=\"#tips\">有用的提示</a>\n\t您也可以在其他页面中创建指向该锚的链接：\n\t<a href=\"http://www.w3school.com.cn/html/html_links.asp#tips\">有用的提示</a>\n\t将 # 符号和锚名称添加到 URL 的末端，就可以直接链接到 tips 这个命名锚了。\n```\n\n### 2.img\n替换文本属性（Alt）  \nalt 属性用来为图像定义一串预备的可替换的文本。替换文本属性的值是用户定义的。  \n在浏览器无法载入图像时，替换文本属性告诉读者她们失去的信息。此时，浏览器将显示这个替代性的文本而不是图像。  \n为页面上的图像都加上替换文本属性是个好习惯，这样有助于更好的显示信息，并且对于那些使用纯文本浏览器的人来说是非常有用的。  \n``` HTML\n\t// 图像的 align 属性设置为 \"right\"。图像将浮动到文本的右侧。\n\t<img src=\"boat.gif\" alt=\"Big Boat\" width=\"50\" height=\"50\" align =\"right\"> \n\t您也可以把图像作为链接来使用：\n\t<a href=\"/example/html/lastpage.html\"><img border=\"0\" src=\"/i/eg_buttonnext.gif\" /></a>\n```\n\n### 3.table\n#### 3.1\n![](1.png)\n``` HTML\n\t// background 向表格添加背景图片\n\t<table border=\"1\" background=\"/i/eg_bg_07.gif\">\n\t\t<tr>\t\t\t\t\t\t\t\t\t\t\t// <tr> 表行\n\t\t\t<th bgcolor=\"red\">姓名</th>\t\t\t\t\t// <th> 表头, 表头设置特定背景色\n\t\t\t<td>Bill Gates</td>\t\t\t\t\t\t\t// <td> 表列\n\t\t</tr>\n\t\t<tr>\n\t\t\t<th rowspan=\"2\">电话</th>\n\t\t\t<td>这个单元包含一个列表：\n\t\t\t<ul>\n\t\t\t\t<li><a href=\"https://www.baidu.com\">苹果</a></li>\n\t\t\t\t<li>香蕉</li>\n\t\t\t\t<li>菠萝</li>\n\t\t\t</ul>\n\t\t\t</td>\n\t\t</tr>\n\t\t<tr>\n\t\t<td>\t\t\t\t\n\t\t\t// Cell padding 来创建单元格内容与其边框之间的空白。\n\t\t\t// Cell spacing 增加单元格之间的距离\n\t\t\t// bgcolor 向表格添加背景色\n\t\t\t<table border=\"1\" cellpadding=\"10\" cellspacing=\"3\" bgcolor=\"blue\">\t\t\n\t\t\t\t<tr>\n\t\t\t\t\t<td>A</td>\n\t\t\t\t\t<td>B</td>\n\t\t\t\t</tr>\n\t\t\t\t<tr>\n\t\t\t\t\t<td>C</td>\n\t\t\t\t\t<td>D</td>\n\t\t\t\t</tr>\n\t\t\t</table>\n\t\t</td>\n\t\t</tr>\n\t</table>\n```\n#### 3.2\n![](3.png)\n``` HTML\n\t<p>Table with frame=\"box\":</p>\n\t<table frame=\"box\">\n\t<tr>\n\t\t<th>Month</th>\n\t\t<th>Savings</th>\n\t</tr>\n\t<tr>\n\t\t<td>January</td>\n\t\t<td>$100</td>\n\t</tr>\n\t</table>\n\t\n\t<p>Table with frame=\"above\":</p>\n\t<table frame=\"above\">\n\t<tr>\n\t\t<th>Month</th>\n\t\t<th>Savings</th>\n\t</tr>\n\t<tr>\n\t\t<td>January</td>\n\t\t<td>$100</td>\n\t</tr>\n\t</table>\n\t<p>Table with frame=\"below\":</p>\n\t<table frame=\"below\">\n\t<tr>\n\t\t<th>Month</th>\n\t\t<th>Savings</th>\n\t</tr>\n\t<tr>\n\t\t<td>January</td>\n\t\t<td>$100</td>\n\t</tr>\n\t</table>\n\t\n\t<p>Table with frame=\"hsides\":</p>\n\t<table frame=\"hsides\">\n\t<tr>\n\t\t<th>Month</th>\n\t\t<th>Savings</th>\n\t</tr>\n\t<tr>\n\t\t<td>January</td>\n\t\t<td>$100</td>\n\t</tr>\n\t</table>\n\t\n\t<p>Table with frame=\"vsides\":</p>\n\t<table frame=\"vsides\">\n\t<tr>\n\t\t<th>Month</th>\n\t\t<th>Savings</th>\n\t</tr>\n\t<tr>\n\t\t<td>January</td>\n\t\t<td>$100</td>\n\t</tr>\n</table>\n```\n#### 3.3\n单元格的边框没有被显示出来。为了避免这种情况，在空单元格中添加一个空格占位符，就可以将边框显示出来。 \n![](table_td_empty.gif)\n``` HTML\n\t<table border=\"1\">\t\t\t// 带边框\n\t<caption>我的标题</caption>\t// table 标题\n\t<tr>\n\t<td>row 1, cell 1</td>\n\t<td>row 1, cell 2</td>\n\t</tr>\n\t<tr>\n\t<td>&nbsp;</td>\t\t\t\t// 空格由和号开始 (\"&\")，然后是字符\"nbsp\"，并以分号结尾(\";\")\n\t<td>row 2, cell 2</td>\n\t</tr>\n\t</table>\n```\n#### 3.4\n横跨两列的单元格，横跨两行的单元格  \n![](2.png)\n``` HTML\n\t<th colspan=\"2\">电话</th>\n\t<th rowspan=\"2\">电话</th>\n```\n\n### 4.无序ul,有序ol,自定义列表项dl\n![](4.png)\n``` html\n<h2>一个定义列表：</h2>\n<ul type=\"square\">\t\t// type=\"circle\" type=\"disc\"\n  <li>咖啡</li>\n  <li>茶</li>\n  <li>牛奶</li>\n</ul>\n\n<ol start=\"50\">\n  <li>咖啡</li>\n  <li>牛奶</li>\n  <li>茶</li>\n</ol>\n<ol type=\"A\">\t// type=\"a\", type=\"I\", type=\"i\"\n  <li>咖啡</li>\n  <li>牛奶</li>\n  <li>茶</li>\n  <ul>\n    <li>红茶</li>\n    <li>绿茶\n      <ul>\n      <li>中国茶</li>\n      <li>非洲茶</li>\n      </ul>\n  </li>\n  </ul>\n</ol>\n\n<dl>\n   <dt>计算机</dt>\n   <dd>用来计算的仪器 ... ...</dd>\n   <dt>显示器</dt>\n   <dd>以视觉方式显示信息的装置 ... ...</dd>\n</dl>\n```\n\n### 5. div, span\n``` html\n\t<!DOCTYPE html>\n\t<html>\n\t<head>\n\t<link rel=\"stylesheet\" type=\"text/css\" href=\"mystyle.css\">\n\t<style type=\"text/css\">\n\tbody {\n\t\tbackground-color: pink;\n\t\t}\n\t#header {\n\t\tbackground-color:black;\n\t\tcolor:white;\n\t\ttext-align:center;\n\t\tpadding:5px;\n\t}\n\t.nav {\n\t\tline-height:30px;\n\t\tbackground-color:#eeeeee;\n\t\theight:300px;\n\t\twidth:100px;\n\t\tfloat:left;\n\t\tpadding:5px;\t      \n\t}\n\t#section {\n\t\twidth:350px;\n\t\tfloat:left;\n\t\tpadding:10px;\t \t \n\t}\n\t#footer {\n\t\tbackground-color:black;\n\t\tcolor:white;\n\t\tclear:both;\n\t\ttext-align:center;\n\t\tpadding:5px;\t \t \n\t}\n\t</style>\n\t</head>\n\t<body>\n\t<div id=\"header\">\n\t<h1>City Gallery</h1>\n\t</div>\n\t<div class=\"nav\">\n\tLondon<br>\n\tParis<br>\n\tTokyo<br>\n\t</div>\n\t<div id=\"section\">\n\t<h2>London</h2>\n\t<p>\n\tLondon is the <span style=\"color:red\">capital city</span> of England. It is the most populous city in the United Kingdom,with a metropolitan area of over 13 million inhabitants.\n\t</p>\n\t</div>\n\t<div id=\"footer\">\n\tCopyright ? W3Schools.com\n\t</div>\n\t</body>\n\t</html>\n```\n### 6. 框架 frameset, frame\n![](6.png)\n不能将 \"body\" 标签与 \"frameset\" 标签同时使用！\n假如一个框架有可见边框，用户可以拖动边框来改变它的大小。为了避免这种情况发生，可以在 <frame> 标签中加入：noresize=\"noresize\"。\n``` html\n<html>\n\t<frameset rows=\"25%,50%,25%\">\t\t\t\t\t// 水平框架\n\t\t<frame src=\"/example/html/frame_a.html\">\n\t\t<frameset cols=\"25%,50%,25%\">\t\t\t\t// 垂直框架\n\t\t\t<frame src=\"https://www.sina.com.cn/\">\n\t\t\t<frame src=\"https://www.baidu.com\">\n\t\t\t<frame src=\"/example/html/frame_c.html\">\n\t\t</frameset>\n\t\t<frame src=\"/example/html/frame_c.html\">\n\t</frameset>\n</html>\n```\n![](6_1.png)\n```\n// // view-source:https://www.w3school.com.cn\n<html>\n<frameset cols=\"120,*\">\n  <frame src=\"/example/html/html_contents.html\">\n  <frame src=\"/example/html/frame_a.html\" name=\"showframe\">\n</frameset>\n</html>\n\n// view-source:https://www.w3school.com.cn/example/html/html_contents.html\n<html>\n<body>\n<a href =\"/example/html/frame_a.html\" target =\"showframe\">Frame a</a><br />\n<a href =\"/example/html/frame_b.html\" target =\"showframe\">Frame b</a><br />\n<a href =\"/example/html/frame_c.html\" target =\"showframe\">Frame c</a>\n</body>\n</html>\n\n// view-source:https://www.w3school.com.cn/example/html/frame_a.html   , frame_b.html,  frame_c.html\n<html>\n<body bgcolor=\"#8F8FBD\">\n<h3>Frame A</h3>\n</body>\n</html>\n\n```\n\n### 7. 内联框架 iframe\n![](7.png)\nheight 和 width 属性用于规定 iframe 的高度和宽度，属性值的默认单位是像素，但也可以用百分比来设定（比如 \"80%\"）\nframeborder 属性规定是否显示 iframe 周围的边框，设置属性值为 \"0\" 就可以移除边框\n注释：由于链接的目标匹配 iframe 的名称，所以点击\"百度新闻\"链接, 会在 iframe 中打开百度新闻网页。\n``` html\n<iframe src=\"https://www.baidu.com\" frameborder=\"0\" width=\"80%\" height=\"200\" name=\"iframe_a\"></iframe>\n<p><a href=\"http://news.baidu.com/\" target=\"iframe_a\">百度新闻</a></p>\n```\n<iframe src=\"https://www.baidu.com\" frameborder=\"0\" width=\"80%\" height=\"200\" name=\"iframe_a\"></iframe>\n<p><a href=\"http://news.baidu.com/\" target=\"iframe_a\">百度新闻</a></p>\n\n### 8. HTML 头部元素\n```\n标签\t描述  \n<head>\t定义关于文档的信息。  \n<title>\t定义文档标题。  \n<base>\t定义页面上所有链接的默认地址或默认目标。  \n<link>\t定义文档与外部资源之间的关系。\n\t<link> 标签最常用于连接样式表：\n<meta>\t定义关于 HTML 文档的元数据。 \n\t<meta> 标签提供关于 HTML 文档的元数据。元数据不会显示在页面上，但是对于机器是可读的。\n\t典型的情况是，meta 元素被用于规定页面的描述、关键词、文档的作者、最后修改时间以及其他元数据。\n\t<meta> 标签始终位于 head 元素中。\n\t元数据可用于浏览器（如何显示内容或重新加载页面），搜索引擎（关键词），或其他 web 服务。\n\t下面的 meta 元素定义页面的描述：\n\t<meta name=\"description\" content=\"Free Web tutorials on HTML, CSS, XML\" />\n\t下面的 meta 元素定义页面的关键词：\n\t<meta name=\"keywords\" content=\"HTML, CSS, XML\" />\n\tname 和 content 属性的作用是描述页面的内容。\n<script>\t定义客户端脚本。  \n<style>\t定义文档的样式信息。\n\t<style> 标签用于为 HTML 文档定义样式信息。\n\t您可以在 style 元素内规定 HTML 元素在浏览器中呈现的样式\n```\n\n### 9. HTML 字符实体\n```\n注释：实体名称对大小写敏感！\n\n显示结果\t描述\t\t实体名称\t\t实体编号\n\t\t空格\t\t&nbsp;\t\t\t&#160;\n<\t\t小于号\t\t&lt;\t\t\t&#60;\n>\t\t大于号\t\t&gt;\t\t\t&#62;\n&\t\t和号\t\t&amp;\t\t\t&#38;\n\"\t\t引号\t\t&quot;\t\t\t&#34;\n'\t\t撇号 \t\t&apos;IE不支持\t&#39;\n￠\t\t分（cent）\t&cent;\t\t\t&#162;\n£\t\t镑（pound）\t&pound;\t\t\t&#163;\n¥\t\t元（yen）\t&yen;\t\t\t&#165;\n€\t\t欧元（euro）\t&euro;\t\t\t&#8364;\n§\t\t小节\t\t&sect;\t\t\t&#167;\n©\t\t版权(copyright)\t&copy;\t\t\t&#169;\n®\t\t注册商标\t&reg;\t\t\t&#174;\n™\t\t商标\t\t&trade;\t\t\t&#8482;\n×\t\t乘号\t\t&times;\t\t\t&#215;\n÷\t\t除号\t\t&divide;\t\t&#247;\n```\n\n### 10. HTML 颜色名\n提示：仅有 16 种颜色名被 W3C 的 HTML 4.0 标准支持  \n它们是：aqua、black、blue、fuchsia、gray、green、lime、maroon、navy、olive、purple、red、silver、teal、white、yellow。  \n如果使用其它颜色的话，就应该使用十六进制的颜色值。   \n\n### 11. HTML <!DOCTYPE>\n```\n<!DOCTYPE> 声明帮助浏览器正确地显示网页\nWeb 世界中存在许多不同的文档。只有了解文档的类型，浏览器才能正确地显示文档。\nHTML 也有多个不同的版本，只有完全明白页面中使用的确切 HTML 版本，浏览器才能完全正确地显示出 HTML 页面。这就是 <!DOCTYPE> 的用处。\n<!DOCTYPE> 不是 HTML 标签。它为浏览器提供一项信息（声明），即 HTML 是用什么版本编写的。\n常用的声明\nHTML5\n<!DOCTYPE html>\n\nHTML 4.01\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\"\n\"http://www.w3.org/TR/html4/loose.dtd\">\n\nXHTML 1.0\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n```\n\n### 12. form表单\nHTML 表单用于收集用户输入。```<form>``` 元素定义 HTML 表单\n\n下面是 ```<form>``` 属性的列表：\n属性\t描述\naccept-charset\t规定在被提交表单中使用的字符集（默认：页面字符集）。\naction\t规定向何处提交表单的地址（URL）（提交页面）。\nautocomplete\t规定浏览器应该自动完成表单(默认:开启)\nenctype\t规定被提交数据的编码（默认：url-encoded）。\nid\t表单唯一id\tid=\"form1\"\nmethod\t规定在提交表单时所用的 HTTP 方法（默认：GET）。\nname\t规定识别表单的名称（对于 DOM 使用：document.forms.name）。\nnovalidate\t规定在提交表单时不对表单数据进行验证。\ntarget\t规定 action 属性中地址的目标（默认：_self）。\n\n列出了一些常用的输入限制\nautocomplete\t当自动完成开启，浏览器会基于用户之前的输入值自动填写值\tautocomplete=\"off\"\nautofocus\t规定当页面加载时 ```<input>``` 元素应该自动获得焦点\tautofocus\ndisabled\t规定输入字段应该被禁用, 不可用和不可点击, 被禁用的元素不会被提交\nmax\t规定输入字段的最大值。\nmaxlength\t规定输入字段的最大字符数。\nmin\t规定输入字段的最小值。\npattern\t规定通过其检查输入值的正则表达式。 只能包含三个字母的输入字段:pattern=\"[A-Za-z]{3}\"\nplaceholder 属性规定用以描述输入字段预期值的提示（样本值或有关格式的简短描述）\nreadonly\t规定输入字段为只读(无法修改).\nrequired\t如果设置，则规定在提交表单之前必须填写输入字段。\nsize\t规定输入字段的宽度（以字符计）。\nstep\t规定输入字段的合法数字间隔。如果 step=\"3\"，则合法数字应该是 -3、0、3、6、等等。\nvalue\t规定输入字段的默认值。\n\n下列属性适用于 type=\"submit\" 以及 type=\"image\"。\nformaction 属性覆盖 ```<form>``` 元素的 action 属性.\tformaction=\"demo_admin.asp\"\nformenctype 属性规定当把表单数据（form-data）提交至服务器时如何对其进行编码(仅针对 method=\"post\" 的表单).\tformenctype=\"multipart/form-data\"\nformmethod 属性定义用以向 action URL 发送表单数据(form-data)的HTTP方法.\tformmethod=\"post\"\nformtarget 属性规定的名称或关键词指示提交表单后在何处显示接收到的响应。\tformtarget=\"_blank\"会提交到新窗口/选项卡\n\n下列属性适用于 type=\"submit\"\n如果设置，则规定在提交表单时不对 ```<input>``` 元素进行验证。\nformnovalidate 属性覆盖 ```<form>``` 元素的 novalidate 属性。\tformnovalidate \n\n下列属性适用于 type=\"image\"\nheight 和 width 属性规定 ```<input type=\"image\">```元素的高度和宽度。\n![](12.png)\n``` HTML\n// action 属性定义在提交表单时执行的动作,指定了某个服务器脚本来处理被提交表单, 通常表单会被提交到 web 服务器上的网页\n// method 属性规定在提交表单时所用的 HTTP 方法（GET 或 POST）\n// 如果表单提交是被动的(比如搜索引擎查询),并且没有敏感信息,当您使用 GET 时，表单数据在页面地址栏中是可见的:action_page.php?firstname=Mickey&lastname=Mouse\n// GET 最适合少量数据的提交。浏览器会设定容量限制。\n// POST 的安全性更加，因为在页面地址栏中被提交的数据是不可见的. 如果表单正在更新数据，或者包含敏感信息(例如密码)\n<form action=\"action_page.php\" method=\"GET\" id=\"form1\">\n First name:<br>\n\n<fieldset>\n\n// 定义用于文本输入的单行输入字段\n<input type=\"text\" name=\"firstname\"  value=\"jone\" disabled>\n<br>\n\n// password 字段中的字符会被做掩码处理（显示为星号或实心圆）\n<input type=\"password\" name=\"psw\" autocomplete=\"off\" autofocus>\n<br>\n\n// <datalist> 元素为 <input> 元素规定预定义选项列表。\n<input list=\"browsers\" name=\"browser\" placeholder=\"Firefox\">\n<datalist id=\"browsers\">\n  <option value=\"Internet Explorer\">\n  <option value=\"Firefox\">\n  <option value=\"Chrome\">\n  <option value=\"Opera\">\n  <option value=\"Safari\">\n</datalist>\n\n// 单选按钮允许用户在有限数量的选项中选择其中之一\n<input type=\"radio\" name=\"sex\" value=\"male\" checked>Male\n<br>\n<input type=\"radio\" name=\"sex\" value=\"female\">Female\n<br>\n\n// 复选框允许用户在有限数量的选项中选择零个或多个选项\n<input type=\"checkbox\" name=\"vehicle\" value=\"Bike\">I have a bike\n<br>\n<input type=\"checkbox\" name=\"vehicle\" value=\"Car\">I have a car\n<br>\n\n// 下拉列表\n<select name=\"cars\">\n<option value=\"volvo\">Volvo</option>\n<option value=\"saab\" selected>Saab</option>\t\t// 通过添加 selected 属性来定义预定义选项。\n<option value=\"fiat\">Fiat</option>\n<option value=\"audi\">Audi</option>\n</select>\n\n// 定义多行输入字段(文本域)\n<textarea name=\"message\" rows=\"10\" cols=\"30\" readonly>\nThe cat was playing in the garden.\n</textarea>\n\n// 定义可点击的按钮\n<button type=\"button\" onclick=\"alert('Hello World!')\">Click Me!</button>\n\n</fieldset>\n\nQuantity (between 1 and 5):<br>\n<input type=\"number\" name=\"quantity\" min=\"1\" max=\"5\">\n<br>\n\nQuantity (between 1 and 5):<br>\n<input type=\"number\" name=\"quantity\" min=\"1\" max=\"5\">\n<br>\n\n// 日期\nBirthday:\n  <input type=\"date\" name=\"bday1\"><br>\nEnter a date before 1980-01-01:\n  <input type=\"date\" name=\"bday2\" max=\"1979-12-31\"><br>\n  Enter a date after 2000-01-01:\n  <input type=\"date\" name=\"bday3\" min=\"2000-01-02\"><br>\n\nSelect your favorite color:\n  <input type=\"color\" name=\"favcolor\"><br>\n\n// 用于应该包含一定范围内的值的输入字段, 根据浏览器支持，输入字段能够显示为滑块控件\n<input type=\"range\" name=\"points\" min=\"0\" max=\"10\"><br>\n\nBirthday (month and year):\n  <input type=\"month\" name=\"bdaymonth\"><br>\nSelect a week:\n  <input type=\"week\" name=\"week_year\"><br>\nSelect a time:\n  <input type=\"time\" name=\"usr_time\"><br>\nBirthday (date and time):\n  <input type=\"datetime\" name=\"bdaytime\"><br>\nBirthday (date and time):\n  <input type=\"datetime-local\" name=\"bdaytime\"><br>\nE-mail:\n  <input type=\"email\" name=\"email\"><br>\nSearch Google:\n  <input type=\"search\" name=\"googlesearch\"><br>\nTelephone:\n  <input type=\"tel\" name=\"usrtel\"><br>\nAdd your homepage 某些智能手机识别 url 类型，并向键盘添加 \".com\" 以匹配 url 输入。:\n  <input type=\"url\" name=\"homepage\"><br>\n\n// multiple 属性是布尔属性。如果设置，则规定允许用户在 <input> 元素中输入一个以上的值。multiple 属性适用于以下输入类型：email 和 file。\nSelect images: <input type=\"file\" name=\"img\" multiple><br>\n\n\n\n\n// 如果要正确地被提交，每个输入字段必须设置一个 name 属性。\n// 定义用于向表单处理程序（form-handler）提交表单的按钮\n// 表单处理程序在表单的 action 属性中指定\n<input type=\"submit\" value=\"Submit\"> \n\n// formaction 属性覆盖 <form> 元素的 action 属性\n<input type=\"submit\" formaction=\"demo_admin.asp\" value=\"Submit as admin\">\n   \n</form> \n\n下面的 \"Last name\" 字段位于 form 元素之外，但仍然是表单的一部分。<br>\nLast name: <input type=\"text\" name=\"lname\" form=\"form1\">\n\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/technologies/web/HTML.md","raw":"---\ntitle: HTML\ncategories:\n- technologies\n- web前端\n---\n\n### 1.HTML 链接&锚语法\n链接的 HTML 代码很简单。它类似这样：\n``` HTML  \n\t<a href=\"https://www.baidu.com\">Link text</a>\n```\n命名锚的语法：\n``` HTML\n\t<a name=\"label\">锚（显示在页面上的文本）</a>\n\t您可以使用 id 属性来替代 name 属性，命名锚同样有效。\n\t<a name=\"tips\">基本的注意事项 - 有用的提示</a>\n\t<a href=\"#tips\">有用的提示</a>\n\t您也可以在其他页面中创建指向该锚的链接：\n\t<a href=\"http://www.w3school.com.cn/html/html_links.asp#tips\">有用的提示</a>\n\t将 # 符号和锚名称添加到 URL 的末端，就可以直接链接到 tips 这个命名锚了。\n```\n\n### 2.img\n替换文本属性（Alt）  \nalt 属性用来为图像定义一串预备的可替换的文本。替换文本属性的值是用户定义的。  \n在浏览器无法载入图像时，替换文本属性告诉读者她们失去的信息。此时，浏览器将显示这个替代性的文本而不是图像。  \n为页面上的图像都加上替换文本属性是个好习惯，这样有助于更好的显示信息，并且对于那些使用纯文本浏览器的人来说是非常有用的。  \n``` HTML\n\t// 图像的 align 属性设置为 \"right\"。图像将浮动到文本的右侧。\n\t<img src=\"boat.gif\" alt=\"Big Boat\" width=\"50\" height=\"50\" align =\"right\"> \n\t您也可以把图像作为链接来使用：\n\t<a href=\"/example/html/lastpage.html\"><img border=\"0\" src=\"/i/eg_buttonnext.gif\" /></a>\n```\n\n### 3.table\n#### 3.1\n![](1.png)\n``` HTML\n\t// background 向表格添加背景图片\n\t<table border=\"1\" background=\"/i/eg_bg_07.gif\">\n\t\t<tr>\t\t\t\t\t\t\t\t\t\t\t// <tr> 表行\n\t\t\t<th bgcolor=\"red\">姓名</th>\t\t\t\t\t// <th> 表头, 表头设置特定背景色\n\t\t\t<td>Bill Gates</td>\t\t\t\t\t\t\t// <td> 表列\n\t\t</tr>\n\t\t<tr>\n\t\t\t<th rowspan=\"2\">电话</th>\n\t\t\t<td>这个单元包含一个列表：\n\t\t\t<ul>\n\t\t\t\t<li><a href=\"https://www.baidu.com\">苹果</a></li>\n\t\t\t\t<li>香蕉</li>\n\t\t\t\t<li>菠萝</li>\n\t\t\t</ul>\n\t\t\t</td>\n\t\t</tr>\n\t\t<tr>\n\t\t<td>\t\t\t\t\n\t\t\t// Cell padding 来创建单元格内容与其边框之间的空白。\n\t\t\t// Cell spacing 增加单元格之间的距离\n\t\t\t// bgcolor 向表格添加背景色\n\t\t\t<table border=\"1\" cellpadding=\"10\" cellspacing=\"3\" bgcolor=\"blue\">\t\t\n\t\t\t\t<tr>\n\t\t\t\t\t<td>A</td>\n\t\t\t\t\t<td>B</td>\n\t\t\t\t</tr>\n\t\t\t\t<tr>\n\t\t\t\t\t<td>C</td>\n\t\t\t\t\t<td>D</td>\n\t\t\t\t</tr>\n\t\t\t</table>\n\t\t</td>\n\t\t</tr>\n\t</table>\n```\n#### 3.2\n![](3.png)\n``` HTML\n\t<p>Table with frame=\"box\":</p>\n\t<table frame=\"box\">\n\t<tr>\n\t\t<th>Month</th>\n\t\t<th>Savings</th>\n\t</tr>\n\t<tr>\n\t\t<td>January</td>\n\t\t<td>$100</td>\n\t</tr>\n\t</table>\n\t\n\t<p>Table with frame=\"above\":</p>\n\t<table frame=\"above\">\n\t<tr>\n\t\t<th>Month</th>\n\t\t<th>Savings</th>\n\t</tr>\n\t<tr>\n\t\t<td>January</td>\n\t\t<td>$100</td>\n\t</tr>\n\t</table>\n\t<p>Table with frame=\"below\":</p>\n\t<table frame=\"below\">\n\t<tr>\n\t\t<th>Month</th>\n\t\t<th>Savings</th>\n\t</tr>\n\t<tr>\n\t\t<td>January</td>\n\t\t<td>$100</td>\n\t</tr>\n\t</table>\n\t\n\t<p>Table with frame=\"hsides\":</p>\n\t<table frame=\"hsides\">\n\t<tr>\n\t\t<th>Month</th>\n\t\t<th>Savings</th>\n\t</tr>\n\t<tr>\n\t\t<td>January</td>\n\t\t<td>$100</td>\n\t</tr>\n\t</table>\n\t\n\t<p>Table with frame=\"vsides\":</p>\n\t<table frame=\"vsides\">\n\t<tr>\n\t\t<th>Month</th>\n\t\t<th>Savings</th>\n\t</tr>\n\t<tr>\n\t\t<td>January</td>\n\t\t<td>$100</td>\n\t</tr>\n</table>\n```\n#### 3.3\n单元格的边框没有被显示出来。为了避免这种情况，在空单元格中添加一个空格占位符，就可以将边框显示出来。 \n![](table_td_empty.gif)\n``` HTML\n\t<table border=\"1\">\t\t\t// 带边框\n\t<caption>我的标题</caption>\t// table 标题\n\t<tr>\n\t<td>row 1, cell 1</td>\n\t<td>row 1, cell 2</td>\n\t</tr>\n\t<tr>\n\t<td>&nbsp;</td>\t\t\t\t// 空格由和号开始 (\"&\")，然后是字符\"nbsp\"，并以分号结尾(\";\")\n\t<td>row 2, cell 2</td>\n\t</tr>\n\t</table>\n```\n#### 3.4\n横跨两列的单元格，横跨两行的单元格  \n![](2.png)\n``` HTML\n\t<th colspan=\"2\">电话</th>\n\t<th rowspan=\"2\">电话</th>\n```\n\n### 4.无序ul,有序ol,自定义列表项dl\n![](4.png)\n``` html\n<h2>一个定义列表：</h2>\n<ul type=\"square\">\t\t// type=\"circle\" type=\"disc\"\n  <li>咖啡</li>\n  <li>茶</li>\n  <li>牛奶</li>\n</ul>\n\n<ol start=\"50\">\n  <li>咖啡</li>\n  <li>牛奶</li>\n  <li>茶</li>\n</ol>\n<ol type=\"A\">\t// type=\"a\", type=\"I\", type=\"i\"\n  <li>咖啡</li>\n  <li>牛奶</li>\n  <li>茶</li>\n  <ul>\n    <li>红茶</li>\n    <li>绿茶\n      <ul>\n      <li>中国茶</li>\n      <li>非洲茶</li>\n      </ul>\n  </li>\n  </ul>\n</ol>\n\n<dl>\n   <dt>计算机</dt>\n   <dd>用来计算的仪器 ... ...</dd>\n   <dt>显示器</dt>\n   <dd>以视觉方式显示信息的装置 ... ...</dd>\n</dl>\n```\n\n### 5. div, span\n``` html\n\t<!DOCTYPE html>\n\t<html>\n\t<head>\n\t<link rel=\"stylesheet\" type=\"text/css\" href=\"mystyle.css\">\n\t<style type=\"text/css\">\n\tbody {\n\t\tbackground-color: pink;\n\t\t}\n\t#header {\n\t\tbackground-color:black;\n\t\tcolor:white;\n\t\ttext-align:center;\n\t\tpadding:5px;\n\t}\n\t.nav {\n\t\tline-height:30px;\n\t\tbackground-color:#eeeeee;\n\t\theight:300px;\n\t\twidth:100px;\n\t\tfloat:left;\n\t\tpadding:5px;\t      \n\t}\n\t#section {\n\t\twidth:350px;\n\t\tfloat:left;\n\t\tpadding:10px;\t \t \n\t}\n\t#footer {\n\t\tbackground-color:black;\n\t\tcolor:white;\n\t\tclear:both;\n\t\ttext-align:center;\n\t\tpadding:5px;\t \t \n\t}\n\t</style>\n\t</head>\n\t<body>\n\t<div id=\"header\">\n\t<h1>City Gallery</h1>\n\t</div>\n\t<div class=\"nav\">\n\tLondon<br>\n\tParis<br>\n\tTokyo<br>\n\t</div>\n\t<div id=\"section\">\n\t<h2>London</h2>\n\t<p>\n\tLondon is the <span style=\"color:red\">capital city</span> of England. It is the most populous city in the United Kingdom,with a metropolitan area of over 13 million inhabitants.\n\t</p>\n\t</div>\n\t<div id=\"footer\">\n\tCopyright ? W3Schools.com\n\t</div>\n\t</body>\n\t</html>\n```\n### 6. 框架 frameset, frame\n![](6.png)\n不能将 \"body\" 标签与 \"frameset\" 标签同时使用！\n假如一个框架有可见边框，用户可以拖动边框来改变它的大小。为了避免这种情况发生，可以在 <frame> 标签中加入：noresize=\"noresize\"。\n``` html\n<html>\n\t<frameset rows=\"25%,50%,25%\">\t\t\t\t\t// 水平框架\n\t\t<frame src=\"/example/html/frame_a.html\">\n\t\t<frameset cols=\"25%,50%,25%\">\t\t\t\t// 垂直框架\n\t\t\t<frame src=\"https://www.sina.com.cn/\">\n\t\t\t<frame src=\"https://www.baidu.com\">\n\t\t\t<frame src=\"/example/html/frame_c.html\">\n\t\t</frameset>\n\t\t<frame src=\"/example/html/frame_c.html\">\n\t</frameset>\n</html>\n```\n![](6_1.png)\n```\n// // view-source:https://www.w3school.com.cn\n<html>\n<frameset cols=\"120,*\">\n  <frame src=\"/example/html/html_contents.html\">\n  <frame src=\"/example/html/frame_a.html\" name=\"showframe\">\n</frameset>\n</html>\n\n// view-source:https://www.w3school.com.cn/example/html/html_contents.html\n<html>\n<body>\n<a href =\"/example/html/frame_a.html\" target =\"showframe\">Frame a</a><br />\n<a href =\"/example/html/frame_b.html\" target =\"showframe\">Frame b</a><br />\n<a href =\"/example/html/frame_c.html\" target =\"showframe\">Frame c</a>\n</body>\n</html>\n\n// view-source:https://www.w3school.com.cn/example/html/frame_a.html   , frame_b.html,  frame_c.html\n<html>\n<body bgcolor=\"#8F8FBD\">\n<h3>Frame A</h3>\n</body>\n</html>\n\n```\n\n### 7. 内联框架 iframe\n![](7.png)\nheight 和 width 属性用于规定 iframe 的高度和宽度，属性值的默认单位是像素，但也可以用百分比来设定（比如 \"80%\"）\nframeborder 属性规定是否显示 iframe 周围的边框，设置属性值为 \"0\" 就可以移除边框\n注释：由于链接的目标匹配 iframe 的名称，所以点击\"百度新闻\"链接, 会在 iframe 中打开百度新闻网页。\n``` html\n<iframe src=\"https://www.baidu.com\" frameborder=\"0\" width=\"80%\" height=\"200\" name=\"iframe_a\"></iframe>\n<p><a href=\"http://news.baidu.com/\" target=\"iframe_a\">百度新闻</a></p>\n```\n<iframe src=\"https://www.baidu.com\" frameborder=\"0\" width=\"80%\" height=\"200\" name=\"iframe_a\"></iframe>\n<p><a href=\"http://news.baidu.com/\" target=\"iframe_a\">百度新闻</a></p>\n\n### 8. HTML 头部元素\n```\n标签\t描述  \n<head>\t定义关于文档的信息。  \n<title>\t定义文档标题。  \n<base>\t定义页面上所有链接的默认地址或默认目标。  \n<link>\t定义文档与外部资源之间的关系。\n\t<link> 标签最常用于连接样式表：\n<meta>\t定义关于 HTML 文档的元数据。 \n\t<meta> 标签提供关于 HTML 文档的元数据。元数据不会显示在页面上，但是对于机器是可读的。\n\t典型的情况是，meta 元素被用于规定页面的描述、关键词、文档的作者、最后修改时间以及其他元数据。\n\t<meta> 标签始终位于 head 元素中。\n\t元数据可用于浏览器（如何显示内容或重新加载页面），搜索引擎（关键词），或其他 web 服务。\n\t下面的 meta 元素定义页面的描述：\n\t<meta name=\"description\" content=\"Free Web tutorials on HTML, CSS, XML\" />\n\t下面的 meta 元素定义页面的关键词：\n\t<meta name=\"keywords\" content=\"HTML, CSS, XML\" />\n\tname 和 content 属性的作用是描述页面的内容。\n<script>\t定义客户端脚本。  \n<style>\t定义文档的样式信息。\n\t<style> 标签用于为 HTML 文档定义样式信息。\n\t您可以在 style 元素内规定 HTML 元素在浏览器中呈现的样式\n```\n\n### 9. HTML 字符实体\n```\n注释：实体名称对大小写敏感！\n\n显示结果\t描述\t\t实体名称\t\t实体编号\n\t\t空格\t\t&nbsp;\t\t\t&#160;\n<\t\t小于号\t\t&lt;\t\t\t&#60;\n>\t\t大于号\t\t&gt;\t\t\t&#62;\n&\t\t和号\t\t&amp;\t\t\t&#38;\n\"\t\t引号\t\t&quot;\t\t\t&#34;\n'\t\t撇号 \t\t&apos;IE不支持\t&#39;\n￠\t\t分（cent）\t&cent;\t\t\t&#162;\n£\t\t镑（pound）\t&pound;\t\t\t&#163;\n¥\t\t元（yen）\t&yen;\t\t\t&#165;\n€\t\t欧元（euro）\t&euro;\t\t\t&#8364;\n§\t\t小节\t\t&sect;\t\t\t&#167;\n©\t\t版权(copyright)\t&copy;\t\t\t&#169;\n®\t\t注册商标\t&reg;\t\t\t&#174;\n™\t\t商标\t\t&trade;\t\t\t&#8482;\n×\t\t乘号\t\t&times;\t\t\t&#215;\n÷\t\t除号\t\t&divide;\t\t&#247;\n```\n\n### 10. HTML 颜色名\n提示：仅有 16 种颜色名被 W3C 的 HTML 4.0 标准支持  \n它们是：aqua、black、blue、fuchsia、gray、green、lime、maroon、navy、olive、purple、red、silver、teal、white、yellow。  \n如果使用其它颜色的话，就应该使用十六进制的颜色值。   \n\n### 11. HTML <!DOCTYPE>\n```\n<!DOCTYPE> 声明帮助浏览器正确地显示网页\nWeb 世界中存在许多不同的文档。只有了解文档的类型，浏览器才能正确地显示文档。\nHTML 也有多个不同的版本，只有完全明白页面中使用的确切 HTML 版本，浏览器才能完全正确地显示出 HTML 页面。这就是 <!DOCTYPE> 的用处。\n<!DOCTYPE> 不是 HTML 标签。它为浏览器提供一项信息（声明），即 HTML 是用什么版本编写的。\n常用的声明\nHTML5\n<!DOCTYPE html>\n\nHTML 4.01\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\"\n\"http://www.w3.org/TR/html4/loose.dtd\">\n\nXHTML 1.0\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n```\n\n### 12. form表单\nHTML 表单用于收集用户输入。```<form>``` 元素定义 HTML 表单\n\n下面是 ```<form>``` 属性的列表：\n属性\t描述\naccept-charset\t规定在被提交表单中使用的字符集（默认：页面字符集）。\naction\t规定向何处提交表单的地址（URL）（提交页面）。\nautocomplete\t规定浏览器应该自动完成表单(默认:开启)\nenctype\t规定被提交数据的编码（默认：url-encoded）。\nid\t表单唯一id\tid=\"form1\"\nmethod\t规定在提交表单时所用的 HTTP 方法（默认：GET）。\nname\t规定识别表单的名称（对于 DOM 使用：document.forms.name）。\nnovalidate\t规定在提交表单时不对表单数据进行验证。\ntarget\t规定 action 属性中地址的目标（默认：_self）。\n\n列出了一些常用的输入限制\nautocomplete\t当自动完成开启，浏览器会基于用户之前的输入值自动填写值\tautocomplete=\"off\"\nautofocus\t规定当页面加载时 ```<input>``` 元素应该自动获得焦点\tautofocus\ndisabled\t规定输入字段应该被禁用, 不可用和不可点击, 被禁用的元素不会被提交\nmax\t规定输入字段的最大值。\nmaxlength\t规定输入字段的最大字符数。\nmin\t规定输入字段的最小值。\npattern\t规定通过其检查输入值的正则表达式。 只能包含三个字母的输入字段:pattern=\"[A-Za-z]{3}\"\nplaceholder 属性规定用以描述输入字段预期值的提示（样本值或有关格式的简短描述）\nreadonly\t规定输入字段为只读(无法修改).\nrequired\t如果设置，则规定在提交表单之前必须填写输入字段。\nsize\t规定输入字段的宽度（以字符计）。\nstep\t规定输入字段的合法数字间隔。如果 step=\"3\"，则合法数字应该是 -3、0、3、6、等等。\nvalue\t规定输入字段的默认值。\n\n下列属性适用于 type=\"submit\" 以及 type=\"image\"。\nformaction 属性覆盖 ```<form>``` 元素的 action 属性.\tformaction=\"demo_admin.asp\"\nformenctype 属性规定当把表单数据（form-data）提交至服务器时如何对其进行编码(仅针对 method=\"post\" 的表单).\tformenctype=\"multipart/form-data\"\nformmethod 属性定义用以向 action URL 发送表单数据(form-data)的HTTP方法.\tformmethod=\"post\"\nformtarget 属性规定的名称或关键词指示提交表单后在何处显示接收到的响应。\tformtarget=\"_blank\"会提交到新窗口/选项卡\n\n下列属性适用于 type=\"submit\"\n如果设置，则规定在提交表单时不对 ```<input>``` 元素进行验证。\nformnovalidate 属性覆盖 ```<form>``` 元素的 novalidate 属性。\tformnovalidate \n\n下列属性适用于 type=\"image\"\nheight 和 width 属性规定 ```<input type=\"image\">```元素的高度和宽度。\n![](12.png)\n``` HTML\n// action 属性定义在提交表单时执行的动作,指定了某个服务器脚本来处理被提交表单, 通常表单会被提交到 web 服务器上的网页\n// method 属性规定在提交表单时所用的 HTTP 方法（GET 或 POST）\n// 如果表单提交是被动的(比如搜索引擎查询),并且没有敏感信息,当您使用 GET 时，表单数据在页面地址栏中是可见的:action_page.php?firstname=Mickey&lastname=Mouse\n// GET 最适合少量数据的提交。浏览器会设定容量限制。\n// POST 的安全性更加，因为在页面地址栏中被提交的数据是不可见的. 如果表单正在更新数据，或者包含敏感信息(例如密码)\n<form action=\"action_page.php\" method=\"GET\" id=\"form1\">\n First name:<br>\n\n<fieldset>\n\n// 定义用于文本输入的单行输入字段\n<input type=\"text\" name=\"firstname\"  value=\"jone\" disabled>\n<br>\n\n// password 字段中的字符会被做掩码处理（显示为星号或实心圆）\n<input type=\"password\" name=\"psw\" autocomplete=\"off\" autofocus>\n<br>\n\n// <datalist> 元素为 <input> 元素规定预定义选项列表。\n<input list=\"browsers\" name=\"browser\" placeholder=\"Firefox\">\n<datalist id=\"browsers\">\n  <option value=\"Internet Explorer\">\n  <option value=\"Firefox\">\n  <option value=\"Chrome\">\n  <option value=\"Opera\">\n  <option value=\"Safari\">\n</datalist>\n\n// 单选按钮允许用户在有限数量的选项中选择其中之一\n<input type=\"radio\" name=\"sex\" value=\"male\" checked>Male\n<br>\n<input type=\"radio\" name=\"sex\" value=\"female\">Female\n<br>\n\n// 复选框允许用户在有限数量的选项中选择零个或多个选项\n<input type=\"checkbox\" name=\"vehicle\" value=\"Bike\">I have a bike\n<br>\n<input type=\"checkbox\" name=\"vehicle\" value=\"Car\">I have a car\n<br>\n\n// 下拉列表\n<select name=\"cars\">\n<option value=\"volvo\">Volvo</option>\n<option value=\"saab\" selected>Saab</option>\t\t// 通过添加 selected 属性来定义预定义选项。\n<option value=\"fiat\">Fiat</option>\n<option value=\"audi\">Audi</option>\n</select>\n\n// 定义多行输入字段(文本域)\n<textarea name=\"message\" rows=\"10\" cols=\"30\" readonly>\nThe cat was playing in the garden.\n</textarea>\n\n// 定义可点击的按钮\n<button type=\"button\" onclick=\"alert('Hello World!')\">Click Me!</button>\n\n</fieldset>\n\nQuantity (between 1 and 5):<br>\n<input type=\"number\" name=\"quantity\" min=\"1\" max=\"5\">\n<br>\n\nQuantity (between 1 and 5):<br>\n<input type=\"number\" name=\"quantity\" min=\"1\" max=\"5\">\n<br>\n\n// 日期\nBirthday:\n  <input type=\"date\" name=\"bday1\"><br>\nEnter a date before 1980-01-01:\n  <input type=\"date\" name=\"bday2\" max=\"1979-12-31\"><br>\n  Enter a date after 2000-01-01:\n  <input type=\"date\" name=\"bday3\" min=\"2000-01-02\"><br>\n\nSelect your favorite color:\n  <input type=\"color\" name=\"favcolor\"><br>\n\n// 用于应该包含一定范围内的值的输入字段, 根据浏览器支持，输入字段能够显示为滑块控件\n<input type=\"range\" name=\"points\" min=\"0\" max=\"10\"><br>\n\nBirthday (month and year):\n  <input type=\"month\" name=\"bdaymonth\"><br>\nSelect a week:\n  <input type=\"week\" name=\"week_year\"><br>\nSelect a time:\n  <input type=\"time\" name=\"usr_time\"><br>\nBirthday (date and time):\n  <input type=\"datetime\" name=\"bdaytime\"><br>\nBirthday (date and time):\n  <input type=\"datetime-local\" name=\"bdaytime\"><br>\nE-mail:\n  <input type=\"email\" name=\"email\"><br>\nSearch Google:\n  <input type=\"search\" name=\"googlesearch\"><br>\nTelephone:\n  <input type=\"tel\" name=\"usrtel\"><br>\nAdd your homepage 某些智能手机识别 url 类型，并向键盘添加 \".com\" 以匹配 url 输入。:\n  <input type=\"url\" name=\"homepage\"><br>\n\n// multiple 属性是布尔属性。如果设置，则规定允许用户在 <input> 元素中输入一个以上的值。multiple 属性适用于以下输入类型：email 和 file。\nSelect images: <input type=\"file\" name=\"img\" multiple><br>\n\n\n\n\n// 如果要正确地被提交，每个输入字段必须设置一个 name 属性。\n// 定义用于向表单处理程序（form-handler）提交表单的按钮\n// 表单处理程序在表单的 action 属性中指定\n<input type=\"submit\" value=\"Submit\"> \n\n// formaction 属性覆盖 <form> 元素的 action 属性\n<input type=\"submit\" formaction=\"demo_admin.asp\" value=\"Submit as admin\">\n   \n</form> \n\n下面的 \"Last name\" 字段位于 form 元素之外，但仍然是表单的一部分。<br>\nLast name: <input type=\"text\" name=\"lname\" form=\"form1\">\n\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"technologies/web/HTML","published":1,"date":"2020-08-12T16:05:49.112Z","updated":"2020-03-16T11:12:19.439Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckdt3hmom009uhohx5uwoh2fx","content":"<h3 id=\"1-HTML-链接-amp-锚语法\"><a href=\"#1-HTML-链接-amp-锚语法\" class=\"headerlink\" title=\"1.HTML 链接&amp;锚语法\"></a>1.HTML 链接&amp;锚语法</h3><p>链接的 HTML 代码很简单。它类似这样：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">href</span>=<span class=\"string\">\"https://www.baidu.com\"</span>&gt;</span>Link text<span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>命名锚的语法：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">name</span>=<span class=\"string\">\"label\"</span>&gt;</span>锚（显示在页面上的文本）<span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></span><br><span class=\"line\">您可以使用 id 属性来替代 name 属性，命名锚同样有效。</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">name</span>=<span class=\"string\">\"tips\"</span>&gt;</span>基本的注意事项 - 有用的提示<span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">href</span>=<span class=\"string\">\"#tips\"</span>&gt;</span>有用的提示<span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></span><br><span class=\"line\">您也可以在其他页面中创建指向该锚的链接：</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">href</span>=<span class=\"string\">\"http://www.w3school.com.cn/html/html_links.asp#tips\"</span>&gt;</span>有用的提示<span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></span><br><span class=\"line\">将 # 符号和锚名称添加到 URL 的末端，就可以直接链接到 tips 这个命名锚了。</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2-img\"><a href=\"#2-img\" class=\"headerlink\" title=\"2.img\"></a>2.img</h3><p>替换文本属性（Alt）<br>alt 属性用来为图像定义一串预备的可替换的文本。替换文本属性的值是用户定义的。<br>在浏览器无法载入图像时，替换文本属性告诉读者她们失去的信息。此时，浏览器将显示这个替代性的文本而不是图像。<br>为页面上的图像都加上替换文本属性是个好习惯，这样有助于更好的显示信息，并且对于那些使用纯文本浏览器的人来说是非常有用的。  </p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 图像的 align 属性设置为 \"right\"。图像将浮动到文本的右侧。</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">img</span> <span class=\"attr\">src</span>=<span class=\"string\">\"boat.gif\"</span> <span class=\"attr\">alt</span>=<span class=\"string\">\"Big Boat\"</span> <span class=\"attr\">width</span>=<span class=\"string\">\"50\"</span> <span class=\"attr\">height</span>=<span class=\"string\">\"50\"</span> <span class=\"attr\">align</span> =<span class=\"string\">\"right\"</span>&gt;</span> </span><br><span class=\"line\">您也可以把图像作为链接来使用：</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">href</span>=<span class=\"string\">\"/example/html/lastpage.html\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">img</span> <span class=\"attr\">border</span>=<span class=\"string\">\"0\"</span> <span class=\"attr\">src</span>=<span class=\"string\">\"/i/eg_buttonnext.gif\"</span> /&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"3-table\"><a href=\"#3-table\" class=\"headerlink\" title=\"3.table\"></a>3.table</h3><h4 id=\"3-1\"><a href=\"#3-1\" class=\"headerlink\" title=\"3.1\"></a>3.1</h4><p><img src=\"1.png\" alt=\"\"></p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// background 向表格添加背景图片</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">border</span>=<span class=\"string\">\"1\"</span> <span class=\"attr\">background</span>=<span class=\"string\">\"/i/eg_bg_07.gif\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span>\t\t\t\t\t\t\t\t\t\t\t// <span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span> 表行</span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span> <span class=\"attr\">bgcolor</span>=<span class=\"string\">\"red\"</span>&gt;</span>姓名<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span>\t\t\t\t\t// <span class=\"tag\">&lt;<span class=\"name\">th</span>&gt;</span> 表头, 表头设置特定背景色</span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>Bill Gates<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span>\t\t\t\t\t\t\t// <span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span> 表列</span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span> <span class=\"attr\">rowspan</span>=<span class=\"string\">\"2\"</span>&gt;</span>电话<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>这个单元包含一个列表：</span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">ul</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">href</span>=<span class=\"string\">\"https://www.baidu.com\"</span>&gt;</span>苹果<span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>香蕉<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>菠萝<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;/<span class=\"name\">ul</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>\t\t\t\t</span><br><span class=\"line\">\t\t// Cell padding 来创建单元格内容与其边框之间的空白。</span><br><span class=\"line\">\t\t// Cell spacing 增加单元格之间的距离</span><br><span class=\"line\">\t\t// bgcolor 向表格添加背景色</span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">border</span>=<span class=\"string\">\"1\"</span> <span class=\"attr\">cellpadding</span>=<span class=\"string\">\"10\"</span> <span class=\"attr\">cellspacing</span>=<span class=\"string\">\"3\"</span> <span class=\"attr\">bgcolor</span>=<span class=\"string\">\"blue\"</span>&gt;</span>\t\t</span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>A<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>B<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>C<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>D<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"3-2\"><a href=\"#3-2\" class=\"headerlink\" title=\"3.2\"></a>3.2</h4><p><img src=\"3.png\" alt=\"\"></p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span>Table with frame=\"box\":<span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">frame</span>=<span class=\"string\">\"box\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span>&gt;</span>Month<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span>&gt;</span>Savings<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>January<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>$100<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span>Table with frame=\"above\":<span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">frame</span>=<span class=\"string\">\"above\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span>&gt;</span>Month<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span>&gt;</span>Savings<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>January<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>$100<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span>Table with frame=\"below\":<span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">frame</span>=<span class=\"string\">\"below\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span>&gt;</span>Month<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span>&gt;</span>Savings<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>January<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>$100<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span>Table with frame=\"hsides\":<span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">frame</span>=<span class=\"string\">\"hsides\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span>&gt;</span>Month<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span>&gt;</span>Savings<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>January<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>$100<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span>Table with frame=\"vsides\":<span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">frame</span>=<span class=\"string\">\"vsides\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span>&gt;</span>Month<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span>&gt;</span>Savings<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>January<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>$100<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"3-3\"><a href=\"#3-3\" class=\"headerlink\" title=\"3.3\"></a>3.3</h4><p>单元格的边框没有被显示出来。为了避免这种情况，在空单元格中添加一个空格占位符，就可以将边框显示出来。<br><img src=\"table_td_empty.gif\" alt=\"\"></p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">border</span>=<span class=\"string\">\"1\"</span>&gt;</span>\t\t\t// 带边框</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">caption</span>&gt;</span>我的标题<span class=\"tag\">&lt;/<span class=\"name\">caption</span>&gt;</span>\t// table 标题</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>row 1, cell 1<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>row 1, cell 2<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span><span class=\"symbol\">&amp;nbsp;</span><span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span>\t\t\t\t// 空格由和号开始 (\"&amp;\")，然后是字符\"nbsp\"，并以分号结尾(\";\")</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>row 2, cell 2<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"3-4\"><a href=\"#3-4\" class=\"headerlink\" title=\"3.4\"></a>3.4</h4><p>横跨两列的单元格，横跨两行的单元格<br><img src=\"2.png\" alt=\"\"></p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">th</span> <span class=\"attr\">colspan</span>=<span class=\"string\">\"2\"</span>&gt;</span>电话<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">th</span> <span class=\"attr\">rowspan</span>=<span class=\"string\">\"2\"</span>&gt;</span>电话<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"4-无序ul-有序ol-自定义列表项dl\"><a href=\"#4-无序ul-有序ol-自定义列表项dl\" class=\"headerlink\" title=\"4.无序ul,有序ol,自定义列表项dl\"></a>4.无序ul,有序ol,自定义列表项dl</h3><p><img src=\"4.png\" alt=\"\"></p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h2</span>&gt;</span>一个定义列表：<span class=\"tag\">&lt;/<span class=\"name\">h2</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">ul</span> <span class=\"attr\">type</span>=<span class=\"string\">\"square\"</span>&gt;</span>\t\t// type=\"circle\" type=\"disc\"</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>咖啡<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>茶<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>牛奶<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">ul</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">ol</span> <span class=\"attr\">start</span>=<span class=\"string\">\"50\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>咖啡<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>牛奶<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>茶<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">ol</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">ol</span> <span class=\"attr\">type</span>=<span class=\"string\">\"A\"</span>&gt;</span>\t// type=\"a\", type=\"I\", type=\"i\"</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>咖啡<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>牛奶<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>茶<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">ul</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>红茶<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>绿茶</span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">ul</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>中国茶<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>非洲茶<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">ul</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">ul</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">ol</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dl</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">dt</span>&gt;</span>计算机<span class=\"tag\">&lt;/<span class=\"name\">dt</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">dd</span>&gt;</span>用来计算的仪器 ... ...<span class=\"tag\">&lt;/<span class=\"name\">dd</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">dt</span>&gt;</span>显示器<span class=\"tag\">&lt;/<span class=\"name\">dt</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">dd</span>&gt;</span>以视觉方式显示信息的装置 ... ...<span class=\"tag\">&lt;/<span class=\"name\">dd</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dl</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"5-div-span\"><a href=\"#5-div-span\" class=\"headerlink\" title=\"5. div, span\"></a>5. div, span</h3><figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&lt;!DOCTYPE <span class=\"meta-keyword\">html</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">link</span> <span class=\"attr\">rel</span>=<span class=\"string\">\"stylesheet\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"text/css\"</span> <span class=\"attr\">href</span>=<span class=\"string\">\"mystyle.css\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">style</span> <span class=\"attr\">type</span>=<span class=\"string\">\"text/css\"</span>&gt;</span></span><br><span class=\"line\">body &#123;</span><br><span class=\"line\">\tbackground-color: pink;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"><span class=\"css\"><span class=\"selector-id\">#header</span> &#123;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">background-color</span><span class=\"selector-pseudo\">:black</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">color</span><span class=\"selector-pseudo\">:white</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">text-align</span><span class=\"selector-pseudo\">:center</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">padding</span><span class=\"selector-pseudo\">:5px</span>;</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"css\"><span class=\"selector-class\">.nav</span> &#123;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">line-height</span><span class=\"selector-pseudo\">:30px</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">background-color</span>:<span class=\"selector-id\">#eeeeee</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">height</span><span class=\"selector-pseudo\">:300px</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">width</span><span class=\"selector-pseudo\">:100px</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">float</span><span class=\"selector-pseudo\">:left</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">padding</span><span class=\"selector-pseudo\">:5px</span>;\t      </span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"css\"><span class=\"selector-id\">#section</span> &#123;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">width</span><span class=\"selector-pseudo\">:350px</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">float</span><span class=\"selector-pseudo\">:left</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">padding</span><span class=\"selector-pseudo\">:10px</span>;\t \t </span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"css\"><span class=\"selector-id\">#footer</span> &#123;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">background-color</span><span class=\"selector-pseudo\">:black</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">color</span><span class=\"selector-pseudo\">:white</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">clear</span><span class=\"selector-pseudo\">:both</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">text-align</span><span class=\"selector-pseudo\">:center</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">padding</span><span class=\"selector-pseudo\">:5px</span>;\t \t </span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">style</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">id</span>=<span class=\"string\">\"header\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h1</span>&gt;</span>City Gallery<span class=\"tag\">&lt;/<span class=\"name\">h1</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">class</span>=<span class=\"string\">\"nav\"</span>&gt;</span></span><br><span class=\"line\">London<span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">Paris<span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">Tokyo<span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">id</span>=<span class=\"string\">\"section\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h2</span>&gt;</span>London<span class=\"tag\">&lt;/<span class=\"name\">h2</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">London is the <span class=\"tag\">&lt;<span class=\"name\">span</span> <span class=\"attr\">style</span>=<span class=\"string\">\"color:red\"</span>&gt;</span>capital city<span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span> of England. It is the most populous city in the United Kingdom,with a metropolitan area of over 13 million inhabitants.</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">id</span>=<span class=\"string\">\"footer\"</span>&gt;</span></span><br><span class=\"line\">Copyright ? W3Schools.com</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">html</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"6-框架-frameset-frame\"><a href=\"#6-框架-frameset-frame\" class=\"headerlink\" title=\"6. 框架 frameset, frame\"></a>6. 框架 frameset, frame</h3><p><img src=\"6.png\" alt=\"\"><br>不能将 “body” 标签与 “frameset” 标签同时使用！<br>假如一个框架有可见边框，用户可以拖动边框来改变它的大小。为了避免这种情况发生，可以在 <frame> 标签中加入：noresize=”noresize”。</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">frameset</span> <span class=\"attr\">rows</span>=<span class=\"string\">\"25%,50%,25%\"</span>&gt;</span>\t\t\t\t\t// 水平框架</span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">frame</span> <span class=\"attr\">src</span>=<span class=\"string\">\"/example/html/frame_a.html\"</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">frameset</span> <span class=\"attr\">cols</span>=<span class=\"string\">\"25%,50%,25%\"</span>&gt;</span>\t\t\t\t// 垂直框架</span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">frame</span> <span class=\"attr\">src</span>=<span class=\"string\">\"https://www.sina.com.cn/\"</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">frame</span> <span class=\"attr\">src</span>=<span class=\"string\">\"https://www.baidu.com\"</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">frame</span> <span class=\"attr\">src</span>=<span class=\"string\">\"/example/html/frame_c.html\"</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;/<span class=\"name\">frameset</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">frame</span> <span class=\"attr\">src</span>=<span class=\"string\">\"/example/html/frame_c.html\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">frameset</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">html</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"6_1.png\" alt=\"\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#x2F;&#x2F; &#x2F;&#x2F; view-source:https:&#x2F;&#x2F;www.w3school.com.cn</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;frameset cols&#x3D;&quot;120,*&quot;&gt;</span><br><span class=\"line\">  &lt;frame src&#x3D;&quot;&#x2F;example&#x2F;html&#x2F;html_contents.html&quot;&gt;</span><br><span class=\"line\">  &lt;frame src&#x3D;&quot;&#x2F;example&#x2F;html&#x2F;frame_a.html&quot; name&#x3D;&quot;showframe&quot;&gt;</span><br><span class=\"line\">&lt;&#x2F;frameset&gt;</span><br><span class=\"line\">&lt;&#x2F;html&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;&#x2F; view-source:https:&#x2F;&#x2F;www.w3school.com.cn&#x2F;example&#x2F;html&#x2F;html_contents.html</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;body&gt;</span><br><span class=\"line\">&lt;a href &#x3D;&quot;&#x2F;example&#x2F;html&#x2F;frame_a.html&quot; target &#x3D;&quot;showframe&quot;&gt;Frame a&lt;&#x2F;a&gt;&lt;br &#x2F;&gt;</span><br><span class=\"line\">&lt;a href &#x3D;&quot;&#x2F;example&#x2F;html&#x2F;frame_b.html&quot; target &#x3D;&quot;showframe&quot;&gt;Frame b&lt;&#x2F;a&gt;&lt;br &#x2F;&gt;</span><br><span class=\"line\">&lt;a href &#x3D;&quot;&#x2F;example&#x2F;html&#x2F;frame_c.html&quot; target &#x3D;&quot;showframe&quot;&gt;Frame c&lt;&#x2F;a&gt;</span><br><span class=\"line\">&lt;&#x2F;body&gt;</span><br><span class=\"line\">&lt;&#x2F;html&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;&#x2F; view-source:https:&#x2F;&#x2F;www.w3school.com.cn&#x2F;example&#x2F;html&#x2F;frame_a.html   , frame_b.html,  frame_c.html</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;body bgcolor&#x3D;&quot;#8F8FBD&quot;&gt;</span><br><span class=\"line\">&lt;h3&gt;Frame A&lt;&#x2F;h3&gt;</span><br><span class=\"line\">&lt;&#x2F;body&gt;</span><br><span class=\"line\">&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"7-内联框架-iframe\"><a href=\"#7-内联框架-iframe\" class=\"headerlink\" title=\"7. 内联框架 iframe\"></a>7. 内联框架 iframe</h3><p><img src=\"7.png\" alt=\"\"><br>height 和 width 属性用于规定 iframe 的高度和宽度，属性值的默认单位是像素，但也可以用百分比来设定（比如 “80%”）<br>frameborder 属性规定是否显示 iframe 周围的边框，设置属性值为 “0” 就可以移除边框<br>注释：由于链接的目标匹配 iframe 的名称，所以点击”百度新闻”链接, 会在 iframe 中打开百度新闻网页。</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">iframe</span> <span class=\"attr\">src</span>=<span class=\"string\">\"https://www.baidu.com\"</span> <span class=\"attr\">frameborder</span>=<span class=\"string\">\"0\"</span> <span class=\"attr\">width</span>=<span class=\"string\">\"80%\"</span> <span class=\"attr\">height</span>=<span class=\"string\">\"200\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"iframe_a\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">iframe</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">href</span>=<span class=\"string\">\"http://news.baidu.com/\"</span> <span class=\"attr\">target</span>=<span class=\"string\">\"iframe_a\"</span>&gt;</span>百度新闻<span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<iframe src=\"https://www.baidu.com\" frameborder=\"0\" width=\"80%\" height=\"200\" name=\"iframe_a\"></iframe>\n<p><a href=\"http://news.baidu.com/\" target=\"iframe_a\">百度新闻</a></p>\n\n<h3 id=\"8-HTML-头部元素\"><a href=\"#8-HTML-头部元素\" class=\"headerlink\" title=\"8. HTML 头部元素\"></a>8. HTML 头部元素</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">标签\t描述  </span><br><span class=\"line\">&lt;head&gt;\t定义关于文档的信息。  </span><br><span class=\"line\">&lt;title&gt;\t定义文档标题。  </span><br><span class=\"line\">&lt;base&gt;\t定义页面上所有链接的默认地址或默认目标。  </span><br><span class=\"line\">&lt;link&gt;\t定义文档与外部资源之间的关系。</span><br><span class=\"line\">\t&lt;link&gt; 标签最常用于连接样式表：</span><br><span class=\"line\">&lt;meta&gt;\t定义关于 HTML 文档的元数据。 </span><br><span class=\"line\">\t&lt;meta&gt; 标签提供关于 HTML 文档的元数据。元数据不会显示在页面上，但是对于机器是可读的。</span><br><span class=\"line\">\t典型的情况是，meta 元素被用于规定页面的描述、关键词、文档的作者、最后修改时间以及其他元数据。</span><br><span class=\"line\">\t&lt;meta&gt; 标签始终位于 head 元素中。</span><br><span class=\"line\">\t元数据可用于浏览器（如何显示内容或重新加载页面），搜索引擎（关键词），或其他 web 服务。</span><br><span class=\"line\">\t下面的 meta 元素定义页面的描述：</span><br><span class=\"line\">\t&lt;meta name&#x3D;&quot;description&quot; content&#x3D;&quot;Free Web tutorials on HTML, CSS, XML&quot; &#x2F;&gt;</span><br><span class=\"line\">\t下面的 meta 元素定义页面的关键词：</span><br><span class=\"line\">\t&lt;meta name&#x3D;&quot;keywords&quot; content&#x3D;&quot;HTML, CSS, XML&quot; &#x2F;&gt;</span><br><span class=\"line\">\tname 和 content 属性的作用是描述页面的内容。</span><br><span class=\"line\">&lt;script&gt;\t定义客户端脚本。  </span><br><span class=\"line\">&lt;style&gt;\t定义文档的样式信息。</span><br><span class=\"line\">\t&lt;style&gt; 标签用于为 HTML 文档定义样式信息。</span><br><span class=\"line\">\t您可以在 style 元素内规定 HTML 元素在浏览器中呈现的样式</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"9-HTML-字符实体\"><a href=\"#9-HTML-字符实体\" class=\"headerlink\" title=\"9. HTML 字符实体\"></a>9. HTML 字符实体</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">注释：实体名称对大小写敏感！</span><br><span class=\"line\"></span><br><span class=\"line\">显示结果\t描述\t\t实体名称\t\t实体编号</span><br><span class=\"line\">\t\t空格\t\t&amp;nbsp;\t\t\t&amp;#160;</span><br><span class=\"line\">&lt;\t\t小于号\t\t&lt;\t\t\t&amp;#60;</span><br><span class=\"line\">&gt;\t\t大于号\t\t&gt;\t\t\t&amp;#62;</span><br><span class=\"line\">&amp;\t\t和号\t\t&amp;\t\t\t&amp;#38;</span><br><span class=\"line\">&quot;\t\t引号\t\t&quot;\t\t\t&amp;#34;</span><br><span class=\"line\">&#39;\t\t撇号 \t\t&amp;apos;IE不支持\t&#39;</span><br><span class=\"line\">￠\t\t分（cent）\t&amp;cent;\t\t\t&amp;#162;</span><br><span class=\"line\">£\t\t镑（pound）\t&amp;pound;\t\t\t&amp;#163;</span><br><span class=\"line\">¥\t\t元（yen）\t&amp;yen;\t\t\t&amp;#165;</span><br><span class=\"line\">€\t\t欧元（euro）\t&amp;euro;\t\t\t&amp;#8364;</span><br><span class=\"line\">§\t\t小节\t\t&amp;sect;\t\t\t&amp;#167;</span><br><span class=\"line\">©\t\t版权(copyright)\t&amp;copy;\t\t\t&amp;#169;</span><br><span class=\"line\">®\t\t注册商标\t&amp;reg;\t\t\t&amp;#174;</span><br><span class=\"line\">™\t\t商标\t\t&amp;trade;\t\t\t&amp;#8482;</span><br><span class=\"line\">×\t\t乘号\t\t&amp;times;\t\t\t&amp;#215;</span><br><span class=\"line\">÷\t\t除号\t\t&amp;divide;\t\t&amp;#247;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"10-HTML-颜色名\"><a href=\"#10-HTML-颜色名\" class=\"headerlink\" title=\"10. HTML 颜色名\"></a>10. HTML 颜色名</h3><p>提示：仅有 16 种颜色名被 W3C 的 HTML 4.0 标准支持<br>它们是：aqua、black、blue、fuchsia、gray、green、lime、maroon、navy、olive、purple、red、silver、teal、white、yellow。<br>如果使用其它颜色的话，就应该使用十六进制的颜色值。   </p>\n<h3 id=\"11-HTML-lt-DOCTYPE-gt\"><a href=\"#11-HTML-lt-DOCTYPE-gt\" class=\"headerlink\" title=\"11. HTML &lt;!DOCTYPE&gt;\"></a>11. HTML &lt;!DOCTYPE&gt;</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;!DOCTYPE&gt; 声明帮助浏览器正确地显示网页</span><br><span class=\"line\">Web 世界中存在许多不同的文档。只有了解文档的类型，浏览器才能正确地显示文档。</span><br><span class=\"line\">HTML 也有多个不同的版本，只有完全明白页面中使用的确切 HTML 版本，浏览器才能完全正确地显示出 HTML 页面。这就是 &lt;!DOCTYPE&gt; 的用处。</span><br><span class=\"line\">&lt;!DOCTYPE&gt; 不是 HTML 标签。它为浏览器提供一项信息（声明），即 HTML 是用什么版本编写的。</span><br><span class=\"line\">常用的声明</span><br><span class=\"line\">HTML5</span><br><span class=\"line\">&lt;!DOCTYPE html&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">HTML 4.01</span><br><span class=\"line\">&lt;!DOCTYPE HTML PUBLIC &quot;-&#x2F;&#x2F;W3C&#x2F;&#x2F;DTD HTML 4.01 Transitional&#x2F;&#x2F;EN&quot;</span><br><span class=\"line\">&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;TR&#x2F;html4&#x2F;loose.dtd&quot;&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">XHTML 1.0</span><br><span class=\"line\">&lt;!DOCTYPE html PUBLIC &quot;-&#x2F;&#x2F;W3C&#x2F;&#x2F;DTD XHTML 1.0 Transitional&#x2F;&#x2F;EN&quot;</span><br><span class=\"line\">&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;TR&#x2F;xhtml1&#x2F;DTD&#x2F;xhtml1-transitional.dtd&quot;&gt;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"12-form表单\"><a href=\"#12-form表单\" class=\"headerlink\" title=\"12. form表单\"></a>12. form表单</h3><p>HTML 表单用于收集用户输入。<code>&lt;form&gt;</code> 元素定义 HTML 表单</p>\n<p>下面是 <code>&lt;form&gt;</code> 属性的列表：<br>属性    描述<br>accept-charset    规定在被提交表单中使用的字符集（默认：页面字符集）。<br>action    规定向何处提交表单的地址（URL）（提交页面）。<br>autocomplete    规定浏览器应该自动完成表单(默认:开启)<br>enctype    规定被提交数据的编码（默认：url-encoded）。<br>id    表单唯一id    id=”form1”<br>method    规定在提交表单时所用的 HTTP 方法（默认：GET）。<br>name    规定识别表单的名称（对于 DOM 使用：document.forms.name）。<br>novalidate    规定在提交表单时不对表单数据进行验证。<br>target    规定 action 属性中地址的目标（默认：_self）。</p>\n<p>列出了一些常用的输入限制<br>autocomplete    当自动完成开启，浏览器会基于用户之前的输入值自动填写值    autocomplete=”off”<br>autofocus    规定当页面加载时 <code>&lt;input&gt;</code> 元素应该自动获得焦点    autofocus<br>disabled    规定输入字段应该被禁用, 不可用和不可点击, 被禁用的元素不会被提交<br>max    规定输入字段的最大值。<br>maxlength    规定输入字段的最大字符数。<br>min    规定输入字段的最小值。<br>pattern    规定通过其检查输入值的正则表达式。 只能包含三个字母的输入字段:pattern=”[A-Za-z]{3}”<br>placeholder 属性规定用以描述输入字段预期值的提示（样本值或有关格式的简短描述）<br>readonly    规定输入字段为只读(无法修改).<br>required    如果设置，则规定在提交表单之前必须填写输入字段。<br>size    规定输入字段的宽度（以字符计）。<br>step    规定输入字段的合法数字间隔。如果 step=”3”，则合法数字应该是 -3、0、3、6、等等。<br>value    规定输入字段的默认值。</p>\n<p>下列属性适用于 type=”submit” 以及 type=”image”。<br>formaction 属性覆盖 <code>&lt;form&gt;</code> 元素的 action 属性.    formaction=”demo_admin.asp”<br>formenctype 属性规定当把表单数据（form-data）提交至服务器时如何对其进行编码(仅针对 method=”post” 的表单).    formenctype=”multipart/form-data”<br>formmethod 属性定义用以向 action URL 发送表单数据(form-data)的HTTP方法.    formmethod=”post”<br>formtarget 属性规定的名称或关键词指示提交表单后在何处显示接收到的响应。    formtarget=”_blank”会提交到新窗口/选项卡</p>\n<p>下列属性适用于 type=”submit”<br>如果设置，则规定在提交表单时不对 <code>&lt;input&gt;</code> 元素进行验证。<br>formnovalidate 属性覆盖 <code>&lt;form&gt;</code> 元素的 novalidate 属性。    formnovalidate </p>\n<p>下列属性适用于 type=”image”<br>height 和 width 属性规定 <code>&lt;input type=&quot;image&quot;&gt;</code>元素的高度和宽度。<br><img src=\"12.png\" alt=\"\"></p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// action 属性定义在提交表单时执行的动作,指定了某个服务器脚本来处理被提交表单, 通常表单会被提交到 web 服务器上的网页</span><br><span class=\"line\">// method 属性规定在提交表单时所用的 HTTP 方法（GET 或 POST）</span><br><span class=\"line\">// 如果表单提交是被动的(比如搜索引擎查询),并且没有敏感信息,当您使用 GET 时，表单数据在页面地址栏中是可见的:action_page.php?firstname=Mickey&amp;lastname=Mouse</span><br><span class=\"line\">// GET 最适合少量数据的提交。浏览器会设定容量限制。</span><br><span class=\"line\">// POST 的安全性更加，因为在页面地址栏中被提交的数据是不可见的. 如果表单正在更新数据，或者包含敏感信息(例如密码)</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">form</span> <span class=\"attr\">action</span>=<span class=\"string\">\"action_page.php\"</span> <span class=\"attr\">method</span>=<span class=\"string\">\"GET\"</span> <span class=\"attr\">id</span>=<span class=\"string\">\"form1\"</span>&gt;</span></span><br><span class=\"line\"> First name:<span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">fieldset</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">// 定义用于文本输入的单行输入字段</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"text\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"firstname\"</span>  <span class=\"attr\">value</span>=<span class=\"string\">\"jone\"</span> <span class=\"attr\">disabled</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">// password 字段中的字符会被做掩码处理（显示为星号或实心圆）</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"password\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"psw\"</span> <span class=\"attr\">autocomplete</span>=<span class=\"string\">\"off\"</span> <span class=\"attr\">autofocus</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">// <span class=\"tag\">&lt;<span class=\"name\">datalist</span>&gt;</span> 元素为 <span class=\"tag\">&lt;<span class=\"name\">input</span>&gt;</span> 元素规定预定义选项列表。</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">list</span>=<span class=\"string\">\"browsers\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"browser\"</span> <span class=\"attr\">placeholder</span>=<span class=\"string\">\"Firefox\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">datalist</span> <span class=\"attr\">id</span>=<span class=\"string\">\"browsers\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">option</span> <span class=\"attr\">value</span>=<span class=\"string\">\"Internet Explorer\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">option</span> <span class=\"attr\">value</span>=<span class=\"string\">\"Firefox\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">option</span> <span class=\"attr\">value</span>=<span class=\"string\">\"Chrome\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">option</span> <span class=\"attr\">value</span>=<span class=\"string\">\"Opera\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">option</span> <span class=\"attr\">value</span>=<span class=\"string\">\"Safari\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">datalist</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">// 单选按钮允许用户在有限数量的选项中选择其中之一</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"radio\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"sex\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"male\"</span> <span class=\"attr\">checked</span>&gt;</span>Male</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"radio\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"sex\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"female\"</span>&gt;</span>Female</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">// 复选框允许用户在有限数量的选项中选择零个或多个选项</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"checkbox\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"vehicle\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"Bike\"</span>&gt;</span>I have a bike</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"checkbox\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"vehicle\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"Car\"</span>&gt;</span>I have a car</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">// 下拉列表</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">select</span> <span class=\"attr\">name</span>=<span class=\"string\">\"cars\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">option</span> <span class=\"attr\">value</span>=<span class=\"string\">\"volvo\"</span>&gt;</span>Volvo<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">option</span> <span class=\"attr\">value</span>=<span class=\"string\">\"saab\"</span> <span class=\"attr\">selected</span>&gt;</span>Saab<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span>\t\t// 通过添加 selected 属性来定义预定义选项。</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">option</span> <span class=\"attr\">value</span>=<span class=\"string\">\"fiat\"</span>&gt;</span>Fiat<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">option</span> <span class=\"attr\">value</span>=<span class=\"string\">\"audi\"</span>&gt;</span>Audi<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">select</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">// 定义多行输入字段(文本域)</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">textarea</span> <span class=\"attr\">name</span>=<span class=\"string\">\"message\"</span> <span class=\"attr\">rows</span>=<span class=\"string\">\"10\"</span> <span class=\"attr\">cols</span>=<span class=\"string\">\"30\"</span> <span class=\"attr\">readonly</span>&gt;</span></span><br><span class=\"line\">The cat was playing in the garden.</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">textarea</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">// 定义可点击的按钮</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">button</span> <span class=\"attr\">type</span>=<span class=\"string\">\"button\"</span> <span class=\"attr\">onclick</span>=<span class=\"string\">\"alert('Hello World!')\"</span>&gt;</span>Click Me!<span class=\"tag\">&lt;/<span class=\"name\">button</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">fieldset</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">Quantity (between 1 and 5):<span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"number\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"quantity\"</span> <span class=\"attr\">min</span>=<span class=\"string\">\"1\"</span> <span class=\"attr\">max</span>=<span class=\"string\">\"5\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">Quantity (between 1 and 5):<span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"number\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"quantity\"</span> <span class=\"attr\">min</span>=<span class=\"string\">\"1\"</span> <span class=\"attr\">max</span>=<span class=\"string\">\"5\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">// 日期</span><br><span class=\"line\">Birthday:</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"date\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"bday1\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">Enter a date before 1980-01-01:</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"date\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"bday2\"</span> <span class=\"attr\">max</span>=<span class=\"string\">\"1979-12-31\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">  Enter a date after 2000-01-01:</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"date\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"bday3\"</span> <span class=\"attr\">min</span>=<span class=\"string\">\"2000-01-02\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">Select your favorite color:</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"color\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"favcolor\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">// 用于应该包含一定范围内的值的输入字段, 根据浏览器支持，输入字段能够显示为滑块控件</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"range\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"points\"</span> <span class=\"attr\">min</span>=<span class=\"string\">\"0\"</span> <span class=\"attr\">max</span>=<span class=\"string\">\"10\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">Birthday (month and year):</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"month\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"bdaymonth\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">Select a week:</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"week\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"week_year\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">Select a time:</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"time\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"usr_time\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">Birthday (date and time):</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"datetime\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"bdaytime\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">Birthday (date and time):</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"datetime-local\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"bdaytime\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">E-mail:</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"email\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"email\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">Search Google:</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"search\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"googlesearch\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">Telephone:</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"tel\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"usrtel\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">Add your homepage 某些智能手机识别 url 类型，并向键盘添加 \".com\" 以匹配 url 输入。:</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"url\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"homepage\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">// multiple 属性是布尔属性。如果设置，则规定允许用户在 <span class=\"tag\">&lt;<span class=\"name\">input</span>&gt;</span> 元素中输入一个以上的值。multiple 属性适用于以下输入类型：email 和 file。</span><br><span class=\"line\">Select images: <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"file\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"img\"</span> <span class=\"attr\">multiple</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">// 如果要正确地被提交，每个输入字段必须设置一个 name 属性。</span><br><span class=\"line\">// 定义用于向表单处理程序（form-handler）提交表单的按钮</span><br><span class=\"line\">// 表单处理程序在表单的 action 属性中指定</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"submit\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"Submit\"</span>&gt;</span> </span><br><span class=\"line\"></span><br><span class=\"line\">// formaction 属性覆盖 <span class=\"tag\">&lt;<span class=\"name\">form</span>&gt;</span> 元素的 action 属性</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"submit\"</span> <span class=\"attr\">formaction</span>=<span class=\"string\">\"demo_admin.asp\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"Submit as admin\"</span>&gt;</span></span><br><span class=\"line\">   </span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">form</span>&gt;</span> </span><br><span class=\"line\"></span><br><span class=\"line\">下面的 \"Last name\" 字段位于 form 元素之外，但仍然是表单的一部分。<span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">Last name: <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"text\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"lname\"</span> <span class=\"attr\">form</span>=<span class=\"string\">\"form1\"</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"1-HTML-链接-amp-锚语法\"><a href=\"#1-HTML-链接-amp-锚语法\" class=\"headerlink\" title=\"1.HTML 链接&amp;锚语法\"></a>1.HTML 链接&amp;锚语法</h3><p>链接的 HTML 代码很简单。它类似这样：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">href</span>=<span class=\"string\">\"https://www.baidu.com\"</span>&gt;</span>Link text<span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>命名锚的语法：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">name</span>=<span class=\"string\">\"label\"</span>&gt;</span>锚（显示在页面上的文本）<span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></span><br><span class=\"line\">您可以使用 id 属性来替代 name 属性，命名锚同样有效。</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">name</span>=<span class=\"string\">\"tips\"</span>&gt;</span>基本的注意事项 - 有用的提示<span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">href</span>=<span class=\"string\">\"#tips\"</span>&gt;</span>有用的提示<span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></span><br><span class=\"line\">您也可以在其他页面中创建指向该锚的链接：</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">href</span>=<span class=\"string\">\"http://www.w3school.com.cn/html/html_links.asp#tips\"</span>&gt;</span>有用的提示<span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></span><br><span class=\"line\">将 # 符号和锚名称添加到 URL 的末端，就可以直接链接到 tips 这个命名锚了。</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2-img\"><a href=\"#2-img\" class=\"headerlink\" title=\"2.img\"></a>2.img</h3><p>替换文本属性（Alt）<br>alt 属性用来为图像定义一串预备的可替换的文本。替换文本属性的值是用户定义的。<br>在浏览器无法载入图像时，替换文本属性告诉读者她们失去的信息。此时，浏览器将显示这个替代性的文本而不是图像。<br>为页面上的图像都加上替换文本属性是个好习惯，这样有助于更好的显示信息，并且对于那些使用纯文本浏览器的人来说是非常有用的。  </p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 图像的 align 属性设置为 \"right\"。图像将浮动到文本的右侧。</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">img</span> <span class=\"attr\">src</span>=<span class=\"string\">\"boat.gif\"</span> <span class=\"attr\">alt</span>=<span class=\"string\">\"Big Boat\"</span> <span class=\"attr\">width</span>=<span class=\"string\">\"50\"</span> <span class=\"attr\">height</span>=<span class=\"string\">\"50\"</span> <span class=\"attr\">align</span> =<span class=\"string\">\"right\"</span>&gt;</span> </span><br><span class=\"line\">您也可以把图像作为链接来使用：</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">href</span>=<span class=\"string\">\"/example/html/lastpage.html\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">img</span> <span class=\"attr\">border</span>=<span class=\"string\">\"0\"</span> <span class=\"attr\">src</span>=<span class=\"string\">\"/i/eg_buttonnext.gif\"</span> /&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"3-table\"><a href=\"#3-table\" class=\"headerlink\" title=\"3.table\"></a>3.table</h3><h4 id=\"3-1\"><a href=\"#3-1\" class=\"headerlink\" title=\"3.1\"></a>3.1</h4><p><img src=\"1.png\" alt=\"\"></p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// background 向表格添加背景图片</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">border</span>=<span class=\"string\">\"1\"</span> <span class=\"attr\">background</span>=<span class=\"string\">\"/i/eg_bg_07.gif\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span>\t\t\t\t\t\t\t\t\t\t\t// <span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span> 表行</span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span> <span class=\"attr\">bgcolor</span>=<span class=\"string\">\"red\"</span>&gt;</span>姓名<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span>\t\t\t\t\t// <span class=\"tag\">&lt;<span class=\"name\">th</span>&gt;</span> 表头, 表头设置特定背景色</span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>Bill Gates<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span>\t\t\t\t\t\t\t// <span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span> 表列</span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span> <span class=\"attr\">rowspan</span>=<span class=\"string\">\"2\"</span>&gt;</span>电话<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>这个单元包含一个列表：</span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">ul</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">href</span>=<span class=\"string\">\"https://www.baidu.com\"</span>&gt;</span>苹果<span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>香蕉<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>菠萝<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;/<span class=\"name\">ul</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>\t\t\t\t</span><br><span class=\"line\">\t\t// Cell padding 来创建单元格内容与其边框之间的空白。</span><br><span class=\"line\">\t\t// Cell spacing 增加单元格之间的距离</span><br><span class=\"line\">\t\t// bgcolor 向表格添加背景色</span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">border</span>=<span class=\"string\">\"1\"</span> <span class=\"attr\">cellpadding</span>=<span class=\"string\">\"10\"</span> <span class=\"attr\">cellspacing</span>=<span class=\"string\">\"3\"</span> <span class=\"attr\">bgcolor</span>=<span class=\"string\">\"blue\"</span>&gt;</span>\t\t</span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>A<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>B<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>C<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>D<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"3-2\"><a href=\"#3-2\" class=\"headerlink\" title=\"3.2\"></a>3.2</h4><p><img src=\"3.png\" alt=\"\"></p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span>Table with frame=\"box\":<span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">frame</span>=<span class=\"string\">\"box\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span>&gt;</span>Month<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span>&gt;</span>Savings<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>January<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>$100<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span>Table with frame=\"above\":<span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">frame</span>=<span class=\"string\">\"above\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span>&gt;</span>Month<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span>&gt;</span>Savings<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>January<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>$100<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span>Table with frame=\"below\":<span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">frame</span>=<span class=\"string\">\"below\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span>&gt;</span>Month<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span>&gt;</span>Savings<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>January<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>$100<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span>Table with frame=\"hsides\":<span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">frame</span>=<span class=\"string\">\"hsides\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span>&gt;</span>Month<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span>&gt;</span>Savings<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>January<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>$100<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span>Table with frame=\"vsides\":<span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">frame</span>=<span class=\"string\">\"vsides\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span>&gt;</span>Month<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">th</span>&gt;</span>Savings<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>January<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>$100<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"3-3\"><a href=\"#3-3\" class=\"headerlink\" title=\"3.3\"></a>3.3</h4><p>单元格的边框没有被显示出来。为了避免这种情况，在空单元格中添加一个空格占位符，就可以将边框显示出来。<br><img src=\"table_td_empty.gif\" alt=\"\"></p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">border</span>=<span class=\"string\">\"1\"</span>&gt;</span>\t\t\t// 带边框</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">caption</span>&gt;</span>我的标题<span class=\"tag\">&lt;/<span class=\"name\">caption</span>&gt;</span>\t// table 标题</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>row 1, cell 1<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>row 1, cell 2<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span><span class=\"symbol\">&amp;nbsp;</span><span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span>\t\t\t\t// 空格由和号开始 (\"&amp;\")，然后是字符\"nbsp\"，并以分号结尾(\";\")</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">td</span>&gt;</span>row 2, cell 2<span class=\"tag\">&lt;/<span class=\"name\">td</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">tr</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"3-4\"><a href=\"#3-4\" class=\"headerlink\" title=\"3.4\"></a>3.4</h4><p>横跨两列的单元格，横跨两行的单元格<br><img src=\"2.png\" alt=\"\"></p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">th</span> <span class=\"attr\">colspan</span>=<span class=\"string\">\"2\"</span>&gt;</span>电话<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">th</span> <span class=\"attr\">rowspan</span>=<span class=\"string\">\"2\"</span>&gt;</span>电话<span class=\"tag\">&lt;/<span class=\"name\">th</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"4-无序ul-有序ol-自定义列表项dl\"><a href=\"#4-无序ul-有序ol-自定义列表项dl\" class=\"headerlink\" title=\"4.无序ul,有序ol,自定义列表项dl\"></a>4.无序ul,有序ol,自定义列表项dl</h3><p><img src=\"4.png\" alt=\"\"></p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h2</span>&gt;</span>一个定义列表：<span class=\"tag\">&lt;/<span class=\"name\">h2</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">ul</span> <span class=\"attr\">type</span>=<span class=\"string\">\"square\"</span>&gt;</span>\t\t// type=\"circle\" type=\"disc\"</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>咖啡<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>茶<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>牛奶<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">ul</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">ol</span> <span class=\"attr\">start</span>=<span class=\"string\">\"50\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>咖啡<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>牛奶<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>茶<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">ol</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">ol</span> <span class=\"attr\">type</span>=<span class=\"string\">\"A\"</span>&gt;</span>\t// type=\"a\", type=\"I\", type=\"i\"</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>咖啡<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>牛奶<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>茶<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">ul</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>红茶<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>绿茶</span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">ul</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>中国茶<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">li</span>&gt;</span>非洲茶<span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">ul</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">li</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">ul</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">ol</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dl</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">dt</span>&gt;</span>计算机<span class=\"tag\">&lt;/<span class=\"name\">dt</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">dd</span>&gt;</span>用来计算的仪器 ... ...<span class=\"tag\">&lt;/<span class=\"name\">dd</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">dt</span>&gt;</span>显示器<span class=\"tag\">&lt;/<span class=\"name\">dt</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">dd</span>&gt;</span>以视觉方式显示信息的装置 ... ...<span class=\"tag\">&lt;/<span class=\"name\">dd</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dl</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"5-div-span\"><a href=\"#5-div-span\" class=\"headerlink\" title=\"5. div, span\"></a>5. div, span</h3><figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&lt;!DOCTYPE <span class=\"meta-keyword\">html</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">link</span> <span class=\"attr\">rel</span>=<span class=\"string\">\"stylesheet\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"text/css\"</span> <span class=\"attr\">href</span>=<span class=\"string\">\"mystyle.css\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">style</span> <span class=\"attr\">type</span>=<span class=\"string\">\"text/css\"</span>&gt;</span></span><br><span class=\"line\">body &#123;</span><br><span class=\"line\">\tbackground-color: pink;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"><span class=\"css\"><span class=\"selector-id\">#header</span> &#123;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">background-color</span><span class=\"selector-pseudo\">:black</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">color</span><span class=\"selector-pseudo\">:white</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">text-align</span><span class=\"selector-pseudo\">:center</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">padding</span><span class=\"selector-pseudo\">:5px</span>;</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"css\"><span class=\"selector-class\">.nav</span> &#123;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">line-height</span><span class=\"selector-pseudo\">:30px</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">background-color</span>:<span class=\"selector-id\">#eeeeee</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">height</span><span class=\"selector-pseudo\">:300px</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">width</span><span class=\"selector-pseudo\">:100px</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">float</span><span class=\"selector-pseudo\">:left</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">padding</span><span class=\"selector-pseudo\">:5px</span>;\t      </span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"css\"><span class=\"selector-id\">#section</span> &#123;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">width</span><span class=\"selector-pseudo\">:350px</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">float</span><span class=\"selector-pseudo\">:left</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">padding</span><span class=\"selector-pseudo\">:10px</span>;\t \t </span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"css\"><span class=\"selector-id\">#footer</span> &#123;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">background-color</span><span class=\"selector-pseudo\">:black</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">color</span><span class=\"selector-pseudo\">:white</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">clear</span><span class=\"selector-pseudo\">:both</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">text-align</span><span class=\"selector-pseudo\">:center</span>;</span></span><br><span class=\"line\"><span class=\"css\">\t<span class=\"selector-tag\">padding</span><span class=\"selector-pseudo\">:5px</span>;\t \t </span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">style</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">id</span>=<span class=\"string\">\"header\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h1</span>&gt;</span>City Gallery<span class=\"tag\">&lt;/<span class=\"name\">h1</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">class</span>=<span class=\"string\">\"nav\"</span>&gt;</span></span><br><span class=\"line\">London<span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">Paris<span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">Tokyo<span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">id</span>=<span class=\"string\">\"section\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h2</span>&gt;</span>London<span class=\"tag\">&lt;/<span class=\"name\">h2</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">London is the <span class=\"tag\">&lt;<span class=\"name\">span</span> <span class=\"attr\">style</span>=<span class=\"string\">\"color:red\"</span>&gt;</span>capital city<span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span> of England. It is the most populous city in the United Kingdom,with a metropolitan area of over 13 million inhabitants.</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">id</span>=<span class=\"string\">\"footer\"</span>&gt;</span></span><br><span class=\"line\">Copyright ? W3Schools.com</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">html</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"6-框架-frameset-frame\"><a href=\"#6-框架-frameset-frame\" class=\"headerlink\" title=\"6. 框架 frameset, frame\"></a>6. 框架 frameset, frame</h3><p><img src=\"6.png\" alt=\"\"><br>不能将 “body” 标签与 “frameset” 标签同时使用！<br>假如一个框架有可见边框，用户可以拖动边框来改变它的大小。为了避免这种情况发生，可以在 <frame> 标签中加入：noresize=”noresize”。</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">frameset</span> <span class=\"attr\">rows</span>=<span class=\"string\">\"25%,50%,25%\"</span>&gt;</span>\t\t\t\t\t// 水平框架</span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">frame</span> <span class=\"attr\">src</span>=<span class=\"string\">\"/example/html/frame_a.html\"</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">frameset</span> <span class=\"attr\">cols</span>=<span class=\"string\">\"25%,50%,25%\"</span>&gt;</span>\t\t\t\t// 垂直框架</span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">frame</span> <span class=\"attr\">src</span>=<span class=\"string\">\"https://www.sina.com.cn/\"</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">frame</span> <span class=\"attr\">src</span>=<span class=\"string\">\"https://www.baidu.com\"</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">frame</span> <span class=\"attr\">src</span>=<span class=\"string\">\"/example/html/frame_c.html\"</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;/<span class=\"name\">frameset</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">frame</span> <span class=\"attr\">src</span>=<span class=\"string\">\"/example/html/frame_c.html\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">frameset</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">html</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"6_1.png\" alt=\"\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#x2F;&#x2F; &#x2F;&#x2F; view-source:https:&#x2F;&#x2F;www.w3school.com.cn</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;frameset cols&#x3D;&quot;120,*&quot;&gt;</span><br><span class=\"line\">  &lt;frame src&#x3D;&quot;&#x2F;example&#x2F;html&#x2F;html_contents.html&quot;&gt;</span><br><span class=\"line\">  &lt;frame src&#x3D;&quot;&#x2F;example&#x2F;html&#x2F;frame_a.html&quot; name&#x3D;&quot;showframe&quot;&gt;</span><br><span class=\"line\">&lt;&#x2F;frameset&gt;</span><br><span class=\"line\">&lt;&#x2F;html&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;&#x2F; view-source:https:&#x2F;&#x2F;www.w3school.com.cn&#x2F;example&#x2F;html&#x2F;html_contents.html</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;body&gt;</span><br><span class=\"line\">&lt;a href &#x3D;&quot;&#x2F;example&#x2F;html&#x2F;frame_a.html&quot; target &#x3D;&quot;showframe&quot;&gt;Frame a&lt;&#x2F;a&gt;&lt;br &#x2F;&gt;</span><br><span class=\"line\">&lt;a href &#x3D;&quot;&#x2F;example&#x2F;html&#x2F;frame_b.html&quot; target &#x3D;&quot;showframe&quot;&gt;Frame b&lt;&#x2F;a&gt;&lt;br &#x2F;&gt;</span><br><span class=\"line\">&lt;a href &#x3D;&quot;&#x2F;example&#x2F;html&#x2F;frame_c.html&quot; target &#x3D;&quot;showframe&quot;&gt;Frame c&lt;&#x2F;a&gt;</span><br><span class=\"line\">&lt;&#x2F;body&gt;</span><br><span class=\"line\">&lt;&#x2F;html&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;&#x2F; view-source:https:&#x2F;&#x2F;www.w3school.com.cn&#x2F;example&#x2F;html&#x2F;frame_a.html   , frame_b.html,  frame_c.html</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;body bgcolor&#x3D;&quot;#8F8FBD&quot;&gt;</span><br><span class=\"line\">&lt;h3&gt;Frame A&lt;&#x2F;h3&gt;</span><br><span class=\"line\">&lt;&#x2F;body&gt;</span><br><span class=\"line\">&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"7-内联框架-iframe\"><a href=\"#7-内联框架-iframe\" class=\"headerlink\" title=\"7. 内联框架 iframe\"></a>7. 内联框架 iframe</h3><p><img src=\"7.png\" alt=\"\"><br>height 和 width 属性用于规定 iframe 的高度和宽度，属性值的默认单位是像素，但也可以用百分比来设定（比如 “80%”）<br>frameborder 属性规定是否显示 iframe 周围的边框，设置属性值为 “0” 就可以移除边框<br>注释：由于链接的目标匹配 iframe 的名称，所以点击”百度新闻”链接, 会在 iframe 中打开百度新闻网页。</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">iframe</span> <span class=\"attr\">src</span>=<span class=\"string\">\"https://www.baidu.com\"</span> <span class=\"attr\">frameborder</span>=<span class=\"string\">\"0\"</span> <span class=\"attr\">width</span>=<span class=\"string\">\"80%\"</span> <span class=\"attr\">height</span>=<span class=\"string\">\"200\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"iframe_a\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">iframe</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">href</span>=<span class=\"string\">\"http://news.baidu.com/\"</span> <span class=\"attr\">target</span>=<span class=\"string\">\"iframe_a\"</span>&gt;</span>百度新闻<span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<iframe src=\"https://www.baidu.com\" frameborder=\"0\" width=\"80%\" height=\"200\" name=\"iframe_a\"></iframe>\n<p><a href=\"http://news.baidu.com/\" target=\"iframe_a\">百度新闻</a></p>\n\n<h3 id=\"8-HTML-头部元素\"><a href=\"#8-HTML-头部元素\" class=\"headerlink\" title=\"8. HTML 头部元素\"></a>8. HTML 头部元素</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">标签\t描述  </span><br><span class=\"line\">&lt;head&gt;\t定义关于文档的信息。  </span><br><span class=\"line\">&lt;title&gt;\t定义文档标题。  </span><br><span class=\"line\">&lt;base&gt;\t定义页面上所有链接的默认地址或默认目标。  </span><br><span class=\"line\">&lt;link&gt;\t定义文档与外部资源之间的关系。</span><br><span class=\"line\">\t&lt;link&gt; 标签最常用于连接样式表：</span><br><span class=\"line\">&lt;meta&gt;\t定义关于 HTML 文档的元数据。 </span><br><span class=\"line\">\t&lt;meta&gt; 标签提供关于 HTML 文档的元数据。元数据不会显示在页面上，但是对于机器是可读的。</span><br><span class=\"line\">\t典型的情况是，meta 元素被用于规定页面的描述、关键词、文档的作者、最后修改时间以及其他元数据。</span><br><span class=\"line\">\t&lt;meta&gt; 标签始终位于 head 元素中。</span><br><span class=\"line\">\t元数据可用于浏览器（如何显示内容或重新加载页面），搜索引擎（关键词），或其他 web 服务。</span><br><span class=\"line\">\t下面的 meta 元素定义页面的描述：</span><br><span class=\"line\">\t&lt;meta name&#x3D;&quot;description&quot; content&#x3D;&quot;Free Web tutorials on HTML, CSS, XML&quot; &#x2F;&gt;</span><br><span class=\"line\">\t下面的 meta 元素定义页面的关键词：</span><br><span class=\"line\">\t&lt;meta name&#x3D;&quot;keywords&quot; content&#x3D;&quot;HTML, CSS, XML&quot; &#x2F;&gt;</span><br><span class=\"line\">\tname 和 content 属性的作用是描述页面的内容。</span><br><span class=\"line\">&lt;script&gt;\t定义客户端脚本。  </span><br><span class=\"line\">&lt;style&gt;\t定义文档的样式信息。</span><br><span class=\"line\">\t&lt;style&gt; 标签用于为 HTML 文档定义样式信息。</span><br><span class=\"line\">\t您可以在 style 元素内规定 HTML 元素在浏览器中呈现的样式</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"9-HTML-字符实体\"><a href=\"#9-HTML-字符实体\" class=\"headerlink\" title=\"9. HTML 字符实体\"></a>9. HTML 字符实体</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">注释：实体名称对大小写敏感！</span><br><span class=\"line\"></span><br><span class=\"line\">显示结果\t描述\t\t实体名称\t\t实体编号</span><br><span class=\"line\">\t\t空格\t\t&amp;nbsp;\t\t\t&amp;#160;</span><br><span class=\"line\">&lt;\t\t小于号\t\t&lt;\t\t\t&amp;#60;</span><br><span class=\"line\">&gt;\t\t大于号\t\t&gt;\t\t\t&amp;#62;</span><br><span class=\"line\">&amp;\t\t和号\t\t&amp;\t\t\t&amp;#38;</span><br><span class=\"line\">&quot;\t\t引号\t\t&quot;\t\t\t&amp;#34;</span><br><span class=\"line\">&#39;\t\t撇号 \t\t&amp;apos;IE不支持\t&#39;</span><br><span class=\"line\">￠\t\t分（cent）\t&amp;cent;\t\t\t&amp;#162;</span><br><span class=\"line\">£\t\t镑（pound）\t&amp;pound;\t\t\t&amp;#163;</span><br><span class=\"line\">¥\t\t元（yen）\t&amp;yen;\t\t\t&amp;#165;</span><br><span class=\"line\">€\t\t欧元（euro）\t&amp;euro;\t\t\t&amp;#8364;</span><br><span class=\"line\">§\t\t小节\t\t&amp;sect;\t\t\t&amp;#167;</span><br><span class=\"line\">©\t\t版权(copyright)\t&amp;copy;\t\t\t&amp;#169;</span><br><span class=\"line\">®\t\t注册商标\t&amp;reg;\t\t\t&amp;#174;</span><br><span class=\"line\">™\t\t商标\t\t&amp;trade;\t\t\t&amp;#8482;</span><br><span class=\"line\">×\t\t乘号\t\t&amp;times;\t\t\t&amp;#215;</span><br><span class=\"line\">÷\t\t除号\t\t&amp;divide;\t\t&amp;#247;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"10-HTML-颜色名\"><a href=\"#10-HTML-颜色名\" class=\"headerlink\" title=\"10. HTML 颜色名\"></a>10. HTML 颜色名</h3><p>提示：仅有 16 种颜色名被 W3C 的 HTML 4.0 标准支持<br>它们是：aqua、black、blue、fuchsia、gray、green、lime、maroon、navy、olive、purple、red、silver、teal、white、yellow。<br>如果使用其它颜色的话，就应该使用十六进制的颜色值。   </p>\n<h3 id=\"11-HTML-lt-DOCTYPE-gt\"><a href=\"#11-HTML-lt-DOCTYPE-gt\" class=\"headerlink\" title=\"11. HTML &lt;!DOCTYPE&gt;\"></a>11. HTML &lt;!DOCTYPE&gt;</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;!DOCTYPE&gt; 声明帮助浏览器正确地显示网页</span><br><span class=\"line\">Web 世界中存在许多不同的文档。只有了解文档的类型，浏览器才能正确地显示文档。</span><br><span class=\"line\">HTML 也有多个不同的版本，只有完全明白页面中使用的确切 HTML 版本，浏览器才能完全正确地显示出 HTML 页面。这就是 &lt;!DOCTYPE&gt; 的用处。</span><br><span class=\"line\">&lt;!DOCTYPE&gt; 不是 HTML 标签。它为浏览器提供一项信息（声明），即 HTML 是用什么版本编写的。</span><br><span class=\"line\">常用的声明</span><br><span class=\"line\">HTML5</span><br><span class=\"line\">&lt;!DOCTYPE html&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">HTML 4.01</span><br><span class=\"line\">&lt;!DOCTYPE HTML PUBLIC &quot;-&#x2F;&#x2F;W3C&#x2F;&#x2F;DTD HTML 4.01 Transitional&#x2F;&#x2F;EN&quot;</span><br><span class=\"line\">&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;TR&#x2F;html4&#x2F;loose.dtd&quot;&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">XHTML 1.0</span><br><span class=\"line\">&lt;!DOCTYPE html PUBLIC &quot;-&#x2F;&#x2F;W3C&#x2F;&#x2F;DTD XHTML 1.0 Transitional&#x2F;&#x2F;EN&quot;</span><br><span class=\"line\">&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;TR&#x2F;xhtml1&#x2F;DTD&#x2F;xhtml1-transitional.dtd&quot;&gt;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"12-form表单\"><a href=\"#12-form表单\" class=\"headerlink\" title=\"12. form表单\"></a>12. form表单</h3><p>HTML 表单用于收集用户输入。<code>&lt;form&gt;</code> 元素定义 HTML 表单</p>\n<p>下面是 <code>&lt;form&gt;</code> 属性的列表：<br>属性    描述<br>accept-charset    规定在被提交表单中使用的字符集（默认：页面字符集）。<br>action    规定向何处提交表单的地址（URL）（提交页面）。<br>autocomplete    规定浏览器应该自动完成表单(默认:开启)<br>enctype    规定被提交数据的编码（默认：url-encoded）。<br>id    表单唯一id    id=”form1”<br>method    规定在提交表单时所用的 HTTP 方法（默认：GET）。<br>name    规定识别表单的名称（对于 DOM 使用：document.forms.name）。<br>novalidate    规定在提交表单时不对表单数据进行验证。<br>target    规定 action 属性中地址的目标（默认：_self）。</p>\n<p>列出了一些常用的输入限制<br>autocomplete    当自动完成开启，浏览器会基于用户之前的输入值自动填写值    autocomplete=”off”<br>autofocus    规定当页面加载时 <code>&lt;input&gt;</code> 元素应该自动获得焦点    autofocus<br>disabled    规定输入字段应该被禁用, 不可用和不可点击, 被禁用的元素不会被提交<br>max    规定输入字段的最大值。<br>maxlength    规定输入字段的最大字符数。<br>min    规定输入字段的最小值。<br>pattern    规定通过其检查输入值的正则表达式。 只能包含三个字母的输入字段:pattern=”[A-Za-z]{3}”<br>placeholder 属性规定用以描述输入字段预期值的提示（样本值或有关格式的简短描述）<br>readonly    规定输入字段为只读(无法修改).<br>required    如果设置，则规定在提交表单之前必须填写输入字段。<br>size    规定输入字段的宽度（以字符计）。<br>step    规定输入字段的合法数字间隔。如果 step=”3”，则合法数字应该是 -3、0、3、6、等等。<br>value    规定输入字段的默认值。</p>\n<p>下列属性适用于 type=”submit” 以及 type=”image”。<br>formaction 属性覆盖 <code>&lt;form&gt;</code> 元素的 action 属性.    formaction=”demo_admin.asp”<br>formenctype 属性规定当把表单数据（form-data）提交至服务器时如何对其进行编码(仅针对 method=”post” 的表单).    formenctype=”multipart/form-data”<br>formmethod 属性定义用以向 action URL 发送表单数据(form-data)的HTTP方法.    formmethod=”post”<br>formtarget 属性规定的名称或关键词指示提交表单后在何处显示接收到的响应。    formtarget=”_blank”会提交到新窗口/选项卡</p>\n<p>下列属性适用于 type=”submit”<br>如果设置，则规定在提交表单时不对 <code>&lt;input&gt;</code> 元素进行验证。<br>formnovalidate 属性覆盖 <code>&lt;form&gt;</code> 元素的 novalidate 属性。    formnovalidate </p>\n<p>下列属性适用于 type=”image”<br>height 和 width 属性规定 <code>&lt;input type=&quot;image&quot;&gt;</code>元素的高度和宽度。<br><img src=\"12.png\" alt=\"\"></p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// action 属性定义在提交表单时执行的动作,指定了某个服务器脚本来处理被提交表单, 通常表单会被提交到 web 服务器上的网页</span><br><span class=\"line\">// method 属性规定在提交表单时所用的 HTTP 方法（GET 或 POST）</span><br><span class=\"line\">// 如果表单提交是被动的(比如搜索引擎查询),并且没有敏感信息,当您使用 GET 时，表单数据在页面地址栏中是可见的:action_page.php?firstname=Mickey&amp;lastname=Mouse</span><br><span class=\"line\">// GET 最适合少量数据的提交。浏览器会设定容量限制。</span><br><span class=\"line\">// POST 的安全性更加，因为在页面地址栏中被提交的数据是不可见的. 如果表单正在更新数据，或者包含敏感信息(例如密码)</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">form</span> <span class=\"attr\">action</span>=<span class=\"string\">\"action_page.php\"</span> <span class=\"attr\">method</span>=<span class=\"string\">\"GET\"</span> <span class=\"attr\">id</span>=<span class=\"string\">\"form1\"</span>&gt;</span></span><br><span class=\"line\"> First name:<span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">fieldset</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">// 定义用于文本输入的单行输入字段</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"text\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"firstname\"</span>  <span class=\"attr\">value</span>=<span class=\"string\">\"jone\"</span> <span class=\"attr\">disabled</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">// password 字段中的字符会被做掩码处理（显示为星号或实心圆）</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"password\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"psw\"</span> <span class=\"attr\">autocomplete</span>=<span class=\"string\">\"off\"</span> <span class=\"attr\">autofocus</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">// <span class=\"tag\">&lt;<span class=\"name\">datalist</span>&gt;</span> 元素为 <span class=\"tag\">&lt;<span class=\"name\">input</span>&gt;</span> 元素规定预定义选项列表。</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">list</span>=<span class=\"string\">\"browsers\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"browser\"</span> <span class=\"attr\">placeholder</span>=<span class=\"string\">\"Firefox\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">datalist</span> <span class=\"attr\">id</span>=<span class=\"string\">\"browsers\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">option</span> <span class=\"attr\">value</span>=<span class=\"string\">\"Internet Explorer\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">option</span> <span class=\"attr\">value</span>=<span class=\"string\">\"Firefox\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">option</span> <span class=\"attr\">value</span>=<span class=\"string\">\"Chrome\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">option</span> <span class=\"attr\">value</span>=<span class=\"string\">\"Opera\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">option</span> <span class=\"attr\">value</span>=<span class=\"string\">\"Safari\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">datalist</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">// 单选按钮允许用户在有限数量的选项中选择其中之一</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"radio\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"sex\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"male\"</span> <span class=\"attr\">checked</span>&gt;</span>Male</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"radio\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"sex\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"female\"</span>&gt;</span>Female</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">// 复选框允许用户在有限数量的选项中选择零个或多个选项</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"checkbox\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"vehicle\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"Bike\"</span>&gt;</span>I have a bike</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"checkbox\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"vehicle\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"Car\"</span>&gt;</span>I have a car</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">// 下拉列表</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">select</span> <span class=\"attr\">name</span>=<span class=\"string\">\"cars\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">option</span> <span class=\"attr\">value</span>=<span class=\"string\">\"volvo\"</span>&gt;</span>Volvo<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">option</span> <span class=\"attr\">value</span>=<span class=\"string\">\"saab\"</span> <span class=\"attr\">selected</span>&gt;</span>Saab<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span>\t\t// 通过添加 selected 属性来定义预定义选项。</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">option</span> <span class=\"attr\">value</span>=<span class=\"string\">\"fiat\"</span>&gt;</span>Fiat<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">option</span> <span class=\"attr\">value</span>=<span class=\"string\">\"audi\"</span>&gt;</span>Audi<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">select</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">// 定义多行输入字段(文本域)</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">textarea</span> <span class=\"attr\">name</span>=<span class=\"string\">\"message\"</span> <span class=\"attr\">rows</span>=<span class=\"string\">\"10\"</span> <span class=\"attr\">cols</span>=<span class=\"string\">\"30\"</span> <span class=\"attr\">readonly</span>&gt;</span></span><br><span class=\"line\">The cat was playing in the garden.</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">textarea</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">// 定义可点击的按钮</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">button</span> <span class=\"attr\">type</span>=<span class=\"string\">\"button\"</span> <span class=\"attr\">onclick</span>=<span class=\"string\">\"alert('Hello World!')\"</span>&gt;</span>Click Me!<span class=\"tag\">&lt;/<span class=\"name\">button</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">fieldset</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">Quantity (between 1 and 5):<span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"number\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"quantity\"</span> <span class=\"attr\">min</span>=<span class=\"string\">\"1\"</span> <span class=\"attr\">max</span>=<span class=\"string\">\"5\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">Quantity (between 1 and 5):<span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"number\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"quantity\"</span> <span class=\"attr\">min</span>=<span class=\"string\">\"1\"</span> <span class=\"attr\">max</span>=<span class=\"string\">\"5\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">// 日期</span><br><span class=\"line\">Birthday:</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"date\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"bday1\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">Enter a date before 1980-01-01:</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"date\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"bday2\"</span> <span class=\"attr\">max</span>=<span class=\"string\">\"1979-12-31\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">  Enter a date after 2000-01-01:</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"date\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"bday3\"</span> <span class=\"attr\">min</span>=<span class=\"string\">\"2000-01-02\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">Select your favorite color:</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"color\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"favcolor\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">// 用于应该包含一定范围内的值的输入字段, 根据浏览器支持，输入字段能够显示为滑块控件</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"range\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"points\"</span> <span class=\"attr\">min</span>=<span class=\"string\">\"0\"</span> <span class=\"attr\">max</span>=<span class=\"string\">\"10\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">Birthday (month and year):</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"month\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"bdaymonth\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">Select a week:</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"week\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"week_year\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">Select a time:</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"time\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"usr_time\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">Birthday (date and time):</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"datetime\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"bdaytime\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">Birthday (date and time):</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"datetime-local\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"bdaytime\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">E-mail:</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"email\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"email\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">Search Google:</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"search\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"googlesearch\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">Telephone:</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"tel\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"usrtel\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">Add your homepage 某些智能手机识别 url 类型，并向键盘添加 \".com\" 以匹配 url 输入。:</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"url\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"homepage\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">// multiple 属性是布尔属性。如果设置，则规定允许用户在 <span class=\"tag\">&lt;<span class=\"name\">input</span>&gt;</span> 元素中输入一个以上的值。multiple 属性适用于以下输入类型：email 和 file。</span><br><span class=\"line\">Select images: <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"file\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"img\"</span> <span class=\"attr\">multiple</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">// 如果要正确地被提交，每个输入字段必须设置一个 name 属性。</span><br><span class=\"line\">// 定义用于向表单处理程序（form-handler）提交表单的按钮</span><br><span class=\"line\">// 表单处理程序在表单的 action 属性中指定</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"submit\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"Submit\"</span>&gt;</span> </span><br><span class=\"line\"></span><br><span class=\"line\">// formaction 属性覆盖 <span class=\"tag\">&lt;<span class=\"name\">form</span>&gt;</span> 元素的 action 属性</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"submit\"</span> <span class=\"attr\">formaction</span>=<span class=\"string\">\"demo_admin.asp\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"Submit as admin\"</span>&gt;</span></span><br><span class=\"line\">   </span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">form</span>&gt;</span> </span><br><span class=\"line\"></span><br><span class=\"line\">下面的 \"Last name\" 字段位于 form 元素之外，但仍然是表单的一部分。<span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">Last name: <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"text\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"lname\"</span> <span class=\"attr\">form</span>=<span class=\"string\">\"form1\"</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"},{"title":"Istio 03 configuration & dashboard","_content":"\n## Architecture\n\n> 新的 Mixer 模型使用 Envoy 中的扩展来提供更多功能。Istio 社区正在领导 Envoy 的 WebAssembly（Wasm）运行时的实现，Wasm 让我们可以使用超过 20 种的语言来开发模块化、沙盒化的扩展。可以在代理继续提供流量的同时动态加载、重载扩展\n> 通过 preview 配置文件安装 Istio 1.5 不会再安装 Mixer\n> 如果有需要，您可以保持安装并启用 Mixer。最终，Mixer 将成为 Istio 单独的发行组件，成为 istio-ecosystem 的一部分\n> 简化其余控制平面的 deployment。为此，我们将几个控制平面组件合并为一个组件：Istiod。该二进制文件包括 Pilot、Citadel、Galley 和 Sidecar 注入器的功能。这种方法从许多方面改善了 Istio 的安装和管理，降低了安装和配置的复杂性、维护工作量以及问题诊断时间，同时提高了响应速度。 关于 Istiod 的更多内容请查看 [Christian Posta 的这篇博客](https://blog.christianposta.com/microservices/istio-as-an-example-of-when-not-to-do-microservices/)。\n> Istiod 作为 1.5 中所有配置文件的默认配置\n从图片来看，我们正在从这里：\n![](istio_arch_19.JPG)\n迁移到这里：\n![](istio_arch_20.JPG)\n2020 年，我们将继续专注于普及，实现默认 零配置 的目标，该默认设置不需要您更改应用程序的任何配置即可使用 Istio 的大多数功能。\n\n## **Security Policy**\n![](security_policy.PNG)\n\n### **AuthorizationPolicy**\n授权认证, 精细化管理网格内的服务可以被哪些服务访问\n * From-来源: 指定从哪里来的服务可以访问此由Label Selector指定的服务\n * To-操作: 能访问到哪些路径,如使用get方法, Path路径等\n * When- 条件: 当满足某条件的时候可以访问服务\n\n\n\t$ cat mtls-auth.yaml\n\tapiVersion: security.istio.io/v1beta1\n\tkind: AuthorizationPolicy\n\tmetadata:\n\t  name: box-nginx\n\t  namespace: rancher\n\tspec:\n\t  action: ALLOW\n\t  selector:\n\t    matchLabels:\n\t      app: nginx-primary\n\t  rules:\n\t  - from:\n\t    - source:\t\t\t\t//包括principals, host主机, IP等等更细致话配置\n\t      principals: [\"cluster.local/ns/rancher/sa/box\"]\t// 指定从namespace:rancher, serviceAccount:box 的服务可以访问标签为app=nginx-primary的服务\n\n\n\n### **PeerAuthentication**\n对等授权认证, 三种模式:\n * PERMISSIVE-宽容 (default,服务间正常访问)\n * STRICT-严格(网格内服务启用mtls)\n * DISABLE-取消网格内的mtls\n\n\n\t$ cat peer.yaml\n\tapiVersion: security.istio.io/v1beta1\n\tkind: PeerAuthentication\n\tmetadata:\n\t  name: rancher-policy\n\t  namespace: rancher\n\tspec:\n\t  mtls:\n\t  mode: STRICT\t// 网格内服务必须经过mtls双向握手才能进行通信, 加强网格内服务安全性, 网格外服务是不会访问进来的\n\n### **RequestAuthentication JWT**\n\n## **Official website demo bookinfo**\n![](traffic_control.PNG)\n\n### **Gateway & VirtualService**\n\n\tapiVersion: networking.istio.io/v1alpha3\n\tkind: Gateway\t\t\t# 相当于外部服务要访问网格内服务的第二道大门, 第一道大门是istio默认的ingressgateway网关\n\tmetadata:\n\t  name: bookinfo-gateway\n\tspec:\n\t  selector:\n\t    istio: ingressgateway # use istio default controller\n\t  servers:\n\t  - port:\n\t      number: 80\t\t# 定义一个80端口供别人访问, 并把80端口暴露到网关上面\n\t      name: http\n\t      protocol: HTTP\n\t    hosts:\t\t\t# \"*\" 表示访问任何主机的80端口都映射都下面的VirtualService下的destination对应的productpage\n\t    - \"*\"\t\t\t# 也指定为\"httpbin.example.com\", 当访问此网址时去找对应的下面的VirtualService, 但需要做解析，否则浏览器无法访问得到.\n\t---\t\t\t\t# 解析方法: linux: 修改/etc/hosts, windows: 修改/Windows/System32/drivers/etc/hosts\n\t\t\t\t\t\t# 添加内容: `Host-Name httpbin.example.com`， 浏览器就可输入http://httpbin.example.com/productpage/200, 然后鼠标右击->Inspect->Network->Headers， 刷新网页即可看到报头\n\tapiVersion: networking.istio.io/v1alpha3\n\tkind: VirtualService\n\tmetadata:\n\t  name: bookinfo\n\tspec:\n\t  hosts:\n\t  - \"*\"\t\t\t\t\t# 也指定为\"httpbin.example.com\", 与上面的hosts保持一致\n\t  gateways:\n\t  - bookinfo-gateway\t# 绑定上面Gateway, 从外部如浏览器可以访问如: curl -s http://ingressgateway-Host-IP:NodePortNumber/productpage\n\t  http:\t\t\t\t\t# 访问协议是http的时候才会进一步匹配\n\t  - match:\n\t    - uri:\n\t        exact: /productpage\n\t    - uri:\n\t        prefix: /static\n\t    - uri:\n\t        exact: /login\n\t    - uri:\n\t        exact: /logout\n\t    - uri:\n\t        prefix: /api/v1/products\n\t    route:\n\t    - destination:\n\t        host: productpage\t# 匹配上面满足后路由到对应k8s部署的svc名字叫productpage的服务, 通过kubectl get svc -n book-info查看\n\t        port:\n\t          number: 9080\t\t# 路由到服务productpage的9080端口提供的服务\n\t  route:\t\t\t\t\t# 上命没有匹配到默认到productpage service\n\t  - destination:\n\t      host: productpage\n\t      port:\n\t        number: 9080\n\n**VirtualService**\n\n\tapiVersion: networking.istio.io/v1alpha3\n\tkind: VirtualService\n\tmetadata:\n\t  name: reviews\n\tspec:\t\t\t\t\t# 没有绑定gateway, 因此从外部还无法访问\n\t  hosts:\n\t    - reviews\n\t  http:\n\t  - route:\n\t    - destination:\n\t        host: reviews\n\t        subset: v1\t\t# 对应下名DestinationRule reviews中的name: v1\n\t      weight: 80\t\t# 路由权重\n\t    - destination:\n\t        host: reviews\n\t        subset: v1\t\t# 对应下名DestinationRule reviews中的name: v2\n\t      weight: 20\n\n### **DestinationRule**\n\n\tapiVersion: networking.istio.io/v1alpha3\n\tkind: DestinationRule\t\t# 路由指向由host指定的svc下面通过Label selector包含的特定POD\n\tmetadata:\n\t  name: reviews\n\tspec:\n\t  host: reviews\t\t\t# 对应k8s部署的svc名字叫productpage, kubectl get svc -n book-info\n\t  trafficPolicy:\n\t    loadBalancer:\t\t# 1.负载均衡 2.断路器 3.TLS 等等\n\t      simple: RANDOM\n\t    tls:\n\t      mode: ISTIO_MUTUAL\n\t  subsets:\n\t  - name: v1\n\t    labels:\n\t      version: v1\t\t# 对应pod的Labels标签里有version=v1, 可通过kubectl describe po/reviews-** -n book-info查看Labels.\n\t  - name: v2\n\t    labels:\n\t      version: v2\n\t  - name: v3\n\t    labels:\n\t      version: v3\n\n通过网关访问服务:\n\n\t$ curl -I -HHost:httpbin.example.com http://$INGRESS_HOST:$INGRESS_PORT/productpage/200\n\t上面命令将浏览器访问http://httpbin.example.com/producpage 对应的解析为 http://$INGRESS_HOST:$INGRESS_PORT/productpage/200\n\t这里-H选项是设置主机的HTTP报头为httpbin.example.com\n\n## **Dashboard & log**\n### Dashboard Overall\ncontrolz: 日志, 也可用kubectl logs查看不过不够直观\nenvoy\ngrafana\njaeger: 查看traces\nkiali: 服务网格的可视化展示\nprometheus\nzipkin: 查看traces\n\n查询istio提供了哪些dashboard\n\n\t$ istioctl dashboard\n查看或修改指定pod的log\n\n\t$ istioctl dashboard controlz istiod-5f47bf5895-lzm6w -n istio-system\n\t$ istioctl dashboard controlz istiod-5f47bf5895-lzm6w -n istio-system --address=192.168.22.184 // 添加了address监听地址\n\thttp://localhost:40230\n\t然后浏览器输入http://localhost:40230就可看到log信息\n查看envoy dashboard, 前提是跑业务的pod中部署了envoy proxy\n\n\t$ istioctl dashboard envoy prometheus-xxx -n istio-system\n\t$ istioctl dashboard envoy prometheus-xxx -n istio-system --address=192.168.22.184\n\n### log\n查看某个pod日志\n\n\t$ kubectl logs po/XXX -n Namespace\n修改整个istio的日志模式\n\n\t$ kubectl edit cm istio -n istio-system\n\t......\n\tdata:\n\t  mesh: |-\n\t    accessLogEncoding: TEXT\t\t// 日志默认是TEXT格式输出，可以改为json模式, 再序列话可以很直观查看进出istio envoy的流量的方向, 上下流等.\n\n### **kiali**\n\n\t$ istioctl dashboard kiali\n\t$ while true; do curl http://10.239.186.141/productpage; done; \n![](kiali_1.PNG)\n\n\n","source":"_posts/micro_service/istio_03_configuration_dashboard.md","raw":"---\ntitle: Istio 03 configuration & dashboard\ntags: istio\ncategories:\n- microService\n- istio\n---\n\n## Architecture\n\n> 新的 Mixer 模型使用 Envoy 中的扩展来提供更多功能。Istio 社区正在领导 Envoy 的 WebAssembly（Wasm）运行时的实现，Wasm 让我们可以使用超过 20 种的语言来开发模块化、沙盒化的扩展。可以在代理继续提供流量的同时动态加载、重载扩展\n> 通过 preview 配置文件安装 Istio 1.5 不会再安装 Mixer\n> 如果有需要，您可以保持安装并启用 Mixer。最终，Mixer 将成为 Istio 单独的发行组件，成为 istio-ecosystem 的一部分\n> 简化其余控制平面的 deployment。为此，我们将几个控制平面组件合并为一个组件：Istiod。该二进制文件包括 Pilot、Citadel、Galley 和 Sidecar 注入器的功能。这种方法从许多方面改善了 Istio 的安装和管理，降低了安装和配置的复杂性、维护工作量以及问题诊断时间，同时提高了响应速度。 关于 Istiod 的更多内容请查看 [Christian Posta 的这篇博客](https://blog.christianposta.com/microservices/istio-as-an-example-of-when-not-to-do-microservices/)。\n> Istiod 作为 1.5 中所有配置文件的默认配置\n从图片来看，我们正在从这里：\n![](istio_arch_19.JPG)\n迁移到这里：\n![](istio_arch_20.JPG)\n2020 年，我们将继续专注于普及，实现默认 零配置 的目标，该默认设置不需要您更改应用程序的任何配置即可使用 Istio 的大多数功能。\n\n## **Security Policy**\n![](security_policy.PNG)\n\n### **AuthorizationPolicy**\n授权认证, 精细化管理网格内的服务可以被哪些服务访问\n * From-来源: 指定从哪里来的服务可以访问此由Label Selector指定的服务\n * To-操作: 能访问到哪些路径,如使用get方法, Path路径等\n * When- 条件: 当满足某条件的时候可以访问服务\n\n\n\t$ cat mtls-auth.yaml\n\tapiVersion: security.istio.io/v1beta1\n\tkind: AuthorizationPolicy\n\tmetadata:\n\t  name: box-nginx\n\t  namespace: rancher\n\tspec:\n\t  action: ALLOW\n\t  selector:\n\t    matchLabels:\n\t      app: nginx-primary\n\t  rules:\n\t  - from:\n\t    - source:\t\t\t\t//包括principals, host主机, IP等等更细致话配置\n\t      principals: [\"cluster.local/ns/rancher/sa/box\"]\t// 指定从namespace:rancher, serviceAccount:box 的服务可以访问标签为app=nginx-primary的服务\n\n\n\n### **PeerAuthentication**\n对等授权认证, 三种模式:\n * PERMISSIVE-宽容 (default,服务间正常访问)\n * STRICT-严格(网格内服务启用mtls)\n * DISABLE-取消网格内的mtls\n\n\n\t$ cat peer.yaml\n\tapiVersion: security.istio.io/v1beta1\n\tkind: PeerAuthentication\n\tmetadata:\n\t  name: rancher-policy\n\t  namespace: rancher\n\tspec:\n\t  mtls:\n\t  mode: STRICT\t// 网格内服务必须经过mtls双向握手才能进行通信, 加强网格内服务安全性, 网格外服务是不会访问进来的\n\n### **RequestAuthentication JWT**\n\n## **Official website demo bookinfo**\n![](traffic_control.PNG)\n\n### **Gateway & VirtualService**\n\n\tapiVersion: networking.istio.io/v1alpha3\n\tkind: Gateway\t\t\t# 相当于外部服务要访问网格内服务的第二道大门, 第一道大门是istio默认的ingressgateway网关\n\tmetadata:\n\t  name: bookinfo-gateway\n\tspec:\n\t  selector:\n\t    istio: ingressgateway # use istio default controller\n\t  servers:\n\t  - port:\n\t      number: 80\t\t# 定义一个80端口供别人访问, 并把80端口暴露到网关上面\n\t      name: http\n\t      protocol: HTTP\n\t    hosts:\t\t\t# \"*\" 表示访问任何主机的80端口都映射都下面的VirtualService下的destination对应的productpage\n\t    - \"*\"\t\t\t# 也指定为\"httpbin.example.com\", 当访问此网址时去找对应的下面的VirtualService, 但需要做解析，否则浏览器无法访问得到.\n\t---\t\t\t\t# 解析方法: linux: 修改/etc/hosts, windows: 修改/Windows/System32/drivers/etc/hosts\n\t\t\t\t\t\t# 添加内容: `Host-Name httpbin.example.com`， 浏览器就可输入http://httpbin.example.com/productpage/200, 然后鼠标右击->Inspect->Network->Headers， 刷新网页即可看到报头\n\tapiVersion: networking.istio.io/v1alpha3\n\tkind: VirtualService\n\tmetadata:\n\t  name: bookinfo\n\tspec:\n\t  hosts:\n\t  - \"*\"\t\t\t\t\t# 也指定为\"httpbin.example.com\", 与上面的hosts保持一致\n\t  gateways:\n\t  - bookinfo-gateway\t# 绑定上面Gateway, 从外部如浏览器可以访问如: curl -s http://ingressgateway-Host-IP:NodePortNumber/productpage\n\t  http:\t\t\t\t\t# 访问协议是http的时候才会进一步匹配\n\t  - match:\n\t    - uri:\n\t        exact: /productpage\n\t    - uri:\n\t        prefix: /static\n\t    - uri:\n\t        exact: /login\n\t    - uri:\n\t        exact: /logout\n\t    - uri:\n\t        prefix: /api/v1/products\n\t    route:\n\t    - destination:\n\t        host: productpage\t# 匹配上面满足后路由到对应k8s部署的svc名字叫productpage的服务, 通过kubectl get svc -n book-info查看\n\t        port:\n\t          number: 9080\t\t# 路由到服务productpage的9080端口提供的服务\n\t  route:\t\t\t\t\t# 上命没有匹配到默认到productpage service\n\t  - destination:\n\t      host: productpage\n\t      port:\n\t        number: 9080\n\n**VirtualService**\n\n\tapiVersion: networking.istio.io/v1alpha3\n\tkind: VirtualService\n\tmetadata:\n\t  name: reviews\n\tspec:\t\t\t\t\t# 没有绑定gateway, 因此从外部还无法访问\n\t  hosts:\n\t    - reviews\n\t  http:\n\t  - route:\n\t    - destination:\n\t        host: reviews\n\t        subset: v1\t\t# 对应下名DestinationRule reviews中的name: v1\n\t      weight: 80\t\t# 路由权重\n\t    - destination:\n\t        host: reviews\n\t        subset: v1\t\t# 对应下名DestinationRule reviews中的name: v2\n\t      weight: 20\n\n### **DestinationRule**\n\n\tapiVersion: networking.istio.io/v1alpha3\n\tkind: DestinationRule\t\t# 路由指向由host指定的svc下面通过Label selector包含的特定POD\n\tmetadata:\n\t  name: reviews\n\tspec:\n\t  host: reviews\t\t\t# 对应k8s部署的svc名字叫productpage, kubectl get svc -n book-info\n\t  trafficPolicy:\n\t    loadBalancer:\t\t# 1.负载均衡 2.断路器 3.TLS 等等\n\t      simple: RANDOM\n\t    tls:\n\t      mode: ISTIO_MUTUAL\n\t  subsets:\n\t  - name: v1\n\t    labels:\n\t      version: v1\t\t# 对应pod的Labels标签里有version=v1, 可通过kubectl describe po/reviews-** -n book-info查看Labels.\n\t  - name: v2\n\t    labels:\n\t      version: v2\n\t  - name: v3\n\t    labels:\n\t      version: v3\n\n通过网关访问服务:\n\n\t$ curl -I -HHost:httpbin.example.com http://$INGRESS_HOST:$INGRESS_PORT/productpage/200\n\t上面命令将浏览器访问http://httpbin.example.com/producpage 对应的解析为 http://$INGRESS_HOST:$INGRESS_PORT/productpage/200\n\t这里-H选项是设置主机的HTTP报头为httpbin.example.com\n\n## **Dashboard & log**\n### Dashboard Overall\ncontrolz: 日志, 也可用kubectl logs查看不过不够直观\nenvoy\ngrafana\njaeger: 查看traces\nkiali: 服务网格的可视化展示\nprometheus\nzipkin: 查看traces\n\n查询istio提供了哪些dashboard\n\n\t$ istioctl dashboard\n查看或修改指定pod的log\n\n\t$ istioctl dashboard controlz istiod-5f47bf5895-lzm6w -n istio-system\n\t$ istioctl dashboard controlz istiod-5f47bf5895-lzm6w -n istio-system --address=192.168.22.184 // 添加了address监听地址\n\thttp://localhost:40230\n\t然后浏览器输入http://localhost:40230就可看到log信息\n查看envoy dashboard, 前提是跑业务的pod中部署了envoy proxy\n\n\t$ istioctl dashboard envoy prometheus-xxx -n istio-system\n\t$ istioctl dashboard envoy prometheus-xxx -n istio-system --address=192.168.22.184\n\n### log\n查看某个pod日志\n\n\t$ kubectl logs po/XXX -n Namespace\n修改整个istio的日志模式\n\n\t$ kubectl edit cm istio -n istio-system\n\t......\n\tdata:\n\t  mesh: |-\n\t    accessLogEncoding: TEXT\t\t// 日志默认是TEXT格式输出，可以改为json模式, 再序列话可以很直观查看进出istio envoy的流量的方向, 上下流等.\n\n### **kiali**\n\n\t$ istioctl dashboard kiali\n\t$ while true; do curl http://10.239.186.141/productpage; done; \n![](kiali_1.PNG)\n\n\n","slug":"micro_service/istio_03_configuration_dashboard","published":1,"date":"2020-08-12T16:05:47.521Z","updated":"2020-08-17T13:12:24.558Z","_id":"ckdwpt4vk0000mghx783e7kae","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"Architecture\"><a href=\"#Architecture\" class=\"headerlink\" title=\"Architecture\"></a>Architecture</h2><blockquote>\n<p>新的 Mixer 模型使用 Envoy 中的扩展来提供更多功能。Istio 社区正在领导 Envoy 的 WebAssembly（Wasm）运行时的实现，Wasm 让我们可以使用超过 20 种的语言来开发模块化、沙盒化的扩展。可以在代理继续提供流量的同时动态加载、重载扩展<br>通过 preview 配置文件安装 Istio 1.5 不会再安装 Mixer<br>如果有需要，您可以保持安装并启用 Mixer。最终，Mixer 将成为 Istio 单独的发行组件，成为 istio-ecosystem 的一部分<br>简化其余控制平面的 deployment。为此，我们将几个控制平面组件合并为一个组件：Istiod。该二进制文件包括 Pilot、Citadel、Galley 和 Sidecar 注入器的功能。这种方法从许多方面改善了 Istio 的安装和管理，降低了安装和配置的复杂性、维护工作量以及问题诊断时间，同时提高了响应速度。 关于 Istiod 的更多内容请查看 <a href=\"https://blog.christianposta.com/microservices/istio-as-an-example-of-when-not-to-do-microservices/\" target=\"_blank\" rel=\"noopener\">Christian Posta 的这篇博客</a>。<br>Istiod 作为 1.5 中所有配置文件的默认配置<br>从图片来看，我们正在从这里：<br><img src=\"istio_arch_19.JPG\" alt=\"\"><br>迁移到这里：<br><img src=\"istio_arch_20.JPG\" alt=\"\"><br>2020 年，我们将继续专注于普及，实现默认 零配置 的目标，该默认设置不需要您更改应用程序的任何配置即可使用 Istio 的大多数功能。</p>\n</blockquote>\n<h2 id=\"Security-Policy\"><a href=\"#Security-Policy\" class=\"headerlink\" title=\"Security Policy\"></a><strong>Security Policy</strong></h2><p><img src=\"security_policy.PNG\" alt=\"\"></p>\n<h3 id=\"AuthorizationPolicy\"><a href=\"#AuthorizationPolicy\" class=\"headerlink\" title=\"AuthorizationPolicy\"></a><strong>AuthorizationPolicy</strong></h3><p>授权认证, 精细化管理网格内的服务可以被哪些服务访问</p>\n<ul>\n<li>From-来源: 指定从哪里来的服务可以访问此由Label Selector指定的服务</li>\n<li>To-操作: 能访问到哪些路径,如使用get方法, Path路径等</li>\n<li>When- 条件: 当满足某条件的时候可以访问服务</li>\n</ul>\n<pre><code>$ cat mtls-auth.yaml\napiVersion: security.istio.io/v1beta1\nkind: AuthorizationPolicy\nmetadata:\n  name: box-nginx\n  namespace: rancher\nspec:\n  action: ALLOW\n  selector:\n    matchLabels:\n      app: nginx-primary\n  rules:\n  - from:\n    - source:                //包括principals, host主机, IP等等更细致话配置\n      principals: [&quot;cluster.local/ns/rancher/sa/box&quot;]    // 指定从namespace:rancher, serviceAccount:box 的服务可以访问标签为app=nginx-primary的服务</code></pre><h3 id=\"PeerAuthentication\"><a href=\"#PeerAuthentication\" class=\"headerlink\" title=\"PeerAuthentication\"></a><strong>PeerAuthentication</strong></h3><p>对等授权认证, 三种模式:</p>\n<ul>\n<li>PERMISSIVE-宽容 (default,服务间正常访问)</li>\n<li>STRICT-严格(网格内服务启用mtls)</li>\n<li>DISABLE-取消网格内的mtls</li>\n</ul>\n<pre><code>$ cat peer.yaml\napiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: rancher-policy\n  namespace: rancher\nspec:\n  mtls:\n  mode: STRICT    // 网格内服务必须经过mtls双向握手才能进行通信, 加强网格内服务安全性, 网格外服务是不会访问进来的</code></pre><h3 id=\"RequestAuthentication-JWT\"><a href=\"#RequestAuthentication-JWT\" class=\"headerlink\" title=\"RequestAuthentication JWT\"></a><strong>RequestAuthentication JWT</strong></h3><h2 id=\"Official-website-demo-bookinfo\"><a href=\"#Official-website-demo-bookinfo\" class=\"headerlink\" title=\"Official website demo bookinfo\"></a><strong>Official website demo bookinfo</strong></h2><p><img src=\"traffic_control.PNG\" alt=\"\"></p>\n<h3 id=\"Gateway-amp-VirtualService\"><a href=\"#Gateway-amp-VirtualService\" class=\"headerlink\" title=\"Gateway &amp; VirtualService\"></a><strong>Gateway &amp; VirtualService</strong></h3><pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: Gateway            # 相当于外部服务要访问网格内服务的第二道大门, 第一道大门是istio默认的ingressgateway网关\nmetadata:\n  name: bookinfo-gateway\nspec:\n  selector:\n    istio: ingressgateway # use istio default controller\n  servers:\n  - port:\n      number: 80        # 定义一个80端口供别人访问, 并把80端口暴露到网关上面\n      name: http\n      protocol: HTTP\n    hosts:            # &quot;*&quot; 表示访问任何主机的80端口都映射都下面的VirtualService下的destination对应的productpage\n    - &quot;*&quot;            # 也指定为&quot;httpbin.example.com&quot;, 当访问此网址时去找对应的下面的VirtualService, 但需要做解析，否则浏览器无法访问得到.\n---                # 解析方法: linux: 修改/etc/hosts, windows: 修改/Windows/System32/drivers/etc/hosts\n                    # 添加内容: `Host-Name httpbin.example.com`， 浏览器就可输入http://httpbin.example.com/productpage/200, 然后鼠标右击-&gt;Inspect-&gt;Network-&gt;Headers， 刷新网页即可看到报头\napiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: bookinfo\nspec:\n  hosts:\n  - &quot;*&quot;                    # 也指定为&quot;httpbin.example.com&quot;, 与上面的hosts保持一致\n  gateways:\n  - bookinfo-gateway    # 绑定上面Gateway, 从外部如浏览器可以访问如: curl -s http://ingressgateway-Host-IP:NodePortNumber/productpage\n  http:                    # 访问协议是http的时候才会进一步匹配\n  - match:\n    - uri:\n        exact: /productpage\n    - uri:\n        prefix: /static\n    - uri:\n        exact: /login\n    - uri:\n        exact: /logout\n    - uri:\n        prefix: /api/v1/products\n    route:\n    - destination:\n        host: productpage    # 匹配上面满足后路由到对应k8s部署的svc名字叫productpage的服务, 通过kubectl get svc -n book-info查看\n        port:\n          number: 9080        # 路由到服务productpage的9080端口提供的服务\n  route:                    # 上命没有匹配到默认到productpage service\n  - destination:\n      host: productpage\n      port:\n        number: 9080</code></pre><p><strong>VirtualService</strong></p>\n<pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: reviews\nspec:                    # 没有绑定gateway, 因此从外部还无法访问\n  hosts:\n    - reviews\n  http:\n  - route:\n    - destination:\n        host: reviews\n        subset: v1        # 对应下名DestinationRule reviews中的name: v1\n      weight: 80        # 路由权重\n    - destination:\n        host: reviews\n        subset: v1        # 对应下名DestinationRule reviews中的name: v2\n      weight: 20</code></pre><h3 id=\"DestinationRule\"><a href=\"#DestinationRule\" class=\"headerlink\" title=\"DestinationRule\"></a><strong>DestinationRule</strong></h3><pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: DestinationRule        # 路由指向由host指定的svc下面通过Label selector包含的特定POD\nmetadata:\n  name: reviews\nspec:\n  host: reviews            # 对应k8s部署的svc名字叫productpage, kubectl get svc -n book-info\n  trafficPolicy:\n    loadBalancer:        # 1.负载均衡 2.断路器 3.TLS 等等\n      simple: RANDOM\n    tls:\n      mode: ISTIO_MUTUAL\n  subsets:\n  - name: v1\n    labels:\n      version: v1        # 对应pod的Labels标签里有version=v1, 可通过kubectl describe po/reviews-** -n book-info查看Labels.\n  - name: v2\n    labels:\n      version: v2\n  - name: v3\n    labels:\n      version: v3</code></pre><p>通过网关访问服务:</p>\n<pre><code>$ curl -I -HHost:httpbin.example.com http://$INGRESS_HOST:$INGRESS_PORT/productpage/200\n上面命令将浏览器访问http://httpbin.example.com/producpage 对应的解析为 http://$INGRESS_HOST:$INGRESS_PORT/productpage/200\n这里-H选项是设置主机的HTTP报头为httpbin.example.com</code></pre><h2 id=\"Dashboard-amp-log\"><a href=\"#Dashboard-amp-log\" class=\"headerlink\" title=\"Dashboard &amp; log\"></a><strong>Dashboard &amp; log</strong></h2><h3 id=\"Dashboard-Overall\"><a href=\"#Dashboard-Overall\" class=\"headerlink\" title=\"Dashboard Overall\"></a>Dashboard Overall</h3><p>controlz: 日志, 也可用kubectl logs查看不过不够直观<br>envoy<br>grafana<br>jaeger: 查看traces<br>kiali: 服务网格的可视化展示<br>prometheus<br>zipkin: 查看traces</p>\n<p>查询istio提供了哪些dashboard</p>\n<pre><code>$ istioctl dashboard</code></pre><p>查看或修改指定pod的log</p>\n<pre><code>$ istioctl dashboard controlz istiod-5f47bf5895-lzm6w -n istio-system\n$ istioctl dashboard controlz istiod-5f47bf5895-lzm6w -n istio-system --address=192.168.22.184 // 添加了address监听地址\nhttp://localhost:40230\n然后浏览器输入http://localhost:40230就可看到log信息</code></pre><p>查看envoy dashboard, 前提是跑业务的pod中部署了envoy proxy</p>\n<pre><code>$ istioctl dashboard envoy prometheus-xxx -n istio-system\n$ istioctl dashboard envoy prometheus-xxx -n istio-system --address=192.168.22.184</code></pre><h3 id=\"log\"><a href=\"#log\" class=\"headerlink\" title=\"log\"></a>log</h3><p>查看某个pod日志</p>\n<pre><code>$ kubectl logs po/XXX -n Namespace</code></pre><p>修改整个istio的日志模式</p>\n<pre><code>$ kubectl edit cm istio -n istio-system\n......\ndata:\n  mesh: |-\n    accessLogEncoding: TEXT        // 日志默认是TEXT格式输出，可以改为json模式, 再序列话可以很直观查看进出istio envoy的流量的方向, 上下流等.</code></pre><h3 id=\"kiali\"><a href=\"#kiali\" class=\"headerlink\" title=\"kiali\"></a><strong>kiali</strong></h3><pre><code>$ istioctl dashboard kiali\n$ while true; do curl http://10.239.186.141/productpage; done; </code></pre><p><img src=\"kiali_1.PNG\" alt=\"\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Architecture\"><a href=\"#Architecture\" class=\"headerlink\" title=\"Architecture\"></a>Architecture</h2><blockquote>\n<p>新的 Mixer 模型使用 Envoy 中的扩展来提供更多功能。Istio 社区正在领导 Envoy 的 WebAssembly（Wasm）运行时的实现，Wasm 让我们可以使用超过 20 种的语言来开发模块化、沙盒化的扩展。可以在代理继续提供流量的同时动态加载、重载扩展<br>通过 preview 配置文件安装 Istio 1.5 不会再安装 Mixer<br>如果有需要，您可以保持安装并启用 Mixer。最终，Mixer 将成为 Istio 单独的发行组件，成为 istio-ecosystem 的一部分<br>简化其余控制平面的 deployment。为此，我们将几个控制平面组件合并为一个组件：Istiod。该二进制文件包括 Pilot、Citadel、Galley 和 Sidecar 注入器的功能。这种方法从许多方面改善了 Istio 的安装和管理，降低了安装和配置的复杂性、维护工作量以及问题诊断时间，同时提高了响应速度。 关于 Istiod 的更多内容请查看 <a href=\"https://blog.christianposta.com/microservices/istio-as-an-example-of-when-not-to-do-microservices/\" target=\"_blank\" rel=\"noopener\">Christian Posta 的这篇博客</a>。<br>Istiod 作为 1.5 中所有配置文件的默认配置<br>从图片来看，我们正在从这里：<br><img src=\"istio_arch_19.JPG\" alt=\"\"><br>迁移到这里：<br><img src=\"istio_arch_20.JPG\" alt=\"\"><br>2020 年，我们将继续专注于普及，实现默认 零配置 的目标，该默认设置不需要您更改应用程序的任何配置即可使用 Istio 的大多数功能。</p>\n</blockquote>\n<h2 id=\"Security-Policy\"><a href=\"#Security-Policy\" class=\"headerlink\" title=\"Security Policy\"></a><strong>Security Policy</strong></h2><p><img src=\"security_policy.PNG\" alt=\"\"></p>\n<h3 id=\"AuthorizationPolicy\"><a href=\"#AuthorizationPolicy\" class=\"headerlink\" title=\"AuthorizationPolicy\"></a><strong>AuthorizationPolicy</strong></h3><p>授权认证, 精细化管理网格内的服务可以被哪些服务访问</p>\n<ul>\n<li>From-来源: 指定从哪里来的服务可以访问此由Label Selector指定的服务</li>\n<li>To-操作: 能访问到哪些路径,如使用get方法, Path路径等</li>\n<li>When- 条件: 当满足某条件的时候可以访问服务</li>\n</ul>\n<pre><code>$ cat mtls-auth.yaml\napiVersion: security.istio.io/v1beta1\nkind: AuthorizationPolicy\nmetadata:\n  name: box-nginx\n  namespace: rancher\nspec:\n  action: ALLOW\n  selector:\n    matchLabels:\n      app: nginx-primary\n  rules:\n  - from:\n    - source:                //包括principals, host主机, IP等等更细致话配置\n      principals: [&quot;cluster.local/ns/rancher/sa/box&quot;]    // 指定从namespace:rancher, serviceAccount:box 的服务可以访问标签为app=nginx-primary的服务</code></pre><h3 id=\"PeerAuthentication\"><a href=\"#PeerAuthentication\" class=\"headerlink\" title=\"PeerAuthentication\"></a><strong>PeerAuthentication</strong></h3><p>对等授权认证, 三种模式:</p>\n<ul>\n<li>PERMISSIVE-宽容 (default,服务间正常访问)</li>\n<li>STRICT-严格(网格内服务启用mtls)</li>\n<li>DISABLE-取消网格内的mtls</li>\n</ul>\n<pre><code>$ cat peer.yaml\napiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: rancher-policy\n  namespace: rancher\nspec:\n  mtls:\n  mode: STRICT    // 网格内服务必须经过mtls双向握手才能进行通信, 加强网格内服务安全性, 网格外服务是不会访问进来的</code></pre><h3 id=\"RequestAuthentication-JWT\"><a href=\"#RequestAuthentication-JWT\" class=\"headerlink\" title=\"RequestAuthentication JWT\"></a><strong>RequestAuthentication JWT</strong></h3><h2 id=\"Official-website-demo-bookinfo\"><a href=\"#Official-website-demo-bookinfo\" class=\"headerlink\" title=\"Official website demo bookinfo\"></a><strong>Official website demo bookinfo</strong></h2><p><img src=\"traffic_control.PNG\" alt=\"\"></p>\n<h3 id=\"Gateway-amp-VirtualService\"><a href=\"#Gateway-amp-VirtualService\" class=\"headerlink\" title=\"Gateway &amp; VirtualService\"></a><strong>Gateway &amp; VirtualService</strong></h3><pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: Gateway            # 相当于外部服务要访问网格内服务的第二道大门, 第一道大门是istio默认的ingressgateway网关\nmetadata:\n  name: bookinfo-gateway\nspec:\n  selector:\n    istio: ingressgateway # use istio default controller\n  servers:\n  - port:\n      number: 80        # 定义一个80端口供别人访问, 并把80端口暴露到网关上面\n      name: http\n      protocol: HTTP\n    hosts:            # &quot;*&quot; 表示访问任何主机的80端口都映射都下面的VirtualService下的destination对应的productpage\n    - &quot;*&quot;            # 也指定为&quot;httpbin.example.com&quot;, 当访问此网址时去找对应的下面的VirtualService, 但需要做解析，否则浏览器无法访问得到.\n---                # 解析方法: linux: 修改/etc/hosts, windows: 修改/Windows/System32/drivers/etc/hosts\n                    # 添加内容: `Host-Name httpbin.example.com`， 浏览器就可输入http://httpbin.example.com/productpage/200, 然后鼠标右击-&gt;Inspect-&gt;Network-&gt;Headers， 刷新网页即可看到报头\napiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: bookinfo\nspec:\n  hosts:\n  - &quot;*&quot;                    # 也指定为&quot;httpbin.example.com&quot;, 与上面的hosts保持一致\n  gateways:\n  - bookinfo-gateway    # 绑定上面Gateway, 从外部如浏览器可以访问如: curl -s http://ingressgateway-Host-IP:NodePortNumber/productpage\n  http:                    # 访问协议是http的时候才会进一步匹配\n  - match:\n    - uri:\n        exact: /productpage\n    - uri:\n        prefix: /static\n    - uri:\n        exact: /login\n    - uri:\n        exact: /logout\n    - uri:\n        prefix: /api/v1/products\n    route:\n    - destination:\n        host: productpage    # 匹配上面满足后路由到对应k8s部署的svc名字叫productpage的服务, 通过kubectl get svc -n book-info查看\n        port:\n          number: 9080        # 路由到服务productpage的9080端口提供的服务\n  route:                    # 上命没有匹配到默认到productpage service\n  - destination:\n      host: productpage\n      port:\n        number: 9080</code></pre><p><strong>VirtualService</strong></p>\n<pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: reviews\nspec:                    # 没有绑定gateway, 因此从外部还无法访问\n  hosts:\n    - reviews\n  http:\n  - route:\n    - destination:\n        host: reviews\n        subset: v1        # 对应下名DestinationRule reviews中的name: v1\n      weight: 80        # 路由权重\n    - destination:\n        host: reviews\n        subset: v1        # 对应下名DestinationRule reviews中的name: v2\n      weight: 20</code></pre><h3 id=\"DestinationRule\"><a href=\"#DestinationRule\" class=\"headerlink\" title=\"DestinationRule\"></a><strong>DestinationRule</strong></h3><pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: DestinationRule        # 路由指向由host指定的svc下面通过Label selector包含的特定POD\nmetadata:\n  name: reviews\nspec:\n  host: reviews            # 对应k8s部署的svc名字叫productpage, kubectl get svc -n book-info\n  trafficPolicy:\n    loadBalancer:        # 1.负载均衡 2.断路器 3.TLS 等等\n      simple: RANDOM\n    tls:\n      mode: ISTIO_MUTUAL\n  subsets:\n  - name: v1\n    labels:\n      version: v1        # 对应pod的Labels标签里有version=v1, 可通过kubectl describe po/reviews-** -n book-info查看Labels.\n  - name: v2\n    labels:\n      version: v2\n  - name: v3\n    labels:\n      version: v3</code></pre><p>通过网关访问服务:</p>\n<pre><code>$ curl -I -HHost:httpbin.example.com http://$INGRESS_HOST:$INGRESS_PORT/productpage/200\n上面命令将浏览器访问http://httpbin.example.com/producpage 对应的解析为 http://$INGRESS_HOST:$INGRESS_PORT/productpage/200\n这里-H选项是设置主机的HTTP报头为httpbin.example.com</code></pre><h2 id=\"Dashboard-amp-log\"><a href=\"#Dashboard-amp-log\" class=\"headerlink\" title=\"Dashboard &amp; log\"></a><strong>Dashboard &amp; log</strong></h2><h3 id=\"Dashboard-Overall\"><a href=\"#Dashboard-Overall\" class=\"headerlink\" title=\"Dashboard Overall\"></a>Dashboard Overall</h3><p>controlz: 日志, 也可用kubectl logs查看不过不够直观<br>envoy<br>grafana<br>jaeger: 查看traces<br>kiali: 服务网格的可视化展示<br>prometheus<br>zipkin: 查看traces</p>\n<p>查询istio提供了哪些dashboard</p>\n<pre><code>$ istioctl dashboard</code></pre><p>查看或修改指定pod的log</p>\n<pre><code>$ istioctl dashboard controlz istiod-5f47bf5895-lzm6w -n istio-system\n$ istioctl dashboard controlz istiod-5f47bf5895-lzm6w -n istio-system --address=192.168.22.184 // 添加了address监听地址\nhttp://localhost:40230\n然后浏览器输入http://localhost:40230就可看到log信息</code></pre><p>查看envoy dashboard, 前提是跑业务的pod中部署了envoy proxy</p>\n<pre><code>$ istioctl dashboard envoy prometheus-xxx -n istio-system\n$ istioctl dashboard envoy prometheus-xxx -n istio-system --address=192.168.22.184</code></pre><h3 id=\"log\"><a href=\"#log\" class=\"headerlink\" title=\"log\"></a>log</h3><p>查看某个pod日志</p>\n<pre><code>$ kubectl logs po/XXX -n Namespace</code></pre><p>修改整个istio的日志模式</p>\n<pre><code>$ kubectl edit cm istio -n istio-system\n......\ndata:\n  mesh: |-\n    accessLogEncoding: TEXT        // 日志默认是TEXT格式输出，可以改为json模式, 再序列话可以很直观查看进出istio envoy的流量的方向, 上下流等.</code></pre><h3 id=\"kiali\"><a href=\"#kiali\" class=\"headerlink\" title=\"kiali\"></a><strong>kiali</strong></h3><pre><code>$ istioctl dashboard kiali\n$ while true; do curl http://10.239.186.141/productpage; done; </code></pre><p><img src=\"kiali_1.PNG\" alt=\"\"></p>\n"}],"PostAsset":[{"_id":"source/_posts/blogs/HTTP_TCP_Socket/ISO-TCP.IP.png","slug":"ISO-TCP.IP.png","post":"ckdt3hmbk0002hohxeg92g1pc","modified":0,"renderable":0},{"_id":"source/_posts/blogs/Hexo_01_部署github_blog/registry_gitalk.PNG","slug":"registry_gitalk.PNG","post":"ckdt3hmbm0004hohx3ryi04nw","modified":0,"renderable":0},{"_id":"source/_posts/deeplearning/deeplearning_01_get_started/02.PNG","slug":"02.PNG","post":"ckdt3hmbw000bhohx6xmx31zh","modified":0,"renderable":0},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture10.jpg","slug":"picture10.jpg","post":"ckdt3hmc7000ihohx5ctccebh","modified":0,"renderable":0},{"_id":"source/_posts/deeplearning/deeplearning_01_get_started/01.PNG","slug":"01.PNG","post":"ckdt3hmbw000bhohx6xmx31zh","modified":0,"renderable":0},{"_id":"source/_posts/deeplearning/deeplearning_01_get_started/07.PNG","slug":"07.PNG","post":"ckdt3hmbw000bhohx6xmx31zh","modified":0,"renderable":0},{"_id":"source/_posts/linux/sda_hda/IDE_power_sata.png","slug":"IDE_power_sata.png","post":"ckdt3hmft0039hohx7tj48sc0","modified":0,"renderable":0},{"_id":"source/_posts/linux/sda_hda/sda_interface.png","slug":"sda_interface.png","post":"ckdt3hmft0039hohx7tj48sc0","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/09_kubernetes_certificate/k8s_certificates.PNG","slug":"k8s_certificates.PNG","post":"ckdt3hmgc004rhohx0qqt3l4o","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/services_analysis/architecture.png","slug":"architecture.png","post":"ckdt3hmgk005dhohxfn4tdl18","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/sublimeconf21.png","slug":"sublimeconf21.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/technologies/maven/maven_project/jar.JPG","slug":"jar.JPG","post":"ckdt3hmmw008thohx43wef4ec","modified":0,"renderable":0},{"_id":"source/_posts/blogs/Restful_API/Restful.png","slug":"Restful.png","post":"ckdt3hmbt0009hohx6njy27x3","modified":0,"renderable":0},{"_id":"source/_posts/linux/BIOS/bios.gif","slug":"bios.gif","post":"ckdt3hmc2000ghohxdcvfg16y","modified":0,"renderable":0},{"_id":"source/_posts/linux/硬盘存储空间单位GB/unit_GB.gif","slug":"unit_GB.gif","post":"ckdt3hmg0003thohx327agzf6","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/05_kubernetes_volume/PV_PVC.PNG","slug":"PV_PVC.PNG","post":"ckdt3hmg6004bhohx08xqbea4","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/07_kubernetes_Etcd/etcd_3.PNG","slug":"etcd_3.PNG","post":"ckdt3hmg8004jhohx3ejy4up6","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/4.node_modules/taobao_mirror.PNG","slug":"taobao_mirror.PNG","post":"ckdt3hmgs0062hohx5y1t6596","modified":0,"renderable":0},{"_id":"source/_posts/blogs/Hexo_01_部署github_blog/deploy.jpg","slug":"deploy.jpg","post":"ckdt3hmbm0004hohx3ryi04nw","modified":0,"renderable":0},{"_id":"source/_posts/linux/ACPI是什么&BIOS中ACPI要怎么设置/acpi.jpg","slug":"acpi.jpg","post":"ckdt3hmby000chohx7kiu6ptb","modified":0,"renderable":0},{"_id":"source/_posts/linux/ACPI是什么&BIOS中ACPI要怎么设置/acpi_bios.jpg","slug":"acpi_bios.jpg","post":"ckdt3hmby000chohx7kiu6ptb","modified":0,"renderable":0},{"_id":"source/_posts/linux/Linux_kernel_userspace体系结构/linux_gun.jpg","slug":"linux_gun.jpg","post":"ckdt3hmcs0010hohxhzn63ph4","modified":0,"renderable":0},{"_id":"source/_posts/linux/Linux_kernel_userspace体系结构/linux_kernel.jpg","slug":"linux_kernel.jpg","post":"ckdt3hmcs0010hohxhzn63ph4","modified":0,"renderable":0},{"_id":"source/_posts/linux/screen程序在后台运行/screen_logs.png","slug":"screen_logs.png","post":"ckdt3hmfs0037hohxf6bmav6w","modified":0,"renderable":0},{"_id":"source/_posts/linux/screen程序在后台运行/screenlog.0.png","slug":"screenlog.0.png","post":"ckdt3hmfs0037hohxf6bmav6w","modified":0,"renderable":0},{"_id":"source/_posts/linux/按字节-字寻址_字长_地址总线_数据总线关系/address.png","slug":"address.png","post":"ckdt3hmfy003nhohxeasngtzd","modified":0,"renderable":0},{"_id":"source/_posts/linux/按字节-字寻址_字长_地址总线_数据总线关系/logical_physical.png","slug":"logical_physical.png","post":"ckdt3hmfy003nhohxeasngtzd","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/09_kubernetes_certificate/CA_simulate.PNG","slug":"CA_simulate.PNG","post":"ckdt3hmgc004rhohx0qqt3l4o","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/services_analysis/REST_FUL_API.png","slug":"REST_FUL_API.png","post":"ckdt3hmgk005dhohxfn4tdl18","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/2.Windows10_Node.js_安装/NODE_PATH.png","slug":"NODE_PATH.png","post":"ckdt3hmgo005phohx8kle7b4v","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/2.Windows10_Node.js_安装/PATH_nodejs_intall.png","slug":"PATH_nodejs_intall.png","post":"ckdt3hmgo005phohx8kle7b4v","modified":0,"renderable":0},{"_id":"source/_posts/linux/ssh端口映射/local_port_transmit.png","slug":"local_port_transmit.png","post":"ckdt3hmfu003bhohxci6tf3f2","modified":0,"renderable":0},{"_id":"source/_posts/linux/ssh端口映射/local_port_transmit1.png","slug":"local_port_transmit1.png","post":"ckdt3hmfu003bhohxci6tf3f2","modified":0,"renderable":0},{"_id":"source/_posts/linux/ssh端口映射/port_transmit_protocol.png","slug":"port_transmit_protocol.png","post":"ckdt3hmfu003bhohxci6tf3f2","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/istio_01_conception/Pilot_Architecture.png","slug":"Pilot_Architecture.png","post":"ckdt3hmgh0052hohxg0rtci2f","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/istio_01_conception/envoy_xds.png","slug":"envoy_xds.png","post":"ckdt3hmgh0052hohxg0rtci2f","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/istio_01_conception/istio_arch.jpeg","slug":"istio_arch.jpeg","post":"ckdt3hmgh0052hohxg0rtci2f","modified":0,"renderable":0},{"_id":"source/_posts/blogs/HTTP_TCP_Socket/ISO.png","slug":"ISO.png","post":"ckdt3hmbk0002hohxeg92g1pc","modified":0,"renderable":0},{"_id":"source/_posts/blogs/HTTP_TCP_Socket/socket.jpg","slug":"socket.jpg","post":"ckdt3hmbk0002hohxeg92g1pc","modified":0,"renderable":0},{"_id":"source/_posts/blogs/HTTP_TCP_Socket/tcp-ip-handshark.png","slug":"tcp-ip-handshark.png","post":"ckdt3hmbk0002hohxeg92g1pc","modified":0,"renderable":0},{"_id":"source/_posts/linux/U盘分区之后如何恢复/clean.png","slug":"clean.png","post":"ckdt3hme0001mhohx8clj8xxk","modified":0,"renderable":0},{"_id":"source/_posts/linux/U盘分区之后如何恢复/diskpart.png","slug":"diskpart.png","post":"ckdt3hme0001mhohx8clj8xxk","modified":0,"renderable":0},{"_id":"source/_posts/linux/U盘分区之后如何恢复/list_disk.png","slug":"list_disk.png","post":"ckdt3hme0001mhohx8clj8xxk","modified":0,"renderable":0},{"_id":"source/_posts/linux/U盘分区之后如何恢复/select_disk.png","slug":"select_disk.png","post":"ckdt3hme0001mhohx8clj8xxk","modified":0,"renderable":0},{"_id":"source/_posts/linux/linux制作U盘启动盘/dd.png","slug":"dd.png","post":"ckdt3hmfi002lhohxe7yn13q1","modified":0,"renderable":0},{"_id":"source/_posts/linux/linux制作U盘启动盘/fdisk.png","slug":"fdisk.png","post":"ckdt3hmfi002lhohxe7yn13q1","modified":0,"renderable":0},{"_id":"source/_posts/linux/linux制作U盘启动盘/mkfs.png","slug":"mkfs.png","post":"ckdt3hmfi002lhohxe7yn13q1","modified":0,"renderable":0},{"_id":"source/_posts/linux/linux制作U盘启动盘/umount.png","slug":"umount.png","post":"ckdt3hmfi002lhohxe7yn13q1","modified":0,"renderable":0},{"_id":"source/_posts/linux/sda_hda/IDE_interface.png","slug":"IDE_interface.png","post":"ckdt3hmft0039hohx7tj48sc0","modified":0,"renderable":0},{"_id":"source/_posts/linux/sda_hda/power_data_interface.png","slug":"power_data_interface.png","post":"ckdt3hmft0039hohx7tj48sc0","modified":0,"renderable":0},{"_id":"source/_posts/windows/U盘分区之后如何恢复/1.png","slug":"1.png","post":"ckdt3hmh4006yhohx0hr06vgc","modified":0,"renderable":0},{"_id":"source/_posts/windows/U盘分区之后如何恢复/2.png","slug":"2.png","post":"ckdt3hmh4006yhohx0hr06vgc","modified":0,"renderable":0},{"_id":"source/_posts/windows/U盘分区之后如何恢复/3.png","slug":"3.png","post":"ckdt3hmh4006yhohx0hr06vgc","modified":0,"renderable":0},{"_id":"source/_posts/windows/U盘分区之后如何恢复/4.png","slug":"4.png","post":"ckdt3hmh4006yhohx0hr06vgc","modified":0,"renderable":0},{"_id":"source/_posts/windows/U盘分区之后如何恢复/5.png","slug":"5.png","post":"ckdt3hmh4006yhohx0hr06vgc","modified":0,"renderable":0},{"_id":"source/_posts/deeplearning/deeplearning_01_get_started/03.PNG","slug":"03.PNG","post":"ckdt3hmbw000bhohx6xmx31zh","modified":0,"renderable":0},{"_id":"source/_posts/deeplearning/deeplearning_01_get_started/04.PNG","slug":"04.PNG","post":"ckdt3hmbw000bhohx6xmx31zh","modified":0,"renderable":0},{"_id":"source/_posts/deeplearning/deeplearning_01_get_started/05.PNG","slug":"05.PNG","post":"ckdt3hmbw000bhohx6xmx31zh","modified":0,"renderable":0},{"_id":"source/_posts/deeplearning/deeplearning_01_get_started/06.PNG","slug":"06.PNG","post":"ckdt3hmbw000bhohx6xmx31zh","modified":0,"renderable":0},{"_id":"source/_posts/deeplearning/deeplearning_01_get_started/08.PNG","slug":"08.PNG","post":"ckdt3hmbw000bhohx6xmx31zh","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/1.webstorm自动提示设置/1.png","slug":"1.png","post":"ckdt3hmgl005hhohxeud05w4h","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/1.webstorm自动提示设置/2.png","slug":"2.png","post":"ckdt3hmgl005hhohxeud05w4h","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/1.webstorm自动提示设置/3.png","slug":"3.png","post":"ckdt3hmgl005hhohxeud05w4h","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/1.webstorm自动提示设置/4.png","slug":"4.png","post":"ckdt3hmgl005hhohxeud05w4h","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/1.webstorm自动提示设置/5.png","slug":"5.png","post":"ckdt3hmgl005hhohxeud05w4h","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/1.webstorm自动提示设置/6.png","slug":"6.png","post":"ckdt3hmgl005hhohxeud05w4h","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/1.webstorm自动提示设置/7.png","slug":"7.png","post":"ckdt3hmgl005hhohxeud05w4h","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/1.webstorm自动提示设置/8.png","slug":"8.png","post":"ckdt3hmgl005hhohxeud05w4h","modified":0,"renderable":0},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture1.jpg","slug":"picture1.jpg","post":"ckdt3hmc7000ihohx5ctccebh","modified":0,"renderable":0},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture11.jpg","slug":"picture11.jpg","post":"ckdt3hmc7000ihohx5ctccebh","modified":0,"renderable":0},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture12.jpg","slug":"picture12.jpg","post":"ckdt3hmc7000ihohx5ctccebh","modified":0,"renderable":0},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture2.jpg","slug":"picture2.jpg","post":"ckdt3hmc7000ihohx5ctccebh","modified":0,"renderable":0},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture3.jpg","slug":"picture3.jpg","post":"ckdt3hmc7000ihohx5ctccebh","modified":0,"renderable":0},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture4.jpg","slug":"picture4.jpg","post":"ckdt3hmc7000ihohx5ctccebh","modified":0,"renderable":0},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture5.jpg","slug":"picture5.jpg","post":"ckdt3hmc7000ihohx5ctccebh","modified":0,"renderable":0},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture6.jpg","slug":"picture6.jpg","post":"ckdt3hmc7000ihohx5ctccebh","modified":0,"renderable":0},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture7.jpg","slug":"picture7.jpg","post":"ckdt3hmc7000ihohx5ctccebh","modified":0,"renderable":0},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture8.jpg","slug":"picture8.jpg","post":"ckdt3hmc7000ihohx5ctccebh","modified":0,"renderable":0},{"_id":"source/_posts/linux/CPU角度理解PCIE/picture9.jpg","slug":"picture9.jpg","post":"ckdt3hmc7000ihohx5ctccebh","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/01_kubernetes_build/1.JPG","slug":"1.JPG","post":"ckdt3hmg30041hohxfufqcm73","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/01_kubernetes_build/2.JPG","slug":"2.JPG","post":"ckdt3hmg30041hohxfufqcm73","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/01_kubernetes_build/3.JPG","slug":"3.JPG","post":"ckdt3hmg30041hohxfufqcm73","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/01_kubernetes_build/4.JPG","slug":"4.JPG","post":"ckdt3hmg30041hohxfufqcm73","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/01_kubernetes_build/5.JPG","slug":"5.JPG","post":"ckdt3hmg30041hohxfufqcm73","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/01_kubernetes_build/6.JPG","slug":"6.JPG","post":"ckdt3hmg30041hohxfufqcm73","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/01_kubernetes_build/Asymmetric_encryption.JPG","slug":"Asymmetric_encryption.JPG","post":"ckdt3hmg30041hohxfufqcm73","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/01_kubernetes_build/K8s_arch1.JPG","slug":"K8s_arch1.JPG","post":"ckdt3hmg30041hohxfufqcm73","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/01_kubernetes_build/K8s_arch2.JPG","slug":"K8s_arch2.JPG","post":"ckdt3hmg30041hohxfufqcm73","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/01_kubernetes_build/K8s_arch3.JPG","slug":"K8s_arch3.JPG","post":"ckdt3hmg30041hohxfufqcm73","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/01_kubernetes_build/K8s_arch4.JPG","slug":"K8s_arch4.JPG","post":"ckdt3hmg30041hohxfufqcm73","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/01_kubernetes_build/Pod_Scaling.JPG","slug":"Pod_Scaling.JPG","post":"ckdt3hmg30041hohxfufqcm73","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/01_kubernetes_build/Pod_communication1.JPG","slug":"Pod_communication1.JPG","post":"ckdt3hmg30041hohxfufqcm73","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/01_kubernetes_build/Pod_communication2.JPG","slug":"Pod_communication2.JPG","post":"ckdt3hmg30041hohxfufqcm73","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/01_kubernetes_build/Pod_communication3.JPG","slug":"Pod_communication3.JPG","post":"ckdt3hmg30041hohxfufqcm73","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/01_kubernetes_build/Rolling_update1.JPG","slug":"Rolling_update1.JPG","post":"ckdt3hmg30041hohxfufqcm73","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/01_kubernetes_build/Rolling_update2.JPG","slug":"Rolling_update2.JPG","post":"ckdt3hmg30041hohxfufqcm73","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/01_kubernetes_build/Symmetric_encryption.JPG","slug":"Symmetric_encryption.JPG","post":"ckdt3hmg30041hohxfufqcm73","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/01_kubernetes_build/k8s_architecture1.JPG","slug":"k8s_architecture1.JPG","post":"ckdt3hmg30041hohxfufqcm73","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/01_kubernetes_build/k8s_architecture2.JPG","slug":"k8s_architecture2.JPG","post":"ckdt3hmg30041hohxfufqcm73","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/pki/tls_deployment.jpg","slug":"tls_deployment.jpg","post":"ckdt3hmog0097hohxck5b6kgy","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/51jobnode.png","slug":"51jobnode.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/DNS.gif","slug":"DNS.gif","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/HTTPMsgStructure2.png","slug":"HTTPMsgStructure2.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/Web.png","slug":"Web.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/chrome_rendering1.png","slug":"chrome_rendering1.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/chrome_rendering2.png","slug":"chrome_rendering2.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/client-server.png","slug":"client-server.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/css_parser.png","slug":"css_parser.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/dom.png","slug":"dom.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/env_path.png","slug":"env_path.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/fiddlersetup.exe","slug":"fiddlersetup.exe","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/flow.png","slug":"flow.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/gecko.jpg","slug":"gecko.jpg","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/handshake.png","slug":"handshake.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/htmlFormEl.png","slug":"htmlFormEl.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/http-header.png","slug":"http-header.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/node-modules.png","slug":"node-modules.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/nodeWeb.png","slug":"nodeWeb.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/npm.png","slug":"npm.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/npm1.png","slug":"npm1.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/sublimeconf1.png","slug":"sublimeconf1.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/sublimeconf22.png","slug":"sublimeconf22.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/taobao_ip.png","slug":"taobao_ip.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/taobao_url.png","slug":"taobao_url.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/nodejs/浏览器工作原理/webkitflow.png","slug":"webkitflow.png","post":"ckdt3hmgt0064hohx2ce45l3g","modified":0,"renderable":0},{"_id":"source/_posts/technologies/web/HTML/6.PNG","slug":"6.PNG","post":"ckdt3hmom009uhohx5uwoh2fx","modified":0,"renderable":0},{"_id":"source/_posts/windows/Windows10_VScode远程连接linux编辑调试/1.png","slug":"1.png","post":"ckdt3hmhz008ghohxfmf65p41","modified":0,"renderable":0},{"_id":"source/_posts/windows/Windows10_VScode远程连接linux编辑调试/2.png","slug":"2.png","post":"ckdt3hmhz008ghohxfmf65p41","modified":0,"renderable":0},{"_id":"source/_posts/windows/Windows10_VScode远程连接linux编辑调试/3.png","slug":"3.png","post":"ckdt3hmhz008ghohxfmf65p41","modified":0,"renderable":0},{"_id":"source/_posts/windows/Windows10_VScode远程连接linux编辑调试/4.png","slug":"4.png","post":"ckdt3hmhz008ghohxfmf65p41","modified":0,"renderable":0},{"_id":"source/_posts/windows/Windows10_VScode远程连接linux编辑调试/5.png","slug":"5.png","post":"ckdt3hmhz008ghohxfmf65p41","modified":0,"renderable":0},{"_id":"source/_posts/windows/Windows10_VScode远程连接linux编辑调试/6.png","slug":"6.png","post":"ckdt3hmhz008ghohxfmf65p41","modified":0,"renderable":0},{"_id":"source/_posts/windows/Windows10_VScode远程连接linux编辑调试/7.png","slug":"7.png","post":"ckdt3hmhz008ghohxfmf65p41","modified":0,"renderable":0},{"_id":"source/_posts/technologies/docker/dockerfile/01.png","slug":"01.png","post":"ckdt3hmm8008qhohx5tai17jd","modified":0,"renderable":0},{"_id":"source/_posts/language/python/linux_install_python_pip_pipenv/pipfile.JPG","slug":"pipfile.JPG","post":"ckdt3hmlf008mhohxbvn33usu","modified":0,"renderable":0},{"_id":"source/_posts/technologies/web/JavaScript/pic.JPG","slug":"pic.JPG","post":"ckdt3hmom009rhohxdv7h9kc8","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/token_jwt/token_scene1.png","slug":"token_scene1.png","post":"ckdt3hmoj009hhohxapct2xgn","modified":0,"renderable":0},{"_id":"source/_posts/technologies/docker/dockerfile/02.png","slug":"02.png","post":"ckdt3hmm8008qhohx5tai17jd","modified":0,"renderable":0},{"_id":"source/_posts/technologies/maven/maven_project/compile.JPG","slug":"compile.JPG","post":"ckdt3hmmw008thohx43wef4ec","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/pki/base_encryption.png","slug":"base_encryption.png","post":"ckdt3hmog0097hohxck5b6kgy","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/pki/key_save.png","slug":"key_save.png","post":"ckdt3hmog0097hohxck5b6kgy","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/pki/pki_mode.png","slug":"pki_mode.png","post":"ckdt3hmog0097hohxck5b6kgy","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/tls_ssl_https_http_protocol/http_tls_ssl.png","slug":"http_tls_ssl.png","post":"ckdt3hmoi009ehohx3zwu66wj","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/tls_ssl_https_http_protocol/https.png","slug":"https.png","post":"ckdt3hmoi009ehohx3zwu66wj","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/tls_ssl_https_http_protocol/osi.png","slug":"osi.png","post":"ckdt3hmoi009ehohx3zwu66wj","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/tls_ssl_https_http_protocol/tcp_ip.png","slug":"tcp_ip.png","post":"ckdt3hmoi009ehohx3zwu66wj","modified":0,"renderable":0},{"_id":"source/_posts/technologies/web/HTML/1.PNG","slug":"1.PNG","post":"ckdt3hmom009uhohx5uwoh2fx","modified":0,"renderable":0},{"_id":"source/_posts/technologies/web/HTML/12.PNG","slug":"12.PNG","post":"ckdt3hmom009uhohx5uwoh2fx","modified":0,"renderable":0},{"_id":"source/_posts/technologies/web/HTML/2.PNG","slug":"2.PNG","post":"ckdt3hmom009uhohx5uwoh2fx","modified":0,"renderable":0},{"_id":"source/_posts/technologies/web/HTML/3.PNG","slug":"3.PNG","post":"ckdt3hmom009uhohx5uwoh2fx","modified":0,"renderable":0},{"_id":"source/_posts/technologies/web/HTML/4.PNG","slug":"4.PNG","post":"ckdt3hmom009uhohx5uwoh2fx","modified":0,"renderable":0},{"_id":"source/_posts/technologies/web/HTML/5.PNG","slug":"5.PNG","post":"ckdt3hmom009uhohx5uwoh2fx","modified":0,"renderable":0},{"_id":"source/_posts/technologies/web/HTML/6_1.PNG","slug":"6_1.PNG","post":"ckdt3hmom009uhohx5uwoh2fx","modified":0,"renderable":0},{"_id":"source/_posts/technologies/web/HTML/7.PNG","slug":"7.PNG","post":"ckdt3hmom009uhohx5uwoh2fx","modified":0,"renderable":0},{"_id":"source/_posts/technologies/web/HTML/table_td_empty.gif","slug":"table_td_empty.gif","post":"ckdt3hmom009uhohx5uwoh2fx","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/0.PNG","slug":"0.PNG","post":"ckdt3hmo40091hohx3f0hbr1d","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/1.png","slug":"1.png","post":"ckdt3hmo40091hohx3f0hbr1d","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/10.png","slug":"10.png","post":"ckdt3hmo40091hohx3f0hbr1d","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/11.png","slug":"11.png","post":"ckdt3hmo40091hohx3f0hbr1d","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/12.png","slug":"12.png","post":"ckdt3hmo40091hohx3f0hbr1d","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/13.png","slug":"13.png","post":"ckdt3hmo40091hohx3f0hbr1d","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/14.jpg","slug":"14.jpg","post":"ckdt3hmo40091hohx3f0hbr1d","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/15.png","slug":"15.png","post":"ckdt3hmo40091hohx3f0hbr1d","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/16.png","slug":"16.png","post":"ckdt3hmo40091hohx3f0hbr1d","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/17.png","slug":"17.png","post":"ckdt3hmo40091hohx3f0hbr1d","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/18.png","slug":"18.png","post":"ckdt3hmo40091hohx3f0hbr1d","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/19.jpg","slug":"19.jpg","post":"ckdt3hmo40091hohx3f0hbr1d","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/2.png","slug":"2.png","post":"ckdt3hmo40091hohx3f0hbr1d","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/20.png","slug":"20.png","post":"ckdt3hmo40091hohx3f0hbr1d","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/3.png","slug":"3.png","post":"ckdt3hmo40091hohx3f0hbr1d","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/4.png","slug":"4.png","post":"ckdt3hmo40091hohx3f0hbr1d","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/5.png","slug":"5.png","post":"ckdt3hmo40091hohx3f0hbr1d","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/6.png","slug":"6.png","post":"ckdt3hmo40091hohx3f0hbr1d","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/7.png","slug":"7.png","post":"ckdt3hmo40091hohx3f0hbr1d","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/8.png","slug":"8.png","post":"ckdt3hmo40091hohx3f0hbr1d","modified":0,"renderable":0},{"_id":"source/_posts/technologies/security/key_digest_signature_certificates/9.png","slug":"9.png","post":"ckdt3hmo40091hohx3f0hbr1d","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/istio_03_configuration_dashboard/istio_arch_19.JPG","slug":"istio_arch_19.JPG","post":"ckdwpt4vk0000mghx783e7kae","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/istio_03_configuration_dashboard/istio_arch_20.JPG","slug":"istio_arch_20.JPG","post":"ckdwpt4vk0000mghx783e7kae","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/istio_03_configuration_dashboard/security_policy.PNG","slug":"security_policy.PNG","post":"ckdwpt4vk0000mghx783e7kae","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/istio_03_configuration_dashboard/traffic_control.PNG","slug":"traffic_control.PNG","post":"ckdwpt4vk0000mghx783e7kae","modified":0,"renderable":0},{"_id":"source/_posts/micro_service/istio_03_configuration_dashboard/kiali_1.PNG","slug":"kiali_1.PNG","post":"ckdwpt4vk0000mghx783e7kae","modified":0,"renderable":0}],"PostCategory":[{"post_id":"ckdt3hmbk0002hohxeg92g1pc","category_id":"ckdt3hmbp0007hohx0y5g3nd5","_id":"ckdt3hmbz000ehohxat7xbvo9"},{"post_id":"ckdt3hmbt0009hohx6njy27x3","category_id":"ckdt3hmbp0007hohx0y5g3nd5","_id":"ckdt3hmc5000hhohxb7hx7rv1"},{"post_id":"ckdt3hmbm0004hohx3ryi04nw","category_id":"ckdt3hmbp0007hohx0y5g3nd5","_id":"ckdt3hmc8000khohx3hnb59da"},{"post_id":"ckdt3hmbn0005hohx7y423oqe","category_id":"ckdt3hmbp0007hohx0y5g3nd5","_id":"ckdt3hmcd000ohohxahof8xxr"},{"post_id":"ckdt3hmbi0001hohx5pfl1irl","category_id":"ckdt3hmbl0003hohx2hea8acf","_id":"ckdt3hmck000thohxc6tlh33o"},{"post_id":"ckdt3hmbi0001hohx5pfl1irl","category_id":"ckdt3hmc8000jhohxfcilaxte","_id":"ckdt3hmcm000vhohxemzfcnud"},{"post_id":"ckdt3hmbo0006hohx0f6n1cql","category_id":"ckdt3hmbp0007hohx0y5g3nd5","_id":"ckdt3hmcp000xhohxdg14aimz"},{"post_id":"ckdt3hmbp0008hohx6jwl8zjf","category_id":"ckdt3hmcj000shohx45ow3c3i","_id":"ckdt3hmcv0011hohx7bch2hjq"},{"post_id":"ckdt3hmbw000bhohx6xmx31zh","category_id":"ckdt3hmcp000yhohx1gvk1di0","_id":"ckdt3hmd60016hohx9nmy3voc"},{"post_id":"ckdt3hmd10014hohxd0ncaaeg","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmdd001ahohxawgg517i"},{"post_id":"ckdt3hmby000chohx7kiu6ptb","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmdh001dhohxhloeawas"},{"post_id":"ckdt3hmd90018hohxa5b65gq5","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmdk001fhohx3sd80449"},{"post_id":"ckdt3hmc2000ghohxdcvfg16y","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmdo001ihohxg7gudc9c"},{"post_id":"ckdt3hmdc0019hohxbnos6g82","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmds001khohxajl0bdy9"},{"post_id":"ckdt3hmdg001chohx7gxzco5x","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hme0001nhohx0res1iew"},{"post_id":"ckdt3hmc7000ihohx5ctccebh","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hme4001phohx0av44p1v"},{"post_id":"ckdt3hmdk001ehohx6dym6wlh","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmeb001shohxhbnnhtf6"},{"post_id":"ckdt3hmdo001hhohx2rgpd386","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmef001uhohx3oh45t6u"},{"post_id":"ckdt3hmca000lhohx1how6kzw","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmek001xhohxagqc129g"},{"post_id":"ckdt3hmdr001jhohx7moa5t0w","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmep001zhohx1pwo96qd"},{"post_id":"ckdt3hme0001mhohx8clj8xxk","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmet0022hohx83ee9guy"},{"post_id":"ckdt3hmcc000nhohx2xyf96ek","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmex0024hohxf2s10k3f"},{"post_id":"ckdt3hme4001ohohxgk8b1c9r","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmf20027hohxhrg7cmv4"},{"post_id":"ckdt3hme9001rhohx8hkzahs1","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmf60029hohx7sd7fj4i"},{"post_id":"ckdt3hmcf000qhohxdmf84rvr","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmfb002chohxbnqvf07z"},{"post_id":"ckdt3hmef001thohx9ki9dkbp","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmff002ehohx5m2xh57p"},{"post_id":"ckdt3hmej001whohxchaj4jr3","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmfg002hhohx99afhebq"},{"post_id":"ckdt3hmch000rhohxdb4ncwky","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmfh002jhohx0w9bgfh8"},{"post_id":"ckdt3hmeo001yhohx4cb45v1z","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmfi002mhohxej89b3gv"},{"post_id":"ckdt3hmet0021hohxcrx12shh","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmfj002ohohx4jer1dtp"},{"post_id":"ckdt3hmck000uhohxdp278o2h","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmfk002qhohxheb16g6s"},{"post_id":"ckdt3hmex0023hohx8kl4b11f","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmfl002shohx68y610pj"},{"post_id":"ckdt3hmf10026hohx8t2nc56b","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmfm002uhohxf8e03wyu"},{"post_id":"ckdt3hmcm000whohx2i3aaqpo","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmfm002whohx3xshe3gr"},{"post_id":"ckdt3hmf60028hohxa776heq2","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmfn002yhohxc26kc7f7"},{"post_id":"ckdt3hmfa002bhohx3sdrbsm1","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmfo0030hohx9m6i27b0"},{"post_id":"ckdt3hmcp000zhohxh61l6g1p","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmfo0032hohxbgk52xh8"},{"post_id":"ckdt3hmff002dhohx31y9hm9m","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmfr0034hohx4zt15v3n"},{"post_id":"ckdt3hmfg002ghohx90hnc481","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmfs0036hohxfnavcf6e"},{"post_id":"ckdt3hmcs0010hohxhzn63ph4","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmft0038hohxd7an4pcm"},{"post_id":"ckdt3hmfh002ihohxhmzqc9m2","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmfu003ahohxh3ul1zfm"},{"post_id":"ckdt3hmfi002lhohxe7yn13q1","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmfv003chohx79j431bt"},{"post_id":"ckdt3hmcv0012hohxcsuldp2n","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmfv003ehohxa2die9bt"},{"post_id":"ckdt3hmfi002nhohxdu01evvp","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmfw003hhohxgeno3iaw"},{"post_id":"ckdt3hmfj002phohx1th1cime","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmfx003jhohxcnzufa1o"},{"post_id":"ckdt3hmfk002rhohxdni184pe","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmfy003lhohxdekecnzw"},{"post_id":"ckdt3hmfl002thohx8api1uab","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmfy003ohohx26q22679"},{"post_id":"ckdt3hmfm002vhohx01645frx","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmfz003qhohx5b8uddwl"},{"post_id":"ckdt3hmfm002xhohxctwyboln","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmg0003shohxb7yug4mw"},{"post_id":"ckdt3hmfn002zhohx1fzu2ya9","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmg1003uhohxcs8kan9b"},{"post_id":"ckdt3hmfo0031hohx9kx76r5j","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmg1003whohx2r0c7hf8"},{"post_id":"ckdt3hmfp0033hohx2l33armm","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmg2003yhohx7ron2cbo"},{"post_id":"ckdt3hmfr0035hohxaunvgpo7","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmg30040hohxbir91aoj"},{"post_id":"ckdt3hmfs0037hohxf6bmav6w","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmg30042hohx43odc0zw"},{"post_id":"ckdt3hmft0039hohx7tj48sc0","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmg40044hohxh7x6dtw8"},{"post_id":"ckdt3hmfu003bhohxci6tf3f2","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmg50048hohx5etyebfr"},{"post_id":"ckdt3hmfv003dhohx3lja7upo","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmg6004ahohx0flnehxg"},{"post_id":"ckdt3hmfw003ghohx4n0fesgf","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmg7004ehohxd0lcffr7"},{"post_id":"ckdt3hmfx003ihohxhquvesbh","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmg8004hhohxdjniei1z"},{"post_id":"ckdt3hmfx003khohxgilshk8f","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmg9004mhohx4oxf0eyd"},{"post_id":"ckdt3hmfy003nhohxeasngtzd","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmga004phohx1hu725p8"},{"post_id":"ckdt3hmfz003phohxfv2pdhga","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmgc004thohxbt2vaa4u"},{"post_id":"ckdt3hmfz003rhohxepb8fwh2","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmgd004whohx9zdg6umw"},{"post_id":"ckdt3hmg0003thohx327agzf6","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmgg004zhohx1e3yev7l"},{"post_id":"ckdt3hmg1003vhohxg3gv6s4s","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmgh0053hohx3detbpnl"},{"post_id":"ckdt3hmg1003xhohxhwsn472z","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmgi0056hohx9spyb6d3"},{"post_id":"ckdt3hmg2003zhohxbndicd3v","category_id":"ckdt3hmcy0013hohx7rbo61gb","_id":"ckdt3hmgk005bhohx65wmftu5"},{"post_id":"ckdt3hmg50049hohx4arxfxcb","category_id":"ckdt3hmg40045hohxek716bww","_id":"ckdt3hmgl005ehohx7hmi20xb"},{"post_id":"ckdt3hmg50049hohx4arxfxcb","category_id":"ckdt3hmgc004shohx1k011z08","_id":"ckdt3hmgm005jhohxdm06djua"},{"post_id":"ckdt3hmge004yhohx0tw701dz","category_id":"ckdt3hmg40045hohxek716bww","_id":"ckdt3hmgn005mhohx7yj56ldj"},{"post_id":"ckdt3hmge004yhohx0tw701dz","category_id":"ckdt3hmgc004shohx1k011z08","_id":"ckdt3hmgo005rhohx7g6q3usz"},{"post_id":"ckdt3hmg30041hohxfufqcm73","category_id":"ckdt3hmg40045hohxek716bww","_id":"ckdt3hmgq005uhohxbfae35u6"},{"post_id":"ckdt3hmg30041hohxfufqcm73","category_id":"ckdt3hmgc004shohx1k011z08","_id":"ckdt3hmgr005xhohx4a6gggh7"},{"post_id":"ckdt3hmg6004bhohx08xqbea4","category_id":"ckdt3hmg40045hohxek716bww","_id":"ckdt3hmgs0060hohx2z9j9pmm"},{"post_id":"ckdt3hmg6004bhohx08xqbea4","category_id":"ckdt3hmgc004shohx1k011z08","_id":"ckdt3hmgt0063hohx8ra3f2w7"},{"post_id":"ckdt3hmg7004ghohx49b3enuo","category_id":"ckdt3hmg40045hohxek716bww","_id":"ckdt3hmgu0065hohx3zf792n4"},{"post_id":"ckdt3hmg7004ghohx49b3enuo","category_id":"ckdt3hmgc004shohx1k011z08","_id":"ckdt3hmgv0068hohxdgba4rdl"},{"post_id":"ckdt3hmg30043hohxfvja1uu1","category_id":"ckdt3hmg40045hohxek716bww","_id":"ckdt3hmgw006ahohxavz41en0"},{"post_id":"ckdt3hmg30043hohxfvja1uu1","category_id":"ckdt3hmgc004shohx1k011z08","_id":"ckdt3hmgx006ehohxaut66gmr"},{"post_id":"ckdt3hmg8004jhohx3ejy4up6","category_id":"ckdt3hmg40045hohxek716bww","_id":"ckdt3hmgz006ghohxdlnbf055"},{"post_id":"ckdt3hmg8004jhohx3ejy4up6","category_id":"ckdt3hmgc004shohx1k011z08","_id":"ckdt3hmh0006khohx4id2ahzi"},{"post_id":"ckdt3hmga004ohohxht6n42go","category_id":"ckdt3hmg40045hohxek716bww","_id":"ckdt3hmh1006nhohx393db2oq"},{"post_id":"ckdt3hmga004ohohxht6n42go","category_id":"ckdt3hmgc004shohx1k011z08","_id":"ckdt3hmh2006shohxfidd8ubk"},{"post_id":"ckdt3hmg40047hohx0rqj1c2t","category_id":"ckdt3hmg40045hohxek716bww","_id":"ckdt3hmh3006vhohx7096dpn6"},{"post_id":"ckdt3hmg40047hohx0rqj1c2t","category_id":"ckdt3hmgc004shohx1k011z08","_id":"ckdt3hmh4006zhohx5jo340ee"},{"post_id":"ckdt3hmgc004rhohx0qqt3l4o","category_id":"ckdt3hmg40045hohxek716bww","_id":"ckdt3hmh50072hohxfdorh4ad"},{"post_id":"ckdt3hmgc004rhohx0qqt3l4o","category_id":"ckdt3hmgc004shohx1k011z08","_id":"ckdt3hmh60075hohxcv7p8at0"},{"post_id":"ckdt3hmgd004vhohxbs4h3mfi","category_id":"ckdt3hmg40045hohxek716bww","_id":"ckdt3hmh60076hohxanmzgguh"},{"post_id":"ckdt3hmgd004vhohxbs4h3mfi","category_id":"ckdt3hmgz006hhohx9awndt37","_id":"ckdt3hmh60079hohxe2rn65t1"},{"post_id":"ckdt3hmgh0052hohxg0rtci2f","category_id":"ckdt3hmg40045hohxek716bww","_id":"ckdt3hmh6007ahohx3zbd68gb"},{"post_id":"ckdt3hmgh0052hohxg0rtci2f","category_id":"ckdt3hmgz006hhohx9awndt37","_id":"ckdt3hmh7007chohx1broa4ss"},{"post_id":"ckdt3hmgi0055hohx4dvudg48","category_id":"ckdt3hmg40045hohxek716bww","_id":"ckdt3hmh7007dhohx206e2qtl"},{"post_id":"ckdt3hmgi0055hohx4dvudg48","category_id":"ckdt3hmgz006hhohx9awndt37","_id":"ckdt3hmh7007fhohx73fhctrt"},{"post_id":"ckdt3hmgk005dhohxfn4tdl18","category_id":"ckdt3hmg40045hohxek716bww","_id":"ckdt3hmh8007jhohx9yrweape"},{"post_id":"ckdt3hmgk005dhohxfn4tdl18","category_id":"ckdt3hmh60077hohx056b3qn9","_id":"ckdt3hmh8007lhohxakn46p92"},{"post_id":"ckdt3hmgl005hhohxeud05w4h","category_id":"ckdt3hmh6007bhohxb1iy7qre","_id":"ckdt3hmh8007mhohxetuddy96"},{"post_id":"ckdt3hmgn005lhohx09jm3mx8","category_id":"ckdt3hmh6007bhohxb1iy7qre","_id":"ckdt3hmh8007ohohxfhcc8inw"},{"post_id":"ckdt3hmgo005phohx8kle7b4v","category_id":"ckdt3hmh6007bhohxb1iy7qre","_id":"ckdt3hmh8007phohx45t0foe6"},{"post_id":"ckdt3hmgp005thohx1bdybopp","category_id":"ckdt3hmh6007bhohxb1iy7qre","_id":"ckdt3hmh9007rhohx2g0a0z72"},{"post_id":"ckdt3hmgq005whohxf6ikf9zt","category_id":"ckdt3hmh6007bhohxb1iy7qre","_id":"ckdt3hmh9007thohx6410hkth"},{"post_id":"ckdt3hmgr005zhohxaokzg9dk","category_id":"ckdt3hmh6007bhohxb1iy7qre","_id":"ckdt3hmha007vhohx1pkw38yx"},{"post_id":"ckdt3hmgs0062hohx5y1t6596","category_id":"ckdt3hmh6007bhohxb1iy7qre","_id":"ckdt3hmha007xhohxfdxr3tlz"},{"post_id":"ckdt3hmgt0064hohx2ce45l3g","category_id":"ckdt3hmh6007bhohxb1iy7qre","_id":"ckdt3hmha007yhohx9pupezhz"},{"post_id":"ckdt3hmgv0067hohx9pwk942x","category_id":"ckdt3hmha007whohx5u5z4fh4","_id":"ckdt3hmhb0081hohx3r9p0nvo"},{"post_id":"ckdt3hmgv0069hohx49dx53cu","category_id":"ckdt3hmha007whohx5u5z4fh4","_id":"ckdt3hmhb0083hohx0jmdhrsr"},{"post_id":"ckdt3hmgw006dhohx8sc6drtj","category_id":"ckdt3hmha007whohx5u5z4fh4","_id":"ckdt3hmhd0085hohxhlquau7c"},{"post_id":"ckdt3hmgx006fhohx6s442w9z","category_id":"ckdt3hmha007whohx5u5z4fh4","_id":"ckdt3hmhe0087hohxcbjfcqc6"},{"post_id":"ckdt3hmgz006ihohxe0t38dat","category_id":"ckdt3hmha007whohx5u5z4fh4","_id":"ckdt3hmhe0089hohx233cd8nh"},{"post_id":"ckdt3hmh1006mhohxfsle9fob","category_id":"ckdt3hmha007whohx5u5z4fh4","_id":"ckdt3hmhe008ahohxdqd2gndz"},{"post_id":"ckdt3hmh2006qhohx7s0z5lbe","category_id":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmhf008dhohx6nnt6ma6"},{"post_id":"ckdt3hmh3006uhohxesbv6e2l","category_id":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmhf008ehohx9fok2ex5"},{"post_id":"ckdt3hmh4006yhohx0hr06vgc","category_id":"ckdt3hmhf008chohxf4nj8et7","_id":"ckdt3hmhf008fhohx22nfbmxv"},{"post_id":"ckdt3hmhz008ghohxfmf65p41","category_id":"ckdt3hmhf008chohxf4nj8et7","_id":"ckdt3hmi1008hhohx4kjnd2v4"},{"post_id":"ckdt3hml3008lhohx0bz46jo7","category_id":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmni008xhohx241uf4td"},{"post_id":"ckdt3hml3008lhohx0bz46jo7","category_id":"ckdt3hmm8008rhohxhz764dlo","_id":"ckdt3hmns0090hohx5f40fkgd"},{"post_id":"ckdt3hmlf008mhohxbvn33usu","category_id":"ckdt3hml3008khohx7oejc87p","_id":"ckdt3hmof0092hohxe3y57s8j"},{"post_id":"ckdt3hmlf008mhohxbvn33usu","category_id":"ckdt3hmmw008uhohx8ipi1kxi","_id":"ckdt3hmog0096hohx535zcio6"},{"post_id":"ckdt3hml2008ihohx0xbpcheg","category_id":"ckdt3hml3008khohx7oejc87p","_id":"ckdt3hmoh0099hohx4sl9d953"},{"post_id":"ckdt3hml2008ihohx0xbpcheg","category_id":"ckdt3hmnr008yhohx3n388q20","_id":"ckdt3hmoi009dhohxaynlg77s"},{"post_id":"ckdt3hmlo008nhohxc36c95br","category_id":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmoj009ghohxd7yi3wqr"},{"post_id":"ckdt3hmlo008nhohxc36c95br","category_id":"ckdt3hmm8008rhohxhz764dlo","_id":"ckdt3hmok009khohx5v4k9dza"},{"post_id":"ckdt3hmly008phohx3rrd9vzx","category_id":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmol009ohohx5uky2yz8"},{"post_id":"ckdt3hmly008phohx3rrd9vzx","category_id":"ckdt3hmoh0098hohx4t1ag7o3","_id":"ckdt3hmom009shohx3pj84jus"},{"post_id":"ckdt3hml2008jhohxcueu4twc","category_id":"ckdt3hml3008khohx7oejc87p","_id":"ckdt3hmon009whohx8cnv7mp8"},{"post_id":"ckdt3hml2008jhohxcueu4twc","category_id":"ckdt3hmoj009ihohx8e0k07dv","_id":"ckdt3hmon009xhohx7bgxgvzf"},{"post_id":"ckdt3hmm8008qhohx5tai17jd","category_id":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmoo009zhohx65i89zyn"},{"post_id":"ckdt3hmm8008qhohx5tai17jd","category_id":"ckdt3hmm8008rhohxhz764dlo","_id":"ckdt3hmoo00a0hohx056a0uvq"},{"post_id":"ckdt3hmmj008shohx4nwc57ht","category_id":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmoo00a2hohx5oplfbvi"},{"post_id":"ckdt3hmmj008shohx4nwc57ht","category_id":"ckdt3hmoh0098hohx4t1ag7o3","_id":"ckdt3hmop00a3hohx7okvhfmx"},{"post_id":"ckdt3hmmw008thohx43wef4ec","category_id":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmop00a5hohx26sz6ike"},{"post_id":"ckdt3hmmw008thohx43wef4ec","category_id":"ckdt3hmoh0098hohx4t1ag7o3","_id":"ckdt3hmop00a6hohx03tuc5va"},{"post_id":"ckdt3hmn6008vhohx91yv53kl","category_id":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmop00a8hohxgs8ighjj"},{"post_id":"ckdt3hmn6008vhohx91yv53kl","category_id":"ckdt3hmoh0098hohx4t1ag7o3","_id":"ckdt3hmoq00a9hohxakhvh2cy"},{"post_id":"ckdt3hmnh008whohx0q2ib3xd","category_id":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmoq00aahohx98pz5lrm"},{"post_id":"ckdt3hmnh008whohx0q2ib3xd","category_id":"ckdt3hmoh0098hohx4t1ag7o3","_id":"ckdt3hmoq00achohxaw0edadv"},{"post_id":"ckdt3hmns008zhohxbqh51bd7","category_id":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmoq00aehohx05e9gsjj"},{"post_id":"ckdt3hmns008zhohxbqh51bd7","category_id":"ckdt3hmop00a7hohxgc2bd91j","_id":"ckdt3hmor00afhohxgu4saray"},{"post_id":"ckdt3hmo40091hohx3f0hbr1d","category_id":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmor00ahhohx9nbs9n2k"},{"post_id":"ckdt3hmo40091hohx3f0hbr1d","category_id":"ckdt3hmop00a7hohxgc2bd91j","_id":"ckdt3hmor00aihohxfmq74hja"},{"post_id":"ckdt3hmof0095hohx6hae5h92","category_id":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmor00akhohxgnxhfidd"},{"post_id":"ckdt3hmof0095hohx6hae5h92","category_id":"ckdt3hmoh0098hohx4t1ag7o3","_id":"ckdt3hmos00alhohx1qrpeynx"},{"post_id":"ckdt3hmog0097hohxck5b6kgy","category_id":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmos00anhohx9wjkbfyi"},{"post_id":"ckdt3hmog0097hohxck5b6kgy","category_id":"ckdt3hmop00a7hohxgc2bd91j","_id":"ckdt3hmos00aohohx3mo0e0p8"},{"post_id":"ckdt3hmoh009ahohx21pa71os","category_id":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmot00aqhohxghgz33f1"},{"post_id":"ckdt3hmoh009ahohx21pa71os","category_id":"ckdt3hmop00a7hohxgc2bd91j","_id":"ckdt3hmot00arhohx55kq2q9e"},{"post_id":"ckdt3hmoi009ehohx3zwu66wj","category_id":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmot00athohxfwo3h3fj"},{"post_id":"ckdt3hmoi009ehohx3zwu66wj","category_id":"ckdt3hmop00a7hohxgc2bd91j","_id":"ckdt3hmot00auhohxftlianov"},{"post_id":"ckdt3hmoj009hhohxapct2xgn","category_id":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmot00avhohxdjey8qd5"},{"post_id":"ckdt3hmoj009hhohxapct2xgn","category_id":"ckdt3hmop00a7hohxgc2bd91j","_id":"ckdt3hmou00axhohxdlhm50wd"},{"post_id":"ckdt3hmok009lhohx6rp67lmw","category_id":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmou00azhohx89ttc0g6"},{"post_id":"ckdt3hmok009lhohx6rp67lmw","category_id":"ckdt3hmot00ashohxbg9y9x86","_id":"ckdt3hmou00b0hohxcxwd2zjd"},{"post_id":"ckdt3hmol009nhohx9itzcmpq","category_id":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmov00b2hohx3ys2d4cu"},{"post_id":"ckdt3hmol009nhohx9itzcmpq","category_id":"ckdt3hmot00ashohxbg9y9x86","_id":"ckdt3hmov00b3hohx6xdig09y"},{"post_id":"ckdt3hmom009rhohxdv7h9kc8","category_id":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmov00b4hohx9l5b8voy"},{"post_id":"ckdt3hmom009rhohxdv7h9kc8","category_id":"ckdt3hmot00ashohxbg9y9x86","_id":"ckdt3hmov00b5hohx2mjg66r8"},{"post_id":"ckdt3hmom009uhohx5uwoh2fx","category_id":"ckdt3hmhe0088hohxf9ld66ze","_id":"ckdt3hmov00b6hohxg2i7h5ec"},{"post_id":"ckdt3hmom009uhohx5uwoh2fx","category_id":"ckdt3hmot00ashohxbg9y9x86","_id":"ckdt3hmov00b7hohx9hfg1oxx"},{"post_id":"ckdwpt4vk0000mghx783e7kae","category_id":"ckdt3hmg40045hohxek716bww","_id":"ckdwpt4x00002mghxfuvsh9me"},{"post_id":"ckdwpt4vk0000mghx783e7kae","category_id":"ckdt3hmgz006hhohx9awndt37","_id":"ckdwpt4x00003mghx6rduhimu"}],"PostTag":[{"post_id":"ckdt3hmbw000bhohx6xmx31zh","tag_id":"ckdt3hmc1000fhohx6m78cusk","_id":"ckdt3hmcc000mhohxhm63dlje"},{"post_id":"ckdt3hmfu003bhohxci6tf3f2","tag_id":"ckdt3hmfw003fhohx4odv25ow","_id":"ckdt3hmfy003mhohx0by26to5"},{"post_id":"ckdt3hmg50049hohx4arxfxcb","tag_id":"ckdt3hmg40046hohxaz4phked","_id":"ckdt3hmg7004fhohx17k3b3c0"},{"post_id":"ckdt3hmg30041hohxfufqcm73","tag_id":"ckdt3hmg40046hohxaz4phked","_id":"ckdt3hmg8004ihohxfpl4105q"},{"post_id":"ckdt3hmg6004bhohx08xqbea4","tag_id":"ckdt3hmg40046hohxaz4phked","_id":"ckdt3hmga004nhohx2519cg1j"},{"post_id":"ckdt3hmg7004ghohx49b3enuo","tag_id":"ckdt3hmg40046hohxaz4phked","_id":"ckdt3hmgc004qhohx4p6zft45"},{"post_id":"ckdt3hmg30043hohxfvja1uu1","tag_id":"ckdt3hmg40046hohxaz4phked","_id":"ckdt3hmgd004uhohxcc1jhp86"},{"post_id":"ckdt3hmg8004jhohx3ejy4up6","tag_id":"ckdt3hmg40046hohxaz4phked","_id":"ckdt3hmge004xhohx4scp7ryf"},{"post_id":"ckdt3hmga004ohohxht6n42go","tag_id":"ckdt3hmg40046hohxaz4phked","_id":"ckdt3hmgg0051hohx9w8u16hn"},{"post_id":"ckdt3hmg40047hohx0rqj1c2t","tag_id":"ckdt3hmg40046hohxaz4phked","_id":"ckdt3hmgi0054hohx0kp46oos"},{"post_id":"ckdt3hmgc004rhohx0qqt3l4o","tag_id":"ckdt3hmg40046hohxaz4phked","_id":"ckdt3hmgj0059hohxfcq3bfcc"},{"post_id":"ckdt3hmgd004vhohxbs4h3mfi","tag_id":"ckdt3hmg40046hohxaz4phked","_id":"ckdt3hmgk005chohxcx7ibfoj"},{"post_id":"ckdt3hmge004yhohx0tw701dz","tag_id":"ckdt3hmg40046hohxaz4phked","_id":"ckdt3hmgl005ghohx2o4w8y3i"},{"post_id":"ckdt3hmgk005dhohxfn4tdl18","tag_id":"ckdt3hmg40046hohxaz4phked","_id":"ckdt3hmgn005khohx8vps08tn"},{"post_id":"ckdt3hmgh0052hohxg0rtci2f","tag_id":"ckdt3hmgj0058hohxcb6gca1g","_id":"ckdt3hmgo005ohohxemingkex"},{"post_id":"ckdt3hmgi0055hohx4dvudg48","tag_id":"ckdt3hmgj0058hohxcb6gca1g","_id":"ckdt3hmgp005shohx00st1lu9"},{"post_id":"ckdt3hmgx006fhohx6s442w9z","tag_id":"ckdt3hmgw006chohx8j4a0dcw","_id":"ckdt3hmh0006lhohx1roxgf8t"},{"post_id":"ckdt3hmgv0067hohx9pwk942x","tag_id":"ckdt3hmgw006chohx8j4a0dcw","_id":"ckdt3hmh1006phohxb7x5g294"},{"post_id":"ckdt3hmgz006ihohxe0t38dat","tag_id":"ckdt3hmgw006chohx8j4a0dcw","_id":"ckdt3hmh3006thohxb87jac3k"},{"post_id":"ckdt3hmh1006mhohxfsle9fob","tag_id":"ckdt3hmgw006chohx8j4a0dcw","_id":"ckdt3hmh4006xhohxeld35qkg"},{"post_id":"ckdt3hmgv0069hohx49dx53cu","tag_id":"ckdt3hmgw006chohx8j4a0dcw","_id":"ckdt3hmh50071hohxe7rl4d3w"},{"post_id":"ckdt3hmgw006dhohx8sc6drtj","tag_id":"ckdt3hmgw006chohx8j4a0dcw","_id":"ckdt3hmh50074hohxaxln0o69"},{"post_id":"ckdt3hmh3006uhohxesbv6e2l","tag_id":"ckdt3hmh40070hohx7vob67u5","_id":"ckdt3hmh60078hohx0lq28awj"},{"post_id":"ckdt3hmog0097hohxck5b6kgy","tag_id":"ckdt3hmof0093hohxc4aw9lec","_id":"ckdt3hmoi009chohxes3i4xyu"},{"post_id":"ckdt3hmns008zhohxbqh51bd7","tag_id":"ckdt3hmof0093hohxc4aw9lec","_id":"ckdt3hmoj009fhohx57x05dko"},{"post_id":"ckdt3hmoh009ahohx21pa71os","tag_id":"ckdt3hmof0093hohxc4aw9lec","_id":"ckdt3hmok009jhohx9w4h45es"},{"post_id":"ckdt3hmoi009ehohx3zwu66wj","tag_id":"ckdt3hmof0093hohxc4aw9lec","_id":"ckdt3hmol009mhohx17a61h7w"},{"post_id":"ckdt3hmo40091hohx3f0hbr1d","tag_id":"ckdt3hmof0093hohxc4aw9lec","_id":"ckdt3hmom009qhohxgr114on2"},{"post_id":"ckdt3hmoj009hhohxapct2xgn","tag_id":"ckdt3hmof0093hohxc4aw9lec","_id":"ckdt3hmom009thohx2zac541z"},{"post_id":"ckdwpt4vk0000mghx783e7kae","tag_id":"ckdt3hmgj0058hohxcb6gca1g","_id":"ckdwpt4x00001mghxf95o6ak5"}],"Tag":[{"name":"deeplearning","_id":"ckdt3hmc1000fhohx6m78cusk"},{"name":"SSH-port","_id":"ckdt3hmfw003fhohx4odv25ow"},{"name":"kubernetes","_id":"ckdt3hmg40046hohxaz4phked"},{"name":"istio","_id":"ckdt3hmgj0058hohxcb6gca1g"},{"name":"storage","_id":"ckdt3hmgw006chohx8j4a0dcw"},{"name":"git","_id":"ckdt3hmh40070hohx7vob67u5"},{"name":"security","_id":"ckdt3hmof0093hohxc4aw9lec"}]}}